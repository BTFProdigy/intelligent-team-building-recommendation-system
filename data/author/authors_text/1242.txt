Unsupervised Feature Selection for Relation Extraction
Jinxiu Chen1 Donghong Ji1 Chew Lim Tan2 Zhengyu Niu1
1Institute for Infocomm Research 2Department of Computer Science
21 Heng Mui Keng Terrace National University of Singapore
119613 Singapore 117543 Singapore
{jinxiu,dhji,zniu}@i2r.a-star.edu.sg tancl@comp.nus.edu.sg
Abstract
This paper presents an unsupervised re-
lation extraction algorithm, which in-
duces relations between entity pairs by
grouping them into a ?natural? num-
ber of clusters based on the similarity
of their contexts. Stability-based crite-
rion is used to automatically estimate
the number of clusters. For removing
noisy feature words in clustering proce-
dure, feature selection is conducted by
optimizing a trace based criterion sub-
ject to some constraint in an unsuper-
vised manner. After relation clustering
procedure, we employ a discriminative
category matching (DCM) to find typi-
cal and discriminative words to repre-
sent different relations. Experimental
results show the effectiveness of our al-
gorithm.
1 Introduction
Relation extraction is the task of finding rela-
tionships between two entities from text contents.
There has been considerable work on supervised
learning of relation patterns, using corpora which
have been annotated to indicate the information to
be extracted (e.g. (Califf and Mooney, 1999; Ze-
lenko et al, 2002)). A range of extraction mod-
els have been used, including both symbolic rules
and statistical rules such as HMMs or Kernels.
These methods have been particularly success-
ful in some specific domains. However, manu-
ally tagging of large amounts of training data is
very time-consuming; furthermore, it is difficult
for one extraction system to be ported across dif-
ferent domains.
Due to the limitation of supervised methods,
some weakly supervised (or semi-supervised) ap-
proaches have been suggested (Brin, 1998; Eu-
gene and Luis, 2000; Sudo et al, 2003). One
common characteristic of these algorithms is that
they need to pre-define some initial seeds for any
particular relation, then bootstrap from the seeds
to acquire the relation. However, it is not easy
to select representative seeds for obtaining good
results.
Hasegawa, et al put forward an unsuper-
vised approach for relation extraction from large
text corpora (Hasegawa et al, 2004). First, they
adopted a hierarchical clustering method to clus-
ter the contexts of entity pairs. Second, after con-
text clustering, they selected the most frequent
words in the contexts to represent the relation
that holds between the entities. However, the ap-
proach exists its limitation. Firstly, the similar-
ity threshold for the clusters, like the appropriate
number of clusters, is somewhat difficult to pre-
defined. Secondly, the representative words se-
lected by frequency tends to obscure the clusters.
For solving the above problems, we present a
novel unsupervised method based on model or-
der selection and discriminative label identifica-
tion. For achieving model order identification,
stability-based criterion is used to automatically
estimate the number of clusters. For removing
noisy feature words in clustering procedure, fea-
ture selection is conducted by optimizing a trace
based criterion subject to some constraint in an
262
unsupervised manner. Furthermore, after relation
clustering, we employ a discriminative category
matching (DCM) to find typical and discrimina-
tive words to represent different relations types.
2 Proposed Method
Feature selection for relation extraction is the task
of finding important contextual words which will
help to discriminate relation types. Unlike su-
pervised learning, where class labels can guide
feature search, in unsupervised learning, it is ex-
pected to define a criterion to assess the impor-
tance of the feature subsets. Due to the interplay
between feature selection and clustering solution,
we should define an objective function to evaluate
both feature subset and model order.
In this paper, the model selection capability is
achieved by resampling based stability analysis,
which has been successfully applied to several un-
supervised learning problems (e.g. (Levine and
Domany, 2001), (Lange et al, 2002), (Roth and
Lange et al, 2003), (Niu et al, 2004)). We extend
the cluster validation strategy further to address
both feature selection and model order identifica-
tion.
Table 1 presents our model selection algorithm.
The objective function MFk,k is relevant with
both feature subset and model order. Clustering
solution that is stable against resampling will give
rise to a local optimum of MFk,k, which indicates
both important feature subset and the true cluster
number.
2.1 Entropy-based Feature Ranking
Let P = {p1, p2, ...pN} be a set of local context
vectors of co-occurrences of entity pair E1 and
E2. Here, the context includes the words occur-
ring between, before and after the entity pair. Let
W = {w1, w2, ..., wM} represent all the words
occurred in P . To select a subset of important
features from W , words are first ranked accord-
ing to their importance on clustering. The im-
portance can be assessed by the entropy criterion.
Entropy-based feature ranking is based on the as-
sumption that a feature is irrelevant if the presence
of it obscures the separability of data set(Dash et
al., 2000).
We assume pn, 1 ? n ? N , lies in feature
space W , and the dimension of feature space is
Table 1: Model Selection Algorithm for Relation Extrac-
tion
Input: Corpus D tagged with Entities(E1, E2);
Output: Feature subset and Model Order (number of
relation types);
1. Collect the contexts of all entity pairs in the document
corpus D, namely P ;
2. Rank features using entropy-based method described
in section 2.1;
3. Set the range (Kl,Kh) for the possible number of
relation clusters;
4. Set estimated model order k = Kl;
5. Conduct feature selection using the algorithm pre-
sented in section 2.2;
6. Record F?k,k and the score of the merit of both of
them, namely MF,k;
7. If k < Kh, k = k + 1, go to step 5; otherwise, go to
Step 7;
8. Select k and feature subset F?k which maximizes the
score of the merit MF,k;
M . Then the similarity between i-th data point
pi and j-th data point pj is given by the equa-
tion: Si,j = exp(?? ? Di,j), where Di,j is the
Euclidean distance between pi and pj , and ? is a
positive constant, its value is ? ln 0.5D , where D is
the average distance among the data points. Then
the entropy of data set P with N data points is
defined as:
E = ?
N?
i=1
N?
j=1
(Si,j logSi,j + (1? Si,j) log(1? Si,j))
(1)
For ranking of features, the importance of each
word I(wk) is defined as entropy of the data af-
ter discarding feature wk. It is calculated in this
way: remove each word in turn from the feature
space and calculate E of the data in the new fea-
ture space using the Equation 1. Based on the
observation that a feature is the least important if
the removal of it results in minimum E, we can
obtain the rankings of the features.
2.2 Feature Subset Selection and Model
Order Identification
In this paper, for each specified cluster number,
firstly we perform K-means clustering analysis on
each feature subset and adopts a scattering cri-
terion ?Invariant Criterion? to select an optimal
feature subset F from the feature subset space.
Here, trace(P?1W PB) is used to compare the clus-
ter quality for different feature subsets 1, which
1trace(P?1W PB) is trace of a matrix which is the sum
of its diagonal elements. PW is the within-cluster scatter
263
Table 2: Unsupervised Algorithm for Evaluation of Fea-
ture Subset and Model Order
Function: criterion(F, k, P, q)
Input: feature subset F , cluster number k, entity pairs
set P , and sampling frequency q;
Output: the score of the merit of F and k;
1. With the cluster number k as input, perform k-means
clustering analysis on pairs set PF ;
2. Construct connectivity matrix CF,k based on above
clustering solution on full pairs set PF ;
3. Use a random predictor ?k to assign uniformly drawn
labels to each entity pair in PF ;
4. Construct connectivity matrix CF,?k based on above
clustering solution on full pairs set PF ;
5. Construct q sub sets of the full pairs set, by randomly
selecting ?N of the N original pairs, 0 ? ? ? 1;
6. For each sub set, perform the clustering analysis in
Step 2, 3, 4, and result C?F,k, C?F,?k ;
7. Compute MF,k to evaluate the merit of k using Equa-
tion 3;
8. Return MF,k;
measures the ratio of between-cluster to within-
cluster scatter. The higher the trace(P?1W PB), the
higher the cluster quality.
To improve searching efficiency, features are
first ranked according to their importance. As-
sume Wr = {f1, ..., fM} is the sorted feature list.
The task of searching can be seen in the feature
subset space: {(f1, ..., fk),1 ? k ? M}.
Then the selected feature subset F is eval-
uated with the cluster number using the ob-
jective function, which can be formulated as:
F?k = argmaxF?Wr{criterion(F, k)}, subject
to coverage(P, F ) ? ? 2. Here, F?k is the opti-
mal feature subset, F and k are the feature subset
and the value of cluster number under evaluation,
and the criterion is set up based on resampling-
based stability, as Table 2 shows.
Let P? be a subset sampled from full entity
pairs set P with size ?|P | (? set as 0.9 in this
paper.), C(C?) be |P | ? |P |(|P?| ? |P?|) con-
nectivity matrix based on the clustering results on
P (P?). Each entry cij(c?ij) of C(C?) is calculated
in the following: if the entity pair pi ? P (P?),
pj ? P (P?) belong to the same cluster, then
cij(c?ij) equals 1, else 0. Then the stability is de-
matrix as: PW =
?c
j=1
?
Xi??j (Xi ? mj)(Xj ? mj)
t
and PB is the between-cluster scatter matrix as: PB =?c
j=1(mj ?m)(mj ?m)t, where m is the total mean vec-
tor and mj is the mean vector for jth cluster and (Xj?mj)t
is the matrix transpose of the column vector (Xj ?mj).
2let coverage(P, F ) be the coverage rate of the feature
set F with respect to P . In practice, we set ? = 0.9.
fined in Equation 2:
M(C?, C) =
?
i,j 1{C?i,j = Ci,j = 1, pi ? P?, pj ? P?}?
i,j 1{Ci,j = 1, pi ? P?, pj ? P?}
(2)
Intuitively, M(C?, C) denotes the consistency
between the clustering results on C? and C. The
assumption is that if the cluster number k is actu-
ally the ?natural? number of relation types, then
clustering results on subsets P? generated by
sampling should be similar to the clustering re-
sult on full entity pair set P . Obviously, the above
function satisfies 0 ? M ? 1.
It is noticed that M(C?, C) tends to decrease
when increasing the value of k. Therefore for
avoiding the bias that small value of k is to be
selected as cluster number, we use the cluster
validity of a random predictor ?k to normalize
M(C?, C). The random predictor ?k achieved
the stability value by assigning uniformly drawn
labels to objects, that is, splitting the data into k
clusters randomly. Furthermore, for each k, we
tried q times. So, in the step 7 of the algorithm
of Table 2, the objective function M(C?F,k, CF,k)
can be normalized as equations 3:
MnormF,k = 1q
q?
i=1
M(C?iF,k, CF,k)?
1
q
q?
i=1
M(C?iF,?k , CF,?k )
(3)
Normalizing M(C?, C) by the stability of the
random predictor can yield values independent of
k.
After the number of optimal clusters and the
feature subset has been chosen, we adopted the
K-means algorithm for the clustering phase. The
output of context clustering is a set of context
clusters, each of them is supposed to denote one
relation type.
2.3 Discriminative Feature identification
For labelling each relation type, we use DCM
(discriminative category matching) scheme to
identify discriminative label, which is also used
in document classification (Gabriel et al, 2002)
and weights the importance of a feature based on
their distribution. In this scheme, a feature is not
important if the feature appears in many clusters
and is evenly distributed in these clusters, other-
wise it will be assigned higher importance.
To weight a feature fi within a category, we
take into account the following information:
264
Table 3: Three domains of entity pairs: frequency distribution for different relation types
PER-ORG # of pairs:786 ORG-GPE # of pairs:262 ORG-ORG # of pairs:580
Relation types Percentage Relation types Percentage Relation types Percentage
Management 36.39% Based-In 46.56% Member 27.76%
General-staff 29.90% Located 35.11% Subsidiary 19.83%
Member 19.34% Member 11.07% Part-Of 18.79%
Owner 4.45% Affiliate-Partner 3.44% Affiliate-Partner 17.93%
Located 3.28% Part-Of 2.29% Owner 8.79%
Client 1.91% Owner 1.53% Client 2.59%
Other 1.91% Management 2.59%
Affiliate-Partner 1.53% Other 1.21%
Founder 0.76% Other 0.52%
? The relative importance of fi within a cluster is de-
fined as: WCi,k = log2(pfi,k+1)log2(Nk+1) , where pfi,k is the
number of those entity pairs which contain feature fi
in cluster k. Nk is the total number of term pairs in
cluster k.
? The relative importance of fi across clusters is given
by: CCi = log N?maxk?Ci{WCi,k}?N
k=1 WCi,k
? 1logN , where Ci
is the set of clusters which contain feature fi. N is the
total number of clusters.
Here, WCi,k and CCi are designed to capture
both local information within a cluster and global
information about the feature distribution across
clusters respectively. Combining both WCi,k and
CCi we define the weight Wi,k of fi in cluster k
as: Wi,k = WC
2
i,k?CC2i?
WC2i,k+CC2i
? ?2, 0 ? Wi,k ? 1.
3 Experiments and Results
3.1 Data
We constructed three subsets for domains PER-
ORG, ORG-GPE and ORG-ORG respectively
from ACE corpus3 The details of these subsets
are given in Table 3, which are broken down by
different relation types. To verify our proposed
method, we only extracted those pairs of entity
mentions which have been tagged relation types.
And the relation type tags were used as ground
truth classes to evaluate.
3.2 Evaluation method for clustering result
Since there was no relation type tags for each
cluster in our clustering results, we adopted a
permutation procedure to assign different rela-
tion type tags to only min(|EC|,|TC|) clusters,
where |EC| is the estimated number of clusters,
and |TC| is the number of ground truth classes
3http://www.ldc.upenn.edu/Projects/ACE/
(relation types). This procedure aims to find an
one-to-one mapping function ? from the TC to
EC. To perform the mapping, we construct a
contingency table T , where each entry ti,j gives
the number of the instances that belong to both
the i-th cluster and j-th ground truth class. Then
the mapping procedure can be formulated as:?? =
argmax?
?|TC|
j=1 t?(j),j , where ?(j) is the index
of the estimated cluster associated with the j-th
class.
Given the result of one-to-one mapping, we
can define the evaluation measure as follows:
Accuracy(P ) =
?
j t??(j),j?
i,j ti,j
. Intuitively, it reflects
the accuracy of the clustering result.
3.3 Evaluation method for relation labelling
For evaluation of the relation labeling, we need
to explore the relatedness between the identified
labels and the pre-defined relation names. To do
this, we use one information-content based mea-
sure (Lin, 1997), which is provided in Wordnet-
Similarity package (Pedersen et al, 2004) to eval-
uate the similarity between two concepts in Word-
net. Intuitively, the relatedness between two con-
cepts in Wordnet is captured by the information
content of their lowest common subsumer (lcs)
and the information content of the two concepts
themselves , which can be formalized as follows:
Relatednesslin(c1, c2) = 2?IC(lcs(c1,c2))IC(c1)+IC(c2) . This
measure depends upon the corpus to estimate in-
formation content. We carried out the experi-
ments using the British National Corpus (BNC)
as the source of information content.
3.4 Experiments and Results
For comparison of the effect of the outer and
within contexts of entity pairs, we used five dif-
265
Table 4: Automatically determined the number of relation types using different feature ranking methods.
Domain Context
Window
Size
# of real
relation
types
Model Or-
der Base-
line
Model
Order with
?2
Model
Order with
Freq
Model Or-
der with
Entropy
PER-ORG 0-5-0 9 7 7 7 7
2-5-2 9 8 6 7 8
0-10-0 9 8 6 8 8
2-10-2 9 6 7 6 8
5-10-5 9 5 5 6 7
ORG-GPE 0-5-0 6 3 3 3 4
2-5-2 6 2 3 4 4
0-10-0 6 6 4 5 6
2-10-2 6 4 3 4 5
5-10-5 6 2 3 3 3
ORG-ORG 0-5-0 9 7 7 7 7
2-5-2 9 7 5 6 7
0-10-0 9 9 8 9 9
2-10-2 9 6 6 6 7
5-10-5 9 8 5 7 9
ferent settings of context window size (WINpre-
WINmid-WINpost) for each domain.
Table 4 shows the results of model order iden-
tification without feature selection (Baseline) and
with feature selection based on different feature
ranking criterion( ?2 , Frequency and Entropy).
The results show that the model order identifica-
tion algorithm with feature selection based on en-
tropy achieve best results: estimate cluster num-
bers which are very close to the true values. In ad-
dition, we can find that with the context setting, 0-
10-0, the estimated number of the clusters is equal
or close to the ground truth value. It demonstrates
that the intervening words less than 10 are appro-
priate features to reflect the structure behind the
contexts, while the intervening words less than 5
are not enough to infer the structure. For the con-
textual words beyond (before or after) the enti-
ties, they tend to be noisy features for the relation
estimation, as can be seen that the performance
deteriorates when taking them into consideration,
especially for the case without feature selection.
Table 5 gives a comparison of the aver-
age accuracy over five different context win-
dow size settings for different clustering settings.
For each domain, we conducted five cluster-
ing procedures: Hasegawa?s method, RLBaseline,
RLFS?2 , RLFSFreq and RLFSEntropy. For
Hasegawa?s method (Hasegawa et al, 2004), we
set the cluster number to be identical with the
number of ground truth classes. For RLBaseline,
we use the estimated cluster number to clus-
ter contexts without feature selection. For
RLFS?2 ,RLFSFreq and RLFSEntropy, we use
the selected feature subset and the estimated clus-
ter number to cluster the contexts, where the fea-
ture subset comes from ?2, frequency and entropy
criterion respectively. Comparing the average ac-
curacy of these clustering methods, we can find
that the performance of feature selection methods
is better than or comparable with the baseline sys-
tem without feature selection. Furthermore, it is
noted that RLFSEntropy achieves the highest av-
erage accuracy in three domains, which indicates
that entropy based feature pre-ranking provides
useful heuristic information for the selection of
important feature subset.
Table 6 gives the automatically estimated labels
for relation types for the domain PER-ORG. We
select two features as labels of each relation type
according to their DCM scores and calculate the
average (and maximum) relatedness between our
selected labels (E) and the predefined labels (H).
Following the same strategy, we also extracted re-
lation labels (T) from the ground truth classes and
provided the relatedness between T and H. From
the column of relatedness (E-H), we can see that it
is not easy to find the hand-tagged relation labels
exactly, furthermore, the identified labels from the
ground-truth classes are either not always compa-
rable to the pre-defined labels in most cases (T-
H). The reason may be that the pre-defined rela-
tion names tend to be some abstract labels over
the features, e.g., ?management? vs. ?president?,
266
Table 5: Performance of the clustering algorithms over three domains: the average accuracy over 5 different context window
size.
Domain Hasegawa?s
method
RLBaseline RLFS?2 RLFSFreq RLFSEntropy
PER-ORG 32.4% 34.3% 33.9% 36.6% 41.3%
ORG-GPE 43.7% 47.4% 47.1% 48.4% 50.6%
ORG-ORG 26.5% 36.2% 36.0% 38.7% 42.4%
Table 6: Relation Labelling using DCM strategy for the domain PER-ORG. Here, (T) denotes the identified relation labels
from ground truth classes. (E) is the identified relation labels from our estimated clusters. ?Ave (T-H)? denotes the average
relatedness between (T) and (H). ?Max (T-H)? denotes the maximum relatedness between (T) and (H).
Hand-tagged La-
bel (H)
Identified Label
(T)
Identified Label
(E)
Ave
(T-H)
Max
(T-H)
Ave
(E-H)
Max
(E-H)
Ave
(E-T)
Max
(E-T)
management head,president president,control 0.3703 0.4515 0.3148 0.3406 0.7443 1.0000
general-staff work,fire work,charge 0.6254 0.7823 0.6411 0.7823 0.6900 1.0000
member join,communist become,join 0.394 0.4519 0.1681 0.3360 0.3366 1.0000
owner bond,bought belong,house 0.1351 0.2702 0.0804 0.1608 0.2489 0.4978
located appear,include lobby,appear 0.0000 0.0000 0.1606 0.3213 0.2500 1.0000
client hire,reader bought,consult 0.4378 0.8755 0.0000 0.0000 0.1417 0.5666
affiliate-partner affiliate,associate assist,affiliate 0.9118 1.0000 0.5000 1.0000 0.5000 1.0000
founder form,found invest,set 0.1516 0.3048 0.3437 0.6875 0.4376 0.6932
?head? or ?control?; ?member? vs. ?join?, ?be-
come?, etc., while the abstract words and the fea-
tures are located far away in Wordnet. Table 6
also lists the relatedness between (E) and (T). We
can see that the labels are comparable by their
maximum relatedness(E-T).
4 Conclusion and Future work
In this paper, we presented an unsupervised ap-
proach for relation extraction from corpus. The
advantages of the proposed approach includes
that it doesn?t need any manual labelling of the re-
lation instances, it can identify an important fea-
ture subset and the number of the context clusters
automatically, and it can avoid extracting those
common words as characterization of relations.
References
Mary Elaine Califf and Raymond J.Mooney. 1999. Rela-
tional Learning of Pattern-Match Rules for Information
Extraction, AAAI99.
Sergey Brin. 1998. Extracting patterns and relations from
world wide web. In Proc. of WebDB?98. pages 172-183.
Kiyoshi Sudo, Satoshi Sekine and Ralph Grishman. 2003.
An Improved Extraction Pattern Representation Model
for Automatic IE Pattern Acquisition. Proceedings of ACL
2003; Sapporo, Japan.
Eugene Agichtein and Luis Gravano. 2000. Snowball: Ex-
tracting Relations from large Plain-Text Collections, In
Proc. of the 5th ACM International Conference on Digi-
tal Libraries (ACMDL?00).
Takaaki Hasegawa, Satoshi Sekine and Ralph Grishman.
2004. Discovering Relations among Named Entities from
Large Corpora, ACL2004. Barcelona, Spain.
Dmitry Zelenko, Chinatsu Aone and Anthony Richardella.
2002. Kernel Methods for Relation Extraction,
EMNLP2002. Philadelphia.
Lange,T., Braun,M.,Roth, V., and Buhmann,J.M.. 2002.
Stability-Based Model Selection, Advances in Neural In-
formation Processing Systems 15.
Levine,E. and Domany,E.. 2001. Resampling Method
for Unsupervised Estimation of Cluster Calidity, Neural
Computation, Vol.13, 2573-2593.
Zhengyu Niu, Donghong Ji and Chew Lim Tan. 2004. Doc-
ument Clustering Based on Cluster Validation, CIKM?04.
November 8-13, 2004, Washington, DC, USA.
Volker Roth and Tilman Lange. 2003. Feature Selection in
Clustering Problems, NIPS2003 workshop.
Manoranjan Dash and Huan Liu. 2000. Feature Selection
for Clustering, Proceedings of Pacific-Asia Conference
on Knowledge Discovery and Data Mining.
Gabriel Pui Cheong Fung, Jeffrey Xu Yu and Hongjun
Lu. 2002. Discriminative Category Matching: Effi-
cient Text Classification for Huge Document Collections,
ICDM2002. December 09-12, 2002, Japan.
D.Lin. 1997. Using syntactic dependency as a local context
to resolve word sense ambiguity. In Proceedings of the
35th Annual Meeting of ACL,. Madrid, July 1997.
Ted Pedersen, Siddharth Patwardhan and Jason Michelizzi.
2004. WordNet::Similarity-Measuring the Relatedness of
Concepts, AAAI2004.
267
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 25?28,
New York, June 2006. c?2006 Association for Computational Linguistics
Semi-supervised Relation Extraction with Label Propagation
Jinxiu Chen1 Donghong Ji1 Chew Lim Tan2 Zhengyu Niu1
1Institute for Infocomm Research 2Department of Computer Science
21 Heng Mui Keng Terrace National University of Singapore
119613 Singapore 117543 Singapore
{jinxiu,dhji,zniu}@i2r.a-star.edu.sg tancl@comp.nus.edu.sg
Abstract
To overcome the problem of not hav-
ing enough manually labeled relation in-
stances for supervised relation extraction
methods, in this paper we propose a label
propagation (LP) based semi-supervised
learning algorithm for relation extraction
task to learn from both labeled and unla-
beled data. Evaluation on the ACE corpus
showed when only a few labeled examples
are available, our LP based relation extrac-
tion can achieve better performance than
SVM and another bootstrapping method.
1 Introduction
Relation extraction is the task of finding relation-
ships between two entities from text. For the task,
many machine learning methods have been pro-
posed, including supervised methods (Miller et al,
2000; Zelenko et al, 2002; Culotta and Soresen,
2004; Kambhatla, 2004; Zhou et al, 2005), semi-
supervised methods (Brin, 1998; Agichtein and Gra-
vano, 2000; Zhang, 2004), and unsupervised method
(Hasegawa et al, 2004).
Supervised relation extraction achieves good per-
formance, but it requires a large amount of manu-
ally labeled relation instances. Unsupervised meth-
ods do not need the definition of relation types and
manually labeled data, but it is difficult to evaluate
the clustering result since there is no relation type
label for each instance in clusters. Therefore, semi-
supervised learning has received attention, which
can minimize corpus annotation requirement.
Current works on semi-supervised resolution for
relation extraction task mostly use the bootstrap-
ping algorithm, which is based on a local consis-
tency assumption: examples close to labeled ex-
amples within the same class will have the same
labels. Such methods ignore considering the simi-
larity between unlabeled examples and do not per-
form classification from a global consistency view-
point, which may fail to exploit appropriate mani-
fold structure in data when training data is limited.
The objective of this paper is to present a label
propagation based semi-supervised learning algo-
rithm (LP algorithm) (Zhu and Ghahramani, 2002)
for Relation Extraction task. This algorithm works
by representing labeled and unlabeled examples as
vertices in a connected graph, then propagating the
label information from any vertex to nearby vertices
through weighted edges iteratively, finally inferring
the labels of unlabeled examples after the propaga-
tion process converges. Through the label propaga-
tion process, our method can make the best of the
information of labeled and unlabeled examples to re-
alize a global consistency assumption: similar ex-
amples should have similar labels. In other words,
the labels of unlabeled examples are determined by
considering not only the similarity between labeled
and unlabeled examples, but also the similarity be-
tween unlabeled examples.
2 The Proposed Method
2.1 Problem Definition
Let X = {xi}ni=1 be a set of contexts of occurrences
of all entity pairs, where xi represents the contexts
of the i-th occurrence, and n is the total number of
occurrences of all entity pairs. The first l examples
are labeled as yg ( yg ? {rj}Rj=1, rj denotes relation
type and R is the total number of relation types).
And the remaining u(u = n? l) examples are unla-
beled.
Intuitively, if two occurrences of entity pairs have
25
the similar contexts, they tend to hold the same re-
lation type. Based on this assumption, we create a
graph where the vertices are all the occurrences of
entity pairs, both labeled and unlabeled. The edge
between vertices represents their similarity. Then
the task of relation extraction can be formulated as
a form of propagation on a graph, where a vertex?s
label propagates to neighboring vertices according
to their proximity. Here, the graph is connected with
the weights: Wij = exp(? s
2
ij
?2 ), where sij is the sim-
ilarity between xi and xj calculated by some simi-
larity measures. In this paper,two similarity mea-
sures are investigated, i.e. Cosine similarity measure
and Jensen-Shannon (JS) divergence (Lin, 1991).
And we set ? as the average similarity between la-
beled examples from different classes.
2.2 Label Propagation Algorithm
Given such a graph with labeled and unlabeled ver-
tices, we investigate the label propagation algorithm
(Zhu and Ghahramani, 2002) to help us propagate
the label information of any vertex in the graph
to nearby vertices through weighted edges until a
global stable stage is achieved.
Define a n ? n probabilistic transition matrix T
Tij = P (j ? i) = wij?n
k=1 wkj
, where Tij is the prob-
ability to jump from vertex xj to vertex xi. Also de-
fine a n?R label matrix Y , where Yij representing
the probabilities of vertex yi to have the label rj .
Then the label propagation algorithm consists the
following main steps:
Step1: Initialization Firstly, set the iteration in-
dex t = 0. Then let Y 0 be the initial soft labels at-
tached to each vertex and Y 0L be the top l rows of Y 0,
which is consistent with the labeling in labeled data
(Y 0ij = 1 if yi is label rj and 0 otherwise ). Let Y 0U
be the remaining u rows corresponding to unlabeled
data points and its initialization can be arbitrary.
Step 2: Propagate the label by Y t+1 = TY t,
where T is the row-normalized matrix of T , i.e.
Tij = Tij/
?
k Tik, which can maintain the class
probability interpretation.
Step 3: Clamp the labeled data, i.e., replace the
top l row of Y t+1 with Y 0L . In this step, the labeled
data is clamped to replenish the label sources from
these labeled data. Thus the labeled data act like
sources to push out labels through unlabeled data.
Table 1: Frequency of Relation SubTypes in the ACE training
and devtest corpus.
Type SubType Training Devtest
ROLE General-Staff 550 149
Management 677 122
Citizen-Of 127 24
Founder 11 5
Owner 146 15
Affiliate-Partner 111 15
Member 460 145
Client 67 13
Other 15 7
PART Part-Of 490 103
Subsidiary 85 19
Other 2 1
AT Located 975 192
Based-In 187 64
Residence 154 54
SOC Other-Professional 195 25
Other-Personal 60 10
Parent 68 24
Spouse 21 4
Associate 49 7
Other-Relative 23 10
Sibling 7 4
GrandParent 6 1
NEAR Relative-Location 88 32
Step 4: Repeat from step 2 until Y converges.
Step 5: Assign xh(l + 1 ? h ? n) with a label:
yh = argmaxjYhj .
3 Experiments and Results
3.1 Data
Our proposed graph-based method is evaluated on
the ACE corpus 1, which contains 519 files from
sources including broadcast, newswire, and news-
paper. A break-down of the tagged data by different
relation subtypes is given in Table 1.
3.2 Features
We extract the following lexical and syntactic fea-
tures from two entity mentions, and the contexts be-
fore, between and after the entity pairs. Especially,
we set the mid-context window as everything be-
tween the two entities and the pre- and post- context
as up to two words before and after the correspond-
ing entity. Most of these features are computed from
the parse trees derived from Charniak Parser (Char-
niak, 1999) and the Chunklink script 2 written by
Sabine Buchholz from Tilburg University.
1 http://www.ldc.upenn.edu/Projects/ACE/
2Software available at http://ilk.uvt.nl/?sabine/chunklink/
26
Table 2: Performance of Relation Detection: SVM and LP algorithm with different size of labeled data. The LP algorithm is
performed with two similarity measures: Cosine similarity and JS divergence.
SVM LPCosine LPJS
Percentage P R F P R F P R F
1% 35.9 32.6 34.4 58.3 56.1 57.1 58.5 58.7 58.5
10% 51.3 41.5 45.9 64.5 57.5 60.7 64.6 62.0 63.2
25% 67.1 52.9 59.1 68.7 59.0 63.4 68.9 63.7 66.1
50% 74.0 57.8 64.9 69.9 61.8 65.6 70.1 64.1 66.9
75% 77.6 59.4 67.2 71.8 63.4 67.3 72.4 64.8 68.3
100% 79.8 62.9 70.3 73.9 66.9 70.2 74.2 68.2 71.1
Table 3: Performance of Relation Classification on Relation Subtype: SVM and LP algorithm with different size of labeled data.
The LP algorithm is performed with two similarity measures: Cosine similarity and JS divergence.
SVM LPCosine LPJS
Percentage P R F P R F P R F
1% 31.6 26.1 28.6 39.6 37.5 38.5 40.1 38.0 39.0
10% 39.1 32.7 35.6 45.9 39.6 42.5 46.2 41.6 43.7
25% 49.8 35.0 41.1 51.0 44.5 47.3 52.3 46.0 48.9
50% 52.5 41.3 46.2 54.1 48.6 51.2 54.9 50.8 52.7
75% 58.7 46.7 52.0 56.0 52.0 53.9 56.1 52.6 54.3
100% 60.8 48.9 54.2 56.2 52.3 54.1 56.3 52.9 54.6
Words: Surface tokens of the two entities and
three context windows.
Entity Type: the entity type of both entity men-
tions, which can be PERSON, ORGANIZATION,
FACILITY, LOCATION and GPE.
POS: Part-Of-Speech tags corresponding to all
tokens in the two entities and three context windows.
Chunking features: Chunk tag information and
Grammatical function of the two entities and three
context windows. IOB-chains of the heads of the
two entities are also considered. IOB-chain notes
the syntactic categories of all the constituents on the
path from the root node to this leaf node of tree.
We combine the above features with their position
information in the context to form the context vec-
tor. Before that, we filter out low frequency features
which appeared only once in the entire set.
3.3 Experimental Evaluation
3.3.1 Relation Detection
We collect all entity mention pairs which co-occur
in the same sentence from the training and devtest
corpus into two set C1 and C2 respectively. The set
C1 includes annotated training data AC1 and un-
related data UC1. We randomly sample l examples
from AC1 as labeled data and add a ?NONE? class
into labeled data for the case where the two entity
mentions are not related. The data of the ?NONE?
Table 4: Comparison of performance on individual relation
type of Zhang (2004)?s method and our method. For Zhang
(2004)?s method, feature sampling probability is set to 0.3 and
agreement threshold is set to 9 out of 10.
Bootstrapping LPJS
Rel-Type P R F P R F
ROLE 78.5 69.7 73.8 81.0 74.7 77.7
PART 65.6 34.1 44.9 70.1 41.6 52.2
AT 61.0 84.8 70.9 74.2 79.1 76.6
SOC 47.0 57.4 51.7 45.0 59.1 51.0
NEAR undef 0 undef 13.7 12.5 13.0
class is resulted by sampling l examples from UC1.
Moreover, we combine the rest examples of C1 and
the whole set C2 as unlabeled data.
Given labeled and unlabeled data,we can perform
LP algorithm to detect possible relations, which
are those entity pairs that are not classified to the
?NONE? class but to the other 24 subtype classes.
In addition,we conduct experiments with different
sampling set size l, including 1% ? Ntrain,10% ?
Ntrain,25%?Ntrain,50%?Ntrain,75%?Ntrain,
100% ? Ntrain (Ntrain = |AC1|). If any major
subtype was absent from the sampled labeled set,we
redo the sampling. For each size,we perform 20 tri-
als and calculate an average of 20 random trials.
3.3.2 SVM vs. LP
Table 2 reports the performance of relation detec-
tion by using SVM and LP with different sizes of
27
labled data. For SVM, we use LIBSVM tool with
linear kernel function 3. And the same sampled la-
beled data used in LP is used to train SVM mod-
els. From Table 2, we see that both LPCosine and
LPJS achieve higher Recall than SVM. Especially,
with small labeled dataset (percentage of labeled
data ? 25%), this merit is more distinct. When
the percentage of labeled data increases from 50%
to 100%, LPCosine is still comparable to SVM in F-
measure while LPJS achieves better F-measure than
SVM. On the other hand, LPJS consistently outper-
forms LPCosine.
Table 3 reports the performance of relation classi-
fication, where the performance describes the aver-
age values over major relation subtypes. From Table
3, we see that LPCosine and LPJS outperform SVM
by F-measure in almost all settings of labeled data,
which is due to the increase of Recall. With smaller
labeled dataset, the gap between LP and SVM is
larger. On the other hand, LPJS divergence consis-
tently outperforms LPCosine.
3.3.3 LP vs. Bootstrapping
In (Zhang, 2004), they perform relation classifi-
cation on ACE corpus with bootstrapping on top of
SVM. To compare with their proposed Bootstrapped
SVM algorithm, we use the same feature stream set-
ting and randomly selected 100 instances from the
training data as the size of initial labeled data.
Table 4 lists the performance on individual rela-
tion type. We can find that LP algorithm achieves
6.8% performance improvement compared with the
(Zhang, 2004)?s bootstrapped SVM algorithm aver-
age on all five relation types. Notice that perfor-
mance reported on relation type ?NEAR? is low, be-
cause it occurs rarely in both training and test data.
4 Conclusion and Future work
This paper approaches the task of semi-supervised
relation extraction on Label Propagation algorithm.
Our results demonstrate that, when only very few
labeled examples are available, this manifold learn-
ing based algorithm can achieve better performance
than supervised learning method (SVM) and boot-
strapping based method, which can contribute to
3LIBSVM : a library for support vector machines. Soft-
ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.
minimize corpus annotation requirement. In the fu-
ture we would like to investigate how to select more
useful feature stream and whether feature selection
method can improve the performance of our graph-
based semi-supervised relation extraction.
References
Agichtein E. and Gravano L. 2000. Snowball: Extracting Rela-
tions from large Plain-Text Collections, In Proceeding of the
5th ACM International Conference on Digital Libraries.
Brin Sergey. 1998. Extracting patterns and relations from
world wide web. In Proceeding of WebDB Workshop at 6th
International Conference on Extending Database Technol-
ogy. pages 172-183.
Charniak E. 1999. A Maximum-entropy-inspired parser. Tech-
nical Report CS-99-12. Computer Science Department,
Brown University.
Culotta A. and Soresen J. 2004. Dependency tree kernels for
relation extraction, In Proceedings of 42th ACL conference.
Hasegawa T., Sekine S. and Grishman R. 2004. Discover-
ing Relations among Named Entities from Large Corpora,
In Proceeding of Conference ACL2004. Barcelona, Spain.
Kambhatla N. 2004. Combining lexical, syntactic and semantic
features with Maximum Entropy Models for extracting rela-
tions, In Proceedings of 42th ACL conference. Spain.
Lin,J. 1991. Divergence Measures Based on the Shannon En-
tropy. IEEE Transactions on Information Theory. 37:1,145-
150.
Miller S.,Fox H.,Ramshaw L. and Weischedel R. 2000. A novel
use of statistical parsing to extract information from text.
In Proceedings of 6th Applied Natural Language Processing
Conference 29 April-4 may 2000, Seattle USA.
Yarowsky D. 1995. Unsupervised Word Sense Disambiguation
Rivaling Supervised Methods. In Proceedings of the 33rd An-
nual Meeting of the Association for Computational Linguis-
tics. pp.189-196.
Zelenko D., Aone C. and Richardella A. 2002. Kernel Meth-
ods for Relation Extraction, In Proceedings of the EMNLP
Conference. Philadelphia.
Zhang Zhu. 2004. Weakly-supervised relation classification for
Information Extraction, In proceedings of ACM 13th con-
ference on Information and Knowledge Management. 8-13
Nov 2004. Washington D.C.,USA.
Zhou GuoDong, Su Jian, Zhang Jie and Zhang min. 2005.
Combining lexical, syntactic and semantic features with
Maximum Entropy Models for extracting relations, In pro-
ceedings of 43th ACL conference. USA.
Zhu Xiaojin and Ghahramani Zoubin. 2002. Learning from
Labeled and Unlabeled Data with Label Propagation. CMU
CALD tech report CMU-CALD-02-107.
28
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 129?136,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Relation Extraction Using Label Propagation Based Semi-supervised
Learning
Jinxiu Chen1 Donghong Ji1 Chew Lim Tan2 Zhengyu Niu1
1Institute for Infocomm Research 2Department of Computer Science
21 Heng Mui Keng Terrace National University of Singapore
119613 Singapore 117543 Singapore
{jinxiu,dhji,zniu}@i2r.a-star.edu.sg tancl@comp.nus.edu.sg
Abstract
Shortage of manually labeled data is an
obstacle to supervised relation extraction
methods. In this paper we investigate a
graph based semi-supervised learning al-
gorithm, a label propagation (LP) algo-
rithm, for relation extraction. It represents
labeled and unlabeled examples and their
distances as the nodes and the weights of
edges of a graph, and tries to obtain a la-
beling function to satisfy two constraints:
1) it should be fixed on the labeled nodes,
2) it should be smooth on the whole graph.
Experiment results on the ACE corpus
showed that this LP algorithm achieves
better performance than SVM when only
very few labeled examples are available,
and it also performs better than bootstrap-
ping for the relation extraction task.
1 Introduction
Relation extraction is the task of detecting and
classifying relationships between two entities from
text. Many machine learning methods have been
proposed to address this problem, e.g., supervised
learning algorithms (Miller et al, 2000; Zelenko et
al., 2002; Culotta and Soresen, 2004; Kambhatla,
2004; Zhou et al, 2005), semi-supervised learn-
ing algorithms (Brin, 1998; Agichtein and Gravano,
2000; Zhang, 2004), and unsupervised learning al-
gorithms (Hasegawa et al, 2004).
Supervised methods for relation extraction per-
form well on the ACE Data, but they require a large
amount of manually labeled relation instances. Un-
supervised methods do not need the definition of
relation types and manually labeled data, but they
cannot detect relations between entity pairs and its
result cannot be directly used in many NLP tasks
since there is no relation type label attached to
each instance in clustering result. Considering both
the availability of a large amount of untagged cor-
pora and direct usage of extracted relations, semi-
supervised learning methods has received great at-
tention.
DIPRE (Dual Iterative Pattern Relation Expan-
sion) (Brin, 1998) is a bootstrapping-based sys-
tem that used a pattern matching system as clas-
sifier to exploit the duality between sets of pat-
terns and relations. Snowball (Agichtein and Gra-
vano, 2000) is another system that used bootstrap-
ping techniques for extracting relations from un-
structured text. Snowball shares much in common
with DIPRE, including the employment of the boot-
strapping framework as well as the use of pattern
matching to extract new candidate relations. The
third system approaches relation classification prob-
lem with bootstrapping on top of SVM, proposed by
Zhang (2004). This system focuses on the ACE sub-
problem, RDC, and extracts various lexical and syn-
tactic features for the classification task. However,
Zhang (2004)?s method doesn?t actually ?detect? re-
laitons but only performs relation classification be-
tween two entities given that they are known to be
related.
Bootstrapping works by iteratively classifying un-
labeled examples and adding confidently classified
examples into labeled data using a model learned
from augmented labeled data in previous iteration. It
129
can be found that the affinity information among un-
labeled examples is not fully explored in this boot-
strapping process.
Recently a promising family of semi-supervised
learning algorithm is introduced, which can effec-
tively combine unlabeled data with labeled data in
learning process by exploiting manifold structure
(cluster structure) in data (Belkin and Niyogi, 2002;
Blum and Chawla, 2001; Blum et al, 2004; Zhu
and Ghahramani, 2002; Zhu et al, 2003). These
graph-based semi-supervised methods usually de-
fine a graph where the nodes represent labeled and
unlabeled examples in a dataset, and edges (may be
weighted) reflect the similarity of examples. Then
one wants a labeling function to satisfy two con-
straints at the same time: 1) it should be close to the
given labels on the labeled nodes, and 2) it should be
smooth on the whole graph. This can be expressed
in a regularization framework where the first term
is a loss function, and the second term is a regu-
larizer. These methods differ from traditional semi-
supervised learning methods in that they use graph
structure to smooth the labeling function.
To the best of our knowledge, no work has been
done on using graph based semi-supervised learning
algorithms for relation extraction. Here we inves-
tigate a label propagation algorithm (LP) (Zhu and
Ghahramani, 2002) for relation extraction task. This
algorithm works by representing labeled and unla-
beled examples as vertices in a connected graph,
then propagating the label information from any ver-
tex to nearby vertices through weighted edges itera-
tively, finally inferring the labels of unlabeled exam-
ples after the propagation process converges. In this
paper we focus on the ACE RDC task1.
The rest of this paper is organized as follows. Sec-
tion 2 presents related work. Section 3 formulates
relation extraction problem in the context of semi-
supervised learning and describes our proposed ap-
proach. Then we provide experimental results of our
proposed method and compare with a popular su-
pervised learning algorithm (SVM) and bootstrap-
ping algorithm in Section 4. Finally we conclude
our work in section 5.
1 http://www.ldc.upenn.edu/Projects/ACE/, Three tasks of
ACE program: Entity Detection and Tracking (EDT), Rela-
tion Detection and Characterization (RDC), and Event Detec-
tion and Characterization (EDC)
2 The Proposed Method
2.1 Problem Definition
The problem of relation extraction is to assign an ap-
propriate relation type to an occurrence of two entity
pairs in a given context. It can be represented as fol-
lows:
R ? (Cpre, e1, Cmid, e2, Cpost) (1)
where e1 and e2 denote the entity mentions, and
Cpre,Cmid,and Cpost are the contexts before, be-
tween and after the entity mention pairs. In this pa-
per, we set the mid-context window as the words be-
tween the two entity mentions and the pre- and post-
context as up to two words before and after the cor-
responding entity mention.
Let X = {xi}ni=1 be a set of contexts of occur-
rences of all the entity mention pairs, where xi rep-
resents the contexts of the i-th occurrence, and n is
the total number of occurrences. The first l exam-
ples (or contexts) are labeled as yg ( yg ? {rj}Rj=1,
rj denotes relation type and R is the total number of
relation types). The remaining u(u = n ? l) exam-
ples are unlabeled.
Intuitively, if two occurrences of entity mention
pairs have the similarity context, they tend to hold
the same relation type. Based on the assumption, we
define a graph where the vertices represent the con-
texts of labeled and unlabeled occurrences of entity
mention pairs, and the edge between any two ver-
tices xi and xj is weighted so that the closer the ver-
tices in some distance measure, the larger the weight
associated with this edge. Hence, the weights are de-
fined as follows:
Wij = exp(?
s2ij
?2 ) (2)
where sij is the similarity between xi and xj calcu-
lated by some similarity measures, e.g., cosine sim-
ilarity, and ? is used to scale the weights. In this
paper, we set ? as the average similarity between la-
beled examples from different classes.
2.2 A Label Propagation Algorithm
In the LP algorithm, the label information of any
vertex in a graph is propagated to nearby vertices
through weighted edges until a global stable stage is
achieved. Larger edge weights allow labels to travel
130
through easier. Thus the closer the examples are, the
more likely they have similar labels.
We define soft label as a vector that is a proba-
bilistic distribution over all the classes. In the la-
bel propagation process, the soft label of each initial
labeled example is clamped in each iteration to re-
plenish label sources from these labeled data. Thus
the labeled data act like sources to push out labels
through unlabeled data. With this push from la-
beled examples, the class boundaries will be pushed
through edges with large weights and settle in gaps
along edges with small weights. Hopefully, the val-
ues of Wij across different classes would be as small
as possible and the values of Wij within the same
class would be as large as possible. This will make
label propagation to stay within the same class. This
label propagation process will make the labeling
function smooth on the graph.
Define an n? n probabilistic transition matrix T
Tij = P (j ? i) = wij?n
k=1 wkj
(3)
where Tij is the probability to jump from vertex xj
to vertex xi. We define a n ? R label matrix Y ,
where Yij representing the probabilities of vertex yi
to have the label rj .
Then the label propagation algorithm consists the
following main steps:
Step1 : Initialization
? Set the iteration index t = 0;
? Let Y 0 be the initial soft labels attached to
each vertex, where Y 0ij = 1 if yi is label rj
and 0 otherwise.
? Let Y 0L be the top l rows of Y 0 and Y 0U
be the remaining u rows. Y 0L is consistent
with the labeling in labeled data and the
initialization of Y 0U can be arbitrary.
Step 2 : Propagate the labels of any vertex to
nearby vertices by Y t+1 = TY t , where
T is the row-normalized matrix of T , i.e.
Tij = Tij/
?
k Tik, which can maintain the
class probability interpretation.
Step 3 : Clamp the labeled data, that is, replace the
top l row of Y t+1 with Y 0L .
Step 4 : Repeat from step 2 until Y converges.
Step 5 : Assign xh(l + 1 ? h ? n) with a label:
yh = argmaxjYhj .
The above algorithm can ensure that the labeled
data YL never changes since it is clamped in Step 3.
Actually we are interested in only YU . This algo-
rithm has been shown to converge to a unique solu-
tion Y?U = limt?? Y tU = (I ? T?uu)?1T?ulY 0L (Zhu
and Ghahramani, 2002). Here, T?uu and T?ul are ac-
quired by splitting matrix T? after the l-th row and
the l-th column into 4 sub-matrices. And I is u? u
identity matrix. We can see that the initialization of
Y 0U in this solution is not important, since Y 0U does
not affect the estimation of Y?U .
3 Experiments and Results
3.1 Feature Set
Following (Zhang, 2004), we used lexical and syn-
tactic features in the contexts of entity pairs, which
are extracted and computed from the parse trees de-
rived from Charniak Parser (Charniak, 1999) and the
Chunklink script 2 written by Sabine Buchholz from
Tilburg University.
Words: Surface tokens of the two entities and
words in the three contexts.
Entity Type: the entity type of both entity men-
tions, which can be PERSON, ORGANIZA-
TION, FACILITY, LOCATION and GPE.
POS features: Part-Of-Speech tags corresponding
to all tokens in the two entities and words in
the three contexts.
Chunking features: This category of features are
extracted from the chunklink representation,
which includes:
? Chunk tag information of the two enti-
ties and words in the three contexts. The
?0? tag means that the word is not in any
chunk. The ?I-XP? tag means that this
word is inside an XP chunk. The ?B-XP?
by default means that the word is at the
beginning of an XP chunk.
? Grammatical function of the two enti-
ties and words in the three contexts. The
2Software available at http://ilk.uvt.nl/?sabine/chunklink/
131
last word in each chunk is its head, and
the function of the head is the function of
the whole chunk. ?NP-SBJ? means a NP
chunk as the subject of the sentence. The
other words in a chunk that are not the
head have ?NOFUNC? as their function.
? IOB-chains of the heads of the two enti-
ties. So-called IOB-chain, noting the syn-
tactic categories of all the constituents on
the path from the root node to this leaf
node of tree.
The position information is also specified in the
description of each feature above. For example,
word features with position information include:
1) WE1 (WE2): all words in e1 (e2)
2) WHE1 (WHE2): head word of e1 (e2)
3) WMNULL: no words in Cmid
4) WMFL: the only word in Cmid
5) WMF, WML, WM2, WM3, ...: first word, last
word, second word, third word, ...in Cmid when at
least two words in Cmid
6) WEL1, WEL2, ...: first word, second word, ...
before e1
7) WER1, WER2, ...: first word, second word, ...
after e2
We combine the above lexical and syntactic features
with their position information in the contexts to
form context vectors. Before that, we filter out low
frequency features which appeared only once in the
dataset.
3.2 Similarity Measures
The similarity sij between two occurrences of entity
pairs is important to the performance of the LP al-
gorithm. In this paper, we investigated two similar-
ity measures, cosine similarity measure and Jensen-
Shannon (JS) divergence (Lin, 1991). Cosine sim-
ilarity is commonly used semantic distance, which
measures the angle between two feature vectors. JS
divergence has ever been used as distance measure
for document clustering, which outperforms cosine
similarity based document clustering (Slonim et al,
2002). JS divergence measures the distance between
two probability distributions if feature vector is con-
sidered as probability distribution over features. JS
divergence is defined as follows:
Table 1: Frequency of Relation SubTypes in the ACE training
and devtest corpus.
Type SubType Training Devtest
ROLE General-Staff 550 149
Management 677 122
Citizen-Of 127 24
Founder 11 5
Owner 146 15
Affiliate-Partner 111 15
Member 460 145
Client 67 13
Other 15 7
PART Part-Of 490 103
Subsidiary 85 19
Other 2 1
AT Located 975 192
Based-In 187 64
Residence 154 54
SOC Other-Professional 195 25
Other-Personal 60 10
Parent 68 24
Spouse 21 4
Associate 49 7
Other-Relative 23 10
Sibling 7 4
GrandParent 6 1
NEAR Relative-Location 88 32
JS(q, r) = 12 [DKL(q?p?) +DKL(r?p?)] (4)
DKL(q?p?) =
?
y
q(y)(log q(y)p?(y) ) (5)
DKL(r?p?) =
?
y
r(y)(log r(y)p?(y) ) (6)
where p? = 12(q + r) and JS(q, r) represents JS
divergence between probability distribution q(y) and
r(y) (y is a random variable), which is defined in
terms of KL-divergence.
3.3 Experimental Evaluation
3.3.1 Experiment Setup
We evaluated this label propagation based rela-
tion extraction method for relation subtype detection
and characterization task on the official ACE 2003
corpus. It contains 519 files from sources including
broadcast, newswire, and newspaper. We dealt with
only intra-sentence explicit relations and assumed
that all entities have been detected beforehand in the
EDT sub-task of ACE. Table 1 lists the types and
subtypes of relations for the ACE Relation Detection
and Characterization (RDC) task, along with their
132
Table 2: The Performance of SVM and LP algorithm with different sizes of labeled data for relation detection on relation subtypes.
The LP algorithm is run with two similarity measures: cosine similarity and JS divergence.
SVM LPCosine LPJS
Percentage P R F P R F P R F
1% 35.9 32.6 34.4 58.3 56.1 57.1 58.5 58.7 58.5
10% 51.3 41.5 45.9 64.5 57.5 60.7 64.6 62.0 63.2
25% 67.1 52.9 59.1 68.7 59.0 63.4 68.9 63.7 66.1
50% 74.0 57.8 64.9 69.9 61.8 65.6 70.1 64.1 66.9
75% 77.6 59.4 67.2 71.8 63.4 67.3 72.4 64.8 68.3
100% 79.8 62.9 70.3 73.9 66.9 70.2 74.2 68.2 71.1
Table 3: The performance of SVM and LP algorithm with different sizes of labeled data for relation detection and classification
on relation subtypes. The LP algorithm is run with two similarity measures: cosine similarity and JS divergence.
SVM LPCosine LPJS
Percentage P R F P R F P R F
1% 31.6 26.1 28.6 39.6 37.5 38.5 40.1 38.0 39.0
10% 39.1 32.7 35.6 45.9 39.6 42.5 46.2 41.6 43.7
25% 49.8 35.0 41.1 51.0 44.5 47.3 52.3 46.0 48.9
50% 52.5 41.3 46.2 54.1 48.6 51.2 54.9 50.8 52.7
75% 58.7 46.7 52.0 56.0 52.0 53.9 56.1 52.6 54.3
100% 60.8 48.9 54.2 56.2 52.3 54.1 56.3 52.9 54.6
frequency of occurrence in the ACE training set and
test set. We constructed labeled data by randomly
sampling some examples from ACE training data
and additionally sampling examples with the same
size from the pool of unrelated entity pairs for the
?NONE? class. We used the remaining examples in
the ACE training set and the whole ACE test set as
unlabeled data. The testing set was used for final
evaluation.
3.3.2 LP vs. SVM
Support Vector Machine (SVM) is a state of the
art technique for relation extraction task. In this ex-
periment, we use LIBSVM tool 3 with linear kernel
function.
For comparison between SVM and LP, we ran
SVM and LP with different sizes of labeled data
and evaluate their performance on unlabeled data
using precision, recall and F-measure. Firstly, we
ran SVM or LP algorithm to detect possible rela-
tions from unlabeled data. If an entity mention pair
is classified not to the ?NONE? class but to the other
24 subtype classes, then it has a relation. Then con-
struct labeled datasets with different sampling set
size l, including 1%?Ntrain, 10%?Ntrain, 25%?
Ntrain, 50%?Ntrain, 75%?Ntrain, 100%?Ntrain
(Ntrain is the number of examples in the ACE train-
3LIBSVM : a library for support vector machines. Soft-
ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.
ing set). If any relation subtype was absent from the
sampled labeled set, we redid the sampling. For each
size, we performed 20 trials and calculated average
scores on test set over these 20 random trials.
Table 2 reports the performance of SVM and LP
with different sizes of labled data for relation detec-
tion task. We used the same sampled labeled data in
LP as the training data for SVM model.
From Table 2, we see that both LPCosine and
LPJS achieve higher Recall than SVM. Specifically,
with small labeled dataset (percentage of labeled
data ? 25%), the performance improvement by LP
is significant. When the percentage of labeled data
increases from 50% to 100%, LPCosine is still com-
parable to SVM in F-measure while LPJS achieves
slightly better F-measure than SVM. On the other
hand, LPJS consistently outperforms LPCosine.
Table 3 reports the performance of relation clas-
sification by using SVM and LP with different sizes
of labled data. And the performance describes the
average values of Precision, Recall and F-measure
over major relation subtypes.
From Table 3, we see that LPCosine and LPJS out-
perform SVM by F-measure in almost all settings
of labeled data, which is due to the increase of Re-
call. With smaller labeled dataset (percentage of la-
beled data ? 50%), the gap between LP and SVM
is larger. When the percentage of labeled data in-
133
0.25
0.3
0.35
0.4
0.45
0.5
0.55
0.6
1% 10% 25% 50% 75% 100%
Percentage of Labeled Examples
F-m
ea
su
re SVM
LP_Cosine
LP_JS
 
Figure 1: Comparison of the performance of SVM
and LP with different sizes of labeled data
creases from 75% to 100%, the performance of LP
algorithm is still comparable to SVM. On the other
hand, the LP algorithm based on JS divergence con-
sistently outperforms the LP algorithm based on Co-
sine similarity. Figure 1 visualizes the accuracy of
three algorithms.
As shown in Figure 1, the gap between SVM
curve and LPJS curves is large when the percentage
of labeled data is relatively low.
3.3.3 An Example
In Figure 2, we selected 25 instances in train-
ing set and 15 instances in test set from the ACE
corpus,which covered five relation types. Using
Isomap tool 4, the 40 instances with 229 feature di-
mensions are visualized in a two-dimensional space
as the figure. We randomly sampled only one la-
beled example for each relation type from the 25
training examples as labeled data. Figure 2(a) and
2(b) show the initial state and ground truth result re-
spectively. Figure 2(c) reports the classification re-
sult on test set by SVM (accuracy = 415 = 26.7%),
and Figure 2(d) gives the classification result on both
training set and test set by LP (accuracy = 1115 =
73.3%).
Comparing Figure 2(b) and Figure 2(c), we find
that many examples are misclassified from class ?
to other class symbols. This may be caused that
SVMs method ignores the intrinsic structure in data.
For Figure 2(d), the labels of unlabeled examples
are determined not only by nearby labeled examples,
but also by nearby unlabeled examples, so using LP
4The tool is available at http://isomap.stanford.edu/.
     




	
      




	

     




	
      




	

Figure 2: An example: comparison of SVM and LP
algorithm on a data set from ACE corpus. ? and
4 denote the unlabeled examples in training set and
test set respectively, and other symbols (?,?,2,+
and 5) represent the labeled examples with respec-
tive relation type sampled from training set.
strategy achieves better performance than the local
consistency based SVM strategy when the size of
labeled data is quite small.
3.3.4 LP vs. Bootstrapping
In (Zhang, 2004), they perform relation classifi-
cation on ACE corpus with bootstrapping on top of
SVM. To compare with their proposed Bootstrapped
SVM algorithm, we use the same feature stream set-
ting and randomly selected 100 instances from the
training data as the size of initial labeled data.
Table 4 lists the performance of the bootstrapped
SVM method from (Zhang, 2004) and LP method
with 100 seed labeled examples for relation type
classification task. We can see that LP algorithm
outperforms the bootstrapped SVM algorithm on
four relation type classification tasks, and perform
comparably on the relation ?SOC? classification
task.
4 Discussion
In this paper,we have investigated a graph-based
semi-supervised learning approach for relation ex-
traction problem. Experimental results showed that
the LP algorithm performs better than SVM and
134
Table 4: Comparison of the performance of the bootstrapped SVM method from (Zhang, 2004) and LP method with 100 seed
labeled examples for relation type classification task.
Bootstrapping LPJS
Relation type P R F P R F
ROLE 78.5 69.7 73.8 81.0 74.7 77.7
PART 65.6 34.1 44.9 70.1 41.6 52.2
AT 61.0 84.8 70.9 74.2 79.1 76.6
SOC 47.0 57.4 51.7 45.0 59.1 51.0
NEAR ? ? ? 13.7 12.5 13.0
Table 5: Comparison of the performance of previous methods on ACE RDC task.
Relation Dectection Relation Detection and Classification
on Types on Subtypes
Method P R F P R F P R F
Culotta and Soresen (2004) Tree kernel based 81.2 51.8 63.2 67.1 35.0 45.8 - - -
Kambhatla (2004) Feature based, Maxi-
mum Entropy
- - - - - - 63.5 45.2 52.8
Zhou et al (2005) Feature based,SVM 84.8 66.7 74.7 77.2 60.7 68.0 63.1 49.5 55.5
bootstrapping. We have some findings from these
results:
The LP based relation extraction method can use
the graph structure to smooth the labels of unlabeled
examples. Therefore, the labels of unlabeled exam-
ples are determined not only by the nearby labeled
examples, but also by nearby unlabeled examples.
For supervised methods, e.g., SVM, very few la-
beled examples are not enough to reveal the struc-
ture of each class. Therefore they can not perform
well, since the classification hyperplane was learned
only from few labeled data and the coherent struc-
ture in unlabeled data was not explored when in-
ferring class boundary. Hence, our LP-based semi-
supervised method achieves better performance on
both relation detection and classification when only
few labeled data is available. Bootstrapping
Currently most of works on the RDC task of
ACE focused on supervised learning methods Cu-
lotta and Soresen (2004; Kambhatla (2004; Zhou
et al (2005). Table 5 lists a comparison on re-
lation detection and classification of these meth-
ods. Zhou et al (2005) reported the best result as
63.1%/49.5%/55.5% in Precision/Recall/F-measure
on the relation subtype classification using feature
based method, which outperforms tree kernel based
method by Culotta and Soresen (2004). Compared
with Zhou et al?s method, the performance of LP al-
gorithm is slightly lower. It may be due to that we
used a much simpler feature set. Our work in this
paper focuses on the investigation of a graph based
semi-supervised learning algorithm for relation ex-
traction. In the future, we would like to use more ef-
fective feature sets Zhou et al (2005) or kernel based
similarity measure with LP for relation extraction.
5 Conclusion and Future Work
This paper approaches the problem of semi-
supervised relation extraction using a label propaga-
tion algorithm. It represents labeled and unlabeled
examples and their distances as the nodes and the
weights of edges of a graph, and tries to obtain a
labeling function to satisfy two constraints: 1) it
should be fixed on the labeled nodes, 2) it should
be smooth on the whole graph. In the classifica-
tion process, the labels of unlabeled examples are
determined not only by nearby labeled examples,
but also by nearby unlabeled examples. Our exper-
imental results demonstrated that this graph based
algorithm can achieve better performance than SVM
when only very few labeled examples are available,
and also outperforms the bootstrapping method for
relation extraction task.
In the future, we would like to investigate more
effective feature set or use feature selection to im-
prove the performance of this graph-based semi-
supervised relation extraction method.
135
References
Agichtein E. and Gravano L.. 2000. Snowball: Ex-
tracting Relations from large Plain-Text Collections,
In Proceedings of the 5th ACM International Confer-
ence on Digital Libraries (ACMDL?00).
Belkin M. and Niyogi P.. 2002. Using Manifold Struc-
ture for Partially Labeled Classification. Advances in
Neural Infomation Processing Systems 15.
Blum A. and Chawla S. 2001. Learning from Labeled
and Unlabeled Data Using Graph Mincuts. In Pro-
ceedings of the 18th International Conference on Ma-
chine Learning.
Blum A., Lafferty J., Rwebangira R. and Reddy R. 2004.
Semi-Supervised Learning Using Randomized Min-
cuts. In Proceedings of the 21th International Confer-
ence on Machine Learning..
Brin Sergey. 1998. Extracting patterns and relations
from world wide web. In Proceedings of WebDB Work-
shop at 6th International Conference on Extending
Database Technology (WebDB?98). pages 172-183.
Charniak E. 1999. A Maximum-entropy-inspired parser.
Technical Report CS-99-12. Computer Science De-
partment, Brown University.
Culotta A. and Soresen J. 2004. Dependency tree kernels
for relation extraction, In Proceedings of 42th Annual
Meeting of the Association for Computational Linguis-
tics. 21-26 July 2004. Barcelona, Spain.
Hasegawa T., Sekine S. and Grishman R. 2004. Dis-
covering Relations among Named Entities from Large
Corpora, In Proceeding of Conference ACL2004.
Barcelona, Spain.
Kambhatla N. 2004. Combining lexical, syntactic and
semantic features with Maximum Entropy Models for
extracting relations, In Proceedings of 42th Annual
Meeting of the Association for Computational Linguis-
tics.. 21-26 July 2004. Barcelona, Spain.
Lin J. 1991. Divergence Measures Based on the Shan-
non Entropy. IEEE Transactions on Information The-
ory. Vol 37, No.1, 145-150.
Miller S.,Fox H.,Ramshaw L. and Weischedel R. 2000.
A novel use of statistical parsing to extract information
from text. In Proceedings of 6th Applied Natural Lan-
guage Processing Conference 29 April-4 may 2000,
Seattle USA.
Slonim, N., Friedman, N., and Tishby, N. 2002. Un-
supervised Document Classification Using Sequential
Information Maximization. In Proceedings of the 25th
Annual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval.
Yarowsky D. 1995. Unsupervised Word Sense Disam-
biguation Rivaling Supervised Methods. In Proceed-
ings of the 33rd Annual Meeting of the Association for
Computational Linguistics. pp.189-196.
Zelenko D., Aone C. and Richardella A. 2002. Ker-
nel Methods for Relation Extraction, Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP). Philadelphia.
Zhang Zhu. 2004. Weakly-supervised relation classifi-
cation for Information Extraction, In Proceedings of
ACM 13th conference on Information and Knowledge
Management (CIKM?2004). 8-13 Nov 2004. Wash-
ington D.C.,USA.
Zhou GuoDong, Su Jian, Zhang Jie and Zhang min.
2005. Exploring Various Knowledge in Relation Ex-
traction. In Proceedings of 43th Annual Meeting of the
Association for Computational Linguistics. USA.
Zhu Xiaojin and Ghahramani Zoubin. 2002. Learning
from Labeled and Unlabeled Data with Label Propa-
gation. CMU CALD tech report CMU-CALD-02-107.
Zhu Xiaojin, Ghahramani Zoubin, and Lafferty J. 2003.
Semi-Supervised Learning Using Gaussian Fields and
Harmonic Functions. In Proceedings of the 20th Inter-
national Conference on Machine Learning.
136
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 89?96,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Unsupervised Relation Disambiguation Using Spectral Clustering
Jinxiu Chen1 Donghong Ji1 Chew Lim Tan2 Zhengyu Niu1
1Institute for Infocomm Research 2Department of Computer Science
21 Heng Mui Keng Terrace National University of Singapore
119613 Singapore 117543 Singapore
{jinxiu,dhji,zniu}@i2r.a-star.edu.sg tancl@comp.nus.edu.sg
Abstract
This paper presents an unsupervised learn-
ing approach to disambiguate various rela-
tions between name entities by use of vari-
ous lexical and syntactic features from the
contexts. It works by calculating eigen-
vectors of an adjacency graph?s Laplacian
to recover a submanifold of data from a
high dimensionality space and then per-
forming cluster number estimation on the
eigenvectors. Experiment results on ACE
corpora show that this spectral cluster-
ing based approach outperforms the other
clustering methods.
1 Introduction
In this paper, we address the task of relation extrac-
tion, which is to find relationships between name en-
tities in a given context. Many methods have been
proposed to deal with this task, including supervised
learning algorithms (Miller et al, 2000; Zelenko et
al., 2002; Culotta and Soresen, 2004; Kambhatla,
2004; Zhou et al, 2005), semi-supervised learn-
ing algorithms (Brin, 1998; Agichtein and Gravano,
2000; Zhang, 2004), and unsupervised learning al-
gorithm (Hasegawa et al, 2004).
Among these methods, supervised learning is usu-
ally more preferred when a large amount of la-
beled training data is available. However, it is
time-consuming and labor-intensive to manually tag
a large amount of training data. Semi-supervised
learning methods have been put forward to mini-
mize the corpus annotation requirement. Most of
semi-supervised methods employ the bootstrapping
framework, which only need to pre-define some ini-
tial seeds for any particular relation, and then boot-
strap from the seeds to acquire the relation. How-
ever, it is often quite difficult to enumerate all class
labels in the initial seeds and decide an ?optimal?
number of them.
Compared with supervised and semi-supervised
methods, Hasegawa et al (2004)?s unsupervised ap-
proach for relation extraction can overcome the dif-
ficulties on requirement of a large amount of labeled
data and enumeration of all class labels. Hasegawa
et al (2004)?s method is to use a hierarchical cluster-
ing method to cluster pairs of named entities accord-
ing to the similarity of context words intervening be-
tween the named entities. However, the drawback of
hierarchical clustering is that it required providing
cluster number by users. Furthermore, clustering is
performed in original high dimensional space, which
may induce non-convex clusters hard to identified.
This paper presents a novel application of spec-
tral clustering technique to unsupervised relation ex-
traction problem. It works by calculating eigenvec-
tors of an adjacency graph?s Laplacian to recover a
submanifold of data from a high dimensional space,
and then performing cluster number estimation on
a transformed space defined by the first few eigen-
vectors. This method may help us find non-convex
clusters. It also does not need to pre-define the num-
ber of the context clusters or pre-specify the simi-
larity threshold for the clusters as Hasegawa et al
(2004)?s method.
The rest of this paper is organized as follows. Sec-
tion 2 formulates unsupervised relation extraction
and presents how to apply the spectral clustering
89
technique to resolve the task. Then section 3 reports
experiments and results. Finally we will give a con-
clusion about our work in section 4.
2 Unsupervised Relation Extraction
Problem
Assume that two occurrences of entity pairs with
similar contexts, are tend to hold the same relation
type. Thus unsupervised relation extraction prob-
lem can be formulated as partitioning collections of
entity pairs into clusters according to the similarity
of contexts, with each cluster containing only entity
pairs labeled by the same relation type. And then, in
each cluster, the most representative words are iden-
tified from the contexts of entity pairs to induce the
label of relation type. Here, we only focus on the
clustering subtask and do not address the relation
type labeling subtask.
In the next subsections we will describe our pro-
posed method for unsupervised relation extraction,
which includes: 1) Collect the context vectors in
which the entity mention pairs co-occur; 2) Cluster
these Context vectors.
2.1 Context Vector and Feature Design
Let X = {xi}ni=1 be the set of context vectors of oc-
currences of all entity mention pairs, where xi repre-
sents the context vector of the i-th occurrence, and n
is the total number of occurrences of all entity men-
tion pairs.
Each occurrence of entity mention pairs can be
denoted as follows:
R ? (Cpre, e1, Cmid, e2, Cpost) (1)
where e1 and e2 represents the entity mentions, and
Cpre,Cmid,and Cpost are the contexts before, be-
tween and after the entity mention pairs respectively.
We extracted features from e1, e2, Cpre, Cmid,
Cpost to construct context vectors, which are com-
puted from the parse trees derived from Charniak
Parser (Charniak, 1999) and the Chunklink script 1
written by Sabine Buchholz from Tilburg University.
Words: Words in the two entities and three context
windows.
1 Software available at http://ilk.uvt.nl/ sabine/chunklink/
Entity Type: the entity type of both entities, which
can be PERSON, ORGANIZATION, FACIL-
ITY, LOCATION and GPE.
POS features: Part-Of-Speech tags corresponding
to all words in the two entities and three con-
text windows.
Chunking features: This category of features are
extracted from the chunklink representation,
which includes:
? Chunk tag information of the two enti-
ties and three context windows. The ?0?
tag means that the word is outside of any
chunk. The ?I-XP? tag means that this
word is inside an XP chunk. The ?B-XP?
by default means that the word is at the
beginning of an XP chunk.
? Grammatical function of the two entities
and three context windows. The last word
in each chunk is its head, and the function
of the head is the function of the whole
chunk. ?NP-SBJ? means a NP chunk as
the subject of the sentence. The other
words in a chunk that are not the head have
?NOFUNC? as their function.
? IOB-chains of the heads of the two enti-
ties. So-called IOB-chain, noting the syn-
tactic categories of all the constituents on
the path from the root node to this leaf
node of tree.
We combine the above lexical and syntactic fea-
tures with their position information in the context
to form the context vector. Before that, we filter out
low frequency features which appeared only once in
the entire set.
2.2 Context Clustering
Once the context vectors of entity pairs are prepared,
we come to the second stage of our method: cluster
these context vectors automatically.
In recent years, spectral clustering technique has
received more and more attention as a powerful ap-
proach to a range of clustering problems. Among
the efforts on spectral clustering techniques (Weiss,
1999; Kannan et al, 2000; Shi et al, 2000; Ng et al,
2001; Zha et al, 2001), we adopt a modified version
90
Table 1: Context Clustering with Spectral-based Clustering
technique.
Input: A set of context vectors X = {x1, x2, ..., xn},
X ? <n?d;
Output: Clustered data and number of clusters;
1. Construct an affinity matrix by Aij = exp(? s
2
ij
?2 ) if i 6=j, 0 if i = j. Here, sij is the similarity between xi and
xj calculated by Cosine similarity measure. and the free
distance parameter ?2 is used to scale the weights;
2. Normalize the affinity matrix A to create the matrix L =
D?1/2AD?1/2, where D is a diagonal matrix whose (i,i)
element is the sum of A?s ith row;
3. Set q = 2;
4. Compute q eigenvectors of L with greatest eigenvalues.
Arrange them in a matrix Y .
5. Perform elongated K-means with q + 1 centers on Y ,
initializing the (q + 1)-th mean in the origin;
6. If the q+1-th cluster contains any data points, then there
must be at least an extra cluster; set q = q + 1 and go
back to step 4. Otherwise, algorithm stops and outputs
clustered data and number of clusters.
(Sanguinetti et al, 2005) of the algorithm by Ng et
al. (2001) because it can provide us model order se-
lection capability.
Since we do not know how many relation types
in advance and do not have any labeled relation
training examples at hand, the problem of model
order selection arises, i.e. estimating the ?opti-
mal? number of clusters. Formally, let k be the
model order, we need to find k in Equation: k =
argmaxk{criterion(k)}. Here, the criterion is de-
fined on the result of spectral clustering.
Table 1 shows the details of the whole algorithm
for context clustering, which contains two main
stages: 1) Transformation of Clustering Space (Step
1-4); 2) Clustering in the transformed space using
Elongated K-means algorithm (Step 5-6).
2.3 Transformation of Clustering Space
We represent each context vector of entity pair as a
node in an undirected graph. Each edge (i,j) in the
graph is assigned a weight that reflects the similarity
between two context vectors i and j. Hence, the re-
lation extraction task for entity pairs can be defined
as a partition of the graph so that entity pairs that
are more similar to each other, e.g. labeled by the
same relation type, belong to the same cluster. As a
relaxation of such NP-hard discrete graph partition-
ing problem, spectral clustering technique computes
eigenvalues and eigenvectors of a Laplacian matrix
related to the given graph, and construct data clus-
ters based on such spectral information.
Thus the starting point of context clustering is to
construct an affinity matrix A from the data, which
is an n ? n matrix encoding the distances between
the various points. The affinity matrix is then nor-
malized to form a matrix L by conjugating with the
the diagonal matrix D?1/2 which has as entries the
square roots of the sum of the rows of A. This is to
take into account the different spread of the various
clusters (points belonging to more rarified clusters
will have lower sums of the corresponding row of
A). It is straightforward to prove that L is positive
definite and has eigenvalues smaller or equal to 1,
with equality holding in at least one case.
Let K be the true number of clusters present in
the dataset. If K is known beforehand, the first K
eigenvectors of L will be computed and arranged as
columns in a matrix Y . Each row of Y corresponds
to a context vector of entity pair, and the above pro-
cess can be considered as transforming the original
context vectors in a d-dimensional space to new con-
text vectors in the K-dimensional space. Therefore,
the rows of Y will cluster upon mutually orthogonal
points on the K dimensional sphere,rather than on
the coordinate axes.
2.4 The Elongated K-means algorithm
As the step 5 of Table 1 shows, the result of elon-
gated K-means algorithm is used to detect whether
the number of clusters selected q is less than the true
number K, and allows one to iteratively obtain the
number of clusters.
Consider the case when the number of clusters q
is less than the true cluster number K present in the
dataset. In such situation, taking the first q < K
eigenvectors, we will be selecting a q-dimensional
subspace in the clustering space. As the rows of the
K eigenvectors clustered along mutually orthogo-
nal vectors, their projections in a lower dimensional
space will cluster along radial directions. Therefore,
the general picture will be of q clusters elongated in
the radial direction, with possibly some clusters very
near the origin (when the subspace is orthogonal to
some of the discarded eigenvectors).
Hence, the K-means algorithm is modified as
the elongated K-means algorithm to downweight
distances along radial directions and penalize dis-
91
-4 -3 -2 -1 0 1 2 3 4-4
-3
-2
-1
0
1
2
3
4
(a) 
-4 -3 -2 -1 0 1 2 3 4-4
-3
-2
-1
0
1
2
3
4
(b) 
0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08-0.08
-0.06
-0.04
-0.02
0
0.02
0.04
0.06
0.08
0.1
(c) 
-4 -3 -2 -1 0 1 2 3 4-4
-3
-2
-1
0
1
2
3
4
(d) 
Figure 1: An Example:(a) The Three Circle Dataset.
(b) The clustering result using K-means; (c) Three
elongated clusters in the 2D clustering space using
Spectral clustering: two dominant eigenvectors; (d)
The clustering result using Spectral-based clustering
(?2=0.05). (4,? and + denote examples in different
clusters)
tances along transversal directions. The elongated
K-means algorithm computes the distance of point
x from the center ci as follows:
? If the center is not very near the origin, cTi ci > ? (? is a
parameter to be fixed by the user), the distances are cal-
culated as: edist(x, ci) = (x ? ci)TM(x ? ci), where
M = 1? (Iq ?
cicTi
cTi ci
) + ? cic
T
i
cTi ci
, ? is the sharpness param-
eter that controls the elongation (the smaller, the more
elongated the clusters) 2.
? If the center is very near the origin,cTi ci < ?, the dis-
tances are measured using the Euclidean distance.
In each iteration of procedure in Table 1, elon-
gated K-means is initialized with q centers corre-
sponding to data points in different clusters and one
center in the origin. The algorithm then will drag the
center in the origin towards one of the clusters not
accounted for. Compute another eigenvector (thus
increasing the dimension of the clustering space to
q + 1) and repeat the procedure. Eventually, when
one reach as many eigenvectors as the number of
clusters present in the data, no points will be as-
signed to the center at the origin, leaving the cluster
empty. This is the signal to terminate the algorithm.
2.5 An example
Figure 1 visualized the clustering result of three cir-
cle dataset using K-means and Spectral-based clus-
tering. From Figure 1(b), we can see that K-means
can not separate the non-convex clusters in three cir-
cle dataset successfully since it is prone to local min-
imal. For spectral-based clustering, as the algorithm
described, initially, we took the two eigenvectors of
L with largest eigenvalues, which gave us a two-
dimensional clustering space. Then to ensure that
the two centers are initialized in different clusters,
one center is set as the point that is the farthest from
the origin, while the other is set as the point that
simultaneously farthest the first center and the ori-
gin. Figure 1(c) shows the three elongated clusters in
the 2D clustering space and the corresponding clus-
tering result of dataset is visualized in Figure 1(d),
which exploits manifold structure (cluster structure)
in data.
2 In this paper, the sharpness parameter ? is set to 0.2
92
Table 2: Frequency of Major Relation SubTypes in the ACE
training and devtest corpus.
Type SubType Training Devtest
ROLE General-Staff 550 149
Management 677 122
Citizen-Of 127 24
Founder 11 5
Owner 146 15
Affiliate-Partner 111 15
Member 460 145
Client 67 13
Other 15 7
PART Part-Of 490 103
Subsidiary 85 19
Other 2 1
AT Located 975 192
Based-In 187 64
Residence 154 54
SOC Other-Professional 195 25
Other-Personal 60 10
Parent 68 24
Spouse 21 4
Associate 49 7
Other-Relative 23 10
Sibling 7 4
GrandParent 6 1
NEAR Relative-Location 88 32
3 Experiments and Results
3.1 Data Setting
Our proposed unsupervised relation extraction is
evaluated on ACE 2003 corpus, which contains 519
files from sources including broadcast, newswire,
and newspaper. We only deal with intra-sentence
explicit relations and assumed that all entities have
been detected beforehand in the EDT sub-task of
ACE. To verify our proposed method, we only col-
lect those pairs of entity mentions which have been
tagged relation types in the given corpus. Then the
relation type tags were removed to test the unsuper-
vised relation disambiguation. During the evalua-
tion procedure, the relation type tags were used as
ground truth classes. A break-down of the data by
24 relation subtypes is given in Table 2.
3.2 Evaluation method for clustering result
When assessing the agreement between clustering
result and manually annotated relation types (ground
truth classes), we would encounter the problem that
there was no relation type tags for each cluster in our
clustering results.
To resolve the problem, we construct a contin-
gency table T , where each entry ti,j gives the num-
ber of the instances that belong to both the i-th es-
timated cluster and j-th ground truth class. More-
over, to ensure that any two clusters do not share
the same labels of relation types, we adopt a per-
mutation procedure to find an one-to-one mapping
function ? from the ground truth classes (relation
types) TC to the estimated clustering result EC.
There are at most |TC| clusters which are assigned
relation type tags. And if the number of the esti-
mated clusters is less than the number of the ground
truth clusters, empty clusters should be added so that
|EC| = |TC| and the one-to-one mapping can be
performed, which can be formulated as the function:
?? = argmax?
?|TC|
j=1 t?(j),j , where ?(j) is the in-
dex of the estimated cluster associated with the j-th
class.
Given the result of one-to-one mapping, we adopt
Precision, Recall and F-measure to evaluate the
clustering result.
3.3 Experimental Design
We perform our unsupervised relation extraction on
the devtest set of ACE corpus and evaluate the al-
gorithm on relation subtype level. Firstly, we ob-
serve the influence of various variables, including
Distance Parameter ?2, Different Features, Context
Window Size. Secondly, to verify the effectiveness
of our method, we further compare it with other two
unsupervised methods.
3.3.1 Choice of Distance Parameter ?2
We simply search over ?2 and pick the value
that finds the best aligned set of clusters on the
transformed space. Here, the scattering criterion
trace(P?1W PB) is used to compare the cluster qual-
ity for different value of ?2 3, which measures the ra-
tio of between-cluster to within-cluster scatter. The
higher the trace(P?1W PB), the higher the cluster
quality.
In Table 3 and Table 4, with different settings of
feature set and context window size, we find out the
3 trace(P?1W PB) is trace of a matrix which is the sum of
its diagonal elements. PW is the within-cluster scatter matrix
as: PW =
?c
j=1
?
Xi??j (Xi ? mj)(Xi ? mj)
t and PB
is the between-cluster scatter matrix as: PB =
?c
j=1(mj ?
m)(mj ? m)t, where m is the total mean vector and mj is
the mean vector for jth cluster and (Xj ? mj)t is the matrix
transpose of the column vector (Xj ?mj).
93
Table 3: Contribution of Different Features
Features ?2 cluster number trace value Precison Recall F-measure
Words 0.021 15 2.369 41.6% 30.2% 34.9%
+Entity Type 0.016 18 3.198 40.3% 42.5% 41.5%
+POS 0.017 18 3.206 37.8% 46.9% 41.8%
+Chunking Infomation 0.015 19 3.900 43.5% 49.4% 46.3%
Table 4: Different Context Window Size Setting
Context Window Size ?2 cluster number trace value Precision Recall F-measure
0 0.016 18 3.576 37.6% 48.1% 42.2%
2 0.015 19 3.900 43.5% 49.4% 46.3%
5 0.020 21 2.225 29.3% 34.7% 31.7%
corresponding value of ?2 and cluster number which
maximize the trace value in searching for a range of
value ?2.
3.3.2 Contribution of Different Features
As the previous section presented, we incorporate
various lexical and syntactic features to extract rela-
tion. To measure the contribution of different fea-
tures, we report the performance by gradually in-
creasing the feature set, as Table 3 shows.
Table 3 shows that all of the four categories of fea-
tures contribute to the improvement of performance
more or less. Firstly,the addition of entity type fea-
ture is very useful, which improves F-measure by
6.6%. Secondly, adding POS features can increase
F-measure score but do not improve very much.
Thirdly, chunking features also show their great use-
fulness with increasing Precision/Recall/F-measure
by 5.7%/2.5%/4.5%.
We combine all these features to do all other eval-
uations in our experiments.
3.3.3 Setting of Context Window Size
We have mentioned in Section 2 that the context
vectors of entity pairs are derived from the contexts
before, between and after the entity mention pairs.
Hence, we have to specify the three context window
size first. In this paper, we set the mid-context win-
dow as everything between the two entity mentions.
For the pre- and post- context windows, we could
have different choices. For example, if we specify
the outer context window size as 2, then it means that
the pre-context (post-context)) includes two words
before (after) the first (second) entity.
For comparison of the effect of the outer context
of entity mention pairs, we conducted three different
Table 5: Performance of our proposed method (Spectral-
based clustering) compared with other unsupervised methods:
((Hasegawa et al, 2004))?s clustering method and K-means
clustering.
Precision Recall F-measure
Hasegawa?s Method1 38.7% 29.8% 33.7%
Hasegawa?s Method2 37.9% 36.0% 36.9%
Kmeans 34.3% 40.2% 36.8%
Our Proposed Method 43.5% 49.4% 46.3%
settings of context window size (0, 2, 5) as Table 4
shows. From this table we can find that with the con-
text window size setting, 2, the algorithm achieves
the best performance of 43.5%/49.4%/46.3% in
Precision/Recall/F-measure. With the context win-
dow size setting, 5, the performance becomes worse
because extending the context too much may include
more features, but at the same time, the noise also
increases.
3.3.4 Comparison with other Unsupervised
methods
In (Hasegawa et al, 2004), they preformed un-
supervised relation extraction based on hierarchical
clustering and they only used word features between
entity mention pairs to construct context vectors. We
reported the clustering results using the same clus-
tering strategy as Hasegawa et al (2004) proposed.
In Table 5, Hasegawa?s Method1 means the test used
the word feature as Hasegawa et al (2004) while
Hasegawa?s Method2 means the test used the same
feature set as our method. In both tests, we specified
the cluster number as the number of ground truth
classes.
We also approached the relation extraction prob-
lem using the standard clustering technique, K-
94
means, where we adopted the same feature set de-
fined in our proposed method to cluster the con-
text vectors of entity mention pairs and pre-specified
the cluster number as the number of ground truth
classes.
Table 5 reports the performance of our proposed
method comparing with the other two unsupervised
methods. Table 5 shows our proposed spectral based
method clearly outperforms the other two unsuper-
vised methods by 12.5% and 9.5% in F-measure re-
spectively. Moreover, the incorporation of various
lexical and syntactic features into Hasegawa et al
(2004)?s method2 makes it outperform Hasegawa et
al. (2004)?s method1 which only uses word feature.
3.4 Discussion
In this paper, we have shown that the modified spec-
tral clustering technique, with various lexical and
syntactic features derived from the context of entity
pairs, performed well on the unsupervised relation
extraction problem. Our experiments show that by
the choice of the distance parameter ?2, we can esti-
mate the cluster number which provides the tightest
clusters. We notice that the estimated cluster num-
ber is less than the number of ground truth classes
in most cases. The reason for this phenomenon may
be that some relation types can not be easily distin-
guished using the context information only. For ex-
ample, the relation subtypes ?Located?, ?Based-In?
and ?Residence? are difficult to disambiguate even
for human experts to differentiate.
The results also show that various lexical and
syntactic features contain useful information for the
task. Especially, although we did not concern the
dependency tree and full parse tree information as
other supervised methods (Miller et al, 2000; Cu-
lotta and Soresen, 2004; Kambhatla, 2004; Zhou et
al., 2005), the incorporation of simple features, such
as words and chunking information, still can provide
complement information for capturing the character-
istics of entity pairs. This perhaps dues to the fact
that two entity mentions are close to each other in
most of relations defined in ACE. Another observa-
tion from the result is that extending the outer con-
text window of entity mention pairs too much may
not improve the performance since the process may
incorporate more noise information and affect the
clustering result.
As regards the clustering technique, the spectral-
based clustering performs better than direct cluster-
ing, K-means. Since the spectral-based algorithm
works in a transformed space of low dimension-
ality, data can be easily clustered so that the al-
gorithm can be implemented with better efficiency
and speed. And the performance using spectral-
based clustering can be improved due to the reason
that spectral-based clustering overcomes the draw-
back of K-means (prone to local minima) and may
find non-convex clusters consistent with human in-
tuition.
Generally, from the point of view of unsu-
pervised resolution for relation extraction, our
approach already achieves best performance of
43.5%/49.4%/46.3% in Precision/Recall/F-measure
compared with other clustering methods.
4 Conclusion and Future work
In this paper, we approach unsupervised relation ex-
traction problem by using spectral-based clustering
technique with diverse lexical and syntactic features
derived from context. The advantage of our method
is that it doesn?t need any manually labeled relation
instances, and pre-definition the number of the con-
text clusters. Experiment results on the ACE corpus
show that our method achieves better performance
than other unsupervised methods, i.e.Hasegawa et
al. (2004)?s method and Kmeans-based method.
Currently we combine various lexical and syn-
tactic features to construct context vectors for clus-
tering. In the future we will further explore other
semantic information to assist the relation extrac-
tion problem. Moreover, instead of cosine similar-
ity measure to calculate the distance between con-
text vectors, we will try other distributional similar-
ity measures to see whether the performance of re-
lation extraction can be improved. In addition, if we
can find an effective unsupervised way to filter out
unrelated entity pairs in advance, it would make our
proposed method more practical.
References
Agichtein E. and Gravano L.. 2000. Snowball: Ex-
tracting Relations from large Plain-Text Collections,
In Proc. of the 5th ACM International Conference on
Digital Libraries (ACMDL?00).
95
Brin Sergey. 1998. Extracting patterns and relations
from world wide web. In Proc. of WebDB Workshop at
6th International Conference on Extending Database
Technology (WebDB?98). pages 172-183.
Charniak E.. 1999. A Maximum-entropy-inspired parser.
Technical Report CS-99-12.. Computer Science De-
partment, Brown University.
Culotta A. and Soresen J. 2004. Dependency tree kernels
for relation extraction, In proceedings of 42th Annual
Meeting of the Association for Computational Linguis-
tics. 21-26 July 2004. Barcelona, Spain.
Defense Advanced Research Projects Agency. 1995.
Proceedings of the Sixth Message Understanding Con-
ference (MUC-6) Morgan Kaufmann Publishers, Inc.
Hasegawa Takaaki, Sekine Satoshi and Grishman Ralph.
2004. Discovering Relations among Named Enti-
ties from Large Corpora, Proceeding of Conference
ACL2004. Barcelona, Spain.
Kambhatla N. 2004. Combining lexical, syntactic and
semantic features with Maximum Entropy Models for
extracting relations, In proceedings of 42th Annual
Meeting of the Association for Computational Linguis-
tics. 21-26 July 2004. Barcelona, Spain.
Kannan R., Vempala S., and Vetta A.. 2000. On cluster-
ing: Good,bad and spectral. In Proceedings of the 41st
Foundations of Computer Science. pages 367-380.
Miller S.,Fox H.,Ramshaw L. and Weischedel R. 2000.
A novel use of statistical parsing to extract information
from text. In proceedings of 6th Applied Natural Lan-
guage Processing Conference. 29 April-4 may 2000,
Seattle USA.
Ng Andrew.Y, Jordan M., and Weiss Y.. 2001. On spec-
tral clustering: Analysis and an algorithm. In Pro-
ceedings of Advances in Neural Information Process-
ing Systems. pages 849-856.
Sanguinetti G., Laidler J. and Lawrence N.. 2005. Au-
tomatic determination of the number of clusters us-
ing spectral algorithms.In: IEEE Machine Learning
for Signal Processing. 28-30 Sept 2005, Mystic, Con-
necticut, USA.
Shi J. and Malik.J. 2000. Normalized cuts and image
segmentation. IEEE Transactions on Pattern Analysis
and Machine Intelligence. 22(8):888-905.
Weiss Yair. 1999. Segmentation using eigenvectors: A
unifying view. ICCV(2). pp.975-982.
Zelenko D., Aone C. and Richardella A.. 2002. Ker-
nel Methods for Relation Extraction, Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP). Philadelphia.
Zha H.,Ding C.,Gu.M,He X.,and Simon H.. 2001. Spec-
tral Relaxation for k-means clustering. In Neural In-
formation Processing Systems (NIPS2001). pages
1057-1064, 2001.
Zhang Zhu. 2004. Weakly-supervised relation classifi-
cation for Information Extraction, In proceedings of
ACM 13th conference on Information and Knowledge
Management (CIKM?2004). 8-13 Nov 2004. Wash-
ington D.C.,USA.
Zhou GuoDong, Su Jian, Zhang Jie and Zhang min.
2005. Exploring Various Knowledge in Relation Ex-
traction, In proceedings of 43th Annual Meeting of the
Association for Computational Linguistics. USA.
96
Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 568?575,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Unsupervised Relation Disambiguation with Order Identification
Capabilities
Jinxiu Chen1 Donghong Ji1 Chew Lim Tan2 Zhengyu Niu1
1Institute for Infocomm Research 2Department of Computer Science
21 Heng Mui Keng Terrace National University of Singapore
119613 Singapore 117543 Singapore
{jinxiu,dhji,zniu}@i2r.a-star.edu.sg tancl@comp.nus.edu.sg
Abstract
We present an unsupervised learning ap-
proach to disambiguate various relations
between name entities by use of various
lexical and syntactic features from the
contexts. It works by calculating eigen-
vectors of an adjacency graph?s Lapla-
cian to recover a submanifold of data
from a high dimensionality space and
then performing cluster number estima-
tion on the eigenvectors. This method
can address two difficulties encoutered
in Hasegawa et al (2004)?s hierarchical
clustering: no consideration of manifold
structure in data, and requirement to pro-
vide cluster number by users. Experiment
results on ACE corpora show that this
spectral clustering based approach outper-
forms Hasegawa et al (2004)?s hierarchi-
cal clustering method and a plain k-means
clustering method.
1 Introduction
The task of relation extraction is to identify vari-
ous semantic relations between name entities from
text. Prior work on automatic relation extraction
come in three kinds: supervised learning algorithms
(Miller et al, 2000; Zelenko et al, 2002; Culotta
and Soresen, 2004; Kambhatla, 2004; Zhou et al,
2005), semi-supervised learning algorithms (Brin,
1998; Agichtein and Gravano, 2000; Zhang, 2004),
and unsupervised learning algorithm (Hasegawa et
al., 2004).
Among these methods, supervised learning is usu-
ally more preferred when a large amount of la-
beled training data is available. However, it is
time-consuming and labor-intensive to manually tag
a large amount of training data. Semi-supervised
learning methods have been put forward to mini-
mize the corpus annotation requirement. Most of
semi-supervised methods employ the bootstrapping
framework, which only need to pre-define some ini-
tial seeds for any particular relation, and then boot-
strap from the seeds to acquire the relation. How-
ever, it is often quite difficult to enumerate all class
labels in the initial seeds and decide an ?optimal?
number of them.
Compared with supervised and semi-supervised
methods, Hasegawa et al (2004)?s unsupervised ap-
proach for relation extraction can overcome the dif-
ficulties on requirement of a large amount of labeled
data and enumeration of all class labels. Hasegawa
et al (2004)?s method is to use a hierarchical cluster-
ing method to cluster pairs of named entities accord-
ing to the similarity of context words intervening be-
tween the named entities. However, the drawback of
hierarchical clustering is that it required providing
cluster number by users. Furthermore, clustering is
performed in original high dimensional space, which
may induce non-convex clusters hard to identified.
This paper presents a novel application of spec-
tral clustering technique to unsupervised relation ex-
traction problem. It works by calculating eigenvec-
tors of an adjacency graph?s Laplacian to recover a
submanifold of data from a high dimensional space,
and then performing cluster number estimation on
a transformed space defined by the first few eigen-
vectors. This method may help us find non-convex
clusters. It also does not need to pre-define the num-
ber of the context clusters or pre-specify the simi-
larity threshold for the clusters as Hasegawa et al
568
(2004)?s method.
The rest of this paper is organized as follows. Sec-
tion 2 formulates unsupervised relation extraction
and presents how to apply the spectral clustering
technique to resolve the task. Then section 3 reports
experiments and results. Finally we will give a con-
clusion about our work in section 4.
2 Unsupervised Relation Extraction
Problem
Assume that two occurrences of entity pairs with
similar contexts, are tend to hold the same relation
type. Thus unsupervised relation extraction prob-
lem can be formulated as partitioning collections of
entity pairs into clusters according to the similarity
of contexts, with each cluster containing only entity
pairs labeled by the same relation type. And then, in
each cluster, the most representative words are iden-
tified from the contexts of entity pairs to induce the
label of relation type. Here, we only focus on the
clustering subtask and do not address the relation
type labeling subtask.
In the next subsections we will describe our pro-
posed method for unsupervised relation extraction,
which includes: 1) Collect the context vectors in
which the entity mention pairs co-occur; 2) Cluster
these Context vectors.
2.1 Context Vector and Feature Design
Let X = {xi}ni=1 be the set of context vectors of oc-
currences of all entity mention pairs, where xi repre-
sents the context vector of the i-th occurrence, and n
is the total number of occurrences of all entity pairs.
Each occurrence of entity mention pairs can be
denoted as follows:
R ? (Cpre, e1, Cmid, e2, Cpost) (1)
where e1 and e2 represents the entity mentions, and
Cpre,Cmid,and Cpost are the contexts before, be-
tween and after the entity pairs respectively.
We extracted features from e1, e2, Cpre, Cmid,
Cpost to construct context vectors, which are com-
puted from the parse trees derived from Charniak
Parser (Charniak, 1999) and the Chunklink script 1
written by Sabine Buchholz from Tilburg University.
1 Software available at http://ilk.uvt.nl/ sabine/chunklink/
Words: Words in the two entities and three context
windows.
Entity Type: the entity type of both entity men-
tions, which can be PERSON, ORGANIZA-
TION, FACILITY, LOCATION and GPE.
POS features: Part-Of-Speech tags corresponding
to all words in the two entities and three con-
text windows.
Chunking features: This category of features are
extracted from the chunklink representation,
which includes:
? Chunk tag information of the two entities and
three context windows. The ?0? tag means that
the word is outside of any chunk. The ?I-XP? tag
means that this word is inside an XP chunk. The
?B-XP? by default means that the word is at the be-
ginning of an XP chunk.
? Grammatical function of the two entities and
three context windows. The last word in each chunk
is its head, and the function of the head is the func-
tion of the whole chunk. ?NP-SBJ? means a NP
chunk as the subject of the sentence. The other
words in a chunk that are not the head have ?NO-
FUNC? as their function.
? IOB-chains of the heads of the two entities. So-
called IOB-chain, noting the syntactic categories of
all the constituents on the path from the root node
to this leaf node of tree.
We combine the above lexical and syntactic fea-
tures with their position information in the context
to form the context vector. Before that, we filter out
low frequency features which appeared only once in
the entire set.
2.2 Context Clustering
Once the context vectors of entity pairs are prepared,
we come to the second stage of our method: cluster
these context vectors automatically.
In recent years, spectral clustering technique has
received more and more attention as a powerful ap-
proach to a range of clustering problems. Among
the efforts on spectral clustering techniques (Weiss,
1999; Kannan et al, 2000; Shi et al, 2000; Ng et al,
2001; Zha et al, 2001), we adopt a modified version
(Sanguinetti et al, 2005) of the algorithm by Ng et
al. (2001) because it can provide us model order se-
lection capability.
Since we do not know how many relation types
in advance and do not have any labeled relation
569
Table 1: Context Clustering with Spectral-based Clustering
technique.
Input: A set of context vectors X = {x1, x2, ..., xn},
X ? <n?d;
Output: Clustered data and number of clusters;
1. Construct an affinity matrix by Aij = exp(? s
2
ij
?2 ) if i 6=j, 0 if i = j. Here, sij is the similarity between xi and
xj calculated by Cosine similarity measure. and the free
distance parameter ?2 is used to scale the weights;
2. Normalize the affinity matrix A to create the matrix L =
D?1/2AD?1/2, where D is a diagonal matrix whose (i,i)
element is the sum of A?s ith row;
3. Set q = 2;
4. Compute q eigenvectors of L with greatest eigenvalues.
Arrange them in a matrix Y .
5. Perform elongated K-means with q + 1 centers on Y ,
initializing the (q + 1)-th mean in the origin;
6. If the q+1-th cluster contains any data points, then there
must be at least an extra cluster; set q = q + 1 and go
back to step 4. Otherwise, algorithm stops and outputs
clustered data and number of clusters.
training examples at hand, the problem of model
order selection arises, i.e. estimating the ?opti-
mal? number of clusters. Formally, let k be the
model order, we need to find k in Equation: k =
argmaxk{criterion(k)}. Here, the criterion is de-
fined on the result of spectral clustering.
Table 1 shows the details of the whole algorithm
for context clustering, which contains two main
stages: 1) Transformation of Clustering Space (Step
1-4); 2) Clustering in the transformed space using
Elongated K-means algorithm (Step 5-6).
2.3 Transformation of Clustering Space
We represent each context vector of entity pair as a
node in an undirected graph. Each edge (i,j) in the
graph is assigned a weight that reflects the similarity
between two context vectors i and j. Hence, the re-
lation extraction task for entity pairs can be defined
as a partition of the graph so that entity pairs that
are more similar to each other, e.g. labeled by the
same relation type, belong to the same cluster. As a
relaxation of such NP-hard discrete graph partition-
ing problem, spectral clustering technique computes
eigenvalues and eigenvectors of a Laplacian matrix
related to the given graph, and construct data clus-
ters based on such spectral information.
Thus the starting point of context clustering is to
construct an affinity matrix A from the data, which
is an n ? n matrix encoding the distances between
the various points. The affinity matrix is then nor-
malized to form a matrix L by conjugating with the
the diagonal matrix D?1/2 which has as entries the
square roots of the sum of the rows of A. This is to
take into account the different spread of the various
clusters (points belonging to more rarified clusters
will have lower sums of the corresponding row of
A). It is straightforward to prove that L is positive
definite and has eigenvalues smaller or equal to 1,
with equality holding in at least one case.
Let K be the true number of clusters present in
the dataset. If K is known beforehand, the first K
eigenvectors of L will be computed and arranged as
columns in a matrix Y . Each row of Y corresponds
to a context vector of entity pair, and the above pro-
cess can be considered as transforming the original
context vectors in a d-dimensional space to new con-
text vectors in the K-dimensional space. Therefore,
the rows of Y will cluster upon mutually orthogonal
points on the K dimensional sphere,rather than on
the coordinate axes.
2.4 The Elongated K-means algorithm
As the step 5 of Table 1 shows, the result of elon-
gated K-means algorithm is used to detect whether
the number of clusters selected q is less than the true
number K, and allows one to iteratively obtain the
number of clusters.
Consider the case when the number of clusters q
is less than the true cluster number K present in the
dataset. In such situation, taking the first q < K
eigenvectors, we will be selecting a q-dimensional
subspace in the clustering space. As the rows of the
K eigenvectors clustered along mutually orthogo-
nal vectors, their projections in a lower dimensional
space will cluster along radial directions. Therefore,
the general picture will be of q clusters elongated in
the radial direction, with possibly some clusters very
near the origin (when the subspace is orthogonal to
some of the discarded eigenvectors).
Hence, the K-means algorithm is modified as
the elongated K-means algorithm to downweight
distances along radial directions and penalize dis-
tances along transversal directions. The elongated
K-means algorithm computes the distance of point
x from the center ci as follows:
? If the center is not very near the origin, cTi ci > ? (? is a
parameter to be fixed by the user), the distances are cal-
570
-4 -3 -2 -1 0 1 2 3 4-4
-3
-2
-1
0
1
2
3
4
(a) 
-4 -3 -2 -1 0 1 2 3 4-4
-3
-2
-1
0
1
2
3
4
(b) 
0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08-0.08
-0.06
-0.04
-0.02
0
0.02
0.04
0.06
0.08
0.1
(c) 
-4 -3 -2 -1 0 1 2 3 4-4
-3
-2
-1
0
1
2
3
4
(d) 
Figure 1: An Example:(a) The Three Circle Dataset.
(b) The clustering result using K-means; (c) Three
elongated clusters in the 2D clustering space using
Spectral clustering: two dominant eigenvectors; (d)
The clustering result using Spectral-based clustering
(?2=0.05). (4,? and + denote examples in different
clusters)
culated as: edist(x, ci) = (x ? ci)TM(x ? ci), where
M = 1? (Iq ?
cicTi
cTi ci
) + ? cic
T
i
cTi ci
, ? is the sharpness param-
eter that controls the elongation (the smaller, the more
elongated the clusters) 2.
? If the center is very near the origin,cTi ci < ?, the dis-
tances are measured using the Euclidean distance.
In each iteration of procedure in Table 1, elon-
gated K-means is initialized with q centers corre-
sponding to data points in different clusters and one
center in the origin. The algorithm then will drag the
center in the origin towards one of the clusters not
accounted for. Compute another eigenvector (thus
increasing the dimension of the clustering space to
q + 1) and repeat the procedure. Eventually, when
one reach as many eigenvectors as the number of
clusters present in the data, no points will be as-
signed to the center at the origin, leaving the cluster
empty. This is the signal to terminate the algorithm.
2.5 An example
Figure 1 visualized the clustering result of three cir-
cle dataset using K-means and Spectral-based clus-
tering. From Figure 1(b), we can see that K-means
can not separate the non-convex clusters in three cir-
cle dataset successfully since it is prone to local min-
imal. For spectral-based clustering, as the algorithm
described, initially, we took the two eigenvectors of
L with largest eigenvalues, which gave us a two-
dimensional clustering space. Then to ensure that
the two centers are initialized in different clusters,
one center is set as the point that is the farthest from
the origin, while the other is set as the point that
simultaneously farthest the first center and the ori-
gin. Figure 1(c) shows the three elongated clusters in
the 2D clustering space and the corresponding clus-
tering result of dataset is visualized in Figure 1(d),
which exploits manifold structure (cluster structure)
in data.
3 Experiments and Results
3.1 Data Setting
Our proposed unsupervised relation extraction is
evaluated on ACE corpus, which contains 519 files
from sources including broadcast, newswire, and
newspaper. We only deal with intra-sentence ex-
plicit relations and assumed that all entities have
2 In this paper, the sharpness parameter ? is set to 0.2
571
Table 2: Frequency of Major Relation SubTypes in the ACE
training and devtest corpus.
Type SubType Training Devtest
ROLE General-Staff 550 149
Management 677 122
Citizen-Of 127 24
Founder 11 5
Owner 146 15
Affiliate-Partner 111 15
Member 460 145
Client 67 13
Other 15 7
PART Part-Of 490 103
Subsidiary 85 19
Other 2 1
AT Located 975 192
Based-In 187 64
Residence 154 54
SOC Other-Professional 195 25
Other-Personal 60 10
Parent 68 24
Spouse 21 4
Associate 49 7
Other-Relative 23 10
Sibling 7 4
GrandParent 6 1
NEAR Relative-Location 88 32
been detected beforehand in the EDT sub-task of
ACE. To verify our proposed method, we only col-
lect those pairs of entity mentions which have been
tagged relation types in the given corpus. Then the
relation type tags were removed to test the unsuper-
vised relation disambiguation. During the evalua-
tion procedure, the relation type tags were used as
ground truth classes. A break-down of the data by
24 relation subtypes is given in Table 2.
3.2 Evaluation method for clustering result
When assessing the agreement between clustering
result and manually annotated relation types (ground
truth classes), we would encounter the problem that
there was no relation type tags for each cluster in our
clustering results.
To resolve the problem, we construct a contin-
gency table T , where each entry ti,j gives the num-
ber of the instances that belong to both the i-th es-
timated cluster and j-th ground truth class. More-
over, to ensure that any two clusters do not share
the same labels of relation types, we adopt a per-
mutation procedure to find an one-to-one mapping
function ? from the ground truth classes (relation
types) TC to the estimated clustering result EC.
There are at most |TC| clusters which are assigned
relation type tags. And if the number of the esti-
mated clusters is less than the number of the ground
truth clusters, empty clusters should be added so that
|EC| = |TC| and the one-to-one mapping can be
performed, which can be formulated as the function:
?? = argmax?
?|TC|
j=1 t?(j),j , where ?(j) is the in-
dex of the estimated cluster associated with the j-th
class.
Given the result of one-to-one mapping, we adopt
Precision, Recall and F-measure to evaluate the
clustering result.
3.3 Experimental Design
We perform our unsupervised relation extraction on
the devtest set of ACE corpus and evaluate the al-
gorithm on relation subtype level. Firstly, we ob-
serve the influence of various variables, including
Distance Parameter ?2, Different Features, Context
Window Size. Secondly, to verify the effectiveness
of our method, we further compare it with super-
vised method based on SVM and other two unsuper-
vised methods.
3.3.1 Choice of Distance Parameter ?2
We simply search over ?2 and pick the value
that finds the best aligned set of clusters on the
transformed space. Here, the scattering criterion
trace(P?1W PB) is used to compare the cluster qual-
ity for different value of ?2 3, which measures the ra-
tio of between-cluster to within-cluster scatter. The
higher the trace(P?1W PB), the higher the cluster
quality.
In Table 3 and Table 4, with different settings of
feature set and context window size, we find out the
corresponding value of ?2 and cluster number which
maximize the trace value in searching for a range of
value ?2.
3.3.2 Contribution of Different Features
As the previous section presented, we incorporate
various lexical and syntactic features to extract rela-
3 trace(P?1W PB) is trace of a matrix which is the sum of
its diagonal elements. PW is the within-cluster scatter matrix
as: PW =
?c
j=1
?
Xi??j (Xi ? mj)(Xi ? mj)
t and PB
is the between-cluster scatter matrix as: PB =
?c
j=1(mj ?
m)(mj ? m)t, where m is the total mean vector and mj is
the mean vector for jth cluster and (Xj ? mj)t is the matrix
transpose of the column vector (Xj ?mj).
572
Table 3: Contribution of Different Features
Features ?2 cluster number trace value Precison Recall F-measure
Words 0.021 15 2.369 41.6% 30.2% 34.9%
+Entity Type 0.016 18 3.198 40.3% 42.5% 41.5%
+POS 0.017 18 3.206 37.8% 46.9% 41.8%
+Chunking Infomation 0.015 19 3.900 43.5% 49.4% 46.3%
Table 4: Different Context Window Size Setting
Context Window Size ?2 cluster number trace value Precision Recall F-measure
0 0.016 18 3.576 37.6% 48.1% 42.2%
2 0.015 19 3.900 43.5% 49.4% 46.3%
5 0.020 21 2.225 29.3% 34.7% 31.7%
tion. To measure the contribution of different fea-
tures, we report the performance by gradually in-
creasing the feature set, as Table 3 shows.
Table 3 shows that all of the four categories of fea-
tures contribute to the improvement of performance
more or less. Firstly,the addition of entity type fea-
ture is very useful, which improves F-measure by
6.6%. Secondly, adding POS features can increase
F-measure score but do not improve very much.
Thirdly, chunking features also show their great use-
fulness with increasing Precision/Recall/F-measure
by 5.7%/2.5%/4.5%.
We combine all these features to do all other eval-
uations in our experiments.
3.3.3 Setting of Context Window Size
We have mentioned in Section 2 that the context
vectors of entity pairs are derived from the contexts
before, between and after the entity mention pairs.
Hence, we have to specify the three context window
size first. In this paper, we set the mid-context win-
dow as everything between the two entity mentions.
For the pre- and post- context windows, we could
have different choices. For example, if we specify
the outer context window size as 2, then it means that
the pre-context (post-context)) includes two words
before (after) the first (second) entity.
For comparison of the effect of the outer context
of entity mention pairs, we conducted three different
settings of context window size (0, 2, 5) as Table 4
shows. From this table we can find that with the con-
text window size setting, 2, the algorithm achieves
the best performance of 43.5%/49.4%/46.3% in
Precision/Recall/F-measure. With the context win-
dow size setting, 5, the performance becomes worse
Table 5: Performance of our proposed method (Spectral-
based clustering) compared with supervised method (SVM) and
unsupervised methods((Hasegawa et al, 2004))?s method and
K-means clustering.
Precision Recall F-measure
SVM 61.2% 49.6% 54.8%
Hasegawa?s Method1 38.7% 29.8% 33.7%
Hasegawa?s Method2 37.9% 36.0% 36.9%
Kmeans 34.3% 40.2% 36.8%
Our Proposed Method 43.5% 49.4% 46.3%
because extending the context too much may include
more features, but at the same time, the noise also
increases.
3.3.4 Comparison with Supervised methods
and other Unsupervised methods
To explore the effectiveness of our unsupervised
method compared to supervised method, we perform
SVM technique with the same feature set defined in
our proposed method. The LIBSVM tool is used in
this test 4. The kernel function we used is linear
and SVM models are trained using the training set
of ACE corpus.
In (Hasegawa et al, 2004), they preformed un-
supervised relation extraction based on hierarchical
clustering and they only used word features between
entity mention pairs to construct context vectors. We
reported the clustering results using the same clus-
tering strategy as Hasegawa et al (2004) proposed.
In Table 5, Hasegawa?s Method1 means the test used
the word feature as Hasegawa et al (2004) while
Hasegawa?s Method2 means the test used the same
feature set as our method. In both tests, we specified
4 LIBSVM : a library for support vector machines. Soft-
ware available at http://www.csie.ntu.edu.tw/ cjlin/libsvm. It
supports multi-class classification.
573
Table 6: Comparison of the existing efforts on ACE RDC task.
Relation Dectection Relation Classification
on Types on Subtypes
Method P R F P R F P R F
Culotta and Soresen (2004) Tree kernel based 81.2 51.8 63.2 67.1 35.0 45.8 - - -
Kambhatla (2004) Feature based, Maxi-
mum Entropy
- - - - - - 63.5 45.2 52.8
Zhou et al (2005) Feature based,SVM 84.8 66.7 74.7 77.2 60.7 68.0 63.1 49.5 55.5
the cluster number as the number of ground truth
classes.
We also approached the relation extraction prob-
lem using the standard clustering technique, K-
means, where we adopted the same feature set de-
fined in our proposed method to cluster the con-
text vectors of entity mention pairs and pre-specified
the cluster number as the number of ground truth
classes.
Table 5 reports the performance of our pro-
posed method comparing with SVM-based super-
vised method and the other two unsupervised meth-
ods. As the result shows, SVM-based method by us-
ing the same feature set in our proposed method can
achieve 61.2%/49.6%/54.8% in Precision/Recall/F-
measure. Table 5 also shows our proposed spec-
tral based method clearly outperforms the other
two unsupervised methods by 12.5% and 9.5% in
F-measure respectively. Moreover, the incorpora-
tion of various lexical and syntactic features into
Hasegawa et al (2004)?s method2 makes it outper-
form Hasegawa et al (2004)?s method1 which only
uses word feature.
3.4 Discussion
In this paper, we have shown that the modified spec-
tral clustering technique, with various lexical and
syntactic features derived from the context of en-
tity pairs, performed well on the unsupervised re-
lation disambiguation problem. Our experiments
show that by the choice of the distance parameter
?2, we can estimate the cluster number which pro-
vides the tightest clusters. We notice that the es-
timated cluster number is less than the number of
ground truth classes in most cases. The reason for
this phenomenon may be that some relation types
can not be easily distinguished using the context in-
formation only. For example, the relation subtypes
?Located?, ?Based-In? and ?Residence? are difficult
to disambiguate even for human experts to differen-
tiate.
The results also show that various lexical and
syntactic features contain useful information for the
task. Especially, although we did not concern the
dependency tree and full parse tree information as
other supervised methods (Miller et al, 2000; Cu-
lotta and Soresen, 2004; Kambhatla, 2004; Zhou et
al., 2005), the incorporation of simple features, such
as words and chunking information, still can provide
complement information for capturing the charac-
teristics of entity pairs. Another observation from
the result is that extending the outer context window
of entity mention pairs too much may not improve
the performance since the process may incorporate
more noise information and affect the clustering re-
sult.
As regards the clustering technique, the spectral-
based clustering performs better than direct cluster-
ing, K-means. Since the spectral-based algorithm
works in a transformed space of low dimension-
ality, data can be easily clustered so that the al-
gorithm can be implemented with better efficiency
and speed. And the performance using spectral-
based clustering can be improved due to the reason
that spectral-based clustering overcomes the draw-
back of K-means (prone to local minima) and may
find non-convex clusters consistent with human in-
tuition.
Currently most of works on the RDC task of ACE
focused on supervised learning methods. Table 6
lists a comparison of these methods on relation de-
tection and relation classification. Zhou et al (2005)
reported the best result as 63.1%/49.5%/55.5% in
Precision/Recall/F-measure on the extraction of
ACE relation subtypes using feature based method,
which outperforms tree kernel based method by
Culotta and Soresen (2004). Although our unsu-
pervised method still can not outperform these su-
574
pervised methods, from the point of view of un-
supervised resolution for relation extraction, our
approach already achieves best performance of
43.5%/49.4%/46.3% in Precision/Recall/F-measure
compared with other clustering methods.
4 Conclusion and Future work
In this paper, we approach unsupervised relation dis-
ambiguation problem by using spectral-based clus-
tering technique with diverse lexical and syntactic
features derived from context. The advantage of our
method is that it doesn?t need any manually labeled
relation instances, and pre-definition the number of
the context clusters. Experiment results on the ACE
corpus show that our method achieves better perfor-
mance than other unsupervised methods.
Currently we combine various lexical and syn-
tactic features to construct context vectors for clus-
tering. In the future we will further explore other
semantic information to assist the relation extrac-
tion problem. Moreover, instead of cosine similar-
ity measure to calculate the distance between con-
text vectors, we will try other distributional similar-
ity measures to see whether the performance of re-
lation extraction can be improved. In addition, if we
can find an effective unsupervised way to filter out
unrelated entity pairs in advance, it would make our
proposed method more practical.
References
Agichtein E. and Gravano L.. 2000. Snowball: Ex-
tracting Relations from large Plain-Text Collections,
In Proc. of the 5th ACM International Conference on
Digital Libraries (ACMDL?00).
Brin Sergey. 1998. Extracting patterns and relations
from world wide web. In Proc. of WebDB Workshop at
6th International Conference on Extending Database
Technology (WebDB?98). pages 172-183.
Charniak E.. 1999. A Maximum-entropy-inspired parser.
Technical Report CS-99-12.. Computer Science De-
partment, Brown University.
Culotta A. and Soresen J. 2004. Dependency tree kernels
for relation extraction, In proceedings of 42th Annual
Meeting of the Association for Computational Linguis-
tics. 21-26 July 2004. Barcelona, Spain.
Defense Advanced Research Projects Agency. 1995.
Proceedings of the Sixth Message Understanding Con-
ference (MUC-6) Morgan Kaufmann Publishers, Inc.
Hasegawa Takaaki, Sekine Satoshi and Grishman Ralph.
2004. Discovering Relations among Named Enti-
ties from Large Corpora, Proceeding of Conference
ACL2004. Barcelona, Spain.
Kambhatla N. 2004. Combining lexical, syntactic and
semantic features with Maximum Entropy Models for
extracting relations, In proceedings of 42th Annual
Meeting of the Association for Computational Linguis-
tics. 21-26 July 2004. Barcelona, Spain.
Kannan R., Vempala S., and Vetta A.. 2000. On cluster-
ing: Good,bad and spectral. In Proceedings of the 41st
Foundations of Computer Science. pages 367-380.
Miller S.,Fox H.,Ramshaw L. and Weischedel R. 2000.
A novel use of statistical parsing to extract information
from text. In proceedings of 6th Applied Natural Lan-
guage Processing Conference. 29 April-4 may 2000,
Seattle USA.
Ng Andrew.Y, Jordan M., and Weiss Y.. 2001. On spec-
tral clustering: Analysis and an algorithm. In Pro-
ceedings of Advances in Neural Information Process-
ing Systems. pages 849-856.
Sanguinetti G., Laidler J. and Lawrence N.. 2005. Au-
tomatic determination of the number of clusters us-
ing spectral algorithms.In: IEEE Machine Learning
for Signal Processing. 28-30 Sept 2005, Mystic, Con-
necticut, USA.
Shi J. and Malik.J. 2000. Normalized cuts and image
segmentation. IEEE Transactions on Pattern Analysis
and Machine Intelligence. 22(8):888-905.
Weiss Yair. 1999. Segmentation using eigenvectors: A
unifying view. ICCV(2). pp.975-982.
Zelenko D., Aone C. and Richardella A.. 2002. Ker-
nel Methods for Relation Extraction, Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP). Philadelphia.
Zha H.,Ding C.,Gu.M,He X.,and Simon H.. 2001. Spec-
tral Relaxation for k-means clustering. In Neural In-
formation Processing Systems (NIPS2001). pages
1057-1064, 2001.
Zhang Zhu. 2004. Weakly-supervised relation classifi-
cation for Information Extraction, In proceedings of
ACM 13th conference on Information and Knowledge
Management (CIKM?2004). 8-13 Nov 2004. Wash-
ington D.C.,USA.
Zhou GuoDong, Su Jian, Zhang Jie and Zhang min.
2005. Exploring Various Knowledge in Relation Ex-
traction, In proceedings of 43th Annual Meeting of the
Association for Computational Linguistics. USA.
575
