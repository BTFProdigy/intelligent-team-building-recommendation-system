Proceedings of the ACL 2007 Demo and Poster Sessions, pages 157?160,
Prague, June 2007. c?2007 Association for Computational Linguistics
Detecting Semantic Relations between Named Entities in Text
Using Contextual Features
Toru Hirano, Yoshihiro Matsuo, Genichiro Kikui
NTT Cyber Space Laboratories, NTT Corporation
1-1 Hikarinooka, Yokosuka-Shi, Kanagawa, 239-0847, Japan
{hirano.tohru, matsuo.yoshihiro, kikui.genichiro}@lab.ntt.co.jp
Abstract
This paper proposes a supervised learn-
ing method for detecting a semantic rela-
tion between a given pair of named enti-
ties, which may be located in different sen-
tences. The method employs newly intro-
duced contextual features based on center-
ing theory as well as conventional syntac-
tic and word-based features. These features
are organized as a tree structure and are
fed into a boosting-based classification al-
gorithm. Experimental results show the pro-
posed method outperformed prior methods,
and increased precision and recall by 4.4%
and 6.7%.
1 Introduction
Statistical and machine learning NLP techniques are
now so advanced that named entity (NE) taggers are
in practical use. Researchers are now focusing on
extracting semantic relations between NEs, such as
?George Bush (person)? is ?president (relation)? of
?the United States (location)?, because they provide
important information used in information retrieval,
question answering, and summarization.
We represent a semantic relation between two
NEs with a tuple [NE1, NE2, Relation Label]. Our
final goal is to extract tuples from a text. For exam-
ple, the tuple [George Bush (person), the U.S. (loca-
tion), president (Relation Label)] would be extracted
from the sentence ?George Bush is the president of
the U.S.?. There are two tasks in extracting tuples
from text. One is detecting whether or not a given
pair of NEs are semantically related (relation detec-
tion), and the other is determining the relation label
(relation characterization).
In this paper, we address the task of relation de-
tection. So far, various supervised learning ap-
proaches have been explored in this field (Culotta
and Sorensen, 2004; Zelenko et al, 2003). They
use two kinds of features: syntactic ones and word-
based ones, for example, the path of the given pair of
NEs in the parse tree and the word n-gram between
NEs (Kambhatla, 2004).
These methods have two problems which we con-
sider in this paper. One is that they target only intra-
sentential relation detection in which NE pairs are
located in the same sentence, in spite of the fact that
about 35% of NE pairs with semantic relations are
inter-sentential (See Section 3.1). The other is that
the methods can not detect semantic relations cor-
rectly when NE pairs located in a parallel sentence
arise from a predication ellipsis. In the following
Japanese example1, the syntactic feature, which is
the path of two NEs in the dependency structure,
of the pair with a semantic relation (?Ken11? and
?Tokyo12?) is the same as the feature of the pair with
no semantic relation (?Ken11? and ?New York14?).
(S-1) Ken11-wa Tokyo12-de, Tom13-wa
New York14-de umareta15.
(Ken11 was born15 in Tokyo12, Tom13 in
New York14.)
To solve the above problems, we propose a super-
vised learning method using contextual features.
The rest of this paper is organized as follows. Sec-
tion 2 describes the proposed method. We report the
results of our experiments in Section 3 and conclude
the paper in Section 4.
2 Relation Detection
The proposed method employs contextual features
based on centering theory (Grosz et al, 1983) as
well as conventional syntactic and word-based fea-
tures. These features are organized as a tree struc-
ture and are fed into a boosting-based classification
algorithm. The method consists of three parts: pre-
processing (POS tagging, NE tagging, and parsing),
1The numbers show correspondences of words between
Japanese and English.
157
feature extraction (contextual, syntactic, and word-
based features), and classification.
In this section, we describe the underlying idea of
contextual features and how contextual features are
used for detecting semantic relations.
2.1 Contextual Features
When a pair of NEs with a semantic relation appears
in different sentences, the antecedent NE must be
contextually easily referred to in the sentence with
the following NE. In the following Japanese exam-
ple, the pair ?Ken22? and ?amerika32 (the U.S.)?
have a semantic relation ?wataru33 (go)?, because
?Ken22? is contextually referred to in the sentence
with ?amerika32? (In fact, the zero pronoun ?i
refers to ?Ken22?). Meanwhile, the pair ?Naomi25?
and ?amerika32? has no semantic relation, because
the sentence with ?amerika32? does not refer to
?Naomi25?.
(S-2) asu21, Ken22-wa Osaka23-o otozure24
Naomi25-to au26.
(Ken22 is going to visit24 Osaka23 to see26
Naomi25, tomorrow21.)
(S-3) sonogo31, (?i-ga) amerika32-ni watari33
Tom34-to ryoko35 suru.
(Then31, (hei) will go33 to the U.S.32 to travel35
with Tom34.)
Furthermore, when a pair of NEs with a seman-
tic relation appears in a parallel sentence arise from
predication ellipsis, the antecedent NE is contextu-
ally easily referred to in the phrase with the follow-
ing NE. In the example of ?(S-1)?, the pair ?Ken11?
and ?Tokyo12? have a semantic relation ?umareta15
(was born)?. Meanwhile, the pair ?Ken11? and
?New York14? has no semantic relation.
Therefore, using whether the antecedent NE is re-
ferred to in the context with the following NE as fea-
tures of a given pair of NEs would improve relation
detection performance. In this paper, we use cen-
tering theory (Kameyama, 1986) to determine how
easily a noun phrase can be referred to in the follow-
ing context.
2.2 Centering Theory
Centering theory is an empirical sorting rule used to
identify the antecedents of (zero) pronouns. When
there is a (zero) pronoun in the text, noun phrases
that are in the previous context of the pronoun are
sorted in order of likelihood of being the antecedent.
The sorting algorithm has two steps. First, from the
beginning of the text until the pronoun appears, noun
Osaka
23
o asu
21
, Naomi
25
othersni
ga Ken22wa
Priority
Figure 1: Information Stacked According to Center-
ing Theory
phrases are stacked depending on case markers such
as particles. In the above example, noun phrases,
?asu21?, ?Ken22?, ?Osaka23? and ?Naomi25?, which
are in the previous context of the zero pronoun ?i,
are stacked and then the information shown in Fig-
ure 1 is acquired. Second, the stacked information is
sorted by the following rules.
1. The priority of case markers is as follows: ?wa
> ga > ni > o > others?
2. The priority of stack structure is as follows:
last-in first-out, in the same case marker
For example, Figure 1 is sorted by the above rules
and then the order, 1: ?Ken22?, 2: ?Osaka23?, 3:
?Naomi25?, 4: ?asu21?, is assigned. In this way, us-
ing centering theory would show that the antecedent
of the zero pronoun ?i is ?Ken22?.
2.3 Applying Centering Theory
When detecting a semantic relation between a given
pair of NEs, we use centering theory to determine
how easily the antecedent NE can be referred to in
the context with the following NE. Note that we do
not explicitly execute anaphora resolutions here.
Applied centering theory to relation detection is
as follows. First, from the beginning of the text until
the following NE appears, noun phrases are stacked
depending on case markers, and the stacked infor-
mation is sorted by the above rules (Section 2.2).
Then, if the top noun phrase in the sorted order is
identical to the antecedent NE, the antecedent NE is
?positive? when being referred to in the context with
the following NE.
When the pair of NEs, ?Ken22? and ?amerika32?,
is given in the above example, the noun phrases,
?asu21?, ?Ken22?, ?Osaka23? and ?Naomi25?, which
are in the previous context of the following NE
?amerika32?, are stacked (Figure 1). Then they are
sorted by the above sorting rules and the order, 1:
?Ken22?, 2: ?Osaka23?, 3: ?Naomi25?, 4: ?asu21?,
is acquired. Here, because the top noun phrase in
the sorted order is identical to the antecedent NE,
the antecedent NE ?Ken22? is ?positive? when be-
158
amerika
32wa: Ken
22
o: Osaka
23
others: Naomi
25others: asu
21
Figure 2: Centering Structure
ing referred to in the context with the following NE
?amerika32?. Whether or not the antecedent NE is
referred to in the context with the following NE is
used as a feature. We call this feature Centering Top
(CT).
2.4 Using Stack Structure
The sorting algorithm using centering theory tends
to rank highly thoes words that easily become sub-
jects. However, for relation detection, it is necessary
to consider both NEs that easily become subjects,
such as person and organization, and NEs that do not
easily become subjects, such as location and time.
We use the stack described in Section 2.3 as a
structural feature for relation detection. We call this
feature Centering Structure (CS). For example, the
stacked information shown in Figure 1 is assumed
to be structure information, as shown in Figure 2.
The method of converting from a stack (Figure 1)
into a structure (Figure 2) is described as follows.
First, the following NE, ?amerika32?, becomes the
root node because Figure 1 is stacked information
until the following NE appears. Then, the stacked
information is converted to Figure 2 depending on
the case markers. We use the path of the given pair
of NEs in the structure as a feature. For example,
?amerika32 ? wa:Ken22?2 is used as the feature of
the given pair ?Ken22? and ?amerika32?.
2.5 Classification Algorithm
There are several structure-based learning algo-
rithms proposed so far (Collins and Duffy, 2001;
Suzuki et al, 2003; Kudo and Matsumoto, 2004).
The experiments tested Kudo and Matsumoto?s
boosting-based algorithm using sub trees as features,
which is implemented as the BACT system.
In relation detection, given a set of training exam-
ples each of which represents contextual, syntactic,
and word-based features of a pair of NEs as a tree
labeled as either having semantic relations or not,
the BACT system learns that a set of rules are ef-
fective in classifying. Then, given a test instance,
which represents contextual, syntactic, and word-
2
?A? B? means A has a dependency relation to B.
Type % of pairs with semantic relations
(A) Intra-sentential 31.4% (3333 / 10626)
(B) Inter-sentential 0.8% (1777 / 225516)
(A)+(B) Total 2.2% (5110 / 236142)
Table 1: Percent of pairs with semantic relations in
annotated text
based features of a pair of NEs as a tree, the BACT
system classifies using a set of learned rules.
3 Experiments
We experimented with texts from Japanese newspa-
pers and weblogs to test the proposed method. The
following four models were compared:
1. WD : Pairs of NEs within n words are detected
as pairs with semantic relation.
2. STR : Supervised learning method using syn-
tactic3 and word-based features, the path of the
pairs of NEs in the parse tree and the word n-
gram between pairs of NEs (Kambhatla, 2004)
3. STR-CT : STR with the centering top feature
explained in Section 2.3.
4. STR-CS : STR with the centering structure fea-
ture explained in Section 2.4.
3.1 Setting
We used 1451 texts from Japanese newspapers and
weblogs, whose semantic relations between person
and location had been annotated by humans for the
experiments4. There were 5110 pairs with seman-
tic relations out of 236,142 pairs in the annotated
text. We conducted ten-fold cross-validation over
236,142 pairs of NEs so that sets of pairs from a
single text were not divided into the training and test
sets.
We also divided pairs of NEs into two types: (A)
intra-sentential and (B) inter-sentential. The reason
for dividing them is so that syntactic structure fea-
tures would be effective in type (A) and contextual
features would be effective in type (B). Another rea-
son is that the percentage of pairs with semantic rela-
tions out of the total pairs in the annotated text differ
significantly between types, as shown in Table 1.
In the experiments, all features were automati-
cally acquired using a Japanese morphological and
dependency structure analyzer.
3There is no syntactic feature in inter-sentential.
4We are planning to evaluate the other pairs of NEs.
159
(A)+(B) Total (A) Intra-sentential (B) Inter-sentential
Precision Recall Precision Recall Precsion Recall
WD10 43.0(2501/5819) 48.9(2501/5110) 48.1(2441/5075) 73.2(2441/3333) 8.0(60/744) 3.4(60/1777)
STR 69.3(2562/3696) 50.1(2562/5110) 75.6(2374/3141) 71.2(2374/3333) 33.9(188/555) 10.6(188/1777)
STR-CT 71.4(2764/3870) 54.1(2764/5110) 78.4(2519/3212) 75.6(2519/3333) 37.2(245/658) 13.8(245/1777)
STR-CS 73.7(2902/3935) 56.8(2902/5110) 80.1(2554/3187) 76.6(2554/3333) 46.5(348/748) 27.6(348/1777)
WD10: NE pairs that appear within 10 words are detected.
Table 2: Results for Relation Detection
0
0.2
0.4
0.6
0.8
1
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
P
r
e
c
i
s
i
o
n
WD
STR
STR-CT
STR-CS
STR-CS
STR
WD
STR-CT
Figure 3: Recall-precision Curves: (A)+(B) total
3.2 Results
To improve relation detection performance, we in-
vestigated the effect of the proposed method using
contextual features. Table 2 shows results for Type
(A), Type (B), and (A)+(B). We also plotted recall-
precision curves5, altering threshold parameters, as
shown in Figure 3.
The comparison between STR and STR-CT and
between STR and STR-CS in Figure 3 indicates that
the proposed method effectively contributed to rela-
tion detection. In addition, the results for Type (A):
intra-sentential, and (B): inter-sentential, in Table
2 indicate that the proposed method contributed to
both Type (A), improving precision by about 4.5%
and recall by about 5.4% and Type (B), improving
precision by about 12.6% and recall by about 17.0%.
3.3 Error Analysis
Over 70% of the errors are covered by two major
problems left in relation detection.
Parallel sentence: The proposed method solves
problems, which result from when a parallel
sentence arises from predication ellipsis. How-
ever, there are several types of parallel sentence
that differ from the one we explained. (For ex-
ample, Ken and Tom was born in Osaka and
New York, respectively.)
5Precision = # of correctly detected pairs / # of detected pairs
Recall = # of correctly detected pairs / # of pairs with semantic
relations
Definite anaphora: Definite noun phrase, such as
?Shusho (the Prime Minister)? and ?Shacho
(the President)?, can be anaphors. We should
consider them in centering theory, but it is dif-
ficult to find them in Japanese .
4 Conclusion
In this paper, we propose a supervised learning
method using words, syntactic structures, and con-
textual features based on centering theory, to im-
prove both inter-sentential and inter-sentential rela-
tion detection. The experiments demonstrated that
the proposed method increased precision by 4.4%,
up to 73.7%, and increased recall by 6.7%, up to
56.8%, and thus contributed to relation detection.
In future work, we plan to solve the problems re-
lating to parallel sentence and definite anaphora, and
address the task of relation characterization.
References
M. Collins and N. Duffy. 2001. Convolution Kernels for
Natural Language. Proceedings of the Neural Information
Processing Systems, pages 625?632.
A. Culotta and J. Sorensen. 2004. Dependency Tree Kernels
for Relation Extraction. Annual Meeting of Association of
Computational Linguistics, pages 423?429.
B. J. Grosz, A. K. Joshi, and S. Weistein. 1983. Providing a
unified account of definite nounphrases in discourse. Annual
Meeting of Association of Computational Linguistics, pages
44?50.
N. Kambhatla. 2004. Combining Lexical, Syntactic, and Se-
mantic Features with Maximum Entropy Models for Infor-
mation Extraction. Annual Meeting of Association of Com-
putational Linguistics, pages 178?181.
M. Kameyama. 1986. A property-sharing constraint in center-
ing. Annual Meeting of Association of Computational Lin-
guistics, pages 200?206.
T. Kudo and Y. Matsumoto. 2004. A boosting algorithm for
classification of semi-structured text. In Proceedings of the
2004 EMNLP, pages 301?308.
J. Suzuki, T. Hirao, Y. Sasaki, and E. Maeda. 2003. Hier-
archical directed acyclic graph kernel : Methods for struc-
tured natural language data. Annual Meeting of Association
of Computational Linguistics, pages 32?39.
D. Zelenko, C. Aone, and A. Richardella. 2003. Kernel Meth-
ods for Relation Extraction. Journal of Machine Learning
Research, pages 3:1083?1106.
160
Coling 2010: Poster Volume, pages 409?417,
Beijing, August 2010
Recognizing Relation Expression between Named Entities based on
Inherent and Context-dependent Features of Relational words
Toru Hirano?, Hisako Asano?, Yoshihiro Matsuo?, Genichiro Kikui?
?NTT Cyber Space Laboratories, NTT Corporation
?Innovative IP Architecture Center, NTT Communications Corporation
hirano.tohru@lab.ntt.co.jp
hisako.asano@ntt.com
{matsuo.yoshihiro,kikui.genichiro}@lab.ntt.co.jp
Abstract
This paper proposes a supervised learn-
ing method to recognize expressions that
show a relation between two named en-
tities, e.g., person, location, or organiza-
tion. The method uses two novel fea-
tures, 1) whether the candidate words in-
herently express relations and 2) how the
candidate words are influenced by the past
relations of two entities. These features
together with conventional syntactic and
contextual features are organized as a tree
structure and are fed into a boosting-based
classification algorithm. Experimental re-
sults show that the proposed method out-
performs conventional methods.
1 Introduction
Much attention has recently been devoted to us-
ing enormous amount of web text covering an ex-
ceedingly wide range of domains as a huge knowl-
edge resource with computers. To use web texts as
knowledge resources, we need to extract informa-
tion from texts that are merely sequences of words
and convert them into a structured form. Although
extracting information from texts as a structured
form is difficult, relation extraction is a way that
makes it possible to use web texts as knowledge
resources.
The aim of relation extraction is to extract se-
mantically related named entity pairs, X and Y ,
and their relation, R, from a text as a struc-
tured form [X , Y , R]. For example, the triple
[Yukio Hatoyama, Japan, prime minister] would
be extracted from the text ?Yukio Hatoyama is the
prime minister of Japan?. This extracted triple
provides important information used in informa-
tion retrieval (Zhu et al, 2009) and building an
ontology (Wong et al, 2010).
It is possible to say that all named entity pairs
that co-occur within a text are semantically related
in some way. However, we define that named en-
tity pairs are semantically related if they satisfy
either of the following rules:
? One entity is an attribute value of the other.
? Both entities are arguments of a predicate.
Following the above definition, explicit and im-
plicit relations should be extracted. An explicit re-
lation means that there is an expression that shows
the relation between a named entity pair in a given
text, while an implicit relation means that there is
no such expression. For example, the triple [Yukio
Hatoyama, Kunio Hatoyama, brother] extracted
from the text ?Yukio Hatoyama, the Democratic
Party, is Kunio Hatoyama?s brother? is an explicit
relation. In contrast, the triple [Yukio Hatoyama,
the Democratic Party, member] extracted from the
same text is an implicit relation because there is
no expression showing the relation (e.g. member)
between ?Yukio Hatoyama? and ?the Democratic
Party? in the text.
Extracting triples [X , Y , R] from a text in-
volves two tasks. One is detecting semantically
related pairs from named entity pairs that co-occur
in a text and the other is determining the rela-
tion between a detected pair. For the former task,
various supervised learning methods (Culotta and
Sorensen, 2004; Zelenko et al, 2003; Hirano et
al., 2007) and bootstrapping methods (Brin, 1998;
Pantel and Pennacchiotti, 2006) have been ex-
plored to date. In contrast, for the latter task,
409
only a few methods have been proposed so far
(Hasegawa et al, 2004; Banko and Etzioni, 2008;
Zhu et al, 2009). We therefore addressed the
problem of how to determine relations between a
given pair.
We used a three-step approach to address this
problem. The first step is to recognize an expres-
sion that shows explicit relations between a given
named entity pair in a text. If no such expression
is recognized, the second step is to estimate the
relationship that exists between a given named en-
tity pair that has an implicit relation. The last step
is to identify synonyms of the relations that are
recognized or estimated in the above steps. In this
paper, we focus on the first step. The task is se-
lecting a phrase from the text that contains a re-
lation expression linking a given entity pair and
outputting the expression as one showing the rela-
tionship between the pair.
In our preliminary experiment, it was found
that using only structural features of a text, such
as syntactic or contextual features, is not good
enough for a number of examples. For instance,
the two Japanese sentences shown in Figure 1
have the same syntactic structure but (a) contains a
relation expression and (b) does not. We therefore
assume there are clues for recognizing relation
expressions other than conventional syntactic and
contextual information. In this paper, we propose
a supervised learning method that includes two
novel features of relational words as well as con-
ventional syntactic and contextual features. The
novel features of our method are:
Inherent Feature: Some words are able to ex-
press the relations between named entities
and some are not. Thus, it would be useful to
know the words that inherently express these
relations.
Context-dependent Feature: There are a num-
ber of typical relationships that change as
time passes, such as ?dating? ? ?engage-
ment? ? ?marriage? between persons. Fur-
thermore, present relations are influenced by
the past relations of a given named entity
pair. Thus, it would be useful to know the
past relations between a given pair and how
the relations change as time passes.
In the rest of this paper, Section 2 references re-
lated work, Section 3 outlines our method?s main
features and related topics, Section 4 describes our
experiments and experimental results, and Section
5 briefly summarizes key points and future work
to be done.
2 Related Work
The ?Message Understanding Conference? and
?Automatic Content Extraction? programs have
promoted relational extraction. The task was stud-
ied so as to extract predefined semantic relations
of entity pairs in a text. Examples include the
supervised learning method cited in (Kambhatla,
2004; Culotta and Sorensen, 2004; Zelenko et al,
2003) and the bootstrapping method cited in (Pan-
tel and Pennacchiotti, 2006; Agichtein and Gra-
vano, 2000). Recently, open information extrac-
tion (Open IE), a novel domain-independent ex-
traction paradigm, has been suggested (Banko and
Etzioni, 2008; Hasegawa et al, 2004). The task is
to detect semantically related named entity pairs
and to recognize the relation between them with-
out using predefined relations.
Our work is a kind of open IE, but our approach
differs from that of previous studies. Banko
(2008) proposed a supervised learning method us-
ing conditional random fields to recognize the re-
lation expressions from words located between a
given pair. Hasegawa (2004) also proposed a rule-
based method that selects all words located be-
tween a given pair as a relation expression if a
given named entities appear within ten words. The
point of these work is that they selected relation
expressions only from the words located between
Osaka Fucho
01
-nosaka ucho
01
-noKacho02-noacho02-no
Yumei
04
-desu.u ei
04
-desu.Suzuki
03
-san-wauzuki
03
-san- a
D
DD
Osaka Fucho
05
-nosaka ucho
05
-noSoumukyoku06-noou ukyoku06-no
Yumei
08
-desu.u ei
08
-desu.Suzuki
07
-san-wauzuki
07
-san- a
D
DD
(a)Mr.Suzuki
03
, a manager
02
of Osaka Prefectural Government
01
, is famous
04
.(b)Mr.Suzuki
07
, administration office
06
in Osaka PrefecturalGovernment
05
, is famous
08
.
(a) (b)
Figure 1: Same syntactic examples
410
given entities in the text, because as far as English
texts are concerned, 86% of the relation expres-
sions of named entity pairs appear between the
pair (Banko and Etzioni, 2008). However, our tar-
get is Japanese texts, in which only 26% of entity
pair relation expressions appear between the pair.
Thus, it is hard to incorporate previous approaches
into a Japanese text.
To solve the problem, our task was to select a
phrase from the entire text that would include a
relation expression for connecting a given pair.
3 Recognizing Relation Expressions
between Named Entities
To recognize the relation expression for a given
pair, we need to select a phrase that includes an
expression that shows the relation between a given
entity pair from among all noun and verb phrases
in a text. Actually, there are two types of candi-
date phrases in this case. One is from a sentence
that contains a given pair (intra-sentential), and
the other is from a sentence that does not (inter-
sentential). For example, the triple [Miyaji21,
Ishii22, taiketsu12] extracted from the following
text is inter-sentential.
(S-1) Chumokoku11-no taiketsu12-ga
mamonaku13 hajimaru14.
(The showcase11 match12 will start14 soon13.)
(S-2) Ano Miyaji21-to Ishii22-toiu
kanemochi23-niyoru yume24-no
kikaku25.
(The dream24 event25 between the rich mens23,
Miyaji21 and Ishii22.)
According to our annotated data shown in Ta-
ble 2, 53% of the semantically-related named en-
tity pairs are intra-sentential and 12% are inter-
sentential. Thus, we first select a phrase from
those in a sentence that contains a given pair, and
if no phrase is selected, select one from the rest of
the sentences in a text.
We propose a supervised learning method that
uses two novel features of relational words as
well as conventional syntactic and contextual fea-
tures. These features are organized as a tree struc-
ture and are fed into a boosting-based classifica-
tion algorithm (Kudo and Matsumoto, 2004). The
highest-scoring phrase is then selected if the score
exceeds a given threshold. Finally, the head of the
selected phrase is output as the relation expression
of a given entity pair.
The method consists of four parts: preprocess-
ing (POS tagging and parsing), feature extraction,
classification, and selection. In this section, we
describe the idea behind using our two novel fea-
tures and how they are implemented to recognize
the relation expressions of given pairs. Before
that, we will describe our proposed method?s con-
ventional features.
3.1 Conventional Features
Syntactic feature
To recognize the intra-sentential relation ex-
pressions for a given pair, we assume that there
is a discriminative syntactic structure that consists
of given entities and their relation expression. For
example, there is a structure for which the com-
mon parent phrase of the given pair, X = ?Ha-
toyama Yukio32? and Y = ?Hatoyama Kunio33?,
has the relation expression, R = ?ani34? in the
Japanese sentence S-3. Figure 2 shows the depen-
dency tree of sentence S-3.
(S-3) Minshuto31-no Hatoyama Yukio32-wa
Hatoyama Kunio33-no ani34-desu.
(Yukio Hatoyama32, the Democratic Party31,
is Kunio Hatoyama33?s brother34.)
To use a discriminative structure for each can-
didate, we make a minimum tree that consists of
given entities and the candidate where each phrase
is represented by a case marker ?CM?, a depen-
dency type ?DT?, an entity class, and the string
and POS of the candidate (See Figure 3).
Minshuto
31
-noinshuto
31
-no
Hatoyama Yukio
32
-waatoya a ukio
32
- a
Ani
34
-desu.ni
34
-desu.
Hatoyama Kunio
33
-noatoya a unio
33
-noD
D D
Figure 2: Dependency tree of sentence S-3
411
X:person:person
Phrasehrase
PhrasehraseCandidateandidatePhrasehrase
Y:person:person
CM:wa: a DT:D:
STR:Ani
34
: ni
34
POS:Noun: ounCM:?: DT:O:CM:no:no DT:D: Inh:1Inh:1C
rank
:1
rank
:1C
prob
:0.23
prob
:0.23
Figure 3: Intra-sentential feature tree
Contextual Feature
To recognize the inter-sentential relation ex-
pressions for a given pair, we assume that there
is a discriminative contextual structure that con-
sists of given entities and their relation expression.
Here, we use a Salient Referent List (SRL) to ob-
tain contextual structure. The SRL is an empirical
sorting rule proposed to identify the antecedent
of (zero) pronouns (Nariyama, 2002), and Hirano
(2007) proposed a way of applying SRL to rela-
tion detection. In this work, we use this way to
apply SRL to recognize inter-sentential relation
expressions.
We applied SRL to each candidate as follows.
First, from among given entities and the candi-
date, we choose the one appearing last in the text
as the root of the tree. We then append noun
phrases, from the chosen one to the beginning of
the text, to the tree depending on case markers,
?wa? (topicalised subject), ?ga? (subject), ?ni?
(indirect object),?wo? (object), and ?others?, with
the following rules. If there are nodes of the same
case marker already in the tree, the noun phrase
is appended as a child of the leaf node of them.
In other cases, the noun phrase is appended as a
child of the root node. For example, we get the
SRL tree shown in Figure 4 with the given entity
pair, X = ?Miyaji21? and Y = ?Ishii22?, and the
candidate, ?taiketsu12?, with the text (S-1, S-2).
To use a discriminative SRL structure, we make
a minimum tree that consists of given entities and
the candidate where each phrase is represented by
an entity class, and the string and POS of the can-
didate (See Figure 5). In this way, there is a prob-
lem when the candidate is a verb phrase, because
ga: Taiketsu
12
ga: aiketsu
12
Ishii
22
Ishii
22
others: Miyaji
21
others: iyaji
21
others: Chumoku
11
others: hu oku
11
Figure 4: Salient referent list tree
only noun phrases are appended to the SRL tree.
If the candidate is a verb phrase, we cannot make
a minimum tree that consists of given entities and
the candidate.
To solve this problem, a candidate verb phrase
is appended to the feature tree using a syntactic
structure. In a dependency tree, almost all verb
phrases have some parent or child noun phrases
that are in the SRL tree. Thus, candidate verb
phrases are appended as offspring of these noun
phrases represented syntactically as ?parent? or
?child?. For example, when given the entity pair,
X = ?Miyaji21? and Y = ?Ishii22?, and the can-
didate, ?hajimaru14? from the text (S-1, S-2), a
feature tree cannot be made because the candi-
date is not in an SRL tree. By extending the way
the syntactic structure is used, ?hajimaru14? has a
child node ?taiketsu12?, which is in an SRL tree,
and this makes it possible to make the feature tree
shown in Figure 6.
3.2 Proposed Features
To recognize intra-sentential or inter-sentential re-
lation expressions for given pairs, we assume
there are clues other than syntactic and contex-
tual information. Thus, we propose inherent and
SRL:gaL:ga Candidateandidate
Y:person:person
X:person:personSRL:othersL:othersSTR:Taiketsu
12
: aiketsu
12
POS:Noun: ounInh:1Inh:1 C
rank
:1
rank
:1 C
prob
:0.23
prob
:0.23
Figure 5: Inter-sentential feature tree
412
SRL:gaL:ga
Dep:Childep: hild Candidateandidate
Y:person:person X:person:personSRL:othersL:othersSTR:Hajimaru
14
: aji aru
14
POS:Verb: erbInh:0Inh:0 C
rank
:2
rank
:2 C
prob
:0.00
prob
:0.00
Figure 6: Extended inter-sentential feature tree
context-dependent features of relational words.
Inherent Feature of Relational words
Some words are able to express the relations be-
tween named entities and some are not. For exam-
ple, the word ?mother? can express a relation, but
the word ?car? cannot. If there were a list of words
that could express relations between named enti-
ties, it would be useful to recognize the relation
expression of a given pair. As far as we know,
however, no such list exists in Japanese. Thus,
we estimate which words are able to express rela-
tions between entities. Here, we assume that al-
most all verbs are able to express relations, and
accordingly we focus on nouns.
When the relation expression, R, of an entity
pair, X and Y , is a noun, it is possible to say ?Y is
R of X? or ?Y is X?s R?. Here, we can say noun
R takes an argument X . In linguistics, this kind
of noun is called a relational noun. Grammatically
speaking, a relational noun is a simple noun, but
because its meaning describes a ?relation? rather
than a ?thing?, it is used to describe relations just
as prepositions do. To estimate which nouns are
able to express the relations between named enti-
ties, we use the characteristics of relational nouns.
In linguistics, many researchers describe the rela-
tionship between possessives and relational nouns
(Chris, 2008). Thus, we use the knowledge that
in the patterns ?B of A? or ?A?s B?, if word B is
a relational noun, the corresponding word A be-
longs to a certain semantic category. In contrast,
if word B is not a relational noun, the correspond-
ing word A belongs to many semantic categories
(Tanaka et al, 1999). Figure 7 shows scattering
of the semantic categories of ?mother? and ?car?
Semantic categoriesRelative
 Frequency
Semantic categoriesRelative
 Frequency
Figure 7: Scattering of semantic category of
?mother? (left) and ?car? (right).
acquired by the following way.
First, we acquired A and B using the patterns
?A no B?1 from a large Japanese corpus, then
mapped words A into semantic categories C= {
c1, c2, ? ? ? , cm } using a Japanese lexicon (Ikehara
et al, 1999). Next, for each word B, we calcu-
lated a scattering score Hc(B) using the semantic
category of corresponding words A. Finally, we
estimated whether a word is a relational noun by
using k-NN estimation with positive and negative
examples. As estimated results, ?Inh:1? shows
that it is a relational noun and ?Inh:0? shows that
it is not. In both cases, the result is appended to
the feature tree as a child of the candidate node
(See Figure 3, 5, or 6).
Hc(B) = ?
?
c?C
P (c|B)logmP (c|B)
P (c|B) = freq(c,B)freq(B)
In our experiments, we acquired 55,412,811
pairs of A and B from 1,698,798 newspaper ar-
ticles and 10,499,468 weblog texts. As training
data, we used the words of relation expressions as
positive examples and other words as negative ex-
amples.
Context-dependent Feature of Relational
words
There are a number of typical relationships that
change as time passes, such as ?dating? ? ?en-
gagement? ? ?marriage? between persons. Fur-
thermore, present relations are affected by the past
relations of a given named entity pair. For in-
stance, if the past relations of a given pair are ?dat-
ing? and ?engagement? and one of the candidates
is ?marriage?, ?marriage? would be selected as the
relation expression of the given pair. Therefore, if
1
?B of A? or ?A?s B? in English.
413
Pair of entity class rm rn PT (rn|rm) Count(rm, rn)
dating 0.050 102
?person,person? dating marriage 0.050 101
engagement 0.040 82
marriage 0.157 786
?person,person? engagement engagement 0.065 325
wedding 0.055 276
president 0.337 17,081
?person,organization? vice president vice president 0.316 16,056
CEO 0.095 4,798
fellow 0.526 61
?person,organization? researcher manager 0.103 12
member 0.078 9
alliance 0.058 8,358
?organization,organization? alliance accommodated 0.027 3,958
acquisition 0.027 3,863
mutual consultation 0.022 2,670
?location,location? neighbour support 0.015 1,792
visit 0.012 1,492
war 0.077 78,170
?location,location? war mutual consultation 0.015 15,337
support 0.010 10,226
Table 1: Examples of calculated relation trigger model between entity classes defined by IREX
we know the past relations of the given pair and
the typical relational change that occurs as time
passes, it would be useful to recognize the rela-
tion expression of a given pair.
In this paper, we represent typical relational
changes that occur as time passes by a simple re-
lation trigger model PT (rn|rm). Note that rm
is a past relation and rn is a relation affected by
rm. This model disregards the span between rn
and rm. To make the trigger model, we automat-
ically extract triples [X , Y , R] from newspaper
articles and weblog texts, which have time stamps
of the document creation. Using these triples with
time stamps for each entity pair, we sort rela-
tions in order of time and count pairs of present
and previous relations. For example, if we ex-
tract ?dating? occurring for an entity pair on Jan-
uary 10, 1998, ?engagement? occurring on Febru-
ary 15, 2001, and ?marriage? occurring on De-
cember 24, 2001, the pairs ?dating, engagement?,
?dating, marriage?, and ?engagement, marriage?
are counted. The counted score is then summed
up by the pair of entity class and the trigger model
is calculated by the following formula.
PT (rn|rm) =
Count(rm, rn)?
rn Count(rm, rn)
For the evaluation, we extracted triples by
named entity recognition (Suzuki et al, 2006), re-
lation detection (Hirano et al, 2007), and the pro-
posed method using the inherent features of rela-
tional words described in Section 3.2. A total of
10,463,232 triples were extracted from 8,320,042
newspaper articles and weblog texts with time
stamps made between January 1, 1991 and June
30, 2006. As examples of the calculated relation
trigger model, Table 1 shows the top three proba-
bility relations rn of several relations rm between
Japanese standard named entity classes defined
in the IREX workshop2. For instance, the rela-
tion ?fellow? has the highest probability of being
changed from the relation ?researcher? between
person and organization as time passes.
2http://nlp.cs.nyu.edu/irex/
414
To obtain the past relations of a given pair in
the input text, we again used the triples with time
stamps extracted as above. The only relations we
use as past relations, Rm = {rm1 , rm2 , ? ? ? , rmk},
are those of a given pair whose time stamps are
older than the input text. Finally, we calcu-
lated probabilities with the following formula us-
ing the past relations Rm and the trigger model
PT (rn|rm).
PT (rn|Rm) = max{PT (rn|rm1),
PT (rn|rm2), ? ? ? , PT (rn|rmk)}
Using this calculated probability, we ranked
candidates and appended the rank ?Crank? and
the probability score ?Cprob? to the feature tree
as a child of the candidate node (See Figure 3,
5, or 6). For example, if the past relations Rm
were ?dating? and ?engagement? and candidates
were ?marriage?, ?meeting?, ?eating?, or ?drink-
ing?, the candidates probabilities were calculated
and ranked as ?marriage? (Cprob:0.15, Crank:1),
?meeting? (Cprob:0.08, Crank:2), etc.
3.3 Classification Algorithms
Several structure-based learning algorithms have
been proposed so far (Collins and Duffy, 2002;
Suzuki et al, 2003; Kudo and Matsumoto, 2004).
The experiments tested Kudo and Matsumoto?s
boosting-based algorithm using sub-trees as fea-
tures, which is implemented as a BACT system.
Given a set of training examples each of which
is represented as a tree labeling whether the can-
didate is the relation expression of a given pair or
not, the BACT system learns that a set of rules
is effective in classifying. Then, given a test in-
stance, the BACT system classifies using a set of
learned rules.
4 Experiments
We conducted experiments using texts from
Japanese newspaper articles and weblog texts to
test the proposed method for both intra- and inter-
sentential tasks. In the experiments, we compared
the following methods:
Conventional Features: trained by conventional
syntactic features for intra-sentential tasks as
Relation Types #
Explicit Intra-sentential 9,178Inter-sentential 2,058
Implicit 5,992
Total 17,228
Table 2: Details of the annotated data
described in Section 3.1, and contextual fea-
tures for inter-sentential tasks as described in
Section 3.1.
+Inherent Features: trained by conventional
features plus inherent features of relational
words described in Section 3.2.
++Context-dependent FeaturesTM: trained
by conventional and inherent features plus
context-dependent features of relational
words with the trigger model described in
Section 3.2.
++Context-dependent FeaturesCM: trained
by conventional and inherent features
plus context-dependent features of rela-
tional words with a cache model. We
evaluated this method to compare it with
Context-dependent FeaturesTM to show the
effectiveness of the proposed trigger model.
The cache model is a simple way to use past
relations in which the probability PC(rcand)
calculated by the following formula and the
rank based on the probability is appended to
every candidate feature tree.
PC(rcand) =
|rcand in past relations|
|past relations|
4.1 Settings
We used 6,200 texts from Japanese newspapers
and weblogs dated from January 1, 2004 to June
30, 2006, manually annotating the semantic rela-
tions between named entities for experiment pur-
poses. There were 17,228 semantically-related
entity pairs as shown in Table 2. In an intra-
sentential experiment, 17,228 entity pairs were
given, but only 9,178 of them had relation expres-
sions. In contrast, in an inter-sentential experi-
ment, 8,050 entity pairs excepted intra-sentential
415
Precision Recall F
Conventional Features 63.5? (3,436/5,411) 37.4? (3,436/9,178) 0.471
+Inherent Features 67.2? (4,036/6,001) 43.9? (4,036/9,178) 0.531
++Context-dependent FeaturesTM 70.7? (4,460/6,312) 48.6? (4,460/9,178) 0.576
++Context-dependent FeaturesCM 67.5? (4,042/5,987) 44.0? (4,042/9,178) 0.533
Table 3: Experimental results of intra-sentential
Precision Recall F
Conventional Features 70.1? (579/825) 28.1? (579/2,058) 0.401
+Inherent Features 77.1? (719/932) 34.9? (719/2,058) 0.480
++Context-dependent FeaturesTM 75.2? (794/1,055) 38.5? (794/2,058) 0.510
++Context-dependent FeaturesCM 74.3? (732/985) 35.5? (732/2,058) 0.481
Table 4: Experimental result of inter-sentential
were given, but only 2,058 of them had relation
expressions.
We conducted five-fold cross-validation over
17,228 entity pairs so that sets of pairs from a sin-
gle text were not divided into the training and test
sets. In the experiments, all features were auto-
matically acquired using a Japanese POS tagger
(Fuchi and Takagi, 1998) and dependency parser
(Imamura et al, 2007).
4.2 Results
Tables 3 and 4 show the performance of several
methods for intra-sentential and inter-sentential.
Precision is defined as the percentage of cor-
rect relation expressions out of recognized ones.
Recall is the percentage of correct relation ex-
pressions from among the manually annotated
ones. The F measure is the harmonic mean of
precision and recall.
A comparison with the Conventional Fea-
tures and Inherent Features method for intra-
/inter-sentential tasks indicates that the proposed
method using inherent features of relational words
improved intra-sentential tasks F by 0.06 points
and inter-sentential tasks F by 0.08 points. Us-
ing a statistical test (McNemar Test) demonstrably
showed the proposed method?s effectiveness.
A comparison with the Inherent Features and
Context-dependent FeaturesTM method showed
that the proposed method using context-dependent
features of relational words improved intra-/inter-
sentential task performance by 0.045 and 0.03
points, respectively. McNemar test results also
showed the method?s effectiveness.
To further compare the usage of context-
dependent features, trigger models, and cache
models, we also used Context-dependent
FeaturesCM method for comparison. Tables
3 and 4 show that our proposed trigger model
performed better than the cache model, and
McNemar test results showed that there was a
significant difference between the models. The
reason the trigger model performed better than
the cache model is that the trigger model correctly
recognized the relation expressions that did not
appear in the past relations of a given pair. Thus,
we can conclude that using typical relationships
that change as time passes helps to recognize
relation expressions between named entities.
5 Conclusion
We proposed a supervised learning method that
employs inherent and context-dependent features
of relational words and uses conventional syntac-
tic or contextual features to improve both intra-
and inter-sentential relation expression recogni-
tion. Our experiments demonstrated that the
method improves the F measure and thus helps
to recognize relation expressions between named
entities.
In future work, we plan to estimate implicit re-
lations between named entities and to identify re-
lational synonyms.
416
References
Agichtein, Eugene and Luis Gravano. 2000. Snow-
ball: Extracting relations from large plain-text col-
lections. In Proceedings of the 5th ACM conference
on Digital libraries, pages 85?94.
Banko, Michele and Oren Etzioni. 2008. The tradeoffs
between open and traditional relation extraction. In
Proceedings of the 46th Annual Meeting on Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, pages 28?36.
Brin, Sergey. 1998. Extracting patterns and rela-
tions from the world wide web. In WebDB Work-
shop at 6th International Conference on Extending
Database Technology, pages 172?183.
Chris, Barker, 2008. Semantics: An international
handbook of natural language meaning, chap-
ter Possessives and relational nouns. Walter De
Gruyter Inc.
Collins, Michael and Nigel Duffy. 2002. Convolution
kernels for natural language. Advances in Neural
Information Processing Systems, 14:625?632.
Culotta, Aron and Jeffrey Sorensen. 2004. Depen-
dency tree kernels for relation extraction. In Pro-
ceedings of the 42nd Annual Meeting on Association
for Computational Linguistics, pages 423?429.
Fuchi, Takeshi and Shinichiro Takagi. 1998. Japanese
morphological analyzer using word co-occurrence
- jtag. In Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Compu-
tational Linguistics, volume 1, pages 409?413.
Hasegawa, Takaaki, Satoshi Sekine, and Ralph Grish-
man. 2004. Discovering relations among named
entities from large corpora. In Proceedings of the
42nd Annual Meeting on Association for Computa-
tional Linguistics, pages 415?422.
Hirano, Toru, Yoshihiro Matsuo, and Genichiro Kikui.
2007. Detecting semantic relations between named
entities in text using contextual features. In Pro-
ceedings of the 45th Annual Meeting on Association
for Computational Linguistics, pages 157?160.
Ikehara, Satoru, Masahiro Miyazaki, Satoru Shirai,
Akio Yoko, Hiromi Nakaiwa, Kentaro Ogura, Masa-
fumi Oyama, and Yoshihiko Hayashi. 1999. Ni-
hongo Goi Taikei (in Japanese). Iwanami Shoten.
Imamura, Kenji, Genichiro Kikui, and Norihito Ya-
suda. 2007. Japanese dependency parsing using se-
quential labeling for semi-spoken language. In Pro-
ceedings of the 45th Annual Meeting on Association
for Computational Linguistics, pages 225?228.
Kambhatla, Nanda. 2004. Combining lexical, syntac-
tic, and semantic features with maximum entropy
models for extracting relations. In Proceedings of
the 42nd Annual Meeting on Association for Com-
putational Linguistics, pages 178?181.
Kudo, Taku and Yuji Matsumoto. 2004. A boosting
algorithm for classification of semi-structured text.
In Proceedings of the 2004 Conference on Empiri-
cal Methods in Natural Language Processing, pages
301?308.
Nariyama, Shigeko. 2002. Grammar for ellipsis res-
olution in japanese. In Proceedings of the 9th In-
ternational Conference on Theoretical and Method-
ological Issues in Machine Translation, pages 135?
145.
Pantel, Patrick and Marco Pennacchiotti. 2006.
Espresso: Leveraging generic patterns for automat-
ically harvesting semantic relations. In Proceed-
ings of the 21st International Conference on Com-
putational Linguistics and the 44th annual meeting
of the Association for Computational Linguistics,
pages 113?120.
Suzuki, Jun, Tsutomu Hirao, Yutaka Sasaki, and
Eisaku Maeda. 2003. Hierarchical directed acyclic
graph kernel: Methods for structured natural lan-
guage data. In Proceedings of the 41st Annual
Meeting on Association for Computational Linguis-
tics, pages 32?39.
Suzuki, Jun, Erik McDermott, and HIdeki Isozaki.
2006. Training conditional random fields with mul-
tivariate evaluation measures. In Proceedings of the
43th Annual Meeting on Association for Computa-
tional Linguistics.
Tanaka, Shosaku, Yoichi Tomiura, and Toru Hitaka.
1999. Classification of syntactic categories of
nouns by the scattering of semantic categories (in
japanese). Transactions of Information Processing
Society of Japan, 40(9):3387?3396.
Wong, Wilson, Wei Liu, and Mohammed Bennamoun.
2010. Acquiring semantic relations using the web
for constructing lightweight ontologies. In Proceed-
ings of the 13th Pacific-Asia Conference on Knowl-
edge Discovery and Data Mining.
Zelenko, Dmitry, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation ex-
traction. Journal of Machine Learning Research,
3:1083?1106.
Zhu, Jun, Zaiqing Nie, Xiaojing Liu, Bo Zhang, and
Ji-Rong Wen. 2009. Statsnowball: a statistical ap-
proach to extracting entity relationships. In Pro-
ceedings of the 18th international conference on
World Wide Web, pages 101?110.
417
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 928?939, Dublin, Ireland, August 23-29 2014.
Towards an open-domain conversational system fully based on natural
language processing
Ryuichiro Higashinaka
1
, Kenji Imamura
1
, Toyomi Meguro
2
, Chiaki Miyazaki
1
Nozomi Kobayashi
1
, Hiroaki Sugiyama
2
, Toru Hirano
1
Toshiro Makino
1
, Yoshihiro Matsuo
1
1
NTT Media Intelligence Laboratories
2
NTT Communication Science Laboratories
{higashinaka.ryuichiro, imamura.kenji, meguro.toyomi, miyazaki.chiaki,
kobayashi.nozomi, sugiyama.hiroaki, hirano.tohru,
makino.toshiro, matsuo.yoshihiro}@lab.ntt.co.jp
Abstract
This paper proposes an architecture for an open-domain conversational system and evaluates an
implemented system. The proposed architecture is fully composed of modules based on natu-
ral language processing techniques. Experimental results using human subjects show that our
architecture achieves significantly better naturalness than a retrieval-based baseline and that its
naturalness is close to that of a rule-based system using 149K hand-crafted rules.
1 Introduction
Although task-oriented dialogue systems have been extensively researched over the decades (Walker
et al., 2001; Williams et al., 2013), it is only recently that non-task-oriented dialogue, open-domain
conversation, or chat has been attracting attention for its social and entertainment aspects (Bickmore
and Picard, 2005; Ritter et al., 2011; Bessho et al., 2012). Creating an open-domain conversational
system is a challenging problem. In task-oriented dialogue systems, it is possible to prepare knowledge
for a domain and create understanding and generation modules for that domain (Nakano et al., 2000).
However, for open-domain conversation, such preparation cannot be performed. Since it is difficult to
handle users? open-domain utterances, to create workable systems, conventional approaches have used
hand-crafted rules (Wallace, 2004). Although elaborate rules may work well, the problem with the rule-
based approach is the high cost and the dependence on individual skills of developers, which hinders
systematic development. Another problem with the rule-based approach is its low coverage; that is, the
inability to handle unexpected utterances.
The recent increase of web data has propelled the development of approaches that use data retrieved
from the web for open-domain conversation (Shibata et al., 2009; Ritter et al., 2011). The merit of such
retrieval-based approaches is that, owing to the diversity of the web, systems can retrieve at least some
responses for user input, which solves the coverage problem. However, this comes at the cost of utterance
quality. Since the web, especially Twitter, is inherently noisy, it is, in many cases, difficult to sift out
appropriate sentences from retrieval results.
In this paper, we propose an architecture for an open-domain conversational system. The proposed
architecture is fully composed of modules based on natural language processing (NLP) techniques. Our
stance is not just to hand-craft or to search the web for utterances, but to create a system that can fully
understand and generate utterances. We want to show that it is possible to build an open-domain conver-
sational system by combining NLP modules, which will open the way to a systematic development and
improvement. We describe our open-domain conversational system based on our architecture and present
results of an evaluation of its performance by human subjects. We compare our system with rule-based
and retrieval-based systems, and show that our architecture is a promising direction. In this work, we
regard the term open-domain conversation to be interchangeable with non-task-oriented dialogue, casual
conversation (Eggins and Slade, 2005), chat, or social dialogue (Bickmore and Cassell, 2000). We use
the term to denote that user input is not restricted in any way as in open-domain question answering
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
928
	
			
	

	
		
	

