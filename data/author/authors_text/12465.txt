Proceedings of the 12th European Workshop on Natural Language Generation, pages 126?129,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
A Situated Context Model for
Resolution and Generation of Referring Expressions
Hendrik Zender and Geert-Jan M. Kruijff and Ivana Kruijff-Korbayova?
Language Technology Lab, German Research Center for Artificial Intelligence (DFKI)
Saarbru?cken, Germany
{zender, gj, ivana.kruijff}@dfki.de
Abstract
The background for this paper is the aim
to build robotic assistants that can ?natu-
rally? interact with humans. One prereq-
uisite for this is that the robot can cor-
rectly identify objects or places a user
refers to, and produce comprehensible ref-
erences itself. As robots typically act
in environments that are larger than what
is immediately perceivable, the problem
arises how to identify the appropriate con-
text, against which to resolve or produce
a referring expression (RE). Existing al-
gorithms for generating REs generally by-
pass this problem by assuming a given
context. In this paper, we explicitly ad-
dress this problem, proposing a method for
context determination in large-scale space.
We show how it can be applied both for re-
solving and producing REs.
1 Introduction
The past years have seen an extraordinary increase
in research on robotic assistants that help users
perform daily chores. Autonomous vacuum clean-
ers have already found their way into people?s
homes, but it will still take a while before fully
conversational robot ?gophers? will assist people
in more demanding everyday tasks. Imagine a
robot that can deliver objects, and give directions
to visitors on a university campus. This robot must
be able to verbalize its knowledge in a way that is
understandable by humans.
A conversational robot will inevitably face sit-
uations in which it needs to refer to an entity (an
object, a locality, or even an event) that is located
somewhere outside the current scene, as Figure 1
illustrates. There are conceivably many ways in
which a robot might refer to things in the world,
but many such expressions are unsuitable in most
Where is the 
IT Help desk?
It is on the 
1st floor in 
building 3b.
it is at
<45.56, -3.92, 10.45>
Where i  the 
IT hel  desk?
It is on the 1st 
floor in building 
3B.
It is at
Figure 1: Situated dialogue with a service robot
human-robot dialogues. Consider the following
set of examples:
1. ?position P = ?45.56,?3.92, 10.45??
2. ?Peter?s office no. 200 at the end of the cor-
ridor on the third floor of the Acme Corp.
building 3 in the Acme Corp. complex, 47
Evergreen Terrace, Calisota, Earth, (...)?
3. ?the area?
These REs are valid descriptions of their respec-
tive referents. Still they fail to achieve their com-
municative goal, which is to specify the right
amount of information that the hearer needs to
uniquely identify the referent. The next REs might
serve as more appropriate variants of the previous
examples (in certain contexts! ):
1. ?the IT help desk?
2. ?Peter?s office?
3. ?the large hall on the first floor?
The first example highlights a requirement on the
knowledge representation to which an algorithm
for generating referring expressions (GRE) has ac-
cess. Although the robot needs a robot-centric rep-
resentation of its surrounding space that allows it
to safely perform actions and navigate its world,
it should use human-centric qualitative descrip-
tions when talking about things in the world. We
126
do not address this issue here, but refer the inter-
ested reader to our recent work on multi-layered
spatial maps for robots, bridging the gap between
robot-centric and human-centric spatial represen-
tations (Zender et al, 2008).
The other examples point out another impor-
tant consideration: howmuch information does the
human need to single out the intended referent
among the possible entities that the robot could be
referring to? According to the seminal work on
GRE by Dale and Reiter (1995), one needs to dis-
tinguish whether the intended referent is already
in the hearer?s focus of attention or not. This focus
of attention can consist of a local visual scene (vi-
sual context) or a shared workspace (spatial con-
text), but also contains recently mentioned entities
(dialogue context). If the referent is already part
of the current context, the GRE task merely con-
sists of singling it out among the other members
of the context, which act as distractors. In this
case the generated RE contains discriminatory in-
formation, e.g. ?the red ball? if several kinds of ob-
jects with different colors are in the context. If, on
the other hand, the referent is not in the hearer?s fo-
cus of attention, an RE needs to contain what Dale
and Reiter call navigational, or attention-directing
information. The example they give is ?the black
power supply in the equipment rack,? where ?the
equipment rack? is supposed to direct the hearers
attention to the rack and its contents.
In the following we propose an approach for
context determination and extension that allows a
mobile robot to produce and interpret REs to enti-
ties outside the current visual context.
2 Background
Most GRE approaches are applied to very lim-
ited, visual scenes ? so-called small-scale space.
The domain of such systems is usually a small vi-
sual scene, e.g. a number of objects, such as cups
and tables, located in the same room), or other
closed-context scenarios (Dale and Reiter, 1995;
Horacek, 1997; Krahmer and Theune, 2002). Re-
cently, Kelleher and Kruijff (2006) have presented
an incremental GRE algorithm for situated di-
alogue with a robot about a table-top setting,
i.e. also about small-scale space. In all these cases,
the context set is assumed to be identical to the
visual scene that is shared between the interlocu-
tors. The intended referent is thus already in the
hearer?s focus of attention.
In contrast, robots typically act in large-scale
space, i.e. space ?larger than what can be per-
ceived at once? (Kuipers, 1977). They need the
ability to understand and produce references to
things that are beyond the current visual and spa-
tial context. In any situated dialogue that involves
entities beyond the current focus of attention, the
task of extending the context becomes key.
Paraboni et al (2007) present an algorithm for
context determination in hierarchically ordered
domains, e.g. a university campus or a document
structure. Their approach is mainly targeted at
producing textual references to entities in written
documents (e.g. figures, tables in book chapters).
Consequently they do not address the challenges
that arise in physically and perceptually situated
dialogues. Still, the approach presents a num-
ber of good contributions towards GRE for situ-
ated dialogue in large-scale space. An appropriate
context, as a subset of the full domain, is deter-
mined through Ancestral Search. This search for
the intended referent is rooted in the ?position of
the speaker and the hearer in the domain? (repre-
sented as d), a crucial first step towards situated-
ness. Their approach suffers from the shortcom-
ing that spatial relationships are treated as one-
place attributes by their GRE algorithm. For ex-
ample they transform the spatial containment re-
lation that holds between a room entity and a
building entity (?the library in the Cockroft build-
ing?) into a property of the room entity (BUILDING
NAME = COCKROFT) and not a two-place relation
(in(library,Cockroft)). Thus they avoid
recursive calls to the algorithm, which would be
needed if the intended referent is related to another
entity that needs to be properly referred to.
However, according to Dale and Reiter (1995),
these related entities do not necessarily serve as
discriminatory information. At least in large-scale
space, in contrast to a document structure that is
conceivably transparent to a reader, they function
as attention-directing elements that are introduced
to build up common ground by incrementally ex-
tending the hearer?s focus of attention. Moreover,
representing some spatial relations as two-place
predicates between two entities and some as one-
place predicates is an arbitrary decision.
We present an approach for context determina-
tion (or extension), that imposes less restrictions
on its knowledge base, and which can be used as a
sub-routine in existing GRE algorithms.
127
3 Situated Dialogue in Large-Scale Space
Imagine the situation in Figure 1 did not take place
somewhere on campus, but rather inside building
3B. Certainly the robot would not have said ?the
IT help desk is on the 1st floor in building 3B.?
To avoid confusing the human, an utterance like
?the IT help desk is on the 1st floor? would have
been appropriate. Likewise, if the IT help desk
happened to be located on another site of the uni-
versity, the robot would have had to identify its lo-
cation as being ?on the 1st floor in building 3B on
the new campus.? The hierarchical representation
of space that people are known to assume (Cohn
and Hazarika, 2001), reflects upon the choice of
an appropriate context when producing REs.
In the above example the physical and spatial
situatedness of the dialogue participants play an
important role in determining which related parts
of space come into consideration as potential dis-
tractors. Another important observation concerns
the verbal behavior of humans when talking about
remote objects and places during a complex dia-
logue (i.e. more than just a question and a reply).
Consider the following example dialogue:
Person A: ?Where is the exit??
Person B: ?You first go down this corridor.
Then you turn right. After a few steps you
will see the big glass doors.?
Person A: ?And the bus station? Is it to the
left??
The dialogue illustrates how utterances become
grounded in previously introduced discourse ref-
erents, both temporally and spatially. Initially,
the physical surroundings of the dialogue partners
form the context for anchoring references. As a di-
alogue unfolds, this point can conceptually move
to other locations that have been explicitly intro-
duced. Discourse markers denoting spatial or tem-
poral cohesion (e.g. ?then? or ?there?) can make
this move to a new anchor explicit, leading to a
?mental tour? through large-scale space.
We propose a general principle of Topological
Abstraction (TA) for context extension which is
rooted in what we will call the Referential Anchor
a.1 TA is designed for a multiple abstraction hier-
archy (e.g. represented as a lattice structure rather
than a simple tree). The Referential Anchor a, cor-
responding to the current focus of attention, forms
the nucleus of the context. In the simple case, a
1similar to Ancestral Search (Paraboni et al, 2007)
loc1 loc2 loc3
room1 room2
floor1_1 floor1_2
building1
loc4 (a) loc5 loc7 loc8loc6
room3 room4 room5 (r)
floor2_1 floor2_2
building2
1
2
3
4
Figure 2: Incremental TA in large-scale space
corresponds to the hearer?s physical location. As
illustrated above, a can also move along the ?spa-
tial progression? of the most salient discourse en-
tity during a dialogue. If the intended referent is
outside the current context, TA extends the context
by incrementally ascending the spatial abstraction
hierarchy until the intended referent is an element
of the resulting sub-hierarchy, as illustrated in Fig-
ure 2. Below we describe two instantiations of the
TA principle, a TA algorithm for reference gener-
ation (TAA1) and TAA2 for reference resolution.
Context Determination for GRE TAA1 con-
structs a set of entities dominated by the Referen-
tial Anchor a (and a itself). If this set contains the
intended referent r, it is taken as the current utter-
ance context set. Else TAA1 moves up one level
of abstraction and adds the set of all child nodes to
the context set. This loop continues until r is in the
context set. At that point TAA1 stops and returns
the constructed context set (cf. Algorithm 1).
TAA1 is formulated to be neutral to the kind of
GRE algorithm that it is used for. It can be used
with the original Incremental Algorithm (Dale and
Reiter, 1995), augmented by a recursive call if a
relation to another entity is selected as a discrim-
inatory feature. It could in principle also be used
with the standard approach to GRE involving re-
lations (Dale and Haddock, 1991), but we agree
with Paraboni et al (2007) that the mutually qual-
ified references that it can produce2 are not easily
resolvable if they pertain to circumstances where
a confirmatory search is costly (such as in large-
scale space). More recent approaches to avoid-
ing infinite loops when using relations in GRE
make use of a graph-based knowledge represen-
tation (Krahmer et al, 2003; Croitoru and van
Deemter, 2007). TAA1 is compatible with these
approaches, as well as with the salience based ap-
proach of (Krahmer and Theune, 2002).
2An example for such a phenomenon is the expression
?the ball on the table? in a context with several tables and
several balls, but of which only one is on a table. Humans
find such REs natural and easy to resolve in visual scenes.
128
Algorithm 1 TAA1 (for reference generation)
Require: a = referential anchor; r = intended referent
Initialize context: C = {}
C = C ? topologicalChildren(a) ? {a}
if r ? C then
return C
else
Initialize: SUPERNODES = {a}
for each n ? SUPERNODES do
for each p ? topologicalParents(n) do
SUPERNODES = SUPERNODES ? {p}
C = C ? topologicalChildren(p)
end for
if r ? C then
return C
end if
end for
return failure
end if
Algorithm 2 TAA2 (for reference resolution)
Require: a = ref. anchor; desc(x) = description of referent
Initialize context: C = {}
Initialize possible referents: R = {}
C = C ? topologicalChildren(a) ? {a}
R = desc(x) ? C
if R 6= {} then
return R
else
Initialize: SUPERNODES = {a}
for each n ? SUPERNODES do
for each p ? topologicalParents(n) do
SUPERNODES = SUPERNODES ? {p}
C = C ? topologicalChildren(p)
end for
R = desc(x) ? C
if R 6= {} then
return R
end if
end for
return failure
end if
Resolving References to Elsewhere Analogous
to the GRE task, a conversational robot must be
able to understand verbal descriptions by its users.
In order to avoid overgenerating possible refer-
ents, we propose TAA2 (cf. Algorithm 2) which
tries to select an appropriate referent from a rel-
evant subset of the full knowledge base. It is ini-
tialized with a given semantic representation of the
referential expression, desc(x), in a format com-
patible with the knowledge base. Then, an appro-
priate entity satisfying this description is searched
for in the knowledge base. Similarly to TAA1,
the description is first matched against the current
context set C consisting of a and its child nodes. If
this set does not contain any instances that match
desc(x), TAA2 increases the context set alng the
spatial abstraction axis until at least one possible
referent can be identified within the context.
4 Conclusions and Future Work
We have presented two algorithms for context de-
termination that can be used both for resolving and
generating REs in large-scale space.
We are currently planning a user study to evalu-
ate the performance of the TA algorithms. Another
important item for future work is the exact nature
of the spatial progression, modeled by ?moving?
the referential anchor, in a situated dialogue.
Acknowledgments
This work was supported by the EU FP7 ICT
Project ?CogX? (FP7-ICT-215181).
References
A. G. Cohn and S. M. Hazarika. 2001. Qualitative
spatial representation and reasoning: An overview.
Fundamenta Informaticae, 46:1?29.
M. Croitoru and K. van Deemter. 2007. A conceptual
graph approach to the generation of referring expres-
sions. In Proc. IJCAI-2007, Hyderabad, India.
R. Dale and N. Haddock. 1991. Generating referring
expressions involving relations. In Proc. of the 5th
Meeting of the EACL, Berlin, Germany, April.
R. Dale and E. Reiter. 1995. Computational interpreta-
tions of the Gricean Maxims in the generation of re-
ferring expressions. Cognitive Science, 19(2):233?
263.
H. Horacek. 1997. An algorithm for generating ref-
erential descriptions with flexible interfaces. In
Proc. of the 35th Annual Meeting of the ACL and
8th Conf. of the EACL, Madrid, Spain.
J. Kelleher and G.-J. Kruijff. 2006. Incremental gener-
ation of spatial referring expressions in situated di-
alogue. In In Proc. Coling-ACL 06, Sydney, Aus-
tralia.
E. Krahmer and M. Theune. 2002. Efficient context-
sensitive generation of referring expressions. In
K. van Deemter and R.Kibble, editors, Information
Sharing: Givenness and Newness in Language Pro-
cessing. CSLI Publications, Stanford, CA, USA.
E. Krahmer, S. van Erk, and A. Verleg. 2003. Graph-
based generation of referring expressions. Compu-
tational Linguistics, 29(1).
B. Kuipers. 1977. Representing Knowledge of Large-
scale Space. Ph.D. thesis, Massachusetts Institute of
Technology, Cambridge, MA, USA.
I. Paraboni, K. van Deemter, and J. Masthoff. 2007.
Generating referring expressions: Making refer-
ents easy to identify. Computational Linguistics,
33(2):229?254, June.
H. Zender, O. Mart??nez Mozos, P. Jensfelt, G.-J. Krui-
jff, and W. Burgard. 2008. Conceptual spatial rep-
resentations for indoor mobile robots. Robotics and
Autonomous Systems, 56(6):493?502, June.
129
Anchor-Progression in Spatially Situated Discourse:
a Production Experiment
Hendrik Zender and Christopher Koppermann and Fai Greeve and Geert-Jan M. Kruijff
Language Technology Lab
German Research Center for Artificial Intelligence (DFKI)
Saarbru?cken, Germany
zender@dfki.de
Abstract
The paper presents two models for produc-
ing and understanding situationally appro-
priate referring expressions (REs) during
a discourse about large-scale space. The
models are evaluated against an empirical
production experiment.
1 Introduction and Background
For situated interaction, an intelligent system
needs methods for relating entities in the world,
its representation of the world, and the natural lan-
guage references exchanged with its user. Hu-
man natural language processing and algorithmic
approaches alike have been extensively studied
for application domains restricted to small visual
scenes and other small-scale surroundings. Still,
rather little research has addressed the specific is-
sues involved in establishing reference to entities
outside the currently visible scene. The challenge
that we address here is how the focus of attention
can shift over the course of a discourse if the do-
main is larger than the currently visible scene.
The generation of referring expressions (GRE)
has been viewed as an isolated problem, focussing
on efficient algorithms for determining which in-
formation from the domain must be incorporated
in a noun phrase (NP) such that this NP allows
the hearer to optimally understand which referent
is meant. The domains of such approaches usu-
ally consist of small, static domains or simple vi-
sual scenes. In their seminal work Dale and Reiter
(1995) present the Incremental Algorithm (IA) for
GRE. Recent extensions address some of its short-
comings, such as negated and disjoined properties
(van Deemter, 2002) and an account of salience for
generating contextually appropriate shorter REs
(Krahmer and Theune, 2002). Other, alternative
GRE algorithms exist (Horacek, 1997; Bateman,
1999; Krahmer et al, 2003). However, all these al-
gorithms rely on a given domain of discourse con-
stituting the current context (or focus of attention).
The task of the GRE algorithm is then to single out
the intended referent against the other members of
the context, which act as potential distractors. As
long as the domains are such closed-context sce-
narios, the intended referent is always in the cur-
rent focus. We address the challenge of producing
and understanding of references to entities that are
outside the current focus of attention, because they
have not been mentioned yet and are beyond the
currently observable scene.
Our approach relies on the dichotomy between
small-scale space and large-scale space for hu-
man spatial cognition. Large-scale space is ?a
space which cannot be perceived at once; its global
structure must be derived from local observations
over time? (Kuipers, 1977). In everyday situa-
tions, an office environment, one?s house, or a uni-
versity campus are large-scale spaces. A table-top
or a part of an office are examples of small-scale
space. Despite large-scale space being not fully
observable, people can nevertheless have a rea-
sonably complete mental representation of, e.g.,
their domestic or work environments in their cog-
nitive maps. Details might be missing, and peo-
ple might be uncertain about particular things and
states of affairs that are known to change fre-
quently. Still, people regularly engage in a con-
versation about such an environment, making suc-
cessful references to spatially located entities.
It is generally assumed that humans adopt a par-
tially hierarchical representation of spatial orga-
nization (Stevens and Coupe, 1978; McNamara,
1986). The basic units of such a representation
are topological regions (i.e., more or less clearly
bounded spatial areas) (Hirtle and Jonides, 1985).
Paraboni et al (2007) are among the few to ad-
dress the issue of generating references to entities
outside the immediate environment, and present
an algorithm for context determination in hierar-
...
...
... ...
...
office1 office4 office1
floor1 floor2
building 1A building 3B
old campus
kitchen office2 helpdesk office3office5
floor1 floor2 floor1
building 2C building 3B
new campus
Dienstag, 14. April 2009
(a) Example for a hierarchical representation of space.
(b) Illustration of the TA principle: starting from the atten-
tional anchor (a), the smallest sub-hierarchy containing both
a and the intended referent (r) is formed incrementally.
Figure 1: TA in a spatial hierarchy.
chically ordered domains. However, since it is
mainly targeted at producing textual references to
entities in written documents (e.g., figures and ta-
bles in book chapters), they do not address the
challenges of physical and perceptual situated-
ness. Large-scale space can be viewed as a hier-
archically ordered domain. To keep track of the
referential context in such a domain, in our previ-
ous work we propose the principle of topological
abstraction (TA, summarized in Fig. 1) for context
extension (Zender et al, 2009a), similar to Ances-
tral Search (Paraboni et al, 2007). In (Zender et
al., 2009b), we describe the integration of the ap-
proach in an NLP system for situated human-robot
dialogues and present two algorithms instantiating
the TA principle for GRE and resolving referring
expressions (RRE), respectively. It relies on two
parameters: the location of the intended referent
r, and the attentional anchor a. As discussed in
our previous works, for single utterances the an-
chor is the physical position where it is made (i.e.,
the utterance situation (Devlin, 2006)). Below, we
propose models for attentional anchor-progression
for longer discourses about large-scale space, and
evaluate them against real-world data.
2 The Models
In order to account for the determination of the
attentional anchor a, we propose a model called
anchor-progression A. The model assumes that
each exophoric reference1 serves as attentional
anchor for the subsequent reference. It is based
on observations on ?principles for anchoring re-
source situations? by Poesio (1993), where the ex-
pression of movement in the domain determines
1This excludes pronouns as well as other descriptions that
pick up an existing referent from the linguistic context.
the updated current mutual focus of attention. a
and r are then passed to the TA algorithm. Taking
into account the verbal behavior observed in our
experiment, we also propose a refined model of
anchor-resetting R, where for each new turn (e.g.,
a new instruction), the anchor is re-set to the utter-
ance situation. R leads to the inclusion of naviga-
tional information for each first RE in a turn, thus
reassuring the hearer of the focus of attention.
3 The Experiment
We are interested in the way the disambiguation
strategies change when producing REs during a
discourse about large-scale space versus discourse
about small-scale space. In our experiment, we
gathered a corpus of spoken instructions in two
different situations: small-scale space (SSS) and
large-scale space (LSS). We use the data to evalu-
ate the utility of the A and R models. We specifi-
cally evaluate them against the traditional (global)
model G in which the indented referent must be
singled out from all entities in the domain.
The cover story for the experiment was to
record spoken instructions to help improve a
speech recognition system for robots. The partici-
pants were asked to imagine an intelligent service
robot capable of understanding natural language
and familiar with its environment. The task of the
participants was to instruct the robot to clean up
a working space, i.e., a table-top (SSS) and an in-
door environment (LSS) by placing target objects
(cookies or balls) in boxes of the same color. The
use of color terms to identify objects was discour-
aged by telling the participants that the robot is un-
able to perceive color. The stimuli consisted of 8
corresponding scenes of the table-top and the do-
mestic setting (cf. Fig. 2). In order to preclude the
specific phenomena of collaborative, task-oriented
dialogue (cf., e.g., (Garrod and Pickering, 2004)),
the participants had to instruct an imaginary recip-
ient of orders. The choice of a robot was made to
rule out potential social implications when imag-
ining, e.g., talking to a child, a butler, or a friend.
The SSS scenes show a bird?s-eye view of the
table including the robot?s position (similar to (Fu-
nakoshi et al, 2004)). The way the objects are ar-
ranged allows to refer to their location with respect
to the corners of the table, with plates as additional
landmarks. The LSS scenes depict an indoor envi-
ronment with a corridor and, parallel to SSS, four
rooms with tables as landmarks. The scenes show
Table 1: Example from the small-scale (1?2) and large-scale space (3?4) scenes in Fig. 2.
1. nimm [das pla?tzchen unten links]mG,A , leg es [in die schachtel unten rechts auf dem teller]oG,A
?take the cookie on the bottom left, put it into the bottom right box on the plate?
2. nimm [das pla?tzchen unten rechts]mG,oA , leg es [in die schachtel oben links auf dem teller]mG,A
?take the cookie on the bottom right, put it into the top left box on the plate?
3. geh [ins wohnzimmer]mG,A,R und nimm [den ball]uG,mA,R und bring ihn [ins arbeitszimmer]mG,A,R , leg ihn [in die
kiste auf dem tisch]uG,oA,R
?go to the living room and take the ball and bring it to the study; put it into the box on the table?
4. und nimm [den ball]uG,R,mA und bring ihn [in die ku?che]mG,A,R und leg ihn [in die kiste auf dem boden]uG,mA,R
?and take the ball and bring it to the kitchen and put it into the box on the floor?
(a) Small-scale space: squares represent small boxes,
stars cookies, and white circles plates.
ArbeitszimmerK?che
Wohnzimmer Bad
(b) Large-scale space: squares represent boxes placed on the
floor or on a table, circles represent balls, rooms are labeled.
Figure 2: Two stimuli scenes from the experiment.
the robot and the participant in the corridor.
In order to gather more comparable data we
opted for a within-participants approach. Each
person participated in the SSS treatment and in the
LSS treatment. To counterbalance potential carry-
over effects, half of the participants were shown
the treatments in inverse order, and the sequence
of the 8 scenes in each treatment was varied in a
principled way. In order to make the participants
produce multi-utterance discourses, they were re-
quired to refer to all target object pairs. The exact
wording of their instructions was up to them.
Participants were placed in front of a screen and
a microphone into which they spoke their orders
to the imaginary robot, followed by a self-paced
keyword after which the experimenter showed the
next scene. The experiment was conducted in Ger-
man and consisted of a pilot study (10 partici-
pants) and the main part (19 female and 14 male
students, aged 19?53, German native speakers).
The data of three participants who did not behave
according to the instructions was discarded. The
individual sessions took 20?35 min., and the par-
ticipants were paid for their efforts.
Using the UAM CorpusTool software, tran-
scriptions of the recorded spoken instructions
were annotated for occurrences of the linguistic
phenomenon we are interested in, i.e., REs. Sam-
ples were cross-checked by a second annotator.
REs were marked as shallow ?refex? segments,
i.e., complex NPs were not decomposed into their
constituents. Only definite NPs representing ex-
ophoric REs (cf. Sec. 2) qualify as ?refex? seg-
ments. If a turn contained an indefinite NP, the
whole turn was discarded. The ?refex? segments
were coded according to the amount of informa-
tion they contain, and under which disambigua-
tion model M ? {G,A,R} (R only for LSS)
they succeed in singling out the described refer-
ent. Following Engelhardt et al (2006), we dis-
tinguish three types of semantic specificity. A RE
is an over-description with respect to M (overM )
if it contains redundant information, and it is an
under-description (underM ) if it is ambiguous ac-
cording to M . Minimal descriptions (minM ) con-
tain just enough information to uniquely identify
the referent. Table 1 shows annotated examples.
4 Results
The collected corpus consists of 30 annotated ses-
sions with 2 treatments comprising 8 scenes with
4 turns. In total, it contains 4,589 annotated REs,
out of which only 83 are errors. Except for the
error rate calculation, we only consider non-error
?refex? segments as the universe. The SSS treat-
Table 2: Mean frequencies (with standard deviation in italics) of minimal (min), over-descriptions
(over), and under-descriptions (under) with respect to the models (A, R, G) in both treatments.
overG overA overR minG minA minR underG underA underR
small-scale 13.94% 34.45% 78.90% 60.11% 7.16% 5.43%
space 15.85% 14.37% 17.66% 13.13% 12.07% 10.50%
large-scale 6.81% 34.75% 20.06 % 68.04% 64.55% 76.73% 25.16% 0.69% 3.21%
space 7.53% 12.13% 10.10% 17.87% 13.13% 10.66% 19.48% 1.72% 5.06%
ment contains 1,902 ?refex?, with a mean number
of 63.4 and a std. dev. ?=1.98 per participant. This
corresponds to the expected number of 64 REs to
be uttered: 8 scenes ? 4 target object pairs. The
LSS treatment contains 2,604 ?refex? with an aver-
age of 86.8 correct REs (?=18.19) per participant.
As can be seen in Table 1 (3?4), this difference
is due to the participants? referring to intermediate
waypoints in addition to the target objects. Table 2
summarizes the analysis of the annotated data.
Overall, the participants had no difficulties with
the experiment. The mean error rates are low in
both treatments: 1.78% (?=3.36%) in SSS, and
1.80% (?=2.98%) in LSS. A paired sample t-
test of both scores for each participant shows that
there is no significant difference between the error
rates in the treatments (p=0.985), supporting the
claim that both treatments were of equal difficulty.
Moreover, a MANOVA shows no significant effect
of treatment-order for the verbal behavior under
study, ruling out potential carry-over effects.
Production experiments always exhibit a con-
siderable variation between participants. When
modeling natural language processing systems,
one needs to take this into account. A GRE com-
ponent should produce REs that are easy to un-
derstand, i.e., ambiguities should be avoided and
over-descriptions should occur sparingly. A GRE
algorithm will always try to produce minimal de-
scriptions. The generation of an under-description
means a failure to construct an identifying RE,
while over-descriptions are usually the result of
a globally ?bad? incremental construction of the
generated REs (as is the case, e.g., in the IA). An
RRE component, on the other hand, should be able
to identify as many referents as possible by treat-
ing as few as possible REs as under-descriptions.
The analysis of the SSS data with respect to
G establishes the baseline for a comparison with
other experiments and GRE approaches. 13.9% of
the REs contain redundant information (overG),
compared to 21% in (Viethen and Dale, 2006). In
contrast, however, our SSS scenes did not provide
the possibility for producing more-than-minimal
REs for every target object, which might account
for the difference. underG REs occur with a fre-
quency of 7.2% in the SSS data. Because under-
descriptions result in the the hearer being unable to
reliably resolve the reference, this means that the
robot in our experiment cannot fulfill its task. This
might explain the difference to the 16% observed
in the task-independent study by Viethen and Dale
(2006). The significantly (p<0.001) higher mean
frequency of minG than minA underpins that G
is an accurate model for the verbal behavior in
SSS. However, G does not fit the LSS data well.
An RRE algorithm with model G would fail to
resolve the intended referent in 1 out of 4 cases
(cf. underG in LSS). With only 0.7% underA
REs on average, A models the LSS data signifi-
cantly better (p<0.001). Still, there is is a high
rate of overA REs. In comparison, R yields a
significantly (p<0.001) lower amount of overR.
The mean frequency of underR is significantly
(p=0.010) higher than for underA, but still below
underG in the SSS data. With a mean frequency
of 76.7% minR, R models the data better than
both G and A. For the REs in LSS minR is in
the same range as minG for the REs in SSS.
5 Conclusions
Overall, the data exhibit a high mean frequency of
over-descriptions. However, since this means that
the human-produced REs contain more informa-
tion than minimally necessary, this does not nega-
tively affect the performance of an RRE algorithm.
For a GRE algorithm, however, a more cautious
approach might be desirable. In situated discourse
about LSS, we thus suggest that A is suitable for
the RRE task because it yields the least amount
of unresolvable under-descriptions. For the GRE
task R is more appropriate. It strikes a balance
between producing short descriptions and supple-
menting navigational information.
Acknowledgments
This work was supported by the EU Project CogX
(FP7-ICT-215181). Thanks to Mick O?Donnell
for his support with the UAM CorpusTool.
References
John A. Bateman. 1999. Using aggregation for select-
ing content when generating referring expressions.
In Proceedings of the 37th annual meeting of the As-
sociation for Computational Linguistics on Compu-
tational Linguistics (ACL?99), pages 127?134, Mor-
ristown, NJ, USA.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the Gricean Maxims in the gener-
ation of referring expressions. Cognitive Science,
19(2):233?263.
Keith Devlin. 2006. Situation theory and situation se-
mantics. In Dov M. Gabbay and John Woods, edi-
tors, Logic and the Modalities in the Twentieth Cen-
tury, volume 7 of Handbook of the History of Logic,
pages 601?664. Elsevier.
Paul E. Engelhardt, Karl G.D. Bailey, and Fernanda
Ferreira. 2006. Do speakers and listeners observe
the Gricean Maxim of Quantity? Journal of Mem-
ory and Language, 54(4):554?573.
Kotaro Funakoshi, Satoru Watanabe, Naoko Kuriyama,
and Takenobu Tokunaga. 2004. Generation of
relative referring expressions based on perceptual
grouping. In COLING ?04: Proceedings of the 20th
international conference on Computational Linguis-
tics, Morristown, NJ, USA.
Simon Garrod and Martin J. Pickering. 2004. Why is
conversation so easy? Trends in Cognitive Sciences,
8(1):8?11, January.
Stephen C. Hirtle and John Jonides. 1985. Evidence
for hierarchies in cognitive maps. Memory and Cog-
nition, 13:208?217.
Helmut Horacek. 1997. An algorithm for generating
referential descriptions with flexible interfaces. In
Proceedings of the 35th Annual Meeting of the As-
sociation for Computational Linguistics and Eighth
Conference of the European Chapter of the Associa-
tion for Computational Linguistics (ACL-97), pages
206?213, Morristown, NJ, USA.
Emiel Krahmer and Marie?t Theune. 2002. Effi-
cient context-sensitive generation of referring ex-
pressions. In Kees van Deemter and R. Kibble, ed-
itors, Information Sharing: Givenness and Newness
in Language Processing, pages 223?264. CSLI Pub-
lications, Stanford, CA, USA.
Emiel Krahmer, Sebastiaan van Erk, and Andre? Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53?72.
Benjamin Kuipers. 1977. Representing Knowledge of
Large-scale Space. PhD thesis, MIT-AI TR-418,
Massachusetts Institute of Technology, Cambridge,
MA, USA, May.
Timothy P. McNamara. 1986. Mental representations
of spatial relations. Cognitive Psychology, 18:87?
121.
Ivandre? Paraboni, Kees van Deemter, and Judith Mas-
thoff. 2007. Generating referring expressions:
Making referents easy to identify. Computational
Linguistics, 33(2):229?254, June.
Massimo Poesio. 1993. A situation-theoretic formal-
ization of definite description interpretation in plan
elaboration dialogues. In Peter Aczel, David Israel,
Yasuhiro Katagiri, and Stanley Peters, editors, Sit-
uation Theory and its Applications Volume 3, CSLI
Lecture Notes No. 37, pages 339?374. Center for the
Study of Language and Information, Menlo Park,
CA, USA.
Albert Stevens and Patty Coupe. 1978. Distortions
in judged spatial relations. Cognitive Psychology,
10:422?437.
Kees van Deemter. 2002. Generating referring expres-
sions: boolean extensions of the incremental algo-
rithm. Computational Linguistics, 28(1):37?52.
Jette Viethen and Robert Dale. 2006. Algorithms
for generating referring expressions: Do they do
what people do? In Proceedings of the 4th Inter-
national Natural Language Generation Conference
(INLG 2006), pages 63?70, Sydney, Australia.
Hendrik Zender, Geert-Jan M. Kruijff, and Ivana
Kruijff-Korbayova?. 2009a. A situated context
model for resolution and generation of referring ex-
pressions. In Proceedings of the 12th European
Workshop on Natural Language Generation (ENLG
2009), pages 126?129, Athens, Greece, March.
Hendrik Zender, Geert-Jan M. Kruijff, and Ivana
Kruijff-Korbayova?. 2009b. Situated resolution
and generation of spatial referring expressions for
robotic assistants. In Proceedings of the Twenty-
First International Joint Conference on Artificial In-
telligence (IJCAI-09), pages 1604?1609, Pasadena,
CA, USA, July.
