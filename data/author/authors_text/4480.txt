Morpheme-based Derivation of  
Bipolar Semantic Orientation of Chinese Words  
Raymond W.M. Yuen, Terence Y.W. Chan, Tom B.Y. Lai, O.Y. Kwong, Benjamin K.Y. T'sou  
Language Information Sciences Research Centre, the City University of Hong Kong 
83 Tat Chee Avenue, Hong Kong  
{ wmyuen, dcywchan, cttomlai, rlolivia, rlbtsou}@cityu.edu.hk 
 
Abstract 
The evaluative character of a word is called its 
semantic orientation (SO). A positive SO 
indicates desirability (e.g. Good, Honest) and 
a negative SO indicates undesirability (e.g., 
Bad, Ugly). This paper presents a method, 
based on Turney (2003), for inferring the SO 
of a word from its statistical association with 
strongly-polarized words and morphemes in 
Chinese. It is noted that morphemes are much 
less numerous than words, and that also a 
small number of fundamental morphemes may 
be used in the modified system to great 
advantage. The algorithm was tested on 1,249 
words (604 positive and 645 negative) in a 
corpus of 34 million words, and was run with 
20 and 40 polarized words respectively, giving 
a high precision (79.96% to 81.05%), but a 
low recall (45.56% to 59.57%). The algorithm 
was then run with 20 polarized morphemes, or 
single characters, in the same corpus, giving a 
high precision of 80.23% and a high recall of 
85.03%. We concluded that morphemes in 
Chinese, as in any language, constitute a dis-
tinct sub-lexical unit which, though small in 
number, has greater linguistic significance 
than words, as seen by the significant en-
hancement of results with a much smaller 
corpus than that required by Turney. 
1. Introduction 
The semantic orientation (SO) of a word indicates 
the direction in which the word deviates from the 
norm for its semantic group or lexical field (Lehrer, 
1974). Words that encode a desirable state (e.g., 
beautiful) have a positive SO, while words that 
represent undesirable states (e.g. absurd) have a 
negative SO (Hatzivassiloglou and Wiebe, 2000). 
Hatzivassiloglou and Mckeown (1997) used the 
words ?and?, ?or?, and ?but? as linguistic cues to 
extract adjective pairs. Turney (2003) assessed the 
SO of words using their occurrences near strongly-
polarized words like ?excellent? and ?poor? with 
accuracy from 61% to 82%, subject to corpus size. 
Turney?s algorithm requires a colossal corpus 
(hundred billion words) indexed by the AltaVista 
search engine in his experiment. Undoubtedly, 
internet texts have formed a very large and easily-
accessible corpus. However, Chinese texts in 
internet are not segmented so it is not cost-
effective to use them. 
This paper presents a general strategy for 
inferring SO for Chinese words from their 
association with some strongly-polarized 
morphemes. The modified system of using 
morphemes was proved to be more effective than  
strongly-polarized words in a much smaller corpus.  
Related work and potential applications of SO 
are discussed in section 2. 
Section 3 illustrates one of the methods of 
Turney?s model for inferring SO, namely, 
Pointwise Mutual Information (PMI), based on the 
hypothesis that the SO of a word tends to 
correspond to the SO of its neighbours. 
The experiment with polarized words is 
presented in section 4. The test set includes 1,249 
words (604 positive and 645 negative). In a corpus 
of 34 million word tokens, 410k word types, the 
algorithm is run with 20 and 40 polarized words, 
giving a precision of 79.96% and 81.05%, and a 
recall  of 45.56% and 59.57%, respectively. 
The system is further modified by using 
polarized morphemes in section 5. We first 
evaluate the distinction of Chinese morphemes to 
justify why the modification can probably give 
simpler and better results, and then introduce a 
more scientific selection of polarized morphemes. 
A high precision of 80.23% and a greatly increased 
recall of 85.03% are yielded. 
In section 6, the algorithm is run with 14, 10 and 
6 morphemes, giving a precision of 79.15%, 
79.89% and 75.65%, and a recall of 79.50%, 
73.26% and 66.29% respectively. It shows that the 
algorithm can be also effectively run with 6 to 10 
polarized morphemes in a smaller corpus. 
The conclusion and future work are discussed in 
section 7. 
2. Related Work and Applications 
Hatzivassiloglou and Mckeown (1997) presented a 
method for automatically assigning a + or ? 
orientation label to adjectives known to have some 
SO by the linguistic constraints on the use of 
adjectives in conjunctions. For example, ?and? 
links adjectives that have the same SO, while ?but? 
links adjectives that have opposite SO. They 
devised an algorithm based on such constraints to 
evaluate 1,336 manually-labeled adjectives (657 
positive and 679 negative) with 97% accuracy in a 
corpus of 21 million words. 
Turney (2003) introduced a method for 
automatically inferring the direction and intensity 
of the SO of a word from its statistical association 
with a set of positive and negative paradigm words, 
i.e., strongly-polarized words. The algorithm was 
evaluated on 3,596 words (1,614 positive and 
1,982 negative) including adjectives, adverbs, 
nouns, and verbs. An accuracy of 82.8% was 
attained in a corpus of hundred billion words. 
SO can be used to classify reviews (e.g., movie 
reviews) as positive or negative (Turney, 2002), 
and applied to subjectivity analysis such as 
recognizing hostile messages, classifying emails, 
mining reviews (Wiebe et al, 2001). The first step 
of those applications is to recognize that the text is 
subjective and then the second step, naturally, is to 
determine the SO of the subjective text. Also, it 
can be used to summarize argumentative articles 
like editorials of news media. A summarization 
system would benefit from distinguishing 
sentences intended to present factual materials 
from those intended to present opinions, since 
many summaries are meant to include only facts. 
3. SO from Association-PMI 
Turney (2003) examined SO-PMI (Pointwise 
Mutual Information) and SO-LSA (Latent 
Semantic Analysis). SO-PMI will be our focus in 
the following parts. PMI is defined as:  
 
PMI(word1, word2)=log2( )()(
)&(
21
21
wordpwordp
wordwordp ) 
 
where p(word1 & word2) is the probability that 
word1 and word2 co-occur. If the words are 
statistically independent, the probability that they 
co-occur is given by the product p(word1) p(word2). 
The ratio between p(word1 & word2) and p(word1) 
p(word2) is a measure of the degree of statistical 
dependence between the words. The SO of a given 
word is calculated from the strength of its 
association with a set of positive words, minus the 
strength of its association with a set of negative 
words. Thus the SO of a word, word, is calculated 
by SO-PMI as follows: 
SO-PMI(word) = 

?Pwordspword
pwordwordPMI ),(  - 
?Nwordsnword
nwordwordPMI ),(  
 
where Pwords is a set of 7 positive paradigm 
words (good, nice, excellent, positive, fortunate, 
correct, and superior) and Nwords is a set of 7 
negative paradigm words (bad, nasty, poor, 
negative, unfortunate, wrong, and inferior). Those 
14 words were chosen by intuition and based on 
opposing pairs (good/bad, excellent/poor, etc.). 
The words are rather insensitive to context, i.e., 
?excellent? is positive in almost all contexts. 
A word, word, is classified as having a positive 
SO when SO-PMI(word) is positive and a negative 
SO when SO-PMI(word) is negative.  
Turney (2003) used the Alta Vista Advanced 
search engine with a NEAR operator, which 
constrains the search to documents that contain the 
words within ten words of one another, in either 
order. Three corpora were tested. AV-ENG is the 
largest corpus covering 350 million web pages 
(English only) indexed by Alta Vista. The medium 
corpus is a 2% subset of AV-ENG corpus called 
AV-CA (Canadian domain only). The smallest 
corpus TASA is about 0.5% of AV-CA and 
contains various short documents. 
One of the lexicons used in Turney?s experiment 
is the GI lexicon (Stone et al, 1966), which 
consists of 3,596 adjectives, adverbs, nouns, and 
verbs, 1,614 positive and 1,982 negative. 
Table 1 shows the precision of SO-PMI with the 
GI lexicon in the three corpora. 
Precision Percent of 
full test set 
Size of 
test set AV-ENG AV-CA TASA 
100% 3596 82.84% 76.06% 61.26% 
75% 2697 90.66% 81.76% 63.92% 
50% 1798 95.49% 87.26% 47.33% 
25% 899 97.11% 89.88% 68.74% 
Approx. no. of 
words 1x10
11
 2x109 1x107 
Table 1: The precision of SO-PMI with the GI 
lexicon  
 
The strength (absolute value) of the SO was 
used as a measure of confidence that the words 
will be correctly classified. Test set words were 
sorted in descending order of the absolute value of 
their SO and the top ranked words (the highest 
confidence words) were then classified. For 
example, the second row (starting with 75%) in 
table 1 shows the precision when the top 75% were 
classified and the last 25% (with lowest confidence) 
were ignored. We will employ this measure of 
confidence in the following experiments.  
Turney concluded that SO-PMI requires a large 
corpus (hundred billion words), but it is simple, 
easy to implement, unsupervised, and it is not 
restricted to adjectives.  
4. Experiment with Chinese Words 
In the following experiments, we applied Turney?s 
method to Chinese. The algorithm was run with 20 
and then 40 paradigm words for comparison. The 
experiment details include: 
NEAR Operator: it was applied to constrain 
the search to documents that contain the words 
within ten words of one another, in either order. 
Corpus: the LIVAC synchronous corpus (Tsou 
et al, 2000, http://www.livac.org) was used. It 
covers 9-year news reports of Chinese 
communities including Hong Kong, Beijing and 
Taiwan, and we used a sub-corpus with about 34 
million word tokens and 410k word types.  
Test Set Words: a combined set of two 
dictionaries of polarized words (Guo, 1999, Wang, 
2001) was used to evaluate the results. While 
LIVAC is an enormous Chinese corpus, its size is 
still far from the hundred-billion-word corpus used 
by Turney. It is likely that some words in the 
combined set are not used in the 9-year corpus. To 
avoid a skewed recall, the number of test set words 
used in the corpus is given in table 2. In other 
words, the recall can be calculated by the total 
number of words used in the corpus, but not by 
that recorded in the dictionaries. The difference 
between two numbers is just 100. 
Polarity Total no. of the 
test set words 
Words used in 
the 9-year corpus 
Positive 629 604 
Negative 721 645 
Total 1350 1249 
Table 2: Number of the test set words  
 
Paradigm words: The paradigm words were 
chosen using intuition and based on opposing pairs, 
as Turney (2003) did. The first experiment was 
conducted with 10 positive and 10 negative 
paradigm words, as follows,  
Pwords: (honest), (clever), (sufficient), 
(lucky), (right), (excellent), 
(prosperous), (kind), (brave), (humble) 
Nwords: (hypocritical), (foolish), 
(deficient), (unlucky), (wrong), (adverse), 
(unsuccessful), (violent), (cowardly), 
(arrogant) 
The experiment was then repeated by increasing 
the number of paradigm words to 40. The 
paradigm words added are: 
Pwords: (mild), (favourable), 
(successful), (positive), (active), 
(optimistic), (benign), (attentive), 
(promising), (incorrupt) 
Nwords: (radical), (unfavourable), 
(failed), (negative), (passive), 
(pessimistic), (malignant), (inattentive), 
(indifferent), (corrupt) 
4.1 Results 
Tables 3 and 4 show the precision and recall of 
SO-PMI by two sets of paradigm words.  
% of test set 100% 75% 50% 25% 
Size of test set 1249 937 625 312 
Extracted Set 569 427 285 142 
Precision 79.96% 86.17% 86.99% 90.16% 
Recall 45.56% 
Table 3: Precision and Recall of the SO-PMI of the 
20 paradigm word test set 
% of  test set 100% 75% 50% 25% 
Size of test set 1249 937 625 312 
Extracted Set 744 558 372 186 
Precision 81.05% 86.02% 88.71% 94.09% 
Recall 59.57% 
Table 4: Precision and Recall of the SO-PMI of the 
40 paradigm word test set 
 
The results of both sets gave a satisfactory 
precision of 80% even in 100% confidence. 
However, the recall was just 45.56% under the 20-
word condition, and rose to 59.57% under the 40-
word condition. The 15% rise was noted. 
To further improve the recall performance, we 
experimented with a modified algorithm based on 
the distinct features of Chinese morphemes.  
5. Experiment with Chinese Morphemes 
Taking morphemes to be smallest linguistic 
meaningful unit, Chinese morphemes are mostly 
monosyllabic and single characters, although there 
are some exceptional poly-syllabic morphemes like 
 (grape),  (coffee), which are mostly 
loanwords. In the following discussion, we 
consider morphemes to be monosyllabic and 
represented by single characters. 
It is observed that many poly-syllabic words 
with the same SO incorporate a common set of 
morphemes. The fact suggests the possibility of 
using paradigm morphemes instead of words.  
Unlike English, the constituent morphemes of a 
Chinese word are often free-standing monosyllabic 
words. It is note-worthy that words in ancient 
Chinese were much more mono-morphemic than 
modern Chinese. The evolution from monosyllabic 
word to disyllabic word may have its origin in the 
phonological simplification which has given rise to 
homophony, and which has affected the efficacy of 
communication. To compensate for this, many 
more related disyllabic words have appeared in 
modern Chinese (Tsou, 1976). There are three 
basic constructions for deriving disyllabic words in 
Chinese, including:  
(1) combination of synonyms or near 
synonyms ( , warm, genial, =warm, mild, 
=warm, genial) 
(2) combination of semantically related 
morphemes ( , =affair, =circumstances) 
(3) The affixation of minor suffixes which 
serve no primary grammatical function ( , 
=village, =zi, suffix) 
The three processes for deriving disyllabic 
morphemes in Chinese outlined here should be 
viewed as historical processes. The extent to which 
such processes may be realized by native speakers 
to be productive synchronically bears further 
exploration. Of the three processes, the first two, 
i.e., synonym and near-synonym compounding, are 
used frequently by speakers for purposes of 
disambiguation. In view of this development, the 
evolution from monosyllabic words in ancient 
Chinese to disyllabic words in modern Chinese 
does not change the inherent meaning of the 
morphemes (words in ancient Chinese) in many 
cases. The SO of a word often conforms to that of 
its morphemes.  
In English, there are affixal morphemes like dis-, 
un- (negation prefix), or ?less (suffix meaning 
short-age), -ful (suffix meaning ?to have a property 
of?), we can say ?careful? or ?careless? to expand 
the meaning of ?care?. However, it is impossible to 
construct a word like ?*ful-care?, ?*less-care?. 
However, in Chinese, the position of a morpheme 
in many disyllabic words is far more flexible in the 
formation of synonym and near-synonym 
compound words. For instance, ? ?(honor) is a 
part of two similar word ? ? (honor-bright) and 
? ?(outstanding-honor). Morphemes in Chinese 
are like a ?zipped file? of the same file types. When 
it unzips, all the words released have the same SO. 
5.1 Probability of Constituent Morphemes 
of Words with the Same SO 
Most morphemes can contribute to positive or 
negative words, regardless of their inherent 
meaning. For example, ? ? (luck) has inherently a 
positive meaning, but it can construct both positive 
word ? ? (lucky) or a negative word ? ? 
(unlucky). Thus it is not easy to define the 
paradigm set simply by intuition. But we can 
assign a probability value for a morpheme in 
forming polarized words on the basis of corpus 
data. 
The first step is to come up with possible 
paradigm morphemes by intuition in a large set of 
polarized words. With the LIVAC synchronous 
corpus, the types and tokens of the words 
constructed by the selected morphemes can easily 
be extracted. The word types, excluding proper 
nouns, are then manually-labeled as negative, 
neutral or positive. Then to obtain the probability 
that a polar morpheme generates words with the 
same SO, the tokens of the polarized word types 
carrying the morpheme are divided by the tokens 
of all word types carrying the morpheme. For 
example, given a negative morpheme, m1, the 
probability that it appears in negative words in 
token, P(m1, -ve) is given by: 
 
1m Carrying  WordtypesAll of Tokens
1m Carrying rdtypesNegativeWo of Tokens
 
 
Positive morphemes can be done likewise. Ten 
negative morphemes and ten positive morphemes 
were chosen as in table 5. Their values of 
P(morpheme, orientation) are all above 0.95. 
 +ve Morpheme -ve Morpheme 
1  (gift) (hurt) 
2  (win)  
3  (good) (doubt) 
4  (secure) (difficult) 
5  (rich) (rush) 
6  (health)  
7  (happy) (explode) 
8  (honor) (ban) 
9 (hardworking) (collapse) 
10 (smooth) (reject) 
Derived Types 7383 2048 
Tokens 247249 166335 
Table 5: Selected positive and negative 
morphemes 
 
Those morphemes were extracted from a 5-year 
subset of the LIVAC corpus. A morpheme, free to 
construct new words, may construct hundreds of 
words but those words with extremely low 
frequency can be regarded as ?noise?. The ?noise? 
may be ?creative use? or even incorrect use. Thus, 
the number of ready-to-label word types formed 
from a particular morpheme was limited to 50, but 
it must cover 80% of the tokens of all word types 
carrying the morpheme in the corpus (i.e., 80% 
dominance). For example, if the morpheme m1 
constructs 120 word types with 10,000 tokens, and 
the first 50 high-frequency words can reach 8,000 
tokens, then the remaining 70 low-frequency word 
types, or noise, are discarded. Otherwise, the 
number of sampled words would be expanded to a 
number (over 50) fulfilling 80% dominance. 
5.2 Results and Evaluation 
In table 6, the precision of 80.23% is slightly better 
than 79.96% of the 20-word condition, and just 1% 
lower than that of the 40-word condition. However, 
the recall drastically increases from 45.56%, or 
59.57% under the 40-word condition, to 85.03%. 
In other words, the algorithm run with 20 Chinese 
paradigm morphemes resulted not only in high 
precision but also much higher recall than Chinese 
paradigm words in the same corpus. 
% of test set 100% 75% 50% 25% 
Size of test set 1249 937 625 312
Extracted Set 1062 797 531 266
Precision 80.23% 85.44% 90.96% 96.61%
Recall 85.03% 
Table 6: Precision and Recall of SO-PMI of the 20 
paradigm morpheme test set 
 
Since the morphemes were chosen from a subset 
of the corpus for evaluation, we repeated the 
experiment in a separate 1-year corpus (2001-
2002). The results in table 7 reflect a similar 
pattern in the two corpora ? both words and 
morphemes can get high precision, but morphemes 
can double the recall of words. 
 40 Words 20 Morphemes 
Size of test set 1065 
Extracted Set 333 671 
Precision (Full Set) 75.38% 73.62% 
Recall 31.27% 63.00% 
Table 7: Precision (full test set only) and Recall of 
SO-PMI of 40 paradigm words and 20 paradigm 
morphemes in 1-year corpus 
 
It is assumed that a smaller corpus easily leads 
to the algorithm?s low recall because many low-
frequency words in the test set barely associate 
with the paradigm words. To examine the 
assumption, the results were further analyzed with 
the frequency of the test set words. First, the 
occurrence of the test set words in the 9-year 
corpus was counted, then the median of the 
frequency, 44 in this case, was taken. The results 
were divided into two sections from the median 
value, and the recall of two sections was calculated 
respectively, as in table 8.  
?
Table 8: Morpheme-based and word-based recall 
of high-frequency and low-frequency words  
 
The results showed that high-frequency words 
could be largely extracted by the algorithm with 
both morphemes (99.80% recall) and words 
(89.45% recall). However, paradigm words gave 
26.55% recall of low-frequency words, whereas 
paradigm morphemes gave 67.66%. They showed 
that morphemes outperform words in the retrieval 
of low-frequency words. 
Colossal corpora like Turney?s hundred-billion-
word corpus can compensate for the low 
performance of paradigm words in low-frequency 
words. Such a large corpus has been easily-
accessible since the emergence of internet, but it is 
not cost-effective to use the Chinese texts from the 
internet because those texts are not segmented. 
Another way of compensation is the expansion of 
paradigm words, but doubling the number of 
paradigm words just raised the recall from 45.56% 
to 59.57%, as shown in section 4. The supervised 
cost is not reasonable if the number of paradigm 
words is further expanded. 
Morphemes, or single characters in Chinese, 
naturally occur more frequently than words in an 
article, so 20 morphemes can be more discretely-
distributed over texts than 20 or even 40 words. 
The results show that some morphemes always 
retain their inherent SO when becoming 
constituents in other derived words. Such 
morphemes are like a zipped file of the same SO, 
when the algorithm is run with 20 paradigm 
morphemes, it is actually run by thousands of 
paradigm words. Consequently, the recall could 
double while the high precision was not affected.  
It may be argued that the labour cost of defining 
the SO of 20 morphemes is not sufficiently low 
either. The following experiments will demonstrate 
that decreasing the number of morphemes can also 
give satisfactory results. 
6. Experiment with different number of 
morphemes 
The following experiments were done respectively 
by decreasing the number of morphemes, i.e., 14 
and 10 morphemes, chosen from table 5. The 
algorithm was then run with 3 groups of 6 different 
morphemes, in which the morphemes were 
different, and the combination of morphemes in 
each group was random. The morphemes in each 
group are shown in table 9. Other conditions for 
the experiments were unchanged. 
6.1 Results and Evaluation 
Table 10 shows the results with different number 
of morphemes, and table 11 shows those for 
different groups of 6 morphemes. For convenient 
comparison, the tables only show the results of the 
full test set, i.e., no threshold filtering. 
It is shown that the recall falls as the number of 
morphemes is reduced. However, even the average 
recall 66.29% under the 6-morpheme condition is 
still higher than that under the 40-word condition 
(59.57%). In section 5, it was evaluated that low 
recall could be attributed to the low frequency of 
test set words. Therefore, 6 to 10 morphemes are 
already ideal for deducing the SO of high-
frequency words.  
 Number of morphemes used 
Morpheme 20 14 10 6 (Gp1) 
6 
(Gp2) 
6 
(Gp3)
P 
 (gift) 1   1   
P 
 (good) 1 1 1 1   
P 
 (happy) 1 1  1   
P 
 (rich) 1 1   1  
P 
 (honor) 1 1 1  1  
P (smooth) 1 1 1  1  
P 
 (win) 1     1 
P 
 (secure) 1     1 
P 
 (health) 1 1 1   1 
P 
 (hardworking) 1 1 1    
N (doubt) 1 1 1 1   
N (explode) 1 1  1   
N (ban) 1 1 1 1   
N (rash) 1 1 1  1  
N (greedy) 1 1 1  1  
N (difficult) 1 1 1  1  
N (hurt) 1 1    1 
N (rush) 1     1 
N (collapse) 1     1 
N (reject) 1      
Table 9: Morphemes selected for different 
experimental sets, P=+ve, N=-ve, 1=?selected?, 
Gp= Group 
 Number of morphemes used 
No of morphemes 20 14 10 
Size of test set 1249 1249 1249 
Extracted Set 1062 993 915 
Precision (%) 80.23 79.15 79.89 
Recall (%) 85.03 79.50 73.26 
Table 10: Precision and Recall of SO-PMI of the 
test set words with different no. of morphemes 
Group of 
Morphemes 
Group 1 Group 2 Group 3 Average 
Size of test set 1249 1249 1249 1249 
Extracted Set 837 776 871 828
Precision (%) 79.69 78.48 68.77 75.65
Recall (%) 67.01 62.13 69.74 66.29
Table 11: Precision and Recall of SO-PMI of the 
test set words with 3 different groups of 6 
morphemes 
 
The precision remains high from 20 morphemes 
to 6 morphemes, but from table 10 the precision 
varies with different sets of morphemes. Group 3 
gave the lowest precision of 68.77%, whereas 
other groups gave a high precision close to 80%. 
The limited space of this paper cannot allow a 
detailed investigation into the reasons for this 
result, only some suggestions can be made. 
The precision may be related to the dominant 
lexical types of the words constructed by the 
morphemes and those of the test set words. Lexical 
types should be carefully considered in the 
algorithm for Chinese because Chinese is an 
isolating language - no form change. For example, 
the word ? ? (recover) can appear in different 
positions of a sentence, such as the following 
examples extracted from the corpus:  
(1)? ? (...American 
economy is gradually recovering?) 
(2) ?
(?most people is now pessimistic about the 
economy recovery) 
(3) ?
(?decelerates the recovery, but also makes the 
future unpredictable.) 
English allows different forms of ?recovery, like 
?recovery?, ?recovering?, ?recovered? but Chinese 
does not. Lexical types are thus an important factor 
for the precision performance. Another way of 
solving the problems of lexical types is the 
automatic extraction of meaningful units 
(Danielsson, 2003). Simply, meaningful units are 
some frequently-used patterns which consist of two 
or more words. It is useful to automatically extract 
the meaningful units with SO in future. 
Syntactic markers like negation, and creative 
uses like ironical expression of adding quotation 
marks can also affect the precision. Here is an 
example from the corpus: 
(?HONEST BUSINESSMAN?). The quotation 
mark (? ? in English) is to actually express the 
opposite meaning of words within the mark, i.e., 
HONEST means DISHONEST in this case. Such 
markers should further be handled, just as with the 
use of ?so-called?. 
6 Conclusion and Future Work 
This paper presents an algorithm based on 
Turney?s model (2003) for inferring SO of Chinese 
words from their association with strongly-
polarized Chinese morphemes. The algorithm was 
run with 20 and 40 strongly-polarized Chinese 
words respectively in a corpus of 34 million words, 
giving a high precision of 79.96% and 81.05%, but 
a low recall of 45.56% and 59.57%. The algorithm 
was then run with 20 Chinese polarized 
morphemes, or single characters, in the same 
corpus, giving a high precision of 80.23% and an 
even high recall of 85.03%. The algorithm was 
further run with just 14, 10 and 6 morphemes, 
giving a precision of 79.15%, 79.89% and 75.65%, 
and a recall of 79.50%, 73.26% and 66.29% 
respectively.  
Thus, conveniently defined morphemes in 
Chinese enhance the effectiveness of the algorithm 
by simplifying processing and yielding better 
results even in a smaller corpus compared with 
what Turney (2003) used. Just 6 to 10 morphemes 
can give satisfactory results in a smaller corpus. 
The efficient application of Turney?s algorithm 
with help of colossal corpus like hundred-billion-
word corpus is matched by the ready availability of 
internet texts. However, the same convenience is 
not available to Chinese because of the heavy cost 
of word segmentation. 
The efficient application of Turney?s algorithm 
with help of colossal corpus like hundred-billion-
word corpus is matched by the ready availability of 
internet texts. However, the same convenience is 
not available to Chinese because of the heavy cost 
of word segmentation. 
In our experiment, all syntactic markers are 
ignored. Better results can be expected if syntactic 
markers are taken into consideration. An obvious 
example is negation (not, never) which can 
counteract the polarity of a word. In future, we will 
try to handle negation and other syntactic markers. 
The lists of the probability of morphemes 
forming polarized words in section 5.2 can be 
handled by the concept of decision list (Yarowsky, 
2000) which has not been applied in this paper for 
simplification. In the future, decision lists can be 
employed to systematically include the loaded 
features of morphemes. 
The experiment can be conducted with different 
sets of paradigm morphemes, and on corpora of 
different sizes. With the LIVAC synchronous 
corpus (Tsou et al, 2000), it should be possible to 
compare the SO of some words in different 
communities like Beijing, Hong Kong and Taipei. 
The data would be valuable for cultural studies if 
the SO of some words fluctuates in different 
communities.  
SO from association can be also applied to the 
judgment of news articles like editorials on 
celebrities. Given a celebrity name or organization 
name, we can calculate, using SO-PMI, the 
strength of SO of the ?given word?, i.e., the name. 
Then we would be able to tell whether the news 
about the target is positive or negative. For 
example, we tried to calculate the SO-PMI of the 
name ?George W Bush?, the U.S. President, with 
thousands of polarized Chinese words in the 
corpus, it was found that the SO-PMI of ?Bush? 
was about -200 from January to February, 2003, 
and plunged to -500 from March to April, 2003, 
when U.S. launched an ?unauthorized war? against 
Iraq. Such useful applications will be further 
investigated in future. 
References  
DANIELSSON, P. 2003. Automatic Extraction of 
Meaningful Units from Corpora. International 
Journal of Corpus Linguistics, 8(1), 109-127. 
GUO XIAN-ZHEN, ZHANG WEI, LIU JIN, WANG 
LING-LING. 1999. ChangYong BaoBianYi CiYu 
XiangJie CiDian ( ). 
Commercial Press, Beijing.  
HATZIVASSILOGLOU, V., AND MCKEOWN, K.R. 
1997. Predicting the Semantic Orientation of 
Adjectives. Proceedings of the 35th Annual Meeting 
of the Association for Computational Linguistics and 
the 8th Conference of the European Chapter of the 
ACL, Madrid, Spain, 174-181. 
HATZIVASSILOGLOU, V. AND WIEBE, J.M. 2000. 
Effects of Adjective Orientation and Grad-ability on 
Sentence Subjectivity. Proceedings of 18th 
International Conference on Computational 
Linguistics (Coling?00), Saarbr?cken, Germany. 
LEHRER, A. 1974. Semantic Fields and Lexical 
Structure. North Holland, Amsterdam and New York. 
STONE, P.J., DUNPHY, D. C., SMITH, M. S., AND 
OGILVIE, D. M. 1966. The General Inquirer: A 
Computer Approach to Content Analysis. MIT Press, 
Cambridge, MA. 
TSOU, B.K. 1976. Homophony and Internal Change in 
Chinese. Computational Analyses of Asian and 
African Languages 3, 67-86. 
TSOU, B.K., TSOI, W.F., LAI, T.B.Y., HU, J. AND 
CHAN, S.W.K. 2000. LIVAC, A Chinese 
Synchronous Corpus, and Some Applications. 
Proceedings of the ICCLC International Conference 
on Chinese Language Computing. Chicago, 233-238. 
TURNEY, P.D. 2002. Thumbs up or Thumbs down? 
Semantic Orientation Applied to Unsupervised 
Classification of Reviews. Proceedings of the 
Association for Computational Linguistics 40th 
Anniversary Meeting, University of Pennsylvania, 
Philadelphia, PA, USA. 
TURNEY, P.D. & LITTMAN, M.L. 2003. Measuring 
Praise and Criticism: Inference of Semantic 
Orientation from Association. ACM Transactions on 
Information System (TOIS), 21(4), pp315-346. 
WANG GUO-ZHANG. 2001. A Dictionary of Chinese 
Praise and Blame Words (
). Sinolingua, Beijing.  
WIEBE, J.M., BRUCE, R., BELL, M. MARTIN, M., 
AND WILSON, T. 2001. A Corpus Study of 
Evaluative and Speculative Language. Proceedings 
of the Second ACL SIG on Dialogue Work-shop on 
Discourse and Dialogue. Aalborg, Denmark.  
YAROWSKY, D. 2000. Hierarchical Decision Lists for 
Word Sense Disambiguation. Computers and the 
Humanities, 34(1-2). 
 
Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 457?464
Manchester, August 2008
Extending a Thesaurus with Words from Pan-Chinese Sources 
Oi Yee Kwong?? and Benjamin K. Tsou? 
?Department of Chinese, Translation and Linguistics 
?Language Information Sciences Research Centre 
City University of Hong Kong 
Tat Chee Avenue, Kowloon, Hong Kong 
{rlolivia, rlbtsou}@cityu.edu.hk 
 Abstract 
In this paper, we work on extending a 
Chinese thesaurus with words distinctly 
used in various Chinese communities.  
The acquisition and classification of such 
region-specific lexical items is an impor-
tant step toward the larger goal of con-
structing a Pan-Chinese lexical resource.  
In particular, we extend a previous study 
in three respects: (1) to improve auto-
matic classification by removing dupli-
cated words from the thesaurus, (2) to 
experiment with classifying words at the 
subclass level and semantic head level, 
and (3) to further investigate the possible 
effects of data heterogeneity between the 
region-specific words and words in the 
thesaurus on classification performance.  
Automatic classification was based on 
the similarity between a target word and 
individual categories of words in the the-
saurus, measured by the cosine function.  
Experiments were done on 120 target 
words from four regions.  The automatic 
classification results were evaluated 
against a gold standard obtained from 
human judgements.  In general accuracy 
reached 80% or more with the top 10 (out 
of 80+) and top 100 (out of 1,300+) can-
didates considered at the subclass level 
and semantic head level respectively, 
provided that the appropriate data sources 
were used. 
                                                 
? 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
 
1 Introduction 
A unique problem in Chinese language process-
ing arises from the extensive lexical variations 
among major Chinese speech communities.  Al-
though different communities (e.g. Beijing, Hong 
Kong, Taipei and Singapore) often share a large 
core lexicon, lexical variations could occur in at 
least two ways.  On the one hand, even the same 
word forms shared by various communities could 
be used with different meanings.  For instance, 
the word?? (ju1wu1)1 refers to general hous-
ing in Mainland China but specifically to housing 
under the Home Ownership Scheme in Hong 
Kong.  On the other hand, there are substantially 
different lexical items used for lexicalizing 
common or region-specific concepts.  For exam-
ple, while the word ?? (zhu4fang2) is similarly 
used as ??  to mean general housing in 
Mainland China, it is rarely seen in the Hong 
Kong context; and ?? (xia4gang3) is specific, 
if not exclusive, to Mainland China for referring 
to a special concept of unemployment. 
Existing Chinese lexical resources are often 
based on language use in one particular region 
and are therefore not comprehensive enough to 
capture the substantial regional variation as an 
important part of the lexical knowledge, which 
will be useful and critical for many NLP applica-
tions, including natural language understanding, 
information retrieval, and machine translation. 
Tsou and Kwong (2006) proposed a compre-
hensive Pan-Chinese lexical resource, using a 
large and unique synchronous Chinese corpus as 
an authentic source of lexical variation among 
various Chinese speech communities.  They also 
studied the feasibility of taking an existing Chi-
nese thesaurus as leverage and classifying new 
words from various Chinese communities with 
respect to the classificatory structure therein 
(Kwong and Tsou, 2007).  They used the catego-
                                                 
1 The transcriptions in brackets are based on Hanyu Pinyin. 
457
ries at the subclass level of the Tongyici Cilin (?
????, abbreviated as Cilin hereafter) for the 
task.  The classification was done by comparing 
the similarity of a target word (i.e. the word to be 
classified) and individual categories of words in 
the thesaurus based on a feature vector of co-
occurring words in a corpus.  Since words in the 
thesaurus are mostly based on lexical items used 
in Mainland China, and the target words come 
from various Chinese communities, a major issue 
in the classification task is thus the heterogeneity 
of the data sources.  It was hypothesized that the 
datasets from which the features were extracted 
(for the target words and words in the thesaurus 
respectively) may affect the performance of 
automatic classification.  The experimental re-
sults supported the hypothesis in part, and the 
actual effect varied with datasets from individual 
regions.  Moreover, there is room to improve the 
overall accuracy for the method to be useful in 
practice, and it appears that the duplicated words 
in the thesaurus might have skewed the similarity 
measurement to a certain extent. 
The current study thus attempts to extend this 
previous study in three respects: (1) to improve 
automatic classification by removing duplicated 
words from the thesaurus, (2) to experiment with 
classifying words at the subclass level and se-
mantic head level (a finer level), and (3) to fur-
ther investigate the possible effects of data het-
erogeneity between the region-specific words 
and words in the thesaurus on classification per-
formance. 
In Section 2, we will briefly review related 
work and the background of the current study.  In 
Sections 3 and 4, we will describe the materials 
used and the experimental setup respectively.  
Results will be presented in Section 5 and dis-
cussed in Section 6, followed by a conclusion in 
Section 7. 
2 Related Work 
To build a semantic lexicon, one has to identify 
the relation between words within a semantic 
hierarchy, and to group similar words together 
into a class.  Previous work on automatic meth-
ods for building semantic lexicons could be di-
vided into two main groups.  One is automatic 
thesaurus acquisition, that is, to identify syno-
nyms or topically related words from corpora 
based on various measures of similarity (e.g. 
Riloff and Shepherd, 1997; Lin, 1998; Caraballo, 
1999; Thelen and Riloff, 2002; You and Chen, 
2006).  
Another line of research, which is more 
closely related to the current study, is to extend 
existing thesauri by classifying new words with 
respect to their given structures (e.g. Tokunaga et 
al., 1997; Pekar, 2004).  An early effort along 
this line is Hearst (1992), who attempted to iden-
tify hyponyms from large text corpora, based on 
a set of lexico-syntactic patterns, to augment and 
critique the content of WordNet.  Ciaramita 
(2002) compared several models in classifying 
nouns with respect to a simplified version of 
WordNet and signified the gain in performance 
with morphological features.  For Chinese, Tseng 
(2003) proposed a method based on morphologi-
cal similarity to assign a Cilin category to un-
known words from the Sinica corpus which were 
not in the Chinese Electronic Dictionary and 
Cilin; but somehow the test data were taken from 
Cilin, and therefore could not really demonstrate 
the effectiveness with unknown words found in 
the Sinica corpus. 
Kwong and Tsou (2007) attempted to classify 
words distinctly used in Beijing, Hong Kong, 
Singapore, and Taiwan, with respect to the Cilin 
classificatory structure.  They brought up the is-
sue of data heterogeneity in the task.  In general, 
automatic classification of words via similarity 
measurement between two words, or between a 
word and a class of words, was often done on 
words from a similar data source, with the as-
sumption that the feature vectors under compari-
son are directly comparable.  In the Pan-Chinese 
context, however, the words to be classified 
come from corpora collected from various Chi-
nese speech communities, but the words in the 
thesaurus are often based on usages found in a 
particular community, such as Mainland China in 
the case of Cilin.  It is thus questionable whether 
the words in Cilin would appear in comparable 
contexts in texts from other places, thus affecting 
the similarity measurement.  In view of this het-
erogeneous nature of the data, they experimented 
with extracting feature vectors for the Cilin 
words from different datasets and found that the 
classification of words from Taipei was most 
affected in this regard. 
In general, up to 85% accuracy was reached 
with the top 15 candidates for classification at 
the Cilin subclass level.  This performance, how-
ever, should be improved for the method to be 
useful in practice.  It is observed that Cilin, as 
most other thesauri, does not have a mutually 
exclusive classification.  Many words appear in 
more than one category (at various levels).  Such 
duplication may affect the similarity comparison 
458
between a target word and words in a category.  
The current study thus attempts to avoid this con-
founding factor by removing duplicated words 
from Cilin for the comparison of similarity, and 
to extend the classification to a finer level. 
3 Materials 
3.1 The Tongyici Cilin 
The Tongyici Cilin (?????) (Mei et al, 
1984) is a Chinese synonym dictionary, or more 
often known as a Chinese thesaurus in the tradi-
tion of the Roget?s Thesaurus for English.  The 
Roget?s Thesaurus has about 1,000 numbered 
semantic heads, more generally grouped under 
higher level semantic classes and subclasses, and 
more specifically differentiated into paragraphs 
and semicolon-separated word groups.  Similarly, 
some 70,000 Chinese lexical items are organized 
into a hierarchy of broad conceptual categories in 
Cilin.  Its classification consists of 12 top-level 
semantic classes, 94 subclasses, 1,428 semantic 
heads and 3,925 paragraphs.  It was first pub-
lished in the 1980s and was based on lexical us-
ages mostly of post-1949 Mainland China.  In the 
current study, we will focus on the subclass level 
and semantic head level.  Some example sub-
classes and semantic heads are shown in Table 1. 
We classify words with respect to the subclass 
level and semantic head level (that is, second and 
third levels in the Cilin organisation).  Moreover, 
we skip class K and class L as the former con-
tains mostly function words and the latter longer 
expressions.  We are thus considering 88 sub-
classes and 1,356 semantic heads in this study. 
Within classes A to J, there are 7,517 words 
which were found to appear in more than one 
category.  Upon removing these entries, 44,588 
words were used in the similarity comparison for 
the current study.  
 
 
Class Subclasses Semantic Heads 
A ? (Human) Aa ? Ae ?? (Occupation)  Af?? 
(Identity) ? An 
Aa01 ? Ae10 ?? ?? ?? ?? (com-
mander, soldier) ? An07 
B ? (Things) Ba ? Bb ??? (Shape) ? Bi ?? 
(Animal)? Bm ?? (Material)?Bq ?? 
(Clothing) ? Br 
Ba01 ? Bm08 ? ? (coal, carbon) ? Bn03 
?? (room) ? Br14 
C ????? (Time and 
Space) 
Ca ?? (Time)  Cb ?? (Space) Ca01 ? Ca18 ? (year) ? Cb28 ?? (loca-
tion) ? Cb30 
D ???? 
(Abstract entities) 
Da ?? ?? (Condition) ? Df ?? (Ide-
ology) ? Di ?? ?? (Society) Dj ?? 
(Economics) ? Dm ?? (Organization) 
Dn ?? ?? (Quantity) 
Da01 ? Di10 ?? ?? (group, party) ? 
Dj04 ?? ?? ?? ?? (capital, interest)  
Dj05 ?? ?? (currency, invoice) ? Dm01 
?? (government) ? Dn10 
E ?? 
(Characteristics) 
Ea ? Ed ?? (Property)? Ef Ea01 ? Ed03 ? ? (goodness, badness) ? 
Ef14 
F ?? (Action) Fa ? Fd ???? (Body action) Fa01 ? Fb01 ? ? (run) ? Fd09 
G ???? (Psycho-
logical activities) 
Ga ? Gb ???? (Psychological activi-
ties)? Gc 
Ga01 ? Gb01 ?? ?? ?? ?? (imag-
ine, think) ? Gc04 
H ?? 
(Activities) 
Ha ? He ???? (Economic activi-
ties) ? Hd ?? (Production) ? Hf ??
?? (Transportation) Hg ???? (Scien-
tific research)? Hi ?? (Social contact) 
Hj ?? (Livelihood) 
Ha01 ? Hc09 ?? ?? ?? ?? ?? (in 
charge, administer, lead) ? He03 ? ? (buy, 
sell) ? Hg01 ?? ?? ?? (teach, 
demo) ? Hj12 ? ?? ?? ?? (do, coop-
erate, try) ? Hn13 
I ????? (Phe-
nomenon and state) 
Ia ? If ?? (Circumstance)  Ig ?? 
(Process)? Ih 
Ia01 ? Ig01 ?? ?? (begin, end) ? Ih05 
?? ?? ?? (increase, decrease) ? Ih13 
J ?? 
(Association) 
Ja ?? (Liaison)  Jb ?? (Similarity and 
Difference) Jc ?? (Matching) ? Je 
Ja01 ? Jc01 ?? ?? ?? (adapt, 
match) ? Je14 
Table 1  Some Examples of Cilin Subclasses and Semantic Heads 
 
3.2 The LIVAC Synchronous Corpus 
LIVAC (http://www.livac.org) stands for Lin-
guistic Variation in Chinese Speech Communi-
ties.  It is a synchronous corpus developed and 
dynamically maintained by the Language Infor-
mation Sciences Research Centre of the City 
University of Hong Kong since 1995 (Tsou and 
Lai, 2003).  The corpus consists of newspaper 
articles collected regularly and synchronously 
from six Chinese speech communities, namely 
Hong Kong, Beijing, Taipei, Singapore, Shang-
459
hai, and Macau.  Texts collected cover a variety 
of domains, including front page news stories, 
local news, international news, editorials, sports 
news, entertainment news, and financial news.  
Up to December 2007, the corpus has already 
accumulated over 250 million character tokens 
which, upon automatic word segmentation and 
manual verification, yielded about 1.2 million 
word types. 
For the present study, we made use of subcor-
pora consisting of the financial news sections 
collected over the 9-year period 1995-2004 from 
Beijing (BJ), Hong Kong (HK), Singapore (SG), 
and Taipei (TW).  Table 2 shows the sizes of the 
subcorpora. 
 
Region Size of Financial Subcorpus 
(rounded to nearest 1K) 
 Word Token Word Type 
BJ 232K 20K 
HK 970K 38K 
SG 621K 28K 
TW 254K 22K 
Table 2  Sizes of Individual Subcorpora 
 
3.3 Test Data 
Kwong and Tsou (2006) observed that among the 
unique lexical items found from the individual 
subcorpora, only about 30-40% are covered by 
Cilin, but not necessarily in the expected senses.  
In other words, Cilin could in fact be enriched 
with over 60% of the unique items from various 
regions. 
In the current study, we sampled the most fre-
quent 30 words distinctly and predominantly 
used in each of the BJ, HK, SG, and TW subcor-
pus.  Classification was based on their similarity 
with each of the Cilin subclasses and semantic 
heads, compared by the cosine measure, as dis-
cussed in Section 4.2. 
4 Experiments 
4.1 Setting the Gold Standard 
Three linguistics undergraduate students and one 
research student on computational linguistics 
from the City University of Hong Kong were 
asked to assign what they would consider to be 
the most appropriate Cilin category (at the sub-
class and semantic head level) to each of the 120 
target words. 
All human judges reported difficulties in vari-
ous degrees in assigning Cilin categories to the 
target words.  The major problem came from the 
regional specificity and thus the unfamiliarity of 
the judges with the respective lexical items and 
contexts.  For example, all judges reported prob-
lem with the term ?? (zi4cuo1), one of the tar-
get words from Singapore referring to ???? 
(zi4cuo1gu3shi4, CLOB in the Singaporean 
stock market), which is specific to Singapore. 
Notwithstanding the difficulty, the inter-
annotator agreement, as measured by Kappa, was 
found to be 0.6870 at the subclass level and 
0.5971 at the semantic head level. 
We took a ?loose? approach to form the gold 
standard, which includes all categories (at the 
subclass level and semantic head level respec-
tively) assigned by one or more judges.  Auto-
matic classification will be considered ?correct? 
if any of these categories is matched. 
4.2 Automatic Classification 
Each target word was compared to all Cilin cate-
gories and automatically classified to the cate-
gory which is most similar to it.  The Cilin data 
was first pre-processed to remove duplicated 
words. 
We compute the similarity by the cosine be-
tween the two corresponding feature vectors con-
taining all co-occurring content words in a cor-
pus within a window of ?5 words (excluding 
many general adjectives and adverbs, and num-
bers and proper names were all ignored).  The 
feature vector of a Cilin category is based on the 
union of the features from all individual mem-
bers in the category. 
The cosine of two feature vectors vv  and wv  is 
computed as 
 
wv
wvwv vv
vvvv ?=),cos(  
 
The feature vector of a given target word is 
extracted from the respective subcorpus from 
which the target word was found (called the tar-
get subcorpus hereafter).  To study the data het-
erogeneity effect, we experimented with two 
conditions for the extraction of feature vectors 
for Cilin words: from the target subcorpus or 
from the BJ subcorpus which is assumed to be 
representative of usages in Mainland China. 
All automatic classification results were 
evaluated against the gold standard based on hu-
460
Sub-tw-tw
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N Candidates
Ac
cu
ra
cy
 (%
)
Baseline With Duplicates No Duplicates
Sub-hk-hk
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N Candidates
Ac
cu
ra
cy
 (%
)
Baseline With Duplicates No Duplicates
Sub-sg-sg
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N Candidates
Ac
cu
ra
cy
 (%
)
Baseline With Duplicates No Duplicates
Sub-bj-bj
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N Candidates
Ac
cu
ra
cy
 (%
)
Baseline With Duplicates No Duplicates
Sub-bj-bj
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N Candidates
Ac
cu
ra
cy
 (%
)
Baseline Sub-bj-bj
Sub-tw-tw and Sub-tw-bj
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N Candidates
Ac
cu
ra
cy
 (%
)
Baseline Sub-tw-tw Sub-tw-bj
Sub-hk-hk and Sub-hk-bj
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N Candidates
Ac
cu
ra
cy
 (%
)
Baseline Sub-hk-hk Sub-hk-bj
Sub-sg-sg and Sub-sg-bj
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N Candidates
Ac
cu
ra
cy
 (%
)
Baseline Sub-sg-sg Sub-sg-bj
man judgements as discussed in Section 4.1.  
Classification performance is measured based on 
the correctness of the top N candidates. 
4.3 Baseline 
A simple baseline measure was obtained by rank-
ing the subclasses in descending order of the 
number of words they cover.  It was assumed 
that the bigger the subclass size, the more likely 
it covers a new term.  The top N candidates in 
this ranking were checked against the gold stan-
dard as above. 
5 Results 
In the following discussion, we will use labels in 
the form of <Cat>-<Target>-<CilinFeatSource> 
to refer to the various testing conditions, where 
Cat refers to the category type, Target to the 
originating source of the target words, and Cilin-
FeatSource to the source from which the feature 
vectors for the Cilin words were extracted.  Thus 
the label Sub-hk-hk means classification of HK 
target words at the Cilin subclass level, with fea-
ture vectors for target words and Cilin words ex-
tracted from the HK subcorpus; and the label 
Head-tw-bj means classification of TW target 
words at the Cilin semantic head level, with fea-
ture vectors for the target words extracted from 
the TW subcorpus and those for the Cilin words 
extracted from the BJ subcorpus. 
5.1 Pre-processing of Cilin 
Figure 1 shows the comparison of classification 
accuracy for words from the four regions at the 
subclass level before and after duplicates in Cilin 
were removed.  All feature vectors were ex-
tracted from the respective target corpora. 
 
Figure 1  Effect of Pre-processing Cilin 
It can be seen from Figure 1 that removing 
duplicated words in Cilin could improve the clas-
sification of words from all regions at the sub-
class level. 
5.2 Data Heterogeneity Effect 
As explained earlier, since the words to be classi-
fied come from various Chinese speech commu-
nities, but the words in Cilin are mostly based on 
usages found in Mainland China, it is uncertain 
whether the words in Cilin would appear in com-
parable contexts in texts from other places, for 
the similarity measurement to be effective.  
Hence, we experimented with two conditions for 
extracting feature vectors for the Cilin words.  
While the features for a target word to be classi-
fied are extracted from the respective target sub-
corpus, the features for the Cilin words are ex-
tracted either from the target subcorpus or from 
the BJ subcorpus.  Figure 2 shows the data het-
erogeneity effect on the classification of target 
words from various regions at the subclass level.  
 
Figure 2  Data Heterogeneity Effect 
 
The data heterogeneity effect is most notice-
able for the TW words.  Extracting features for 
the Cilin words from the BJ subcorpus always 
gives better classification results for the TW 
words, than if the features were extracted from 
the TW subcorpus.  The difference between Sub-
hk-hk and Sub-hk-bj, and that between Sub-sg-sg 
and Sub-sg-bj, however, is not as great.  This 
suggests that the lexical difference is particularly 
significant between BJ and TW. 
5.3 Fine-grainedness of Classification 
The semantic head level is more fine-grained 
than the subclass level, and is expected to be 
461
Head-bj-bj
0
10
20
30
40
50
60
70
80
90
100
0 10 20 30 40 50 60 70 80 90 100 110
Top N Candidates
Ac
cu
ra
cy
 (%
)
Head-bj-bj
Head-tw-tw and Head-tw-bj
0
10
20
30
40
50
60
70
80
90
100
0 10 20 30 40 50 60 70 80 90 100 110
Top N Candidates
Ac
cu
ra
cy
 (%
)
Head-tw-tw Head-tw-bj
Head-hk-hk and Head-hk-bj
0
10
20
30
40
50
60
70
80
90
100
0 10 20 30 40 50 60 70 80 90 100 110
Top N Candidates
Ac
cu
ra
cy
 (%
)
Head-hk-hk Head-hk-bj
Head-sg-sg and Head-sg-bj
0
10
20
30
40
50
60
70
80
90
100
0 10 20 30 40 50 60 70 80 90 100 110
Top N Candidates
Ac
cu
ra
cy
 (%
)
Head-sg-sg Head-sg-bj
more difficult for classification.  Figure 3 shows 
the results of classification at the semantic head 
level, with the effect of data heterogeneity. 
 
Figure 3  Semantic Head Level Classification 
 
It is observed from Figures 2 and 3 that data 
heterogeneity affects the classification of TW 
words at both the subclass and semantic head 
level.  In both cases, features for Cilin words ex-
tracted from BJ subcorpus work better than those 
from TW subcorpus.  A somewhat opposite ef-
fect was observed for SG target words, especially 
beyond the top 5 to 10 candidates.  There is not 
much difference for the HK target words. 
The classification at the semantic head level is 
expectedly less precise than that at the subclass 
level.  At the subclass level, 80% or more accu-
racy could be reached with the top 10 candidates 
considered, whereas the top 50 candidates or 
more would be needed to reach a similar level of 
accuracy at the semantic head level.  This is nev-
ertheless encouraging in view of the total number 
of categories at the semantic head level. 
6 Discussions 
6.1 Overall Classification Accuracy 
From the results reported in the last section, it 
can be seen that removing the duplicated words 
in Cilin could help improve the classification 
accuracy at all conditions.  This is because some 
words, which appear in more than one category 
at the subclass or semantic head level, might 
skew the similarity measured between a target 
word and a given category.  An example will be 
discussed in Section 6.3. 
In general, the top 10 candidates could lead to 
over 80% accuracy at the subclass level (much 
improved from previous results before removing 
duplicates in Cilin, where it usually took the top 
15 candidates to reach about 80% accuracy).  At 
the semantic head level, the top 50 candidates 
could lead to over 70% accuracy for HK and TW 
words and to 80% or more for BJ and SG words.  
The accuracy, nevertheless, is also dependent on 
the datasets from which features were extracted, 
as shown in Sections 5.2 and 5.3 above and fur-
ther discussed below. 
6.2 Regional Variation 
The various Chinese speech communities might 
differ not only in the lexical items they use, but 
also in the way they use the lexical items in 
common.  The demand on cross-cultural knowl-
edge thus poses a challenge for building a Pan-
Chinese lexical resource manually.  Cilin, for 
instance, is quite biased in language use in 
Mainland China, and it requires experts with 
knowledge of a wide variety of Chinese terms to 
be able to manually classify lexical items specific 
to other Chinese speech communities.  It is there-
fore even more important to devise robust ways 
for automatic classification of words from vari-
ous regions. 
The data heterogeneity effect is quite different 
for the classification of SG words and TW words, 
but apparently not very significant for HK words.  
Beyond the top 5 to 10 candidates, features ex-
tracted from the SG subcorpus for Cilin words 
seem to have an advantage.  This suggests that 
although the SG subcorpus shares those words in 
Cilin, the context in which they are used might 
be slightly different from their use in Mainland 
China.  Thus extracting their contextual features 
from the SG subcorpus might better reflect their 
usage and make them more comparable with the 
target words from SG.  For the TW words, on the 
contrary, features for Cilin words extracted from 
the BJ subcorpus always have an advantage over 
those extracted from the TW subcorpus.  As 
Kwong and Tsou (2006) observed, Beijing and 
Taipei data share the least number of lexical 
items among the four regions under investigation.  
Words in Cilin therefore might not have the ap-
propriate contextual feature vectors extracted 
from the TW subcorpus. 
6.3 Analysis for Individual Words 
In order to study the actual effect of various ex-
perimental conditions on the classification of 
individual target words, we also worked out the 
change in the ranking (?r) of the correct category 
for each target word.  A negative ?r thus corre-
462
sponds to an improvement in the classification as 
the new ranking of the correct category is smaller 
(earlier) than the old one.  Table 3 shows some 
examples with improvement in this regard.  The 
Rank column refers to the rank of the correct 
category in Sub-{bj,hk,tw,sg}-bj, ?r(D) is the 
change after duplicates were removed from Cilin, 
and ?r(H) is the change from Sub-x-x conditions. 
 
No. Word (Region) Rank ?r(D) ?r(H) 
1 ??? (BJ) 1 -6 - 
2 ??? (BJ) 3 -15 - 
3 ?? (BJ) 1 -1 - 
4 ?? (BJ) 1 -2 - 
5 ?? (BJ) 3 -2 - 
6 ?? (HK) 4 -4 -6 
7 ?? (HK) 2 -3 -6 
8 ??? (HK) 1 -6 -1 
9 ?? (HK) 1 -8 -5 
10 ??  (HK) 2 -4 -5 
11 ?? (SG) 1 -3 -4 
12 ?? (SG) 1 -12 -1 
13 ??? (SG) 1 -3 -1 
14 ??? (SG) 2 -2 -4 
15 ??? (SG) 2 -7 1 
16 ?? (TW) 3 -1 -13 
17 ??? (TW) 2 -3 -7 
18 ?? (TW) 1 0 -3 
19 ?? (TW) 6 -3 -20 
20 ?? (TW) 3 -6 -5 
Table 3  Ranking Change for Individual Words2 
 
Take the example of the BJ target word ??
? (xin4xi1hua4, informationize).  Before dupli-
cated words were removed from Cilin, the most 
appropriate subclass (Ih:Change) ranked 7th in 
the automatic classification.  Upon the removal 
of duplicated words, subclass Ih ranked first in 
the results.  The words shared by other top rank-
ing subclasses (e.g. Je:influence, Da:condition, 
etc.) such as ? (jia1, increase), ? (tui1, push), 
?? (ti2gao1, raise), etc., may have skewed the 
similarity comparison by introducing many 
common co-occurring words which are not par-
ticularly characteristic of any subclass. 
For the TW target word ?? (tou2xin4, in-
vestment trust), the appropriate subclass 
                                                 
2 English gloss: 1-informationize, 2-re-employed, 3-
unemployed, 4-resist drought, 5-quality check, 6-general 
trend of stock market, 7-buy in stocks, 8-H stock, 9-interest 
rate, 10-sell (stocks), 11-Singaporean dollar, 12-Malaysian 
stocks, 13-closing price, 14-rights issue, 15-holding space 
rate, 16-investment trust, 17-growth rate, 18-financial hold-
ings, 19-over-bought, 20-bank. 
(Dm:organization) soared from the 16th to the 
3rd when features were extracted for the Cilin 
words from the BJ subcorpus instead of the TW 
subcorpus.  It was observed that both vectors 
have a large part in common, but the one ex-
tracted from TW subcorpus contained many 
more spurious features which might not be char-
acteristic of the subclass, thus affecting the simi-
larity score. 
It is also apparent that region-specific but 
common concepts like ??? (xie3zi4lou2, of-
fice), ??  (zu3wu1, apartment), and ?? 
(si1zhai2, private residence), etc., are more ad-
versely affected when features for Cilin words 
were extracted from the BJ subcorpus instead of 
the respective target subcorpora, while other 
more core financial concepts could often take 
advantage of the former.  Thus it appears that the 
domain and concept specificity could also affect 
the effectiveness of the method. 
6.4 Future Directions 
There is room to improve the results at both the 
subclass and semantic head level.  More qualita-
tive analysis is needed for the data heterogeneity 
effect.  The category size, and as pointed out 
above, the domain and concept specificity are 
also worth further investigation.  The latter will 
thus involve the classification of words from 
other special domains like sports, as well as those 
from the general domain. 
One problem we need to address in the next 
step is the class imbalance problem as Cilin cate-
gories could differ considerably in size, which 
will affect the number of features and subsequent 
classification.  For this we plan to try the k near-
est neighbours approach.  In addition, the fea-
tures might need to be constrained, as simple co-
occurrence might be too coarse for distinguishing 
the subtle characteristics among Cilin categories. 
7 Conclusion 
We have worked on extending a Chinese thesau-
rus with words distinctly used in various Chinese 
communities.  Classification results have im-
proved as duplicated words in Cilin were re-
moved.  In view of the demand on cross-cultural 
knowledge for building a Pan-Chinese lexical 
resource manually, it is particularly important to 
devise robust ways for automatic acquisition of 
such a resource.  Automatic classification of 
words with respect to an existing classificatory 
structure with proper datasets for feature extrac-
tion should be a prominent direction in this re-
463
gard.  Further investigation is needed to better 
understand the interaction among data heteroge-
neity, category size, feature selection, and the 
domain and concept specificity of the words. 
Acknowledgements 
The work described in this paper was supported 
by a grant from the Research Grants Council of 
the Hong Kong Special Administrative Region, 
China (Project No. CityU 1317/03H).  The au-
thors would like to thank Jingbo Zhu for useful 
discussions on an earlier draft of this paper, and 
the anonymous reviewers for their comments on 
the submission. 
References 
Caraballo, S.A. (1999)  Automatic construction of a 
hypernym-labeled noun hierarchy from text.  In 
Proceedings of the 37th Annual Meeting of the As-
sociation for Computational Linguistics (ACL?99), 
Maryland, USA, pp.120-126. 
Ciaramita, M. (2002)  Boosting automatic lexical ac-
quisition with morphological information.  In Pro-
ceedings of the ACL?02 Workshop on Unsuper-
vised Lexical Acquisition, Philadelphia, USA, 
pp.17-25. 
Hearst, M. (1992)  Automatic Acquisition of Hypo-
nyms from Large Text Corpora.  In Proceedings of 
the 14th International Conference on Computa-
tional Linguistics (COLING-92), Nantes, France, 
pp.539-545. 
Kwong, O.Y. and Tsou, B.K. (2006)  Feasibility of 
Enriching a Chinese Synonym Dictionary with a 
Synchronous Chinese Corpus.  In T. Salakoski, F. 
Ginter, S. Pyysalo and T. Pahikkala (Eds.), Ad-
vances in Natural Language Processing: Proceed-
ings of FinTAL 2006. Lecture Notes in Artificial 
Intelligence, Vol.4139, pp.322-332, Springer-
Verlag. 
Kwong, O.Y. and Tsou, B.K. (2007)  Extending a 
Thesaurus in the Pan-Chinese Context.  In Pro-
ceedings of the 2007 Joint Conference on Empiri-
cal Methods in Natural Language Processing and 
Computational Natural Language Learning 
(EMNLP-CoNLL-2007), Prague, pp.325-333. 
Lin, D. (1998)  Automatic Retrieval and Clustering of 
Similar Words.  In Proceedings of the 36th Annual 
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on 
Computational Linguistics (COLING-ACL?98), 
Montreal, Canada, pp.768-774. 
Mei et al ??????????????? (1984)  
??????? (Tongyici Cilin).  ????? 
(Commercial Press) / ???????. 
Pekar, V. (2004)  Linguistic Preprocessing for Distri-
butional Classification of Words.  In Proceedings 
of the COLING2004 Workshop on Enhancing and 
Using Electronic Dictionaries, Geneva. 
Riloff, E. and Shepherd, J. (1997)  A corpus-based 
approach for building semantic lexicons.  In Pro-
ceedings of the Second Conference on Empirical 
Methods in Natural Language Processing, Provi-
dence, Rhode Island, pp.117-124. 
Thelen, M. and Riloff, E. (2002)  A Bootstrapping 
Method for Learning Semantic Lexicons using Ex-
traction Pattern Contexts.  In Proceedings of the 
2002 Conference on Empirical Methods in Natural 
Language Processing (EMNLP 2002), Philadelphia, 
USA. 
Tokunaga, T., Fujii, A., Iwayama, M., Sakurai, N. and 
Tanaka, H. (1997)  Extending a thesaurus by clas-
sifying words.  In Proceedings of the ACL Work-
shop on Automatic Information Extraction and 
Building of Lexical Semantic Resources for NLP 
Applications, Madrid, pp.16-21. 
Tseng, H. (2003)  Semantic Classification of Chinese 
Unknown Words.  In the Proceedings of the ACL-
2003 Student Research Workshop, Companion 
Volume to the Proceedings of the 41st Annual 
Meeting of the Association for Computational Lin-
guistics, Sapporo, Japan. 
Tsou, B.K. and Kwong, O.Y. (2006)  Toward a Pan-
Chinese Thesaurus.  In Proceedings of the Fifth In-
ternational Conference on Language Resources 
and Evaluation (LREC 2006), Genoa, Italy. 
Tsou, B.K. and Lai, T.B.Y. ??????? (2003)  
????????????.  In B. Xu, M. Sun 
and G. Jin ?????????? (Eds.), ???
???????????  (Issues in Chinese 
Language Processing).  ???????? , 
pp.147-165 
You, J-M. and Chen, K-J. (2006)  Improving Context 
Vector Models by Feature Clustering for Auto-
matic Thesaurus Construction.  In Proceedings of 
the Fifth SIGHAN Workshop on Chinese Language 
Processing, COLING-ACL 2006, Sydney, Austra-
lia, pp.1-8. 
 
 
464
Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 325?333, Prague, June 2007. c?2007 Association for Computational Linguistics
Extending a Thesaurus in the Pan-Chinese Context 
Oi Yee Kwong and Benjamin K. Tsou 
Language Information Sciences Research Centre 
City University of Hong Kong 
Tat Chee Avenue, Kowloon, Hong Kong 
{rlolivia,rlbtsou}@cityu.edu.hk 
 
Abstract 
In this paper, we address a unique problem 
in Chinese language processing and report 
on our study on extending a Chinese the-
saurus with region-specific words, mostly 
from the financial domain, from various 
Chinese speech communities.  With the 
larger goal of automatically constructing a 
Pan-Chinese lexical resource, this work 
aims at taking an existing semantic classi-
ficatory structure as leverage and incorpo-
rating new words into it.  In particular, it is 
important to see if the classification could 
accommodate new words from heterogene-
ous data sources, and whether simple simi-
larity measures and clustering methods 
could cope with such variation.  We use the 
cosine function for similarity and test it on 
automatically classifying 120 target words 
from four regions, using different datasets 
for the extraction of feature vectors.  The 
automatic classification results were evalu-
ated against human judgement, and the per-
formance was encouraging, with accuracy 
reaching over 85% in some cases.  Thus 
while human judgement is not straightfor-
ward and it is difficult to create a Pan-
Chinese lexicon manually, it is observed 
that combining simple clustering methods 
with the appropriate data sources appears 
to be a promising approach toward its 
automatic construction. 
1 Introduction 
Large-scale semantic lexicons are important re-
sources for many natural language processing 
(NLP) tasks.  For a significant world language 
such as Chinese, it is especially critical to capture 
the substantial regional variation as an important 
part of the lexical knowledge, which will be useful 
for many NLP applications, including natural lan-
guage understanding, information retrieval, and 
machine translation.  Existing Chinese lexical re-
sources, however, are often based on language use 
in one particular region and thus lack the desired 
comprehensiveness. 
Toward this end, Tsou and Kwong (2006) pro-
posed a comprehensive Pan-Chinese lexical re-
source, based on a large and unique synchronous 
Chinese corpus as an authentic source for lexical 
acquisition and analysis across various Chinese 
speech communities.  To allow maximum versatil-
ity and portability, it is expected to document the 
core and universal substances of the language on 
the one hand, and also the more subtle variations 
found in different communities on the other.  Dif-
ferent Chinese speech communities might share 
lexical items in the same form but with different 
meanings.  For instance, the word ?? refers to 
general housing in Mainland China but specifically 
to housing under the Home Ownership Scheme in 
Hong Kong; and while the word ?? is similar to 
?? to mean general housing in Mainland China, 
it is rarely seen in the Hong Kong context. 
Hence, the current study aims at taking an exist-
ing Chinese thesaurus, namely the Tongyici Cilin 
????? , as leverage and extending it with 
lexical items specific to individual Chinese speech 
communities.  In particular, the feasibility depends 
on the following issues:  (1) Can lexical items from 
various Chinese speech communities, that is, from 
such heterogeneous sources, be classified as effec-
tively with methods shown to work for clustering 
325
closely related words from presumably the same, 
or homogenous, source?  (2) Could existing se-
mantic classificatory structures accommodate con-
cepts and expressions specific to individual Chi-
nese speech communities? 
Measuring similarity will make sense only if the 
feature vectors of the two words under comparison 
are directly comparable.  There is usually no prob-
lem if both words and their contextual features are 
from the same data source.  Since Tongyici Cilin 
(or simply Cilin hereafter) is based on the vocabu-
lary used in Mainland China, it is not clear how 
often these words will be found in data from other 
places, and even if they are found, how well the 
feature vectors extracted could reflect the expected 
usage or sense.  Our hypothesis is that it will be 
more effective to classify new words from 
Mainland China with respect to Cilin categories, 
than to do the same on new words from regions 
outside Mainland China.  Furthermore, if this hy-
pothesis holds, one would need to consider sepa-
rate mechanisms to cluster heterogeneous region-
specific words in the Pan-Chinese context. 
Thus in the current study we sampled 30 target 
words specific to each of Beijing, Hong Kong, 
Singapore, and Taipei, from the financial domain; 
and used the cosine similarity function to classify 
them into one or more of the semantic categories in 
Cilin.  The automatic classification results were 
compared with a simple baseline method, against 
human judgement as the gold standard.  In general, 
an accuracy of up to 85% could be reached with 
the top 15 candidates considered.  It turns out that 
our hypothesis is supported by the Taipei test data, 
whereas the data heterogeneity effect is less obvi-
ous in Hong Kong and Singapore test data, though 
the effect on individual test items varies. 
In Section 2, we will briefly review related work 
and highlight the innovations of the current study.  
In Sections 3 and 4, we will describe the materials 
used and the experimental setup respectively.  Re-
sults will be presented and discussed with future 
directions in Section 5, followed by a conclusion in 
Section 6. 
2 Related Work 
To build a semantic lexicon, one has to identify the 
relation between words within a semantic 
hierarchy, and to group similar words together into 
a class.  Previous work on automatic methods for 
building semantic lexicons could be divided into 
two main groups.  One is automatic thesaurus 
acquisition, that is, to identify synonyms or 
topically related words from corpora based on 
various measures of similarity (e.g. Riloff and 
Shepherd, 1997; Thelen and Riloff, 2002).  For 
instance, Lin (1998) used dependency relation as 
word features to compute word similarities from 
large corpora, and compared the thesaurus created 
in such a way with WordNet and Roget classes.  
Caraballo (1999) selected head nouns from 
conjunctions and appositives in noun phrases, and 
used the cosine similarity measure with a bottom-
up clustering technique to construct a noun 
hierarchy from text.  Curran and Moens (2002) 
explored a new similarity measure for automatic 
thesaurus extraction which better compromises 
with the speed/performance tradeoff.  You and 
Chen (2006) used a feature clustering method to 
create a thesaurus from a Chinese newspaper 
corpus. 
Another line of research, which is more closely 
related with the current study, is to extend existing 
thesauri by classifying new words with respect to 
their given structures (e.g. Tokunaga et al, 1997; 
Pekar, 2004).  An early effort along this line is 
Hearst (1992), who attempted to identify hypo-
nyms from large text corpora, based on a set of 
lexico-syntactic patterns, to augment and critique 
the content of WordNet.  Ciaramita (2002) com-
pared several models in classifying nouns with re-
spect to a simplified version of WordNet and signi-
fied the gain in performance with morphological 
features.  For Chinese, Tseng (2003) proposed a 
method based on morphological similarity to as-
sign a Cilin category to unknown words from the 
Sinica corpus which were not in the Chinese Elec-
tronic Dictionary and Cilin; but somehow the test 
data were taken from Cilin, and therefore could not 
really demonstrate the effectiveness with unknown 
words found in the Sinica corpus. 
The current work attempts to classify new words 
with an existing thesaural classificatory structure.  
However, the usual practice in past studies is to 
test with a portion of data from the thesaurus itself 
and evaluate the results against the original classi-
fication of those words.  This study is thus differ-
ent in the following ways: (1) The test data (i.e. the 
target words to be classified) were not taken from 
the thesaurus, but extracted from corpora and these 
words were unknown to the thesaurus.  (2) The 
326
target words were not limited to nouns.  (3) Auto-
matic classification results were compared with a 
baseline method and with the manual judgement of 
several linguistics students constituting the gold 
standard.  (4) In view of the heterogeneous nature 
of the Pan-Chinese context, we experimented with 
extracting feature vectors from different datasets. 
3 Materials 
3.1 The Tongyici Cilin 
The Tongyici Cilin (?????) (Mei et al, 1984) 
is a Chinese synonym dictionary, or more often 
known as a Chinese thesaurus in the tradition of 
the Roget?s Thesaurus for English.  The Roget?s 
Thesaurus has about 1,000 numbered semantic 
heads, more generally grouped under higher level 
semantic classes and subclasses, and more 
specifically differentiated into paragraphs and 
semicolon-separated word groups.  Similarly, some 
70,000 Chinese lexical items are organized into a 
hierarchy of broad conceptual categories in Cilin.  
Its classification consists of 12 top-level semantic 
classes, 94 subclasses, 1,428 semantic heads and 
3,925 paragraphs.  It was first published in the 
1980s and was based on lexical usages mostly of 
post-1949 Mainland China.  The Appendix shows 
some example subclasses.  In the following 
discussion, we will mainly refer to the subclass 
level and semantic head level. 
3.2 The LIVAC Synchronous Corpus 
LIVAC (http://www.livac.org) stands for Linguis-
tic Variation in Chinese Speech Communities.  It is 
a synchronous corpus developed and dynamically 
maintained by the Language Information Sciences 
Research Centre of the City University of Hong 
Kong since 1995 (Tsou and Lai, 2003).  The cor-
pus consists of newspaper articles collected regu-
larly and synchronously from six Chinese speech 
communities, namely Hong Kong, Beijing, Taipei, 
Singapore, Shanghai, and Macau.  Texts collected 
cover a variety of domains, including front page 
news stories, local news, international news, edito-
rials, sports news, entertainment news, and finan-
cial news.  Up to December 2006, the corpus has 
already accumulated over 200 million character 
tokens which, upon automatic word segmentation 
and manual verification, amount to over 1.2 mil-
lion word types. 
For the present study, we made use of the sub-
corpora collected over the 9-year period 1995-2004 
from Beijing (BJ), Hong Kong (HK), Singapore 
(SG), and Taipei (TW).  In particular, we made use 
of the financial news sections in these subcorpora, 
from which we extracted feature vectors for com-
paring similarity between a given target word and a 
thesaurus class, which is further explained in Sec-
tion 4.3.  Table 1 shows the sizes of the subcorpora. 
3.3 Test Data 
Instead of using a portion of Cilin as the test data, 
we extracted unique lexical items from the various 
subcorpora above, and classified them with respect 
to the Cilin classification. 
Kwong and Tsou (2006) observed that among 
the unique lexical items found from the individual 
subcorpora, only about 30-40% are covered by 
Cilin, but not necessarily in the expected senses.  
In other words, Cilin could in fact be enriched with 
over 60% of the unique items from various regions. 
In the current study, we sampled the most fre-
quent 30 words from each of these unique item 
lists for testing.  Classification was based on their 
similarity with each of the Cilin subclasses, com-
pared by the cosine measure, as discussed in Sec-
tion 4.3. 
 
 
Subcorpus Size of Financial News Sections 
(rounded to nearest 1K) 
 Word Token Word Type 
BJ 232K 20K 
HK 970K 38K 
SG 621K 28K 
TW 254K 22K 
Table 1  Sizes of Individual Subcorpora 
 
4 Experiments 
4.1 Human Judgement 
Three undergraduate linguistics students and one 
research student on computational linguistics from 
the City University of Hong Kong were asked to 
do the task.  The undergraduate students were 
raised in Hong Kong and the research student in 
Mainland China.  They were asked to assign what 
they consider the most appropriate Cilin category 
(up to the semantic head level, i.e. third level in the 
327
Cilin structure) to each of the 120 target words.  
The inter-annotator agreement was measured by 
the Kappa statistic (Siegel and Castellan, 1988), at 
both the subclass and semantic head levels.  Re-
sults on the human judgement are discussed in Sec-
tion 5.1. 
4.2 Creating Gold Standard 
The ?gold standard? was set at both the subclass 
level and semantic head level.  For each level, we 
formed a ?strict? standard for which we considered 
all categories assigned by at least two judges to a 
word; and a ?loose? standard for which we consid-
ered all categories assigned by one or more judges.  
For evaluating the automatic classification in this 
study, however, we only experimented with the 
loose standard at the subclass level. 
4.3 Automatic Classification 
Each target word was automatically classified with 
respect to the Cilin subclasses based on the similar-
ity between the target word and each subclass. 
We compute the similarity by the cosine be-
tween the two corresponding feature vectors.  The 
feature vector of a given target word contains all 
its co-occurring content words in the corpus within 
a window of ?5 words (excluding many general 
adjectives and adverbs, and numbers and proper 
names were all ignored).  The feature vector of a 
Cilin subclass is based on the union of the features 
(i.e. co-occurring words in the corpus) from all 
individual members in the subclass. 
The cosine of two feature vectors is computed as 
 
wv
wvwv vv
vvvv ?=),cos(  
 
In view of the difference in the feature space of a 
target word and a whole class of words, and thus 
the potential difference in the number of occur-
rence of individual features, we experimented with 
two versions of the cosine measurement, namely 
binary vectors and real-valued vectors. 
In addition, as mentioned in previous sections, 
we also experimented with the following condi-
tions: whether feature vectors for the Cilin sub-
classes were extracted from the subcorpus where a 
given target word originates, or from the Beijing 
subcorpus which is assumed to be representative of 
language use in Mainland China.  All automatic 
classification results were evaluated against the 
gold standard based on human judgement. 
4.4 Baseline 
To evaluate the effectiveness of the automatic clas-
sification, we adopted a simple baseline measure 
by ranking the 94 subclasses in descending order 
of the number of words they cover.  In other words, 
assuming the bigger the subclass size, the more 
likely it covers a new term, thus we compared the 
top-ranking subclasses with the classifications ob-
tained from the automatic method using the cosine 
measure. 
5 Results and Discussion 
5.1 Response from Human Judges 
All human judges reported difficulties in various 
degrees in assigning Cilin categories to the target 
words.  The major problem comes from the re-
gional specificity and thus the unfamiliarity of the 
judges with the respective lexical items and con-
texts.  For instance, students grown up in Hong 
Kong were most familiar with the Hong Kong data, 
and slightly less so with the Beijing data, but more 
often had the least ideas for the Taipei and Singa-
pore data.  The research student from Mainland 
China had no problem with Beijing data and the 
lexical items in Cilin, but had a hard time figuring 
out the meaning for words from Hong Kong, 
Taipei and Singapore.  For example, all judges re-
ported problem with the term ??, one of the tar-
get words from Singapore referring to ???? 
(CLOB in the Singaporean stock market), which is 
really specific to Singapore. 
The demand on cross-cultural knowledge thus 
poses a challenge for building a Pan-Chinese 
lexical resource manually.  Cilin, for instance, is 
quite biased in language use in Mainland China, 
and it requires experts with knowledge of a wide 
variety of Chinese terms to be able to manually 
classify lexical items specific to other Chinese 
speech communities.  It is therefore even more 
important to devise robust ways for automatic 
acquisition of such a resource. 
Notwithstanding the difficulty, the inter-
annotator agreement was quite satisfactory.  At the 
subclass level, we found K=0.6870.  At the seman-
tic head level, we found K=0.5971.  Both figures 
are statistically significant. 
328
5.2 Gold Standard 
As mentioned, we set up a loose standard and a 
strict standard at both the subclass and semantic 
head level.  In general, the judges managed to 
reach some consensus in all cases, except for two 
words from Singapore.  For these two cases, we 
considered all categories assigned by any of the 
judges for both standards. 
The gold standards were verified by the authors.  
Although in several cases the judges did not reach 
complete agreement with one another, we found 
that their decisions reflected various possible per-
spectives to classify a given word with respect to 
the Cilin classification; and the judges? assign-
ments, albeit varied, were nevertheless reasonable 
in one way or another. 
5.3 Evaluating Automatic Classification 
In the following discussion, we will refer to the 
various testing conditions for each group of target 
words with labels in the form of Cos-<Vector 
Type>-<Target Words>-<Cilin Feature Source>.  
Thus the label Cos-Bin-hk-hk means testing on 
Hong Kong target words with binary vectors and 
extracting features for the Cilin words from the 
Hong Kong subcorpus; and the label Cos-RV-sg-bj 
means testing on Singapore target words with real-
valued vectors and extracting features for the Cilin 
words from the Beijing subcorpus.  For each target 
word, we evaluated the automatic classification 
(and the baseline ranking) by matching the human 
decisions with the top N candidates.  If any of the 
categories suggested by the human judges is cov-
ered, the automatic classification is considered ac-
curate.  The results are shown in Figure 1 for test 
data from individual regions. 
Overall speaking, the results are very encourag-
ing, especially in view of the number of categories 
(over 90) we have at the subclass level.  An accu-
racy of 80% or more is obtained in general if the 
top 15 candidates were considered, which is much 
higher than the baseline result in all cases.  Table 2 
shows some examples with appropriate classifica-
tion within the Top 3 candidates.  The two-letter 
codes in the ?Top 3? column in Table 2 refer to the 
subclass labels, and the code in bold is the one 
matching human judgement. 
In terms of the difference between binary vec-
tors and real-valued vectors in the similarity meas-
urement, the latter almost always gave better re-
sults.  This was not surprising as we expected by 
using real-valued vectors we could be less affected 
by the potential huge difference in the feature 
space and the number of occurrence of the features 
for a Cilin subclass and a target word. 
As for extracting features for Cilin subclasses 
from the Beijing subcorpus or other subcorpora, 
the difference is more obvious for the Singapore 
and Taipei target words.  We will discuss the re-
sults for each group of target words in detail below. 
5.4  Performance on Individual Sources 
Target words from Beijing were expected to have a 
relatively higher accuracy because they are ho-
mogenous with the Cilin content.  It turned out, 
however, the accuracy only reached 73% with top 
15 candidates and 83% with top 20 candidates 
even under the Cos-RV-bj-bj condition.  Words 
like ?? (SARS), ?? (save water), ??? (in-
dustrialize / industrialization), ??? (passing rate) 
and ?? (multi-level marketing) could not be suc-
cessfully classified. 
Results were surprisingly good for target words 
from the Hong Kong subcorpus.  Under the Cos-
RV-hk-hk condition, the accuracy was 87% with 
top 15 candidates and even over 95% with top 20 
candidates considered.  Apart from this high accu-
racy, another unexpected observation is the lack of 
significant difference between Cos-RV-hk-hk and 
Cos-RV-hk-bj.  One possible reason is that the 
relatively larger size of the Hong Kong subcorpus 
might have allowed enough features to be ex-
tracted even for the Cilin words.  Nevertheless, the 
similar results from the two conditions might also 
suggest that the context in which Cilin words are 
used might be relatively similar in the Hong Kong 
subcorpus and the Beijing subcorpus, as compared 
with other communities.  
Similar trends were observed from the Singa-
pore target words.  Looking at Cos-RV-sg-sg and 
Cos-RV-sg-bj, it appears that extracting feature 
vectors for the Cilin words from the Singapore 
subcorpus leads to better performance than extract-
ing them from the Beijing subcorpus.  It suggests 
that although the Singapore subcorpus shares those 
words in Cilin, the context in which they are used 
might be slightly different from their use in 
Mainland China.  Thus extracting their contextual 
features from the Singapore subcorpus might better 
reflect their usage and makes it more comparable 
329
Classification Accuracy for HK Data
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N
Acc %
Cos-Bin-hk Cos-Bin-bj Cos-RV-hk Cos-RV-bj Baseline
Classification Accuracy for BJ Data
0
10
20
30
40
50
60
70
80
0 5 10 15
Top N
Acc %
Cos-Bin Cos-RV Baseline
`
Classification Accuracy for SG Data
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N
Acc %
Cos-Bin-sg Cos-Bin-bj Cos-RV-sg Cos-RV-bj Baseline
Classification Accuracy for TW Data
0
10
20
30
40
50
60
70
80
90
100
0 5 10 15
Top N
Acc %
Cos-Bin-tw Cos-Bin-bj Cos-RV-tw Cos-RV-bj Baseline
with the unique target words from Singapore.  
Such possible difference in contextual features 
with shared lexical items between different Chi-
nese speech communities would require further 
investigation, and will form part of our future work 
as discussed below.  Despite the above observation 
from the accuracy figures, the actual effect, how-
ever, seems to vary on individual lexical items.  
Table 3 shows some examples of target words 
which received similar (with white cells) and very 
different (with shaded cells) classification respec-
tively under the two conditions.  It appears that the 
region-specific but common concepts like ??? 
(office), ??  (apartment), ??  (private resi-
dence), which relate to building or housing, were 
affected most. 
Taipei data, on the contrary, seems to be more 
affected by the different testing conditions.  Cos-
Bin-tw-bj and Cos-RV-tw-bj produced similar re-
sults, and both conditions showed better results 
than Cos-RV-tw-tw.  This supports our hypothesis 
that the effect of data heterogeneity is so apparent 
that it is much harder to classify target words 
unique to Taipei with respect to the Cilin catego-
ries.  In addition, as Kwong and Tsou (2006) ob-
served, Beijing and Taipei data share the least 
number of lexical items, among the four regions 
under investigation.  Hence, words in Cilin might 
not have the appropriate contextual feature vectors 
extracted from the Taipei subcorpus. 
The different results for individual regions 
might be partly due to the endocentric and exocen-
tric nature of influence in lexical innovation (e.g. 
Tsou, 2001) especially with respect to the financial 
domain and the history of capitalism in individual 
regions.  This factor is worth further investigation. 
 
 
 
Figure 1  Classification Results with Top N Candidates 
 
330
No. Region Word Top 3 
1 BJ ???? Di  Gb  Df 
2 BJ ?? Bq  Ae  Hd 
3 BJ ?? Bm  Hi  Hd 
4 BJ ?? Hj  Di  Hd 
5 BJ ?? Aa  If  Ae 
6 HK ?? Da  Cb  Bi 
7 HK ?? Bb  Jc  Hi 
8 HK ?? Dj  Da  Hi 
9 HK ?? Bi  Dj  Dn 
10 HK ??? Bi  Dj  Gb 
11 SG ?? Ca  Dm  Hi 
12 SG ?? Ig  He  Dj 
13 SG ?? Dm  Dj  Hi 
14 SG ?? Dm  Dj  He 
15 SG ?? Hi  Hg  Af 
16 TW ?? Dm  Hd  Hi 
17 TW ?? Jb  Dn  Dj 
18 TW ?? Ja  Ca  He 
19 TW ??? Hf  Dj  Dm 
20 TW ?? Dj  Ed  Ca 
Table 2  Examples of Correct Classification (Top 3)1 
  
5.5 General Discussions and Future Work 
As mentioned in a previous section, the test data in 
this study were not taken from the thesaurus itself, 
but were unknown words to the thesaurus.  They 
were extracted from corpora, and were not limited 
to nouns.  We found in this study that the simple 
cosine measure, which used to be applied for clus-
tering contextually similar words from homoge-
nous sources, performs quite well in general for 
classifying these unseen words with respect to the 
Cilin subclasses.  The automatic classification re-
sults were compared with the manual judgement of 
several linguistics students.  In addition to provid-
ing a gold standard for evaluating the automatic 
classification results in this study, the human 
                                                 
1 English gloss: 1-restoring agricultural lands for affore-
station, 2-material, 3-coal mine, 4-to seize (an opportu-
nity), 5-unemployed, 6-sales performance, 7-broadband, 
8-red chip, 9-interest rate, 10-property stocks, 11-
financial year, 12-sell short, 13-proposal, 14-sell, 15-
brigadier general, 16-financial holdings, 17-individual 
stocks, 18-property market, 19-cash card, 20-stub. 
judgement on the one hand proves that the Cilin 
classificatory structure could accommodate region-
specific lexical items; but on the other hand also 
suggests how difficult it would be to construct such 
a Pan-Chinese lexicon manually as rich cultural 
and linguistic knowledge would be required.  
Moreover, we started with Cilin as the established 
semantic classification and attempted to classify 
words specific to Beijing, Hong Kong, Singapore, 
and Taipei respectively.  The heterogeneity of 
sources did not seem to hamper the similarity 
measure on the whole, provided appropriate data-
sets are used for feature extraction, although the 
actual effect seemed to vary on individual lexical 
items. 
 
No. Source Word Ranking of 
1st appropriate class 
   Cos-RV-hk-hk, 
etc. 
Cos-RV-hk-bj, 
etc. 
1 HK ?? 1 1 
2 HK ?? 1 1 
3 HK ?? 1 1 
4 HK ?? 2 10 
5 HK ?? 19 5 
6 HK ??? 13 30 
7 SG ??? 2 2 
8 SG ?? 2 1 
9 SG ??? 5 4 
10 SG ?? 1 12 
11 SG ??? 1 9 
12 SG ?? 8 26 
13 TW ?? 1 1 
14 TW ?? 4 3 
15 TW ?? 5 1 
16 TW ?? 18 4 
17 TW ??? 12 5 
18 TW ??? 8 2 
Table 3  Different Impact on Individual Items2 
 
Despite the encouraging results with the top 15 
candidates in the current study, it is desirable to 
improve the accuracy for the system to be useful in 
                                                 
2 English gloss: 1-sales performance, 2-broadband, 3-
red chip, 4-add (supply to market), 5-low level, 6-office, 
7-financial year, 8-sell short, 9-rights issue, 10-
apartment, 11-holding space rate, 12-private residence, 
13-stub, 14-individual stocks, 15-financial holdings, 16-
investment trust, 17-growth rate, 18-cash card. 
331
practice.  Hence our next step is to expand the test 
data size and to explore alternative methods such 
as using a nearest neighbour approach.  In addition, 
we plan to further the investigation in the follow-
ing directions.  First, we will experiment with the 
automatic classification at the Cilin semantic head 
level, which is much more fine-grained than the 
subclasses.  The fine-grainedness might make the 
task more difficult, but at the same time the more 
specialized grouping might pose less ambiguity for 
classification.  Second, we will further experiment 
with classifying words from other special domains 
like sports, as well as the general domain.  Third, 
we will study the classification in terms of the part-
of-speech of the target words, and their respective 
requirements on the kinds of features which give 
best classification performance. 
The current study only dealt with presumably 
Modern Standard Chinese in different communities, 
and it could potentially be expanded to handle 
various dialects within a common resource, even-
tually benefiting speech lexicons and applications 
at large. 
6 Conclusion 
In this paper, we have reported our study on a 
unique problem in Chinese language processing, 
namely extending a Chinese thesaurus with new 
words from various Chinese speech communities, 
including Beijing, Hong Kong, Singapore and 
Taipei.  The critical issues include whether the ex-
isting classificatory structure could accommodate 
concepts and expressions specific to various Chi-
nese speech communities, and whether the differ-
ence in textual sources might pose difficulty in us-
ing conventional similarity measures for the auto-
matic classification.  Our experiments, using the 
cosine function to measure similarity and testing 
with various sources for extracting contextual vec-
tors, suggest that the classification performance 
might depend on the compatibility between the 
words in the thesaurus and the sources from which 
the target words are drawn.  Evaluated against hu-
man judgement, an accuracy of over 85% was 
reached in some cases, which were much higher 
than the baseline and were very encouraging in 
general.  While human judgement is not straight-
forward and it is difficult to create a Pan-Chinese 
lexicon manually, combining simple classification 
methods with the appropriate data sources seems to 
be a promising approach toward its automatic 
construction. 
Acknowledgements 
The work described in this paper was supported by 
a grant from the Research Grants Council of the 
Hong Kong Special Administrative Region, China 
(Project No. CityU 1317/03H). 
Appendix 
The following table shows some examples of the 
Cilin subclasses: 
 
Class Subclasses 
A ? (Human) Aa ? Ae ?? (Occupation)  Af
?? (Identity) ? An 
B ? (Things) Ba ? Bb ??? (Shape) ? Bi ?
? (Animal)? Bm ?? (Mate-
rial)?Bq ?? (Clothing) ? Br 
C ????? 
(Time and Space) 
Ca ?? (Time)  Cb ?? (Space) 
D ???? 
(Abstract entities) 
Da ?? ?? (Condition) ? Df 
?? (Ideology) ? Di ?? ?? 
(Society) Dj ?? (Economics) ? 
Dm ?? (Organization) Dn ?? 
?? (Quantity) 
E ?? 
(Characteristics) 
Ea ? Ed ?? (Property)? Ef 
F ?? (Action) Fa ? Fd 
G ???? 
(Psychological 
activities) 
Ga ? Gb ???? (Psychologi-
cal activities)? Gc 
H ?? 
(Activities) 
Ha ? He ???? (Economic 
activities) ? Hd ?? (Produc-
tion) ? Hf ???? (Transporta-
tion) Hg ???? (Scientific re-
search)? Hi ?? (Social contact) 
Hj ?? (Livelihood) 
I ????? 
(Phenomenon and 
state) 
Ia ? If ?? (Circumstance)  Ig ?
? (Process)? Ih 
J ?? 
(Association) 
Ja ?? (Liaison)  Jb ?? (Simi-
larity and Difference) Jc ?? 
(Matching) ? Je 
K ?? 
(Auxiliary words) 
Ka ? Kf 
L ?? 
(Respectful ex-
pressions) 
 
 
332
References 
Caraballo, S.A. (1999)  Automatic construction of a 
hypernym-labeled noun hierarchy from text.  In Pro-
ceedings of the 37th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL?99), Mary-
land, USA, pp.120-126. 
Ciaramita, M. (2002)  Boosting automatic lexical acqui-
sition with morphological information.  In Proceed-
ings of the ACL?02 Workshop on Unsupervised Lexi-
cal Acquisition, Philadelphia, USA, pp.17-25. 
Curran, J.R. and Moens, M. (2002)  Improvements in 
Automatic Thesaurus Extraction.  In Proceedings of 
the ACL?02 Workshop on Unsupervised Lexical Ac-
quisition, Philadelphia, USA, pp.59-66. 
Hearst, M. (1992)  Automatic Acquisition of Hyponyms 
from Large Text Corpora.  In Proceedings of the 14th 
International Conference on Computational Linguis-
tics (COLING-92), Nantes, France, pp.539-545. 
Kwong, O.Y. and Tsou, B.K. (2006)  Feasibility of En-
riching a Chinese Synonym Dictionary with a Syn-
chronous Chinese Corpus.  In T. Salakoski, F. Ginter, 
S. Pyysalo and T. Pahikkala (Eds.), Advances in 
Natural Language Processing: Proceedings of Fin-
TAL 2006. Lecture Notes in Artificial Intelligence, 
Vol.4139, pp.322-332, Springer-Verlag. 
Lin, D. (1998)  Automatic Retrieval and Clustering of 
Similar Words.  In Proceedings of the 36th Annual 
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on Com-
putational Linguistics (COLING-ACL?98), Montreal, 
Canada, pp.768-774. 
Mei et al ??????????????? (1984)  
???????  (Tongyici Cilin).  ????? 
(Commerical Press) / ???????. 
Pekar, V. (2004)  Linguistic Preprocessing for Distribu-
tional Classification of Words.  In Proceedings of the 
COLING2004 Workshop on Enhancing and Using 
Electronic Dictionaries, Geneva. 
Riloff, E. and Shepherd, J. (1997)  A corpus-based ap-
proach for building semantic lexicons.  In Proceed-
ings of the Second Conference on Empirical Methods 
in Natural Language Processing, Providence, Rhode 
Island, pp.117-124. 
Siegel, S. and Castellan, N.J. (1988)  Nonparametric 
Statistics for the Behavioral Sciences (2nd Ed.).  
McGraw-Hill. 
Thelen, M. and Riloff, E. (2002)  A Bootstrapping 
Method for Learning Semantic Lexicons using Ex-
traction Pattern Contexts.  In Proceedings of the 2002 
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP 2002), Philadelphia, 
USA. 
Tokunaga, T., Fujii, A., Iwayama, M., Sakurai, N. and 
Tanaka, H. (1997)  Extending a thesaurus by classi-
fying words.  In Proceedings of the ACL Workshop 
on Automatic Information Extraction and Building of 
Lexical Semantic Resources for NLP Applications, 
Madrid, pp.16-21. 
Tseng, H. (2003)  Semantic Classification of Chinese 
Unknown Words.  In the Proceedings of the ACL-
2003 Student Research Workshop, Companion Vol-
ume to the Proceedings of the 41st Annual Meeting of 
the Association for Computational Linguistics, Sap-
poro, Japan. 
Tsou, B.K. (2001)  Language Contact and Lexical Inno-
vation.  In M. Lackner, I. Amelung and J. Kurtz 
(Eds.), New Terms for New Ideas: Western Knowl-
edge and Lexical Change in Late Imperial China.  
Berlin: Brill. 
Tsou, B.K. and Kwong, O.Y. (2006)  Toward a Pan-
Chinese Thesaurus.  In Proceedings of the Fifth In-
ternational Conference on Language Resources and 
Evaluation (LREC 2006), Genoa, Italy. 
Tsou, B.K. and Lai, T.B.Y. ??????? (2003)  ?
???????????.  In B. Xu, M. Sun and G. 
Jin ?????????? (Eds.), ??????
????????  (Issues in Chinese Language 
Processing).  ????????, pp.147-165 
You, J-M. and Chen, K-J. (2006)  Improving Context 
Vector Models by Feature Clustering for Automatic 
Thesaurus Construction.  In Proceedings of the Fifth 
SIGHAN Workshop on Chinese Language Processing, 
COLING-ACL 2006, Sydney, Australia, pp.1-8. 
 
 
333
115
116
117
118
R. Dale et al (Eds.): IJCNLP 2005, LNAI 3651, pp. 804 ? 814, 2005. 
? Springer-Verlag Berlin Heidelberg 2005 
Semantic Role Tagging for Chinese at the Lexical Level 
Oi Yee Kwong and Benjamin K. Tsou 
Language Information Sciences Research Centre, City University of Hong Kong, 
Tat Chee Avenue, Kowloon, Hong Kong 
{rlolivia, rlbtsou}@cityu.edu.hk 
Abstract. This paper reports on a study of semantic role tagging in Chinese, in 
the absence of a parser.  We investigated the effect of using only lexical infor-
mation in statistical training; and proposed to identify the relevant headwords in 
a sentence as a first step to partially locate the corresponding constituents to be 
labelled.  Experiments were done on a textbook corpus and a news corpus, rep-
resenting simple data and complex data respectively.  Results suggested that in 
Chinese, simple lexical features are useful enough when constituent boundaries 
are known, while parse information might be more important for complicated 
sentences than simple ones. Several ways to improve the headword identifica-
tion results were suggested, and we also plan to explore some class-based tech-
niques for the task, with reference to existing semantic lexicons. 
1   Introduction 
As the development of language resources progresses from POS-tagged corpora to 
syntactically annotated treebanks, the inclusion of semantic information such as 
predicate-argument relations is becoming indispensable.  The expansion of the Penn 
Treebank into a Proposition Bank [11] is a typical move in this direction.  Lexical 
resources also need to be enhanced with semantic information (e.g. [5]).  In fact the 
ability to identify semantic role relations correctly is essential to many applications 
such as information extraction and machine translation; and making available re-
sources with this kind of information would in turn facilitate the development of such 
applications. 
Large-scale production of annotated resources is often labour-intensive, and thus 
needs automatic labelling to streamline the work.  The task can essentially be per-
ceived as a two-phase process, namely to recognise the constituents bearing some 
semantic relationship to the target verb in a sentence, and then to label them with the 
corresponding semantic roles. 
In their seminal proposal, Gildea and Jurafsky approached the task using various 
features such as headword, phrase type, and parse tree path [6].  Such features have 
remained the basic and essential features in subsequent research, irrespective of the 
variation in the actual learning components.  In addition, parsed sentences are often 
required, for extracting the path features during training and providing the argument 
boundaries during testing.  The parse information is deemed important for the per-
formance of role labelling [7, 8]. 
More precisely, in semantic role labelling, parse information is rather more critical 
for the identification of boundaries for candidate constituents than for the extraction 
 Semantic Role Tagging for Chinese at the Lexical Level 805 
of training data.  Its limited function in training, for instance, is reflected in the low 
coverage reported (e.g. [21]).  However, given the imperfection of existing automatic 
parsers, which are far from producing gold standard parses, many thus resort to shal-
low syntactic information from simple chunking, though results often turn out to be 
less satisfactory than with full parses. 
This limitation is even more pertinent for the application of semantic role labelling 
to languages which do not have sophisticated parsing resources.  In the case of Chi-
nese, for example, there is considerable variability in its syntax-semantics interface; 
and when one has more nested and complex sentences such as those from news arti-
cles, it becomes more difficult to capture the sentence structures by typical examples. 
It is therefore worthwhile to investigate alternatives to the role labelling task for 
Chinese under the parsing bottleneck, both in terms of the features used and the short-
cut or compromise to at least partially pin down the relevant constituents.  A series of 
related questions deserve consideration here: 
1. how much could we achieve with only parse-independent features in the role la-
belling process; 
2. with constituent boundaries unknown in the absence of parse information, could 
we at least identify the headwords in the relevant constituents to be tagged; and 
3. whether the unknown boundary problem varies with the nature of the dataset, 
e.g., will the degradation in performance from known boundaries to unknown 
boundaries be more serious for complicated sentences than for simple  
sentences. 
So in the current study we experiment on the use of parse-independent features for 
semantic role labelling in Chinese, for locating the headwords of the constituents 
corresponding to arguments to be labelled.  We will also compare the results on two 
training and testing datasets. 
In Section 2, related work will be reviewed.  In Section 3, the data used in the cur-
rent study will be introduced.  Our proposed method will be explained in Section 4, 
and the experiment reported in Section 5.  Results and future work will be discussed 
in Section 6, followed by conclusions in Section 7. 
2   Related Work 
The definition of semantic roles falls on a continuum from abstract ones to very spe-
cific ones.  Gildea and Jurafsky [6], for instance, used a set of roles defined according 
to the FrameNet model [2], thus corresponding to the frame elements in individual 
frames under a particular domain to which a given verb belongs.  Lexical entries (in 
fact not limited to verbs, in the case of FrameNet) falling under the same frame will 
share the same set of roles.  Gildea and Palmer [7] defined roles with respect to indi-
vidual predicates in the PropBank, without explicit naming.  To date PropBank and 
FrameNet are the two main resources in English for training semantic role labelling 
systems. 
The theoretical treatment of semantic roles is also varied in Chinese.  In practice, 
for example, the semantic roles in the Sinica Treebank mark not only verbal argu-
ments but also modifier-head relations within individual constituents, following a 
806 O.Y. Kwong and B.K. Tsou 
head-driven principle [4].  In our present study, we use a set of more abstract semantic 
roles, which are generalisable to most Chinese verbs and are not dependent on par-
ticular predicates.  They will be further introduced in Section 3. 
The major concerns in automatic semantic role labelling include the handling of al-
ternations (as in ?the window broke? and ?John broke the window?, where in both 
cases ?the window? should be tagged as ?patient? despite its appearance in different 
positions in the sentences), and generalisation to unseen constituents and predicates.  
For the latter, clustering and semantic lexicons or hierarchies have been used (e.g. 
[6]), or similar argument structures are assumed for near-synonyms and verbs under 
the same frame (e.g. [11]). 
Approaches in automatic semantic role labelling are mostly statistical, typically 
making use of a number of features extracted from parsed training sentences.  In 
Gildea and Jurafsky [6], the features studied include phrase type (pt), governing cate-
gory (gov), parse tree path (path), position of constituent with respect to the target 
predicate (position), voice (voice), and headword (h).  The labelling of a constituent 
then depends on its likelihood to fill each possible role r given the features and the 
target predicate t, as in the following, for example: 
),,,,,|( tvoicepositiongovpthrP    
Subsequent studies exploited a variety of implementation of the learning compo-
nent, including Maximum Entropy (e.g. [1, 12]), Support Vector Machines (e.g. [9, 
16]), etc.  Transformation-based approaches were also used (e.g. [10, 19]).  Swier and 
Stevenson [17] innovated with an unsupervised approach to the problem, using a 
bootstrapping algorithm, and achieved 87% accuracy. 
While the estimation of the probabilities could be relatively straightforward, the 
key often lies in locating the candidate constituents to be labelled.  A parser of some 
kind is needed.  Gildea and Hockenmaier [8] compared the effects of Combinatory 
Categorial Grammar (CCG) derivations and traditional Treebank parsing, and found 
that the former performed better on core arguments, probably due to its ability to 
capture long range dependencies, but comparable for all arguments.  Gildea and 
Palmer [7] compared the effects of full parsing and shallow chunking; and found that 
when constituent boundaries are known, both automatic parses and gold standard 
parses resulted in about 80% accuracy for subsequent automatic role tagging, but 
when boundaries are unknown, results with automatic parses dropped to 57% preci-
sion and 50% recall.  With chunking only, performance further degraded to below 
30%.  Problems mostly arise from arguments which correspond to more than one 
chunk, and the misplacement of core arguments. 
A couple of evaluation exercises for semantic role labelling were organized re-
cently, such as the shared task in CoNLL-2004 using PropBank data [3], and the one 
in SENSEVAL-3 using the FrameNet dataset [15].  Most systems in SENSEVAL-3 
used a parser to obtain full syntactic parses for the sentences, whereas systems par-
ticipating in the CoNLL task were restricted to using only shallow syntactic informa-
tion.  Results reported in the former tend to be higher.  Although the dataset may be a 
factor affecting the labelling performance, it nevertheless reinforces the usefulness of 
full syntactic information. 
 Semantic Role Tagging for Chinese at the Lexical Level 807 
According to Carreras and M?rquez [3], for English, the state-of-the-art results 
reach an F1 measure of slightly over 83 using gold standard parse trees and about 77 
with real parsing results.  Those based on shallow syntactic information is about 60. 
The usefulness of parse information for semantic role labelling would be especially 
interesting in the case of Chinese, given the flexibility in its syntax-semantics interface 
(e.g. the object after ? ?eat? could refer to the Patient as in ??? ?eat apple?, Loca-
tion as in ??? ?eat canteen?, Duration as in ??? ?eat three years?, etc.).  In the 
absence of sophisticated parsing resources, however, we attempt to investigate how 
well one could simply use a set of parse-independent features and backward guess the 
likelihood of headwords to partially locate the candidate constituents to be labelled. 
3   The Data 
3.1   Materials 
As mentioned in the introduction, we attempted to investigate the difference between 
labelling simple sentences and complex ones.  For this purpose, sentences from pri-
mary school textbooks were taken as examples for simple data, while sentences from 
a large corpus of newspaper texts were taken as complex examples. 
Two sets of primary school Chinese textbooks popularly used in Hong Kong were 
taken for reference.  The two publishers were Keys Press [22] and Modern Education 
Research Society Ltd [23].  Texts for Primary One to Six were digitised, segmented 
into words, and annotated with parts-of-speech (POS).  The two sets of textbooks 
amount to a text collection of about 165K character tokens and upon segmentation 
about 109K word tokens (about 15K word types).  There were about 2,500 transitive 
verb types, with frequency ranging from 1 to 926. 
The complex examples were taken from a subset of the LIVAC synchronous cor-
pus1 [13, 18].   The subcorpus consists of newspaper texts from Hong Kong, including 
local news, international news, financial news, sports news, and entertainment news, 
collected in 1997-98.  The texts were segmented into words and POS-tagged, amount-
ing to about 1.8M character tokens and upon segmentation about 1M word tokens 
(about 47K word types).  There were about 7,400 transitive verb types, with fre-
quency ranging from 1 to just over 6,300. 
3.2   Training and Testing Data 
For the current study, a set of 41 transitive verbs common to the two corpora (hereaf-
ter referred to as textbook corpus and news corpus), with frequency over 10 and over 
50 respectively, was sampled.   
Sentences in the corpora containing the sampled verbs were extracted.  Constituents 
corresponding to semantic roles with respect to the target verbs were annotated by a 
trained annotator, whose annotation was verified by another.  In this study, we worked 
with a set of 11 predicate-independent abstract semantic roles.  According to the Dic-
tionary of Verbs in Contemporary Chinese (Xiandai Hanyu Dongci Dacidian, ???
??????) [14], our semantic roles include the necessary arguments for most 
                                                          
1
 http://www.livac.org 
808 O.Y. Kwong and B.K. Tsou 
verbs such as Agent and Patient, or Goal and Location in some cases; and some op-
tional arguments realised by adjuncts, such as Quantity, Instrument, and Source.  Some 
examples of semantic roles with respect to a given predicate are shown in Fig. 1. 
 
Fig. 1. Examples of semantic roles with respect to a given predicate 
Altogether 980 sentences covering 41 verb types in the textbook corpus were anno-
tated, resulting in 1,974 marked semantic roles (constituents); and 2,122 sentences 
covering 41 verb types in the news corpus were annotated, resulting in 4,933 marked 
constituents2. 
The role labelling system was trained on 90% of the sample sentences from the 
textbook corpus and the news corpus separately; and tested on the remaining 10% of 
the respective corpora.   
4   Automatic Role Labelling 
The automatic labelling was based on the statistical approach in Gildea and Jurafsky 
[6].  In Section 4.1, we will briefly mention the features employed in the training 
process.  Then in Sections 4.2 and 4.3, we will explain our approach for locating 
headwords in candidate constituents associated with semantic roles, in the absence of 
parse information. 
4.1   Training 
In this study, our probability model was based mostly on parse-independent features 
extracted from the training sentences, namely: 
                                                          
2
  These figures only refer to the samples used in the current study.  In fact over 35,000 sen-
tences in the LIVAC corpus have been semantically annotated, covering about 1,500 verb 
types and about 80,000 constituents were marked. 
? ?? ?? ?? ? ?? ??
Next week school hold tell story contest 
Time Agent Target Patient 
Example: (Next week, the school will hold a story-telling contest.) 
?? ? ?? 
??
??
? ?
(-pl) write essay always feel not anything 
Experiencer Target Theme 
Example: (Students always feel there is nothing to write about for their essays.) 
?  
?
time 
??
? 
can 
Time 
Student write 
 Semantic Role Tagging for Chinese at the Lexical Level 809 
Headword (head): The headword from each constituent marked with a semantic role 
was identified.  For example, in the second sentence in Fig. 1, ?? (school) is the 
headword in the constituent corresponding to the Agent of the verb ?? (hold), and 
?? (contest) is the headword of the noun phrase corresponding to the Patient. 
Position (posit): This feature shows whether the constituent being labelled appears 
before or after the target verb.  In the first example in Fig. 1, the Experiencer and 
Time appear on the left of the target, while the Theme is on its right. 
POS of headword (HPos): Without features provided by the parse, such as phrase 
type or parse tree path, the POS of the headword of the labelled constituent could 
provide limited syntactic information. 
Preposition (prep): Certain semantic roles like Time and Location are often realised 
by prepositional phrases, so the preposition introducing the relevant constituents 
would be an informative feature. 
Hence for automatic labelling, given the target verb t, the candidate constituent, 
and the above features, the role r which has the highest probability for P(r | head, 
posit, HPos, prep, t) will be assigned to that constituent.  In this study, however, we 
are also testing with the unknown boundary condition where candidate constituents 
are not available in advance, hence we attempt to partially locate them by identifying 
their headwords to start with.  Our approach is explained in the following sections. 
4.2   Locating Candidate Headwords 
In the absence of parse information, and with constituent boundaries unknown, we 
attempt to partially locate the candidate constituents by trying to identify their corre-
sponding headwords first.  Sentences in our test data were segmented into words and 
POS-tagged.  We thus divide the recognition process into two steps, locating the 
headword of a candidate constituent first, and then expanding from the headword to 
determine its boundaries. 
Basically, if we consider every word in the same sentence as the target verb (both 
to its left and to its right) a potential headword for a candidate constituent, what we 
need to do is to find out the most probable words in the sentence to match against 
individual semantic roles.  We start with a feature set with more specific distributions, 
and back off to feature sets with less specific distributions.  Hence in each round we 
look for 
)|(maxarg setfeaturerP
r
 
for every candidate word.  Ties are resolved by giving priority to the word nearest to 
the target verb in the sentence. 
Fig. 2 shows an example illustrating the procedures for locating candidate head-
words.  The target verb is ?? (discover).  In the first round, using features head, 
posit, HPos, and t, ?? (time) and ?? (problem) were identified as Time and Pa-
tient respectively.  In the fourth subsequent round, backing off with features posit and 
HPos, ?? (we) was identified as a possible Agent.  In this round a few other words 
were identified as potential Patients.  However, since Patient was already located in 
810 O.Y. Kwong and B.K. Tsou 
the previous round, those come up in this round are not considered.  So in the end the 
headwords identified for the test sentence are ?? (we) for Agent, ?? (problem) 
for Patient and ?? (time) for Time. 
 
Fig. 2. Example illustrating the procedures for locating candidate headwords 
4.3   Constituent Boundary 
Upon the identification of headwords for potential constituents, the next step is to 
expand from these headwords for constituent boundaries.  Although we are not doing 
this step in the current study, it can potentially be done via some finite state tech-
niques, or better still, with shallow syntactic processing like simple chunking if  
available. 
5   The Experiment 
5.1   Testing 
The system was trained and tested on the textbook corpus and the news corpus  
respectively.  The testing was done under the ?known constituent? and ?unknown 
constituent? conditions.  The former essentially corresponds to the known-boundary 
condition in related studies; whereas in the unknown-constituent condition, which we 
will call ?headword location? condition hereafter, we tested our method of locating 
candidate headwords as explained above in Section 4.2.  In this study, every noun, 
verb, adjective, pronoun, classifier, and number within the test sentence containing 
the target verb was considered a potential headword for a candidate constituent  
Sentence: 
?????????????????????????????????????? 
During revision, we discover a lot of problems which we have not thought of or cannot be 
solved, then we go and ask father. 
Candidate  Round 1 ? Round 4  Final Result 
Headwords 
 
?? (revision)    Patient 
?? (time)  Time     ----       Time 
?? (we)    Agent       Agent 
?? (normally) 
?? (think)    Patient 
? (can) 
?? (solve)    Patient 
?? (problem)  Patient     ----       Patient 
? (go)     Patient 
? (ask)    Patient 
?? (father)    Patient 
 Semantic Role Tagging for Chinese at the Lexical Level 811 
corresponding to some semantic role.  The performance was measured in terms of the 
precision (defined as the percentage of correct outputs among all outputs), recall (de-
fined as the percentage of correct outputs among expected outputs), and F1 score 
which is the harmonic mean of precision and recall. 
5.2   Results 
The results are shown in Table 1, for testing on both the textbook corpus and the news 
corpus under the known constituent condition and the headword location condition. 
Table 1. Results on two datasets for known constituents and headword location 
 Textbook Data News Data 
 Precision Recall F1 Precision Recall F1 
Known Constituent 93.85 87.50 90.56 90.49 87.70 89.07 
Headword Location 46.12 61.98 52.89 38.52 52.25 44.35 
Under the known constituent condition, the results were good on both datasets, 
with an F1 score of about 90.  This is comparable or even better to the results reported 
in related studies for known boundary condition.  The difference is that we did not use 
any parse information in the training, not even phrase type.  Our results thus suggest 
that for Chinese, even without more complicated syntactic information, simple lexical 
information might already be useful in semantic role tagging. 
Comparison of the known constituent condition with the headword location condi-
tion shows that performance for the latter has expectedly dropped.  However, the 
degradation was less serious with simple sentences than with complex ones, as is seen 
from the higher precision and recall for textbook data than for news data under the 
headword location condition.  What is noteworthy here is that recall apparently dete-
riorated less seriously than precision.  In the case of news data, for instance, we were 
able to maintain over 50% recall but only obtained about 39% precision.  The surpris-
ingly low precision is attributed to a technical inadequacy in the way we break ties.  
In this study we only make an effort to eliminate multiple tagging of the same role to 
the same target verb in a sentence on either side of the target verb, but not if they 
appear on both sides of the target verb.  This should certainly be dealt with in future 
experiments.  The differential degradation of performance between textbook data and 
news data also suggests the varied importance of constituent boundaries to simple 
sentences and complex ones, and hence possibly their varied requirements for full 
parse information for the semantic labelling task. 
6   Discussion 
According to Carreras and M?rquez [3], the state-of-the-art results for semantic role 
labelling systems based on shallow syntactic information is about 15 lower than 
those with access to gold standard parse trees, i.e., around 60.  Our experimental 
results for the headword location condition, with no syntactic information available 
812 O.Y. Kwong and B.K. Tsou 
at all, give an F1 score of 52.89 and 44.35 respectively for textbook data and news 
data. This further degradation in performance is nevertheless within expectation, 
but whether this is also a result of the difference between English and Chinese  
remains to be seen. 
In response to the questions raised in the introduction, firstly, the results for the 
known constituent condition (F1 of 90.56 and 89.07 for textbook data and news data 
respectively) have shown that even if we do not use parse-dependent features such as 
governing category and parse tree path, results are not particularly affected.  In other 
words, lexical features are already very useful as long as the constituent boundaries 
are given.  Secondly, in the absence of parse information, the results of identifying the 
relevant headwords in order to partially locate candidate constituents were not as 
satisfactory as one would like to see.  One possible way to improve the results, as 
suggested above, would be to improve the handling of ties.  Other possibilities includ-
ing a class-based method could also be used, as will be discussed below.  Thirdly, 
results for news data degraded more seriously than textbook data from the known 
constituent condition to the headword location condition.  This suggests that complex 
sentences in Chinese are more affected by the availability of full parse information.  
To a certain extent, this might be related to the relative flexibility in the syntax-
semantics interface of Chinese; hence when a sentence gets more complicated, there 
might be more intervening constituents and the parse information would be useful to 
help identify the relevant ones in semantic role labelling.   
In terms of future development, apart from improving the handling of ties in our 
method, as mentioned in the previous section, we plan to expand our work in several 
respects, the major part of which is on the generalization to unseen headwords and 
unseen predicates.  As is with other related studies, the examples available for training 
for each target verb are very limited; and the availability of training data is also insuf-
ficient in the sense that we cannot expect them to cover all target verb types.  Hence it 
is very important to be able to generalize the process to unseen words and predicates.  
To this end, we will experiment with a semantic lexicon like Tongyici Cilin (???
??, a Chinese thesaurus) in both training and testing, which we expect to improve 
the overall performance. 
Another area of interest is to look at the behaviour of near-synonymous predicates 
in the tagging process.  Many predicates may be unseen in the training data, but while 
the probability estimation could be generalized from near-synonyms as suggested by a 
semantic lexicon, whether the similarity and subtle differences between near-
synonyms with respect to the argument structure and the corresponding syntactic 
realisation could be distinguished would also be worth studying.  Related to this is the 
possibility of augmenting the feature set with semantic features.  Xue and Palmer 
[20], for instance, looked into new features such as syntactic frame, lexicalized con-
stituent type, etc., and found that enriching the feature set improved the labelling 
performance. 
Another direction of future work is on the location of constituent boundaries upon 
the identification of the headword.  As mentioned earlier on, this could probably be 
tackled by some finite state techniques or with the help of simple chunkers. 
 Semantic Role Tagging for Chinese at the Lexical Level 813 
7   Conclusion 
The study reported in this paper has thus tackled the unknown constituent boundary 
condition in semantic role labelling for Chinese, by attempting to locate the corre-
sponding headwords first.  We experimented with both simple and complex data.  
Using only parse-independent features, our results on known boundary condition are 
comparable to those reported in related studies.  Although the results for headword 
location condition were not as good as state-of-the-art performance with shallow 
syntactic information, we have nevertheless suggested some possible ways to improve 
the results.  We have further observed that the influence of full syntactic information 
is more serious for complex data than simple data, which might be a consequence of 
the characteristic syntax-semantics interface of Chinese.  As a next step, we plan to 
explore some class-based techniques for the task, with reference to existing  
semantic lexicons. 
Acknowledgements 
This work is supported by Competitive Earmarked Research Grants (CERG) of the 
Research Grants Council of Hong Kong under grant Nos. CityU1233/01H and 
CityU1317/03H. 
References 
1. Baldewein, U., Erk, K., Pad?, S. and Prescher, D. (2004)  Semantic Role Labelling With 
Chunk Sequences.  In Proceedings of the Eighth Conference on Computational Natural 
Language Learning (CoNLL-2004), Boston, Massachusetts, pp.98-101. 
2. Baker, C.F., Fillmore, C.J. and Lowe, J.B. (1998)  The Berkeley FrameNet Project.  In 
Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics 
and the 17th International Conference on Computational Linguistics (COLING-ACL ?98), 
Montreal, Quebec, Canada, pp.86-90. 
3. Carreras, X. and M?rquez, L. (2004)  Introduction to the CoNLL-2004 Shared Task: Se-
mantic Role Labeling.  In Proceedings of the Eighth Conference on Computational Natu-
ral Language Learning (CoNLL-2004), Boston, Massachusetts, pp.89-97. 
4. Chen, F-Y., Tsai, P-F., Chen, K-J. and Huang, C-R. (1999)  Sinica Treebank (?????
???????). Computational Linguistics and Chinese Language Processing, 4(2): 
87-104. 
5. Fellbaum, C., Palmer, M., Dang, H.T., Delfs, L. and Wolf, S. (2001)  Manual and Auto-
matic Semantic Annotation with WordNet.  In Proceedings of the NAACL-01 SIGLEX 
Workshop on WordNet and Other Lexical Resources, Invited Talk, Pittsburg, PA. 
6. Gildea, D. and Jurafsky, D. (2002)  Automatic Labeling of Semantic Roles.  Computa-
tional Linguistics, 28(3): 245-288. 
7. Gildea, D. and Palmer, M. (2002)  The Necessity of Parsing for Predicate Argument Rec-
ognition.  In Proceedings of the 40th Meeting of the Association for Computational Lin-
guistics (ACL-02), Philadelphia, PA. 
8. Gildea, D. and Hockenmaier, J. (2003)  Identifying Semantic Roles Using Combinatory 
Categorial Grammar.  In Proceedings of the 2003 Conference on Empirical Methods in 
Natural Language Processing, Sapporo, Japan. 
814 O.Y. Kwong and B.K. Tsou 
9. Hacioglu, K., Pradhan, S., Ward, W., Martin, J.H. and Jurafsky, D. (2004)  Semantic Role 
Labeling by Tagging Syntactic Chunks.  In Proceedings of the Eighth Conference on 
Computational Natural Language Learning (CoNLL-2004), Boston, Massachusetts, 
pp.110-113. 
10. Higgins, D. (2004)  A transformation-based approach to argument labeling.  In Proceed-
ings of the Eighth Conference on Computational Natural Language Learning (CoNLL-
2004), Boston, Massachusetts, pp.114-117. 
11. Kingsbury, P. and Palmer, M. (2002)  From TreeBank to PropBank.  In Proceedings of the 
Third Conference on Language Resources and Evaluation (LREC-02), Las Palmas, Ca-
nary Islands, Spain. 
12. Kwon, N., Fleischman, M. and Hovy, E. (2004)  SENSEVAL Automatic Labeling of Se-
mantic Roles using Maximum Entropy Models.  In Proceedings of the Third International 
Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3), 
Barcelona, Spain, pp.129-132. 
13. Kwong, O.Y. and Tsou, B.K. (2003) Categorial Fluidity in Chinese and its Implications 
for Part-of-speech Tagging. In Proceedings of the Research Note Session of the 10th Con-
ference of the European Chapter of the Association for Computational Linguistics, Buda-
pest, Hungary, pp.115-118. 
14. Lin, X., Wang, L. and Sun, D. (1994)  Dictionary of Verbs in Contemporary Chinese.  
Beijing Language and Culture University Press. 
15. Litkowski, K.C. (2004) SENSEVAL-3 Task: Automatic Labeling of Semantic Roles.  In 
Proceedings of the Third International Workshop on the Evaluation of Systems for the Se-
mantic Analysis of Text (SENSEVAL-3), Barcelona, Spain, pp.9-12. 
16. Moldovan, D., Girju, R., Olteanu, M. and Fortu, O. (2004)  SVM Classification of Frame-
Net Semantic Roles.  In Proceedings of the Third International Workshop on the Evalua-
tion of Systems for the Semantic Analysis of Text (SENSEVAL-3), Barcelona, Spain, 
pp.167-170. 
17. Swier, R.S. and Stevenson, S. (2004)  Unsupervised Semantic Role Labelling.  In Pro-
ceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, 
Barcelona, Spain, pp.95-102. 
18. Tsou, B.K., Tsoi, W.F., Lai, T.B.Y., Hu, J. and Chan, S.W.K. (2000)  LIVAC, A Chinese 
Synchronous Corpus, and Some Applications.  In Proceedings of the ICCLC International 
Conference on Chinese Language Computing, Chicago, pp. 233-238. 
19. Williams, K., Dozier, C. and McCulloh, A. (2004)  Learning Transformation Rules for 
Semantic Role Labeling.  In Proceedings of the Eighth Conference on Computational 
Natural Language Learning (CoNLL-2004), Boston, Massachusetts, pp.134-137. 
20. Xue, N. and Palmer, M. (2004)  Calibrating Features for Semantic Role Labeling.  In Pro-
ceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, 
Barcelona, Spain, pp.88-94. 
21. You, J-M. and Chen, K-J. (2004)  Automatic Semantic Role Assignment for a Tree Struc-
ture.  In Proceedings of the 3rd SigHAN Workshop on Chinese Language Processing, 
ACL-04, Barcelona, pp.109-115. 
22. ?????? Qisi Zhongguo Yuwen.  Primary 1-6, 24 volumes, 2004.  Hong Kong: Keys 
Press. 
23. ?????? Xiandai Zhongguo Yuwen.  Primary 1-6, 24 volumes, 2004.  Hong Kong: 
Modern Education Research Society Ltd. 
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 21?24,
Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLP
Homophones and Tonal Patterns in English-Chinese Transliteration 
 
 
Oi Yee Kwong 
Department of Chinese, Translation and Linguistics  
City University of Hong Kong 
Tat Chee Avenue, Kowloon, Hong Kong 
Olivia.Kwong@cityu.edu.hk 
 
  
Abstract 
The abundance of homophones in Chinese 
significantly increases the number of similarly 
acceptable candidates in English-to-Chinese 
transliteration (E2C).  The dialectal factor also 
leads to different transliteration practice.  We 
compare E2C between Mandarin Chinese and 
Cantonese, and report work in progress for 
dealing with homophones and tonal patterns 
despite potential skewed distributions of indi-
vidual Chinese characters in the training data.  
1 Introduction 
This paper addresses the problem of automatic 
English-Chinese forward transliteration (referred 
to as E2C hereafter). 
There are only a few hundred Chinese charac-
ters commonly used in names, but their combina-
tion is relatively free.  Such flexibility, however, 
is not entirely ungoverned.  For instance, while 
the Brazilian striker Ronaldo is rendered as??
?  long5-naa4-dou6 in Cantonese, other pho-
netically similar candidates like ??? long5-
naa4-dou6 or ??? long4-naa4-dou11 are least 
likely.  Beyond linguistic and phonetic properties, 
many other social and cognitive factors such as 
dialect, gender, domain, meaning, and perception, 
are simultaneously influencing the naming proc-
ess and superimposing on the surface graphemic 
correspondence. 
The abundance of homophones in Chinese fur-
ther complicates the problem.  Past studies on 
phoneme-based E2C have reported their adverse 
effects (e.g. Virga and Khudanpur, 2003).  Direct 
orthographic mapping (e.g. Li et al, 2004), mak-
ing use of individual Chinese graphemes, tends 
                                                 
1 Mandarin names are transcribed in Hanyu Pinyin 
and Cantonese names are transcribed in Jyutping pub-
lished by the Linguistic Society of Hong Kong. 
to overcome the problem and model the charac-
ter choice directly.  Meanwhile, Chinese is a 
typical tonal language and the tone information 
can help distinguish certain homophones.  Pho-
neme mapping studies seldom make use of tone 
information.  Transliteration is also an open 
problem, as new names come up everyday and 
there is no absolute or one-to-one transliterated 
version for any name.  Although direct ortho-
graphic mapping has implicitly or partially mod-
elled the tone information via individual charac-
ters, the model nevertheless heavily depends on 
the availability of training data and could be 
skewed by the distribution of a certain homo-
phone and thus precludes an acceptable translit-
eration alternative.  We therefore propose to 
model the sound and tone together in E2C.  In 
this way we attempt to deal with homophones 
more reasonably especially when the training 
data is limited.  In this paper we report some 
work in progress and compare E2C in Cantonese 
and Mandarin Chinese. 
Related work will be briefly reviewed in Sec-
tion 2.  Some characteristics of E2C will be dis-
cussed in Section 3.  Work in progress will be 
reported in Section 4, followed by a conclusion 
with future work in Section 5. 
2 Related Work 
There are basically two categories of work on 
machine transliteration.  First, various alignment 
models are used for acquiring transliteration 
lexicons from parallel corpora and other re-
sources (e.g. Kuo and Li, 2008).  Second, statis-
tical models are built for transliteration.  These 
models could be phoneme-based (e.g. Knight and 
Graehl, 1998), grapheme-based (e.g. Li et al, 
2004), hybrid (Oh and Choi, 2005), or based on 
phonetic (e.g. Tao et al, 2006) and semantic (e.g. 
Li et al, 2007) features. 
Li et al (2004) used a Joint Source-Channel 
Model under the direct orthographic mapping 
21
(DOM) framework, skipping the middle phone-
mic representation in conventional phoneme-
based methods, and modelling the segmentation 
and alignment preferences by means of contex-
tual n-grams of the transliteration units.  Al-
though DOM has implicitly modelled the tone 
choice, since a specific character has a specific 
tone, it nevertheless heavily relies on the avail-
ability of training data.  If there happens to be a 
skewed distribution of a certain Chinese charac-
ter, the model might preclude other acceptable 
transliteration alternatives.  In view of the abun-
dance of homophones in Chinese, and that 
sound-tone combination is important in names 
(i.e., names which sound ?nice? are preferred to 
those which sound ?monotonous?), we propose 
to model sound-tone combinations in translitera-
tion more explicitly, using pinyin transcriptions 
to bridge the graphemic representation between 
English and Chinese.  In addition, we also study 
the dialectal differences between transliteration 
in Mandarin Chinese and Cantonese, which is 
seldom addressed in past studies. 
3 Some E2C Properties 
3.1 Dialectal Differences 
English and Chinese have very different phono-
logical properties.  A well cited example is a syl-
lable initial /d/ may surface as in Baghdad ??
? ba1-ge2-da2, but the syllable final /d/ is not 
represented.  This is true for Mandarin Chinese, 
but since ending stops like ?p, ?t and ?k are al-
lowed in Cantonese syllables, the syllable final 
/d/ in Baghdad is already captured in the last syl-
lable of??? baa1-gaak3-daat6 in Cantonese. 
Such phonological difference between Manda-
rin Chinese and Cantonese might also account 
for the observation that Cantonese translitera-
tions often do not introduce extra syllables for 
certain consonant segments in the middle of an 
English name, as in Dickson, transliterated as?
?? di2-ke4-xun4 in Mandarin Chinese and ?
? dik6-san4 in Cantonese. 
3.2 Ambiguities from Homophones 
The homophone problem is notorious in Chinese.  
As far as personal names are concerned, the 
?correctness? of transliteration is not clear-cut at 
all.  For example, to transliterate the name Hilary 
into Chinese, based on Cantonese pronunciations, 
the following are possibilities amongst many 
others: (a) ??? hei1-laai1-lei6, (b) ??? 
hei1-laai1-lei6, and (c) ??? hei1-laai1-lei5. 
The homophonous third character gives rise to 
multiple alternative transliterations in this exam-
ple, where orthographically ? lei6, ? lei6 and 
? lei5 are observed for ?ry? in transliteration 
data.  One cannot really say any of the combina-
tions is ?right? or ?wrong?, but perhaps only 
?better? or ?worse?.  Such judgement is more 
cognitive than linguistic in nature, and appar-
ently the tonal patterns play an important role in 
this regard.  Hence naming is more of an art than 
a science, and automatic transliteration should 
avoid over-reliance on the training data and thus 
missing unlikely but good candidates. 
4 Work in Progress 
4.1 Datasets 
A common set of 1,423 source English names 
and their transliterations2  in Mandarin Chinese 
(as used by media in Mainland China) and Can-
tonese (as used by media in Hong Kong) were 
collected over the Internet.  The names are 
mostly from soccer, entertainment, and politics.  
The data size is admittedly small compared to 
other existing transliteration datasets, but as a 
preliminary study, we aim at comparing the 
transliteration practice between Mandarin speak-
ers and Cantonese speakers in a more objective 
way based on a common set of English names.  
The transliteration pairs were manually aligned, 
and the pronunciations for the Chinese characters 
were automatically looked up. 
4.2 Preliminary Quantitative Analysis 
 Cantonese Mandarin 
Unique name pairs 1,531 1,543 
Total English segments 4,186 4,667 
Unique English segments 969 727 
Unique grapheme pairs 1,618 1,193 
Unique seg-sound pairs 1,574 1,141 
Table 1. Quantitative Aspects of the Data 
 
As shown in Table 1, the average segment-name 
ratios (2.73 for Cantonese and 3.02 for Mandarin) 
suggest that Mandarin transliterations often use 
more syllables for a name.  The much smaller 
number of unique English segments for Manda-
rin and the difference in token-type ratio of 
grapheme pairs (3.91 for Mandarin and 2.59 for 
Cantonese) further suggest that names are more 
consistently segmented and transliterated in 
Mandarin. 
                                                 
2 Some names have more than one transliteration. 
22
4.2.1 Graphemic Correspondence 
Assume grapheme pair mappings are in the form 
<ek, {ck1,ck2,?,ckn}>, where ek stands for the kth 
unique English segment from the data, and 
{ck1,ck2,?,ckn} for the set of n unique Chinese 
segments observed for it.  It was found that n 
varies from 1 to 10 for Mandarin, with 34.9% of 
the distinct English segments having multiple 
grapheme mappings, as shown in Table 2.  For 
Cantonese, n varies from 1 to 13, with 31.5% of 
the distinct English segments having multiple 
grapheme mappings.  The proportion of multiple 
mappings is similar for Mandarin and Cantonese, 
but the latter has a higher percentage of English 
segments with 5 or more Chinese renditions.  
Thus Mandarin transliterations are relatively 
more ?standardised?, whereas Cantonese trans-
literations are graphemically more ambiguous. 
 
n Cantonese Mandarin 
>=5 5.3% 3.3% 
4 4.0% 4.4% 
3 6.2% 7.2% 
2 16.0% 20.0% 
1 68.5% 65.1% 
Example <le, {?, ?, ?, ?, 
?, ?, ?, ?, ?, 
?, ?, ?, ?}> 
<le, {?, ?, ?,  ?, 
?, ?, ?, ?, ?, 
?}> 
Table 2. Graphemic Ambiguity of the Data 
4.2.2 Homophone Ambiguity (Sound Only) 
Table 3 shows the situation with homophones 
(ignoring tones).  For example, all five characters
????? correspond to the Jyutping lei.  De-
spite the tone difference, they are considered 
homophones in this section. 
 
n Cantonese Mandarin 
>=5 3.3% 1.9% 
4 4.0% 2.5% 
3 5.8% 5.7% 
2 16.3% 20.7% 
1 70.5% 69.2% 
Example <le, {ji, laak, lei, 
leoi, lik, lit, loi, lou, 
nei}> 
<le, {er, lai, le, lei, 
li, lie, lu}> 
Table 3. Homophone Ambiguity (Ignoring Tone) 
 
Assume grapheme-sound pair mappings are in 
the form <ek, {sk1,sk2,?,skn}>, where ek stands for 
the kth unique English segment, and 
{sk1,sk2,?,skn} for the set of n unique pronuncia-
tions (regardless of tone).  For Mandarin, n var-
ies from 1 to 7, with 30.8% of the distinct Eng-
lish segments having multiple sound mappings.  
For Cantonese, n varies from 1 to 9, with 29.5% 
of the distinct English segments having multiple 
sound mappings.  Comparing with Table 2 above, 
the downward shift of the percentages suggests 
that much of the graphemic ambiguity is a result 
of the use of homophones, instead of a set of 
characters with very different pronunciations. 
4.2.3 Homophone Ambiguity (Sound-Tone) 
Table 4 shows the situation of homophones with 
both sound and tone taken into account.  For ex-
ample, the characters ?? all correspond to lei6 
in Cantonese, while ???  all correspond to 
lei5, and they are thus treated as two groups. 
Assume grapheme-sound/tone pair mappings 
are in the form <ek, {stk1,stk2,?,stkn}>, where ek 
stands for the kth unique English segment, and 
{stk1,stk2,?,stkn} for the set of n unique pronun-
ciations (sound-tone combination).  For Manda-
rin, n varies from 1 to 8, with 33.5% of the dis-
tinct English segments corresponding to multiple 
Chinese homophones.  For Cantonese, n varies 
from 1 to 10, with 30.8% of the distinct English 
segments having multiple Chinese homophones.  
 
n Cantonese Mandarin 
>=5 4.1% 2.8% 
4 4.8% 3.3% 
3 6.1% 6.8% 
2 15.8% 20.7% 
1 69.2% 66.5% 
Example <le, {ji5, laak6, lei5, 
lei6, leoi4, lik6, lit6, 
loi4, lou6, nei4}> 
<le, {er3, lai2, le4, 
lei2, li3, li4, lie4, 
lu4} 
Table 4. Homophone Ambiguity (Sound-Tone) 
 
The figures in Table 4 are somewhere between 
those in Table 2 and Table 3, suggesting that a 
considerable part of homophones used in the 
transliterations could be distinguished by tones.  
This supports our proposal of modelling tonal 
combination explicitly in E2C. 
4.3 Method and Experiment 
The Joint Source-Channel Model in Li et al 
(2004) was adopted in this study.  However, in-
stead of direct orthographic mapping, we model 
the mapping between an English segment and the 
pronunciation in Chinese.  Such a model is ex-
pected to have a more compact parameter space 
as individual Chinese characters for a certain 
English segment are condensed into homophones 
defined by a finite set of sounds and tones.  The 
model could save on computational effort, and is 
less affected by any bias or sparseness of the data.  
We refer to this approach as SoTo hereafter. 
Hence our approach with a bigram model is as 
follows: 
23
 ?
=
?? ><><=
><><><=
=
K
k
kkkk
kk
kk
stesteP
stestesteP
stststeeePSTEP
1
11
2211
2121
),|,(
),,...,,,,(
),...,,,,...,,(),(
 
where E refers to the English source name and 
ST refers to the sound/tone sequence of the trans-
literation, while ek and stk refer to kth segment 
and its Chinese sound respectively.  Homo-
phones in Chinese are thus captured as a class in 
the phonetic transcription.  For example, the ex-
pected Cantonese transliteration for Osborne is 
????  ou3-si1-bong1-nei4.  Not only is it 
ranked first using this method, its homophonous 
variant ???? is within the top 5, thus bene-
fitting from the grouping of the homophones, 
despite the relatively low frequency of <s,?>.  
This would be particularly useful for translitera-
tion extraction and information retrieval. 
Unlike pure phonemic modelling, the tonal 
factor is modelled in the pronunciation transcrip-
tion.  We do not go for phonemic representation 
from the source name as the transliteration of 
foreign names into Chinese is often based on the 
surface orthographic forms, e.g. the silent h in 
Beckham is pronounced to give ?? han4-mu3 
in Mandarin and ? haam4 in Cantonese. 
Five sets of 50 test names were randomly ex-
tracted from the 1.4K names mentioned above 
for 5-fold cross validation.  Training was done 
on the remaining data.  Results were also com-
pared with DOM.  The Mean Reciprocal Rank 
(MRR) was used for evaluation (Kantor and 
Voorhees, 2000). 
4.4 Preliminary Results 
Method Cantonese Mandarin 
DOM 0.2292 0.3518 
SoTo 0.2442 0.3557 
Table 5. Average System Performance 
 
Table 5 shows the average results of the two 
methods.  The figures are relatively low com-
pared to state-of-the-art performance, largely due 
to the small datasets.  Errors might have started 
to propagate as early as the name segmentation 
step.  As a preliminary study, however, the po-
tential of the SoTo method is apparent, particu-
larly for Cantonese.  A smaller model thus per-
forms better, and treating homophones as a class 
could avoid over-reliance on the prior distribu-
tion of individual characters.  The better per-
formance for Mandarin data is not surprising 
given the less ?standardised? Cantonese translit-
erations as discussed above.  From the research 
point of view, it suggests more should be consid-
ered in addition to grapheme mapping for han-
dling Cantonese data. 
5 Future Work and Conclusion 
Thus we have compared E2C between Mandarin 
Chinese and Cantonese, and discussed work in 
progress for our proposed SoTo method which 
more reasonably treats homophones and better 
models tonal patterns in transliteration.  Future 
work includes testing on larger datasets, more in-
depth error analysis, and developing better meth-
ods to deal with Cantonese transliterations. 
Acknowledgements 
The work described in this paper was substan-
tially supported by a grant from City University 
of Hong Kong (Project No. 7002203). 
References  
Kantor, P.B. and Voorhees, E.M. (2000)  The TREC-
5 Confusion Track: Comparing Retrieval Methods 
for Scanned Text.  Information Retrieval, 2(2-3): 
165-176. 
Knight, K. and Graehl, J. (1998)  Machine Translit-
eration.  Computational Linguistics, 24(4):599-612. 
Kuo, J-S. and Li, H. (2008)  Mining Transliterations 
from Web Query Results: An Incremental Ap-
proach.  In Proceedings of SIGHAN-6, Hyderabad, 
India, pp.16-23. 
Li, H., Zhang, M. and Su, J. (2004)  A Joint Source-
Channel Model for Machine Transliteration.  In 
Proceedings of the 42nd Annual Meeting of ACL, 
Barcelona, Spain, pp.159-166. 
Li, H., Sim, K.C., Kuo, J-S. and Dong, M. (2007)  
Semantic Transliteration of Personal Names.  In 
Proceedings of the 45th Annual Meeting of ACL, 
Prague, Czech Republic, pp.120-127. 
Oh, J-H. and Choi, K-S. (2005)  An Ensemble of 
Grapheme and Phoneme for Machine Translitera-
tion.  In R. Dale et al (Eds.), Natural Language 
Processing ? IJCNLP 2005.  Springer, LNAI Vol. 
3651, pp.451-461. 
Tao, T., Yoon, S-Y., Fister, A., Sproat, R. and Zhai, C. 
(2006)  Unsupervised Named Entity Transliteration 
Using Temporal and Phonetic Correlation.  In Pro-
ceedings of EMNLP 2006, Sydney, Australia, 
pp.250-257. 
Virga, P. and Khudanpur, S. (2003)  Transliteration of 
Proper Names in Cross-lingual Information Re-
trieval.  In Proceedings of the ACL2003 Workshop 
on Multilingual and Mixed-language Named Entity 
Recognition. 
24
 	
 Some Considerations on Guidelines for  
Bilingual Alignment and Terminology Extraction 
 
Lawrence Cheung, Tom Lai, Robert Luk?, Oi Yee Kwong, King Kui Sin, Benjamin K. Tsou 
 
Language Information Sciences Research Centre 
City University of Hong Kong 
Tat Chee Avenue, Kowloon, Hong Kong  
{rlylc, cttomlai, rlolivia, ctsinkk, rlbtsou}@cityu.edu.hk  
?Department of Computing 
Hong Kong Polytechnic University  
Hung Hom, Kowloon, Hong Kong 
csrluk@comp.polyu.edu.hk 
 
Abstract  
Despite progress in the development of 
computational means, human input is still 
critical in the production of consistent and 
useable aligned corpora and term banks. This 
is especially true for specialized corpora and 
term banks whose end-users are often 
professionals with very stringent 
requirements for accuracy, consistency and 
coverage. In the compilation of a high quality 
Chinese-English legal glossary for ELDoS 
project, we have identified a number of issues 
that make the role human input critical for 
term alignment and extraction. They include 
the identification of low frequency terms, 
paraphrastic expressions, discontinuous units, 
and maintaining consistent term granularity, 
etc. Although manual intervention can more 
satisfactorily address these issues, steps must 
also be taken to address intra- and 
inter-annotator inconsistency.  
 
Keyword: legal terminology, bilingual 
terminology, bilingual alignment, 
corpus-based linguistics 
1. Introduction 
Multilingual terminology is an important 
language resource for a range of natural language 
processing tasks such as machine translation and 
cross-lingual information retrieval. The 
compilation of multilingual terminology is often 
time-consuming and involves much manual 
labour to be of practical use. Aligning texts of 
typologically different languages such as Chinese 
and English is even more challenging because of 
the significant differences in lexicon, syntax, 
semantics and styles. The discussion in the paper 
is based on issues arising from the extraction of 
bilingual legal terms from aligned 
Chinese-English legal corpus in the 
implementation of a bilingual a text retrieval 
system for the Judiciary of the Hong Kong Special 
Administrative Region (HKSAR) Government.  
 Much attention in computational 
terminology has been directed to the development 
of algorithms for extraction from parallel texts. 
For example, Chinese-English (Wu and Xia 1995), 
Swedish-English-Polish (Borin 2000), and 
Chinese-Korean (Huang and Choi 2000). Despite 
considerable progress, bilingual terminology so 
generated is often not ready for immediate and 
practical use. Machine extraction is often the first 
step of terminology extraction and must be used in 
conjunction with rigorous and well-managed 
manual efforts which are critical for the 
production of consistent and useable multilingual 
terminology. However, there has been relatively 
little discussion on the significance of human 
intervention. The process is far from being 
straightforward because of the different purposes 
of alignment, the requirements of target users and 
the corpus type. Indeed, there remain many 
problematical issues that will not be easy to be 
resolved satisfactorily by computational means in 
the near future, especially when typologically 
different languages are involved, and must require 
considerable manual intervention. Unfortunately, 
such critical manual input has often been treated as 
an obscure process. As with other human cognitive 
process (T?sou et al 1998), manual terminology 
markup is not a straightforward task and many 
issues deserve closer investigation. 
 In this paper, we will present some 
significant issues for Chinese-English alignment 
 and term extraction for the construction of a 
bilingual legal glossary. Section 2 describes the 
background of the associated bilingual alignment 
project. Section 3 discusses the necessity of 
manual input in bilingual alignment, and some 
principles adopted in the project to address these 
issues. Section 4 provides an outline for further 
works to improve terminology management, 
followed by a conclusion in Section 5. 
2. High Quality Terminology Alignment 
and Extraction 
2.1 Bilingual Legal Terminology in Hong 
Kong 
The implementation of a bilingual legal system in 
Hong Kong as a result of the return of 
sovereignty to China in 1997 has given rise to a 
need for the creation and standardization of 
Chinese legal terminology of the Common Law 
on par with the English one. The standardization 
of legal terminology will not only facilitate the 
mandated wider use of Chinese among legal 
professionals in various legal practices such as 
trials and production of legal documentation 
involving bilingual laws and judgments, but also 
promote greater consistency of semantic 
reference of terminology to minimize ambiguity 
and to avoid confusion of interpretation in legal 
argumentation.  
 In the early 90?s, Hong Kong law drafters 
and legal translation experts undertook the 
unprecedented task of translating Hong Kong 
Laws, which are based on the Common Law 
system, from English into Chinese. In the 
process, many new Chinese legal terms for the 
Common Law were introduced. On this basis, an 
English-Chinese Glossary of legal terms and a 
Chinese-English Glossary were published in 1995 
and 1999 respectively. The legal terminology was 
vetted by the high level Bilingual Laws Advisory 
Committee (BLAC) of Hong Kong. The 
glossaries which contain about 30,000 basic 
entries have become an important reference for 
Chinese legal terms in Hong Kong. The Bilingual 
Legal Information System (BLIS) developed by 
the Department of Justice, HKSAR provides 
simple keyword search for the glossaries and 
laws that are available in both Chinese and 
English. Nevertheless, the glossaries are far from 
being adequate for many different types of legal 
documentation, e.g. contracts, court judgments, 
etc. One major limitation of the BLIS glossary is 
its restricted coverage of legal terminology in the 
Laws of Hong Kong, within a basically 
prescriptive context as when the laws were studied 
at the time of its promulgation. There are other 
important bilingual references (Li and Poon 1998, 
Yiu and Au-Yeung 1992, Yiu and Cheung 1996) 
which focus more on the translation of Common 
Law concepts. These are almost exclusively 
nominal expressions. 
 In 2000, the City University of Hong 
Kong, in cooperation with the Judiciary, HKSAR, 
initiated a research project to develop a bilingual 
text retrieval system, Electronic Legal 
Documentation/Corpus System (ELDoS), which is 
supported by a bilingually aligned corpus of 
judgments. The purpose of the on-going project is 
twofold. First, the aligned legal corpus enables the 
retrieval of legal terms used in authentic contexts 
where the essence and spirit of the laws are tested 
(and contested) in reality, explicated and 
elaborated on, as an integral part of the evolving 
and defining body of important precedent cases 
unique to the Common Law tradition. Second, the 
corpus covers judgment texts involving 
interpretation of different language styles and 
vocabulary from Hong Kong laws. The alignment 
markup also serves as the basis for the compilation 
of a high-quality bilingual legal term bank. To 
complete the task within the tight timeframe, a 
team of annotators highly trained in law and 
language are involved in alignment markup and 
related editing. 
2.2 Need for Human Input 
The legal professionals which are the target users 
of ELDoS have very stringent demands on 
terminology in terms of accuracy, coverage and 
consistency. Aligned texts and extracted terms 
must therefore be carefully and thoroughly 
verified manually to minimize errors. 
Furthermore, many studies on terminology 
alignment and extraction deal predominantly with 
nominal expressions. Since the project aims to 
provide comprehensive information on the 
manifestations of legal vocabulary in Chinese and 
English texts, the retrieval system should not 
restrict users to nominal expressions but should 
also provide reference to many other phenomena 
such as alternation of part-of-speech (POS) (e.g. 
noun-verb alternation) inherent in bilingual texts, 
as will be seen in Section 3.  
 The availability of bilingual corpora has 
made it possible to construct representative term 
 banks. Nonetheless, current alignment and term 
extraction technology are still considered 
insufficient to meet the requirements for high 
quality terminology extraction. In ELDoS project, 
many issues are difficult to be handled 
satisfactorily by the computer in the foreseeable 
future. Although human input is essential for high 
quality term bank construction, the practice of 
manual intervention is not straightforward. 
Indeed, the manual efforts to correct the errors 
can be substantial, and the associated cost should 
not be underestimated. The annotator must first 
go through the entire texts to spot the errors and 
terms left out by the machines. In this process, 
both the source and target materials have to be 
consulted. The annotator must also ensure the 
consistency of the output. As a result, guidelines 
should be set up to streamline the process. 
3. Aspects of Terminology Alignment 
The approach adopted for the manual annotation 
of alignment markup and the maintenance of term 
bank in the ELDoS project will be described. 
Additional caution has been taken in the 
coordination of a team of annotators.  
3.1 Term Frequency 
An important reason for manual intervention in 
bilingual term alignment is the relatively poor 
recall rate for low frequency terms. Many 
extraction algorithms make use of statistical 
techniques to identify multi-word strings that 
frequently co-occur (Wu and Xia 1995; Kwong 
and Tsou 2001). These methods are less effective 
for locating low frequency terms. Of the 16,000 
terms extracted from ELDoS bilingual corpora, 
about 62% occur only once in about 80 
judgments. For high quality alignment and 
extraction, failure to include these low frequency 
terms would be totally unacceptable.  
3.2 Correspondence of Aligned Units 
Because of the different grammatical requirement 
and language style, a term in the source language 
often differs in different ways from the 
corresponding manifestations in the target 
language. These differences could be alternation 
of POS and the use of paraphrastic expressions. 
Although many term banks avoid such variations 
and focus primarily on equivalent nominals or 
verbs, the correspondence of terms between two 
typologically different languages is often more 
complicated. For example, the English nominal 
(?fulfilment?) is more naturally translated into 
Chinese as a verb (?l??, ?????, ????). 
More examples can be found in Table 1. 
 
Alternation of POS  
English  Chinese POS alternation 
The accused 
o+ 
det + adj ~ noun 
hold 
*? 
verb ~ noun 
fulfillment  
?
 
noun ~ verb 
administration  
?D 
noun ~ verb 
repudiation  
l? 
noun ~ neg + verb 
Table 1. Alternation of POS  
 
In some cases, there are simply no equivalent 
words in the target language. Paraphrasing or 
circumlocution may be necessary. Such 
correspondence is far less consistent and obvious 
to be identified by the computer.  
 
Paraphrasing/Circumlocution 
English Chinese 
The judge entered judgment in 
favour of the respondents in 
respect of their claim for arrears 
of wages, and severance payment. 
t?o31
?2??KDI
??9? 
In our view,? z??a?
 
?evidenced by the Defendant's 
letter ? 
?7:+3?}
???1$Ym
??S??? 
Table 2.  Examples of paraphrasing 
 
Because of language differences, legal terms can 
be contextually realized as anaphors in the target 
language. Examples of such correspondence 
would be useful for legal drafting and translation. 
Again, such anaphoric relations are more 
accurately handled by humans. 
 
Anaphoric Relation 
English Chinese 
He was subsequently 
charged?  
9?3??s? 
Liu JA dealt with that 
application on 14 March 
1996 and dismissed it. 
B9?t?W?
?1996?3?14?A?
 ?-??9?? 
Enforcement of a 
Convention award may 
also be refused if the 
award is in respect of a 
matter which is not capable 
of settlement by arbitration.
???*????1
??"lh?X*
?????M???
N+Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 1?9,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Data Homogeneity and Semantic Role Tagging in Chinese 
Oi Yee Kwong and Benjamin K. Tsou 
Language Information Sciences Research Centre 
City University of Hong Kong 
Tat Chee Avenue, Kowloon, Hong Kong 
{rlolivia, rlbtsou}@cityu.edu.hk 
 
 
Abstract 
This paper reports on a study of semantic 
role tagging in Chinese in the absence of a 
parser.  We tackle the task by identifying 
the relevant headwords in a sentence as a 
first step to partially locate the corre-
sponding constituents to be labelled.  We 
also explore the effect of data homogene-
ity by experimenting with a textbook cor-
pus and a news corpus, representing 
simple data and complex data respectively.  
Results suggest that while the headword 
location method remains to be improved, 
the homogeneity between the training and 
testing data is important especially in 
view of the characteristic syntax-
semantics interface in Chinese.  We also 
plan to explore some class-based tech-
niques for the task with reference to exist-
ing semantic lexicons, and to modify the 
method and augment the feature set with 
more linguistic input. 
1 Introduction 
As the development of language resources pro-
gresses from POS-tagged corpora to syntactically 
annotated treebanks, the inclusion of semantic in-
formation such as predicate-argument relations 
becomes indispensable.  The expansion of the Penn 
Treebank into a Proposition Bank (Kingsbury and 
Palmer, 2002) is a typical move in this direction.  
Lexical resources also need to be enhanced with 
semantic information (e.g. Fellbaum et al, 2001).  
The ability to identify semantic role relations cor-
rectly is essential to many applications such as in-
formation extraction and machine translation; and 
making available resources with this kind of in-
formation would in turn facilitate the development 
of such applications. 
Large-scale production of annotated resources 
is often labour intensive, and thus calls for auto-
matic labelling to streamline the process.  The task 
is essentially done in two phases, namely recognis-
ing the constituents bearing some semantic rela-
tionship to the target verb in a sentence, and then 
labelling them with the corresponding semantic 
roles. 
In their seminal proposal, Gildea and Jurafsky 
(2002) approached the task using various features 
such as headword, phrase type, and parse tree path.  
While such features have remained the basic and 
essential features in subsequent research, parsed 
sentences are nevertheless required, for extracting 
the path features during training and providing the 
argument boundaries during testing.  The parse 
information is deemed important for the perform-
ance of role labelling (Gildea and Palmer, 2002; 
Gildea and Hockenmaier, 2003). 
More precisely, parse information is rather 
more critical for the identification of boundaries of 
candidate constituents than for the extraction of 
training data.  Its limited function in training, for 
instance, is reflected in the low coverage reported 
(e.g. You and Chen, 2004).  As full parses are not 
always accessible, many thus resort to shallow syn-
tactic information from simple chunking, even 
though results often turn out to be less satisfactory 
than with full parses. 
This limitation is even more pertinent for the 
application of semantic role labelling to languages 
which do not have sophisticated parsing resources.  
In the case of Chinese, for example, there is con-
1
siderable variability in its syntax-semantics inter-
face; and when one comes to more nested and 
complex sentences such as those from news arti-
cles, it becomes more difficult to capture the sen-
tence structures by typical examples. 
Thus in the current study, we approach the 
problem in Chinese in the absence of parse infor-
mation, and attempt to identify the headwords in 
the relevant constituents in a sentence to be tagged 
as a first step.  In addition, we will explore the ef-
fect of training on different datasets, simple or 
complex, to shed light on the relative importance 
of parse information for indicating constituent 
boundaries in semantic role labelling. 
In Section 2, related work will be reviewed.  In 
Section 3, the data used in the current study will be 
introduced.  Our proposed method will be ex-
plained in Section 4, and the experiment reported 
in Section 5.  Results and future work will be dis-
cussed in Section 6, followed by conclusions in 
Section 7. 
 
2 Related Work 
The definition of semantic roles falls on a contin-
uum from abstract ones to very specific ones.  
Gildea and Jurafsky (2002), for instance, used a set 
of roles defined according to the FrameNet model 
(Baker et al, 1998), thus corresponding to the 
frame elements in individual frames under a par-
ticular domain to which a given verb belongs.  
Lexical entries (in fact not limited to verbs, in the 
case of FrameNet) falling under the same frame 
will share the same set of roles.  Gildea and Palmer 
(2002) defined roles with respect to individual 
predicates in the PropBank, without explicit nam-
ing.  To date PropBank and FrameNet are the two 
main resources in English for training semantic 
role labelling systems, as in the CoNLL-2004 
shared task (Carreras and M?rquez, 2004) and 
SENSEVAL-3 (Litkowski, 2004). 
The theoretical treatment of semantic roles is 
also varied in Chinese.  In practice, for example, 
the semantic roles in the Sinica Treebank mark not 
only verbal arguments but also modifier-head rela-
tions (You and Chen, 2004).  In our present study, 
we go for a set of more abstract semantic roles 
similar to the thematic roles for English used in 
VerbNet (Kipper et al, 2002).  These roles are 
generalisable to most Chinese verbs and are not 
dependent on particular predicates.  They will be 
further introduced in Section 3. 
Approaches in automatic semantic role label-
ling are mostly statistical, typically making use of 
a number of features extracted from parsed training 
sentences.  In Gildea and Jurafsky (2002), the fea-
tures studied include phrase type (pt), governing 
category (gov), parse tree path (path), position of 
constituent with respect to the target predicate (po-
sition), voice (voice), and headword (h).  The la-
belling of a constituent then depends on its 
likelihood to fill each possible role r given the fea-
tures and the target predicate t, as in the following, 
for example: 
 
),,,,,|( tvoicepositiongovpthrP    
 
Subsequent studies exploited a variety of im-
plementation of the learning component.  Trans-
formation-based approaches were also used (e.g. 
see Carreras and M?rquez (2004) for an overview 
of systems participating in the CoNLL shared task).  
Swier and Stevenson (2004) innovated with an un-
supervised approach to the problem, using a boot-
strapping algorithm, and achieved 87% accuracy. 
While the estimation of the probabilities could 
be relatively straightforward, the trick often lies in 
locating the candidate constituents to be labelled.  
A parser of some kind is needed.  Gildea and 
Palmer (2002) compared the effects of full parsing 
and shallow chunking; and found that when con-
stituent boundaries are known, both automatic 
parses and gold standard parses resulted in about 
80% accuracy for subsequent automatic role tag-
ging, but when boundaries are unknown, results 
with automatic parses dropped to 57% precision 
and 50% recall.  With chunking only, performance 
further degraded to below 30%.  Problems mostly 
arise from arguments which correspond to more 
than one chunk, and the misplacement of core ar-
guments.  Sun and Jurafsky (2004) also reported a 
drop in F-score with automatic syntactic parses 
compared to perfect parses for role labelling in 
Chinese, despite the comparatively good results of 
their parser (i.e. the Collins parser ported to Chi-
nese).  The necessity of parse information is also 
reflected from recent evaluation exercises.  For 
instance, most systems in SENSEVAL-3 used a 
parser to obtain full syntactic parses for the sen-
tences, whereas systems participating in the 
CoNLL task were restricted to use only shallow 
2
syntactic information.  Results reported in the for-
mer tend to be higher.  Although the dataset may 
be a factor affecting the labelling performance, it 
nevertheless reinforces the usefulness of full syn-
tactic information. 
According to Carreras and M?rquez (2004), for 
English, the state-of-the-art results reach an F1 
measure of slightly over 83 using gold standard 
parse trees and about 77 with real parsing results.  
Those based on shallow syntactic information is 
about 60. 
In this work, we study the problem in Chinese, 
treating it as a headword identification and label-
ling task in the absence of parse information, and 
examine how the nature of the dataset could affect 
the role tagging performance. 
3 The Data 
3.1 Materials 
In this study, we used two datasets: sentences from 
primary school textbooks were taken as examples 
for simple data, while sentences from a large cor-
pus of newspaper texts were taken as complex ex-
amples. 
Two sets of primary school Chinese textbooks 
popularly used in Hong Kong were taken for refer-
ence.  The two publishers were Keys Press and 
Modern Education Research Society Ltd.  Texts 
for Primary One to Six were digitised, segmented 
into words, and annotated with parts-of-speech 
(POS).  This results in a text collection of about 
165K character tokens and upon segmentation 
about 109K word tokens (about 15K word types).  
There were about 2,500 transitive verb types, with 
frequency ranging from 1 to 926. 
The complex examples were taken from a sub-
set of the LIVAC synchronous corpus1 (Tsou et al, 
2000; Kwong and Tsou, 2003).   The subcorpus 
consists of newspaper texts from Hong Kong, in-
cluding local news, international news, financial 
news, sports news, and entertainment news, col-
lected in 1997-98.  The texts were segmented into 
words and POS-tagged, resulting in about 1.8M 
character tokens and upon segmentation about 1M 
word tokens (about 47K word types).  There were 
about 7,400 transitive verb types, with frequency 
ranging from 1 to just over 6,300. 
                                                          
                                                          
1 http://www.livac.org 
3.2 Training and Testing Data 
For the current study, a set of 41 transitive verbs 
common to the two corpora (hereafter referred to 
as textbook corpus and news corpus), with fre-
quency over 10 and over 50 respectively, was 
sampled.   
Sentences in the corpora containing the sam-
pled verbs were extracted.  Constituents corre-
sponding to semantic roles with respect to the 
target verbs were annotated by a trained human 
annotator and the annotation was verified by an-
other.  In this study, we worked with a set of 11 
predicate-independent abstract semantic roles.  
According to the Dictionary of Verbs in Contem-
porary Chinese (Xiandai Hanyu Dongci Dacidian, 
????????? ? Lin et al, 1994), our se-
mantic roles include the necessary arguments for 
most verbs such as agent and patient, or goal and 
location in some cases; and some optional argu-
ments realised by adjuncts, such as quantity, in-
strument, and source.  Some examples of semantic 
roles with respect to a given predicate are shown in 
Figure 1. 
Altogether 980 sentences covering 41 verb 
types in the textbook corpus were annotated, re-
sulting in 1,974 marked semantic roles (constitu-
ents); and 2,122 sentences covering 41 verb types 
in the news corpus were annotated, resulting in 
4,933 marked constituents2. 
The role labelling system was trained on 90% 
of the sample sentences from the textbook corpus 
and the news corpus separately; and tested on the 
remaining 10% of both corpora.   
4 Automatic Role Labelling 
The automatic labelling was based on the statistical 
approach in Gildea and Jurafsky (2002).  In Sec-
tion 4.1, we will briefly mention the features used 
in the training process.  Then in Sections 4.2 and 
4.3, we will explain our approach for locating 
headwords in candidate constituents associated 
with semantic roles, in the absence of parse infor-
mation. 
2 These figures only refer to the samples used in the current 
study.  In fact over 35,000 sentences in the LIVAC corpus 
have been semantically annotated, covering about 1,500 verb 
types and about 80,000 constituents were marked. 
3
4.1 Training 
In this study, our probability model was based 
mostly on parse-independent features extracted 
from the training sentences, namely: 
 
Headword (head): The headword from each con-
stituent marked with a semantic role was identified.  
For example, in the second sentence in Figure 1, 
?? (school) is the headword in the constituent 
corresponding to the agent of the verb ?? (hold), 
and ?? (contest) is the headword of the noun 
phrase corresponding to the patient. 
 
Position (posit): This feature shows whether the 
constituent being labelled appears before or after 
the target verb.  In the first example in Figure 1, 
the experiencer and time appear on the left of the 
target, while the theme is on its right. 
 
POS of headword (HPos): Without features pro-
vided by the parse, such as phrase type or parse 
tree path, the POS of the headword of the labelled 
constituent could provide limited syntactic infor-
mation. 
 
Preposition (prep): Certain semantic roles like 
time and location are often realised by preposi-
tional phrases, so the preposition introducing the 
relevant constituents would be an informative fea-
ture. 
 
Hence for automatic labelling, given the target 
verb t, the candidate constituent, and the above 
features, the role r which has the highest probabil-
ity for P(r | head, posit, HPos, prep, t) will be as-
signed to that constituent.  In this study, however, 
we are also testing with the unknown boundary 
condition where candidate constituents are not 
available in advance.  To start with, we attempt to 
partially locate them by identifying their head-
words first, as explained in the following sections.  
 
 
 
Figure 1  Examples of semantic roles with respect to a given predicate 
 
 
4.2 Locating Candidate Headwords 
In the absence of parse information, and with con-
stituent boundaries unknown, we attempt to par-
tially locate the candidate constituents by 
identifying their corresponding headwords first.  
Sentences in our test data were segmented into 
words and POS-tagged.  We thus divide the recog-
nition process into two steps, locating the head-
word of a candidate constituent first, and then 
expanding from the headword to determine its 
boundaries. 
Student 
? ?? ?? ?? ? ?? ?? 
Next week school hold tell story contest 
Time Agent Target Patient 
Example: (Next week, the school will hold a story-telling contest.) 
?? ? ?? ?? ?? ? ? 
(-pl) write essay always feel (neg) anything 
Experiencer Target Theme 
Example: (Students always feel there is nothing to write about for their essays.) 
?   ?
time 
?? ? 
can 
Time 
write 
4
Basically, if we consider every word in the 
same sentence with the target verb (both to its left 
and to its right) a potential headword for a candi-
date constituent, what we need to do is to find out 
the most probable words in the sentence to match 
against individual semantic roles.  We start with a 
feature set with more specific distributions, and 
back off to feature sets with less specific distribu-
tions3.  Hence in each round we look for 
 
)|(maxarg setfeaturerP
r
 
 
for every candidate word.  Ties are resolved by 
giving priority to the word nearest to the target 
verb in the sentence. 
Figure 2 shows an example illustrating the pro-
cedures for locating candidate headwords.  The 
target verb is ?? (discover).  In the first round, 
using features head, posit, HPos, and t, ?? (time) 
and ?? (problem) were identified as Time and 
Patient respectively.  In the fourth subsequent 
round, backing off with features posit and HPos, 
?? (we) was identified as a possible Agent.  In 
this round a few other words were identified as 
potential Patients.  However, they would not be 
considered since Patient was already located in a 
previous round.  So in the end the headwords iden-
tified for the test sentence are ?? for Agent, ?
? for Patient and ?? for Time. 
4.3 Constituent Boundary 
Upon the identification of headwords for potential 
constituents, the next step is to expand from these 
headwords for constituent boundaries.  Although 
we are not doing this step in the current study, it 
can potentially be done via some finite state tech-
niques, or better still, with shallow syntactic proc-
essing like simple chunking if available. 
                                                          
3 In this experiment, we back off in the following order: 
P(r|head, posit, HPos, prep t), P(r|head, posit, t), P(r | head, t), 
P(r | HPos, posit, t), P(r | HPos, t).  However, the prep feature 
becomes obsolete when constituent boundaries are unknown. 
5 The Experiment 
5.1 Testing 
The system was trained on the textbook corpus and 
the news corpus separately, and tested on both cor-
pora (the data is homogeneous if the system is 
trained and tested on materials from the same 
source).  The testing was done under the ?known 
constituent? condition and ?unknown constituent? 
condition.  The former essentially corresponds to 
the known-boundary condition in related studies; 
whereas in the unknown-constituent condition, 
which we will call ?headword location? condition 
hereafter, we tested our method of locating candi-
date headwords as explained above in Section 4.2.  
In this study, every noun, verb, adjective, pronoun, 
classifier, and number within the test sentence con-
taining the target verb was considered a potential 
headword for a candidate constituent correspond-
ing to some semantic role.  The performance was 
measured in terms of the precision (defined as the 
percentage of correct outputs among all outputs), 
recall (defined as the percentage of correct outputs 
among expected outputs), and F1 score which is the 
harmonic mean of precision and recall. 
5.2 Results 
The results are shown in Tables 1 and 2, for train-
ing on homogeneous dataset and different dataset 
respectively, and testing under the known constitu-
ent condition and the headword location condition. 
When trained on homogeneous data, the results 
were good on both datasets under the known con-
stituent condition, with an F1 score of about 90.  
This is comparable or even better to the results re-
ported in related studies for known boundary con-
dition.  The difference is that we did not use any 
parse information in the training, not even phrase 
type.  When trained on a different dataset, however, 
the accuracy was maintained for textbook data, but 
it decreased for news data, for the known constitu-
ent condition. 
For the headword location condition, the per-
formance in general was expectedly inferior to that 
for the known constituent condition.  Moreover, 
this degradation seemed to be quite consistent in 
most cases, regardless of the nature of the training 
set.  In fact, despite the effect of training set on 
news data, as mentioned above, the degradation 
5
Sentence: 
?????????????????????????????????????
During revision, we discover a lot o
? 
f problems which we have not thought of or cannot be 
solved, then we go and ask father. 
Candidate  Round 1       ? Round 4    Final Result 
eadwords 
n) 
H
 
?? (revisio    Patient
?? (time)  Time            ----       Time 
?? (we)    Agent       Agent 
k)    Patient
?? (normally) 
?? (thin
? (can) 
?? (solve)    Patient
?? (problem)  Patient    ----       Patient 
? (go)     Patient
? (ask)     Patient
from known constituent to headword location is 
nevertheless the least fo
?? (father)    Patient
r news data when trained 
on 
remature at this stage, given the considerable dif-
 
 
 
Figure 2  Example illustrating the procedures for locating candidate headwords 
  
 
Tex ata News a 
different materials.   
Hence the effect of training data is only obvious 
in the news corpus.  In other words, both sets of 
training data work similarly well with textbook test 
data, but the performance on news test data is 
worse when trained on textbook data.  This is un-
derstandable as the textbook data contain fewer 
examples and the sentence structures are usually 
much simpler than those in newspapers.  Hence the 
system tends to miss many secondary roles like 
location and time, which are not sufficiently repre-
sented in the textbook corpus.  The conclusion that 
training on news data gives better result might be 
ference in the corpus size of the two datasets.  
Nevertheless, the deterioration of results on text-
book sentences, even when trained on news data, is 
simply reinforcing the importance of data homoge-
neity, if nothing else.  More on data homogeneity 
will be discussed in the next section. 
p
In addition, the surprisingly low precision under 
the headword location condition is attributable to a 
technical inadequacy in the way we break ties.  In 
this study we only make an effort to eliminate mul-
tiple tagging of the same role to the same target 
verb in a sentence on either side of the target verb, 
but not if they appear on both sides of the target 
verb.  This should certainly be dealt with in future 
experiments. 
 
 
 
 
 tbook D Dat
 P  Precisionrecision Recall F1 Recall F1
Known Constituent 93.85 87.50 90.56 90.49 87.70 89.07 
Headword Location 46.12 61.98 52.89 38.52 52.25 44.35 
 
Table 1  Results for Training on Homogeneous Datasets 
 
 
6
 
Tex ata News a  tbook D Dat
 P  Precisionrecision Recall F1 Recall F1
Known Constituent 91.85 88.02 89.86 80.30 66.80 72.93 
Headword Location 38.87 57.29 46.32 37.89 42.01 39.84 
 
Table 2  Results for Training on Different Datasets 
 
6 Discussion 
 
hen
cuss this below in relation to 
n?, duration as in 
??
d the parse information 
wo
verb ?? , being very 
pol
he design 
he feature set should benefit 
 m nalysis and input. 
 
6.1 Role of Parse Information 
According to Carreras and M?rquez (2004), the 
state-of-the-art results for semantic role labelling 
systems based on shallow syntactic information is 
about 15 lower than those with access to gold stan-
dard parse trees, i.e., around 60.  With homogene-
ous training and testing data, our experimental 
results for the headword location condition, with 
no syntactic information available at all, give an F1 
score of 52.89 and 44.35 respectively for textbook 
data and news data.  Such results are in line with 
and comparable to those reported for the unknown 
boundary condition with automatic parses in 
Gildea and Palmer (2002), for instance.  Moreover, 
when they used simple chunks instead of full 
parses, the performance resulted in a drop to below 
50% precision and 35% recall with relaxed scoring,
ce their conclusion on the necessity of a parser. 
The more degradation in performance observed 
in the news data is nevertheless within expectation, 
and it suggests that simple and complex data seem 
to have varied dependence on parse information.  
We will further dis
data homogeneity. 
6.2 Data Homogeneity 
The usefulness of parse information for semantic 
role labelling is especially interesting in the case of 
Chinese, given the flexibility in its syntax-
semantics interface (e.g. the object after ? ?eat? 
could refer to the patient as in ??? ?eat apple?, 
location as in ??? ?eat cantee
? ?eat three years?, etc.).   
  As reflected from the results, the nature of 
training data is obviously more important for the 
news data than the textbook data; and the main 
reason might be the failure of the simple training 
data to capture the many complex structures of the 
news sentences, as we suggested earlier.  The rela-
tive flexibility in the syntax-semantics interface of 
Chinese is particularly salient; hence when a sen-
tence gets more complicated, there might be more 
intervening constituents an
uld be useful to help identify the relevant ones 
in semantic role labelling. 
With respect to the data used in the experiment, 
we tried to explore the complexity in terms of the 
average sentence length and number of semantic 
role patterns exhibited.  For the news data, the av-
erage sentence length is around 59.7 characters 
(syllables), and the number of semantic role pat-
terns varies from 4 (e.g. ?? ?to plan?) to as many 
as 25 (e.g. ?? ?to proceed with some action?), 
with an average of 9.5 patterns per verb.  On the 
other hand, the textbook data give an average sen-
tence length of around 39.7 characters, and the 
number of semantic role patterns only varies from 
1 (e.g. ?? ?to decide?) to 11 (e.g. ?? ?to hold 
some event?), with an average of 5.1 patterns per 
verb.  Interestingly, the 
ymorphous in news texts, only shows 5 differ-
ent patterns in textbooks. 
Thus the nature of the dataset for semantic role 
labelling is worth further investigation.  T
of the method and t
from ore linguistic a
6.3 Future Work 
In terms of future development, apart from improv-
ing the handling of ties in our method, as men-
tioned above, we plan to expand our work in 
several respects.  The major part would be on the 
generalization to unseen headwords and unseen 
predicates.  As is with other related studies, the 
examples available for training for each target verb 
are very limited; and the availability of training 
data is also insufficient in the sense that we cannot 
expect them to cover all target verb types.  Hence 
7
it is very important to be able to generalize the 
process to unseen words and predicates.  To this 
end we will experiment with a semantic lexicon 
like Tongyici Cilin (?????, a Chinese the-
sau
re of 
Chinese, we intend to improve our method and 
re linguistic consideration. 
 
 
 semantic lexicons, 
and to modify the method and augment the feature 
set with more linguistic input. 
This work is supported by Competitive Earmarked 
Research Grants (CERG) of the Research Grants 
Hong Kong under grant Nos. 
R
Ba
 the 
Ca troduction to the 
Fe
Resources, Invited Talk, Pittsburg, PA. 
Gi D. and Palmer, M. (2002)  The Necessity of 
Gi kenmaier, J. (2003)  Identifying Se-
Kw
r Part-of-speech 
Tagging. In Proceedings of the Research Note Ses-
sion of the 10th Conference of the European Chapter 
rus) in both training and testing, which we ex-
pect to improve the overall performance. 
Another area of interest is to look at the behav-
iour of near-synonymous predicates in the tagging 
process.  Many predicates may be unseen in the 
training data, but while the probability estimation 
could be generalized from near-synonyms as sug-
gested by a semantic lexicon, whether the similar-
ity and subtle differences between near-synonyms 
with respect to the argument structure and the cor-
responding syntactic realisation could be distin-
guished would also be worth studying.  Related to 
this is the possibility of augmenting the feature set.  
Xue and Palmer (2004), for instance, looked into 
new features such as syntactic frame, lexicalized 
constituent type, etc., and found that enriching the 
feature set improved the labelling performance.  In 
particular, given the importance of data homogene-
ity as observed from the experimental results, and 
the challenges posed by the characteristic natu
feature set with mo
7 Conclusion 
The study reported in this paper has thus tackled 
semantic role labelling in Chinese in the absence of 
parse information, by attempting to locate the cor-
responding headwords first.  We experimented 
with both simple and complex data, and have ex-
plored the effect of training on different datasets. 
Using only parse-independent features, our results 
under the known boundary condition are compara-
ble to those reported in related studies.  The head-
word location method can be further improved. 
More importantly, we have observed the impor-
tance of data homogeneity, which is especially sa-
lient given the relative flexibility of Chinese in its 
syntax-semantics interface.  As a next step, we 
plan to explore some class-based techniques for the 
task with reference to existing
 
Acknowledgements 
Council of 
CityU1233/01H and CityU1317/03H. 
 
eferences 
ker, C.F., Fillmore, C.J. and Lowe, J.B. (1998)  The 
Berkeley FrameNet Project.  In Proceedings of
36th Annual Meeting of the Association for Computa-
tional Linguistics and the 17th International Confer-
ence on Computational Linguistics (COLING-
ACL ?98), Montreal, Quebec, Canada, pp.86-90. 
rreras, X. and M?rquez, L. (2004)  In
CoNLL-2004 Shared Task: Semantic Role Labeling.  
In Proceedings of the Eighth Conference on Compu-
tational Natural Language Learning (CoNLL-2004), 
Boston, Massachusetts, pp.89-97. 
llbaum, C., Palmer, M., Dang, H.T., Delfs, L. and 
Wolf, S. (2001)  Manual and Automatic Semantic 
Annotation with WordNet.  In Proceedings of the 
NAACL-01 SIGLEX Workshop on WordNet and 
Other Lexical 
Gildea, D. and Jurafsky, D. (2002)  Automatic Labeling 
of Semantic Roles.  Computational Linguistics, 28(3): 
245-288. 
ldea, 
Parsing for Predicate Argument Recognition.  In Pro-
ceedings of the 40th Meeting of the Association for 
Computational Linguistics (ACL-02), Philadelphia, 
PA. 
ldea, D. and Hoc
mantic Roles Using Combinatory Categorial Gram-
mar.  In Proceedings of the 2003 Conference on 
Empirical Methods in Natural Language Processing, 
Sapporo, Japan. 
Kingsbury, P. and Palmer, M. (2002)  From TreeBank 
to PropBank.  In Proceedings of the Third Confer-
ence on Language Resources and Evaluation (LREC-
02), Las Palmas, Canary Islands, Spain. 
Kipper, K., Palmer, M. and  Rambow, O. (2002)  Ex-
tending PropBank with VerbNet Semantic Predicates.  
In Proceedings of the AMTA-2002 Workshop on Ap-
plied Interlinguas, Tiburon, CA. 
ong, O.Y. and Tsou, B.K. (2003) Categorial Fluidity 
in Chinese and its Implications fo
8
of the Association for Computational Linguistics, 
Budapest, Hungary, pages 115-118. 
n, X., Wang, L. and Sun, D. Li (1994)  Dictionary of 
Li
uation of 
(
Sun
apter of the Association for Computa-
Swi
Ts
ings of 
Xu
2004 
Yo
.109-115. 
? ongguo Yuwen.  Primary 1-6, 
24 volumes, 2004.  Hong Kong: Modern Education 
Research Society Ltd. 
 
Verbs in Contemporary Chinese.  Beijing Language 
and Culture University Press. 
tkowski, K.C. (2004) SENSEVAL-3 Task: Automatic 
Labeling of Semantic Roles.  In Proceedings of the 
Third International Workshop on the Eval
Systems for the Semantic Analysis of Text 
SENSEVAL-3), Barcelona, Spain, pp.9-12. 
, H. and Jurafsky, D. (2004)  Shallow Semantic 
Parsing of Chinese.  In Proceedings of the Human 
Language Technology Conference of the North 
American Ch
tional Linguistics (HLT-NAACL 2004), Boston, 
pp.249-256. 
er, R.S. and Stevenson, S. (2004)  Unsupervised 
Semantic Role Labelling.  In Proceedings of the 
2004 Conference on Empirical Methods in Natural 
Language Processing, Barcelona, Spain, pp.95-102. 
ou, B.K., Tsoi, W.F., Lai, T.B.Y., Hu, J. and Chan, 
S.W.K. (2000)  LIVAC, A Chinese Synchronous 
Corpus, and Some Applications.  In Proceed
the ICCLC International Conference on Chinese 
Language Computing, Chicago, pp. 233-238. 
e, N. and Palmer, M. (2004)  Calibrating Features for 
Semantic Role Labeling.  In Proceedings of the 
Conference on Empirical Methods in Natural Lan-
guage Processing, Barcelona, Spain, pp.88-94. 
u, J-M. and Chen, K-J. (2004)  Automatic Semantic 
Role Assignment for a Tree Structure.  In Proceed-
ings of the 3rd SigHAN Workshop on Chinese Lan-
guage Processing, ACL-04, Barcelona, pp
?????? Qisi Zhongguo Yuwen.  Primary 1-6, 24 
volumes, 2004.  Hong Kong: Keys Press. 
????? Xiandai Zh
9
Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 9?16,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Regional Variation of Domain-Specific Lexical Items: Toward a Pan-
Chinese Lexical Resource 
 
 
Oi Yee Kwong and Benjamin K. Tsou 
Language Information Sciences Research Centre 
City University of Hong Kong 
Tat Chee Avenue, Kowloon, Hong Kong 
{rlolivia,rlbtsou}@cityu.edu.hk 
 
  
 
Abstract 
This paper reports on an initial and nec-
essary step toward the construction of a 
Pan-Chinese lexical resource.  We inves-
tigated the regional variation of lexical 
items in two specific domains, finance 
and sports; and explored how much of 
such variation is covered in existing Chi-
nese synonym dictionaries, in particular 
the Tongyici Cilin.  The domain-specific 
lexical items were obtained from subsec-
tions of a synchronous Chinese corpus, 
LIVAC.  Results showed that 20-40% of 
the words from various subcorpora are 
unique to the individual communities, 
and as much as 70% of such unique items 
are not yet covered in the Tongyici Cilin.  
The results suggested great potential for 
building a Pan-Chinese lexical resource 
for Chinese language processing.  Our 
next step would be to explore automatic 
means for extracting related lexical items 
from the corpus, and to incorporate them 
into existing semantic classifications. 
1 Introduction 
Many cities have underground railway systems.  
Somehow one takes the tube in London but the 
subway in New York.  In a more recent edition 
of the Roget?s Thesaurus (Kirkpatrick, 1987), 
subway, tube, underground railway and metro 
are found in the same semicolon-separated group 
under head 624 Way.  Similarly if one looks up 
WordNet (http://wordnet.princeton.edu; Miller et 
al., 1990), the synset to which subway belongs 
also contains the words metro, tube, under-
ground, and subway system; and it is further in-
dicated that ?in Paris the subway system is called 
the ?metro? and in London it is called the ?tube? 
or the ?underground??.  Such regional lexical 
variation is also found in Chinese.  For instance, 
the subway system in Hong Kong, known as the 
Mass Transit Railway or MTR, is called ?? in 
Chinese.  The subway systems in Beijing and 
Shanghai, as well as the one in Singapore, are 
also known as ??, but that in Taipei is known 
as ??.  Their counterpart in Japan is written as 
??? in Kanji.  Such regional variation, as part 
of lexical knowledge, is important and useful for 
many natural language applications, including 
natural language understanding, information re-
trieval, and machine translation.  Unfortunately, 
existing Chinese lexical resources often lack 
such comprehensiveness. 
To fill this gap, Tsou and Kwong (2006) pro-
posed a comprehensive Pan-Chinese lexical re-
source, based on a large and unique synchronous 
Chinese corpus as an authentic basis for lexical 
acquisition and analysis across various Chinese 
speech communities.  For a significant world 
language like Chinese, a useful lexical resource 
should have maximum versatility and portability.  
It is not sufficient to target at one particular 
community speaking the language and thus cover 
only language usage observed from that particu-
lar community.  Instead, such a lexical resource 
should document the core and universal sub-
stances of the language on the one hand, and also 
the more subtle variations found in different 
communities on the other.  As is evident from the 
above example on the variation of subway, re-
gional variation should be captured for the lexi-
cal resource to be useful in a wide range of ap-
plications. 
In this study, we investigate and compare the 
regional variation of lexical items from two spe-
9
cific domains, finance and sports, as an initial 
and necessary step toward the more important 
undertaking of building a Pan-Chinese lexical 
resource.  In addition, we make use of an exist-
ing Chinese synonym dictionary, the Tongyici 
Cilin (Mei et al, 1984) as leverage, and explore 
its coverage of such variation and thus the poten-
tial for enriching it.  The lexical items under 
study were obtained from a synchronous Chinese 
corpus, LIVAC, which will be further introduced 
in Section 4.  Corpus data from four Chinese 
speech communities were compared with respect 
to their commonality and uniqueness, and also 
against Cilin for their coverage.  Results showed 
that 20-40% of the words extracted from the cor-
pus are unique to the individual communities, 
and as much as 70% of such unique items are not 
yet covered in Cilin.  It therefore suggests that 
the synchronous corpus is a rich source for 
mining region-specific lexical items, and there is 
great potential for building a Pan-Chinese lexical 
resource for Chinese language processing. 
In Section 2, we will briefly review existing 
resources and related work.  Then in Section 3, 
we will briefly outline the design and architec-
ture of the Pan-Chinese lexical resource pro-
posed by Tsou and Kwong (2006).  In Section 4, 
we will further describe the Chinese synonym 
dictionary and the synchronous Chinese corpus 
used in this study.  The comparison of their lexi-
cal items will be discussed in Section 5.  Future 
directions will be presented in Section 6, fol-
lowed by a conclusion. 
2 Existing Resources and Related Work 
The construction and development of large 
lexical resources is relying more and more on 
corpus-based approaches, not only as a result of 
the increased availability of large corpora, but 
also for the authoritativeness and authenticity 
allowed by the approach.  The Collins 
COBUILD English Dictionary (Sinclair, 1987) is 
amongst the most well-known lexicographic fruit 
based on large corpora. 
For natural language applications, much of the 
information in conventional dictionaries targeted 
at human readers must be made explicit.  Lexical 
resources for computer use thus need consider-
able manipulation, customisation, and supple-
mentation (e.g. Calzolari, 1982).  WordNet 
(Miller et al, 1990), grouping words into synsets 
and linking them up with relational pointers, is 
probably the first broad coverage general compu-
tational lexical database.  In view of the intensive 
time and effort required in resource building, 
some researchers have taken an alternative route 
by extracting information from existing machine-
readable dictionaries and corpora semi-
automatically (e.g. Vossen et al, 1989; Riloff 
and Shepherd, 1999; Lin et al 2003). 
Compared to the development of thesauri and 
lexical databases, and research into semantic 
networks for major languages such as English, 
similar work for the Chinese language is less 
mature.  This gap was partly due to the lack of 
authoritative Chinese corpora as a basis for 
analysis, but has been gradually reduced with the 
recent availability of large Chinese corpora in-
cluding the LIVAC synchronous corpus (Tsou 
and Lai, 2003) used in this work and further de-
scribed below, the Sinica Corpus (Chen et al, 
1996), the Chinese Penn Treebank (Xia et al, 
2000), and the like. 
An important issue which is seldom addressed 
in the construction of Chinese lexical databases 
is the problem of versatility and portability.  For 
a language such as Chinese which is spoken in 
many different communities, different linguistic 
norms have emerged as a result of the individual-
istic evolution and development of the language 
within a particular community and culture.  Such 
variations are seldom adequately reflected in ex-
isting lexical resources, which often only draw 
reference from one particular source.  For in-
stance, Tongyici Cilin (?????) (Mei et al, 
1984) is a thesaurus containing some 70,000 
Chinese lexical items in the tradition of the Ro-
get?s Thesaurus for English, that is, in a hierar-
chy of broad conceptual categories.  First pub-
lished in the 1980s, it was based exclusively on 
Chinese as used in post-1949 Mainland China.  
Thus for the subway example above, the closest 
word group found is ??, ?? (train) only, let 
alone the subway itself and its regional variations. 
With the recent availability of large corpora, 
especially synchronous ones, to construct an au-
thoritative and timely lexical resource for Chi-
nese is less distant than it was in the past.  A 
large synchronous corpus provides authentic ex-
amples of the language as used in a variety of 
locations.  It thus enables us to attempt a com-
prehensive and in-depth analysis of the core 
common language in constructing a lexical re-
source; and to incorporate useful information 
relating to location-sensitive linguistic variations. 
10
3 Proposal of a Pan-Chinese Thesaurus 
The Pan-Chinese lexicon proposed by Tsou and 
Kwong (2006) is expected to capture not only the 
core senses of lexical items but also senses and 
uses specific to individual Chinese speech 
communities. 
The lexical database will be organised into a 
core database and a supplementary one.  The 
core database will contain the core lexical infor-
mation for word senses and usages which are 
common to most Chinese speech communities, 
whereas the supplementary database will contain 
the language uses specific to individual commu-
nities, including ?marginal? and ?sublanguage? 
uses. 
A network structure will be adopted for the 
lexical items.  The nodes could be sets of near-
synonyms or single lexical items (in which case 
synonymy will be one type of links).  The links 
will not only represent the paradigmatic semantic 
relations but also syntagmatic ones (such as se-
lectional restrictions). 
We thus begin by investigating in depth the 
regional variation of lexical items, especially 
domain-specific words, among several Chinese 
speech communities.  In addition, we explore the 
potential of enriching existing resources as a start.  
In the following section, we will discuss the 
Tongyici Cilin and the synchronous Chinese cor-
pus used in this study in greater details. 
4 Materials and Method 
4.1 The Tongyici Cilin 
The Tongyici Cilin (?????) (Mei et al, 
1984) is a Chinese synonym dictionary, or more 
often known as a Chinese thesaurus in the tradi-
tion of the Roget?s Thesaurus for English.  The 
Roget?s Thesaurus has about 1,000 numbered 
semantic heads, more generally grouped under 
higher level semantic classes and subclasses, and 
more specifically differentiated into paragraphs 
and semicolon-separated word groups.  Similarly, 
some 70,000 Chinese lexical items are organized 
into a hierarchy of broad conceptual categories in 
the Tongyici Cilin.  Its classification consists of 
12 top-level semantic classes, 94 sub-classes, 
1,248 semantic heads and 3,925 paragraphs. 
4.2 The LIVAC Synchronous Corpus 
LIVAC (http://www.livac.org) stands for Lin-
guistic Variation in Chinese Speech Communi-
ties.  It is a synchronous corpus developed by the 
Language Information Sciences Research Centre 
of the City University of Hong Kong since 1995 
(Tsou and Lai, 2003).  The corpus consists of 
newspaper articles collected regularly and syn-
chronously from six Chinese speech communi-
ties, namely Hong Kong, Beijing, Taipei, Singa-
pore, Shanghai, and Macau.  Texts collected 
cover a variety of domains, including front page 
news stories, local news, international news, edi-
torials, sports news, entertainment news, and fi-
nancial news.  Up to December 2005, the corpus 
has already accumulated about 180 million char-
acter tokens which, upon automatic word seg-
mentation and manual verification, amount to 
over 900K word types. 
For the present study, we make use of the sub-
corpora collected over the 9-year period 1995-
2004 from Hong Kong (HK), Beijing (BJ), 
Taipei (TW), and Singapore (SG).  In particular, 
we focus on the financial news and sports news 
to investigate the commonality and uniqueness of 
the lexical items used in these specific domains 
in the various communities.  We also evaluate 
the adequacy of the Tongyici Cilin in terms of its 
coverage of such domain-specific terms espe-
cially from the Pan-Chinese perspective, and 
thus assess the room for its enrichment with the 
synchronous corpus.  Table 1 shows the sizes of 
the subcorpora used for this study. 
 
Subcorpus Overall 
(rounded to nearest 0.01M) 
Financial News 
(rounded to nearest 1K) 
Sports News 
(rounded to nearest 1K) 
 Word Token Word Type Word Token Word Type Word Token Word Type 
HK 14.39M 0.22M 970K 38K 1041K 39K 
BJ 11.70M 0.19M 232K 20K 443K 28K 
TW 12.32M 0.20M 254K 22K 657K 33K 
SG 13.22M 0.21M 621K 28K 998K 34K 
Table 1  Sizes of individual subcorpora 
 
11
4.3 Procedures 
Word-frequency lists were generated from the 
financial and sports subcorpora from each indi-
vidual community.  For each resulting list, the 
steps below were followed to remove irrelevant 
items and retain only the potentially useful con-
tent words: 
(a) Remove all numbers and non-Chinese words. 
(b) Remove all proper names, including those 
annotated as personal names, geographical 
names, and organisation names.  Proper 
names have been annotated in the corpora 
during the process of word segmentation. 
(c) Remove function words. 
(d) Remove lexical items with frequency 5 or 
below. 
The numbers of remaining items in each sub-
corpus after the above steps are listed in Tables 2 
and 3 for the two domains respectively.  The 
lexical items retained, which are expected to con-
tain a substantial amount of content words, are 
potentially useful for the current study.  The lists 
in each domain (from the various subcorpora) 
were compared in terms of the items they share 
and those unique to individual communities.  
Their unique items were also compared against 
the Tongyici Cilin to investigate its adequacy 
and explore how it might be enriched with the 
synchronous corpus. 
 
Subcorpus All After (a) After (b) After (c) After(d) 
HK 37,525 27,937 20,422 17,162 5,238 
BJ 20,025 17,361 14,460 12,134 2,791 
TW 22,142 19,428 16,316 13,496 3,088 
SG 28,193 22,829 16,863 13,822 3,836 
Table 2  Number of word types remaining after various data cleaning steps for the financial domain 
 
Subcorpus All After (a) After (b) After (c) After(d) 
HK 39,190 35,720 25,289 21,502 6,316 
BJ 27,971 26,049 19,799 16,598 3,878 
TW 32,706 30,231 20,361 17,248 4,601 
SG 34,040 31,974 19,995 16,780 5,120 
Table 3  Number of word types remaining after various data cleaning steps for the sports domain 
 
5 Results and Discussion 
5.1 Lexical Items from LIVAC 
The four subcorpora of the financial domain 
differ considerably in their sizes, and slightly less 
so for the sports domain.  Despite this, we ob-
served for both domains from Tables 2 and 3 that 
in general about 40-50% of all word types are 
numbers, non-Chinese words, proper names, and 
function words.  Of the remaining items, about 
20-30% have frequency greater than 5.  These 
several thousand word types from each subcor-
pus are expected to be amongst the more interest-
ing items and form the ?candidate sets? for fur-
ther investigation. 
5.2 Commonality among Various Regions  
Comparing the candidate sets from various sub-
corpora, which reflect the use of Chinese in vari-
ous Chinese speech communities, Tables 4 and 5 
show the sizes of the intersection sets among 
different places for the two domains respectively. 
The intersection set for all four places contains 
slightly more than 1,000 lexical items in the fi-
nancial domain.  A quick skim through these 
common lexical items suggests that they contain, 
on the one hand, the many general concepts in 
the financial domain (e.g. ?? company, ?? 
market, ?? bank, ?? invest / investment, ?
? business, ?? develop / development, ?? 
corporation, ?? stock shares, ?? shareholder, 
?? capital, etc.); and on the other hand, many 
reportage and cognitive verbs often used in news 
articles (e.g. ?? express, ?? reckon, ?? 
appear, ?? reflect, etc.). 
In the sports domain, more than 1,700 lexical 
items were found in all of the four subcorpora.  
Like its financial counterpart, we found many 
general concepts at the top of the list (e.g. ?? 
player, ?? team, ?? match, ?? competi-
12
tion, ?? league, ?? coach, ?? opponent, 
?? champion, etc.). 
The numbers of overlaps in Tables 4 suggest 
that lexical items used in Mainland China (as 
evident from BJ data) seem to have the least in 
common with the rest.  For instance, compared to 
the overlap amongst all four regions (i.e. 1,039), 
the overlap has increased most when BJ was not 
included in the comparison; and when we com-
pare any two regions, the overlap between BJ 
and TW is smallest.  Nevertheless, such unique-
ness of BJ data is less apparent in the sports do-
main.  In particular, the difference between 
HK/BJ and BJ/TW is even slightly less than that 
in the financial domain. 
If we look at the individual regions, HK ap-
parently shares most (about 50%) with SG, and 
vice versa (about 68%), in the financial domain.  
At the same time, BJ also shares more with HK 
than with the other two regions, and so does TW.  
But surprisingly, BJ has over 60% overlap with 
SG and about 55% with TW in the sports domain.  
The overlaps of TW with HK and with BJ differ 
by more than 20% in the finance domain, but 
only by about 10% in the sports domain.  All 
these patterns might suggest lexical items in the 
financial domain are more versatile and have 
more varied focus in different communities, 
whereas those in the sports domain reflect the 
more common interests of different places.   
 
Regions Overlap Proportion to individual lists (%) 
  HK BJ TW SG 
HK / BJ / TW / SG 1039 19.84 37.23 33.65 27.09 
HK / BJ / TW 1126 21.50 40.34 36.46  
HK / BJ / SG 1327 25.33 47.55  34.59 
HK / TW / SG 1581 30.18  51.20 41.21 
BJ / TW / SG 1092  39.13 35.36 28.47 
HK / BJ 1609 30.72 57.65   
HK / TW 1912 36.50  61.92  
HK / SG 2607 49.77   67.96 
BJ / TW 1250  44.79 40.48  
BJ / SG 1505  53.92  39.23 
TW / SG 1795   58.13 46.79 
Table 4  Commonality amongst various regions for the financial domain 
 
Regions Overlap Proportion to individual lists (%) 
  HK BJ TW SG 
HK / BJ / TW / SG 1668 26.41 43.01 36.25 32.58 
HK / BJ / TW 1782 28.21 45.95 38.73  
HK / BJ / SG 2047 32.41 52.78  39.98 
HK / TW / SG 2249 35.61  48.88 43.93 
BJ / TW / SG 1864  48.07 40.51 36.41 
HK / BJ 2318 36.70 59.77   
HK / TW 2693 42.64  58.53  
HK / SG 3305 52.33   64.55 
BJ / TW 2124  54.77 46.16  
BJ / SG 2554  65.86  49.88 
TW / SG 2709   58.88 52.91 
Table 5  Commonality amongst various regions for the sports domain 
 
5.3 Uniqueness of Various Regions 
Next we compared the lists with respect to what 
they have unique to themselves.  Table 6 shows 
the numbers of unique items found in each list, 
together with examples from the most frequent 
20 unique items in each case. 
Again, taking the size difference among the 
candidate sets into account, about 40% of the 
lexical items found in HK data are unique to the 
region, which re-echoes the versatility and wide 
13
coverage of interests of HK data.  This is espe-
cially evident when compared to only about 20% 
of the candidate sets for SG are unique to Singa-
pore.1 
Looking at the unique lexical items found in 
individual regions, it is not difficult to see the 
region-specific lexicalisation of certain concepts.  
For instance, in terms of housing, ?? (housing 
under the Home Ownership Scheme) is a specific 
kind of housing in Hong Kong, ?? is a specific 
term in Singapore (as seen in SG data), whereas 
housing is generally expressed as ??  in 
Mainland China (as seen in BJ data).  Similarly, 
?? (HK) and ?? (BJ) both refer to training, 
but may relate to different practice in the two 
communities.  Such regional variation lends 
strong support to the importance of a Pan-
Chinese lexical resource. 
The lists of unique items also suggest the vari-
ous focus and orientation in different Chinese 
speech communities.  For example, while Hong 
Kong pays much attention to the real estate mar-
ket and stock market, Mainland China may be 
focusing more on the basic needs like water, 
farming, poverty alleviation, etc., and Singapore 
is relatively more concerned with local affairs 
like port management.  The passion for baseball, 
among other more popular sports like soccer, is 
most obvious from the unique lexical items 
found in TW data. 
5.4 Comparison with Tongyici Cilin 
As mentioned earlier, the Tongyici Cilin contains 
some 70,000 lexical items under 12 broad se-
mantic classes, 94 subclasses, and 1,428 heads.  
It was first published in the 1980s and was based 
on lexical usages mostly of post-1949 Mainland 
China.  In this section, we discuss the results ob-
tained from comparing the unique lexical items 
found from individual subcorpora with Cilin, 
which are shown in Table 7. 
On the one hand, Cilin?s collection of words 
may be considerably dated and obviously will 
not include new concepts and neologisms arising 
in the last two decades.  On the other hand, the 
data in LIVAC come from newspaper materials 
in the 1990s.  So overall speaking, for each of the 
unique word lists, much less than 50% are cov-
ered in Cilin. 
                                                 
1 Upon further analysis, on average about 60% of these 
?unique? items were actually found in one or more of the 
other regions, but with frequency 5 or below.  Since the 
difference in frequency is quite large for most items, we can 
reasonably treat them as unique to a particular community. 
Nevertheless, there is still an apparent gap be-
tween Cilin?s coverage of the unique items from 
various places.  About 40% of the unique items 
found in BJ for both domains are covered; but 
for other places, the coverage is more often less 
than 30% in either or both domains.  Again, this 
could be considered a result of Cilin?s bias to-
ward lexical usages in Mainland China. 
In addition, while almost 40% of the unique 
items in BJ data are found in Cilin, many of 
these unique items covered are amongst the most 
frequent items.  On the contrary, even though 
about 560 unique items in HK data are also 
found in Cilin, only 3 out of the 20 most frequent 
items are amongst them.  In addition, the appar-
ent coverage does not necessarily suggest the 
correct match of word senses.  For instance, ?? 
is found under head Bn1 together with other 
items like ??, ??, etc., all of which only re-
fer to the general concept of housing, instead of 
the housing specifically under the Home Owner-
ship Scheme as known in Hong Kong.   Also, 
coverage of words like ??, ?? and ?? in 
the sports domain does not match their actual 
usages which refer to team names.  A more inter-
esting example might be ??, which is used in 
the basketball context in TW data, and in no way 
refers to the literal ?hot pot? sense. 
Results from the above comparisons thus sup-
port that (1) different Chinese speech communi-
ties have their distinct usage of Chinese lexical 
items, in terms of both form and sense; (2) such 
variation is found in different domains, such as 
the financial and sports domain; (3) existing 
lexical resources, the Tongyici Cilin in particular 
as in our current study, should be enriched and 
enhanced by capturing lexical usages from a va-
riety of Chinese speech communities, to repre-
sent the lexical items from a Pan-Chinese per-
spective; and (4) lexical items obtained from the 
synchronous Chinese corpus can supplement the 
existing content of the Tongyici Cilin, with more 
contemporarily lexicalised concepts, as well as 
variant expressions of similar and related con-
cepts from various Chinese speech communities. 
Hence it remains for us to further investigate 
how the related lexical items obtained from the 
synchronous corpus should be grouped and in-
corporated into the semantic classification of ex-
isting lexical resources; and to further explore 
how they might be extracted in a large scale by 
automatic means.  These will definitely be 
amongst the most important future directions as 
discussed in the next section. 
14
6 Future Work 
In the current study, we have investigated the 
regional variation of lexical items from the fi-
nancial and sports domain, and the coverage of 
the Tongyici Cilin for such variation.  The results 
suggested great potential for building a Pan-
Chinese lexical resource for Chinese language 
processing.  Our next step would thus be to fur-
ther investigate more automatic means for ex-
tracting the near-synonymous or closely related 
items from the various subcorpora.  To this end, 
we would explore algorithms like those used in 
Lin et al (2003).  Of similar importance is the 
mechanism for grouping the related lexical items 
and incorporating them into the semantic classi-
fications of existing lexical resources.  In this 
regard we will proceed with further in-depth 
analysis of the classificatory structures of indi-
vidual resources and fit in our Pan-Chinese ar-
chitecture. 
Apart from the Tongyici Cilin, there are other 
existing Chinese lexical resources such as 
HowNet (Dong and Dong, 2000), SUMO and 
Chinese WordNet (Huang et al, 2004), as well 
as other synonym dictionaries from which we 
might draw reference to build up our Pan-
Chinese lexical resource. 
7 Conclusion 
In this paper, we have investigated the regional 
variation of lexical items in two specific domains 
from a synchronous Chinese corpus, and ex-
plored their coverage in a Chinese synonym dic-
tionary.  Results are encouraging in the sense 
that 20-40% of the candidate words from various 
subcorpora are unique to the individual commu-
nities, and as much as 70% of such unique items 
are not yet covered in the Tongyici Cilin.  It 
therefore suggests great importance and potential 
for a Pan-Chinese lexical resource which we aim 
to construct.  The synchronous corpus is a valu-
able resource for mining the region-specific 
expressions while existing synonym dictionaries 
might provide a ready-made semantic classifica-
tory structure.  Our next step would be to explore 
automatic means for extracting related lexical 
items from the corpus, and to incorporate them 
into existing semantic classifications. 
Acknowledgements 
This work is supported by Competitive Ear-
marked Research Grant (CERG) of the Research 
Grants Council of Hong Kong under grant No. 
CityU1317/03H.  The authors would like to 
thank the anonymous reviewers for comments. 
References 
Calzolari, N. (1982)  Towards the organization of 
lexical definitions on a database structure. In E. 
Hajicova (Ed.), COLING ?82 Abstracts, Charles 
University, Prague, pp.61-64. 
Caraballo, S.A. (1999)  Automatic construction of a 
hypernym-labeled noun hierarchy.  In Proceedings 
of the 37th Annual Meeting of the Association for 
Computational Linguistics (ACL?99), College Park, 
Maryland, pp.120-126. 
Chen, K-J., Huang, C-R., Chang, L-P. and Hsu, H-L. 
(1996)  Sinica Corpus: Design Methodology for 
Balanced Corpora.  In Proceedings of the 11th Pa-
cific Asia Conference on Language, Information, 
and Computation (PACLIC 11), Seoul, Korea, 
pp.167-176. 
Dong, Z. and Dong, Q. (2000)  HowNet.  
http://www.keenage.com. 
Huang, C-R., Chang, R-Y. and Lee, S-B. (2004)  
Sinica BOW (Bilingual Ontological Wordnet): In-
tegration of Bilingual WordNet and SUMO.  In 
Proceedings of the 4th International Conference on 
Language Resources and Evaluation (LREC2004), 
Lisbon, Portugal. 
Kirkpatrick, B. (1987)  Roget?s Thesaurus of English 
Words and Phrases.  Penguin Books. 
Lin, D., Zhao, S., Qin, L. and Zhou, M. (2003)  Iden-
tifying Synonyms among Distributionally Similar 
Words.  In Proceedings of the 18th Joint Interna-
tional Conference on Artificial Intelligence (IJCAI-
03), Acapulco, pp.1492-1493 . 
Mei et al ??????????????? (1984)  
??????? (Tongyici Cilin).  ????? 
(Commerical Press) / ???????. 
Miller, G.A., Beckwith, R., Fellbaum, C., Gross, D. 
and Miller, K.J. (1990)  Introduction to WordNet: 
An online lexical database.  International Journal 
of Lexicography, 3(4):235-244. 
Riloff, E. and Shepherd, J. (1999)  A corpus-based 
bootstrapping algorithm for semi-automated se-
mantic lexicon construction.  Natural Language 
Engineering, 5(2):147-156. 
Sinclair, J. (1987)  Collins COBUILD English Lan-
guage Dictionary.  London, UK: HarperCollins. 
Tsou, B.K. and Kwong, O.Y. (2006)  Toward a Pan-
Chinese Thesaurus.  In Proceedings of the Fifth 
International Conference on Language Resources 
and Evaluation (LREC 2006), Genoa, Italy. 
Tsou, B.K. and Lai, T.B.Y. ??????? (2003)  
????????????.  In B. Xu, M. Sun 
15
and G. Jin ?????????? (Eds.), ???
???????????  (Issues in Chinese 
Language Processing).  ???????? , 
pp.147-165. 
Vossen, P., Meijs, W. and den Broeder, M. (1989)  
Meaning and structure in dictionary definitions.  In 
B. Boguraev and T. Briscoe (Eds.), Computational 
Lexicography for Natural Language Processing.  
Essex, UK: Longman Group. 
Xia, F., Palmer, M., Xue, N., Okwrowski, M.E., 
Kovarik, J., Huang, S., Kroch, T. and Marcus, M. 
(2000)  Developing Guidelines and Ensuring Con-
sistency for Chinese Text Annotation.  In Proceed-
ings of the 2nd International Conference on Lan-
guage Resources and Evaluation (LREC-2000), 
Athens, Greece. 
 
Region Unique Items and Examples (Financial) Unique Items and Examples (Sports) 
HK 2105 (40.19%) 
?? ??? ?? ?? 
?? ?? ??? ?? 
?? ??  ?? ?? 
?? ??  ?? ??  
?? ??  ?? ?? 
2410 (38.16%) 
?? ?? ?? ?? 
?? ?? ?? ?? 
?? ?? ?? ??? 
?? ?? 12? ?? 
??? ?? ?? ?? 
BJ 933 (33.43%) 
?? ??  ? ?? 
???? ??  ?? ?? 
?? ??  ?? ?? 
?? ??  ?? ??  
??  ??  ??? ??  
907 (23.39%) 
??? ?? ??? ??? 
?? ?? ???? ??? 
??? ??? ?? ?? 
??? ??? ?? ?? 
??? ?? ??? ?? 
TW 891 (28.85%) 
?? ??  ??? ?? 
?? ??  ??? ??? 
??? ???  ?? ?? 
?? ??  ? ?? 
?? ??  ?? ??  
1302 (28.30%) 
?? ?? ?? ?? 
??? ?? ?? ?? 
?? ?? ?? ?? 
?? ?? ?? ?? 
??? ?? ?? ??? 
SG 890 (23.20%) 
?? ??  ?? ?? 
?? ??  ??? ?? 
?? ??  ?? ?? 
?? ???  ?? ??? 
???? ??  ?? ??   
1044 (20.39%) 
???? ???? ??? ????? 
?? ?? ??? 76?? 
?? ???? ???? ??? 
?? ?? ?? ??? 
??? ??? ?? ?? 
Table 6  Uniqueness of individual subcorpora 
 
Region Financial Sports 
 Found in Cilin Not in Cilin Found in Cilin Not in Cilin 
HK 560 (26.60%) 
??  ??  ??  ??  ?? 
??  ??  ??  ??  ?? 
1545 
(73.40%) 
884 (36.68%) 
??  ??  ??  ??  ?? 
??  ??  ?  ?  ?? 
1526 
(62.32%) 
BJ 369 (39.55%) 
??  ??  ??  ??  ? 
??  ??  ??  ??  ?? 
564 
(60.45%) 
355 (39.14%) 
???  ??  ???  ??  ???  
??  ??  ???  ??  ?? 
552 
(60.86%) 
TW 265 (29.74%) 
??  ??  ???  ??  ?? 
??  ??  ?  ??  ?? 
626 
(70.26%) 
 
354 (27.19%) 
??  ??  ??  ??  ?? 
??  ??  ??  ??  ?? 
948 
(72.81%) 
SG 333 (37.42%) 
??  ????  ??  ??  ??  
??  ??  ??  ??  ?? 
557 
(62.58%) 
281 (26.91%) 
??  ???  ???  ??  ?? 
???  ???  ???  ???  ??? 
763 
(73.08%) 
Table 7  Coverage of the Tongyici Cilin for the unique lexical items in individual subcorpora 
16
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 109?112,
Prague, June 2007. c?2007 Association for Computational Linguistics
CITYU-HIF: WSD with Human-Informed Feature Preference 
Oi Yee Kwong 
Language Information Sciences Research Centre 
City University of Hong Kong 
Tat Chee Avenue, Kowloon, Hong Kong 
rlolivia@cityu.edu.hk 
Abstract 
This paper describes our word sense dis-
ambiguation (WSD) system participating in 
the SemEval-2007 tasks.  The core system 
is a fully supervised system based on a Na-
?ve Bayes classifier using multiple knowl-
edge sources.  Toward a larger goal of in-
corporating the intrinsic nature of individ-
ual target words in disambiguation, thus in-
troducing a cognitive element in automatic 
WSD, we tried to fine-tune the results ob-
tained from the core system with human-
informed feature preference, and compared 
it with automatic feature selection as com-
monly practised in statistical WSD.  De-
spite the insignificant improvement ob-
served in this preliminary attempt, more 
systematic analysis remains to be done for 
a cognitively plausible account of the fac-
tors underlying the lexical sensitivity of 
WSD, which would inform and enhance 
the development of WSD systems in return. 
1 Introduction 
In recent years, many research teams all over the 
world have gained rich experience on word sense 
disambiguation (WSD) from the shared tasks of 
the SENSEVAL workshops.  The need for multiple 
knowledge sources has become a golden rule, and 
the ?lexical sensitivity? once remarked by Resnik 
and Yarowsky (1997) is addressed by various 
means in statistical classifiers, such as learning an 
optimal combination of the various knowledge 
sources for individual target words (e.g. Mihalcea, 
2002; Escudero et al, 2004).  Another common 
practice is to use an ensemble of classifiers.  As 
pointed out by Mihalcea et al (2004), among the 
participating systems in the SENSEVAL-3 English 
lexical sample task, ?several of the top perform-
ance systems are based on combination of multiple 
classifiers, which shows once again that voting 
scheme that combine several learning algorithms 
outperform the accuracy of individual classifiers?.  
However, the advancement in WSD is rarely ac-
companied by any extensive account on the cogni-
tive aspects of the task or qualitative analysis of 
the relation between the disambiguation results and 
the nature of individual target words underlying 
the apparent lexical sensitivity of the task. 
Given that humans apparently use different 
strategies in making sense of words, it might be 
beneficial to have such cognitive aspects, including 
the type and strength of various kinds of semantic 
association, realised in NLP systems explicitly.  
Thus in addition to an optimal combination of clas-
sifiers alone, to better understand the contribution 
of different information types for different types of 
target words, it is important to look at WSD in re-
lation to the very intrinsic nature of individual tar-
get words, which could comprise many factors 
such as frequency, abstractness, sense relatedness 
and parts-of-speech (POS).  We thus use the con-
cept Information Susceptibility (Kwong, 2005) to 
refer to the relationship between the intrinsic fea-
tures of a target word and its senses, and the effec-
tiveness of various lexical information to charac-
terise them. 
Our current participation in SemEval-2007 is 
thus intended as a means toward a larger goal, i.e., 
to incorporate a cognitive element into automatic 
WSD systems.  In particular, we tried to fine-tune 
the results obtained from the core system with hu-
man-informed feature preference. 
In Section 2, we will briefly describe the imple-
mentation of our disambiguation system and the 
features used.  In Section 3 we will discuss the 
109
human input on the target nature and the informa-
tiveness of various features.  The experiments and 
results are presented in Section 4, followed by a 
conclusion in Section 5. 
2 System Description 
2.1 Core Classifier 
The core system is a fully supervised one based on 
a Na?ve Bayes classifier.  We made use of the 
Weka API (Witten and Frank, 2005) in our 
implementation.  According to Yarowsky and 
Radu (2002), Bayesian classifiers belong to one of 
the aggregative models which depend heavily on 
the multiple reinforcing feature clues obtainable 
from wide context.  Thus we use all features 
described in Section 2.2 below for our core system. 
2.2 Knowledge Sources 
Only the training data provided by the task organ-
isers was used to train the system.  We used four 
major types of contextual features, which could be 
classified into Target features, Local features, 
Topical features and Syntactic features, as de-
scribed in Table 1.  All features were converted to 
binary features. 
2.3 Feature Selection 
On top of the core system, we tested two value-
added steps to accommodate for the lexical sensi-
tivity of WSD.  One is automatic feature selection 
(AFS), for which we used CfsSubsetEval (correla-
tion-based feature selection) as implemented in 
Weka, based on the training samples of each target 
word.  The other is human-informed feature pref-
erence (HIF), for which we ran another Na?ve 
Bayes classifier in parallel with a feature subset 
deemed informative by human judges to fine-tune 
the disambiguation results obtained from the core 
system (see Sections 3 and 4 below). 
3 Intrinsic Nature of Target Words 
Leacock et al (1998), for example, observed that 
?the benefits of adding topical to local context 
alone depend on syntactic category as well as on 
the characteristics of the individual word?.  In 
other words, some target words happen to be more 
?topical? than others and might therefore be more 
susceptible to topical contextual features during 
disambiguation.  Others, however, might only be 
optimally disambiguated with other types of in-
formation. 
 
Target Features 
W0  Word form of the target word  
P0 POS of the target word 
 
Local Features 
P-2 
P-1 
P+1 
P+2 
POS of words at fixed positions 
from the target word, including 
the first and second word on its 
left and the first and second word 
on its right 
W-2 
W-1 
W+1 
W+2 
Word forms of the words at fixed 
positions from the target word, 
including the first and second 
word on its left and the first and 
second word on its right 
 
Topical Features 
W-10?W+10 Content words appearing within 
the window of ten words on each 
side of the target word 
 
Syntactic Features 
P-2 P0 
P-1 P0 
P0 P+1 
P0 P+2 
POS bigrams composed of the 
target word and its neighbouring 
words, the non-immediate P-2 P0 
and P0 P+2 are included to ac-
commodate for some flexibility 
P-2 P-1 P0 
P0 P+1 P+2 
POS trigrams composed of the 
target word and its neighbouring 
words 
Table 1  Features Used in the Na?ve Bayes Classifer 
 
While statistical WSD has more or less reached 
its ceiling, it is assumed that a more thorough un-
derstanding of the effectiveness of different types 
of lexical information for characterising a word 
sense and distinguishing it from others should be 
able to further inform and enhance the develop-
ment of WSD systems.  To this end, three under-
graduate linguistics students in the City University 
of Hong Kong were asked to go through the train-
ing data for the Chinese lexical sample task in 
SENSEVAL-3 and that for the multilingual Chi-
nese-English lexical sample task (Task 5) in Se-
mEval-2007.  For each sense of a given target 
word, they were asked to rate the difficulty, ab-
stractness, and topicality of the sense on a 3-point 
scale.  At the same time, they were asked to indi-
110
cate the type of information, among local POS, 
local words, and contextual words (i.e. the topical 
features in Table 1), which they reckon to be most 
useful for disambiguating a given sample of the 
target word.1 
While the information collected from the human 
judges is pending in-depth analysis, the feature 
preference indicated by them was used to fine-tune 
the results obtained from our core system.  During 
disambiguation, we run two Na?ve Bayes classifi-
ers in parallel, the core one on all features above, 
and the other only on the type of information 
deemed most useful by two or more of the human 
judges, and use the latter to adjust the results from 
the former, as further discussed in Section 4.2. 
4 Experiment and Results 
4.1 Datasets 
We participated in the Multilingual Chinese-
English Lexical Sample Task (Task 5) and the 
English Lexical Sample Task via English-Chinese 
Parallel Text (Task 11). 
Task 5 consists of 40 Chinese target words, 19 
nouns and 21 verbs.  The number of senses for the 
target words ranges from 2 to 8, with an average of 
3.  There are altogether 2,680 training samples, i.e. 
on average about 22 for each sense.  A total of 935 
testing instances were to be tagged, i.e. on average 
about 23 for each target word.  The data were from 
People?s Daily.  The sense tags are given in the 
form of their English translations in the Chinese 
Semantic Dictionary developed by the Institute of 
Computational Linguistics of Peking University.  
The task organiser has provided the data with word 
segmentation and POS for each segmented word. 
Task 11 consists of 40 English target words, in-
cluding 20 nouns and 20 adjectives.  The average 
number of training samples for each sense is about 
42.  The number of senses for the target words 
ranges from 2 to 6, with an average of 3.125.  The 
average number of testing samples for each target 
word is 68.  The data were gathered from word-
aligned English-Chinese parallel texts. 
In addition, we also used the SENSEVAL-3 
Chinese lexical sample data during evaluation, 
which contains 20 target words. 
                                                 
1 To simplify the task for the human judges, we did not 
distinguish between fixed-position local POS and n-
gram syntactic features, and only used the former. 
4.2 Evaluation 
For Task 5, we made use of the segmentation and 
POS information provided by the task organiser.  
For Task 11, we first ran the data through the Brill 
tagger (Brill, 1994) to obtain the POS, from which 
we then extracted the feature values. 
On top of the core system, we also tested two 
value-added conditions, namely automatic feature 
selection (AFS) and human-informed feature pref-
erence (HIF).  For the latter, we run a separate Na-
?ve Bayes classifier in parallel to the core system, 
using the knowledge source deemed most useful 
for a given target word by two or more human 
judges.  When the probability of the best guess 
from the core classifier is under a certain threshold, 
the best guess from the other is used instead.  For 
the current experiment, the probability of the best 
guess from the core classifier must at least double 
that for the next best guess. 
For evaluation, we ran a 10-fold cross validation 
on the SemEval-2007 Task 5 training data, with 
the core system and AFS.  In addition, we tested 
with the Senseval-3 Chinese lexical sample data.  
We trained the classifier with the Senseval-3 train-
ing data, with the core classifier, AFS, and HIF.  
The results are discussed below. 
4.3 Results 
Table 2 shows the evaluation results of the various 
conditions described above. 
 
Condition Ave. Precision 
 
SemEval-2007 training data (10-fold CV) 
Core classifier 77.33% 
Core classifier + AFS 85.51% 
 
Senseval-3 testing data 
Core classifier 60.2% 
Core classifier + AFS 61.7% 
Core classifier + HIF 60.7% 
Table 2  Evaluation Results 
Apparently, and as known and expected, feature 
selection is useful for choosing an optimal set of 
features for each target word.  How this compares 
and works together with human intuition and the 
nature of the individual target words and senses is 
what we would like to further investigate.  In the 
above experiment, fine-tuning with human-
111
informed feature preference did not improve the 
performance as significantly as one would like to 
see, and the effect varied with individual target 
words.  One possibility is that Na?ve Bayes classi-
fiers favour aggregative features, so it might not be 
most appropriate to do the fine-tuning with a sepa-
rate classifier.  Rather, we could explore the feasi-
bility of adjusting the weights of individual fea-
tures based on the feature preference. 
Our next step is to perform in-depth and system-
atic analysis on the difficulty, abstractness and 
topicality of the target words and senses, with the 
information gathered from the human judges and 
the confusion matrices generated from the experi-
ment, in association with psychological evidence 
like semantic activation and the organisation of the 
mental lexicon (e.g. Kwong, 2007). 
4.4 Official Scores in SemEval-2007 
The official scores for our system are shown in 
Table 3. 
 
Task System MicroAvg MacroAvg Rank 
5 HIF 71.0% 74.9% 3 / 6 
11 AFS 75.3%2 - 3 / 3 
Table 3  Official Scores for CITYU in SemEval-2007 
 
Our scores are comparable to the state-of-the-art 
results.  Although the HIF step did not increase the 
performance significantly, in view of the limitation 
of state-of-the-art statistical WSD systems, every 
minor improvement counts.  It therefore remains 
for us to further investigate the cognitive aspects of 
WSD in relation to target nature and have them 
systematically realised in WSD systems. 
5 Conclusion 
In this paper, we have described our system par-
ticipating in the SemEval-2007 multilingual Chi-
nese-English lexical sample task and English lexi-
cal sample task via English-Chinese parallel text.  
Toward a larger goal of supplementing statistical 
                                                 
2 A post-hoc analysis reveals a technical problem for six 
of the target words in Task 11 (educational.a, change.n, 
future.n, interest.n, need.n, program.n) which were not 
properly processed by the system in one of the steps, 
and the most frequent sense was used by default.  Ignor-
ing these cases, a precision of 78.3% was obtained using 
the task organiser?s key and scoring program. 
methods with some cognitive elements of WSD, 
more systematic analysis of the intrinsic nature of 
target words underlying the lexical sensitivity of 
WSD is underway.  
Acknowledgements 
The work described in this paper was supported by 
a grant from the Research Grants Council of the 
Hong Kong Special Administrative Region, China 
(Project No. CityU 1508/06H). 
References 
Brill, E. (1994)  Some advances in transformation-based 
part of speech tagging.  In Proceedings of the 12th 
National Conference on Artificial Intelligence (AAAI-
94), pp.722-727. 
Escudero, G., M?rquez, L. and Rigau, G. (2004)  TALP 
System for the English Lexical Sample Task.  In 
Proceedings of SENSEVAL-3, Barcelona, Spain. 
Kwong, O.Y. (2005)  Word Sense Classification Based 
on Information Susceptibility.  In A. Lenci, S. Mon-
temagni and V. Pirrelli (Eds.), Acquisition and Rep-
resentation of Word Meaning. Linguistica Compu-
tazionale, pp.89-115. 
Kwong, O.Y. (2007)  Sense Abstractness, Semantic 
Activation and Word Sense Disambiguation: Impli-
cations from Word Association Norms.  To appear in 
Proceedings of NLPCS-2007, Madeira, Portugal. 
Leacock, C., Miller, G.A. and Chodorow, M. (1998)  
Using Corpus Statistics and WordNet Relations for 
Sense Identification.  Computational Linguistics, 
24(1):147-166. 
Mihalcea, R.F. (2002) Word sense disambiguation with 
pattern learning and automatic feature selection. 
Natural Language Engineering, 8(4):343-358. 
Mihalcea, R., Chklovski, T. and Kilgarriff, A. (2004)  
The SENSEVAL-3 English Lexical Sample Task.  In 
Proceedings of SENSEVAL-3, Barcelona, Spain. 
Resnik, P. and Yarowsky, D. (1997)  A perspective on 
word sense disambiguation methods and their evalua-
tion.  In Proceedings of SIGLEX?97 Workshop: Tag-
ging Text with Lexical Semantics: Why, What, and 
How?, Washington, D.C., pp.79-86. 
Witten, I.H. and Frank, E. (2005)  Data Mining: Practi-
cal Machine Learning Tools and Techniques with 
Java Implementations.  Morgan Kaufmann. 
Yarowsky, D. and Radu, F. (2002)  Evaluating sense 
disambiguation across diverse parameter spaces.  
Natural Language Engineering, 8(4):293-310. 
112
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 76?79,
Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLP
Phonological Context Approximation and Homophone Treatment 
for NEWS 2009 English-Chinese Transliteration Shared Task 
 
 
Oi Yee Kwong 
Department of Chinese, Translation and Linguistics 
City University of Hong Kong 
Tat Chee Avenue, Kowloon, Hong Kong 
Olivia.Kwong@cityu.edu.hk 
 
  
 
Abstract 
This paper describes our systems participating 
in the NEWS 2009 Machine Transliteration 
Shared Task.  Two runs were submitted for the 
English-Chinese track.  The system for the 
standard run is based on graphemic approxi-
mation of local phonological context.  The one 
for the non-standard run is based on parallel 
modelling of sound and tone patterns for treat-
ing homophones in Chinese.  Official results 
show that both systems stand in the mid range 
amongst all participating systems. 
1 Introduction 
This paper describes our systems participating in 
the English-Chinese track of the NEWS 2009 
Machine Transliteration Shared Task. 
The apparently free combination of Chinese 
characters in names is not entirely ungoverned.  
There are no more than a few hundred Chinese 
characters which are used in names.  Moreover, 
beyond linguistic and phonetic properties, many 
social and cognitive factors are simultaneously 
influencing the naming process and superimpos-
ing on the surface graphemic correspondence. 
Our systems in the standard and non-standard 
runs aim at addressing two issues in English-
Chinese forward transliteration (referred to as 
E2C hereafter), namely graphemic ambiguity and 
homophones in Chinese respectively. 
By graphemic ambiguity, we refer to the mul-
tiple mappings between English segments and 
Chinese segments.  For example, the English 
segment ?ty? could be rendered as ? di4 as in 
Christy ???? ke4-li3-si1-di4, or ? tai4 as 
in Style ??? si1-tai4-er31.  Although direct 
                                                 
1 The transcriptions in this paper are in Hanyu Pinyin. 
orthographic mapping (e.g. Li et al, 2004) has 
been shown to work even more effectively than 
phoneme-based methods (e.g. Virga and Khu-
danpur, 2003), it is observed that phonological 
context plays an important role in resolving gra-
phemic ambiguity.  In the absence of an explicit 
phonemic representation of the source names, 
our GAP system, to be described in Section 4.1, 
attempts to approximate the local phonological 
context for a given segment by means of surface 
graphemic properties. 
An English name could be acceptably translit-
erated in various ways, e.g. ??? xi1-la1-li3, 
??? xi1-la1-li4, ??? xi1-la1-li4, as well as 
??? xi1-la1-rui3 are all possible translitera-
tions for Hilary.  Homophones are abundant in 
Chinese, as evident from the first three alterna-
tives above.  However, conventional translitera-
tion models often rely heavily on the distribution 
of the training data, which might preclude infre-
quent but similarly acceptable transliteration 
candidates.  Also, Chinese is a typical tonal lan-
guage.  The sound-tone combination is important 
in names.  Names which sound ?nice? are often 
preferred to those which sound ?monotonous?.  
Our SoToP system to be described in Section 4.2 
thus attempts to model sound and tone patterns in 
parallel, to deal with homophones more reasona-
bly despite possible skewed prior distributions. 
Related work will be briefly reviewed in Sec-
tion 2, and the datasets will be described in Sec-
tion 3.  The systems for both runs and their per-
formance will be reported in Section 4, followed 
by future work and conclusion in Section 5. 
2 Related Work 
There are basically two categories of work on 
machine transliteration.  First, various alignment 
models are used for acquiring transliteration 
76
lexicons from parallel corpora and other re-
sources (e.g. Kuo and Li, 2008).  Second, statis-
tical models are built for transliteration.  These 
models could be phoneme-based (e.g. Knight and 
Graehl, 1998), grapheme-based (e.g. Li et al, 
2004), hybrid (Oh and Choi, 2005), or based on 
phonetic (e.g. Tao et al, 2006) and semantic (e.g. 
Li et al, 2007) features. 
The core of our systems is based on Li et al?s 
(2004) Joint Source-Channel Model under the 
direct orthographic mapping framework, which 
skips the middle phonemic representation in 
conventional phoneme-based methods and mod-
els the segmentation and alignment preferences 
by means of contextual n-grams of the translit-
eration segment pairs (or token pairs in their ter-
minology).  A bigram model under their frame-
work is thus as follows: 
 
?
=
?? ><><?
><><><=
=
K
k
kkkk
kk
kk
ceceP
cececeP
ccceeePCEP
1
11
2211
2121
),|,(
),,...,,,,(
),...,,,,...,,(),(
 
 
where E refers to the English source name and C 
refers to the transliterated Chinese name.  With K 
segments aligned between E and C, ek and ck re-
fer to the kth English segment and its corre-
sponding Chinese segment respectively. 
3 Datasets 
The current study used the English-Chinese 
(EnCh) data provided by the shared task organis-
ers.  There are 31,961 English-Chinese name 
pairs in the training set, 2,896 English-Chinese 
name pairs in the development set, and another 
2,896 English names in the test set.  The Chinese 
transliterations basically correspond to Mandarin 
Chinese pronunciations of the English names, as 
used by media in Mainland China (Xinhua News 
Agency, 1992). 
The training and development data were 
manually cleaned up and aligned with respect to 
the correspondence between English segments 
and Chinese segments, e.g. Aa/l/to ?/?/?, and 
the pronunciations for the Chinese characters 
were automatically looked up. 
Based on all the unique English segments re-
sulting from manual alignment, all possible seg-
mentations of a test name were first obtained, 
and they were then ranked using a probabilistic 
score computed by: 
 
?
=
+??
K
k
kkkk sfcsPslcsPSScore
1
11 ))(|())(|()(  
 
where S is a segmentation sequence with K seg-
ments, sk is the kth segment in S, lc(sk-1) is the 
last character of segment sk-1 and fc(sk+1) is the 
first character of segment sk+1. 
4 System Description 
4.1 Standard Run ? GAP 
Our system for the standard run is called GAP, 
which stands for Graphemic Approximation of 
Phonological context. 
Although direct orthographic mapping has 
been shown to be an effective method, it is nev-
ertheless observed that phonological context sig-
nificantly contributes to the resolution of some 
graphemic ambiguity.  For example, the English 
segment ?le? was found to correspond to as 
many as 15 Chinese segments in the data, includ-
ing ? li4, ? le4, ? li4, ? er3, ? lai2, ? li3, 
etc.  When ?le? appears at the end of a name, all 
but a few cases are rendered as ? er3, e.g. Dale 
?? dai4-er3 and Dipasquale ????? di2-
pa4-si1-kui2-er3.  This is especially true when 
the previous character is ?a?.  On the contrary, 
when ?le? appears at the end of a name following 
an ?r?, it is more often rendered as ? li4 instead, 
e.g. Berle ?? bo2-li4.  On the other hand, ?le? 
at the beginning of name is often rendered as ? 
le4 or ? lai2, e.g. Lepke ??? lai2-pu3-ke4, 
except when it is followed by the vowel ?o?, 
where it is then often transliterated as ? li4, e.g. 
Leonor ??? li4-ao4-nuo4.  Such observation 
thus indicates two important points for E2C.  
First, the phonological context is useful as Eng-
lish graphemic segments could be ambiguous in 
terms of pronunciation, and the actual pronuncia-
tion often determines which Chinese segment is 
to be used.  Second, local contexts on both sides 
are important as they indicate the environment in 
which the segment is embedded, which might 
affect the way it is pronounced. 
GAP thus attempts to approximate local pho-
nological context by means of surface graphemic 
properties, making use of bigrams in both direc-
tions.  Since the phonological environment might 
be sufficiently represented by a neighbouring 
phoneme instead of a whole syllable, we ap-
proximate the phonological context with one 
character on both sides of a given English seg-
ment, irrespective of their corresponding Chinese 
77
segments.  Using single characters on both sides 
could also ensure that a small and consistent pa-
rameter space is maintained.  Hence, weighting 
the context on both sides equally, GAP assigns a 
score Score(E,C) to a transliteration candidate 
with K segment pairs as follows: 
 
?
=
+? ><><
K
k
kkkkkk efccePelcceP
1
11 ))(|,())(|,(  
 
where <ek,ck> is the kth English-Chinese segment 
pair, lc(ek-1) is the last character of segment ek-1 
and fc(ek+1) is the first character of segment ek+1. 
Taking the top 3 segmentation candidates, the 
transliteration candidates were generated by 
looking up the grapheme pairs obtained from 
manual alignment with frequency f ? 3.  If there 
is no grapheme pair above the threshold, all pairs 
below the threshold would be considered.  All 
combinations obtained were then subject to rank-
ing with Score(E,C) above. 
4.2 Non-standard Run ? SoToP 
The homophone problem is notorious in Chinese.  
As far as personal name transliteration is con-
cerned, unless there are standardised principles 
prescribed, the ?correctness? of transliterated 
names is not clear-cut at all.  As a tonal language, 
how a combination of characters sounds is also 
important in naming.  As in the example given in 
Section 1, one cannot really say any of the trans-
literations for Hilary is ?right? or ?wrong?, but 
perhaps only ?better? or ?worse?.  Hence naming 
is more of an art than a science, and automatic 
transliteration should avoid over-reliance on the 
training data and thus missing unlikely but good 
alternative candidates. 
Our system for the non-standard run, SoToP, 
thus aims at addressing this cognitive or percep-
tual aspect of transliteration beyond its linguistic 
and phonetic properties.  Instead of direct ortho-
graphic mapping, we use a Sound model (SoM) 
and a Tone model (ToM) in Parallel.  The SoToP 
architecture is shown in Figure 1. 
SoM basically assembles the homophones and 
captures the sound patterns in terms of a graph-
eme-phoneme mapping.  The operation of SoM 
is like GAP above, except that the <ek,ck> pairs 
are replaced by <ek,sok> pairs, where sok refers to 
the phonetic transcription in Hanyu Pinyin 
(without tone) for the kth Chinese segment in a 
candidate. 
ToM, on the other hand, captures the tone pat-
terns of transliteration, irrespective of the sound 
and the character choice.  Although English does 
not have tones, the intonation and stress of a syl-
lable may prompt for the usage of a Chinese 
character of a certain tone.  Chinese, on the other 
hand, is a tonal language.  The tone patterns are 
more cognitive in nature, as some combinations 
may just sound awkward for no apparent reason.  
Moreover, some sound-tone combinations might 
result in undesirable homophones, which are also 
avoided in names in general.  The operation of 
ToM is also like GAP, except that the <ek,ck> 
pairs are replaced by <ek,tok> pairs, where tok 
refers to the tone for the kth Chinese segment in 
a candidate. 
The Candidate Generator combines the top M 
candidates from ToM and top N candidates from 
SoM to generate character combinations by look-
ing up a pronunciation table.  The lookup table 
lists the homophones for each sound-tone com-
bination found in the data.  In the current study, 
both M and N were set to 3.  The generated can-
didates were then ranked by a simple bigram 
model based on the bigram probabilities of the 
Chinese segments. 
4.3 System Testing 
The two systems were tested on the NEWS de-
velopment data, containing 2,896 English names.  
System performance was measured by the fol-
lowing evaluation metrics: Word Accuracy in 
Top-1 (ACC), Fuzziness in Top-1 (Mean F-
score), Mean Reciprocal Rank (MRR), MAPref, 
MAP10, and MAPsys.  Detailed description of 
these metrics can be found in the NEWS shared 
task whitepaper (Li et al, 2009). 
Table 1 shows the system testing results on the 
development data.  The standard run, GAP, in 
general gives better results than the non-standard 
run, SoToP.  One possible reason is apart from 
the source name segmentation step, SoToP has 
more steps allowing error propagation as the 
mapping was done separately with sound and 
tone, whereas GAP directly maps English seg-
ments to Chinese segments at the graphemic 
level. 
  
Metric GAP SoToP 
ACC 0.645 0.597 
Mean F-score 0.860 0.836 
MRR 0.732 0.674 
MAPref 0.645 0.597 
MAP10 0.223 0.206 
MAPsys 0.225 0.335 
Table 1. System Testing Results 
78
 
 
 
 
 
 
 
 
4.4 Official Results 
The two systems were trained on both the train-
ing data and development data together, and run 
on the test data.  The official results are shown in 
Table 2.  The performance of the two systems is 
in the mid range amongst all participating sys-
tems, including standard and non-standard runs.  
Despite the shortcoming and lower performance 
of SoToP, modelling the sound and tone patterns 
has its merits for handling homophones.  For ex-
ample, the expected transliteration for Mcgiveran, 
???? mai4-ji2-fu2-lun2, was ranked 6th by 
GAP but 1st by SoToP.  The segment ?ve? is 
much more likely rendered as ? fu1 than as ? 
fu2, but ToM in SoToP was able to capture the 
preferred tone pattern 4-2-2-2 in this case. 
 
Metric GAP SoToP 
ACC 0.621 0.587 
Mean F-score 0.852 0.834 
MRR 0.718 0.665 
MAPref 0.621 0.587 
MAP10 0.220 0.203 
MAPsys 0.222 0.330 
Table 2. Official Results on Test Data 
 
5 Future Work and Conclusion 
Thus we have reported on the two systems par-
ticipating in the NEWS shared task.  The stan-
dard run, GAP, relies on direct orthographic 
mapping and approximates local phonological 
context with neighbouring graphemes to help 
resolve graphemic ambiguity.  The non-standard 
run, SoToP, attempts to address the homophone 
issues in Chinese, by modelling the sound and 
tone patterns in parallel, and subsequently com-
bining them to generate transliteration candidates.  
In general GAP gives better results than SoToP, 
while both are in the mid range amongst all par-
ticipating systems.  Future work includes more 
error analysis and improving the accuracy of in-
dividual steps to minimise error propagation.  
The possible combination of the two methods is 
also worth further investigation. 
Acknowledgements 
The work described in this paper was substan-
tially supported by a grant from City University 
of Hong Kong (Project No. 7002203). 
References  
Knight, K. and Graehl, J. (1998)  Machine Translit-
eration.  Computational Linguistics, 24(4):599-612. 
Kuo, J-S. and Li, H. (2008)  Mining Transliterations 
from Web Query Results: An Incremental Ap-
proach.  In Proceedings of SIGHAN-6, Hyderabad, 
India, pp.16-23. 
Li, H., Zhang, M. and Su, J. (2004)  A Joint Source-
Channel Model for Machine Transliteration.  In 
Proceedings of the 42nd Annual Meeting of ACL, 
Barcelona, Spain, pp.159-166. 
Li, H., Sim, K.C., Kuo, J-S. and Dong, M. (2007)  
Semantic Transliteration of Personal Names.  In 
Proceedings of 45th Annual Meeting of ACL, Pra-
gue, Czech Republic, pp.120-127. 
Li, H., Kumaran, A., Zhang, M. and Pervouchine, V. 
(2009)  Whitepaper of NEWS 2009 Machine 
Transliteration Shared Task.  In Proceedings of 
ACL-IJCNLP 2009 Named Entities Workshop 
(NEWS 2009), Singapore. 
Oh, J-H. and Choi, K-S. (2005)  An Ensemble of 
Grapheme and Phoneme for Machine Translitera-
tion.  In R. Dale et al (Eds.), Natural Language 
Processing ? IJCNLP 2005.  Springer, LNAI Vol. 
3651, pp.451-461. 
Tao, T., Yoon, S-Y., Fister, A., Sproat, R. and Zhai, C. 
(2006)  Unsupervised Named Entity Transliteration 
Using Temporal and Phonetic Correlation.  In Pro-
ceedings of EMNLP 2006, Sydney, Australia, 
pp.250-257. 
Virga, P. and Khudanpur, S. (2003)  Transliteration of 
Proper Names in Cross-lingual Information Re-
trieval.  In Proceedings of the ACL2003 Workshop 
on Multilingual and Mixed-language Named Entity 
Recognition. 
Xinhua News Agency. (1992)  Chinese Translitera-
tion of Foreign Personal Names.  The Commercial 
Press. 
 
Sound Model (SoM) 
Tone Model (ToM) 
Candidate Generator English name 
Chinese 
candidates + 
Figure 1. The SoToP Architecture for E2C Transliteration 
79
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 186?193,
Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLP
Graphemic Approximation of Phonological Context 
for English-Chinese Transliteration 
 
 
Oi Yee Kwong 
Department of Chinese, Translation and Linguistics 
City University of Hong Kong 
Tat Chee Avenue, Kowloon, Hong Kong 
Olivia.Kwong@cityu.edu.hk 
 
  
 
Abstract 
Although direct orthographic mapping has 
been shown to outperform phoneme-based 
methods in English-to-Chinese (E2C) translit-
eration, it is observed that phonological con-
text plays an important role in resolving gra-
phemic ambiguity.  In this paper, we investi-
gate the use of surface graphemic features to 
approximate local phonological context for 
E2C.  In the absence of an explicit phonemic 
representation of the English source names, 
experiments show that the previous and next 
character of a given English segment could ef-
fectively capture the local context affecting its 
expected pronunciation, and thus its rendition 
in Chinese. 
1 Introduction 
Proper names including personal names, place 
names, and organization names, make up a con-
siderable part of naturally occurring texts.  Per-
sonal names, in particular, do not only play an 
important role in identifying an individual, but 
also carry the family history, parental expecta-
tion, as well as other information about a person.  
In natural language processing, the proper rendi-
tion of personal names, especially between dis-
similar languages such as Chinese and English, 
often contributes significantly to machine trans-
lation accuracy and intelligibility, and cross-
lingual information retrieval.  This paper ad-
dresses the problem of automatic English-
Chinese forward transliteration (referred to as 
E2C hereafter) of personal names. 
Unlike many other languages, Chinese names 
are characteristic in their relatively free choice 
and combination of characters, particularly for 
given names.  Such apparent flexibility does not 
only account for the virtually infinite number of 
authentic Chinese names, but also leads to a con-
siderable sample space when foreign names are 
transliterated into Chinese.  Underlying the large 
sample space, however, is not entirely a random 
distribution.  On the one hand, there are no more 
than a few hundred Chinese characters which are 
used in names (e.g. Sproat et al, 1996).  On the 
other hand, beyond linguistic and phonetic prop-
erties, many other social and cognitive factors 
such as dialect, gender, domain, meaning, and 
perception, are simultaneously influencing the 
naming process and superimposing on the sur-
face graphemic correspondence. 
As the state-of-the-art approach, direct ortho-
graphic mapping (e.g. Li et al, 2004), making 
use of graphemic correspondence between Eng-
lish and Chinese directly, has been shown to out-
perform phoneme-based methods (e.g. Virga and 
Khudanpur, 2003).  In fact, transliteration of for-
eign names into Chinese is often based on the 
surface orthographic forms, as exemplified in the 
transliteration of Beckham, where the supposedly 
silent h in ?ham? is taken as pronounced, result-
ing in ?? han4-mu3 in Mandarin Chinese and 
? haam4 in Cantonese1. 
However, as we have observed, there is con-
siderable graphemic ambiguity in E2C, where an 
English segment might correspond to different 
Chinese segments.  Such multiple mappings, to a 
large extent, is associated with the phonological 
context embedding the English segment, thus 
affecting its expected pronunciation.  Hence, if 
such phonological context could be considered in 
                                                 
1 Mandarin names are shown in simplified Chinese 
characters and transcribed in Hanyu Pinyin, while 
Cantonese names are shown in traditional Chinese 
characters and transcribed in Jyutping published by 
the Linguistic Society of Hong Kong. 
186
the transliteration model, some of the graphemic 
ambiguity could be resolved.  However, instead 
of going for an explicit phonemic representation, 
which might introduce an extra step for error 
propagation, in the current study we investigate 
the usefulness of surface graphemic features for 
approximating the local phonological context in 
E2C.  Experiments show that the previous and 
next character of a given segment could effec-
tively capture the local phonological context and 
improve transliteration accuracy. 
A short note on terminology before we move 
on: We use ?segment? to refer to a minimal gra-
phemic transliteration unit in the names.  For 
instance, in the data, the name Amyx is translit-
erated as ???? a1-mi3-ke4-si1, the graph-
eme pairs are <a, ?>, <my, ?>, and <x, ??>.  
There are three English segments: ?a?, ?my? and 
?x?; and three Chinese segments: ?, ? and ?
?.  A segment may or may not correspond to 
exactly a syllable, although it often does. 
In Section 2, we will briefly review some re-
lated work.  In Section 3, we will discuss some 
observations on graphemic ambiguity in E2C.  
The proposed method will be presented in Sec-
tion 4.  Experiments will be reported in Section 5, 
with results discussed in Section 6, followed by a 
conclusion in Section 7. 
2 Related Work 
There are basically two categories of work on 
machine transliteration.  On the one hand, vari-
ous alignment models are used for acquiring 
transliteration lexicons from parallel corpora and 
other resources (e.g. Lee et al, 2006; Jin et al, 
2008; Kuo and Li, 2008).  On the other hand, 
statistical transliteration models are built for 
transliterating personal names and other proper 
names, such as by means of noisy channel mod-
els or direct models amongst others, phoneme-
based (e.g. Knight and Graehl, 1998; Virga and 
Khudanpur, 2003), or grapheme-based (e.g. Li et 
al., 2004), or a combination of them (Oh and 
Choi, 2005), or based on phonetic (e.g. Tao et al, 
2006; Yoon et al, 2007) and semantic (e.g. Li et 
al., 2007) features. 
Li et al (2004), for instance, used a Joint 
Source-Channel Model under the direct ortho-
graphic mapping (DOM) framework, skipping 
the middle phonemic representation in conven-
tional phoneme-based methods, and modelling 
the segmentation and alignment preferences by 
means of contextual n-grams of the translitera-
tion units.  Their method was shown to outper-
form phoneme-based methods and those based 
on the noisy channel model. 
The n-gram model used in Li et al (2004) was 
based on previous local context of grapheme 
pairs.  However, as we are going to show in Sec-
tion 3, contexts on both sides of a segment are 
important in determining the actual rendition of 
it in Chinese.  In addition, graphemic ambiguity 
could in part be resolved by means of the phono-
logical context embedding the segment.    Hence 
in the current study, we propose a method modi-
fied from the Joint Source-Channel Model to 
take into account contexts on both sides of a 
segment, and to approximate local phonological 
context by means of surface graphemic features. 
3 Some Observations 
In this section, we will quantitatively analyse 
some properties of E2C based on our data, and 
show the importance of considering neighbour-
ing context on both sides of a certain segment, as 
well as the possibility of approximating phono-
logical properties graphemically. 
3.1 Dataset 
The data used in the current study are based on 
the English-Chinese (EnCh) training and devel-
opment data provided by the organisers of the 
NEWS 2009 Machine Transliteration Shared 
Task.  There are 31,961 English-Chinese name 
pairs in the training set, and 2,896 English-
Chinese name pairs in the development set.  The 
data were manually cleaned up and aligned with 
respect to the correspondence between English 
and Chinese segments, e.g. Aa/l/to ? /? /? .  
The analysis in this section is based on the train-
ing set. 
The Chinese transliterations in the data basi-
cally correspond to Mandarin Chinese pronun-
ciations of the English names, as used by media 
in Mainland China (Xinhua News Agency, 1992).  
Note that transliterations for English names 
could differ considerably in Chinese, depending 
on the dialect in question.  Names transliterated 
according to Mandarin Chinese pronunciations 
are very different from those according to Can-
tonese pronunciations, for instance.   Translitera-
tions used in Mainland China are also different 
from those used in Taiwan region, despite both 
are based on Mandarin Chinese.  A well cited 
example is a syllable initial /d/ may surface as in 
Baghdad ??? ba1-ge2-da2, but the syllable 
final /d/ is not represented.  This is true for trans-
literation based on Mandarin Chinese pronuncia-
187
tions.  For Cantonese, however, it is different 
since ending stops like ?p, ?t and ?k are allowed 
in Cantonese syllables.  Hence the syllable final 
/d/ in Baghdad is already captured in the last syl-
lable of??? baa1-gaak3-daat6 in Cantonese. 
Such phonological properties of Mandarin 
Chinese might also account for the observation 
that extra syllables are often introduced for cer-
tain consonant segments in the middle of an Eng-
lish name, as in Hamilton, transliterated as ??
??  han4-mi4-er3-dun4 in Mandarin Chinese 
(c.f. ??? haam4-mei5-deon6 in Cantonese); 
and Beckham, transliterated as ???? bei4-
ke4-han4-mu3 in Mandarin Chinese (c.f. ?? 
bik1-haam4 in Cantonese). 
3.2 Graphemic Ambiguity 
Table 1 quantitatively describes the training data.  
On average each English name has around 3.14 
segments, or transliteration units.  On average 
each English segment has around 1.7 different 
renditions in Chinese.  On the other hand, al-
though the number of unique Chinese segments 
is just a few hundred, on average one Chinese 
segment could correspond to about 10 different 
English segments.  This suggests that English-
Chinese graphemic segment correspondence 
could be quite ambiguous.  Further analysis is 
therefore needed to see if any systematic patterns 
could be found among such ambiguity. 
 
Unique English names 31,822 
Total English segments 99,930 
Unique English segments 2,822 
Unique Chinese segments 458 
Unique grapheme pairs 4,750 
Table 1. Quantitative Aspects of the Data 
 
Assume transliteration pair mappings are in 
the form <ek, {ck1,ck2,?,ckn}>, where ek stands 
for the kth unique English segment, and 
{ck1,ck2,?,ckn} for the set of n unique Chinese 
segments observed for it in the data.  It was 
found in the training data that n varies from 1 to 
15, while 32.2% of the distinct English segments 
have multiple grapheme correspondence. Table 2 
shows the degree of graphemic ambiguity with 
illustrative examples.  Some of the ambiguity, 
however, is the result of homophones.  The effect 
of homophones (whether or not tones are taken 
into account) in E2C transliteration is worth 
more in-depth investigation, but it is beyond the 
scope of the current study. 
 
Examples 
n Proportion English 
Segment 
Chinese 
Segments 
Source Name Transliteration 
? nei4 Abernathy ???? 
? na4 Adamina ???? 
? ni2 Cranage ???? 
? na2 Buonaparte ??? 
? nao3 Kenall ??? 
? na4 Stranahan ????? 
?5 4.8% na 
? nuo4 Widnall ???? 
? dan1 Lafontain ??? 
? tan3 Stainton ??? 
? ting2 Sartain ?? 4 2.9% tain 
? dun4 Chastain ??? 
? lan2 Granberg ???? 
? lang3 Francine ??? 3 7.3% ran 
? lun2 Karran ?? 
? di4 Christy ???? 
2 17.2% ty ? tai4 Style ??? 
Angie ?? 
1 67.8% gie ? ji2 
Cowgiel ??? 
Table 2. Graphemic Ambiguity of the Data 
188
The other multiple correspondences are never-
theless genuine ambiguity.  The same English 
graphemic segment, depending on its pronuncia-
tion within the name, could be rendered in vari-
ous Chinese segments of very different pronun-
ciations.  To determine the expected pronuncia-
tion of the ambiguous English segment, however, 
the phonological context embedding the segment 
has an important role to play.  For instance, the 
graphemic segment ?na?, when appearing at the 
end of a name, is often pronounced as /na/ and 
rendered as ? na4, especially for female names.  
But when it is in the middle of a name, and espe-
cially before ?th?, it is often pronounced as /nei/ 
and rendered as ? nei4.  Similarly, the segment 
?ty? is often pronounced as /ti/ at the end of a 
name and transliterated as ? di4.  On the other 
hand, if it is in the middle of a name, after an ?s? 
or in front of ?le? or ?re?, it is often pronounced 
as /tai/ and therefore transliterated as ? tai4. 
Take another segment ?le? as an example.  It 
is found to correspond to as many as 15 different 
Chinese segments, including ? li4, ? le4, ? li4, 
? er3, ? lai2, ? li3, etc.  When ?le? appears at 
the end of a name, all but a few cases are pro-
nounced as /l/ and rendered as ? er3, particu-
larly when it follows ?a?, e.g. Dale ?? dai4-
er3 and Dipasquale ?????  di2-pa4-si1-
kui2-er3.  Exceptions are when ?le? at the end of 
a name follows ?r?, where it is often rendered as 
? li4 instead.  On the other hand, when ?le? ap-
pears at the beginning of a name where the 
vowel is often prominently pronounced, it is usu-
ally rendered as ? le4 or ? lai2, e.g. Lepke ?
?? lai2-pu3-ke4, except when it is followed by 
the vowel ?o?, where it is then often transliter-
ated as ? li4, e.g. Leonor ??? li4-ao4-nuo4.  
When ?le? appears in the middle of a name, the 
transliteration is nevertheless more variable.  
Still it is remarkable that ?le? is transliterated as 
? li4 when it is followed by ?c? or ?x?, e.g. 
Alex ???? a4-li4-ke4-si1. 
Such observations thus suggest two important 
points for E2C.    First, contexts on both sides of 
a given segment do play a role in determining its 
likely rendition in Chinese.  Second, the phono-
logical context is important for determining the 
expected pronunciation of an English segment 
given its position in a name.  Hence we propose 
a method, making use of contexts on both sides 
of a segment, to approximate the local phono-
logical context of a segment via surface gra-
phemic features. 
4  Proposed Method 
The Joint Source-Channel Model in Li et al 
(2004) making use of direct orthographic map-
ping and a bigram language model for the seg-
ment pairs (or token pairs in their terms) is as 
follows:  
 
?
=
?? ><><?
><><><=
=
K
k
kkkk
kk
kk
ceceP
cececeP
ccceeePCEP
1
11
2211
2121
),|,(
),,...,,,,(
),...,,,,...,,(),(
 
 
where E refers to the English source name and C 
refers to the transliterated Chinese name.  With K 
segments aligned between E and C, ek and ck re-
fer to the kth English segment and its corre-
sponding Chinese segment respectively. 
While we have grounds for orthographic map-
ping as mentioned in the introduction, there is 
some modification we hope to make to the above 
model.  As pointed out in the last section, local 
contexts on both sides of a given segment should 
be important and useful for modelling the con-
text embedding the segment, which in turn could 
help determine its expected pronunciation.  In 
addition, the phonological environment might be 
sufficiently represented by a neighbouring pho-
neme instead of even a syllable.  Thus we take 
the last character from the previous segment and 
the first character of the next segment (instead of 
the whole neighbouring segment) into account, 
irrespective of their corresponding Chinese seg-
ments.  This could be considered an attempt to 
approximate the local phonological context of a 
given segment by means of surface graphemic 
features, even if we do not go for an explicit 
phonemic representation of the source name. 
Hence we propose to make use of bigrams in 
both directions with equal weighting, and assign 
a score, Score(E,C), to a transliteration candidate 
as below: 
 
?
=
+? ><><
K
k
kkkkkk efccePelcceP
1
11 ))(|,())(|,(  
 
where lc(ek-1) refers to the last character of the 
previous English segment, and fc(ek+1) refers to 
the first character of the next English segment. 
In the rest of this paper, we will refer to this 
method as GAP, which stands for Graphemic 
Approximation of Phonological context. 
189
5 Experiments 
The 31,961 English-Chinese name pairs from the 
NEWS shared task training set were used for 
training, and the 2,896 names in the development 
set were used for testing.  The data were first 
manually cleaned up and aligned with respect to 
the correspondence between English segments 
and Chinese segments. 
5.1 Segmentation of Test Names 
Each test name was first segmented.  All possible 
segmentations were obtained based on the unique 
English segments obtained from the manual 
alignment above. 
The graphemic units are made case-insensitive. 
When finding all possible graphemic segmenta-
tions of the English source names, segments with 
length 1 are only allowed if no longer segment 
with that initial letter followed by a vowel is pos-
sible.  For example, while ?a?, ?k?, ?l?, ?o?, ?v?, 
?s? and ?y? are all observed segments in the 
training data, when computing the transliteration 
for the test name Akalovsky, only two of the 
possible segmentations, A/ka/lo/v/s/ky and 
A/kal/o/v/s/ky, were considered while the rest 
involving more single-letter segments were ig-
nored.  This is justified by three reasons.  First, 
the more alternative segmentations, the more 
alternative transliteration candidates are to be 
evaluated.  This is computationally expensive, 
and many alternatives are in fact quite unlikely.  
Second, single-letter segments are redundant if a 
longer segment is possible.  On the one hand, 
transliterations are usually based on a consonant-
vowel combination as a unit.  A consonant will 
only be on its own as a segment if it occurs 
among a consonant cluster, which has no direct 
syllable correspondence in Chinese.  For exam-
ple, it is useless to single out the second ?k? in 
Akalovsky as the longer segment ?ka? is pro-
nounceable anyway, unlike in names with con-
sonant clusters like Akst.  On the other hand, in 
the cases of doubling consonants like Ross, both 
?s? and ?ss? will correspond to similar sounds.  
Third, the n-gram models favour transliterations 
with fewer segments anyway, so the segmenta-
tions with more single-letter segments will be 
less probable in any case. 
The possible segmentations obtained were 
then ranked by a method similar to GAP.  The 
score for each segmentation candidate S, 
Score(S), is computed by: 
 
?
=
+?
K
k
kkkk sfcsPslcsP
1
11 ))(|())(|(  
 
where sk is the kth segment in a name, lc(sk-1) is 
the last character of the previous segment and 
fc(sk+1) is the first character of the next segment. 
In the experiments, we selected the top N seg-
mentation candidates for use in subsequent steps, 
where N was varied from 1 to 3. 
5.2 Transliteration Candidates 
With the top N segmentation candidates, the 
transliteration candidates were generated by 
looking up the grapheme pairs obtained from 
manual alignment with frequency over a certain 
threshold f.  We tested with f ? 3 and f ? 5.  If 
there is no grapheme pair for a certain segment 
above the threshold, all pairs below the threshold 
would be considered.  All combinations obtained 
were then subject to ranking by the GAP translit-
eration method. 
5.3 Testing 
The transliteration candidates were evaluated and 
ranked by the GAP method.  For comparison, we 
also run the Joint Source-Channel Model (JSCM) 
described in Li et al (2004) on the test data.  In 
addition, we also tested a variation of GAP, 
called GAP-s, where the neighbouring characters 
are replaced by the neighbouring segments in the 
computation of the scores, that is, lc(ek-1) is re-
place by <ek-1,ck-1> and fc(ek+1) is replaced by 
<ek+1,ck+1>.  Note that similar changes were ap-
plied to the ranking of the source name segmen-
tations for both methods accordingly. 
System performance was measured by the 
Mean Reciprocal Rank (MRR) (Kantor and 
Voorhees, 2000), as well as the Word Accuracy 
in Top-1 (ACC) and Fuzziness in Top-1 (Mean 
F-score) used in the NEWS shared task.  Only 
the top 10 transliteration candidates produced by 
the systems were considered. 
6 Results and Discussion 
6.1 Candidates Filtering 
As mentioned in the last section, candidates were 
filtered in two stages.  First, when the source 
English name was segmented, only the top N 
segmentation candidates were retained for sub-
sequent processes.  Second, when transliteration 
candidates were generated, only those grapheme 
pairs with frequency ? f, where applicable, were 
considered for the candidates.  Table 3 shows the 
190
results of GAP with various combinations of N 
and f. 
 
 f  \ N 1 2 3 
ACC 0.6357 0.6443 0.6450 
Mean F 0.8558 0.8600 0.8598 
MRR 
3 
0.6961 0.7279 0.7319 
ACC 0.6336 0.6423 0.6430 
Mean F 0.8547 0.8597 0.8595 
MRR 
5 
0.6910 0.7233 0.7280 
Table 3. Performance of GAP 
 
As seen in Table 3, although the top 1 seg-
mentation candidate could already achieve a cer-
tain performance level, taking the top 3 segmen-
tation candidates could nevertheless considerably 
improve the MRR.  This apparently suggests that 
the source name segmentation step could have 
significantly affected the overall performance of 
transliteration.  Taking more segmentation can-
didates into account could help raise some cor-
rect transliterations to a higher rank, but there 
was not much improvement in terms of the accu-
racy at the top 1 position. 
In terms of the grapheme pair frequency, set-
ting the threshold at 3 gave only slightly better 
results than setting it at 5.  A possible reason is 
that about 70% of all unique grapheme pairs 
have frequency below 5, and out of these over 
47% only have single correspondence.  In other 
words, there are a lot of grapheme pairs of low 
frequency, and for those ambiguous English seg-
ments, the distribution of their corresponding 
Chinese segments could be relatively uneven. 
Hence the following comparison between 
various transliteration methods was based on the 
combination of N=3 and f ? 3.  
6.2 System Performance 
To show the effectiveness of our proposed 
method, GAP was compared with JSCM and 
GAP-s.  Table 4 shows the results of the three 
methods. 
 
 JSCM GAP-s GAP 
ACC 0.5760 0.6174 0.6450 
Mean F 0.8309 0.8507 0.8598 
MRR 0.6881 0.7175 0.7319 
Table 4. System Performance Comparison 
 
As evident from Table 4, system GAP-s out-
performed JSCM.  The accuracy at top 1 position 
is much improved, thus boosting the MRR too.  
This improvement therefore supports our hy-
pothesis that contexts on both sides of a given 
segment are important for determining its rendi-
tion in Chinese, where part of the graphemic am-
biguity could be successfully resolved.  Mean-
while, system GAP further improves the results 
from GAP-s, bringing ACC up to 0.6450 and 
MRR to 0.7319.  This shows that the phonologi-
cal context could be better captured, though only 
approximately, by means of the last character of 
the previous segment and the first character of 
the next segment, instead of the whole 
neighbouring segments.  This is because the 
phonological context is often most closely re-
lated to the neighbouring phonemes instead of a 
whole syllable. 
6.3 Examples 
In this section we show two examples from the 
experimental outcomes to illustrate the useful-
ness of the GAP method. 
The name Abercromby, according to the gold 
standard, should be transliterated as ????? 
a4-bo2-ke4-long2-bi3.  This transliteration came 
third in the JSCM system, whose top first and 
second candidates were ?????? a4-bo2-
ke4-luo2-mu3-bi3 and??????? a4-bei4-
er3-ke4-luo2-mu3-bi3 respectively.  On the con-
trary, the expected transliteration came first in 
the GAP system. 
The top 3 source name segmentation candi-
dates for both methods are shown in Table 5.  
The expected segmentation has already been 
identified as the best candidate in GAP, while it 
came third in JSCM. 
 
Top JSCM GAP 
1 a/ber/c/ro/m/by a/ber/c/rom/by 
2 a/be/r/c/ro/m/by a/ber/c/ro/m/by 
3 a/ber/c/rom/by a/be/r/c/rom/by 
Table 5. Segmentations for Abercromby 
 
When it comes to the evaluation of the trans-
literation candidates, the longer candidates could 
even score higher than the expected outcome in 
JSCM.  The statistical data show that the bigram 
c/?+ro/? is far more likely than c/?+rom/?, 
but P(<ek,ck>=<rom,?> | fc(ek+1)=b) is much 
stronger than P(<ek,ck>=<m,? > | fc(ek+1)=b).  
Hence, taking the character on both sides of a 
segment, GAP managed to rank ????? 
highest. 
Another example is the name Regelson, which 
is transliterated as ???? li3-ge2-er3-sen1 in 
the gold standard.  The expected transliteration is 
191
ranked 8th in JSCM and 2nd in GAP.  Although 
P(<ek,ck>=<ge,?> | <ek-1,ck-1>=<re,?>) is much 
higher than P(<ek,ck>=<ge,?> | <ek-1,ck-1>=<re,
?>), when taking the next segment <l,?> into 
account, the likelihood of <ge,?> is lowered.  
Hence the expected transliteration is ranked 
higher in GAP. 
6.4 Error Analysis 
As the proposed method stands, errors could 
have been propagated from two steps.  The first 
is the source name segmentation step.  If it hap-
pens that the top segmentation candidates are 
already wrong to start with, there is no way to 
reach the expected transliteration at all.  Hence it 
is even more important to maintain a high accu-
racy for the segmentation step.  The other error-
propagation step is certainly when transliteration 
candidates are evaluated.  The results for this 
step often heavily rely on the training data.  If it 
happens that the grapheme pair distributions are 
somewhat skewed, particular Chinese segments 
would be preferred irrespective of relevant lin-
guistic or other factors.  On the other hand, if 
many homophones are used for a particular Eng-
lish segment, the chance of reaching the expected 
transliteration with one of the homophones is 
again loosened.  More on this will be discussed 
in the next section. 
For the latter error-propagation step, our at-
tempt to make use of contexts on both sides of a 
segment has been shown to be able to improve 
the results.  To see how much of the errors is at-
tributable to the segmentation step, we roughly 
made an estimation by comparing the length of 
the top 1 candidates given in JSCM and GAP 
with the gold standard.  It was found that 17.8% 
and 14.2% of the first candidates in JSCM and 
GAP respectively do not match the length of the 
gold standard.  More detailed analysis of the 
segmentation results is in progress. 
6.5 Current Limitations and Future Work 
Our current treatment of neighbouring context 
and graphemic approximation of phonological 
context is shown to outperform pure DOM based 
on previous context only.  Nevertheless, there are 
several directions of work which would require 
more investigation to further improve E2C per-
formance. 
First, the source name segmentation step needs 
further improvement to minimise error propaga-
tion from an early step.  Phonological knowledge 
is obviously important in this regard as how a 
given English name should be segmented and 
pronounced is determined by its phonological 
context.  Even without an explicit phonemic rep-
resentation of the source names, more could be 
done in terms of modelling the phonological con-
text via the surface graphemes. 
Second, relating to the above, foreign names 
of different origins often have very different 
phonological properties leading to different pro-
nunciations for the same orthographic forms.  
The silent h in Beckham mentioned earlier is one 
example, even though Chinese transliterations 
are often based on surface orthographic proper-
ties.  Other problematic cases could be from lan-
guages like Russian and German where there are 
relatively more consonant clusters.  For instance, 
the segment ?scho? is often transliterated as one 
syllable (e.g. ? shao4, ? xiao4, or ? she4) but 
the segment ?stro? often leads to three syllables 
(e.g. ??? si1-te4-luo2).  It is therefore impor-
tant to incorporate more phonological knowledge 
into the transliteration model, not only to gener-
ate more reliable and acceptable transliteration 
candidates, but also to reduce effort in evaluating 
phonologically invalid segmentation candidates 
and syllable structures, thus making the task 
computationally less expensive.  
Third, as one of our separate ongoing studies 
shows, homophones are not only abundant in 
Chinese language per se, but also in E2C trans-
literation.  The situation is particularly salient in 
Chinese transliterations based on Cantonese pro-
nunciations.  For example, while some names 
might have two transliterations with different 
pronunciations, like Jackson as ?? zik1-seon3 
or ?? zik1-san4, the same name might also be 
rendered in two forms with a different character 
having the same pronunciation, such as Adam as 
?? or ?? (both pronounced as aa3-dong1 in 
Cantonese).  Two transliterations for the same 
name might have the same sound but different 
tones, e.g. Ashley as ??? aai6-syu4-lei6 or ?
?? aai6-syu1-lei6.  We therefore attempt to 
model the English-Chinese segment correspon-
dence via an intermediate representation of the 
phonetic transcription of the Chinese characters.  
Preliminary results are reported in Kwong (2009).  
Although it happens that only one transliteration 
is given for each name in the gold standard data 
used in this study, the variability of E2C in real-
ity is evident.  It is therefore important for sys-
tems to be able to accommodate acceptable 
transliteration alternatives, particularly for trans-
literation extraction and information retrieval. 
192
Fourth, given that tonal patterns could help 
distinguish some homophone ambiguity, the ef-
fect of the tonal factor and its potential associa-
tion with the pitch and accent in the English 
names is worth further investigation. 
7 Conclusion 
Hence in this paper, we have reported our work 
on approximating phonological context for E2C 
with surface graphemic features.  This is based 
on the observation that certain graphemic ambi-
guity is closely associated with the local contexts 
on both sides of a given segment, the phonologi-
cal properties of which often determine its ex-
pected pronunciation.  Experiments have shown 
that in the absence of an explicit phonemic repre-
sentation of the English source names, the previ-
ous and next character of a given segment could 
be effectively employed to approximate the local 
phonological context affecting the rendition of a 
given segment in Chinese.  Our proposed method 
GAP gives better results than the conventional 
JSCM which only makes use of previous context, 
and GAP-s which considers the whole 
neighbouring segments.  Future work includes 
improving the source name segmentation step to 
minimise error propagation from an early stage, 
incorporating other factors like name origin and 
special phonological properties of different 
source languages into the transliteration model, 
as well as effectively handling homophones and 
tonal patterns in E2C transliteration. 
Acknowledgements 
The work described in this paper was substan-
tially supported by a grant from City University 
of Hong Kong (Project No. 7002203). 
References  
Jin, C., Na, S-H., Kim, D-I. and Lee, J-H. (2008)  
Automatic Extraction of English-Chinese Translit-
eration Pairs using Dynamic Window and Token-
izer.  In Proceedings of the Sixth SIGHAN Work-
shop on Chinese Language Processing (SIGHAN-
6), Hyderabad, India, pp.9-15. 
Kantor, P.B. and Voorhees, E.M. (2000)  The TREC-
5 Confusion Track: Comparing Retrieval Methods 
for Scanned Text.  Information Retrieval, 2(2-3): 
165-176. 
Knight, K. and Graehl, J. (1998)  Machine Translit-
eration.  Computational Linguistics, 24(4):599-612. 
Kuo, J-S. and Li, H. (2008)  Mining Transliterations 
from Web Query Results: An Incremental Ap-
proach.  In Proceedings of the Sixth SIGHAN 
Workshop on Chinese Language Processing 
(SIGHAN-6), Hyderabad, India, pp.16-23. 
Kwong, O.Y. (2009)  Homophones and Tonal Pat-
terns in English-Chinese Transliteration.  To ap-
pear in Proceedings of ACL-IJCNLP 2009, Singa-
pore. 
Lee, C-J., Chang, J.S. and Jang, J-S. R. (2006)  Ex-
traction of transliteration pairs from parallel cor-
pora using a statistical transliteration model.  In-
formation Sciences, 176:67-90. 
Li, H., Zhang, M. and Su, J. (2004)  A Joint Source-
Channel Model for Machine Transliteration.  In 
Proceedings of the 42nd Annual Meeting of the As-
sociation for Computational Linguistics (ACL 
2004), Barcelona, Spain, pp.159-166. 
Li, H., Sim, K.C., Kuo, J-S. and Dong, M. (2007)  
Semantic Transliteration of Personal Names.  In 
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics (ACL 
2007), Prague, Czech Republic, pp.120-127. 
Oh, J-H. and Choi, K-S. (2005)  An Ensemble of 
Grapheme and Phoneme for Machine Translitera-
tion.  In R. Dale, K-F. Wong, J. Su and O.Y. 
Kwong (Eds.), Natural Language Processing ? 
IJCNLP 2005.  Springer, LNAI Vol. 3651, pp.451-
461. 
Sproat, R., Shih, C., Gale, W. and Chang, N. (1996)  
A stochastic finite-state word-segmentation algo-
rithm for Chinese.  Computational Linguistics, 
22(3): 377-404. 
Tao, T., Yoon, S-Y., Fister, A., Sproat, R. and Zhai, C. 
(2006)  Unsupervised Named Entity Transliteration 
Using Temporal and Phonetic Correlation.  In Pro-
ceedings of the 2006 Conference on Empirical 
Methods in Natural Language Processing (EMNLP 
2006), Sydney, Australia, pp.250-257. 
Virga, P. and Khudanpur, S. (2003)  Transliteration of 
Proper Names in Cross-lingual Information Re-
trieval.  In Proceedings of the ACL2003 Workshop 
on Multilingual and Mixed-language Named Entity 
Recognition. 
Xinhua News Agency. (1992)  Chinese Translitera-
tion of Foreign Personal Names.  The Commercial 
Press. 
Yoon, S-Y., Kim, K-Y. and Sproat, R. (2007)  Multi-
lingual Transliteration Using Feature based Pho-
netic Method.  In Proceedings of the 45th Annual 
Meeting of the Association for Computational Lin-
guistics (ACL 2007), Prague, Czech Republic, 
pp.112-119. 
193
Mining Large-scale Parallel Corpora from Multilingual Patents: 
An English-Chinese example and its application to SMT 
Bin Lu?, Benjamin K. Tsou??, Tao Jiang?, Oi Yee Kwong?, and Jingbo Zhu? 
?Department of Chinese, Translation & Linguistics, City University of Hong Kong 
?Research Centre on Linguistics and Language Information Sciences,  
Hong Kong Institute of Education 
?ChiLin Star Corp., Southern Software Park, Zhuhai, China 
?Natural Language Processing Lab, Northeastern University, Shenyang, China 
{lubin2010, rlbtsou, jiangtaoster}@gmail.com, 
rlolivia@cityu.edu.hk, zhujingbo@mail.neu.edu.cn 
 
Abstract 
In this paper, we demonstrate how to 
mine large-scale parallel corpora with 
multilingual patents, which have not 
been thoroughly explored before. We 
show how a large-scale English-Chinese 
parallel corpus containing over 14 
million sentence pairs with only 1-5% 
wrong can be mined from a large amount 
of English-Chinese bilingual patents. To 
our knowledge, this is the largest single 
parallel corpus in terms of sentence pairs. 
Moreover, we estimate the potential for 
mining multilingual parallel corpora 
involving English, Chinese, Japanese, 
Korean, German, etc., which would to 
some extent reduce the parallel data 
acquisition bottleneck in multilingual 
information processing. 
1 Introduction 
Multilingual data are critical resources for 
building many applications, such as machine 
translation (MT) and cross-lingual information 
retrieval. Many parallel corpora have been built, 
such as the Canadian Hansards (Gale and 
Church, 1991), the Europarl corpus (Koehn, 
2005), the Arabic-English and English-Chinese 
parallel corpora used in the NIST Open MT 
Evaluation.  
However, few parallel corpora exist for many 
language pairs, such as Chinese-Japanese, 
Japanese-Korean, Chinese- French or 
Japanese-German. Even for language pairs with 
several parallel corpora, such as Chinese-English 
and Arabic-English, the size of parallel corpora 
is still a major limitation for SMT systems to 
achieve higher performance. 
In this paper, we present a way which could, to 
some extent, reduce the parallel data acquisition 
bottleneck in multilingual language processing.  
Based on multilingual patents, we show how an 
enlarged English-Chinese parallel corpus 
containing over 14 million high-quality sentence 
pairs can be mined from a large number of 
comparable patents harvested from the Web. To 
our knowledge, this is the largest single parallel 
corpus in terms of parallel sentences. Some SMT 
experiments are also reported. Moreover, we 
investigate the potential to get large-scale 
parallel corpora for languages beyond the 
Canadian Hansards, Europarl and UN news used 
in NIST MT Evaluation by estimating the 
quantity of multilingual patents involving 
English, Chinese, Japanese, Korean, German, 
etc.  
Related work is introduced in Section 2. 
Patents, PCT patents, multilingual patents are 
described in Section 3. Then an English-Chinese 
parallel corpus, its mining process and 
application to SMT are introduced in Section 4, 
followed by the quantity estimation of 
multilingual patents involving other language 
pairs in Section 5. We discuss the results in 
Section 6, and conclude in Section 7. 
2 Related Work 
Parallel sentences could be extracted from 
parallel documents or comparable corpora. 
Different approaches have been proposed to 
align sentences in parallel documents consisting 
of the same content in different languages based 
on the following information: a) the sentence 
length in bilingual sentences (Brown et al 1991; 
Gale and Church, 1991); b) lexical information 
in bilingual dictionaries (Ma, 2006); c) statistical 
translation model (Chen, 1993), or the composite 
of more than one approach (Simard and 
Plamondon, 1998; Moore, 2002).  
To overcome the lack of parallel documents, 
comparable corpora are also used to mine 
parallel sentences, which raises further 
challenges since the bilingual contents are not 
strictly parallel. For instance, Zhao and Vogel 
(2002) investigated the mining of parallel 
sentences for Web bilingual news. Munteanu and 
Marcu (2005) presented a method for 
discovering parallel sentences in large Chinese, 
Arabic, and English comparable, non-parallel 
corpora based on a maximum entropy classifier. 
Cao et al, (2007) and Lin et al, (2008) proposed 
two different methods utilizing the parenthesis 
pattern to extract term translations from bilingual 
web pages. Jiang et al (2009) presented an 
adaptive pattern-based method which produced 
Chinese-English bilingual sentences and terms  
with over 80% accuracy. 
Only a few papers were found on the related 
work in the patent domain. Higuchi et al (2001) 
used the titles and abstracts of 32,000 
Japanese-English bilingual patents to extract 
bilingual terms. Utiyama and Isahara (2007) 
mined about 2 million parallel sentences by 
using two parts in the description section of 
Japanese-English comparable patents. Lu et al 
(2009) derived about 160K parallel sentences 
from Chinese-English comparable patents by 
aligning sentences and filtering alignments with 
the combination of different quality measures. 
Another closely related work is the 
English-Chinese parallel corpus (Lu et al, 
2010), which is largely extended by this work, in 
which both the number of patents and that of 
parallel sentences are augmented by about 
100%, and more SMT experiments are given. 
Moreover, we show the potential for mining 
parallel corpora from multilingual patents 
involving other languages. 
For statistical machine translation (SMT), 
tremendous strides have been made in two 
decades, including Brown et al (1993), Och and 
Ney (2004) and Chiang (2007). For the MT 
evaluation, NIST (Fujii et al, 2008; 2010) has 
been organizing open evaluations for years, and 
the performance of the participants has been 
improved rapidly.  
3 Patents and Multilingual Patents 
A patent is a legal document representing ?an 
official document granting the exclusive right to 
make, use, and sell an invention for a limited 
period? (Collins English Dictionary1). A patent 
application consists of different sections, and we 
focus on the text, i.e. only title, abstract, claims 
and description.  
3.1 PCT Patents 
Since the invention in a patent is only protected 
in the filing countries, a patent applicant who 
wishes to protect his invention outside the 
original country should file patents in other 
countries, which may involve other languages. 
The Patent Cooperation Treaty (PCT) system 
offers inventors and industry an advantageous 
route for obtaining patent protection 
internationally. By filing one ?international? 
patent application under the PCT via the World 
Intellectually Property Organization (WIPO), 
protection of an invention can be sought 
simultaneously (i.e. the priority date) in each of a 
large number of countries. 
The number of PCT international applications 
                                                          
1 Retrieved March 2010, from 
http://www.collinslanguage.com/ 
filed is more than 1.7 million 2 . A PCT 
international application may be filed in any 
language accepted by the relevant receiving 
office, but must be published in one of the 
official publication languages (Arabic, Chinese, 
English, French, German, Japanese, Korean, 
Russian and Spanish). Other highly used 
languages for filing include Italian, Dutch, 
Finnish, Swedish, etc. Table 1 3  shows the 
number of PCT applications for the most used 
languages of filing and publication.  
 Lang. of Filing 
Share 
(%) 
Lang. of 
Publication 
Share 
(%) 
English 895K 52.1 943K 54.9 
Japanese 198K 11.5 196K 11.4 
German 185K 10.8 184K 10.7 
French 55K 3.2 55K 3.2 
Korean 24K 1.4 3K4 0.2 
Chinese 24K 1.4 24K 1.4 
Other 336K 19.6 313K 18.2 
Total 1.72M 100 1.72M 100 
Table 1. PCT Application Numbers for Languages of 
Publication and Filing 
From Table 1, we can observe that English, 
Japanese and German are the top 3 languages in 
terms of PCT applications, and English accounts 
for over 50% of applications in terms of 
language of both publication and filing.  
3.2 Multilingual Patents 
A PCT application does not necessarily mean a 
multilingual patent. An applicant who has 
decided to proceed further with his PCT 
international application must fulfill the 
requirements for entry into the PCT national 
phase at the patent offices of countries where he 
seeks protection. For example, a Chinese 
company may first file a Chinese patent in China 
                                                          
2 Retrieved Apr., 2010 from 
http://www.wipo.int/pctdb/en/. The data below involving 
PCT patents comes from the website of WIPO. 
3 The data in this and other tables in the following sections 
involving PCT patents comes from the website of WIPO. 
4  Korean just became one of the official publication 
languages for the PCT system since 2009, and thus the 
number of PCT patents with Korean as language of 
publication is small. 
patent office and then file its international 
application also in Chinese under the PCT. Later 
on, it may have the patent translated into English 
and file it in USA patent office, which means the 
patent becomes bilingual. If the applicant 
continues to file it in Japan with Japanese, it 
would be trilingual. Even more, it would be 
quadrilingual or involve more languages when it 
is filed in other countries with more languages. 
Such multilingual patents are considered 
comparable (or noisy parallel) because they are 
not parallel in the strict sense but still closely 
related in terms of information conveyed 
(Higuchi et al, 2001; Lu et al, 2009). 
4 A Large English-Chinese Parallel 
Corpus Mined from Bilingual Patents 
In this section, we introduce the English-Chinese 
bilingual patents harvested from the Web and the 
method to mine parallel sentences from them. 
SMT experiments on the final parallel corpus are 
also described. 
4.1 Harvesting English-Chinese Bilingual 
Patents 
The official patent office in China is the State 
Intellectual Property Office (SIPO). In early 
2009,  by searching on its website, we found 
about 200K Chinese patents previously filed as 
PCT applications in English and crawled their 
bibliographical data, titles, abstracts and the 
major claim from the Web, and then other claims 
and descriptions were also added. Since some 
contents are in the image format, the images 
were OCRed and the texts recognized were 
manually verified. 
All PCT patent applications are filed through 
WIPO. With the Chinese patents mentioned 
above, the corresponding English patents were 
searched from the website of WIPO by the PCT 
publication numbers to obtain relevant sections 
of the English PCT applications, including 
bibliographical data, title, abstract, claims and 
description. About 80% (160K) out of the 
Chinese patents found their corresponding 
English ones. Some contents of the English 
patents were OCRed by WIPO. 
We automatically split the patents into 
individual sections according to the respective 
tags inside the patents, and segmented each 
section sentences according to punctuations. The 
statistics of each section for Chinese and 
English patents are shown in Table 2. 
Chinese English 
Sections 
#Char #Sent #Word #Sent 
Title 2.7M 157K 1.6M 157K 
Abstract 33M 596K 20M 784K 
Claim 367M 6.8M 217M 7.4M 
Desc. 2,467M 48.8M 1,353M 54.0M 
Total 2,870M 56.2M 1,591M 62.3M 
Table 2. Statistics of Comparable Patents 
4.2 Mining Parallel Sentences from 
Bilingual Patents 
The sentences in each section of Chinese patents 
were aligned with those in the corresponding 
section of the corresponding English patents to 
find parallel sentences after the Chinese 
sentences were segmented into words. 
Since the comparable patents are not strictly 
parallel, the individual alignment methods 
mentioned in Section 2 would be not effective: 1) 
the length-based method is not accurate since it 
does not consider content similarity; 2) the 
bilingual dictionary-based method cannot deal 
with new technical terms in the patents; 3) the 
translation model-based method would need 
training data to get a translation model. Thus, in 
this study we combine these three methods to 
mine high-quality parallel sentences from 
comparable patents. 
We first use a bilingual dictionary to 
preliminarily align the sentences in each section 
of the comparable patents. The dictionary-based 
similarity score dP  of a sentence pair is 
computed based on a bilingual dictionary as 
follows (Utiyama and Isahara, 2003):  
2/??
)deg()deg(
),(
),(
ce
Sw Sw ec
ec
ecd ll
ww
ww
SSp cc ee
+
=
? ?
? ?
?
 
where cw  and ew  are respectively the 
word types in Chinese sentence cS  and 
English sentence eS ; cl  and el  respectively 
denote the lengths of cS  and eS  in terms of 
the number of words; and ),( ec ww?  = 1 if 
cw  and ew  is a translation pair in the 
bilingual dictionary or are the same string, 
otherwise 0; and 
?
?
=
ee Sw
ecc www ),()deg( ?
?
?
=
ce Sw
ece www ),()deg( ? . 
For the bilingual dictionary, we combine three 
ones: namely, LDC_CE_DIC2.0 5  constructed 
by LDC, bilingual terms in HowNet and the 
bilingual lexicon in Champollion (Ma, 2006). 
We then remove sentence pairs using length 
filtering and ratio filtering: 1) for length filtering, 
if a sentence pair has more than 100 words in the 
English sentence or more than 333 characters in 
the Chinese one, it is removed; 2) for length ratio 
filtering, we discard the sentence pairs with 
Chinese-English length ratio outside the range of 
0.8 to 1.8. The parameters here are set 
empirically. 
We further filter the parallel sentence 
candidates by learning an IBM Model-1 on the 
remaining aligned sentences and compute the 
translation similarity score tP  of sentence 
pairs by combining the translation probability 
value of both directions (i.e. Chinese->English 
and English->Chinese) based on the trained 
IBM-1 model (Moore, 2002; Chen, 2003; Lu et 
al, 2009). It is computed as follows: 
ec
ecce
ect ll
)S(SPlog)S(SPlog
SSp
+
+
=
)|()|(
),(
 
where )SS(P ce | denotes the probability 
that a translator will produce eS  in English 
when presented with cS  in Chinese, and vice 
versa for )|(S ec SP . Sentence pairs with 
                                                          
5 http://projects.ldc.upenn.edu/Chinese/LDC_ch.htm 
similarity score tP  lower than a predefined 
threshold are filtered out as wrong aligned 
sentences. 
Table 3 shows the sentence numbers and the 
percentages of sentences kept in each step above 
with respect to all sentence pairs. In the first row 
of Table 3, 1.DICT denotes the first step of using 
the bilingual dictionary to align sentences; 2. FL 
denotes the length and ratio filtering; 3. TM 
refers to the third and final step of using 
translation models to filter sentence pairs. 
 1. DICT 2.FL 3. TM (final) 
Abstr. 503K 352K  (70%) 
166K  
(33%) 
Claims 6.0M 4.3M (72.1%) 
2.0M 
(33.4%) 
Desc. 38.6M 26.8M (69.4%) 
12.1M 
(31.3%) 
Total6 45.1M 31.5M (69.8%) 
14.3M 
(31.7%) 
Table 3. Numbers of Sentence Pairs 
Both the 31.5M parallel sentences after the 
second step FL and the final 14.3M after the third 
step TM are manually evaluated by randomly 
sampling 100 sentence pairs for each section. 
The evaluation metric follows the one in Lu et al 
(2009), which classifies each sentence pair into 
Correct, Partially Correct or Wrong. The results 
of manual evaluation are shown in Table 4. 
 Section Correct Partially Correct Wrong 
Abstr. 85% 7% 8% 
Claims 83% 10% 7% 2. FL 
Desc. 69% 15% 15% 
Abstr. 97% 2% 1% 
Claims 92% 3% 5% 3. TM  (final) 
Desc. 89% 8% 3% 
Table 4. Manual Evaluation of the Corpus 
From Table 4, we can see that: 1) In the final 
corpus, the percentages of correct parallel 
sentences are quite high, and the wrong 
percentages are no higher than 5%; 2) Without 
                                                          
6 Here the total number does not include the number of 
titles, which are directly treated as parallel. 
the final step of TM, the accuracies of 31.5M 
sentence pairs are between 69%-85%, and the 
percentages of wrong pairs are between 
7%-15%; 3) The abstract section shows the 
highest correct percentage, while the description 
section shows the lowest. 
Thus, we could conclude that the mined 14M 
parallel sentences are of high quality with only 
1%-5% wrong pairs, and our combination of 
bilingual dictionaries and translation models for 
mining parallel sentences are quite effective. 
4.3 Chinese-English Statistical Machine 
Translation 
A Chinese-English SMT system is setup using 
Moses (Koehn, 2007). We train models  based 
on different numbers of parallel sentences mined 
above. The test set contains 548 sentence pairs 
which are randomly selected and different from 
the training data. The sizes of the training data 
and BLEU scores for the models are shown in 
Table 5. 
System BLEU (%) #Sentence Pairs for training 
Model-A 17.94 300K 
Model-B 19.96 750K 
Model-C 20.09 1.5M 
Model-D 20.98 3M 
Model-E 22.60 6M 
Table 5. SMT Experimental Results 
From Table 5, we can see that the BLEU 
scores are improving steadily when the training 
data increases. When the training data is 
enlarged by 20 times from 300K to 6M, the 
BLEU score increases to 22.60 from 17.94, 
which is quite a significant improvement. We 
show the translations of one Chinese sample 
sentence in Table 6 below. 
CN  
Sent. 
?? ?? ?? ??? ?? ? ? ?? ? 
? ? 
Ref. 
the main shaft of the electric motor 
extends into the working cavity of the 
compressor shell , 
Model-A the motor main shaft into the compressor the chamber 
Model-B motor shaft into the compressor housing . the working chamber 
Model-C motor shaft into the compressor housing . the working chamber 
Model-D 
motor spindle extends into the 
compressor housing . the working 
chamber 
Model-E motor spindle extends into the working chamber of the compressor housing , 
Table 6. Translations of One Chinese Sentence 
From Table 6, we can see the translations 
given by Model-A to Model-C are lack of the 
main verb, the one given by Model-D has an 
ordering problem for the head noun and the 
modifier, and the one given by Model-E seems 
better than the others and its content is already 
quite similar to the reference despite the lexical 
difference. 
5 Multilingual Corpora for More 
Languages 
In this section, we describe the potential of 
building large-scale parallel corpora for more 
languages, especially Asian languages by using 
the 1.7 million PCT patent applications and their 
national correspondents. By using PCT 
applications as the pivot, we can build 
multilingual parallel corpora from multilingual 
patents, which would greatly enlarge parallel 
data we could obtain. 
The patent applications filed in one country 
should be in the official language(s) of the 
country, e.g. the applications filed in China 
should be in Chinese, those in Japan be in 
Japanese, and so on. In Table 7, the second 
column shows the total numbers of patent 
applications in different countries which were 
previously filed as PCT ones; and the third 
column shows the total numbers of applications 
in different countries, which were previously 
filed as PCT ones with English as language of 
publication. 
National Phase 
Country7 ALL 
English as Lang. 
of Publication 
                                                          
7 For the national phase of the PCT System, the statistics 
are based on data supplied to WIPO by national and 
Japan 424K 269K 
China 307K 188K 
Germany 32K 10K 
R. Korea 236K 134K 
China & Japan 189K 130K 
China & R. Korea 154K 91K 
Japan & R. Korea 158K 103K 
China & Japan  
& R. Korea 106K 73K 
Table 7. Estimated Numbers of Multilingual 
Patents 
The number of the Chinese-English bilingual 
patents (CE) in Table 7 is about 188K, which is 
consistent with the number of 160K found in 
Section 4.1 since the latter contains only the 
applications up to early 2009. Based on Table 7, 
we estimate below the rough sizes of bilingual 
corpora, trilingual corpora, and even 
quadrilingual corpora for different languages. 
1) Bilingual Corpora with English as one 
language 
Compared to CE (188K), the 
Japanese-English bilingual corpus (269K) could 
be 50% larger in terms of bilingual patents, the 
Korean-English one (134K) could be about 30% 
smaller, and the German-English one (10K) 
would be much smaller. 
2) Bilingual Corpora for Asian Languages  
The Japanese-Chinese bilingual corpus 
(189K) could be comparable to CE (188K) in 
terms of bilingual applications, the Chinese- 
Korean one (154K) could be about 20% smaller, 
and the Japanese-Korean one (158K) is quite 
similar to the Chinese-Korean one. 
3)  Trilingual Corpora 
In addition to bilingual corpora, we can also 
build trilingual corpora from trilingual patents. It 
is quite interesting to note that the trilingual 
corpora  could be quite large even compared to 
the bilingual corpora.  
The trilingual corpora for Chinese, Japanese 
and English (130K) could be only 30% smaller 
than CE in terms of patents. The trilingual corpus 
                                                                                      
regional patent Offices, received at WIPO often 6 months or 
more after the end of the year concerned, i.e. the numbers 
are not up-to-date . 
for Chinese, Korean and English (91K) and that 
for Japanese, Korean and English (103K) are 
also quite large. The number of the trilingual 
patents for the Asian languages of Chinese, 
Japanese and Korean (106K) is about 54% of 
that of CE. 
4) Quadrilingual Corpora 
The number of the quadrilingual patents for 
Chinese, Japanese, Korean and English (73K) is 
about 38% of that of CE. From these figures, we 
could say that a large proportion of the PCT 
applications published in English later have been 
filed in all the three Asian countries: China, 
Japan, and R. Korea. 
6 Discussion 
The websites from which the Chinese and 
English patents were downloaded were quite 
slow to access, and were occasionally down 
during access. To avoid too much workload for 
the websites, the downloading speed had been 
limited. Some large patents would cost much 
time for the websites to respond and had be 
specifically handled. It took considerable efforts 
to obtain these comparable patents.  
In addition our English-Chinese corpus mined 
in this study is at least one order of magnitude 
larger, we give some other differences between 
ours and those introduced in Section 2 (Higuchi 
et al, 2001; Utiyama and Isahara, 2007; Lu et al 
2009)  
1) Their bilingual patents were identified by 
the priority information in the US patents, and 
could not be easily extended to language pairs 
without English; while our method using PCT 
applications as the pivot could be easily 
extended to other language pairs as illustrated in 
Section 5. 
2) The translation process is different: their 
patents were filed in USA Patent Office in 
English by translating from Japanese or Chinese, 
while our patents were first filed in English as a 
PCT application, and later translated into 
Chinese. The different translation processes may 
have different characteristics. 
Since the PCT and multilingual patent 
applications increase rapidly in recent years as 
discussed in Section 3, we could expect more 
multilingual patents to enlarge the large-scale 
parallel corpora with the new applications and 
keep them up-to-date with new technical terms. 
On the other hand, patents are usually translated 
by patent agents or professionals, we could 
expect high quality translations from 
multilingual patents. We have been planning to 
build trilingual and quadrilingual corpora from 
multilingual patents. 
One possible limitation of patent corpora is 
that the sentences are all from technical domains 
and written in formal style, and thus it is 
interesting to know if the parallel sentences 
could improve the performance of SMT systems  
on NIST MT evaluation corpus containing news 
sentences and web sentences.  
7 Conclusion 
In this paper, we show how a large high-quality 
English-Chinese parallel corpus can be mined 
from a large amount of comparable patents 
harvested from the Web, which is the largest 
single parallel corpus in terms of the  number of 
parallel sentences. Some sampled parallel 
sentences are available at 
http://www.livac.org/smt/parpat.html, and more 
parallel sentences would be publicly available to 
the research community. 
With 1.7 million PCT patent applications and 
their corresponding national ones, there are 
considerable potentials of constructing 
large-scale high-quality parallel corpora for 
languages. We give an estimation on the sizes of 
multilingual parallel corpora which could be 
obtained from multilingual patents involving 
English, Chinese, Japanese, Korean, German, 
etc., which would to some extent reduce the 
parallel data acquisition bottleneck in 
multilingual information processing. 
Acknowledgements 
We wish to thank Mr. Long Jiang from 
Microsoft Research Asia and anonymous 
reviewers for their valuable comments. 
References 
Brown, Peter F., Jennifer C. Lai, and Robert L. 
Mercer. 1991. Aligning sentences in parallel 
corpora. In Proceedings of ACL. pp.169-176. 
Brown, Peter F., Stephen A. Della Pietra, Vincent J. 
Della Pietra, and Robert L. Mercer. 1993. 
Mathematics of statistical machine translation: 
Parameter estimation. Computational Linguistics, 
19(2), 263-311. 
Cao, Guihong, Jianfeng Gao and Jianyun Nie. 2007. 
A System to Mine Large-scale Bilingual 
Dictionaries from  Monolingual Web Pages. In 
Proceedings of MT Summit. pp. 57-64. 
Chen, Stanley F. 1993. Aligning sentences in 
bilingual corpora using lexical information. In 
Proceedings of ACL. pp. 9-16. 
Chiang, David. 2007. Hierarchical phrase-based 
translation. Computational Linguistics, 33(2), 
201?228. 
Fujii, Atsushi, Masao Utiyama, Mikio Yamamoto, 
and Takehito Utsuro. 2008. Overview of the patent 
translation task at the NTCIR-7 workshop. In 
Proceedings of the NTCIR-7 Workshop. pp. 
389-400. Tokyo, Japan. 
Fujii, Atsushi, Masao Utiyama, Mikio Yamamoto, 
Takehito Utsuro, Terumasa Ehara, Hiroshi 
Echizen-ya and Sayori Shimohata. 2010. 
Overview of the patent translation task at the 
NTCIR-8 workshop. In Proceedings of the 
NTCIR-8 Workshop. Tokyo, Japan. 
Gale, William A., and Kenneth W. Church. 1991. A 
program for aligning sentences in bilingual 
corpora. In Proceedings of ACL. pp.79-85. 
Higuchi, Shigeto, Masatoshi Fukui, Atsushi Fujii, and 
Tetsuya Ishikawa. PRIME: A System for 
Multi-lingual Patent Retrieval. In Proceedings of 
MT Summit VIII, pp.163-167, 2001. 
Koehn, Philipp. 2005. Europarl: A parallel corpus for 
statistical machine translation. In Proceedings of 
MT Summit X. 
Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, et al 2007. Moses: Open source 
toolkit for statistical machine translation. In 
Proceedings of ACL Demo Session. pp. 177-180. 
Lin, Dekang, Shaojun Zhao, Benjamin V. Durme and 
Marius Pasca. 2008. Mining Parenthetical 
Translations from the Web by Word Alignment. In 
Proceedings of ACL-08. pp. 994-1002. 
Jiang, Long, Shiquan Yang, Ming Zhou, Xiaohua Liu, 
and Qingsheng Zhu. 2009. Mining Bilingual Data 
from the Web with Adaptively Learnt Patterns. In 
Proceedings of ACL-IJCNLP. pp. 870-878. 
Lu, Bin, Benjamin K. Tsou, Jingbo Zhu, Tao Jiang, 
and Olivia Y. Kwong. 2009. The Construction of 
an English-Chinese Patent Parallel Corpus. MT 
Summit XII 3rd Workshop on Patent Translation. 
Lu, Bin, Tao Jiang, Kapo Chow and Benjamin K. 
Tsou. 2010. Building a Large English-Chinese 
Parallel Corpus from Comparable Patents and its 
Experimental Application to SMT. LREC 
Workshop on Building and Using Comparable 
Corpora. Malta. May, 2010. 
Ma, Xiaoyi. 2006. Champollion: A Robust Parallel 
Text Sentence Aligner. In Proceedings of the 5th 
International Conference on Language Resources 
and Evaluation (LREC). Genova, Italy. 
Moore, Robert C. 2002. Fast and Accurate Sentence 
Alignment of Bilingual Corpora. In Proceedings of 
AMTA. pp.135-144. 
Munteanu, Dragos S., and Daniel Marcu. 2005. 
Improving Machine Translation Performance by 
Exploiting Non-parallel Corpora. Computational 
Linguistics, 31(4), 477?504. 
Och, Franz J., and Hermann Ney. 2004. The 
Alignment Template Approach to Machine 
Translation. Computational Linguistics, 30(4), 
417-449. 
Simard, Michel, and Pierre Plamondon. 1998. 
Bilingual Sentence Alignment: Balancing 
Robustness and Accuracy. Machine Translation, 
13(1), 59-80. 
Utiyama, Masao, and Hitoshi Isahara. 2007. A 
Japanese-English patent parallel corpus. In 
Proceeding of MT Summit XI. pp. 475?482. 
Zhao, Bing, and Stephen Vogel. 2002. Adaptive 
Parallel Sentences Mining from Web Bilingual 
News Collection. In Proceedings of Second IEEE 
International Conference on Data Mining 
(ICDM?02). 
