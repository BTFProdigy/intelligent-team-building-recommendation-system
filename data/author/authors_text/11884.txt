Forest-Based Statistical Sentence Generat ion 
I rene  Langk i lde  
Information Sciences Inst i tute 
University of Southern California 
Marina del Rey CA 90292 
ilangkil?isi .edu 
Abst rac t  
This paper presents a new approach to sta- 
tistical sentence generation in which Mterna- 
tive phrases are represented as packed sets of 
trees, or forests, and then ranked statistically to 
choose the best one. This representation ffers 
advantages in compactness and in the ability 
to represent syntactic information. It also fa- 
cilitates more efficient statistical ranking than 
a previous approach to statistical generation. 
An efficient ranking algorithm is described, to- 
gether with experimental results showing signif- 
icant improvements over simple enumeration or
a lattice-based approach. 
1 I n t roduct ion  
Large textual corpora offer the possibility of 
a statistical approach to the task of sentence 
generation. Like any large-scale NLP or AI 
task, the task of sentence generation requires 
immense amounts of knowledge. The knowledge 
needed includes lexicons, grammars, ontologies, 
collocation lists, and morphological tables. Ac- 
quiring and applying accurate, detailed knowl- 
edge of this breadth poses difficult problems. 
Knight and Hatzivassiloglou (1995) suggested 
overcoming the knowledge acquisition bottle- 
neck in generation by tapping the information 
inherent in textual corpora. They performed ex- 
periments showing that automatically-acquired, 
corpus-based knowledge greatly reduced the 
need for deep, hand-crafted knowledge. At 
the same time, this approach to generation im- 
proved scalability and robustness, offering the 
potential in the future for higher quality out- 
put. 
In their approach, K ~: H adapted techniques 
used in speech recognition. Corpus-based sta- 
tistical knowledge was applied to the generation 
process after encoding many alternative phras- 
ings into a structure called a lattice (see Fig- 
ure 1). A lattice was able to represent large 
numbers alternative phrases without requiring 
the large amount of space that an explicitly enu- 
merated list of individual alternatives would re- 
quire. The Mternative sentences in the lattice 
were then ranked according to a statistical lan- 
guage model, and the most likely sentence was 
chosen as output. Since the number of phrases 
that needed be considered typically grew ex- 
ponentially with the length of the phrase, the 
lattice was usually too large for an exhaustive 
search, and instead an n-best algorithm was 
used to heuristically narrow the search. 
The lattice-based method, though promising, 
had several drawbacks that will be discussed 
shortly. This paper presents a different method 
of statistical generation based on a forest struc- 
ture (a packed set of trees). A forest is more 
compact han a lattice, and it offers a hierar- 
chical organization that is conducive to repre- 
senting syntactic information. Furthermore, it 
facilitates dramatically more efficient statistical 
ranking, since constraints can be localized, and 
the combinatorial explosion of possibilities that 
need be considered can be reduced. In addition 
to describing the forest data structure we use, 
this paper presents a forest-based ranking algo- 
rithm, and reports experimental results on its 
efficiency in both time and space. It also favor- 
ably compares these results to the performance 
of a lattice-based approach. 
2 Represent ing  Al ternat ive  Phrases  
2.1 Enumerated  lists and lattices 
The task of sentence generation involves map- 
ping from an abstract representation f mean- 
ing or syntax to a linear ordering of words. 
Subtasks of generation usually include choosing 
content words, determining word order, 
170 
.g 
.~ 
Figure 1: A lattice representing 576 different sen- 
tences, including "You may have to eat chicken", 
"The chicken may have to be eaten by you", etc. 
171 
deciding when to insert function words, per- 
forming morphological inflections, and satis- 
fying agreement constraints, as well as other 
tasks. 
One way of leveraging corpus-based knowl- 
edge is to explicitly enumerate many alternate 
possibilities and select the most likely according 
to a corpus-based statistical model. Since many 
subphrases and decisions will be common across 
propose d sentences, a lattice is a more efficient 
way than one-by-one numeration to represent 
them. A lattice is a graph where each arc is la- 
beled with a word. A complete path from the 
left-most node to right-most node through the 
lattice represents a possible sentence. Multiple 
arcs leaving a particular node represent alter- 
nate paths. A lattice thus allows structure to 
be shared between sentences. An example of a 
lattice is shown in Figure 1. This lattice encodes 
576 unique sentences. In practice, a lattice may 
represent many trillions of sentences. Without 
a compact representation for so many sentences, 
statistical generation would be much less feasi- 
ble. 
The lattice in Figure 1 illustrates several 
types of decisions that need to be made in gen- 
eration. For example, there is a choice be- 
tween the root words "chicken" and "poulet", 
the choice of whether to use singular or plural 
forms of these words, the decision whether to 
use an article or not, and if so, which one--  
definite or indefinite. There are also other word 
choice decisions uch as whether to use the aux- 
iliary verb "could", "might", or "may", and 
whether to express the mode of eating with the 
predicate "have to", "be obliged to", or "be re- 
quired to". Finally, there is a choice between 
active voice (bottom half of lattice), and pas- 
sive voice (top half). 
Inspection of the lattice reveals some un- 
avoidable duplication, however. For example, 
the word "chicken" occurs four times, while 
the sublattice for the noun phrase contain- 
ing "chicken" is repeated twice. So is the 
verb phrase headed by the auxiliaries "could", 
"might", and "may". Such repetition is com- 
mon in a lattice representation for text genera- 
tion, and has a negative impact on the efficiency 
of the ranking algorithm because the same set 
of score calculations end up being made several 
times. Another drawback of the duplication is 
that the representation consumes more storage 
space than necessary. 
Yet another drawback of the lattice represen- 
tation is that the independence between many 
choices cannot be fully exploited. Stolcke et al 
(1997) noted that 55% of all word dependencies 
occur between adjacent words. This means that 
most choices that must be made in non-adjacent 
parts of a sentence are independent. For ex- 
ample, in Figure 1, the choice between "may", 
"might", or "could" is independent of the choice 
between "a", "an" or "the" to precede "chicken" 
or "poulet". Independence r duces the combi- 
nation of possibilities that must be considered, 
and allows some decisions to be made with- 
out taking into account he rest of the context. 
Even adjacent words are sometimes indepen- 
dent of each other, such as the words "tail" and 
"ate" in the sentence "The dog with the short 
tail ate the bone". A lattice does not offer any 
way of representing which parts of a sentence 
are independent of each other, and thus can- 
not take advantage of this independence. This 
negatively impacts both the amount of process- 
ing needed and the quality of the results. In 
contrast, a forest representation, which we will 
discuss shortly, does allow the independence to
be explicitly annotated. 
A final difficulty with using lattices is that 
the search space grows exponentially with the 
length of the sentence(s), making an exhaustive 
search for the most likely sentence impractical 
for long sentences. Heuristic-based searches of- 
fer only a poor approximation. Any pruning 
that is done renders the solution theoretically 
inadmissable, and in practice, frequently ends 
up pruning the mathematically optimal solu- 
tion. 
2.2 Forests  
These weaknesses of the lattice representation 
can be overcome with a forest representation. If 
we assign a label to each unique arc and to each 
group of arcs that occurs more than once in a 
lattice, a lattice becomes a forest, and the prob- 
lems with duplication in a lattice are eliminated. 
The resulting structure can be represented as a 
set of context-free rewrite rules. Such a forest 
need not necessarily comply with a particular 
theory of syntactic structure, but it can if one 
wishes. It also need not be derived specifically 
from a lattice, but can be generated irectly 
172 
from a semantic input. 
With a forest representation, it is quite nat- 
ural to incorporate syntactic information. Syn- 
tactic information offers some potentially signif- 
icant advantages for statistical language model- 
ing. However, this paper will not discuss tatis- 
tical modeling of syntax beyond making men- 
tion of it, leaving it instead for future work. In- 
stead we focus on the nature of the forest repre- 
sentation itself and describe ageneral algorithm 
for ranking alternative trees that can be used 
with any language model. 
A forest representation corresponding to the 
lattice in Figure 1 is shown in Figure 3. This 
forest structure is an AND-OR graph, where the 
AND nodes represent sequences ofphrases, and 
the OR nodes represent mutually exclusive al- 
ternate phrasings for a particular elative po- 
sition in the sentence. For example, at the top 
level of the forest, node S.469 encodes the choice 
between active and passive voice versions of the 
sentence. The active voice version is the left 
child node, labelled S.328, and the passive voice 
version is the right child node, S.358. There 
are eight OR-nodes in the forest, corresponding 
to the eight distinct decisions mentioned earlier 
that need to be made in deciding the best sen- 
tence to output. 
The nodes are uniquely numbered, so that re- 
peated references to the same node can be iden- 
tified as such. In the forest diagram, only the 
first (left-most) reference to a node is drawn 
completely. Subsequent references only show 
the node name written in italics. This eases 
readability and clarifies which portions of the 
forest actually need to have scores computed 
during the ranking process. Nodes N.275, 
NP.318, VP.225 and PRP.3 are repeated in the 
forest of Figure 3. 
S.469 ~ S.328 
S.469 ==~ S.358 
S.328 ~ PRP.3 VP.327 
PRP.3 ~ "you" 
VP.327 ==ez VP.248 NP.318 
S.358 ~ NP.318 VP.357 
NP.318 ~ NP.317 
NP.318 ~ N.275 
Figure 2: Internal representation f top nodes in 
forest 
Figure 2 illustrates how the forest is repre- 
sented internally, showing context-free r write 
rules for some of the top nodes in the forest. 
OR-nodes are indicated by the same label oc- 
curing more than once on the left-hand side of a 
rule. This sample of rules includes an example 
of multiple references to a node, namely node 
NP.318, which occurs on the right-hand side of 
two different rules. 
A generation forest differs from a parse forest 
in that a parse forest represents different pos- 
sible hierarchicM structures that cover a single 
phrase. Meanwhile a generation forest gener- 
ally represents one (or only a few) heirarchi- 
cal structures for a given phrase, but represents 
many different phrases that generally express 
the same meaning. 
2.3 Prev ious work on packed 
generat ion trees 
There has been previous work on developing 
a representation for a packed generation forest 
structure. Shemtov (1996) describes extensions 
to a chart structure for generation originally 
presented in (Kay, 1996) that is used to gen- 
erate multiple paraphrases from a semantic in- 
put. A prominent aspect of the representation 
is the use of boolean vector expressions to asso- 
ciate each sub-forest with the portions of the in- 
put that it covers and to control the unification- 
based generation process. A primary goM of the 
representation is to guarantee that each part of 
the semantic input is expressed once and only 
once in each possible output phrase. 
In contrast, the packed forest in this paper 
keeps the association between the semantic in- 
put and nodes in the forest separate from the 
forest representation itself. (In our system, 
these mappings are maintained via an external 
cache mechanism as described in (Langkilde and 
Knight, 1998)). Once-and-only-once coverage of 
the semantic input is implicit, and is achieved 
by the process that maps from the input to a 
forest. 
3 Forest  rank ing  a lgor i thm 
The algorithm proposed here for ranking sen- 
tences in a forest is a bottom-up dynamic pro- 
gramming algorithm. It is analogous to a 
chart parser, but performs an inverse compari- 
son. Rather than comparing alternate syntactic 
structures indexed to the same positions of an 
173 
7 
/t 71 
\ / \  ,- 
tit .~ ~=-~ \ / \ />  ,;-. 
} 
i g - ~ 
} 
? ~ -~ 
- -~-~. 
Figure 3: A generation forest 
174 
input sentence, it compares alternate phrases 
corresponding to the same semantic input. 
As in a probabilistic hart parser, the key 
insight of this algorithm is that the score for 
each of the phrases represented by a particu- 
lar node in the forest can be decomposed into 
a context-independent (i ternal) score, and a 
context-dependent (external) score. The inter- 
nal score, once computed, is stored with the 
phrase, while the external score is computed in 
combination with other sibling nodes. 
In general, the internal score for a phrase as- 
sociated with a node p can be defined recur- 
sively as: 
I(p) = 1-Ij=lJ I(cj) ? E(cjJcontext(cl..Cj_l) ) 
where I stands for the internal score, E the ex- 
ternal score, and cj for a child node of p. The 
specific formulation of I and E, and the pre- 
cise definition of the context depends on the lan- 
guage model being used. As an example, in a 
bigram model, I I=1 for leaf nodes, and E can 
be expressed as: 
E = P(E i rstWord(e j ) lLastWord(c j_ l )  ) 
Depending on the language model being used, 
a phrase will have a set of externally-relevant 
features. These features are the aspects of the 
phrase that contribute to the context-dependent 
scores of sibling phrases. In the case of the bi- 
gram model, the features are the first and last 
words of the phrase. In a trigram model it is the 
first and last two words. In more elaborate lan- 
guage models, features might include elements 
such as head word, part-of-speech tag, constitu- 
tent category, etc. 
A crucial advantage of the forest-based 
method is that at each node only the best in- 
ternally scoring phrase for each unique combi- 
nation of externally relevant features needs to 
be maintained. The rest can be pruned with- 
out sacrificing the guarantee of obtaining the 
overall optimal solution. This pruning reduces 
exponentially the total number of phrases that 
need to be considered. In effect, the ranking 
IA bigram model is based on conditional probabil- 
ities, where the likelihood of each word in a phrase is 
assumed to depend on only the immediately previous 
word. The likelihood of a whole phrase is the product of 
the conditional probabilities of each of the words in the 
phrase. 
VP.344 ~ VP.225 TO.341 VB.342 VBN.330 
225: 341: 342: 330: 
might have 
may have 
could have 
might be required 
may be required 
could be required 
might be having 
may be having 
could be having 
might be obliged 
may be obliged 
could be obliged 
to be eaten 
344: 
might ... eaten 
may ... eaten 
could ... eaten 
Figure 4: Pruning phrases from a forest node, 
assuming a bigram model 
algorithm exploits the independence that exists 
between most disjunctions in the forest. 
To illustrate this, Figure 4 shows an exam- 
ple of how phrases in a node are pruned, as- 
suming a bigram model. The rule for node 
VP.344 in the forest of Figure 3 is shown, to- 
gether with the phrases corresponding to each 
of the child nodes. If every possible com- 
bination of phrases is considered for the se- 
quence of nodes on the right-hand side, there 
are three unique first words, namely "might", 
"may" and "could", and only one unique final 
word, "eaten". Given that only the first and 
last words of a phrase are externally relevant 
features in a bigram model, only the three best 
scoring phrases (out of the 12 total) need to 
be maintained for node VP.344--one for each 
unique first-word and last-word pair. The other 
nine phrases can never be ranked higher, no 
matter what constituents VP.344 later combines 
with. 
Pseudocode for the ranking algorithm is 
shown below. "Node" is assumed to be 
a record composed at least of an array of 
child nodes, "Node->c\[1..N\]," and best-ranked 
phrases, "Node->p\[1..M\]." The function Con- 
catAndScore concatenates two strings together, 
and computes a new score for it based on the 
formula given above. The function Prune guar- 
175 
antees that only the best phrase for each unique 
set of features values is maintained. The core 
loop in the algorithm considers the children of 
the node one-by-one, concatenating and scoring 
the phrases of the first two children and prun- 
ing the results, before considering the phrases 
of the third child, and concatenating them with 
the intermediate results, and so on. From the 
pseudocode, it can be seen that the complex- 
ity of the algorithm is dominated by the num- 
ber of phrases associated with a node (not the 
number of rules used to represent he forest, 
nor the number of children in a an AND node). 
More specifically, because of the pruning, it de- 
pends on the number of features associated with 
the language model, and the average number of 
unique combinations of feature values that are 
seen. If f is the number of features, v the av- 
erage number of unique values seen in a node 
for each feature, and N the number of N best 
being maintained for each unique set of fea- 
ture values (but not a cap on the number of 
phrases), then the algorithm has the complex- 
ity O((vN) 2/) (assuming that children of AND 
nodes are concatenated in pairs). Note that f=2 
for the bigram model, and f=4 for the trigram 
model. 
In comparison, the complexity of an exhaus- 
RankForest(Node) 
{ 
if ( Leafp(Node)) LeafScore( Node); 
fo r j= l to J  { 
if ( not(ranked?(Node->e\[j\]))) 
RankForest(Node- > c\[j\]); 
} 
for m=l  to NumberOfPhrasesIn(Node->c\[1\]) 
Node->p\[m\] = (Node->c\[1\])->p\[m\]; 
k=ffpr j=2 to J { 
for m=l  to NumberOfPhrasesIn(Node) 
for n=l  to NumberOfPhrasesIn( 
Node->c\[j\]) 
temp\[k++\] = ConcatAndScore( 
Node->p\[m\], 
(Node- >c\[j\])- >Pin\]); 
Prune( temp); 
for m=l  to NumberOfPhrasesIn(temp) 
Node->p\[m\] = (temp\[m\]); 
} 
tive search algorithm on a lattice is O((vN)~), 
where l is approximately the length of the 
longest sentence in the lattice. The forest-based 
algorithm thus offers an exponential reduction 
in complexity while still guaranteeing an opti- 
mal solution. A capped N-best heuristic search 
algorithm on the other hand has complexity 
O(vN1). However, as mentioned earlier, it typ- 
ically fails to find the optimal solution with 
longer sentences. 
In conclusion, the tables in Figure 5 and Fig- 
ure 6 show experimental results comparing a 
forest representation to a lattice in terms of the 
time and space used to rank sentences. These 
results were generated from 15 test set inputs, 
whose average sentence length ranged from 14 
to 36 words. They were ranked using a bigram 
model. The experiments were run on a Sparc 
Ultra 2 machine. Note that the time results for 
the lattice are not quite directly comparable to 
those for a forest because they include overhead 
costs for loading portions of a hash table. It was 
not possible to obtain timing measurements for
the search algorithm alone. We estimate that 
roughly 80% of the time used in processing the 
lattice was used for search alone. Instead, the 
results in Figure 5 should be interpreted as a 
comparison between different kinds of systems. 
In that respect, it can be observed from Ta- 
ble 5 that the forest ranking program performs 
at least 3 or 4 seconds faster, and that the time 
needed does not grow linearly with the num- 
ber of paths being considered as it does with 
the lattice program. Instead it remains fairly 
constant. This is consistent with the theoreti- 
cal result that the forest-based algorithm does 
not depend on sentence length, but only on the 
number of different alternatives being consid- 
ered at each position in the sentence. 
From Table 6 it can be observed that when 
there are a relatively moderate number of sen- 
tences being ranked, the forest and the lattice 
are fairly comparable in their space consump- 
tion. The forest has a little extra overhead in 
representing hierarchical structure. However, 
the space requirements of a forest do not grow 
linearly with the number of paths, as do those 
of the lattice. Thus, with very large numbers 
of paths, the forest offers significant savings in 
space. 
The spike in the graphs deserves particular 
176 
comment. Our current system for producing 2so~ 
forests from semantic inputs generally produces 
OR-nodes with about two branches. The par- 20o00o 
ticular input that triggered the spike produced 
a forest where some high-level OR-nodes had a 
much larger number of branches. In a lattice, 150~o 
any increase in the number of branches expo- 
nentially increases the processing time and stor- 
age space requirements. However, in the forest ,000oo 
representation, the increase is only polynomial 
with the number of branches, and thus did not ~o 
produce a spike. 
IO0  , ? , ? , ? , ? , ? , 
90 "latt;,'e" 
" fo res t "  ---x---  
SO 
70 
60 
5O 
40 
3O 
2O 
10 
. . . . .  -x 
00000 . . . . . . . . . . .  10+06 10+08 10+10 10+12 10+14 10+16 le+18 lo+20 
Figure 5: Time required for the ranking pro- 
cess using a lattice versus a forest representa- 
tion. The X-axis is the number of paths (loglo 
scale), and the Y-axis is the time in seconds. 
4 Future  Work  
The forest representation a d ranking algorithm 
have been implemented as part of the Nitro- 
gen generator system. The results shown in 
the previous section illustrate the time and 
space advantages of the forest representation 
which make calculating the mathematically op- 
timal sentence in the forest feasible (particularly 
for longer sentences). However, obtaining the 
mathematically optimal sentence is only valu- 
able if the mathematical model itself provides 
a good fit. Since a forest representation makes 
it possible to add syntactic information to the 
mathematical model, the next question to ask 
is whether such a model can provide a better 
fit for natural English than the ngram models 
we have used previously. In future work, we 
plan to modify the forests our system produces 
~orest"  -*-x- -- 
10000 le+06 le+08 le+10 le+12 le+14 Ie+16 le+18 le+20 
Figure 6: Size of the data structure for a lattice 
versus a forest representation. The X-axis is the 
number of paths (log~o scale), and the Y-axis is 
the size in bytes. 
so they conform to the Penn Treebank corpus 
(Marcus et al, 1993) annotation style, and then 
do experiments using models built with Tree- 
bank data. 
5 Acknowledgments  
Special thanks go to Kevin Knight, Daniel 
Marcu, and the anonymous reviewers for their 
comments. This research was supported in part 
by NSF Award 9820291. 
Re ferences  
M. Kay. 1996. Chart generation. In Proc. ACL. 
K. Knight and V. Hatzivassiloglou. 1995. Two- 
level, many-paths generation. In Proc. A CL. 
I. Langkilde and K. Knight. 1998. Generation 
that exploits corpus-based statistical knowl- 
edge. In Proc. COLING-ACL. 
M. Marcus, B. Santorini, and M. Marcinkiewicz. 
1993. Building a large annotated corpus of 
english: the Penn treebank. Computational 
Linguistics, 19(2). 
H. Shemtov. 1996. Generation of paraphrases 
from ambiguous logical forms. In Coling'96. 
A. Stolcke. 1997. Linguistic knowledge and 
empirical methods in speech recognition. AI 
Magazine, 18(4):25-31. 
177 
Learning to Predict Problematic Situations in a Spoken Dialogue 
System: Experiments with How May I Help You? 
Mar i lyn  Walker ,  I rene  Langk i lde ,  Je r ry  Wr ight ,  A l ien  Gor in ,  D iane  L i tman 
AT&T Labs- -Research 
180 Park Avenue 
F lorham Park, NJ 07932-0971 USA 
walker, jwright, algor, diane@research, art. corn, ilangkil@isi, edu 
Abst rac t  
Current spoken dialogue systems are deficient in 
their strategies for preventing, identifying and re- 
pairing problems that arise in the conversation. This 
paper reports results on learning to automatically 
identify and predict problematic human-computer 
dialogues in a corpus of 4774 dialogues collected with 
the How May I Help You spoken dialogue system. 
Our expectation is that the ability to predict prob- 
lematic dialogues will allow the system's dialogue 
manager to modify its behavior to repair problems, 
and even perhaps, to prevent them. We train a 
problematic dialogue classifier using automatically- 
obtainable features that can identify problematic 
dialogues ignificantly better (23%) than the base- 
line. A classifier trained with only automatic fea- 
tures from the first exchange in the dialogue can 
predict problematic dialogues 7% more accurately 
than the baseline, and one trained with automatic 
features from the first two exchanges can perform 
14% better than the baseline. 
1 In t roduct ion  
Spoken dialogue systems promise fficient and nat- 
ural access to a large variety of information sources 
and services from any phone. Systems that sup- 
port short utterances to select a particular function 
(through a statement such as "Say credit card, col- 
lect or person-to-person") are saving companies mil- 
lions of dollars. Research prototypes exist for appli- 
cations uch as personal email and calendars, travel 
and restaurant information, and personal banking 
(Baggia et al, 1998; Walker et al, 1998; Seneff et 
al., 1995; Sanderman et al, 1998; Chu-Carroll and 
Carpenter, 1999) inter alia. Yet there are still many 
research challenges: current systems are limited in 
the interaction they support and brittle in many re- 
spects. We show how spoken dialogue systems can 
learn to support more natural interaction on the ba- 
sis of their previous experience. 
One way that current spoken dialogue systems are 
quite limited is in their strategies for detecting and 
repairing problems that arise in conversation. If 
a problem can be detected, the system can either 
transfer the call to a human operator or modify its 
dialogue strategy in an attempt to repair the prob- 
lem. We can train systems to improve their ability to 
detect problems by exploiting dialogues collected in 
interactions with human users. The initial segments 
of these dialogues can be used to predict hat a prob- 
lem is likely to occur. We expect hat the ability to 
predict that a dialogue is likely to be problematic 
will allow the system's dialogue manager to apply 
more sophisticated strategies to repairing problems, 
and even perhaps, to prevent hem. 
This paper reports experiments on predicting 
problems in spoken dialogue interaction by train- 
ing a problematic dialogue predictor on a corpus of 
4774 dialogues collected in an experimental trial of 
AT~;T's How May I Help You (HMIHY) spoken dia- 
logue system (Gorin et al, 1997; Riccardi and Gorin, 
to appear; E. Ammicht and Alonso, 1999). In this 
trial, the HMIHY system was installed at an AT&T 
customer care center. HMIHY answered calls from 
live customer traffic and successfully automated a 
large number of customer requests. An example of 
a dialogue that HMIHY completed successfully is
shown in Figure 13 
St: AT&T How may I help you? 
UI: I need to \[ uh \] put a call on my calling card please 
$2: May I have your card number, please? 
U2:765432 10987654 
$3: What number would you like to call? 
U3:8 1 4 7 7 7 6 6 6 6 (misrecognized) 
$4: May I have that number again? 
U4:8147776666 
$5: Thank you. 
Figure 1: Sample TASKSUCCESS Dialogue 
We shall refer to the dialogues with a TASKSUC- 
CESS outcome, in which HMIHY successfully auto- 
mates the customer's call, as the TASKSUCCESS dia- 
logues. In addition to the TASKSUCCESS dialogues, 
there are several other call outcomes, to be described 
in detail below, which we consider problematic. 
tThe phone numbers, card numbers, and pin numbers in 
the sample dialogues are artificial. 
210 
This paper reports results from a set of experi- 
ments that test whether we can learn to automat- 
ically predict that a dialogue will be problematic 
on the basis of information the system has: (1) 
early on in the dialogue; and (2) in real time. We 
train an automatic lassifer for predicting problem- 
atic dialogues from features that can be automat- 
ically extracted from the HMIHY corpus. The re- 
sults show that we can learn to predict problematic 
dialogues using fully automatic features with an ac- 
curacy ranging from 72% to 87%, depending on how 
much of the dialogue the system has seen so far. 
Section 2 describes HMIHY and the dialogue corpus 
which the experiments are based on. Section 3 de- 
tails the encoding of the dialogues and the methods 
used for utilizing the machine learning program RIP- 
PER to train an automatic problematic dialogue pre- 
dictor (Cohen, 1996). Section 4 presents the results 
and section 5 summarizes the paper and describes 
future work. 
2 Exper imenta l  Sys tem and Data  
HMIHY is a spoken dialogue system based on the no- 
tion of call routing (Gorin et al, 1997; Chu-Carroll 
and Carpenter, 1999). In the HMIHY call rout- 
ing system, services that the user can access are 
classified into 14 categories, plus a category called 
other for calls that cannot be automated and must 
be transferred to a human operator (Gorin et al, 
1997). ~ Each category describes a different task, 
such as person-to-person dialing, or receiving credit 
for a misdialed number. The system determines 
which task the caller is requesting on the basis of 
its understanding of the cMler's response to the 
open-ended system greeting A T~ T, How May I Help 
You?. Once the task has been determined, the infor- 
mation needed for completing the caller's request is 
obtained using dialogue submodules that are specific 
for each task (Abella and Gorin, 1999). 
In addition to the TASKSUCCESS dialogues in 
which HMIHY successfully automates the cus- 
tomer's call, illustrated in Figure 1, and the calls 
that are transferred to a human operator, there are 
three other possible outcomes for a call, all of which 
are problematic. The first category, which we call 
HANGUP, results from a customer's decision to hang 
up on the system. A sample HANGUP dialogue is 
in Figure 2. A caller may hang up because s/he is 
frustrated with the system; our goal is to learn from 
the corpus which system behaviors led to the caller's 
frustration. 
The second problematic ategory (WIZARD), re- 
suits from a human customer care agent's decision to 
take over the call from the system. Because HMIHY 
is experimental, each call was monitored by a human 
2 One potential use of our results is to provide better ules 
for making the transfer decision. 
SI: AT&T How may I help you? 
UI: I need credit please. 
$2: Okay. What is the reason for the credit? 
U2: Miss, uh, Miss, different area code than I needed. 
$3: Sorry. I need to know whether you need credit for 
a wrong number, bad connection or a call that was cut  
off. 
U3: It is a wrong number. (impatient humming) 
$4: What was the number that you dialed? 
USER HANGS UP 
Figure 2: Sample HANGUP Dialogue 
agent serving as a wizard who could override the 
system. There were a number of agents who partici- 
pated as wizards during the trial of HMIHY and each 
wizard was simply told to take over the call if s/he 
perceived problems with the system's performance. 
The wizard's decision was logged by the experimen- 
tal setup, resulting in labelling the call as one that 
the wizard took over. s A dialogue where the wizard 
decided that the dialogue was problematic and took 
over the call is shown in Figure 3. 
Sh AT&T How may I help you? 
Uh (silence) 
$2: Sorry. Please briefly tell me how I may  help you? 
U2: I'm trying to call 1 8 hundred call A T T. 
$3: Do you want to place a call? 
U3: Through my calling card. 
$4: May I have your card number, please? 
U4: It's 8 7 6 5 4 3 2 1 0 and then my pin number is 8 
7 6 5. (misrecognized) 
$5: Sorry. Please enter or say your card number again.  
WIZARD STEPS IN 
Figure 3: Sample WIZARD Dialogue 
The third problematic category, the TASKFAILURE 
dialogues, are cases where the system completed the 
call, but carried out a task that was not the task 
that the customer was actually requesting. An ex- 
ample TASKFAILURE dialogue is given in Figure 4: 
HMIHY interpreted utterance U2 as a request to 
make a third-party call e.g. to bill it to my home 
phone. HMIHY then asked the caller for the infor- 
mation it needed to carry out this task, the caller 
complied, and the system completed the call. 
The corpus of 4774 dialogues used in our exper- 
iments was collected in severM experimental trials 
of HMIHY on live customer traffic (Pdccardi and 
Gorin, to appear; E. Ammicht and Alonso, 1999), 
and is referred to as HM2 in (Riccardi and Gorin, to 
appear)). During the trial, all of the system behav- 
iors were automatically recorded in a log file, and 
later the dialogues were transcribed by humans and 
labelled with a semantic ategory representing the 
sOf  course we can only infer what might have mot ivated 
the wizard to take over the call, but we assume that the wizard 
had good reason for doing so. 
211 
SI: AT&T How may I help you? 
UI: (silence) 
$2: Sorry. Please briefly tell me how I may help you? 
U2: I wanta find out how much my bill's worth. 
$3: What phone number would you like the call billed 
to? 
U3: Urn the access number. 
$4: Sorry. Could I have that phone number again? 
U4:18hundred2255288.  
$5: What number would you like to call? 
U5:800 225 5288 (touchtone input) 
$6: Thank you. 
Figure 4: Sample TASKFAILURE Dialogue 
task that the caller was asking HMIHY to perform, 
on a per utterance basis. The logfiles also included 
labels indicating whether the wizard had taken over 
the call or the user had hung up. 
3 T ra in ing  an  Automat ic  
P rob lemat ic  D ia logue  Pred ic tor  
Our experiments apply the machine learning pro- 
gram RIPPER (Cohen, 1996) to automatically induce 
a "problematic dialogue" classification model. RIP- 
PER takes as input the names of a set of classes to 
be learned, the names and ranges of values of a fixed 
set of features, and training data specifying the class 
and feature values for each example in a training set. 
Its output is a classification model for predicting the 
class of future examples. In RIPPER, the classifica- 
tion model is learned using greedy search guided by 
an information gain metric, and is expressed as an 
ordered set of if-then rules. 
To apply RIPPER, the dialogues in the corpus must 
be encoded in terms of a set of classes (the output 
classification) and a set of input features that are 
used as predictors for the classes. We start with the 
dialogue categories described above, but since our 
goal is to develop algorithms that predict/identify 
problematic dialogues, we treat HANGUP, WIZARD 
and TASKFAILURE as equivalently problematic. Thus 
we train the classifier to distinguish between two 
classes: TASKSUCCESS and PROBLEMATIC. Note that 
our categorization is inherently noisy because we do 
not know the real reasons why a caller hangs up or a 
wizard takes over the call. The caller may hang up 
because she is frustrated with the system, or she may 
simply dislike automation, or her child may have 
started crying. Similarly, one wizard may have low 
confidence in the system's ability to recover from er- 
rors and use a conservative approach that results in 
taking over many calls, while another wizard may be 
more willing to let the system try to recover. Nev- 
ertheless we take these human actions as a human 
labelling of these calls as problematic. Given this 
classification, approximately 36% of the calls in the 
corpus of 4774 dialogues are PROBLEMATIC and 64% 
are TASKSUCCESS. 
Next, we encoded each dialogue in terms of a set 
of 196 features that were either automatically ogged 
by one of the system modules, hand-labelled by hu- 
mans, or derived from raw features. We use the 
hand-labelled features to produce a TOPLINE, an es- 
timation of how well a classifier could do that had 
access to perfect information. The entire feature set 
is summarized in Figure 5. 
? Acoust ic /ASR Features 
- recog, recog-numwords, ASR-duration, dtmf- 
flag, rg-modality, rg-grammar 
? NLU Features 
- a confidence measure for all of the possible 
tasks that the user could be trying to do 
- salience-coverage, inconsistency, context-shift, 
top-task, nexttop-task, top-confidence, dill- 
confidence 
? D ia logue  Manager  Features  
- sys-label, utt-id, prompt, reprompt, confirma- 
tion, subdial 
- running tallies: num-reprompts, num- 
confirms, num-subdials, reprompt%, confir- 
mation%, subdialogue% 
? Hand-Labe l led  Features  
- tscript, human-label, age, gender, user- 
modality, clean-tscript, cltscript-numwords, 
rsuccess 
? Whole-Dialogue Features 
num-utts, num-reprompts, percent-reprompts, 
num-confirms, percent-confirms, num- 
subdials, percent-subdials, dial-duration. 
Figure 5: Features for spoken dialogues. 
There are 8 features that describe the whole dia- 
logue, and 47 features for each of the first four ex- 
changes. We encode features for the first four ex- 
changes because we want to predict failures before 
they happen. Since 97% of the dialogues in our cor- 
pus are five exchanges or less, in most cases, any 
potential problematic outcome will have occurred 
by the time the system has participated in five ex- 
changes. Because the system needs to be able to 
predict whether the dialogue will be problematic us- 
ing information it has available in the initial part of 
the dialogue, we train classifiers that only have ac- 
cess to input features from exchange 1, or only the 
features from exchange 1 and exchange 2. To see 
whether our results generalize, we also experiment 
with a subset of features that are task-independent. 
We compare results for predicting problematic din- 
212 
logues, with results for identifying problematic di- 
alogues, when the classifier has access to features 
representing the whole dialogue. 
We utilized features logged by the system because 
they are produced automatically, and thus could be 
used during runtime to alter the course of the dia- 
logue. The system modules that we collected infor- 
mation from were the acoustic processer/automatic 
speech recognizer (ASR) (Riccardi and Gorin, to ap- 
pear), the natural anguage understanding (NLU) 
module (Gorin et al, 1997), and the dialogue man- 
ager (DM) (Abella and Gorin, 1999). Below we de- 
scribe each module and the features obtained from 
it. 
ASR takes as input the acoustic signal and 
outputs a potentially errorful transcription of what 
it believes the caller said. The ASR features for 
each of the first four exchanges were the output 
of the speech recognizer (recog), the number of 
words in the recognizer output (recog-numwords), 
the duration in seconds of the input to the 
recognizer (asr-duration), a flag for touchtone 
input (dtmf-flag), the input modality expected 
by the recognizer (rg-modality) (one of: none, 
speech, touchtone, speech+touchtone, touchtone- 
card, speech+touchtone-card, touchtone-date, 
speech+touchtone-date, or none-final-prompt), and 
the grammar used by the recognizer (rg-grammar). 
The motivation for the ASR features is that any 
one of them may have impacted performance. For 
example, it is well known that longer utterances 
are less likely to be recognized correctly, thus asr- 
duration could be a clue to incorrect recognition re- 
suits. In addition, the larger the grammar is, the 
more likely an ASR error is, so the name of the 
grammar vg-grammar could be a predictor of incor- 
rect recognition. 
The natural language understanding (NLU) mod- 
ule takes as input a transcription ofthe user's utter- 
ance from ASR and produces 15 confidence scores 
representing the likelihood that the caller's task is 
one of the 15 task types. It also extracts other 
relevant information, such as phone or credit card 
numbers. Thus 15 of the NLU features for each ex- 
change represent the 15 confidence scores. There 
are also features that the NLU module calculates 
based on processing the utterance. These include 
an intra-utterance measure of the inconsistency be- 
tween tasks that the user appears to be requesting 
(inconsistency), a measure of the coverage of the 
utterance by salient grammar fragments (salience- 
coverage), a measure of the shift in context between 
utterances (context-shift), he task with the highest 
confidence score (top-task), the task with the second 
highest confidence score (nexttop-task), the value of 
the highest confidence score (top-confidence), and 
the difference in values between the top and next- 
to-top confidence scores (diff-confidence). 
The motivation for these NLU features i  to make 
use of information that the NLU module has based 
on processing the output of ASR and the current dis- 
course context. For example, for utterances that fol- 
low the first utterance, the NLU module knows what 
task it believes the caller is trying to complete. If it 
appears that the caller has changed her mind, then 
the NLU module may have misunderstood a previ- 
ous utterance. The context-shift feature indicates 
the NLU module's belief that it may have made an 
error (or be making one now). 
The dialogue manager (DM) takes the output of 
NLU and the dialogue history and decides what it 
should say to the caller next. It decides whether it 
believes there is a single unambiguous task that the 
user is trying to accomplish, and how to resolve any 
ambiguity. The DM features for each of the first four 
exchanges are the task-type label which includes a 
label that indicates task ambiguity (sys-label), utter- 
ance id within the dialogue (implicit in the encod- 
ing), the name of the prompt played before the user 
utterance (prompt), and whether that prompt was a 
reprompt (reprompt), a confirmation (confirm), or a 
subdialogue prompt (subdia O, a superset of the re- 
prompts and confirmation prompts. 
The DM features are primarily motivated by pre- 
vious work. The task-type label feature is to cap- 
ture the fact that some tasks may be harder than 
others. The utterance id feature is motivated by the 
idea that the length of the dialogue may be impor- 
tant, possibly in combination with other features like 
task-type. The different prompt features for initial 
prompts, reprompts, confirmation prompts and sub- 
dialogue prompts are motivated by results indicating 
that reprompts and confirmation prompts are frus- 
trating for callers and that callers are likely to hy- 
perarticulate when they have to repeat hemselves, 
which results in ASR errors (Shriberg et al, 1992; 
Levow, 1998). 
The DM features also include running tallies for 
the number of reprompts (num-reprompts), number 
of confirmation prompts (num.confirms), and num- 
ber of subdialogue prompts (num-subdials), that had 
been played up to each point in the diMogue, as well 
as running percentages (percent-reprompts, ercent- 
confirms, percent-subdials). The use of running tal- 
lies and percentages is based on the assumption that 
these features are likely to produce generalized pre- 
dictors (Litman et al, 1999). 
The features obtained via hand-labelling were hu- 
man transcripts of each user utterance (tscript), a 
set of semantic labels that are closely related to the 
system task-type labels (human-label), age (age) and 
gender (gender) of the user, the actual modality of 
the user utterance (user-modality) (one of: nothing, 
speech, touchtone, speech+touchtone, on-speech), 
213 
and a cleaned transcript with non-word noise infor- 
mation removed (clean-tscript). From these features 
we calculated two derived features. The first was the 
number of words in the cleaned transcript (cltscript 
numwords), again on the assumption that utterance 
length is strongly correlated with ASR and NLU er- 
rors. The second derived feature was based on cal- 
culating whether the human-label matches the sys- 
label from the dialogue manager (rsuccess). There 
were four values for rsuccess: rcorrect, rmismatch, 
rpartial-match and rvacuous-match, indicating re- 
spectively correct understanding, incorrect under- 
standing, partial understanding, and the fact that 
there had been no input for ASR and NLU to oper- 
ate on, either because the user didn't say anything 
or because she used touch-tone. 
The whole-dialogue f atures derived from the per- 
utterance features were: num-utts, num-reprompts, 
percent-reprampts, hum.confirms, percent-confirms, 
num-subdials, and per-cent-subdials for the whole di- 
alogue, and the duration of the entire dialogue in 
seconds (dial-duration). 
In the experiments, the features in Figure 5 except 
the Hand-Labelled features are referred to as the AU- 
TOMATIC feature set. We examine how well we can 
identify or predict problematic dialogues using these 
features, compared to the full feature set including 
the Hand-Labelled features. As mentioned earlier, 
we wish to generalize our problematic dialogue pre- 
dictor to other systems. Thus we also discuss how 
well we can predict problematic dialogues using only 
features that are both automatically acquirable dur- 
ing runtime and independent of the HMIHY task. 
The subset of features from Figure 5 that fit this 
qualification are in Figure 6. We refer to them as 
the AUTO, TASK-INDEP feature set. 
The output of each RIPPER. experiment is a clas- 
sification model learned from the training data. To 
evaluate these results, the error rates of the learned 
classification models are estimated using the resam- 
pling method of cross-validation. In 5-fold cross- 
validation, the total set of examples is randomly di- 
vided into 5 disjoint test sets, and 5 runs of the learn- 
ing program are performed. Thus, each run uses the 
examples not in the test set for training and the re- 
maining examples for testing. An estimated error 
rate is obtained by averaging the error rate on the 
testing portion of the data from each of the 5 runs. 
Since we intend to integrate the rules learned 
by RIPPER into the HMIHY system, we examine 
the precision and recall performance of specific hy- 
potheses. Because hypotheses from different cross- 
validation experiments cannot readily be combined 
together, we apply the hypothesis learned on one 
randomly selected training set (80% of the data) to 
that set's respective test data. Thus the precision 
and recall results reported below are somewhat less 
? Acoust ic /ASR Features 
- recog, recog-numwords, ASR-duration, dtmf- 
flag, rg-modality 
? NLU Features 
- salience-coverage, inconsistency, context-shift, 
top-confidence, dig-confidence 
? D ia logue  Manager  Features  
- utt-id, reprompt, confirmation, subdial 
- running tallies: num-reprompts, num- 
confirms, num-subdials, reprompt%, confir- 
mation%, subdialogue% 
Figure 6: Automatic task independent (AUTO, 
TASK-INDEP) features available at runtime. 
reliable than the error rates from cross-validation. 
4 Results 
We present results for both predicting and identi- 
fying problematic dialogues. Because we are inter- 
ested in predicting that a dialogue will be problem- 
atic at a point in the dialogue where the system can 
do something about it, we compare prediction ac- 
curacy after having only seen the first exchange of 
the diMogue with prediction accuracy after having 
seen the first two exchanges, with identification ac- 
curacy after having seen the whole dialogue. For 
each of these situations we also compare results for 
the AUTOMATIC and AUTO, TASK-INDEP feature sets 
(as described earlier), with results for the whole fea- 
ture set including hand-labelled features. Table 1 
summarizes the results. 
The baseline on the first line of Table 1 repre- 
sents the prediction accuracy from always guess- 
ing the majority class. Since 64% of the dialogues 
are TASKSUCCESS dialogues, we can achieve 64% ac- 
curacy from simply guessing TASKSUCCESS without 
having seen any of the dialogue yet. 
The first EXCHANGE 1 row shows the results of 
using the AUTOMATIC features from only the first 
exchange to predict whether the dialogue outcome 
will be TASKSUCCESS or PROBLEMATIC. The results 
show that the machine-learned classifier can predict 
problematic dialogues 8% better than the baseline 
after having seen only the first user utterance. Using 
only task-independent automatic features (Figure 6) 
the EXCHANGE 1 classifier can still do nearly as well. 
The ALL row for EXCHANGE 1 indicates that even 
if we had access to human perceptual ability (the 
hand-labelled features) we would still only be able 
to distinguish between TASKSUCCESS and PROBLEM- 
ATIC dialogues with 77% accuracy after having seen 
the first exchange. 
214 
Features Used 
BASELINE (majority class) 
EXCHANGE 1 AUTOMATIC 
AUTO, TASK-INDEP 
ALL 
EXCHANGES l&2 AUTOMATIC 
AUTO, TASK-INDEP 
ALL 
FULL DIALOGUE AUTOMATIC 
AUTO, TASK-INDEP 
TOPLINE ALL 
\]Accuracy (SE) 
64.0 % 
72.3 % 1.04 % 
71.6 % 1.05 % 
77.0 % 0.56 % 
79.9 % 0.58 % 
78.6 % 0.37 % 
86.7 % 0.33 % 
87.0 % 0.72 % 
86.7 % 0.82 % 
92.3 % 0.72 % 
Table 1: Results for predicting and identifying problematic dialogues (SE --- Standard Error) 
The EXCHANGE l&2 rows of Table 1 show the re- 
suits using features from the first two exchanges in 
the dialogue to predict he outcome of the dialogue. 4 
The additional exchange gives roughly an additional 
7% boost in predictive accuracy using either of the 
AUTOMATIC feature sets. This is only 8% less than 
the accuracy we can achieve using these features af- 
ter having seen the whole dialogue (see below). The 
ALL row for EXCHANGE l&2 shows that we could 
achieve over 86% accuracy if we had the ability to 
utilize the hand-labelled features. 
The FULL DIALOGUE row in Table 1 for AUTO- 
MATIC and AUTO, TASK-INDEP features hows the 
ability of the classifier to identify problematic dia- 
logues, rather than predict them, using features for 
the whole dialogue. The ALL row for the FULL DI- 
ALOGUE shows that we could correctly identify over 
92% of the outcomes accurately if we had the ability 
to utilize the hand-labelled features. 
Note that the task-independent automatic fea- 
tures always perform within 2% error of the auto- 
matic features, and the hand-labelled features con- 
sistently perform with accuracies ranging from 6-8% 
greater. 
The rules that RIPPER learned on the basis of the 
Exchange 1 automatic features are below. 
Exchange 1, Automat ic  Features:  
i f  (el-top-confidence _< .924) A (el-dtmf-f lag = '1') 
then  problematic, 
if (el-cliff-confidence _<.916) A (el-asr-duration > 6.92) 
then problematic, 
default is tasksuccess. 
According to these rules, a dialogue will be prob- 
lematic if the confidence score for the top-ranked 
4Since 23% of the dialogues consisted of only two ex- 
changes, we exclude the second exchange features for those 
dialogues where the second exchange consists only of the sys- 
tem playing a closing prompt. We also excluded any features 
that indicated to the classifier that the second exchange was 
the last exchange in the dialogue. 
task (given by the NLU module) is moderate or low 
and there was touchtone input in the user utterance. 
The second rule says that if the difference between 
the top confidence score and the second-ranked con- 
fidence score is moderate or low, and the duration 
of the user utterance is more than 7 seconds, predict 
PROBLEMATIC. 
The performance of these rules is summarized in
Table 2. These results show that given the first ex- 
change, this ruleset predicts that 22% of the dia- 
logues will be problematic, while 36% of them ac- 
tually will be. Of the dialogues that actually will 
be problematic, it can predict 41% of them. Once 
it predicts that a dialogue will be problematic, it is 
correct 69% of the time. As mentioned earlier, this 
reflects an overMl improvement in accuracy of 8% 
over the baseline. 
The rules learned by training on the automatic 
task-independent features for exchanges 1 and 2 are 
given below. As in the first rule set, the features that 
the classifier appears to be exploiting are primarily 
those from the ASR and NLU modules. 
Exchanges l&2, Automatic Task- 
Independent Features: 
i f  (e2-recog-numwords < 0) A (el-cliff-confidence < .95) 
then  problematic. 
if (el-salience-coverage < .889) A (e2-recog contains 
"I') A (e2-asr-duration > 7.48) then problematic. 
if (el-top-confidence < .924) A (e2-asr-duration >_ 5.36) 
A (el-asr-duration > 8.6) then problematic. 
if (e2-recog is blank) A (e2-asr-duration > 2.8) then 
problematic. 
if (el-salience-coverage < .737) A (el-recog contains 
"help") A (el-asr-duration < 7.04) then problematic. 
if (el-cliff-confidence < .924) A (el-dtmf-flag = '1') A 
(el-asr-duration < 6.68) then problematic. 
default is tasksuccess. 
The performance of this ruleset is summarized in
Table 3. These results show that, given the first 
two exchanges, this ruleset predicts that 26% of the 
215 
Class 
Success 
Problematic 
Occur red  Pred ic ted  Recal l  P rec i s ion  
64.1% 78.3 % 89.44 % 73.14 % 
35.9 % 21.7 % 41.47 % 68.78 % 
Table 2: Precision and Recall with Exchange 1 Automatic Features 
Class 
Success 
Problematic 
Occur red  Pred ic ted  Recal l  Prec is ion  
64.1% 75.3 % 91.42 % 77.81% 
35.9 % 24.7 %' 53.53 % 77.78 % 
Table 3: Precision and Recall with Exchange l&2 Automatic, Task-Independent Features 
dialogues will be problematic, while 36% of them 
actually will be. Of the problematic dialogues, it 
can predict 57% of them. Once it predicts that a 
dialogue will be problematic, it is correct 79% of 
the time. Compared with the classifier for the first 
utterance alone, this classifier has an improvement 
of 16% in recall and 10% in precision, for an overall 
improvement in accuracy of 7% over using the first 
exchange alone. 
One observation from these hypotheses i  the clas- 
sifier's preference for the asr-duration feature over 
the feature for the number of words recognized 
(recog-numwords). One would expect longer utter- 
ances to be more difficult, but the learned rulesets 
indicate that duration is a better measure of utter- 
ance length than the number of words. Another ob- 
servation is the usefulness of the NLU confidence 
scores and the NLU salience-coverage in predicting 
problematic dialogues. These features eem to pro- 
vide good general indicators of the system's uccess 
in recognition and understanding. The fact that the 
main focus of the rules is detecting ASR and NLU 
errors and that none of the DM behaviors are used 
as predictors also indicates that, in all likelihood, the 
DM is performing as well as it can, given the noisy 
input that it is getting from ASR and NLU. 
To identify potential improvements in the prob- 
lematic dialogue predictor, we analyzed which hand- 
labelled features made large performance improve- 
ments, under the assumption that future work can 
focus on developing automatic features that ap- 
proximate the information provided by these hand- 
labelled features. The analysis indicated that the 
vsuceess feature alone improves the performance of 
the TOPLINE from 88.5%, as reported in (Langkilde 
et al, 1999), to 92.3%. Using rsuccess as the only 
feature results in 73.75% accuracy for exchange 1, 
81.9% accuracy for exchanges 18z2 and 85.3% accu- 
racy for the full dialogue. In addition, for Exchanges 
l&2, the accuracy of the AUTOMATIC, TASK-INDEP 
feature set plus the rsuccess feature is 86.5%, which 
is only 0.2% less than the accuracy of ALL the lea- 
tures for Exchanges l&2 as shown in Table 1. The 
rules that RIPPER learns for Exchanges 1&52 when 
the AUTOMATIC, TASK-INDEP feature set is aug- 
mented with the single hand-labelled rsuccess fea- 
ture is shown below. 
Exchanges  1~2,  Rsuccess -b Automat ic  
Task - Independent  Features: 
ife2-salience-coverage ~ 0.651 A e2-asr-duration >_0.04 
A e2-rsuccess=Rvacuous-match then problematic, 
if e2-rsuccess=Rmismatch A el-top-confidence < 0.909 
then problematic, 
if e2-rsuccess=Rmismatch A e2-context-shift < 0.014 A 
e2-salience-coverage ~ 0.2 A e2-recog-numwords < 12 ( 
then problematic, 
if e2-rsuccess=Rmismatch ^ el-rsuccess=Rmismatch 
then problematic, 
if e2-rsuccess=Rmismatch A e2-top-confidence < 0.803 
^ e2-asr-duration >__2.68 ^  e2-asr-duration < 6.32 then 
problematic, 
if el-rsuccess=Rmismatch A el-diff-confidence > 0.83 
then problematic, 
if e2-rsuccess=Rmismatch A e2-context-shift >_ 0.54 
then problematic, 
ife2-asr-duration > 5.24 A e2-salience-coverage < 0.833 
A e2-top-confidence < 0.801 A e2-recog-numwords < 7 
A e2-asr-duration < 16.08 then problematic, 
if el-diff-confidence < 0.794 A el-asr-duration > 7.2 
A el-inconsistency > 0.024 A el-inconsistency > 0.755 
then problematic, 
default is tasksuccess 
Note that the rsuccess feature is frequently used in 
the rules and that RIPPER learns rules that combine 
the rsuccess feature with other features, such as the 
confidence, asr-duration, and salience-coverage fea- 
tures. 
5 D iscuss ion  and Future  Work  
In summary, our results show that: (1) All feature 
sets significantly improve over the baseline; (2) Us- 
ing automatic features from the whole dialogue, we 
can identify problematic dialogues 23% better than 
the baseline; (3) Just the first exchange provides ig- 
216 
nificantly better prediction (8%) than the baseline; 
(4) The second exchange provides an additional sig- 
nificant (7%) improvement, (5) A classifier based on 
task-independent automatic features performs with 
less than 1% degradation in error rate relative to 
the automatic features. Even with current accuracy 
rates, the improved ability to predict problematic 
dialogues means that it may be possible to field the 
system without human agent oversight, and we ex- 
pect to be able to improve these results. 
The research reported here is the first that we 
know of to automatically analyze a corpus of logs 
from a spoken dialogue system for the purpose of 
learning to predict problematic situations. Our work 
builds on earlier research on learning to identify di- 
alogues in which the user experienced poor speech 
recognizer performance (Litman et al, 1999). How- 
ever, that work was based on a much smaller set of 
experimental dialogues where the notion of a good or 
bad dialogue was automatically approximated rather 
than being labelled by humans. In addition, because 
that work was based on features ynthesized over the 
entire dialogues, the hypotheses that were learned 
could not be used for prediction during runtime. 
We are exploring several ways to improve the per- 
formance of and test the problematic dialogue pre- 
dictor. First, we noted above the extent to which 
the hand-labelled feature rsuccess improves classifier 
performance. In other work we report results from 
training an rsuccess classifier on a per-utterance level 
(Walker et al, 2000), where we show that we can 
achieve 85% accuracy using only fully automatic fea- 
tures. In future work we intend to use the (noisy) 
output from this classifier as input to our problem- 
atic dialogue classifier with the hope of improving 
the performance of the fully automatic feature sets. 
In addition, since it is more important o minimize 
errors in predicting PROBLEMATIC dialogues than er- 
rors in predicting TASKSUCCESS dialogues, we intend 
to experiment with RIPPER'S loss ratio parameter, 
which instructs RIPPER to achieve high accuracy for 
the PROBLEMATIC class, while potentially reducing 
overall accuracy. Finally, we plan to integrate the 
learned rulesets into the HMIHY dialogue system to 
improve the system's overall performance. 
Re ferences  
A. Abella and A.L. Gorin. 1999. Construct algebra: 
An analytical method for dialog management. In
Proc. of the Association for Computational Lin- 
guistics. 
P. Baggia, G. Castagneri, and M. Danieli. 1998. 
Field trials of the Italian Arise Train Timetable 
System. In Interactive Voice Technology for 
Telecommunications Applications, IVTTA, pages 
97-102. 
J. Chu-Carroll and R. Carpenter. 1999. Vector- 
based natural language call routing. Computa- 
tional Linguistics, 25-3:361-387. 
W. Cohen. 1996. Learning trees and rules with set- 
valued features. In l~th Conference of the Amer- 
ican Association of Artificial Intelligence, AAAI. 
A.L. Gorin E. Ammicht and T. Alonso. 1999. 
Knowledge collection for natural anguage spoken 
dialog systems. In Proc. of EUROSPEECH 99. 
A.L. Gorin, G. Riccardi, and J.H. Wright. 1997. 
How may I Help You? Speech Communication, 
23:113-127. 
I. Langkilde, M. Walker, J. Wright, A. Gorin, and 
D. Litman. 1999. Automatic prediction of prob- 
lematic human-computer dialogues in How May 
I Help You? In Proc. IEEE Workshop on Auto- 
matic Speech Recognition and Understanding. 
G. A. Levow. 1998. Characterizing and recogniz- 
ing spoken corrections in human-computer dia- 
logue. In Proc. of the 36th Annual Meeting of the 
Association of Computational Linguistics, COL- 
ING/ACL 98, pages 736-742. 
D. J. Litman, M. A. Walker, and M. J. Kearns. 1999. 
Automatic detection of poor speech recognition at 
the dialogue level. In Proc. of the 37th Annual 
Meeting of the Association of Computational Lin- 
guistics, ACL99, pages 309-316. 
G. Riccardi and A.L. Gorin. to appear. Spoken lan- 
guage adaptation over time and state in a natu- 
ral spoken dialog system. IEEE Transactions on 
Speech and Audio. 
A. Sanderman, J. Sturm, E. den Os, L. Bores, and 
A. Cremers. 1998. Evaluation of the Dutch Train 
Timetable Information System developed in the 
ARISE project. In Interactive Voice Technology 
for Telecommunications Applications, pages 91- 
96. 
S. Seneff, V. Zue, J. Polifroni, C. Pao, L. Hethering- 
ton, D. Goddeau, and J. Glass. 1995. The pre- 
liminary development of a displayless PEGASUS 
system. In ARPA SLT Workshop. 
E. Shriberg, E. Wade, and P. Price. 1992. Human- 
machine problem solving using spoken language 
systems (SLS): Factors affecting performance and 
user satisfaction. In Proc. of the DARPA Speech 
and NL Workshop, pages 49-54. 
M. A. Walker, J. C. Fromer, and S. Narayanan. 
1998. Learning optimal dialogue strategies: A 
ease study of a spoken dialogue agent for email. 
In Proc. of the 36th Annual Meeting of the 
Association of Computational Linguistics, COL- 
ING/ACL 98, pages 1345-1352. 
M. Walker, I. Langkilde, and J. Wright. 2000. Us- 
ing NLP and Discourse features to identify under- 
standing errors in the How May I Help You spoken 
dialogue system. In Submission. 
217 
Proceedings of the NAACL HLT Workshop on Integer Linear Programming for Natural Language Processing, pages 36?37,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
A Constraint Programming Approach to Probabilistic Syntactic Processing
Irene Langkilde-Geary
Independent Consultant
South Jordan, UT USA
i.l.geary@gmail.com
1 Introduction
Integer linear programming (ILP) is a framework
for solving combinatorial problems with linear con-
straints of the form y = c1x1 + c2x2 + ... + cnxn
where the variables (ie., y and xis) take on only in-
teger values. ILP is a special case of a larger fam-
ily of contraint-based solving techniques in which
variables may take on additional types of values (eg.
discrete, symbolic, real, set, and structured) or in-
volve additional kinds of constraints (eg. logical
and non-linear, such as x ? y ? z and y = cxn).
Constraint-based problem solving approaches offer
a more natural way of modeling many kinds of real-
world problems. Furthermore, the declarative nature
of constraint-based approaches makes them versatile
since the order in which the variables are solved is
not predetermined. The same program can thus be
reused for solving different subsets of the problem?s
variables. Additionally, in some cases, constraint-
based approaches can solve problems more effi-
ciently or accurately than alternative approaches.
Constraint Programming (CP) is a field of re-
search that develops algorithms and tools for
constraint-based problem solving. This abstract de-
scribes work-in-progress on a project to develop
a CP-based general-purpose broad-coverage prob-
abilistic syntactic language processing system for
English. Because of its declarative nature, the sys-
tem can be used for both parsing and realization as
well as their subtasks (such as tagging, chunk pars-
ing, lexical choice, or word ordering) or hybridiza-
tions (like text-to-text generation). We expect this
tool to be useful for a wide range of applications
from information extraction to machine translation
to human-computer dialog. An ambitious project
such as this poses a number of questions and difficult
challenges, including: a) how to declaratively repre-
sent the syntactic structure of sentences, b) how to
integrate the processing of hard constraints with soft
(probabilistic) ones, c) how to overcome problems
of intractibility associated with large problems and
rich representations in learning, inference, as well
as search.
2 Related Work
Declarative and constraint-based representations
and computation mechanisms have been the subject
of much research in the fields of both Linguistics
and Computer Science over the last 30-40 years,
at times motivating each other but also sometimes
developing independently. Although there is quite
a large literature on constraint-based processing in
NLP, the notion of a constraint and the methods for
processing them vary significantly from that in CP.
See (Duchier et al, 1998; Piwek and van Deemter,
2006; Blache, 2000). The CP approach has been
designed for a broader ranger of applications and
rests on a stronger, more general theoretical foun-
dation. It coherently integrates a variety of solving
techniques whereas theoretical linguistic formalisms
have traditionally used only a single kind of con-
straint solver, namely unification. In comparison,
the 2009 ILPNLP workshop focuses on NLP pro-
cessing using solely integer linear constraints.
36
3 Methodology
Three key elements of our approach are its syntactic
representation, confidence-based beam search, and a
novel on-demand learning and inference algorithm.
The last is used to calculate probability-based fea-
ture costs and the confidences used to heuristically
guide the search for the best solution. A description
of the flat featurized dependency-style syntactic rep-
resentation we use is available in (Langkilde-Geary
and Betteridge, 2006), which describes how the en-
tire Penn Treebank (Marcus et al, 1993) was con-
verted to this representation. The representation has
been designed to offer finer-grained declarativeness
than other existing representations.
Our confidence-based search heuristic evaluates
the conditional likelihood of undetermined output
variables (ie., word features) at each step of search
and heuristically selects the case of the mostly likely
variable/value pair as the next (or only one) to ex-
plore. The likelihood is contextualized by the in-
put variables and any output variables which have
already been explored and tentatively solved. Al-
though one theoretical advantage of CP (and ILP)
is the ability to calculate an overall optimal solu-
tion through search, we unexpectedly found that
our confidence-based heuristic led to the first inter-
mediate solution typically being the optimal. This
allowed us to simplify the search methodology to
a one-best or threshold-based beam search without
any significant loss in accuracy. The result is dra-
matically improved scalability.
We use the concurrent CP language Mozart/Oz
to implement our approach. We previously im-
plemented an exploratory prototype that used raw
frequencies instead of smoothed probabilities for
the feature costs and search heuristic confidences.
(Langkilde-Geary, 2005; Langkilde-Geary, 2007).
The lack of smoothing severely limited the applica-
bility of the prototype. We are currently finishing
development of the before-mentioned on-demand
learning algorithm which will overcome that chal-
lenge and allow us to evaluate our approach?s ac-
curacy and efficiency on a variety of NLP tasks on
common test sets. Informal preliminary results on
the much-studied subtask of part-of-speech tagging
indicate that our method outperforms a Naive Bayes-
based baseline in terms of accuracy and within 2%
of state-of-the-art single-classifier methods, while
running in linear time with respect to the number of
output variables or word tokens. We are not aware
of any other approach that achieves this level of ac-
curacy in comparable algorithmic time.
4 Conclusion
The versatility and potential scalability of our ap-
proach are its most noteworthy aspects. We ex-
pect it to be able to handle not only a wider vari-
ety of NLP tasks than existing approaches but also
to tackle harder tasks that have been intractible be-
fore now. Although ILP has the same theoretical
power as CP for efficiently solving problems, our
approach takes advantage of several capabilities that
CP offers that ILP doesn?t, including modeling with
not only linear constraints but also logical, set-based
and other kinds of constraints; customized search
methodology with dynamically computed costs, and
conditionally applied constraints, among others.
References
P. Blache. 2000. Constraints, linguistic theories and nat-
ural language processing. Natural Language Process-
ing, 1835.
D. Duchier, C. Gardent, and J. Niehren. 1998. Concur-
rent constraint programming in oz for natural language
processing. Technical report, Universitt des Saarlan-
des.
I. Langkilde-Geary and J. Betteridge. 2006. A factored
functional dependency transformation of the english
penn treebank for probabilistic surface generation. In
Proc. LREC.
I. Langkilde-Geary. 2005. An exploratory applica-
tion of constraint optimization in mozart to probabilis-
tic natural language processing. In H. Christiansen,
P. Skadhauge, and J. Villadsen, editors, Proceedings of
the International Workshop on Constraint Solving and
Language Processing (CSLP), volume 3438. Springer-
Verlag LNAI.
I. Langkilde-Geary. 2007. Declarative syntactic process-
ing of natural language using concurrent constraint
programming and probabilistic dependency modeling.
In Proc. UCNLG.
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993.
Building a large annotated corpus of english: the Penn
treebank. Computational Linguistics, 19(2).
P. Piwek and K. van Deemter. 2006. Constraint-based
natural language generation: A survey. Technical re-
port, The Open University.
37
