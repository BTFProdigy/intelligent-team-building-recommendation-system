Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 108?111,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
The Coding Scheme for Annotating Extended Nominal Coreference 
and Bridging Anaphora in the Prague Dependency Treebank 
Anna Nedoluzhko,  Ji?? M?rovsk?,  Petr Pajas
Charles University in Prague
Institute of Formal and Applied Linguistics
{nedoluzko, mirovsky, pajas}@ufal.mff.cuni.cz
Abstract
The present paper outlines an ongoing project 
of annotation of the extended nominal corefer-
ence and the bridging anaphora in the Prague 
Dependency Treebank. We describe the anno-
tation  scheme  with  respect  to  the  linguistic 
classification of coreferential and bridging re-
lations and focus also on details of the annota-
tion process from the technical point of view. 
We present methods of helping the annotators 
?  by  a  pre-annotation  and  by  several  useful 
features  implemented  in  the  annotation  tool. 
Our method of the inter-annotator agreement 
is focused on the improvement of the annota-
tion  guidelines;  we  present  results  of  three 
subsequent measurements of the agreement.
1 Introduction
The Prague Dependency Treebank (PDT 2.0) is a 
large collection  of linguistically  annotated  data 
and documentation (Haji?  et al, 2006). In PDT 
2.0,  Czech  newspaper  texts  are  annotated  on 
three  layers.  The most abstract  (tectogrammati-
cal) layer includes the annotation of coreferential 
links of two types: grammatical coreference (typ-
ically within a single sentence) and textual coref-
erence (for pronominal and zero anaphora). The 
current paper focuses on the present annotation 
of  extended  textual  coreference,  where  the 
anaphoric  expression  is  neither  personal  pro-
noun, nor zero. Also the annotation of bridging 
anaphora on PDT is discussed.
In the last few years, a number of annotation 
schemes have been released, three of which are 
to be shortly presented here. The MUC is consid-
ered to be the most standard annotation scheme 
(Hirschman, 1997) and it  is  used in more than 
one  application  (MUC-6,  MUC-7,  ACE).  The 
advantage of this scheme is its simplicity and a 
very  detailed  linguistically  oriented  coding 
scheme.  It  has  been  however  criticized  for  its 
vague interpretation of the notion of coreference 
and for  the  limited  coverage of  relations  (only 
identical  relation  between  nouns  is  annotated). 
One of the most well known later approaches is 
MATE (Poesio, 2004)  and its  extension on the 
GNOME  corpus.  The  project  is  meant  to  be 
multi-functional. The annotation scheme was pri-
marily  developed  for  dialog  acts  analyses,  but 
may be easily  adapted  for  any other  investiga-
tion. In the extended GNOME scheme, the iden-
tical  coreference  is  annotated  along with  some 
bridging  relations,  such  as  ELEMENT,  SUB-
SET,  POSSession  and  OTHER for  underspeci-
fied relations. In PoCoS (Krasavina and Chiar-
chos, 2007), a two layer coreference annotation 
scheme was suggested: the Core Layer is general 
and reusable, while the Extended Layer supports 
a wider range of specific extensions.
In this document, we present the application of 
coreference  annotation  on  a  slavonic  language 
(Czech).  Czech  has  no  definite  article,  so  in 
many cases, an anaphoric relation cannot be eas-
ily identified. That's why we concentrated solely 
on coreference, i.e. on the case when two expres-
sions denote the same entity. Anaphoric relation 
between  non-coreferential  objects  is  annotated 
separately,  together  with  some  other  types  of 
bridging anaphora (see 2.1).
2 Methods of coreference and bridging 
anaphora annotation
Subject to annotation are pairs of coreferring ex-
pressions, the preceding expression is called an-
tecedent, the subsequent one is called anaphor.
The  (mostly  manual)  annotation  of  the  ex-
tended  coreference  and  bridging  anaphora  pro-
ceeds  basically  in  one  phase.  Unlike 
MUC/MATE/PoCoS projects,  where  annotation 
is divided into two phases (identifying  elements 
that can come in coreference relation (so called 
?markables?) and  establishing  anaphoric  rela-
tion), we do not make preliminary annotation of 
?markables?. Realizing the disadvantage of diffi-
cult agreement comparison, we still think that to 
separate identifying ?markables? is unnecessary 
in case of a language without grammatical cate-
gory of definiteness.
108
2.1 The annotation scheme
For the time being, we annotate textual corefer-
ence and bridging anaphora. In what follows, we 
briefly  present  the  classification  of  these  two 
types of context-dependences.
The  cases  where  anaphor  is  a  personal, 
demonstrative or zero pronoun are already anno-
tated in PDT. In the present annotation, the most 
cases of anaphoric expressions are expressed by 
NP with  nominal  head,  in  some cases  also  by 
pronominal  demonstrative  adverbs  (there,  then 
etc.),  adjectives  (by  named  entities  (e.g.  Ger-
many ? German) and possessive forms)), numer-
als or verbs (own ? ownership), see ex. (1).
Textual coreference is further classified into 
two types ? coreference of NPs with specific  or 
generic coreference. This decision is made on the 
basis of the expectation, that generic coreferen-
tial  chains  have  different  anaphoric  rules  from 
the specific ones. Into this group, there is also in-
cluded  a  big number  of  abstract  nouns,  whose 
coreference is not quite clear in every particular 
case. So, the generic type of textual coreference 
serves as the ambiguity group too. 
In  bridging anaphora we distinguish PART, 
SUBSET and FUNCT traditional  relations  (see 
e.g. Clark 1977), CONTRAST for coherence rel-
evant  discourse  opposites  (e.g.  People don't  
chew, it's cows who chew) and further underspec-
ified group REST, which is  used  for capturing 
bridging references ? potential  candidates for  a 
new bridging group (e.g. location ? resident, rel-
atives, event ? argument and some others).
2.2 Annotation Principles
In order to develop maximally consistent annota-
tion scheme, we follow a number of basic princi-
ples. Some of them are presented below: 
Chain principle: coreference relations in text 
are organized in ordered chains.  The most recent 
mention  of  a referent  is  marked  as  antecedent. 
This  principle  is  controlled  automatically  (see 
3.1.2). Chain principle does not concern bridging 
anaphora.
Principle of the maximum length of corefer-
encial  chains also  concerns  only  the  case  of 
coreference.  It  says  that  in  case  of  multiple 
choice, we prefer to continue the existing coref-
erence chain, rather than to begin a new one. To 
satisfy  this  principle,  grammatical  coreferential 
chains are being continued by textual ones, and 
already annotated  textual  coreferences  are con-
tinued  by  currently  annotated   non-pronominal 
links in turn.
The principle of maximal size of an anaforic 
expression:  subject  to annotation is always the 
whole  subtree  of  the  antecedent/anaphor.  This 
principle is partially directed by the dependency 
structure  of tectogrammatical trees  and may be 
sometimes counter-intuitive. See ex. (1):
(1)Henry's brother Nicholas has owned the 
Hall  for  27  years.  On  Nicholas'  death,  it 
passed  into  the  ownership  of  his  nephew, 
Yarburgh Greame
The principle of cooperation with the syntac-
tic structure of a given dependency tree: we do 
not annotate relations, which are already caught 
up by the  syntactic  structure  of  the  tectogram-
matical tree. So, unlike most schemes, we do not 
annotate predication and apposition relations.
Preference  of  coreference  over  bridging 
anaphora: in case of multiple choice, we prefer 
coreference.
3 The Tool and Data Format
The primary format of PDT 2.0 is called PML. It 
is  an  abstract  XML-based  format  designed  for 
annotation of treebanks. For editing and process-
ing data in PML format, a fully customizable tree 
editor  TrEd  has  been  implemented  (Pajas  & 
?t?p?nek 2008).
TrEd  can  be  easily  customized  to  a  desired 
purpose by extensions that are included into the 
system as modules. In this section, we describe 
some features of an extension that has been im-
plemented for our purposes.
The data  scheme used  in  PDT 2.0 has  been 
slightly extended to support the annotation of the 
extended textual  coreference (that  has ? unlike 
the originally annotated textual coreference ? a 
type)  and  the  bridging  anaphora  (that  has  not 
been annotated before and also has a type). Tech-
nically,  various  kinds  of  non-dependency  rela-
tions between nodes in PDT 2.0 use dedicated re-
ferring  attributes  that  contain unique identifiers 
of the nodes they refer to.
3.1 Helping the Annotators
We employ two ways of helping the annotators 
in their  tedious  task. First,  we pre-annotate the 
data with highly probable coreference relations. 
The annotators check these links and can remove 
them  if  they  are  wrong.  This  approach  has 
proved to be faster than letting the annotators an-
notate  the  data  from scratch.  Second,  we have 
implemented several supporting features into the 
annotation  tool  (the  TrEd  extension)  that  help 
during the annotation process.
109
3.1.1 Pre-Annotation
We use a list of pairs of words that with a high 
probability  form  a  coreferential  pair  in  texts. 
Most of the pairs in the list consist of a noun and 
a derived adjective, which are different in Czech, 
e.g.  Praha  ?  pra?sk?  (in  English:  Prague  ? 
Prague,  like  in  the  sentence:  He  arrived  in  
Prague and found the Prague atmosphere quite  
casual).  The rest  of the list  is formed by pairs 
consisting  of  an abbreviation  and its  one-word 
expansion, e.g. ?R ? ?esko (similarly in English: 
USA ? States).  The whole list consists of more 
than  6  thousand  pairs  obtained  automatically 
from  the  morphological  synthesizer  for  Czech, 
manually checked and slightly extended.
3.1.2 Annotation
Several features have been implemented in the 
annotation tool to help with the annotation.
Manual  pre-annotation: If  the  annotator 
finds a word in the text that appears many times 
in the document and its occurrences seem to co-
refer,  he can create a coreferential chain out of 
these  words  by  a  single  key-stroke.  All  nodes 
that  have  the  same  tectogrammatical  lemma 
(t_lemma) become a part of the chain.
Finding the nearest antecedent: The annota-
tion  instructions  require  that  the  nearest  an-
tecedent is always selected for the coreferential 
link.  The  tool  automatically  re-directs  a  newly 
created coreferential arrow to the nearest one (in 
the already existing coreferential chain) if the an-
notator  selects  a farther  antecedent  by mistake. 
However, the rule of the nearest antecedent can 
be broken in less clear situations. For example, if 
there are three coreferential words in the text, A, 
B and C (ordered from left to right), and the an-
notator connects A and C (overlooking B), and 
later realizes that B is also coreferential with A 
and creates the arrow from B to A, the tool re-
connects  the  C?A arrow  to  C?B.  Thus,  the 
chain C?B?A is correctly created.
Preserving the coreferential chain: If the an-
notator  removes  an  arrow  and  a  coreferential 
chain is thus interrupted, the tool asks the anno-
tator whether it should re-connect the chain.
Text highlighting: The annotation of the ex-
tended  textual  coreference  and  the  bridging 
anaphora is  performed on the tectogrammatical 
layer of PDT. However, the annotators prefer to 
work on the surface form of the text, using the 
tectogrammatical trees only as a supporting de-
piction of the relations. After selecting a word in 
the sentences (by clicking on it), the tool deter-
mines  to  which  node  in  the  tectogrammatical 
trees the word belongs. Then, the projection back 
to the surface is performed and all words on the 
surface that belong to the selected node are high-
lighted. Only one word of the highlighted words 
is a lexical counterpart of the tectogrammatical 
node  (which  is  usually  the  word  the  annotator 
clicked on ? only in cases such as if the annotator 
clicks on a preposition or other auxiliary word, 
the lexical counterpart of the corresponding tec-
togrammatical  node  differs  from  the  word 
clicked  on).  Using  this  information,  also  all 
words  in  the  sentences  that  have  the  same 
t_lemma (again, we use only the lexical counter-
parts)  as  the  selected  word,  are  underlined. 
Words that are connected with the selected word 
via a coreferential chain are highlighted in such 
colors that indicate whether the last connecting 
relation in the chain was textual or grammatical. 
Moreover,  all  words  that  are  connected  via  a 
bridging anaphora with any word of this corefer-
ential chain, are highlighted in a specific color.
4 Application and Evaluation
The annotation of the extended textual  corefer-
ence  and  the  bridging  anaphora  started  in  No-
vember 2008. Two annotators work on different 
texts  (each document  is  annotated only by one 
annotator),  except  for  a small  overlap  used for 
measuring the inter-annotator agreement.
As of April 2009, about one fifth of PDT 2.0 
data  has been  annotated.  The detailed  numbers 
are summed in Table 1:
number of annotated documents 611
total number of sentences 9,425
total number of words 157,817
total number of tectogrammatical nodes 
(excl. the technical root) 127,954
number of newly annotated co-referring 
nodes  (bridging  relations  and  textual 
coreference)
16,874
number of co-referring nodes including 
the textual coreference originally anno-
tated in PDT 2.0
20,532
% of co-referring nodes 16 %
Table 1. Annotation statistics
Figure 1 presents the proportion of  types of 
coreferential  and  bridging  relations  in  the  cur-
rently annotated part of PDT1. TK_0 is used for 
textual coreference of specific NPs, TK_NR for 
textual  coreference  of  non-specific  NPs,  other 
abbreviations are believed to be self-explaining. 
1  Including the originally annotated textual coreference 
in PDT 2.0.
110
Inter-annotator agreement: For the purposes 
of checking and improving the annotation guide-
lines,  we  require  a  more  strict  inter-annotator 
agreement than agreement  on sets  (for  corefer-
ence),  often  used  in  other  projects  (e.g.  Pas-
soneau  2004).  For  both  the  extended  textual 
coreference  and the  bridging anaphora,  we use 
F1-measure for the agreement on the antecedent, 
and Cohen's  ? (Cohen 1960) for the agreement 
on the type of the link. In Table 2, the results of 
the three performed measurements of the inter-
annotator agreement are presented:
arrows 
TC (F1)
arrows 
TC + 
types 
(F1)
TC 
types 
only 
(?)
arrows
bridging 
(F1)
arrows
bridging
+ 
types (F1)
bridging 
types 
only
(?)
1st measure-
ment 
(40 sent.) 0.76 0.67 0.54 0.49 0.42 0.79
2nd measure-
ment
(40 sent.) 0.64 0.41 0.33 0.52 0.52 1
3rdmeasure-
ment 
(100 sent.) 0.80 0.68 0.67 0.59 0.57 0.88
Table 2. Evaluation of the inter-annotator agreement
5 Conclusion
We have presented the annotation scheme and 
principles  for  the  extended  textual  coreference 
and the bridging anaphora in PDT 2.0.
Pre-annotation and features of the annotation 
tool that help the annotators have been described 
in detail. We have presented basic statistics about 
the  annotation  completed  so  far  and  results  of 
first  measurements of the inter-annotator agree-
ment (which are difficult to compare to other ap-
proaches, as we do not use "markables"). 
Improvement of the inter-annotator agreement 
is  in  our  focus  for  the  upcoming  stage  of  the 
project. The experience shows that the agreement 
is greatly affected by parameters of the text as a 
whole. Short texts are generally far less demand-
ing for their interpretation than longer ones, texts 
with  many  abstract  and  general  notions  allow 
more  possibilities  of  interpretation  and  so  on. 
Frequent  problems  causing  inter-annotator  dis-
agreement  are  of  two  types  -  different  under-
standing  of  the  content  and  inaccuracy  of  the 
coding  scheme.  The  first  case  is  hardly  to  be 
solved entirely. The problems of the second type 
are  being  worked  on:  we  prepare  the  detailed 
classification of the inter-annotator disagreement 
and regularly specify the annotation guidelines.
Acknowledgment 
We gratefully  acknowledge  the support  of the 
Czech  Ministry  of  Education  (grant  MSM-
0021620838),  the  Czech  Grant  Agency  (grant 
405/09/0729), the European Union (project Com-
panions  ?  FP6-IST-5-034434),  and  the  Grant 
Agency  of  the  Academy  of  Sciences  of  the 
Czech Republic (project 1ET101120503).
References 
Clark, H. 1977. Bridging. In Johnson-Laird and Wa-
son, editors,  Thinking: Readings in Cognitive Sci-
ence. Cambridge. 411-420.
Cohen, J. 1960. A coefficient of agreement for nomi-
nal  scales.  Educational  and  Psychological  Mea-
surement, 20(1), 37-46.
Haji?,  J.  et  al.  2006.  Prague  Dependency  Treebank 
2.0.CD-ROM,  Linguistic  Data  Consortium,  LDC 
Catalog No.: LDC2006T01, Philadelphia.
Hirschman, L. 1997. MUC-7 coreference task defini-
tion. Version 3.0.
Krasavina, O. and  Ch. Chiarcos. 2007. PoCoS ? Pots-
dam  Coreference  Scheme.  Proc.  of  ACL  2007, 
Prague, Czech Republic
Ku?ov? L. and E. Haji?ov?. 2004. Coreferential Rela-
tions in the Prague Dependency Treebank. In 5th 
Discourse Anaphora and Anaphor Resolution Col-
loquium. Edi??es Colibri.
Pajas, P. and J. ?t?p?nek 2008. Recent advances in a 
feature-rich framework for treebank annotation. In 
The 22nd Interntional Conference on Computatio-
nal  Linguistics  ?  Proceedings  of  the  Conference. 
Manchester, pp. 673-680.
Passonneau, R. 2004. Computing Reliability for Core-
ference. In Proceedings of LREC, vol. 4, Lisbon, 
pp. 1503-1506.
Poesio, M. 2004 The MATE/GNOME Proposals for 
Anaphoric  Annotation,  Revisited.  Proc.  of  SIG-
DIAL.
Figure 1. Types of  relations
111
Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 103?111,
Sofia, Bulgaria, August 8-9, 2013. c?2013 Association for Computational Linguistics
Generic noun phrases and annotation of coreference and bridging re-
lations in the Prague Dependency Treebank 
Anna Nedoluzhko 
Faculty of Mathematics and Physics, Charles University in Prague 
nedoluzko@ufal.mff.cuni.cz 
 
 
 
 
Abstract 
This paper discusses the problem of annotating 
coreference relations with generic expressions 
in a large scale corpus. We present and ana-
lyze some existing theories of genericity, 
compare them to the approaches to generics 
that are used in the state-of-the-art coreference 
annotation guidelines and discuss how coref-
erence of generic expressions is processed in 
the manual annotation of the Prague Depend-
ency Treebank. After analyzing some typical 
problematic issues we propose some partial 
solutions that can be used to enhance the 
quality and consistency of the annotation. 
1 Introduction 
One of the most problematic issues of anno-
tating coreference in large scale corpora is 
processing coreference of generic expres-
sions. The decision to annotate generic noun 
phrases produces a significant decrease of inter-
annotator agreement. On the other hand, neglect-
ing coreference relations between generic ex-
pressions causes a significant loss of information 
on the text coherence that is primordially the rea-
son for annotating coreference relations at all. It 
also causes the inconsistency of annotation 
guidelines: due to relatively vague definition of 
genericity, it is almost impossible to exclude all 
coreference relations between generics from the 
annotation. 
In the Prague Dependency Treebank (hence-
forth PDT), we tried to distinguish coreference 
relations between nominal expressions with spe-
cific and generic reading. Comparing the inter-
annotator agreement for these groups shows that 
the agreement for noun coreference with specific 
reading is significantly higher than the agreement 
for the coreference of generic NPs (F1-measure 
0.705 for specific NPs and 0.492 for generics1). 
Moreover, the manual analysis of the cases of 
disagreement of specific NPs coreference 
demonstrates that most cases of disagreement are 
those where NPs in question may be interpreted 
generically. 
Having formulated a set of criteria which help 
identifying generic expressions, there still re-
mains a wide range of typical examples which 
can have generic interpretation, though not nec-
essarily. In this paper, we try to delimit the set of 
generic NPs presenting the overview of some 
existing theories of genericity (Sections 2 and 
3.1) and compare them to the stand-of-the-art 
coreference annotation guidelines (Section 3.2). 
Then we present our approach to annotating co-
reference with generic noun phrases in PDT 
where we apply the presented theories to coref-
erence and bridging relations annotation (Section 
4). We analyze typical problematic issues (Sec-
tion 5) and discuss some possible solutions (Sec-
tion 6). 
2 What are generics and can they co-
refer? 
Generic reference is a term commonly used in 
linguistic semantics to describe noun-phrase ref-
erence to kinds of things (Carlson 2005). In dif-
ferent languages, generic reference may be 
expressed by noun phrases with definite and 
indefinite articles and with determinerless 
expressions quite generally. In languages 
without articles, the determinerless form is 
typically used (Carlson 2005, Hlavsa 1975; 
Padu?eva 1985, etc.).  
                                                 
1 F1-measure for generics is closer to inter-annotator 
agreement for bridging relations (0.460 for all anno-
tated data). 
103
Compare some typical examples for generic 
noun reference (different uses of a/the dog(s)) in 
English, German and Czech: 
English:  Dogs bark ? The dog has evolved 
from the Jackal  ? A dog knows when it is time 
for his walk2.  
German: Hunde bei?en. Der Hund stammt 
vom Schakal ab. Ein Hund wei?// Hunde wissen, 
wenn es Zeit f?r seinen Spaziergang ist. 
Czech (non-article language): Psi ?t?kaj?. ? 
Pes je ?elma. 
The examples above demonstrate that generic 
noun phrases cannot be recognized by their 
forms (this fact  was pointed out in Lyons 1999, 
Carlson 2005, etc.). While in English the plural 
form of the definite can only marginally have 
generic reference, in German, which is closely 
related to English, the plural definite may imply 
generic reference quite easily. In Romance lan-
guages, the form of bare plural with generics is 
prohibited (Delfitto 2006) and even in languages 
without articles, generics with determiners are 
not so rare (see e.g. common examples with 
Czech in Nedoluzhko 2003) 3 . This leads to a 
suggestion that genericity is not a primitive cate-
gory of semantic or syntactic description. 
Theoretical studies like Carlson (1980) appeal 
to typical examples with noun phrases referring 
to specific objects. A discussion on his approach 
(Paducheva 1985, Delfitto 2006, Lyons 1999) 
concerns theoretical issues that are analyzed in 
similar typical cases. 
When analyzing real corpus examples we en-
counter a lot of cases indicating that not all ge-
neric expressions are generic in the same way. 
Problems with processing generic expressions 
arise also from the lack of a universally accepted 
theory of genericity which would be applicable 
to the real texts analysis. 
Generic reading is possible not only with re-
ferring nouns, but also with mass nouns, group 
nouns, abstract nouns, quantifiers and 
deverbatives. Look at the example (1). Everyone 
should probably agree that the homeless is a ge-
neric expression, but is the same true about the 
homeless population? 
                                                 
2  However, Carlson ?  Pelletier (1995) do not consid-
er a dog in the last sentence to be generic, because it 
cannot be combined with kind-level predicates. 
3 It may be possible to determine generics in sentenc-
es with so-called ?kind-level predicates? (Carlson 
2005), they interact with aspectual distinctions in 
verbs (Lyons 1999) etc, but these approaches are not 
applicable to real-text data. 
(1) Your comments implied we had discov-
ered that the principal cause of homeless-
ness is to be found in the large numbers of 
mentally ill and substance-abusing people 
in the homeless population. [...] The study 
shows that nearly 40% of the homeless pop-
ulation is made up of women and children 
and that only 25% of the homeless exhibits 
some combination of drug, alcohol and 
mental problems4. 
Another relevant question is if generic ex-
pressions referring to the same kind can be 
considered coreferent in the same sense as 
noun phrases with a specific reading. Ac-
cording to Carlson?s (1980) and Lyons? (1999) 
claim, generics refer to classes in the similar way 
as proper names refer to unique entities. In this 
sense, coreference of generic expressions appears 
to be obvious. On the other hand, Carlson?s ob-
servations seem to be quite language-specific. 
Arguing against a quantificational analysis of 
bare plurals with generic meaning, he claims that 
the sentence Miles wants to meet policemen can-
not be assigned a reading according to which 
?there are certain policemen that Miles wants to 
meet,? whereas this interpretation is naturally 
available in the case of Miles wants to meet some 
policemen. This is not the case of languages 
without articles where plural forms can be as-
signed any reading regardless of the use of the 
quantifier5. Generally, we suppose that quantifi-
cational (or predicative) interpretation of generic 
expressions in different languages is not impos-
sible (see for example almost obligatory predica-
tive reading of Czech exporters in (7)). However, 
this fact does not necessarily exclude the coref-
erence relation between them. Eventually, the 
discourse deixis as reference to events is also 
often considered and annotated as coreference. 
3 Recent research on generics 
We believe that it would not be a strong exag-
geration to claim that theoretical and computa-
tional linguistics have different goals as concerns 
their approach to genericity. The challenge of 
linguistic research is to find out more about the 
essence of genericity. The aim of annotating is to 
                                                 
4 The example comes from the Prague English De-
pendency Treebank (PEDT, Haji? et al 2009) 
5 Actually, even in English not all bare plurals should 
necessarily refer to kinds. In modern journalistic texts, 
the tendency to omit articles appears to be quite 
strong. 
104
make the group of generics as clear as possible, 
in order to  reach higher agreement and better 
results of automatic processing. 
It is also generally known that the features of 
an annotation must be adapted to the task it is 
designed for. However, the existing large-scale 
annotated corpora (especially those prepared on 
university basis) are often meant to be multi-
purpose. They serve both as train data for (dif-
ferent!) automatic tasks and as a rich manually 
annotated material for linguistic research.  
In what follows, we complete the theoretical 
overview (started in section 2), present the anno-
tation approach and look for the common points. 
3.1 Linguistic research 
There is a rich variety of linguistic approaches to 
genericity. Even as concerns the terminology 
with generics, it is quite inconsistent and cannot 
be relied on with much certainty. According to 
different researchers, generic NPs are considered 
to be either referring to classes (Carlson ?  Pelle-
tier 1995, Mendoza 2004) or non-referring (ra-
ther predicating) classifications over kinds 
(Paducheva 1985), beeing able to have specific 
and non-specific interpretation (Mendoza 2004, 
Smelev 1996) and divided from non-specific NPs 
as a separate group (Carlson ?  Pelletier 2005, 
Paducheva 1985). 
Carlson (1980) represents the most influential 
approach to genericity that has been elaborated 
in the framework of formal semantics and gener-
ative grammar. Calson?s hypothesis is that gener-
ics are kind-referring expressions, roughly names 
for kinds, as opposed to individual-referring ex-
pressions that refer to individuals or groups of 
individuals. In his approach, there is a difference 
between generic reference and individual non-
specific reference, i.e. reference to an open set of 
individual objects. For example, NP lions that 
have toothaches is not generic, its reference is 
individual (i.e. non-generic) and non-specific, 
which can be demonstrated by the fact that it 
cannot be substituted by the definite NP the lion 
that has toothache (such NP can have only indi-
vidual reading). However, the problem with this 
criterion is that it is clearly language-specific (it 
cannot be applied at all to Czech, for instance). 
3.2 Annotation coreference with generic 
expression 
Let?s now have a look on how generic NPs are 
processed in annotation projects with anaphoric 
and coreference annotation. 
In some projects, e.g. ARRAU and other corpora 
based on the MATE coreference annotation 
scheme (Poesio 2004), genericity is marked as a 
part of lexico-semantical information of the noun 
(an attribute generic-yes/no/undersp is 
applied to each noun). This information is con-
templated in the annotation of identical corefer-
ence.  Identical coreference for generics is also 
annotated in AnCora (Recasens 2010) and PDT 
(Nedoluzhko 2011).  
In other projects, annotation of coreference 
with generic NPs may be excluded from annota-
tion schemes that are geared towards a reliable 
annotation of large text quantities. For example, 
generics are not annotated for coreference in On-
tonotes (Pradhan et al 2007), T?BA-DZ (Hin-
richs et al 2004) and PoCoS (Krasavina-
Chiarchos 2007).  
However, even if an annotation scheme ex-
plicitly says that coreference of generic NPs is 
not annotated, there are some borderline cases 
where coreference can still be annotated quite 
systematically. So, T?BA annotates coreference 
with the nominal expression if it appears repeat-
edly in the text with the same interpretation. In 
Ontonotes, the explicit anaphora with it in the 
anaphoric position is commonly annotated for 
coreference: 
(2) Still, any change in East Germany has 
enormous implications, for both East and 
West. It raises the long-cherished hopes of 
many Germans for reunification6. 
Furthermore, systematic exclusion of generic 
expressions from the annotation will force the 
coders not to mark the cases like (3) and (4)7. 
From the point of view of applied tasks and au-
tomatic coreference resolvers it will lead to the 
loss of relevant information and to an essential 
complification of automatic tools. 
(3) The sterilizing gene is expressed just be-
fore the pollen is about to develop and it 
deactivates the anthers of every flower in 
the plant. Mr. Leemans said this genetic 
manipulation doesn't hurt the growth of that 
plant. 
(4) A workshop needs to be planned careful-
ly. Otherwise it may turn in a disaster. 
As far as we know, there are no significant 
projects for annotating coreference separately for 
                                                 
6 This example is taken from PEDT, to which the On-
tonotes coreference was applied. 
7 Examples come from PEDT. 
105
generic, unspecific non-generic and specific ex-
pressions.  
4 Coreference annotation in Prague 
Dependency Treebank 
In this section we describe how generic expres-
sions (or more precisely, what we decided to 
consider generic expressions) are annotated in 
the Prague Dependency Treebank.  
Annotation of coreference and discourse rela-
tions is a project related to the Prague Dependen-
cy Treebank 2.5 (PDT; Bej?ek et al 2011). It 
represents a new manually annotated layer of 
language description, above the existing layers of 
the PDT (morphology, analytic syntax and tecto-
grammatics) and it captures linguistic phenome-
na from the perspective of discourse structure 
and coherence. This special layer of the treebank 
consists of annotation of nominal coreference 
and bridging relations (Nedoluzhko et al 2009), 
discourse connectives, discourse units linked by 
them and semantic relations between these units 
(Mladov? 2011).  
Considering the fact that Czech has no definite 
article (hence no formal possibility to exclude 
non-anaphoric coreference), our annotation is 
aimed at coreference relations regardless to their 
anaphoricity. 
Coreference relations are marked for noun 
phrases with specific and generic reference sepa-
rately ? coreference of specific noun phrases ? 
type SPEC, coreference of generic noun phrases 
? type GEN8.  Bridging relations, which mark 
some semantic relations between non-
coreferential entities, are also annotated in PDT. 
The following types of bridging relations are dis-
tinguished: PART-OF (e.g. room - ceiling), 
SUBSET (students - some students) and FUNCT 
(state - president) traditional relations, CON-
TRAST for coherence relevant discourse oppo-
sites (this year - last year), ANAF for explicitly 
anaphoric relations without coreference or one of 
the semantic relations mentioned above (rainbow 
- that word) and the further underspecified group 
REST9.  
As seen from the point of view of the annotat-
ed groups, generic NPs are explicitly marked 
                                                 
8 The reason for this decision is the lack of semantic 
information assigned to nouns themselves, as it is 
done e.g. for Gnome in MATE sceme (Poesio 2004). 
9  For detailed classification of identity coreference 
and bridging relations used in PDT, see e.g. Ne-
doluzhko et al 2011. 
only with the second element of the coreference 
relation. However, this distinction remains un-
registered by bridging relations. Moreover, it 
appears to be possible (and even not so uncom-
mon) that a coreference relation was annotated 
between a generic and a non-generic noun 
phrase. These cases are interpreted as either (lin-
guistically) ambiguous or insufficiently classified 
by the guidelines. For example, in (5), the specif-
ic noun phrase tento n?rod (=this nation) is core-
ferent with generic plural Romy (=the Gipsies): 
(5) Nic z toho se v?ak nevyrovn? m??e 
ne?t?st?, kter? Romy postihlo v letech druh? 
sv?tov? v?lky. Spolu se ?idy byli ozna?eni 
za m?n?cennou rasu a stali se objektem pa-
tologick?ch fa?istick?ch opat?en?, jejich? c?-
lem byla ?pln? genocida tohoto n?roda. (= 
Nothing of this, however, compares to the 
misfortune that befell the Gipsies during the 
Second World War. Together with the Jews, 
they were called an inferior race and be-
came the object of pathological fascist 
measures, their purpose being the complete 
genocide of the nation.) 
Annotation rules for generics in PDT are de-
scribed in detail in sections 4.1-4.3. 
4.1 Type coreference of generic NPs 
Coreference relations between the same types 
are annotated as coreference of generic NPs (at-
tribute coref_text, type GEN). Cf. (6) 
where antecedent generic drug is pronominalized 
in the anaphoric position: 
(6) Droga je tedy tak ??inn?, ?e ten, kdo ji  
u??v?, se snadno dostane do ?pohody? kou-
?en?m nebo ??up?n?m. (= The drug is so ef-
fective that the person who takes it can easi-
ly achieve the state of ?coolness? by smok-
ing or snorting.) 
The ?generic coreference? is more frequent for 
plural forms (7): 
(7) Nov? striktn? omezen? vl?dy SR proti 
?esk?m export?r?m. Ji? n?kolik dn? je v?eo-
becn? zn?mo, ?e ochran??sk? opat?en? slov-
ensk? vl?dy proti ?esk?m export?r?m se 
dot?kaj? zejm?na oblasti obchodu s po-
travinami a zem?d?lsk?mi produkty. (= The 
new Slovak government's strict restrictions 
on Czech exporters. It?s commonly known 
for several days that protective measures of 
Slovakia's government against Czech ex-
porters apply mostly to the trade of food 
and agricultural products.) 
106
Textual coreference of type GEN is also anno-
tated for the majority of abstract nouns (see more 
detail in Section 5.5), cf. (8): 
(8) T?mto faktorem je podnikatel-inov?tor, 
kter? se sna?? o zisk, a proto logicky nem??e 
existovat ve stavu statiky, kter? nezn? ani 
zisk, ani ztr?tu. (= This factor is the enter-
preneur-innovator, who is trying to gain 
profit, and hence, logically, cannot exist in 
a static state, where there is no profit or 
loss.) 
4.2. Classes and subclasses 
The relation ?category ? sub-category? is 
marked as a bridging relation of the SUBSET 
type. Cf. (9).  
(9) I kdy? konzervativn? Anglie jeho ?in od-
soudila, ? Brit?nie se pro ?v?ka?ku stala 
br?nou do Evropy. Je?t? jeden miln?k si 
zaslou?? zm?nku ? zrod bublinov? ?v?ka?ky 
(= Although conservative England did not 
accept it, ... for the gum, Britain has become 
the gateway to Europe. Another milestone is 
worth mentioning, that is the birth of a bub-
ble gum.) 
Annotating the SUBSET relation with generic 
expressions appears to be quite a serious prob-
lem. This relation has a different meaning com-
pared to the SUBSET relation of noun phrases 
with specific reading. However, such relations 
may be quite relevant for cohesion.  
4.3 The relation ?type ? entity? 
If a specific mention is used in the text af-
ter a generic mention (or the contrary), the 
relation between them is annotated as a 
bridging relation of the SUBSET type. Cf. (10): 
(10) Nov? VW Golf je vybaven motorem 
o s?le... Dostali jsme mo?nost se nov?m 
golfem projet. (= The new VW Golf is 
equipped with an engine power ... We 
had an opportunity to ride a new golf.) 
Similar, but not the same is the relation be-
tween a set of specific objects and a non-specific 
element in (11): 
(11) [volont??i] Absolvovali ?kolen? v prvn? 
pomoci pro ?lov?ka v nouzi . [?]Kdy? d?t? 
zavol?, dostane bu? radu hned, nebo si s 
n?m volont?r domluv? dal?? hovor. (=The 
volunteers have been trained in first aid for 
people in need. [...] When a child calls, it 
will get get an advice immediately, or a vol-
unteer will arrange a meeting with him.) 
5 Problem cases with generics in PDT 
Although the cases presented in sections 4.1-4.3 
do not look very reliable, they are still consid-
ered to be relatively clear as compared to what 
follows in 5.1 -5.6.  The decisions made in anno-
tation guidelines for these cases are often case-
sensitive, might be in some cases contra-
intuitive, and they result in high inter-annotator 
disagreement. 
5.1 Non-generic non-specific NPs 
In case of non-generic non-specific noun 
phrases, when antecedent and anaphoric noun 
phrases have the same t-lemmas and the same 
scope, but anaphoric NP does not have a deter-
miner, coreference of type GEN is annotated. 
Although this kind of relation does not contribute 
much to text coherence, we still tend to mark this 
relation, also for the reason that the border be-
tween what should be annotated and what should 
not is not always easy to determine.  
(12) Kdy? si d?t? bude p??t, aby se o jeho 
probl?mu nikdo z rodiny nebo ?koly ne-
dozv?d?l, mus?me to respektovat, vysv?tluje 
Jana Drtilov? . [?] V?t?inou se st?v?, ?e 
d?t? ani nechce, aby se rodina  dozv?d?la, ?e 
se n?m ozval. Linka by nem?la rodinu 
nahrazovat, ale dopl?ovat. (= If a child de-
sires that no one from the family or school 
would find out about his problems, we have 
to respect that, says Jana Drtilova. [?] It is 
usually the case that the child does not even 
want for the family to know that he contact-
ed us.  The hotline should not replace the 
family, but to supplement it.)  
There are also cases of non-specific non-
generic NPs the referential value of which is 
provided by syntactic factors. These are so-called 
contexts with removed assertiveness, e.g. sen-
tences with modal verbs (can, want, need), im-
perative sentences, future tense, questions, nega-
tions, disjunctions, irreality, uncertainty and so 
on. Non-specific NPs are often used with per-
formative verbs, propositional attitudes (want, 
think, consider) and some constructions as e.g. in 
English such as, in Czech jde o (=lit. It is about), 
takov? X (=such X), etc. These contexts can give 
a non-specific reading to an expression, even if it 
actually has a specific meaning. Cf (13), where  
107
(13) Ale jedna v?c je jist? - pal?c bude 
stavebn? p?ed?v?n letos na podzim. [?] 
Provoz tak obrovsk? budovy p?ijde ro?n? 
na des?tky milion? korun. (=lit. But one 
thing is certain ? the reconstruction of 
the palace will be finished this fall. [...] It 
will cost tens of millions crowns, to run 
such a huge building.) 
5.2 Borderline cases between coreference of 
specific and generic NPs 
In some cases, it is hard to decide if a noun 
phrase has a specific or a generic reading. Most-
ly, both interpretations are possible. There are no 
firm rules for an unambiguous assignment of the 
types in those cases; the type is chosen on the 
basis of the available context and the annotator?s 
consideration. Uncertainty of the choice between 
generic and specific reference is common with 
some typical groups of noun phrases, first of all 
with those that have or may have modifications. 
Cf. po?ad (=TV show) in (14) that may have a 
temporal modification. The obligatoriness of this 
modification influences the annotator?s decision 
if (s)he should read it as a generic or a specific 
NP. For this case, the specific reading was cho-
sen.  
(14) K t?matu po?adu TV NOVA TABU 
?Zrak za b?lou h?l? byl p?izv?n ke kon-
zultaci Old?ich ??lek. Kate?ina Hamrov?, 
dramaturgyn? po?adu, TV NOVA. (= To 
consult the topic of the TV NOVA show TA-
BU "Vision for a white cane", Ulrich ??lek 
was invited. Catherine Hamrov?, the dram-
atist of the show, TV NOVA) 
Also, for example for (15), the detergent Toto 
can be understood as a specific (a name for a de-
tergent brand) or generic (the type of the deter-
gent of such brand). Also in this case, the specif-
ic reference is preferred in PDT: 
(15) U detergentu Toto jsme nap??klad ?e?ili 
probl?m s udr?en?m st?l? kvality, proto?e 
jednotliv? partie byly nevyv??en?. In-
vestovali jsme dva miliony korun do n?kupu 
p?sov?ch vah, zp?esnili d?vkov?n? a jakost 
prac?ho pr??ku stabilizovali. (=For exam-
ple, with the Toto detergent we face prob-
lems with maintaining consistent quality... 
We invested two million crowns... and stabi-
lized the quality of the detergent. ) 
5.3 Borderline cases between coreference of 
generic NPs and zero relation 
There is also a borderline between the cases of 
coreference of the generic NPs and the cases 
where it makes no sense to mark a coreferential 
relation. We do not annotate ?generic corefer-
ence? if noun phrases have different scope (i.e. 
they refer to different sets of objects), e.g. ?eny 
(= women) ? ?eny v 19. stolet? (= women in 19th 
century). In this case, the bridging relation of the 
type SUBSET is annotated instead. In other 
problematic cases, annotators usually apply to 
their intuition and the text coherence. If both say 
no, no coreference is annotated. 
5.4 Coreference with measure NPs and oth-
er NPs with a ?container? meaning 
In PDT, a special group of numerals and 
nouns with a ?container? meaning is singled out. 
They  have  the  modification  in  their  valency  
frames denoting  the  content  (people,  things,  
substance etc.) of a container expressed by the 
governing noun. These ?container? expressions 
are e.g. nouns and numerals denoting groups, 
number or amount, sets, collections, portions, 
etc. (skupina lid? (=group of people), po?et akci? 
(=number of stocks), st?do krav (=herd of cows), 
dostatek financ? (=abundance of finance), 
mili?ny ?id? (=millions of Jews), sklenice piva 
(=glass of beer), deset procent obyvatel (=ten 
percent of population)). 
The PDT convention on annotating corefer-
ence by NPs with a ?container? meaning follows 
the maximum-scope rule, i.e., if possible, the 
governing (?container?) node is linked by a co-
reference link (16). The modifications of con-
tainers may be coreferential themselves inde-
pendently of the ?containers? (17) 
(16) Absolutn? v?t?ina lid? z?visl?ch na her-
oinu je p??li? mlad? na to, aby si #PersPron 
pamatovala rozklad a zesl?blost generace 
sedmdes?t?ch let, tak?e odvr?cenou str?nku 
?fantastick?ho? ?ivota si #PersPron 
mnohdy v?bec neuv?dom?. (=Absolute ma-
jority of people addicted to heroin is too 
young to remember the decomposition and 
enfeeblement of the generation of seventies, 
so they (lit. ?she? referring to ?majority?) do 
not realize the downside of the "fantastic" 
life.) 
(17) V b??n?m vzorku sedmdes?t?ch let byla 
pouze 3?4 procenta ?ist? suroviny. b. Nyn? 
jsou k dost?n? bal??ky obsahuj?c? a? 80 pro-
cent ?ist?ho heroinu. (=In an average sam-
108
ple from the seventies, there were only 3-4 
percent of pure raw material. Currently, 
one can get packages containing up to 80 
percent of pure heroin.) 
Coreference of ?containers? can be problemat-
ic from the point of view of their generic or spe-
cific interpretation. Nouns referring to groups 
may refer generically to the elements belonging 
to that group or specifically to the group itself. In 
the following example, there has been a disa-
greement between annotators concerning the ge-
neric/specific reading of the NP skupina 
(=group). We believe that this kind of disagree-
ment could be solved by separating the group of 
non-specific non-generic references. 
(18) Podle v?zkum? ve vysp?l?ch zem?ch se 
ukazuje, ?e lid?, kte?? pot?ebuj? speci?ln? 
slu?by, je daleko v?c. U n?s by tuto skupinu 
tvo?ilo asi tak 70000 osob. Jsou to hlavn? 
star?? lid? se zbytky zraku a slabozrac?. Tato 
skupina stoj? ?pln? mimo a m? tak ?ivot 
je?t? v?ce zt??en?, proto?e mnoz? o t?chto 
slu?b?ch ani nev?d?. (=According to the re-
search in the developed countries, there are 
many more people who need special ser-
vices. In our country, the group of such 
people would count about 70,000 individu-
als. They are mainly older people sighted 
and visually impaired. This group is com-
pletely off, their life being even more diffi-
cult, because they don?t even know about 
many of these services.) 
More complicated are the cases where coref-
erence chains for ?containers? and their modifica-
tions intersect. In (19), a coreference link for the 
strikers in b. should lead to three and a half 
thousand workers but in c., the number of strik-
ers changes, so the container modification work-
ers should be marked as coreferent with the 
strikers in b. For such cases, coreference of type 
GEN is used in PDT. 
(19) a. T?? a p?l tis?ce d?ln?k? vyhl?sili 
st?vku. b. St?vkuj?c? ??daj? zv??en? plat? o 
?est procent. c. Do 8. b?ezna se po?et 
st?vkuj?c?ch m??e zdvojn?sobit. (a. Three 
and a half thousand workers went on strike. 
b. The strikers demand six percent of salary 
increase. c. By 8 March, the number of 
strikers may double.)  
However, in this case, the problem is rather 
specific. Here, po?et st?vkuj?c?ch  (=the number 
of strikers) does not actually refer to the strikers 
(as it would e.g. in tis?c st?vkuj?c?ch (=thousand 
strikers) but to the number itself and that is the 
reason for coreference annotation to strikers. In 
such cases, the number does not serve as a ?con-
tainer? in proper sense. 
5.5 Coreference with abstract nouns 
Processing coreference of abstract nouns 
seems to be in some respects close to that of ge-
nerics. Abstract nouns do not refer to a type, but 
to a notion. However, this notion is unique in the 
same way as type is unique to the generic ex-
pression which refers to it. Moreover, abstract 
nouns are close to predicative and quantification-
al interpretation and there are no formal rules 
distinguishing them from concrete NPs and 
deverbatives. They also result in high ambiguity 
when annotated for coreference. 
There have been several changes in the guide-
lines for the annotation of coreference and bridg-
ing relations with abstract nouns. Finally, we 
decided to distinguish between ?specific? and 
?generic? abstracts. If subjects to annotation 
have complements with specific reference, or 
they have unambiguously specific reference 
themselves, coreference between them is anno-
tated as textual coreference, type SPEC (20). In 
case of even a little doubt, we annotate textual 
coreference, type GEN (8).  
(20) Ve specifick?ch podm?nk?ch ?esk? 
ekonomiky r?st nezam?stnanosti v letech 
1991?1993 zna?n? zaostal za poklesem 
HDP. [?] Nejm?n? dvouprocentn? r?st 
?esk? ekonomiky  ji? letos. (=In the specific 
conditions of the Czech economy the growth 
of unemployment... This year at least a two 
percent growth of the Czech economy.) 
5.6 Coreference with verbal nouns 
With verbal nouns, both specifying and gener-
ic reference are possible as well. Textual corefer-
ence with verbal nouns is annotated according to 
the following strategy: 
- If both verbal nouns are specific, they re-
fer to a specific situation and their possi-
ble arguments are coreferential, the rela-
tion between them is annotated as textual 
coreference, type SPEC, cf. (21); 
- If both verbal nouns are generic, or rather 
if their arguments are generic, the relation 
between them is annotated as textual co-
reference, type GEN. Cf. (22); 
- If both verbal nouns are specific, but their 
arguments are not coreferential, coreferen-
109
tial relation between them is not annotat-
ed.; 
- If one verbal noun is specific and the other 
is generic, coreferential relation between 
them is not annotated. 
(21) Veden? Poji??ovny Investi?n? a Po?tov-
n? banky n?s upozornilo, ?e jejich poji??ov-
na nebyla za?azena mezi ty, kter? umo??uj? 
?razov? p?ipoji?t?n?, a? tuto slu?bu posky-
tuj?. Omlouv?me se za toto nedopat?en?, 
doty?n? redaktorka byla pokutov?na. (=The 
Insurance Investment and the Post Bank 
management has notified us that their in-
surance company was not included among 
those that allow casualty insurance, alt-
hough it provides this service. We apologize 
for this oversight, the editor who made the 
mistake was fined.) 
(22) Rychl?, av?ak i bezpe?n? vypo??d?n?. 
Rychlost vypo??d?n? burzovn?ch obchod? v 
?ase odpov?d? podle Ji??ho B?ra pot?eb?m. 
(= Fast, yet safe transaction. According to 
Ji??ho B?r?s opinion, the speed of transac-
tion corresponds to the needs.) 
However, such instructions are quite ambigu-
ous themselves, because, firstly, it is not always 
clear, what a specific verbal noun means and, 
secondly and most importantly, verbal nouns 
may have more than one argument, one of them 
being generic and other ? specific (Pergler 2010). 
Moreover, deverbatives themselves may refer to 
specific events that has already happened (thus 
tending to type SPEC if coreferent) or to hypo-
thetic or typical ones (then, in case of corefer-
ence, marked as GEN). 
6 Discussion 
Processing coreference of generic expressions, 
even in manual annotation, raises a number of 
problems, both theoretical and the applied, like 
complification of coreference resolving. As we 
have seen, the problem of generics is very lan-
guage-specific. Each resolving system trying to 
process coreference for generics will have to be 
oriented towards the specific linguistic descrip-
tion of the language in question. But even so, 
there are many possibilities of expressing generic 
expressions in every language, thus making the 
formal problem of extracting generics even in 
one separate language extremely difficult. 
 Generic expressions are analyzed relatively in 
more detail for English (Carlson 1980, Carlson -  
Pelletier 1995). However, this research relies 
heavily on language forms, it is not based on a 
large-scale corpus and it seems to be too theoret-
ical to be easily adapted to a large corpus (manu-
al or automatic) processing. On the other hand, 
Carlson?s classification of the reference reading 
of nouns could be used in practice for the distinc-
tion between generic and non-specific non-
generic NPs. Using our experience, we believe 
that it would make the annotation more con-
sistent: there would be less ambiguity between 
specific and generic readings. However, being 
helpful in resolving the cases from section 5.1, 
this decision would not resolve the majority of 
the remaining problematic cases. There still re-
main borderline cases with specific noun expres-
sions with possible valency frames (see 5.2), co-
reference with abstract and verbal nouns and so 
on. Separating the group of NPs with non-
specific reading, the coders should concentrate 
on quite specific semantic issues when annotat-
ing. Moreover, annotating more groups of nouns 
is always a costly and time-consuming task. 
From the theoretical point of view, one could 
imagine a scale: from noun expressions with 
concrete meaning and specific reading (say 
named entities) up to abstract nouns and 
deverbatives with generic reading. However, 
such an approach will not help to process generic 
NPs in large-scale corpora. 
7 Conclusion 
In this paper, we discussed the problem of anno-
tating coreference with generic expressions. 
Considering theoretical approaches has revealed 
that they tend to be very language specific. State-
of-the-art in annotating coreference relations for 
generic NPs needs unification but this is compli-
cated, as the formal representation of genericity 
differs dramatically from language to language 
and can be hardly unified. We have presented an 
approach to annotation of generic expressions in 
PDT and analyzed some typical problematic ex-
amples. We consider this issue to be far from 
being solved. Both, theoretical research and large 
data approaches should be further investigated.  
 
Acknowledgments 
We gratefully acknowledge support from the 
Grant Agency of the Czech Republic (grants 
P406/12/0658 and P406/2010/0875).  
 
110
References  
Eduard Bej?ek, Jan Haji?, Jarmila Panevov?, Jan 
Popelka, Lenka Smejkalov?, Pavel Stra??k, Magda 
?ev??kov?, Jan ?t?p?nek, Josef Toman and Zden?k 
?abokrtsk?. 2011. Prague Dependency Treebank 
2.5. Data/software, Charles University in Prague, 
MFF, ?FAL, Praha, Czech Republic 
(http://ufal.mff.cuni.cz/pdt2.5/). 
Greg Carlson. 1980. Reference to kinds in English. 
New York: Garland. 
Greg Carlson. 2005. Generic Reference. In The Ency-
clopedia of Language and Linguistics, 2nd Ed. 
Elsevier. 
Greg Carlson and F.J. Pelletier (eds.). 1995. The Ge-
neric Book. Chicago: University of Chicago Press. 
Denis Delfitto. 2006. Bare plurals. In Martin Everaert 
and Henk van Riemsdijk (eds.) The Blackwell 
Companion to Syntax. Blackwell Publishing, pp. 
214-259. 
Erhard Hinrichs, Sandra K?bler, Karin Naumann, 
Heike Telljohann, Julia Trushkina und Heike 
Zinsmeister. 2004. Recent Developments in Lin-
guistic Annotations of the T?Ba?D/Z Treebank. In 
Proceedings of the third workshop on treebanks 
and linguistic theories (TLT 2004). T?bingen. 
Jan Haji?, Silvie Cinkov?, Krist?na ?erm?kov?, Lucie 
Mladov?, Anja Nedolu?ko, Petr Pajas, Ji?? 
Semeck?, Jana ?indlerov?, Josef Toman, Krist?na 
Tom??, Mat?j Korvas, Magdal?na Rysov?, 
Kate?ina Veselovsk?, Zden?k ?abokrtsk?. 2009. 
Prague English Dependency Treebank 1.0. Insti-
tute of Formal and Applied Linguistics. Charles 
University in Prague. 
Zden?k Hlavsa. 1975. Denotace objektu a jej? 
prost?edky v sou?asn? ?e?tin?. (Object denotation 
and its means in current Czech). Prague, Czech 
Republic. 
Olga Krasavina and Christian Chiarcos. 2007. PoCoS 
? Potsdam Coreference Scheme. In Proceedings of 
ACL 2007, Prague, Czech Republic. 
Christopher Lyons. 1999.  Definiteness. Cambridge: 
Cambridge University Press. 
Lucie Mladov?. 2011. Annotating Discourse in Pra-
gue Dependency Treebank. In Workshop of Anno-
tation of Discourse Relations in Large Corpora at 
the conference Corpus Linguistics 2011 (CL 2011). 
Birmingham, Great Britain, July 2011. 
Anna Nedoluzhko, Ji?? M?rovsk?, Radek Ocel?k, Ji?? 
Pergler. 2009. Extended Coreferential Relations 
and Bridging Anaphora in the Prague Dependency 
Treebank. In Proceedings of the 7th Discourse 
Anaphora and Anaphor Resolution Colloquium 
(DAARC 2009). Goa, India, 2009, pp. 1?16. 
Anna Nedoluzhko. 2003. Ukazovac? z?jmeno ?ten? a 
generick? jmenn? fr?ze v ?e?tin?. In IV. 
mezin?rodn? setk?n? mlad?ch lingvist? Olomouc 
2003: Jazyky v kontaktu, jazyky v konfliktu. Olo-
mouc: Univerzita Palack?ho v Olomouci, pp. 85 ? 
96. 
Anna Nedoluzhko. 2011. Roz???en? textov? korefer-
ence a asocia?n? anafora. Koncepce anotace 
?esk?ch dat v Pra?sk?m z?vislostn?m korpusu. Pra-
gue, ?FAL. 
?lena V. Paducheva. 1985. Vyskazyvanie i ego 
sootnesennost s dejstvite?nos?ju. Moskva. 
Ji?? Pergler. 2010. Koreferen?n? ?et?zce s nespecific-
kou a generickou referenc? v ?e?tin? (Coreferential 
chains with non-specific and generic reference in 
Czech). Unpublished bachelor thesis. Prague.  
Massimo Poesio. 2004. The MATE/GNOME Propo-
sals for Anaphoric Annotation, Revisited. In Pro-
ceedings of SIGDIAL. 
Sameer S. Pradhan, Eduard Hovy, Mitch Marcus, 
Martha Palmer, Lance Ramshaw, and Ralph Weis-
chedel. 2007. Ontonotes: A unified relational se-
mantic representation. In Proceedings of the Inter-
national Conference on Se-mantic Computing 
(ICSC-07). Washington, DC, pp. 517?526. 
Marta Recasens and Ant?nia Mart?. 2010. AnCora-
CO: Coreferentially annotated corpora for Spanish 
and Catalan. In Language Resources and Evaluati-
on.  
Uriel Weinreich. 1966. On the Semantic Structure of 
Language. In Universals of Language, 2nd ed. 
Cambridge, Mass.  
 
 
111
Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 51?59,
Sofia, Bulgaria, August 9, 2013. c?2013 Association for Computational Linguistics
Translation of ?It? in a Deep Syntax Framework
Michal Nova?k, Anna Nedoluzhko and Zdene?k ?Zabokrtsky?
Charles University in Prague, Faculty of Mathematics and Physics
Institute of Formal and Applied Linguistics
Malostranske? na?me?st?? 25, CZ-11800
{mnovak,nedoluzko,zabokrtsky}@ufal.mff.cuni.cz
Abstract
We present a novel approach to the trans-
lation of the English personal pronoun it
to Czech. We conduct a linguistic analysis
on how the distinct categories of it are usu-
ally mapped to their Czech counterparts.
Armed with these observations, we design
a discriminative translation model of it,
which is then integrated into the TectoMT
deep syntax MT framework. Features in
the model take advantage of rich syntac-
tic annotation TectoMT is based on, exter-
nal tools for anaphoricity resolution, lex-
ical co-occurrence frequencies measured
on a large parallel corpus and gold coref-
erence annotation. Even though the new
model for it exhibits no improvement in
terms of BLEU, manual evaluation shows
that it outperforms the original solution in
8.5% sentences containing it.
1 Introduction
After it has long been neglected, retaining cohe-
sion of a text larger than a single sentence in Ma-
chine Translation (MT) has recently become a dis-
cussed topic. Correct translation of referential ex-
pressions is in many cases essential for humans to
grasp the meaning of a translated text.
Especially, the translation of pronouns attracts
a higher rate of interest. In the previous works
of Le Nagard and Koehn (2010), Hardmeier and
Federico (2010) and Guillou (2012), it has been
shown that current MT systems perform poorly in
producing the correct forms of pronouns. As re-
gards English, the personal pronoun it is the most
complicated case. Not only can it corefer with al-
most any noun phrase (making it hard to pick the
correct gender and number if the target language is
morphologically rich), but it can also corefer with
a larger discourse segment or play the role of a
filler in certain grammatical constructions.
In this work, we turn our attention to the transla-
tion of the English personal pronoun it into Czech.
Even if we ignore morphology and merge all re-
lated surface forms into one, we cannot find a
single Czech expression that would comprise all
functions of the English it. Moreover, there is no
simple one-to-one mapping from categories of it
to Czech expressions. For instance, one would ex-
pect that the translation of it which is coreferen-
tial with a noun phrase has to agree in number and
gender with the translation of its antecedent. How-
ever, there are cases when it is more suitable to
translate it as the demonstrative pronoun to, whose
gender is always neuter.
The aim of this work is to build an English-to-
Czech translation model for the personal pronoun
it within the TectoMT framework ( ?Zabokrtsky? et
al., 2008). TectoMT is a tree-to-tree translation
system with transfer via tectogrammatical layer,
a deep syntactic layer which follows the Prague
tectogrammatics theory (Sgall, 1967; Sgall et al,
1986) Therefore, its translation model outputs the
deep syntactic representation of a Czech expres-
sion. Selecting the correct grammatical categories
and thus producing a concrete surface form of a
deep syntactic representation is provided by the
translation synthesis stage, which we do not focus
on in this work.
The mapping between it and corresponding
Czech expressions depends on many aspects. We
address them by introducing features based on
syntactic annotation and anaphoricity resolver out-
put. Furthermore, we make use of lexical co-
occurrence counts aggregated on a large auto-
matically annotated Czech-English parallel corpus
CzEng 1.0 (Bojar et al, 2012). Coreference links
also appear to be a source of valuable features.1
In contrast to the related work, we prefer a dis-
criminative model to a commonly used generative
1However, we excluded them from the final model used
in MT as they originate from gold standard annotation.
51
model. The former allows us to feed it with many
syntactic and lexical features that may affect the
output, which would hardly be possible in the lat-
ter.
2 Related Work
Our work addresses a similar issue that has been
explored by Le Nagard and Koehn (2010), Hard-
meier and Federico (2010) and Guillou (2012).
These works attempted to incorporate informa-
tion on coreference relations into MT, aiming to
improve the translation of English pronouns into
morphologically richer languages. The poor re-
sults in the first two works were mainly due to im-
perfect automatic coreference annotation.
The work of Guillou (2012) is of special interest
to this work because it is also focused on English
to Czech translation and makes an extensive use
of the Prague Czech-English Dependency Tree-
bank 2.0 (PCEDT). Instead of automatic corefer-
ence links, they employed gold annotation, reveal-
ing further reasons of small improvements ? the
number of occurrences in the tranining data weak-
ened by including grammatical number and gen-
der in the annotation and availability of only a sin-
gle reference translation.
The first issue is a consequence of the assump-
tion that a Czech pronoun must agree in gen-
der and number with its antecedent. There are
cases, though, when demonstrative pronoun to fits
better and grammatical categories are not propa-
gated. Keeping grammatical information on its
antecedent may in this case result in probably not
harmful but still superfluous partitioning the train-
ing data.
Our work deals also with the second issue, how-
ever, at the cost of partial manual annotating.
The most significant difference of our work
compared to the abovementioned ones lies in the
MT systems used. Whereas they tackle the issue
of pronoun translation within the Moses phrase-
based system (Koehn et al, 2003), we rely on the
translation via deep syntax with TectoMT system
( ?Zabokrtsky? et al, 2008). Our approach is more
linguistically oriented, working with deep syntac-
tic representations and postponing the decisions
about the concrete forms to the synthesis stage.
3 Linguistic Analysis
In English, three main coarse-grained types of
it are traditionally distinguished. Referential it
points to a noun phrase in the preceding or the fol-
lowing context:
(1) Peter has finished writing an article and
showed it to his supervisor.
Anaphoric it refers to a verbal phrase or larger dis-
course segments (so-called discourse deixis).
(2) Peter has discussed the issue with his su-
pervisor and it helped him to finish the ar-
ticle.
Pleonastic it has no antecedent in the preced-
ing/following context and its presence is imposed
only by the syntactic rules of English.
(3) It is difficult to give a good example.
From the perspective of Czech, there are also
three prevailing types of how it can be translated.
The most frequent are personal pronouns or zero
forms.2 In Prague tectogrammatics theory zero
anaphors are reconstructed on the tectogrammat-
ical layer. Same as expressed personal pronouns,
they are represented by a node with the #PersPron
symbol, e.g.
(4) Bushova vla?da ozna?mila, z?e se svu?j pla?n
#PersPron pokus?? vzkr???sit.
The Bush administration has said it will
try to resurrect its plan.
The second typical possibility is the Czech demon-
strative pronoun to (= it, this), which is a form of
a pronoun ten in its neuter singular form, e.g.
(5) Analytik r?ekl, z?e to byla tato moz?nost
poz?adavku, ktera? pevne?js???m cena?m po-
mohla.
The analyst said that it was the possibility
of this demand that helped firm prices.
In many cases, it has no lexical counterpart in
the Czech translation, the English and Czech sen-
tences thus having a different syntactic structure.
These are cases like, for instance:
(6) Obchodn??ci uvedli, z?e je obt??z?ne? nove?
emise REMIC strukturovat, kdyz? se ceny
tolik me?n??.
Dealers noted that it?s difficult to struc-
ture new Remics when prices are moving
widely.
2Czech is a pro-drop language.
52
Figure 1: The mapping of the types of English it
to Czech translations.
There are also some other possibilities of how it
can be translated into Czech, such as the repeti-
tion of the antecedent noun, different genders of
the demonstrative ten (=it, this) in the anaphoric
position, using synonyms and hyperomyns. How-
ever, these cases are not so frequent and they rarely
cannot be converted to one of the three broader
categories.
The correspondence between the course-
grained types of English it and its possible Czech
translations is not one-to-one. As seen from
Figure 1, a personal pronoun/zero anaphora
translates to the referential it (see example 4) and
no lexical counterpart is used when translating the
pleonastic it (see example 6).
However, all types of it can be translated as a
neuter demonstrative to. The typical case ?it refer-
ring to VPs/larger discourse segments = to? was
demonstrated in (5).
The mapping ?referential it = to? is common for
cases where the referent is attributed some further
characteristics, mostly in constructions with a verb
to be like ?It is something.?, such as (7).3 This
is an interesting case for Czech, because a gen-
der and number agreement between the antecedent
and the anaphoric to is generally absent.
(7) Some investors say Friday?s sell-off was a
good thing. ?It was a healthy cleansing,?
says Michael Holland.
Ne?kter??? investor?i r???kaj??, z?e pa?tec?n??
vy?prodej byla dobra? ve?c. ?Byla to zdrava?
oc?ista,? r???ka? Michael Holland.
The ?cleft sentences? (see example 8) and some
other syntactic constructions are the case when
pleonastic it is translated into Czech with the
demonstrative to.
3We suspect that it holds also for he/she/they but such a
claim is not yet empirically supported. For the sake of sim-
plicity, we conduct our research only for it.
(8) But it is Mr. Lane, as movie director, who
has been obsessed with refitting Chaplin?s
Little Tramp in a contemporary way.
Ale je to Lane jako filmovy? rez?ise?r, kdo je
posedly? t??m, z?e zmodernizuje Chaplinu?v
film ?Little Tramp (Maly? tula?k)?.
In some cases, both translations of pleonastic it
are possible: neuter demonstrative to or a different
syntactic construction with no lexical counterpart
of it. Compare the examples from PCEDT where
it with similar syntactic function was translated by
changing the syntactic structure in (9) and using a
neuter to in (10):
(9) ?It was great to have the luxury of time,?
Mr. Rawls said.
?Bylo skve?le?, z?e jsme me?li dostatek c?asu,?
r?ekl Rawls.
(10) ?On days that I?m really busy,? says Ms.
Foster, ?it seems decadent to take time off
for a massage.?
?Ve dnech, kdy ma?m opravdu mnoho
pra?ce,? r???ka? pan?? Fosterova?, ?to vypada?
zvrhle, kdyz? si vyhrad??m c?as na masa?z?.?
4 Translation via Deep Syntax
Following a phrase-based statistical MT approach,
it may be demanding to tackle issues that arise
when translating between typologically different
languages. Translation from English to Czech is a
typical example. One has to deal with a rich mor-
phology, less constrained word order, changes in
clauses bindings, pro-drops etc.
In this work, we make use of the English to
Czech translation implemented within the Tec-
toMT system, first introduced by ?Zabokrtsky? et al
(2008). In contrast to the phrase-based approach,
TectoMT performs a tree-to-tree machine transla-
tion. Given an input English sentence, the trans-
lation process is divided into three stages: analy-
sis, transfer and synthesis. TectoMT at first con-
ducts an automatic analysis including POS tag-
ging, named entity recognition, syntactic parsing,
semantic role labeling, coreference resolution etc.
This results in a deep syntactic representation of
the English sentence, which is subsequently trans-
ferred into Czech, with the translation of lexical
and grammatical information being provided via
several factors. The process proceeds with a rule-
53
based synthesis stage, when a surface Czech sen-
tence is generated from its deep syntactic struc-
ture.
Deep syntactic representation of a sentence fol-
lows the Prague tectogrammatics theory (Sgall,
1967; Sgall et al, 1986). It is a dependency
tree whose nodes correspond to the content words
in the sentence. Personal pronouns missing on
the surface are reconstructed in special nodes.
Nodes are assigned semantic roles (called func-
tors) and grammatical information is comprised in
so called grammatemes. Furthermore, tectogram-
matical representation is a place where corefer-
ence relations are annotated.
4.1 Model of it within TectoMT
The transfer stage, which maps an English tec-
togrammatical tree to a Czech one, is a place
where the translation model of it is applied. For
every English node corresponding to it, a feature
vector is extracted and fed into a discriminative re-
solver that assigns one of the three classes to it ?
PersPron, To and Null, corresponding to the
main Czech types introduced in Section 3.
If labeled as PersPron, the English node
is mapped to a Czech #PersPron node and the
English coreference link is projected. During
the synthesis, it is decided whether the pronoun
should be expressed on a surface, its gender and
number are copied from the antecedent?s head and
finally the correct form (if any) is generated.
Obtaining class To makes things easier. The
English node is only mapped to a Czech node con-
taining the pronoun ten with its gender and num-
ber set to neuter singular, so that later the correct
form to will be generated.
Last, if it is assigned Null, no corresponding
node on the Czech side is generated, but the Czech
counterpart of the governing verb is forced to be in
neuter singular.
5 Prague Czech-English Dependency
Treebank as a source of data
The Prague Czech-English Dependency Treebank
(Hajic? et al, 2011, PCEDT) is a manually parsed
Czech-English parallel corpus comprising over 1.2
million words for each language in almost 50,000
sentence pairs. The English part contains the en-
tire Penn Treebank?Wall Street Journal Section
(Linguistic Data Consortium, 1999). The Czech
part consists of translations of all the texts from
the English part. The data from both parts are
annotated on three layers following the theory of
Prague tectogrammatics ? the morphological layer
(where each token from the sentence gets a lemma
and a POS tag), the analytical layer (surface syn-
tax in the form of a dependency tree, where each
node corresponds to a token in the sentence) and
the tectogrammatical representation (see Section
4).
Sentences of PCEDT have been automatically
morphologically annotated and parsed into ana-
lytical dependency trees.4 The tectogrammatical
trees in both language parts have been annotated
manually (Hajic? et al, 2012). The nodes of Czech
and English trees have been automatically aligned
on analytical as well as tectogrammatical layer
(Marec?ek et al, 2008).
5.1 Extraction of Classes
The shortcomings of the automatic alignment
is particularly harmful for pronouns and zero
anaphors, which can replace a whole range of con-
tent words and their meaning is inferred mainly
from the context. The situation is better for verbs
as their usual parents in dependency trees: since
they carry meaning in a greater extent, their auto-
matic alignment is of a higher quality.
Thus, we did not search for a Czech counterpart
of it by following the alignment of it itself. Using
the fact that the verb alignment is more reliable
and functors in tectogrammatical trees have been
manually corrected, we followed the alignment of
the parent of it (a verb) and selected the Czech sub-
tree with the same tectogrammatical functor as it
had on the English side. If the obtained subtree
is a single node of type #PersPron or ten, we as-
signed class PersPron or To, respectively, to the
corresponding it. This approach relies also on the
assumption that semantic roles do not change in
the translation.
The automatic acquisition of classes covered
more than 60% of instances, the rest had to be la-
beled manually. During the annotation, we obeyed
the following rules:
1. If a demonstrative pronoun to is present in the
Czech sentence or if a personal pronoun is
either present or unexpressed, assign the in-
stance to the corresponding class.
4The English dependency trees were built by automati-
cally transforming the original phrase-structure annotation of
the Penn Treebank.
54
2. Otherwise, ignore the Czech translation pro-
vided in the corpus and follow the most sim-
plistic possible translation which would still
be correct. Assign the instance to the class
which fits it the best.
Note that it may happen that none of the three
options fits, because it is either an idiomatic ex-
pression or larger structural modifications are re-
quired. Such cases are very rare and we left them
out of the data.
The manual annotation was a bottleneck. We
managed to tag the complete testing data, but were
only able to annotate more than just 1/6 of the
training data due to time reasons. We only use
a corresponding proportion of the automatically
labeled training instances in order to respect the
overall distribution.
5.2 Extraction of Features
Given the linguistically supported observation on
both manually and automatically annotated tree-
banks, we designed features to differentiate be-
tween the ways it is translated.
Since this work focuses on MT with transfer via
deep-syntactic layer, it is possible for the proposed
features to exploit morphological, syntactic and a
little of semantic information present on various
annotation layers.
Unlike the target classes, which have to be as-
signed as accurately as possible, extracted fea-
tures must follow the real-world scenario of MT
? the only information that is given is the source
sentence. Thus, whereas extracting classes may
exploit the gold standard linguistic annotation, it
cannot be employed in feature extraction. We ex-
tract them from text automatically annotated by
the same pipeline that is used in the TectoMT anal-
ysis stage.
However, there is an exception where we violate
this approach ? coreference. Performance of state-
of-the-art coreference resolvers is still far from the
ideal, especially for distinguishing between pro-
nouns referring to noun phrases and those refer-
ring to clauses or wider discourse segments. Sim-
ilarly to the work of Guillou (2012) we wanted
to isolate the problem of translating referential
expressions from the task of resolving the entity
they refer to. Therefore, we opted for extracting
the coreferential features from the gold annotation
projected onto automatically analyzed trees. Note
that the results achieved using these features have
to be considered an upper bound for a given set-
ting.
Although the mapping between Czech transla-
tion of it and English categories of it does not al-
low to translate it directly, the category of it es-
timated by an anaphoricity resolver might be a
promising feature. We therefore constructed a bi-
nary feature based on the output of a system iden-
tifying whether a pronoun it is coreferential or
not. We employed the NADA resolver (Bergsma
and Yarowsky, 2011)5 exploiting the web-scale n-
gram data and its tree-based extension presented
in (Veselovska? et al, 2012).
Some verbs are more likely to bind with it that
refers to a longer utterance. Such it is quite con-
sistently translated as a demonstrative to. This
motivated incorporating a parent lemma of an oc-
currence of it into the feature set. However, the
training data is too small to be a sufficient sample
from a distribution over lexical properties. Hence,
we took advantage of the automatically annotated6
Czech-English corpus CzEng 1.0 (Bojar et al,
2012) that comprises more than 15 million sen-
tence pairs. In the manner described in Section
5.1, we collected co-occurrence counts between
a functor that the given it possesses concatenated
with a lemma of its verbal parent and a Czech
counterpart having the same functor (denoted as
csit). We filtered out all occurrences where csit
was neither #PersPron nor ten. Then, for both val-
ues of csit a feature is constructed by looking up
counts for a concrete occurrence in the collected
counts and quantized into 4-5 bins (Bansal and
Klein, 2012) following the formula:
bin(log(
count(functor : parent ? csit)
count(functor : parent)count(csit)
)).
Linguistic analysis carried out in Section 3 sug-
gests the following syntax-oriented features re-
lated to the verb to be. Some nominal predicates
tend to be translated as to, even though it is usually
coreferential in such expressions (see example 7).
So the corresponding binary feature fires if it is a
subject and its parent is the verb to be having an
object (Figure 2a).
Similarly, adjectival predicates that are not fol-
lowed by a subordinating clause connected with
5A probability value returned by this tool was binarized at
a threshold 0.5
6Using the same annotation layers as in PCEDT and Tec-
toMT, i.e. in accordance with the Prague tectogrammatics
theory.
55
Figure 2: Syntactic features capturing typical con-
structions with a verb be.
the main clause by the English connectives to or
that are usually referential and translated as to,
too. We proposed a feature describing these cases,
illustrated in Figure 2b.
In contrast, if an adjectival predicate is followed
by a subordinating clause with the verb being finite
and connected to the main clause by a conjunction
that, in majority of cases it is a pleonastic usage of
it translated as a null subject (see example 6). A
schema of the feature is depicted in Figure 2c.
Being definitely pleonastic, it in cleft sentences
is expressed in Czech either by to or by sentence
rearranging (see example 8). We target this phe-
nomenon by another feature being fired if it is a
subject of the verb to be and if this verb has an ob-
ject and is followed by a relative clause (see Figure
2d).
Finally, we designed two features exploiting
coreference relations. The first one simply indi-
cates if it has an antecedent, while the second fires
if any of the antecedents in the coreferential chain
is a verb phrase. As we noted above, these fea-
tures are based on the gold standard annotation of
coreference.
5.3 Data Description
The data for training and testing a discriminative
translation model of the personal pronoun it were
extracted from PCEDT with classes and features
obtained as described in Section 5.1 and 5.2, re-
spectively. Due to the limited amount of manually
annotated training data, the training set extracted
from sections 00 ? 19 was reduced from 5841 to
940 instances, though. The testing set was an-
notated thoroughly, thus containing 543 instances
extracted from sections 20 ? 21. Every instance
represents an occurrence of it in PCEDT. The dis-
Class Train Test
PersPron 576 322
To 231 138
Null 133 83
Table 1: Distribution of classes in the data sets.
tribution of target classes in the data is shown in
Table 1.
6 Experiments
Experiments were conducted in two settings that
differ in the usage of features extracted from gold
coreferential relations.
To mitigate a possible error caused by a wrong
classifier choice, we built several models based on
various Machine Learning classification methods.
If not explicitly mentioned, the methods below are
applied with default parameters:
? Vowpal Wabbit (Langford, 2012). Binary
logistic regression with one-against-all strat-
egy for handling multiple classes. The opti-
mum has been found using the online method
(Stochastic Gradient Descent). We varied the
parameters of the number of passes over the
data and the L2 regularization weight.
? AI::MaxEntropy.7 Multiclass logistic re-
gression.8 The optimum has been found us-
ing the batch method (L-BFGS).
? sklearn.neighbors.9 k-nearest neighbors
classifier with the parameter k being varied.
? sklearn.tree. Decision tree classifier.
? sklearn.SVC. Support Vector Machines with
one-against-one strategy to handle multiple
classes. We varied the choice of a kernel.
The accuracy evaluated on both training and test
sets is shown in Table 2 (columns Acc:Train and
Acc:Test). The baseline resolver simply picks the
most frequent class in the training set, which is
PersPron. For both experimental settings, the
standard deviation measured on the test set is less
than 1% in total, if the method?s best configuration
of parameters is taken and the result on decision
trees, which we did not tune, is excluded. This
shows that all classifiers are consistent in their de-
cisions.
7http://search.cpan.org/
?
laye/
AI-MaxEntropy-0.20/
8In the field of NLP also called Maximum Entropy.
9All classifiers labeled as sklearn.* are implemented in
the Scikit-learn Python library (Pedregosa et al, 2011).
56
all feats all feats + coref
ML Method Acc:Train Acc:Test BLEU Acc:Train Acc:Test
Baseline 60.70 59.30 0.1401 60.70 59.30
Original TectoMT ? ? 0.1404 ? ?
Vowpal Wabbit (passes=30) 90.62 75.69 ? 90.83 75.87
Vowpal Wabbit (passes=20) 89.99 76.43 0.1403 90.20 76.98
Vowpal Wabbit (passes=10) 87.78 76.24 ? 87.78 76.61
Vowpal Wabbit (passes=30, l2=0.001) 71.23 66.11 ? 83.03 77.16
Vowpal Wabbit (passes=20, l2=0.001) 82.19 74.95 ? 78.19 74.40
Vowpal Wabbit (passes=10, l2=0.001) 75.03 70.17 ? 72.81 70.17
Vowpal Wabbit (passes=30, l2=0.00001) 90.52 75.69 ? 90.94 76.06
Vowpal Wabbit (passes=20, l2=0.00001) 89.99 76.43 ? 90.09 76.98
Vowpal Wabbit (passes=10, l2=0.00001) 87.67 76.24 ? 87.67 76.61
AI::MaxEntropy 85.99 76.61 0.1403 86.09 76.98
sklearn.neighbors (k=1) 91.57 71.64 ? 93.36 72.19
sklearn.neighbors (k=3) 84.62 72.01 ? 84.93 71.82
sklearn.neighbors (k=5) 84.93 74.77 0.1403 84.72 75.87
sklearn.neighbors (k=10) 82.51 73.30 ? 83.14 75.87
sklearn.tree 93.36 73.66 0.1403 94.10 71.82
sklearn.SVC (kernel=linear) 90.83 75.51 0.1402 91.15 76.80
sklearn.SVC (kernel=poly) 60.70 59.30 ? 60.70 59.30
sklearn.SVC (kernel=rbf) 71.23 68.69 ? 73.76 71.27
Table 2: Intrinsic (accuracy on the training and test data) and extrinsic (BLEU score) evaluation of
translation model of it in configuration with (all feats) and without gold coreferential features (all feats
+ coref).
By introducing linguistically motivated features
exploiting the deep-syntactic description of the
sentence, we gained 17% in total over the base-
line. Moreover, adding features based on the gold
coreference annotation results in a further 0.5%
improvement.
7 Evaluation on MT
Although intrinsic evaluation as performed in Sec-
tion 6 can give us a picture of how accurate the
translation model might be, the main purpose of
this work is to integrate it in a full-fledged MT
system. As explained in Section 4, this component
is tailored for TectoMT ? an MT system where the
transfer is provided through a deep-syntactic layer.
The extrinsic evaluation of the proposed method
was carried out on the English-Czech test set for
WMT 2011 Shared Translation Task (Callison-
Burch et al, 2011).10 This data set contains 3,003
English sentences with one Czech reference trans-
lation, out of which 430 contain at least one occur-
rence of it.
Since this test set is provided with no annota-
tion of coreferential links, the model of it that is
involved in experiments on the end-to-end transla-
tion was trained on a complete feature set exclud-
10http://www.statmt.org/wmt11/test.tgz
ing the coreferential features using the Machine
Learning method that performed best in the intrin-
sic test, i.e. AI::MaxEntropy (see Section 6).
The new method was compared to the rule-
based approach originally used in TectoMT, which
works as follows. In the transfer stage, all occur-
rences of it are translated to a demonstrative ten.
In the synthesis stage, another rule is fired, which
determines whether ten is omitted on the surface.
Then, omitting it corresponds either to a structural
change (Null class) or an unexpressed personal
pronoun (a subset of PersPron class). It makes
this original approach difficult to compare with the
scores in Table 2, as the translation model of it
is applied in the transfer stage, where we do not
know yet if a personal pronoun is to be expressed
or not. Thus, we consider it the most appropriate
to use final translated sentences produced by two
versions of TectoMT in order to compare the dif-
ferent way they handle it.
The shift from the original settings to a new
model for it results in 166 changed sentences. In
terms of BLEU score, we observe a marginal drop
from 0.1404 to 0.1403 when using the new ap-
proach.11 Other classifiers achieved the same or
11For comparison, the best system so far ? Chimera (Bojar
et al, 2013) achieves 0.1994 on the same test set. Chimera
combines Moses, TectoMT and rule-based corrections.
57
new better than old 24
old better than new 13
both equally wrong 9
both equally correct 4
Table 3: The results of manual evaluation con-
ducted on 50 sentences translated by TectoMT in
the original settings (old) and with the new trans-
lation model for it (new)
similar score which correlates with the findings
from intrinsic evaluation (see Table 2). It accords
with a similar experience of Le Nagard and Koehn
(2010) and Guillou (2012) and gives another evi-
dence that the BLEU metric is inaccurate for mea-
suring pronoun translation.
Manual evaluation gives a more realistic view.
We randomly sampled 50 out of the 166 sentences
that differ and one annotator assessed which of
the two systems gave a better translation. Table
3 shows that in almost half of the cases the change
was an improvement. Including the sentences that
are acceptable for both settings, the new approach
picked the correct Czech counterpart of it in 22%
more sentences than the original approach. Since
the proportion of the changed sentences accounts
for almost 39% of all sentences containing it, the
overall proportion of improved sentences with it is
around 8.5% in total.
8 Discussion
Inspecting the manually evaluated translation for
types of improvements and losses, we have found
that in none of the changed sentences the original
system decided to omit ten (obtained by the rule)
on the surface. It shows that the new approach
agrees with the original one on the way of omit-
ting personal pronouns and mainly addresses the
overly simplistic assignment of the demonstrative
ten.
The distribution of target classes over cor-
rected sentences is almost uniform. In 13 out
of 24 improvements, the new system succeeded
in correctly resolving the Null class while in
the remaining 11 cases, the corrected class was
PersPron. It took advantage mostly of the
syntax-based features in the former and sugges-
tions given by the NADA anaphoricity resolver in
the latter.
Examining the errors, we observed that the ma-
jority of them are incurred in the structures with
?it is?. These errors stem mostly from incorrect
activation of syntactic features due to parsing and
POS tagging errors. Example 11 (the Czech sen-
tence is an MT output) shows the latter, when the
POS tagger erroneously labeled the word soy as an
adjective. That resulted in activating the feature
for adjectival predicates followed by that (Figure
2c) instead of a feature indicating cleft structures
(Figure 2d), thus preferring the label Null to the
correct To.
(11) SOURCE: It is just soy that all well-known
manufacturers use now.
TECTOMT: Je to jen so?jove?, z?e zna?m??
vy?robci vs?ech pouz???vaj?? te?d.
9 Conclusion
In this work we presented a novel approach to
dealing with the translation of the English personal
pronoun it. We have shown that the mapping be-
tween the categories of it and the ways of trans-
lating it to Czech is not one-to-one. In order to
deal with this, we designed a discriminative trans-
lation model of it for the TectoMT deep syntax MT
framework.
We have built a system that outperforms its pre-
decessor in 8.5% sentences containing it, taking
advantage of the features based on rich syntactic
annotation the MT system provides, external tools
for anaphoricity resolution and features capturing
lexical co-occurrence in a massive parallel corpus,
The main bottleneck that hampered bigger im-
provements is the manual annotation of the train-
ing data. We managed to accomplish it just on 1/6
of the data, which did not provide sufficient evi-
dence for some specific features.
Our main objective of the future work is thus
to reduce a need for manual annotation by dis-
covering ways of automatic extraction of reliable
classes from a semi-manually annotated corpus
such as PCEDT.
Acknowledgments
This work has been supported by the Grant
Agency of the Czech Republic (grants
P406/12/0658 and P406/2010/0875), the grant
GAUK 4226/2011 and EU FP7 project Khresmoi
(contract no. 257528). This work has been using
language resources developed and/or stored and/or
distributed by the LINDAT-Clarin project of the
Ministry of Education of the Czech Republic
(project LM2010013).
58
References
Mohit Bansal and Dan Klein. 2012. Coreference Se-
mantics from Web Features. In Proceedings of the
50th Annual Meeting of the ACL: Long Papers ? Vol-
ume 1, pages 389?398, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Shane Bergsma and David Yarowsky. 2011. NADA:
A Robust System for Non-Referential Pronoun De-
tection. In DAARC, pages 12?23, Faro, Portugal,
October.
Ondr?ej Bojar, Zdene?k ?Zabokrtsky?, Ondr?ej Dus?ek, Pe-
tra Galus?c?a?kova?, Martin Majlis?, David Marec?ek, Jir???
Mars???k, Michal Nova?k, Martin Popel, and Ales? Tam-
chyna. 2012. The Joy of Parallelism with CzEng
1.0. In Proceedings of LREC 2012, Istanbul, Turkey,
May. ELRA, European Language Resources Associ-
ation.
Ondr?ej Bojar, Rudolf Rosa, and Ales? Tamchyna. 2013.
Chimera ? Three Heads for English-to-Czech Trans-
lation. In Proceedings of the Eight Workshop on Sta-
tistical Machine Translation. Under review.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Omar Zaidan. 2011. Findings of the 2011
Workshop on Statistical Machine Translation. In
Proceedings of the Sixth Workshop on Statisti-
cal Machine Translation, pages 22?64, Edinburgh,
Scotland, July. Association for Computational Lin-
guistics.
Liane Guillou. 2012. Improving Pronoun Translation
for Statistical Machine Translation. In Proceedings
of the Student Research Workshop at the 13th Con-
ference of the EACL, pages 1?10, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Jan Hajic?, Eva Hajic?ova?, Jarmila Panevova?, Petr Sgall,
Silvie Cinkova?, Eva Fuc???kova?, Marie Mikulova?, Petr
Pajas, Jan Popelka, Jir??? Semecky?, Jana ?Sindlerova?,
Jan ?Ste?pa?nek, Josef Toman, Zden?ka Ures?ova?, and
Zdene?k ?Zabokrtsky?. 2011. Prague Czech-English
Dependency Treebank 2.0.
Jan Hajic?, Eva Hajic?ova?, Jarmila Panevova?, Petr
Sgall, Ondr?ej Bojar, Silvie Cinkova?, Eva Fuc???kova?,
Marie Mikulova?, Petr Pajas, Jan Popelka, Jir???
Semecky?, Jana ?Sindlerova?, Jan ?Ste?pa?nek, Josef
Toman, Zden?ka Ures?ova?, and Zdene?k ?Zabokrtsky?.
2012. Announcing Prague Czech-English Depen-
dency Treebank 2.0. In Proceedings of the 8th In-
ternational Conference on Language Resources and
Evaluation (LREC 2012), pages 3153?3160. ELRA.
Christian Hardmeier and Marcello Federico. 2010.
Modelling Pronominal Anaphora in Statistical Ma-
chine Translation. In Marcello Federico, Ian Lane,
Michael Paul, and Franc?ois Yvon, editors, Proceed-
ings of the seventh International Workshop on Spo-
ken Language Translation (IWSLT), pages 283?289.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical Phrase-based Translation. In Pro-
ceedings of the 2003 Conference of the NAACL HLT
? Volume 1, pages 48?54, Stroudsburg, PA, USA.
Association for Computational Linguistics.
John Langford. 2012. Vowpal Wabbit.
Ronan Le Nagard and Philipp Koehn. 2010. Aid-
ing Pronoun Translation with Co-Reference Resolu-
tion. In Proceedings of the Joint Fifth Workshop on
Statistical Machine Translation and MetricsMATR,
pages 252?261, Uppsala, Sweden, July. Association
for Computational Linguistics.
Linguistic Data Consortium. 1999. Penn Treebank 3.
LDC99T42.
David Marec?ek, Zdene?k ?Zabokrtsky?, and Va?clav
Nova?k. 2008. Automatic Alignment of Czech and
English Deep Syntactic Dependency Trees. In Pro-
ceedings of the Twelfth EAMT Conference, pages
102?111.
Fabian Pedregosa, Gae?l Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, Jake Vanderplas, Alexan-
dre Passos, David Cournapeau, Matthieu Brucher,
Matthieu Perrot, and ?Edouard Duchesnay. 2011.
Scikit-learn: Machine Learning in Python. Jour-
nal of Machine Learning Research, 12:2825?2830,
November.
Petr Sgall, Eva Hajic?ova?, and Jarmila Panevova?. 1986.
The Meaning of the Sentence in Its Semantic and
Pragmatic Aspects. D. Reidel Publishing Company,
Dordrecht.
Petr Sgall. 1967. Generativn?? popis jazyka a c?eska?
deklinace. Academia, Prague, Czech Republic.
Kater?ina Veselovska?, Giang Linh Nguy, and Michal
Nova?k. 2012. Using Czech-English Parallel Cor-
pora in Automatic Identification of It. In The Fifth
Workshop on Building and Using Comparable Cor-
pora, pages 112?120.
Zdene?k ?Zabokrtsky?, Jan Pta?c?ek, and Petr Pajas. 2008.
TectoMT: Highly Modular MT System with Tec-
togrammatics Used as Transfer Layer. In Proceed-
ings of the Third Workshop on Statistical Machine
Translation, pages 167?170, Stroudsburg, PA, USA.
Association for Computational Linguistics.
59
