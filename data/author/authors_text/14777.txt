Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 110?119,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
Stability and Accuracy in Incremental Speech Recognition
Ethan O. Selfridge?, Iker Arizmendi?, Peter A. Heeman?, and Jason D. Williams?
? Center for Spoken Language Understanding, Oregon Health & Science University, Portland, OR
?AT&T Labs ? Research, Shannon Laboratory, Florham Park, NJ
{selfridg,heemanp}@ohsu.edu {iker,jdw}@research.att.com
Abstract
Conventional speech recognition ap-
proaches usually wait until the user
has finished talking before returning a
recognition hypothesis. This results in
spoken dialogue systems that are unable
to react while the user is still speaking.
Incremental Speech Recognition (ISR),
where partial phrase results are returned
during user speech, has been used to
create more reactive systems. However,
ISR output is unstable and so prone to
revision as more speech is decoded. This
paper tackles the problem of stability
in ISR. We first present a method that
increases the stability and accuracy of
ISR output, without adding delay. Given
that some revisions are unavoidable,
we next present a pair of methods for
predicting the stability and accuracy of
ISR results. Taken together, we believe
these approaches give ISR more utility for
real spoken dialogue systems.
1 Introduction
Incremental Speech Recognition (ISR) enables a
spoken dialogue system (SDS) to react quicker
than when using conventional speech recogni-
tion approaches. Where conventional methods
only return a result after some indication of user
completion (for example, a short period of si-
lence), ISR returns partial phrase results while
the user is still speaking. Having access to a real-
time stream of user speech enables more natural
behavior by a SDS, and is a foundation for cre-
ating systems which take a more active role in
conversations.
Research by Fink et al(1998) and Skantze
& Schlangen (2009), among others, has demon-
strated the efficacy of ISR but has also drawn
attention to a significant obstacle to widespread
use: partial phrase results are generally unsta-
ble and so, as more speech is decoded, are prone
to revision. For example, the ISR component in
a bus information SDS may return the partial
?leaving from Hills?, where ?Hills? is a neigh-
borhood name. It may then return the revi-
sion ?leaving from Pittsburgh?, which the sys-
tem must handle gracefully. Given this propen-
sity to revise, a Stability Measure (SM) ? like-
lihood of a partial result remaining unchanged
compared to the final result ? is necessary for
optimal incremental system behavior. Further-
more, since a stable partial may still be inaccu-
rate, a Confidence Measure (CM) ? likelihood
of partial correctness ? is also necessary.
Effective ISR enables systems to participate in
more dynamic turn-taking. For instance, these
two measures would enable an SDS to identify
inaccurate recognition results while the user is
still speaking. The SDS could then interrupt
and prompt the user to start again. On the
other hand, ISR allows systems to handle pauses
gracefully. If the SDS recognizes that an utter-
ance is incomplete (though stable and accurate),
it could give the user more time to speak before
reacting.
We present two contributions specific to the
use of ISR. First, we characterize three ap-
proaches to ISR which make different trade-offs
between stability and the number of partials
generated. We then present a novel hybrid ap-
proach that combines their strengths to increase
110
stability without adding latency. However, even
with this method, some partial results are still
later revised. The second contribution of the
paper is to present a pair of methods which pre-
dict the stability and accuracy of each partial
result. These two measures are designed for use
in concert by dialogue systems, which must de-
cide whether to act on each partial result in real
time.
2 Background and Related Work
We now describe modern speech recognition
methodology, the production of partial phrase
results, and the advantages and deficiencies of
ISR. In this we seek only to provide a topical
foundation, and not a comprehensive review.
Most modern speech recognition engines use
Hidden-Markov Models and the Viterbi algo-
rithm to decode words from audio. Decod-
ing employs three models: an acoustic model,
which assigns probabilities to speech audio given
a phone; a lexicon, which specifies phone se-
quences for a word; and a language model, which
specifies the probability of a word sequence. The
aim of the decoding process is to find the N most
probable word sequences given the audio spoken
and these three models.
Two useful but different forms of language
models are commonly used in spoken dialogue
systems. A Rule-based Language Model (RLM)
specifies a list of valid sentences which may be
recognized, usually via expansion rules. By con-
trast, a Statistical Language Model (SLM) spec-
ifies a vocabulary of words, allowing arbitrary
sentences to be formed. Both models specify
probabilities over their respective sets ? RLMs
via whole-sentence probabilities, and SLMs via
probabilities of short word sequences called N-
grams. In an SLM, special word symbols are
used to represent the beginning and end of the
phrase, so the probability of beginning or ending
phrases with words can be modeled.
As speech frames are received, the recognizer
builds up a lattice which compactly describes the
probable sequences of words decoded from the
audio. In conventional turn-based speech recog-
nition, decoding continues until the user finishes
speaking. Once the user has finished, the engine
searches the lattice for the most probable word
sequence and returns this to the dialogue man-
ager. By contrast, in ISR the engine inspects
the lattice as it is being built, and returns partial
results to the dialogue manager as they become
available. A key issue for ISR is that partial
results may later be revised, because as more
speech is received and the lattice is extended, a
different path may become the most probable.
In other words, partial results are unstable in
the sense that they may later be revised. Note
that stability is not the same as accuracy: a par-
tial result may be accurate (correct so far) but
unstable, because it is later revised. Similarly, a
stable result may not be accurate.
In the literature, ISR has been proposed for
dialogue systems to enable them to engage in
more natural, human-like interactions. Stud-
ies have shown that incremental systems react
faster than non-incremental ones, and are well-
liked by users because of their naturalness (Aist
et al, 2007; Skantze and Schlangen, 2009). Aist
et al (2007) found that incremental speech
recognition yielded 20% faster task completion.
Moreover, adding ISR improved users? satisfac-
tion with the interaction; the authors attributed
this improvement to ?naturalness?: ?incremen-
tal systems are more like human-human con-
versation than their non-incremental counter-
parts.? Skantze & Schlangen (2009) observed a
similar trend, finding that an incremental sys-
tem was ?clearly preferred? since it ?was ex-
perienced as more pleasant and human-like?,
though it did not actually outperform the non-
incremental system in a number dictation task.
Some recent work has focused on incremen-
tal natural language understanding (NLU). De-
Vault et al (2009) showed that when using a
relatively small number of semantic possibili-
ties the correct interpretation could be predicted
by early incremental results. Schlangen et al
(2009) demonstrated that an incremental refer-
ence resolver could identify the correct reference
out of 12 more than 50% of the time. This
type of NLU can use context and other infor-
mation to be somewhat resilient to errors, and
word recognition inaccuracies may not yield a
111
change in understanding. In this paper we focus
on improving accuracy and stability at the word
level; we belief that improvements at the word
level are likely to improve performance at the
understanding level, although we do not evalu-
ate this here.
A number of researchers have described meth-
ods for evaluating and improving the stability of
ISR results (Baumann et al, 2009; Fink et al,
1998). Baumann, Atterer, & Schlangen spoke
directly to stability by comparing partial phrase
results against the ?final hypothesis produced
by the ASR?. They show that increasing the
amount of ?right context? ? the amount of
speech after the end of the putative partial result
? increases the stability of the partials. Fink et
al. (1998) also used a right context delay to de-
crease the word error rate of ISR results.
A key limitation of these past efforts to im-
prove stability is that adding right context nec-
essarily incurs delay, which degrades responsive-
ness and erodes the overall benefits of ISR. Fur-
thermore, past work has not addressed the prob-
lem of identifying which partials are likely to be
revised. In this paper, we tackle both of these
problems. We first present a method for im-
proving stability by considering features of the
lattice itself, without incurring the delay asso-
ciated with adding right context. Additionally,
since some partials will still be revised, we then
propose a method of scoring the stability of par-
tial speech recognition results.
3 Three approaches to ISR
We now describe three approaches to ISR: Ba-
sic, Terminal, and Immortal. Basic ISR simply
returns the most likely word sequence observed
after some number of speech frames has been de-
coded (in our case every 3 frames or 30ms). This
is the least restrictive approach, and we believe
is the method used by recent ISR research.
Terminal ISR, a more restrictive approach,
finds a partial result if the most likely path
through the (partially-decoded) lattice ends at
a terminal node in the language model. The in-
tuition is that if a partial result finishes a com-
plete phrase expected by the language model,
it is more likely to be stable. The meaning of
terminal is slightly different for rule-based lan-
guage models (RLMs) and statistical language
models (SLMs). For a rule-based grammar,
the terminal node is simply one that ends a
valid phrase (?Pittsburgh? in ?leaving from Pitts-
burgh?). For an SLM, a terminal node indicates
that the most likely successor state is the spe-
cial end-of-sentence symbol. In other words, in
an SLM Terminal partial result, the language
model assigns the highest probability to ending
the phrase.
A third method, Immortal ISR, is the most
restrictive method (Spohrer et al, 1980). If all
paths of the lattice come together into a node
? called an immortal node ? then the lattice
structure before that node will be unchanged by
any subsequent decoding. This structure guar-
antees that the best word sequence prior to an
immortal node is stable. Immortal ISR operates
identically for both RLMs and SLMs.1
To compare these approaches we evaluate
their performance. Utterances were extracted
from real calls to the Carnegie Mellon ?Lets
Go!? bus information system for Pittsburgh,
USA (Raux et al, 2005; Parent and Eskenazi,
2009). We chose this domain because this cor-
pus is publicly available, and this domain has
recently been used as a test bed for dialogue
systems (Black et al , 2010). The AT&T WAT-
SON speech recognition engine was used, modi-
fied to output partials as described above (Goffin
et al, 2005). We tested these three approaches
to ISR on three different recognition tasks. The
first two tasks used rule-based language models
(RLM), and the third used a statistical language
model (SLM).
The two rule-based language models were de-
veloped for AT&T ?Let?s Go? dialogue sys-
tem, prior to its deployment (Williams et al
, 2010). The first RLM (RLM1) consisted
1The choice of search beam size affects both accuracy
and the number of immortal nodes produced: a smaller
beams yields a sparser lattice with more immortal nodes
and lower accuracy; a larger beam yields a richer lattice
with fewer immortal nodes and higher accuracy. In this
work we used our recognizer?s default beam size, which
allows recognition to run in less than real time and yields
near-asymptotic accuracy for all experiments.
112
of street and neighborhood names, built from
the bus timetable database. The second RLM
(RLM2) consisted of just neighborhood names.
Utterances to test RLM1 and RLM2 were se-
lected from the corpus provided by Carnegie
Mellon to match the expected distribution of
speech at the dialogue states where RLM1 and
RLM2 would be used. RLM1 was evaluated on
a set of 7722 utterances, and RLM2 on 5411 ut-
terances. To simulate realistic use, both RLM
test sets were built so that 80% of utterances
are in-grammar, and 20% are out-of-grammar.
The SLM was a 3-gram trained on a set of 140K
utterances, and is tested on a set of 42620 ut-
terances.
In past work, Raux et al (2005) report word
error rates (WERs) of 60-68% on data from the
same dialogue system, though on a different set
of utterances. By comparison, our SLM yields
a WER of 35%, which gives us some confidence
that our overall recognition accuracy is compet-
itive, and that our results are relevant.
Table 1 provides a few statistics of the LMs
and test sets, including whole-utterance accu-
racy, computed using an exact string match.
Results are analyzed in two groups: All, where
all of the utterances are analyzed, and Multi-
Word (MW), where only utterances whose tran-
scribed speech (what was actually said) has
more than one word. Intuitively, these utter-
ances are where ISR would be most effective.
That said, ISR is beneficial for both short and
long utterances ? for example, ISR systems
can react faster to users regardless of utterance
length.
ISR was run using each of the three ap-
proaches (Basic, Terminal, Immortal) in each of
the three configurations (RLM1, RLM2, SLM).
The mean number of partials per utterance is
shown in Table 2. For all ISR methods, the more
flexible SLM produces more partials than the
RLMs. Also as expected, multi-word utterances
produce substantially more partials per utter-
ance than when looking at the entire utterance
set. The Basic approach produces nearly dou-
ble the number of partials than Terminal ISR
does, and Immortal ISR production highlights
its primary weakness: in many utterances, no
Table 1: Statistics for Recognition Tasks. In all ta-
bles, All refers to all utterances in a test set, and
MW refers to the subset of multi-word utterances in
a test set.
RLM1 RLM2 SLM
Num. Utts All 7722 5411 42620
Num. Utts MW 3213 1748 20396
Words/Utt All 1.7 1.5 2.3
Words/Utt MW 2.8 2.6 3.8
Utt. Acc. All. 50 % 60 % 62 %
Utt. Acc. MW 53 % 56 % 44 %
immortal nodes are found. Given this however,
immortal node occurrence is directly related to
the number of words, as indicted by the greater
number of immortal partials in multi-word ut-
terances.
Stability is assessed by comparing the partial
to the final recognition result. For simplicity, we
restrict our analysis to 1-Best hypotheses. If the
partial 1-Best hypothesis is a prefix (or full ex-
act match) of the final 1-Best hypothesis then it
is considered stable. For instance, if the partial
1-Best hypothesis is ?leaving from Forbes? then
it would be stable if the final 1-Best is ?leaving
from Forbes? or ?leaving from Forbes and Mur-
ray? but not if it is ?from Forbes and Murray? or
?leaving?. Accuracy is assessed similarly except
that the transcribed reference is used instead of
the final recognition result.
We report stability and accuracy in Table 3.
Immortal partials are excluded from stability
since they are guaranteed to be stable. The first
four rows report stability, and the second six
report accuracy. The results show that Termi-
nal Partials are relatively unstable, with 23%-
Table 2: Average Number of Partials per utterance
ISR Group RLM1 RLM2 SLM
Basic All 12.0 9.9 11.6MW 14.6 12.3 29.7
Terminal All 5.4 3.3 6.2MW 6.4 4.1 8.8
Immortal All 0.22 0.32 0.55MW 0.42 0.67 0.63
113
Table 3: Stability and Accuracy Percentages
ISR Group RLM1 RLM2 SLM
Stability
Basic All 10 % 11 % 7 %MW 14 % 15 % 9 %
Terminal All 23 % 31 % 37 %MW 20 % 28 % 36 %
Accuracy
Basic All 9 % 1 % 5 %MW 11 % 13 % 6 %
Terminal All 13 % 21 % 24 %MW 12 % 17 % 21 %
Immortal All 91 % 93 % 55 %MW 90 % 90 % 56 %
37% of partials being stable, and that their sta-
bility drops off when looking at multi-word ut-
terances. SLM stability seems to be somewhat
higher than that of the RLM. Basic partials
are even more unstable (about 10% of partials
are stable), with extremely low stability for the
SLM. Unlike Terminal ISR, their stability grows
when only multi-word utterances are analyzed,
though the maximum is still quite low.
The results also show that partials are always
less accurate than they are stable, indicating
that not all stable partials are accurate. Immor-
tal partials are rare, but when they are found,
they are much more accurate than Terminal or
Basic partials. The RLM accuracy is very high,
and we suspect that immortal nodes are corre-
lated with utterances which are easier to recog-
nize. Terminal ISR is far more accurate than
Basic ISR for all of the utterances, but its im-
provement declines for multi-word RLMs.
We have shown three types of ISR: Basic, Ter-
minal and Immortal ISR. While Basic and Ter-
minal ISR are both highly productive, Terminal
ISR is far more stable and accurate than Basic.
Furthermore, there are far more Basic partials
than Terminal partials, implying that the dia-
logue manager would have to handle more un-
stable and inaccurate partials more often. Given
this, Terminal ISR is a far better ?productive
ISR? than the Basic method. Taking produc-
tion and stability together, there is a double dis-
Table 4: Lattice-Aware ISR (LAISR) Example
1-best Partial Type
yew Terminal
sarah Terminal
baum Terminal
dallas Terminal
downtown Terminal
downtown Immortal
downtown pittsburgh Terminal
downtown pittsburgh Immortal
sociation between Terminal and Immortal ISR.
Terminal partials are over produced and rela-
tively unstable. Furthermore, they are even less
stable when the transcribed reference is greater
than one word. On the other hand, Immortal
partials are stable and quite accurate, but too
rare for use alone. By integrating the Immortal
Partials with the Terminal ones, we may be able
to increase the stability and accuracy overall.
4 Lattice-Aware ISR (LAISR)
We introduce Lattice-Aware ISR (LAISR ?
pronounced ?laser?), that integrates Terminal
and Immortal ISR by allowing both types of par-
tials to be found. The selection procedure works
by first checking for an Immortal partial. If one
is not found then it looks for a Terminal. Re-
dundant partials are returned when the partial
type changes. An example recognition is shown
in Table 4. Notice how the first four partials
are completely unstable. This is very common,
and suppressing this noise is one of the primary
benefits of using more right context. Basic ISR
has even more of this type of noise.
LAISR was evaluated on the three recogni-
tion tasks described above (see Table 5). The
first two rows show the average number of par-
tials per utterance for each task and utterance
group. Unsurprisingly, these numbers are quite
similar to Terminal ISR. The stability percent-
age of LAISR is shown in the second two rows.
For all the utterances, there appears to be a very
slight improvement when compared to Termi-
nal ISR in Table 3. The improvement increases
for MW utterances, with LAISR improving over
114
Table 5: Lattice-Aware ISR Stats
Partials per Utterance
RLM1 RLM2 SLM
All 5.6 3.5 6.7
MW 6.7 4.5 9.6
Stability Percentage
All 24 % 33 % 40 %
MW 24 % 35 % 41 %
Accuracy Percentage
All 15 % 23 % 26 %
MW 16 % 22 % 24 %
Terminal ISR by 4?7 percentage points. This
is primarily because there is a higher occur-
rence of Immortal partials as the utterance gets
longer. Accuracy is reported in the final two
rows. Like the previous ISR methods described,
the accuracy percentage is lower than the sta-
bility percentage. When compared to Terminal
ISR, LAISR accuracy is slightly higher, which
confirms the benefit of incorporating immortal
partials with their relatively high accuracy. To
be useful in practice, it is important to exam-
ine when in the utterance ISR results are be-
ing produced. For example, if most of the par-
tials are returned towards the end of utterances,
than ISR is of little value over standard turn-
based recognition. Figure 1 shows the percent
of partials returned from the start of speech to
the final partial for MW utterances using the
SLM. This figure shows that partials are re-
turned rather evenly over the duration of ut-
terances. For example, in the first 10% of dura-
tion of each utterance, about 10% of all partial
results are returned. Figure 1 also reports the
stability and accuracy of the partials returned.
These numbers grow as decoding progresses, but
shows that mid-utterance results do yield rea-
sonable accuracy: partials returned in the mid-
dle of utterances (50%-60% duration) have an
accuracy of near 30%, compared to final partials
47% percent.
For use in a real-time dialogue system, it is
also important to assess latency. Here we define
latency as the difference in (real-world) time be-
tween (1) when the recognizer receives the last
Figure 1: Percent of LAISR partials returned from
the start of detected speech to the final partial using
the SLM. The percentage of partials returned that
are stable/accurate are also shown.
frame of audio for a segment of speech, and (2)
when the partial that covers that segment of
speech is returned from the recognizer. Mea-
suring latencies of LAISR on each task, we find
that RLM1 has a median of 0.26 seconds and a
mean of 0.41s; RLM2 has a median of 0.60s and
a mean of 1.48s; and SLM has a median of 1.04s
and a mean of 2.10s. Since reducing latency
was not the focus on this work, no speed opti-
mizations have been made, and we believe that
straightforward optimization can reduce these
latencies. For example, on the SLM, simply
turning off N-Best processing reduces the me-
dian latency to 0.55s and the mean to 0.79s.
Human reaction time to speech is roughly 0.20
seconds (Fry, 1975), so even without optimiza-
tion the RLM latencies are not far off human
performance.
In sum, LAISR produces a steady stream
of partials with relatively low latency over the
course of recognition. LAISR has higher stabil-
ity and accuracy than Terminal ISR, but its par-
tials are still quite unstable and inaccurate. This
means that in practice, dialogue systems will
need to make important decisions about which
partials to use, and which to discard. This need
motivated us to devise techniques for predicting
when a partial is stable, and when it is accurate,
which we address next.
115
Table 6: Equal Error Rates: Significant improvements in bold. Basic at p < 0.016, Terminal at p < 0.002,
and LAISR at p < 0.00001
All Multi-Word
Stability Measure (SM) Equal Error Rate
RLM 1 RLM 2 SLM RLM 1 RLM 2 SLM
Basic WATSON Score 13.3 13.3 12.8 15.6 16.4 15.2Regression 10.7 11.3 12.3 13.2 15.2 15.1
Terminal WATSON Score 24.3 29.1 34.4 26.6 26.0 34.1Regression 19.7 26.5 26.5 23.0 24.3 24.7
LAISR WATSON Score 24.7 29.3 35.0 24.0 27.0 35.3Regression 19.2 25.6 25.0 18.4 23.3 22.7
Confidence Measure (CM) Equal Error Rate
Basic WATSON Score 11.3 11.7 9.9 14.1 14.0 11.6Regression 9.8 9.8 9.7 12.3 12.9 11.0
Terminal WATSON Score 15.1 21.1 30.6 15.7 17.4 29.3Regression 11.7 16.8 20.8 12.1 14.5 18.4
LAISR WATSON Score 15.8 21.8 32.3 18.4 19.5 31.8Regression 11.6 16.6 21.0 11.6 14.2 18.7
5 Stability and Confidence Measures
As seen in the previous section, partial speech
recognition results are often revised and inaccu-
rate. In order for a dialogue system to make
use of partial results, measures of both stability
and confidence are crucial. A Stability Measure
(SM) predicts whether the current partial is a
prefix or complete match of the final recogni-
tion result (regardless of whether the final result
is accurate). A Confidence Measure (CM) pre-
dicts whether the current partial is a prefix or
complete match of what the user actually said.
Both are useful in real systems: for example, if
a partial is likely stable but unlikely correct, the
system might interrupt the user and ask them
to start again.
We use logistic regression to learn separate
classifiers for SM and CM. Logistic regression is
appealing because it is well-calibrated, and has
shown good performance for whole-utterance
confidence measures (Williams and Balakrish-
nan, 2009). For this, we use the BXR pack-
age with default settings (Genkin et al, 2011).
For Terminal and Basic ISR we use 11 features:
the raw WATSON confidence score, the individ-
ual features which affect the confidence score,
the normalized cost, the normalized speech like-
lihood, the likelihoods of competing models,
the best path score of word confusion network
(WCN), the length of WCN, the worst probabil-
ity in the WCN, and the length of N-best list.
For LAISR, four additional features are used:
three binary indicators of whether the partial is
Terminal, Immortal or a Terminal following an
Immortal, and one which gives the percentage
of words in the hypothesis that are immortal.
We built stability and confidence measures for
Basic ISR, Terminal ISR, and LAISR. Each of
the three corpora (RLM1, RLM2, SLM) was di-
vided in half to form a train set and test set.
Regression models were trained on all utter-
ances in the train set. The resulting models were
then evaluated on both All and MW utterances.
As a baseline for both measures, we compare
to AT&T WATSON?s existing confidence score.
This score is used in numerous deployed com-
mercial applications, so we believe it is a fair
baseline. Although the existing confidence score
is designed to predict accuracy (not stability),
there is no other existing mechanism for pre-
dicting stability.
We first report ?equal error rate? for the mea-
sures (Table 6). Equal error rate (EER) is the
sum of false accepts and false rejects at the rejec-
116
Figure 2: True accept percentages for stability measure (a) and confidence measure (b), using a fixed false
accept rate of 5%. LAISR yields highest true accept rates, with p < 0.0001 in all cases.
(a) Stability measure (b) Confidence measure
tion threshold for which false accepts and false
rejects are equal. Equal error rate is a widely
used metric to evaluate the quality of scoring
models used for accept/reject decisions. A per-
fect scoring model would yield an EER of 0. For
statistical significance we use ?2 contingency ta-
bles with 1 degree of freedom. It is inappropri-
ate to compare EER across ISR methods, since
the total percentage of stable or accurate par-
tials significantly effects the EER. For example,
Basic ISR has relatively low EER, but this is
because it also has a relatively low number of
stable or accurate partials.
The top six rows of Table 6 show EER for the
Stability Measure (SM). The left three columns
show results on the entire test set (all utterances,
of any length). On the whole, the SM outper-
forms the WATSON confidence scores, and the
greatest improvement is a 10.0 point reduction
in EER for LAISR on the SLM task. The right
three columns show results on only multi-word
(MW) utterances. Performance is similar to the
entire test set, with a maximum EER reduction
of 12.6 percent. The SLM MW performance is
interesting, suggesting that it is easier to pre-
dict stability after at least one word has been
decoded, possibly due to higher probability of
immortal nodes occurring. This suggests there
would be benefit in combining our method with
past work that adds right-context, perhaps us-
ing more context early in the utterance. This
idea is left for future work.
The bottom six rows show results for the Con-
fidence Measure (CM). We see that that even
when comparing our CM against the WATSON
confidence scores, there is significant improve-
ment, with a maximum of 13.1 for LAISR in the
MW SLM task.
The consistent improvement shows that logis-
tic regression is an effective technique for learn-
ing confidence and stability measures. It is most
powerful when combined with LAISR, and only
slightly less so with Terminal. Furthermore,
though the gains are slight, it is also useful with
Basic ISR, which speaks to the generality of the
approach.
While equal error rate is useful for evaluating
discriminative ability, when building an actual
system a designer would be interested to know
how often the correct partial is accepted. To
evaluate this, we assumed a fixed false-accept
rate of 5%, and report the resulting percentage
of partials which are correctly accepted (true-
accepts). Results are shown in Figure 1. LAISR
accepts substantially more correct partials than
other methods, indicating that LAISR would be
more useful in practice. This result also shows
a synergy between LAISR and our regression-
based stability and confidence measures: not
only does LAISR improve the fraction of stable
117
and correct partials, but the regression is able
to identify them better than for Terminal ISR.
We believe this shows the usefulness of the ad-
ditional lattice features used by the regression
model built on LAISR results.
6 Discussion and Conclusion
The adoption of ISR is hindered by the num-
ber of revisions that most partials undergo. A
number of researchers have proposed the use of
right context to increase the stability of par-
tials. While this does increase stability, it mit-
igates the primary gain of ISR: getting a rela-
tively real-time stream of the user?s utterance.
We offer two methods to improve ISR function-
ality: the integration of low-occurring Immortal
partials with higher occurring Terminal partials
(LAISR), and the use of logistic regression to
learn stability and confidence measures.
We find that the integrative approach,
LAISR, outperforms Terminal ISR on three
recognition tasks for a bus timetable spoken dia-
logue system. When looking at utterances with
more than one word this difference becomes even
greater, and this performance increase is due to
the addition of immortal partials, which have
a higher occurrence in longer utterances. This
suggests that as dialogue systems are used to
process multi-phrasal utterances and have more
dynamic turn-taking interactions, immortal par-
tials will play an even larger roll in ISR and par-
tial stability will further improve.
The Stability and Confidence measures both
have lower Equal Error Rates than raw recog-
nition scores when classifying partials. The im-
provement is greatest for LAISR, which benefits
from additional features describing lattice struc-
ture. It also suggests that other incremental fea-
tures such as the length of right context could be
useful for predicting stability. The higher num-
ber of True Accept partials by LAISR indicates
that this method is more useful to a dialogue
manager than Basic or Terminal ISR. Even so,
for all ISR methods there are still more use-
ful stable partials than there are accurate ones.
This suggests that both of these measures are
important to the downstream dialogue manager.
For example, if the partial is predicted to be sta-
ble but not correct, than the agent could possi-
bly interrupt the user and ask them to begin
again.
There are a number of avenues for future
work. First, this paper has examined the word
level; however dialogue systems generally oper-
ate at the intention level. Not all changes at
the word level yield a change in the resulting
intention, so it would be interesting to apply
the confidence measure and stability measures
developed here to the (partial) intention level.
These measures could also be applied to later
stages of the pipeline ? for example, tracking
stability and confidence in the dialogue state re-
sulting from the current partial intention. Fea-
tures from the intention level and dialogue state
could be useful for these measures ? for instance,
indicating whether the current partial intention
is incompatible with the current dialogue state.
Another avenue for future work would be to
apply these techniques to non-dialogue real-time
ASR tasks, such as transcription of broadcast
news. Confidence and stability measures could
be used to determine whether/when/how to dis-
play recognized text to a viewer, or to inform
down-stream processes such as named entity ex-
traction or machine translation.
Of course, an important objective is to eval-
uate our Stability and Confidence Measures
with LAISR in an actual spoken dialogue sys-
tem. ISR completely restructures the conven-
tional turn-based dialogue manager, giving the
agent the opportunity to speak at any mo-
ment. The use of reinforcement learning to make
these turn-taking decisions has been shown in a
small simulated domain by Selfridge and Hee-
man (2010), and we believe this paper builds
a foundation for pursuing these ideas in a real
system.
Acknowledgments
Thanks to Vincent Goffin for help with this
work, and the anonymous reviewers for their
thoughtful suggestions and critique. We ac-
knowledge funding from the NSF under grant
IIS-0713698.
118
References
G. Aist, J. Allen, E. Campana, C. Gallo, S. Stoness,
Mary Swift, and Michael K. Tanenhaus. 2007. In-
cremental understanding in human-computer di-
alogue and experimental evidence for advantages
over nonincremental methods. In Proc. DECA-
LOG, pages 149?154.
T. Baumann, M. Atterer, and D. Schlangen. 2009.
Assessing and improving the performance of
speech recognition for incremental systems. In
Proc. NAACL: HLT, pages 380?388.
A. Black, S. Burger, B. Langner, G. Parent, and
M. Eskenazi, 2010. Spoken dialog challenge 2010,
In Proc. Workshop on Spoken Language Technolo-
gies (SLT), Spoken Dialog Challenge 2010 Special
Session.
David DeVault, Kenji Sagae, and David Traum.
2009. Can i finish? learning when to respond to
incremental interpretation results in interactive di-
alogue. In Proc. SIGdial 2009 Conference, pages
11?20,
G.A. Fink, C. Schillo, F. Kummert, and G. Sagerer.
1998. Incremental speech recognition for multi-
modal interfaces. In Industrial Electronics Soci-
ety, 1998. IECON?98 volume 4, pages 2012?2017.
D.B. Fry. 1975. Simple reaction-times to speech and
non-speech stimuli.. Cortex volume 11, number 4,
page 355.
A. Genkin, L. Shenzhi, D. Madigan, and DD.
Lewis. 2011. Bayesian logistic regression.
http://www.bayesianregression.org.
V. Goffin, C. Allauzen, E. Bocchieri, D. Hakkani-
Tur, A. Ljolje, S. Parthasarathy, M. Rahim,
G. Riccardi, and M. Saraclar. 2005. The AT&T
WATSON speech recognizer. In Proc. of ICASSP,
pages 1033?1036.
G. Parent and M. Eskenazi. 2009. Toward Better
Crowdsourced Transcription: Transcription of a
year of the Let?s Go Bus Information System Data.
Proc. of Interspeech 2005, Lisbon, Portugal.
A. Raux, B. Langner, D. Bohus, A.W. Black, and
M. Eskenazi. 2005. Lets go public! taking a spo-
ken dialog system to the real world. In Proc. of
Interspeech 2005.
D. Schlangen, T. Baumann, and M. Atterer. 2009.
Incremental reference resolution: The task, met-
rics for evaluation, and a Bayesian filtering model
that is sensitive to disfluencies. In Proc. SIGdial,
pages 30?37.
E.O. Selfridge and P.A. Heeman. 2010. Importance-
Driven Turn-Bidding for spoken dialogue systems.
In Proc. of ACL 2010, pages 177?185.
G. Skantze and D. Schlangen. 2009. Incremental
dialogue processing in a micro-domain. In Proc.
EACL 2009, pages 745?753
J.C. Spohrer, PF Brown, PH Hochschild, and
JK Baker. 1980. Partial traceback in continuous
speech recognition. In Proc. of the IEEE Interna-
tional Conference on Cybernetics and Society.
J.D. Williams, I. Arizmendi and A. Conkie.
2010. Demonstration of AT&T ?Let?s Go?: A
production-grade statistical spoken dialog system.
In Proc Demonstration Session at IEEE Workshop
on Spoken Language Technology
J.D. Williams and S. Balakrishnan. 2009. Estimat-
ing probability of correctness for ASR N-Best lists.
In Proc. of SIGdial 2009, pages 132?135.
119
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 275?279,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Integrating Incremental Speech Recognition and POMDP-based Dialogue
Systems
Ethan O. Selfridge?, Iker Arizmendi?, Peter A. Heeman?, and Jason D. Williams1
? Center for Spoken Language Understanding, Oregon Health & Science University, Portland, OR, USA
?AT&T Labs ? Research, Shannon Laboratory, Florham Park, NJ, USA
1Microsoft Research, Redmond, WA, USA
{selfridg,heemanp}@ohsu.edu
iker@research.att.com jason.williams@microsoft.com
Abstract
The goal of this paper is to present a first
step toward integrating Incremental Speech
Recognition (ISR) and Partially-Observable
Markov Decision Process (POMDP) based di-
alogue systems. The former provides sup-
port for advanced turn-taking behavior while
the other increases the semantic accuracy of
speech recognition results. We present an In-
cremental Interaction Manager that supports
the use of ISR with strictly turn-based dia-
logue managers. We then show that using
a POMDP-based dialogue manager with ISR
substantially improves the semantic accuracy
of the incremental results.
1 Introduction and Background
This paper builds toward integrating two distinct
lines of research in spoken dialogue systems: in-
cremental speech recognition (ISR) for input, and
Partially Observable Markov Decision Processes
(POMDPs) for dialogue management.
On the one hand, ISR improves on whole-
utterance speech recognition by streaming results to
the dialogue manager (DM) in real time (Baumann
et al, 2009; Skantze and Schlangen, 2009). ISR
is attractive because it enables sophisticated system
behavior such as interruption and back-channeling.
However, ISR output is particularly error-prone, and
often requires a specialized dialogue manager to be
written (Bu? and Schlangen, 2011; Schlangen and
Skantze, 2009).
1Work done while at AT&T Labs - Research
On the other hand, POMDP-based dialogue man-
agers improve on traditional approaches by (in part)
tracking a distribution over many possible dialogue
states, rather than just one, thereby improving ro-
bustness to speech recognition errors (Williams and
Young, 2007; Thomson and Young, 2010; Young
et al, 2010). The overall aim of combining these
two lines of research is to improve the robustness of
error-prone ISR output.
To our knowledge only one study to date has com-
bined ISR and POMDPs. Lu et al (2011) show
how 1-best ISR hypotheses can be used within a sin-
gle dialogue turn. This work is different than the
present paper, where we use N-Best lists of ISR re-
sults across multiple turns of a dialogue.
Specifically, this paper makes two contributions.
First, as a foundation, we introduce an Incremental
Interaction Manager (IIM) that enables ISR to be
used within the traditional turn-based dialogue man-
agement framework. The IIM confers many, but not
all, of the benefits of ISR without requiring mod-
ification to a traditional dialogue manager. Thus,
in theory, any existing dialogue system architecture
could use ISR with the addition of an IIM. Second,
we show that pairing our IIM with a POMDP-based
dialogue manager yields a substantial improvement
in accuracy for incremental recognition results at the
dialogue level.
The paper is organized as follows. Section 2 de-
scribes the IIM, section 3 describes the POMDP in-
tegration, sections 4 and 5 describe experiments and
results, and section 6 concludes.
275
Table 1: Example IIM operation. P = partial ISR result; A = dialogue action.
Original Copied
ISR IIM DM state DM state DM Action
Prompt: ?Where are you leaving from??
yew Rej. P 0 0 -
ridge Acc. P / Rej. A 0 0 ?I?m sorry...?
mckee Acc. P / Acc. A 0 1 ?Ok, Mckee...?
mckeesport Acc. P / Acc. A 0 2 ?Ok, Mckeesport..?
mckeesport center Acc. P / Rej. A 0 2 ?Ok, Mckeesport..?
Prompt: ?Ok, Mckeesport. Where are you going to??
pitt Acc. P / Rej. A 2 4 ?I?m sorry...?
pittsburgh Acc. P / Acc. A 2 5 ?Ok, Pittsburgh...?
2 Incremental Interaction manager
The Incremental Interaction Manager (IIM) medi-
ates communication between the incremental speech
recognizer and the DM. The key idea is that the
IIM evaluates potential dialogue moves by apply-
ing ISR results to temporary instances of the DM.
The IIM copies the current state of the DM, pro-
vides the copied DM with a recognition result, and
inspects the action that the copied DM would take.2
If the action does not sufficiently advance the dia-
logue (such as re-asking the same question), the ac-
tion is rejected and the copied DM is discarded. If
the action advances the dialogue (such as asking for
or providing new information), then that action is
immediately executed.
The system should gracefully handle revisions
following a premature action execution, and a copy-
ing procedure is a viable solution for any DM. When
a revision is received, a second copy of the original
DM is made and the new ISR result is passed to that
second copy; if that second copy takes an action that
advances the dialogue and is different from the ac-
tion generated by the first copy, then the first action
is terminated, the first copy of the DM is discarded,
the second action is initiated, and the second copy
assumes the position of the first copy. Additional
revisions can be handled by following the same pro-
cedure. Terminating a speech action and immedi-
ately starting another can be jarring (?Say a city /
Ok, Boston...?), which can be mitigated by preced-
2If the DM design does not force a state transition following
a result then the DM supplies the the action without copying.
ing actions with either a sound or simple silence (at
the expense of some response delay). Once recog-
nition is complete, the copied DM is installed as the
new original DM.
Many ISR results can be discarded before passing
them to the DM. First, only incremental results that
could correspond to complete user utterance are con-
sidered: incomplete results are discarded and never
passed to the DM. In addition, ISR results are of-
ten unstable, and it is undesirable to proceed with
an ISR result if it will very likely be revised. Thus
each candidate ISR result is scored for stability (Sel-
fridge et al, 2011) and results with scores below a
manually-set threshold are discarded.
Table 1 shows an example of the recognizer, the
IIM, and the DM. For sake of clarity, stability scores
are not shown. The system asks ?Where are you
leaving from?? and the user answers ?Mckeesport
Center.? The IIM receives five ISR results (called
partials), rejecting the first, yew, because its stabil-
ity score is too low (not shown). With the second,
ridge, it copies the DM, passes ridge to the copy,
and discards the action of the copied DM (also dis-
carded) because it does not advance the dialogue. It
accepts and begins to execute the action generated
by the third partial, mckee. The fourth partial revises
the action, and the fifth action is rejected since it is
the same. The original DM is then discarded and the
copied DM state is installed in its place.
Overall, the IIM enables a turn-based DM to en-
joy many of the benefits of ISR ? in particular, the
ability to make turn-taking decisions with a com-
plete account of the dialogue history.
276
3 Integrating ISR with a POMDP-based
dialogue manager
A (traditional) dialogue manager based on a partially
observable Markov decision process (POMDP DM)
tracks a probability distribution over multiple hid-
den dialogue states called a belief state (Williams
and Young, 2007).3 As such, POMDP DMs read-
ily make use of the entire ASR N-Best list, even
for low-confidence results ? the confidence level of
each N-Best list item contributes proportionally to
the probability of its corresponding hidden state.
It is straightforward to integrate ISR and a
POMDP DM using the IIM. Each item on the N-
Best list of an incremental result is assigned a confi-
dence score (Williams and Balakrishnan, 2009) and
passed to the POMDP DM as if it were a complete
result, triggering a belief state update. Note that this
approach is not predicting future user speech from
partial results (DeVault et al, 2009; Lu et al, 2011),
but rather (tentatively) assuming that partial results
are complete.
The key benefit is that a belief state generated
from an incremental result incorporates all of the
contextual information available to the system from
the start of the dialogue until the moment of that
incremental result. By comparison, an isolated in-
cremental result includes only information from the
current utterance. If the probability models in the
POMDP are estimated properly, belief states should
be more accurate than isolated incremental results.
4 Experimental design
For our experiments we used a corpus of 1037 calls
from real users to a single dialogue system that pro-
vides bus timetable information for Pittsburgh, PA
(a subsequent version of Williams (2011)). This di-
alogue system opened by asking the caller to say a
bus route number or ?I don?t know?; if the system
had insufficient confidence following recognition, it
repeated the question. We extracted the first 3 re-
sponses to the system?s bus route question. Often
the system did not need to ask 3 times; our exper-
imental set contained 1037 calls with one or more
attempts, 586 calls with two or more attempts, and
3It also uses reinforcement learning to choose actions, al-
though in this paper we are not concerned with this aspect.
356 calls with three or more attempts. These utter-
ances were all transcribed, and tagged for the bus
route they contained, if any: 25% contained neither
a route nor ?I don?t know?.
We ran incremental speech recognition on each
utterance using Lattice-Aware Incremental Speech
Recognition (Selfridge et al, 2011) on the AT&T
WATSONSM speech recognizer (Goffin et al, 2005)
with the same rule-based language models used in
the production system. On average, there were
5.78, 5.44, and 5.11 incremental results per utter-
ance (plus an utterance-final result) for the first, sec-
ond, and third attempts. For each incremental result,
we noted its time stamp and interpretation: correct,
if the interpretation was present and correct, other-
wise incorrect. Each incremental result included an
N-Best list, from which we determined oracle accu-
racy: correct if the correct interpretation was present
anywhere on the most recent ISR N-Best list, other-
wise incorrect.
Each incremental result was then passed to the
IIM and POMDP DM. The models in the POMDP
DM were estimated using data collected from a dif-
ferent (earlier) time period. When an incremental
result updated the belief state, the top hypothesis
for the route was extracted from the belief state and
scored for correctness. For utterances in the first at-
tempt, the belief state was initialized to its prior; for
subsequent attempts, it incorporated all of the prior
(whole-turn) utterances. In other words, each at-
tempt was begun assuming the belief state had been
running up to that point.
5 Results and Discussion
We present results by showing instantaneous seman-
tic accuracy for the raw incremental result (base-
line), the top belief state, and oracle. Instantaneous
semantic accuracy is shown with respect to the per-
cent of the total recognition time the partial is rec-
ognized at. An utterance is incorrect if it has no in-
cremental result before a certain percentage.
We show 2 sets of plots. Figure 1 shows only in-
cremental recognition results and excludes the end-
of-utterance (phrase) results; Figure 2 shows incre-
mental recognition results and includes phrase re-
sults. It is useful to view these separately since the
phrase result, having access to all the speech, is sub-
277
Figure 1: Instantaneous semantic accuracy of incremental results, excluding phrase-final results
Figure 2: Instantaneous semantic accuracy of incremental and phrase-final results
stantially more accurate than the incremental results.
Figure 1 shows that the POMDP is more accu-
rate than the raw incremental result (excluding end-
of-phrase results). Its performance gain is minimal
in attempt 1 because the belief is informed only by
the prior. In attempt 2 and 3, the gain is larger
since the belief also benefits from the previous at-
tempts. Since the top POMDP result in subsequent
attempts is sometimes already correct (because it
incorporates past recognitions), the POMDP some-
times meets and occasionally exceeds the oracle dur-
ing the early portions of attempts 2 and 3.
Figure 2 shows that when end-of-phrase recog-
nition results are included, the benefit of the belief
state is limited to the initial portions of the second
and third turns. This is because the POMDP mod-
els are not fit well to the data: the models were
estimated from an earlier version of the system,
with a different user base and different functionality.
Identifying and eliminating this type of mismatch
is an important issue and has been studied before
(Williams, 2011).
Taken as a whole, we find that using belief track-
ing increases the accuracy of partials by over 8%
(absolute) in some cases. Even though the final
phrase results of the 1-best list are more accurate
than the belief state, the POMDP shows better ac-
curacy on the volatile incremental results. As com-
pared to the whole utterance results, incremental re-
sults have lower 1-best accuracy, yet high oracle ac-
curacy. This combination is a natural fit with the
POMDPs belief state, which considers the whole N-
Best list, effectively re-ranking it by synthesizing in-
formation from dialogue history priors.
6 Conclusion
This paper has taken a step toward integrating ISR
and POMDP-based dialogue systems. The Incre-
mental Interaction Manager (IIM) enables a tradi-
tional turn-based DM to make use of incremental
results and enjoy many their benefits. When this
IIM is paired with a POMDP DM, the interpreta-
tion accuracy of incremental results improves sub-
stantially. In the future we hope to build on this work
by incorporating Reinforcement Learning into turn-
taking and dialogue action decisions.
Acknowledgments
Thanks to Vincent Goffin for help with this work,
and to the anonymous reviewers for their comments
and critique. We acknowledge funding from the
NSF under grant IIS-0713698.
278
References
T. Baumann, M. Atterer, and D. Schlangen. 2009.
Assessing and improving the performance of speech
recognition for incremental systems. In Proc. NAACL:
HLT, pages 380?388. Association for Computational
Linguistics.
O. Bu? and D. Schlangen. 2011. Dium?an incremen-
tal dialogue manager that can produce self-corrections.
Proceedings of semdial.
David DeVault, Kenji Sagae, and David Traum. 2009.
Can i finish? learning when to respond to incremental
interpretation results in interactive dialogue. In Pro-
ceedings of the SIGDIAL 2009 Conference, pages 11?
20, London, UK, September. Association for Compu-
tational Linguistics.
V. Goffin, C. Allauzen, E. Bocchieri, D. Hakkani-Tur,
A. Ljolje, S. Parthasarathy, M. Rahim, G. Riccardi,
and M. Saraclar. 2005. The AT&T WATSON speech
recognizer. In Proceedings of ICASSP, pages 1033?
1036.
D. Lu, T. Nishimoto, and N. Minematsu. 2011. Decision
of response timing for incremental speech recogni-
tion with reinforcement learning. In Automatic Speech
Recognition and Understanding (ASRU), 2011 IEEE
Workshop on, pages 467?472. IEEE.
D. Schlangen and G. Skantze. 2009. A general, ab-
stract model of incremental dialogue processing. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics, pages 710?718. Association for Computational
Linguistics.
E.O. Selfridge, I. Arizmendi, P.A. Heeman, and J.D.
Williams. 2011. Stability and accuracy in incremen-
tal speech recognition. In Proceedings of the SIGdial
2011.
G. Skantze and D. Schlangen. 2009. Incremental dia-
logue processing in a micro-domain. In Proceedings
of the 12th Conference of the European Chapter of
the Association for Computational Linguistics, pages
745?753. Association for Computational Linguistics.
B. Thomson and S. Young. 2010. Bayesian update of di-
alogue state: A pomdp framework for spoken dialogue
systems. Computer Speech & Language, 24(4):562?
588.
J.D. Williams and S. Balakrishnan. 2009. Estimating
probability of correctness for asr n-best lists. In Proc
SIGDIAL, London, United Kingdom.
J.D. Williams and S. Young. 2007. Partially observable
markov decision processes for spoken dialog systems.
Computer Speech & Language, 21(2):393?422.
J.D. Williams. 2011. An empirical evaluation of a sta-
tistical dialog system in public use. In Proceedings of
the SIGDIAL 2011 Conference, pages 130?141. Asso-
ciation for Computational Linguistics.
S. Young, M. Gasic, S. Keizer, F. Mairesse, J. Schatz-
mann, B. Thomson, and K. Yu. 2010. The hidden
information state model: A practical framework for
pomdp-based spoken dialogue management. Com-
puter Speech & Language, 24(2):150?174.
279
Proceedings of the SIGDIAL 2013 Conference, pages 384?393,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Continuously Predicting and Processing Barge-in
During a Live Spoken Dialogue Task
Ethan O. Selfridge?, Iker Arizmendi?, Peter A. Heeman?, and Jason D. Williams1
? Center for Spoken Language Understanding, Oregon Health & Science University, Portland, OR, USA
?AT&T Labs ? Research, Shannon Laboratory, Florham Park, NJ, USA
1Microsoft Research, Redmond, WA, USA
selfridg@ohsu.edu
Abstract
Barge-in enables the user to provide input
during system speech, facilitating a more
natural and efficient interaction. Stan-
dard methods generally focus on single-
stage barge-in detection, applying the di-
alogue policy irrespective of the barge-in
context. Unfortunately, this approach per-
forms poorly when used in challenging
environments. We propose and evaluate
a barge-in processing method that uses a
prediction strategy to continuously decide
whether to pause, continue, or resume the
prompt. This model has greater task suc-
cess and efficiency than the standard ap-
proach when evaluated in a public spoken
dialogue system.
Index Terms: spoken dialogue systems, barge-in
1 Introduction
Spoken dialogue systems (SDS) communicate
with users with spoken natural language; the op-
timal SDS being effective, efficient, and natural.
Allowing input during system speech, known as
barge-in, is one approach that designers use to
improve system performance. In the ideal use
case, the system detects user speech, switches off
the prompt, and then responds to the user?s utter-
ance. Dialogue efficiency improves, as the sys-
tem receives information prior to completing its
prompt, and the interaction becomes more natu-
ral, as the system demonstrates more human-like
turn-taking behavior. However, barge-in poses a
number of new challenges; the system must now
recognize and process input during its prompt that
may not be well-formed system directed speech.
This is a difficult task and standard barge-in ap-
proaches often stop the prompt for input that will
not be understood, subsequently initiating a clari-
fication sub-dialogue (?I?m sorry, I didn?t get that.
You can say...etc.?). This non-understood barge-in
(NUBI) could be from environmental noise, non-
system directed speech, poorly-formed system di-
rected speech, legitimate speech recognition diffi-
culties (such as acoustic model mismatch), or any
combination thereof.
This paper proposes and evaluates a barge-in
processing method that focuses on handling NU-
BIs. Our Prediction-based Barge-in Response
(PBR) model continuously predicts interpretation
success by applying adaptive thresholds to incre-
mental recognition results. In our view, predicting
whether the recognition will be understood has far
more utility than detecting whether the barge-in
is truly system directed speech as, for many do-
mains, we feel only understandable input has more
discourse importance than system speech. If the
input is predicted to be understood, the prompt is
paused. If it is predicted or found to be NUBI, the
prompt is resumed. Using this method, the sys-
tem may resume speaking before recognition is
complete and will never initiate a clarifying sub-
dialogue in response to a NUBI. The PBR model
was implemented in a public Lets Go! statistical
dialogue system (Raux et al, 2005), and we com-
pare it with a system using standard barge-in meth-
ods. We find the PBR model has a significantly
better task success rate and efficiency.
Table 1 illustrates the NUBI responses produced
by the standard barge-in (Baseline) and PBR mod-
els. After both prompts are paused, the standard
method initiates a clarifying sub-dialogue whereas
PBR resumes the prompt.
We first provide background on Incremental
Speech Recognition and describe the relevant re-
lated work on barge-in. We then detail the
Prediction-based Barge-in Response model?s op-
eration and motivation before presenting a whole-
call and component-wise analysis of the PBR
1Work done while at AT&T Labs - Research
384
Table 1: System response to Non-Understood Barge-In (NUBI)
Baseline Ok, sixty one <NUBI> Sorry, say a bus route like twenty eight x
PBR Ok, sixty one <NUBI> sixty one c. Where are you leaving from?
model. The paper concludes with a discussion of
our findings and implications for future SDS.
2 Background and Related Work
Incremental Speech Recognition: Incremental
Speech Recognition (ISR) provides the real-time
information critical to the PBR model?s continu-
ous predictions. ISR produces partial recognition
results (?partials?) until input ceases and the ?fi-
nal? recognition result is produced following some
silence. As partials have a tendency to be revised
as more audio is processed, stability measures are
used to predict whether a given partial hypothe-
sis will be present in the final recognition result
(McGraw and Gruenstein, 2012; Selfridge et al,
2011). Here, we use Lattice-Aware ISR, which
produces partials after a Voice Activity Detector
(VAD) indicates speech and limits them to be a
complete language model specified phrase or have
guaranteed stability (Selfridge et al, 2011).
Barge-In: Using the standard barge-in model,
the system stops the prompt if barge-in is detected
and applies the dialogue logic to the final recogni-
tion result. This approach assumes that the barge-
in context should not influence the dialogue pol-
icy, and most previous work on barge-in has fo-
cused on detection: distinguishing system directed
speech from other environmental sounds. Cur-
rently, these methods are either based on a VAD
(e.g. (Stro?m and Seneff, 2000)), ISR hypothe-
ses (Raux, 2008), or some combination (Rose and
Kim, 2003). Both approaches can lead to detection
errors: background speech will trigger the VAD,
and partial hypotheses are unreliable (Baumann et
al., 2009). To minimize this, many systems only
enable barge-in at certain points in the dialogue.
One challenge with the standard barge-in model
is that detection errors can initiate a clarifying sub-
dialogue to non-system directed input, as it is un-
likely that this input will be understood (Raux,
2008). Since this false barge-in, which in most
cases is background speech (e.g. the television), is
highly indicative of poor recognition performance
overall, the system?s errant clarifying response can
only further degrade user experience.
Strom and Seneff (2000) provide, to our knowl-
edge, the only mature work that proposed deviat-
ing from the dialogue policy when responding to
a barge-in recognition. Instead of initiating a clar-
ifying sub-dialogue, the system produced a filled-
pause disfluency (?umm?) and resumed the prompt
at the phrase boundary closest to the prompt?s sus-
pension point. However, this model only operated
at the final recognition level (as opposed the incre-
mental level) and, unfortunately, they provide no
evaluation of their approach. An explicit compar-
ison between the approaches described here and
the PBR model is found in Section 3.5.
3 Prediction-based Barge-in Response
The PBR model is characterized by three high-
level states: State 1 (Speaking Prediction), whose
goal is to pause the prompt if stability scores pre-
dict understanding; State 2 (Silent Prediction),
whose goal is to resume the prompt if stability
scores and the incremental recognition rate pre-
dict non-understanding; and State 3 (Completion),
which operates on the final recognition result, and
resumes the prompt unless the recognition is un-
derstood and the new speech act will advance the
dialogue. Here, we define ?advancing the dia-
logue? to be any speech act that does not start a
clarifying sub-dialogue indicating a NUBI. Tran-
sitions between State 1 and 2 are governed by
adaptive thresholds ? repeated resumptions sug-
gest the user is in a noisy environment, so each
resumption increases the threshold required to ad-
vance from State 1 to State 2 and decreases the
threshold required to advance from State 2 to State
1. A high-level comparison of the standard model
and our approach is shown in Figure 1; a complete
PBR state diagram is provided in the Appendix.
3.1 State 1: Speaking Prediction
In State 1, Speaking Prediction, the system is both
speaking and performing ISR. The system scores
each partial for stability, predicting the probability
that it will remain ?stable? ? i.e., will not be later
revised ? using a logistic regression model (Self-
ridge et al, 2011). This model uses a number of
features related to the recognizer?s generic confi-
dence score, the word confusion network, and lat-
tice characteristics. Table 2 shows partial results
385
Table 2: Background noise and User Speech ISR
Background Noise User Utterance
Partial Stab. Scr. Partial Stab. Scr.
one 0.134 six 0.396
two 0.193 sixty 0.542
six 0.127 fifty one 0.428
two 0.078 sixty one a 0.491
and stability scores for two example inputs: back-
ground noise on the left, and the user saying ?sixty
one a? on the right.
State 1 relies on the internal threshold param-
eter, T1. If a partial?s stability score falls below
T1, control remains in State 1 and the partial re-
sult is discarded. If a stability score meets T1, the
prompt is paused and control transitions to State 2.
T1 is initially set to 0 and is adapted as the dialogue
progresses. The adaptation procedure is described
below in Section 3.4. If a final recognition result
is received, control transitions directly to State 3.
Transitioning from State 1 to State 2 is only al-
lowed during the middle 80% of the prompt; oth-
erwise only transitions to State 3 are allowed.1
3.2 State 2: Silent Prediction
Upon entering State 2, Silent Prediction, the
prompt is paused and a timer is started. State 2 re-
quires continuous evidence (at least every T2 ms)
that the ISR is recognizing valid speech and each
time a partial result that meets T1 is received, the
timer is reset. If the timer reaches the time thresh-
old T2, the prompt is resumed and control returns
to State 1. T2 is initially set at 1.0 seconds and is
adapted as the dialogue progresses. Final recogni-
tion results trigger a transition to State 3.
The resumption prompt is constructed using the
temporal position of the VAD specified speech
start to find the percentage of the prompt that was
played up to that point. This percentage is then
reduced by 10% and used to create the resump-
tion prompt by finding the word that is closest to,
but not beyond, the modified percentage. White
space characters and punctuation are used to deter-
mine word boundaries for text-to-speech prompts,
whereas automatically generated word-alignments
are used for pre-recorded prompts.
1We hypothesized that people will rarely respond to the
current prompt during the first 10% of prompt time as over-
laps at the beginning of utterances are commonly initiative
conflicts (Yang and Heeman, 2010). Users may produce
early-onset utterances during the last 10% that should not
stop the prompt as it is not an ?intentional? barge-in.
Figure 1: The Standard Barge-in and PBR Models
3.3 State 3: Completion
State 3, Completion, is entered when a final recog-
nition result is received and determines whether
the current dialogue policy will advance the dia-
logue or not. Here, the PBR model relies on the
ability of the dialogue manager (DM) to produce a
speculative action without transitioning to the next
dialogue state. If the new action will not advance
the dialogue, it is discarded and the recognition
is NUBI. However, if it will advance the dialogue
then it is classified as an Understood Barge-In
(UBI). In the NUBI case, the system either contin-
ues speaking or resumes the current prompt (tran-
sitioning to State 1). In the UBI case, the system
initiates the new speech act after playing a short
reaction sound and the DM transitions to the next
dialogue state. This reaction sound precedes all
speech acts outside the barge-in context but is not
used for resumption or timeout prompts. Note that
by depending solely on the new speech act, our
model does not require access to the DM?s internal
understanding or confidence scoring components.
3.4 Threshold adjustments
States 1 and 2 contain parameters T1 and T2 that
are adapted to the user?s environment. T1 is the
stability threshold used in State 1 and State 2 that
controls how stable an utterance must be before
the prompt should be paused. In quiet environ-
ments ? where only the user?s speech produces
partial results ? a low threshold is desirable as
it enables near-immediate pauses in the prompt.
Conversely, noisy environments yield many spu-
rious partials that (in general) have much lower
stability scores, so a higher threshold is advan-
tageous. T2 is the timing threshold used to re-
sume the prompt during recognition in State 2. In
quiet environments, a higher threshold reduces the
chance that the system will resume its prompt dur-
ing a well-formed user speech. In noisy environ-
386
Figure 2: Example dialogue fragment of PBR Model
ments, a lower threshold allows the system to re-
sume quickly as the NUBI likelihood is greater.
Both T1 and T2 are dependent on the number of
system resumptions, as we view the action of re-
suming the prompt as an indication that the thresh-
old is not correct. With every resumption, the pa-
rameter R is incremented by 1 and, to account for
changing environments, R is decremented by 0.2
for every full prompt that is not paused until it
reaches 0. UsingR, T1 is computed by T1 = 0.17?
R, and T2 by T2 = argmax(0.1, 1? (0.1 ?R)).2
3.5 Method Discussion
The motivation behind the PBR model is both the-
oretical and practical. According to Selfridge and
Heeman (2010), turn-taking is best viewed as a
collaborative process where the turn assignment
should be determined by the importance of the
utterance. During barge-in, the system is speak-
ing and so should only yield the turn if the user?s
speech is more important than its own. For many
domains, we view non-understood input as less
important than the system?s prompt and so, in this
case, the system should not release the turn by
stopping the prompt and initiating a clarifying sub-
dialogue. On the practical side, there is a high
likelihood that non-advancing input is not system
directed, to which the system should neither con-
sume, in terms of belief state updating, nor re-
spond to, in terms of asking for clarification. In
the rare case of non-understood system directed
speech, the user can easily repeat their utterance.
Here, we note that in the event that the user is
backchanneling, the PBR model will behave cor-
rectly and not release the turn.
The PBR approach differs from standard barge-
in approaches in several respects. First, standard
barge-in stops the prompt (i.e., transitions from
State 1 to State 2) if either the VAD or the partial
hypothesis suggests that there is speech; our ap-
proach? using acoustic, language model, and lat-
tice features ? predicts whether the input is likely
to contain an interpretable recognition result. Sec-
2The threshold update values were determined empiri-
cally by the authors.
ond, standard barge-in uses a static threshold; our
approach uses dynamic thresholds that adapt to
the user?s acoustic environment. Parameter adjust-
ments are straightforward since our method auto-
matically classifies each barge-in as NUBI or UBI.
In practice, the prompt will be paused incorrectly
only a few times in a noisy environment, after
which the adaptive thresholds will prevent incor-
rect pauses at the expense of being less responsive
to true user speech. If the noise level decreases,
the thresholds will become more sensitive again,
enabling swifter responses. Finally, with the ex-
ception of Strom and Seneff, standard approaches
always discard the prompt; our approach can re-
sume the prompt if recognition is not understood
or is proceeding poorly, enabling the system to
resume speaking before recognition is complete.
Moreover, resumption yields a natural user expe-
rience as it often creates a repetition disfluency
(?Ok, sixty - sixty one c?), which are rarely no-
ticed by the listener (Martin and Strange, 1968).
An example dialogue fragment is shown in Fig-
ure 2, with the state transitions shown above. Note
the transition from State 2 to State 1, which is the
system resuming speech during recognition. This
recognition stream, produced by non-system di-
rected user speech, does not end until the user says
?repeat? for the last time.
4 Evaluation Results
The PBR model was evaluated during the Spoken
Dialog Challenge 2012-2013 in a live Lets Go!
bus information task. In this task, the public can
access bus schedule information during off hours
in Pittsburgh, PA via a telephonic interaction with
a dialogue system (Raux et al, 2005). The task
can be divided into five sub-tasks: route, origin,
destination, date/time, and bus schedules. The last
sub-task, bus schedules, provides information to
the user whereas the first four gather information.
We entered two systems using the same POMDP-
based DM (Williams, 2012). The first system, the
?Baseline?, used the standard barge-in model with
VAD barge-in detection and barge-in disabled in
387
Figure 3: Estimated success rate for the PBR and Baseline systems. Stars indicate p<0.018 with ?2 test.
a small number of dialogue states that appeared
problematic during initial testing. The second sys-
tem used the PBR model with an Incremental In-
teraction Manager (Selfridge et al, 2012) to pro-
duce speculative actions in State 3. The pub-
lic called both systems during the final weeks of
2011 and the start of 2012. The DM applied a lo-
gistic regression based confidence measure to de-
termine whether the recognition was understood.
Both systems used the AT&T WATSONSM speech
recognizer (Goffin et al, 2005) with the same
sub-task specific rule-based language models and
standard echo cancellation techniques. The beam
width was set to maximize accuracy while still
running faster than real-time. The PBR system
used a WATSON modification to output lattice-
aware partial results.
Call and barge-in statistics are shown in Table
3. Here, we define (potential) barge-in (some-
what imprecisely) as a full recognition that at
some point overlaps with the system prompt, as
determined by the call logs. We show the calls
with barge-in before the bus schedule sub-task was
reached (BI-BS) and the calls with barge-in during
any point of the call (BI All). Since the Baseline
system only enabled barge-in at specific points in
the dialogue, it has fewer instances of barge-in
(Total Barge-In) and fewer barge-in calls. Regret-
fully, due to logging issues with the PBR system,
recognition specific metrics such as Word Error
Rate and true/false barge-in rates are unavailable.
4.1 Estimated Success Rate
We begin by comparing the success rate and
efficiency between the Baseline and PBR sys-
Table 3: Baseline and PBR call/barge-in statistics.
Baseline PBR
Total Calls 1027 892
BI-BS 228 (23%) 345 (39%)
BI All 281 (27%) 483 (54%)
Total Barge-In 829 1388
tems. Since task success can be quite difficult to
measure, we use four increasingly stringent task
success definitions: Bus Times Reached (BTR),
where success is achieved if the call reaches the
bus schedule sub-task; List Navigation (List Nav.),
where success is achieved if the user says ??next?,
?previous?, or ?repeat? ? the intuition being that
if the user attempted to navigate the bus sched-
ule sub-task they were somewhat satisfied with
the system?s performance so far; and Immediate
Exit (BTR2Ex and ListNav2Ex), which further
constrains both of the previous definitions to only
calls that finish directly after the initial visit to the
bus times sub-task. Success rate for the defini-
tions were automatically computed (not manually
labeled). Figure 3 shows the success rate of the
PBR and Baseline systems for all four definitions
of success. It shows, from left to right, Barge-In,
No Barge-In (NBI), and All calls. Here we restrict
barge-in calls to those where barge-in occurred
prior to the bus schedule task being reached.
For the calls with barge-in, a ?2 test finds sig-
nificant differences between the PBR and Base-
line for all four task success definitions. However,
we also found significant differences in the NBI
calls. This was surprising since, when barge-in
is not triggered, both systems are ostensibly the
same. We speculate this could be due to the Base-
line?s barge-in enabling strategy: an environment
that triggers barge-in in the Baseline would always
trigger barge-in in the PBR model, whereas the
converse is not true as the Baseline only enabled
barge-in in some of the states. This means that
there is a potential mismatch when separating the
calls based on barge-in, and so the fairest compar-
ison is using All the calls. This is shown on the far
right of Figure 3. We find that, while the effect is
not as large, there are significant differences in the
success rate for the PBR model for the most and
least stringent success definition, and very strong
trends for the middle two definitions (p < 0.07 for
BTR2Ex and p < 0.054 for List Nav.). Taken as
a whole, we feel this offers compelling evidence
388
Figure 4: Seconds from beginning of dialogue to
reaching the Bus Schedule Information sub-task
that the PBR method is more effective: i.e. yields
higher task completion.
Next, we turn our attention to task efficiency.
For this, we report the amount of clock time from
the beginning of the call to when the Bus Schedule
sub-task was reached. Calls that do not reach this
sub-task are obviously excluded, and PBR times
are adjusted for the reaction sound (explained in
Section 3.3). Task efficiency is reported by cu-
mulative percentage in Figure 4. We find that,
while the NBI call times are nearly identical for
both systems, the PBR barge-in calls are much
faster than the Baseline calls. Here, we do not
feel the previously described mismatch is partic-
ularly problematic as all the calls reached the goal
state and the NBI are nearly identical. In fact, as
more NUBI should actually reduce efficiency, the
potential mismatch only strengthens the result.
Taken together, these results provide substantial
evidence that the PBR model is more effective and
more efficient than the Baseline. In order to ex-
plain PBR?s performance, we explore the effect of
prediction and resumption in isolation.
4.2 State 1: Speaking Prediction
State 1 is responsible for pausing the prompt, the
goal being to pause the prompt for UBI input and
not to pause the prompt for NUBI input. The
prompt is paused if a partial?s stability score meets
or exceeds the T1 threshold. We evaluate the ef-
ficacy of State 1 and T1 by analyzing the statis-
tics of NUBI/UBI input and Paused/Not Paused
(hereafter Continued) prompts. Since resuming
the prompt during recognition affects the recog-
nition outcome, we restrict our analysis to recog-
nitions that do not transition from State 2 back
to State 1. For comparison we show the overall
UBI/NUBI percentages for the Baseline and PBR
systems. This represents the recognition distri-
Table 4: Evaluation of T1, off-line PBR, and Base-
line VAD. For T1 we respectively (?-? split) show
the UBI/NUBI % that are Paused/Continued, the
Paused/Continued % that are UBI/NUBI, and the
percentage over all recognitions
T1 (%) VAD (%)
Paused Continued PBR BL
UBI 72-40-26 28-29-10 36 54
NUBI 61-60-39 39-71-25 64 46
bution for the live Baseline VAD detection and
off-line speculation for the PBR model. Recall
PBR does have VAD activation preceding partial
results and so the off-line PBR VAD shows how
the model would have behaved if it only used the
VAD for detection, as the Baseline does.
Table 4 provides a number of percentages, with
three micro-columns separated by dashes (?-?) for
T1. The first micro-column shows the percent-
age of UBI/NUBI that either Paused or Contin-
ued the prompt (sums to 100 horizontally). The
second micro-column shows the percentage of
Paused/Continued that are UBI/NUBI (sums to
100 vertically). The third micro-column shows
the percentage of each combination (e.g. UBI and
Paused) over all the barge-in recognitions. The
VAD columns show the percentage of UBI/NUBI
that (would) pause the prompt.
We first look at UBI/NUBI percentage that are
Paused/Continued (first micro-column): We find
that 72% of UBI are paused and 28% are Contin-
ued versus 61% of NUBI that are Paused with 39%
Continued. We now look at the Paused/Continued
percentage that are UBI/NUBI (second micro-
column): We find that 40% of Paused are UBI
and 60% are NUBI, whereas 29% of Continued
are UBI and 71% are NUBI. So, while T1 sus-
pends the prompt for the majority of NUBI (not
desirable, though expected since T1 starts at 0),
it has high precision when continuing the prompt.
This reduces the number of times that the prompt
is paused erroneously for NUBI while minimizing
incorrect (UBI) continues. This is clearly shown
by considering all of the recognitions (third micro-
column). We find that PBR erroneously paused
the prompt for 39% of recognitions, as opposed to
64% for the off-line PBR and 46% for the Base-
line. This came at the cost of reducing the number
of correct (UBI) pauses to 26% from 36% (off-line
PBR) and 54% (Baseline VAD).
The results show that the T1 threshold had
389
Figure 5: Secs from Speech Start to Final Result
modest success at discriminating UBI and NUBI;
while continuing the prompt had quite a high
precision for NUBI, the recall was substantially
lower. We note that, since erroneous pauses lead
to resumptions and erroneous continues still lead
to a new speech act, there is minimal cost to these
errors. Furthermore, in our view, reducing the per-
centage of recognitions that pause and resume the
prompt is more critical as these needlessly disrupt
the prompt. In this, T1 is clearly effective, reduc-
ing the percentage from 64% to 39%.
4.3 State 2: Silent Prediction
State 2 governs whether the prompt will remain
paused or be resumed during incremental recogni-
tion. This decision depends on the time parameter
T2, which should trigger resumptions for NUBIs.
Since the act of resuming the prompt during recog-
nition changes the outcome of the recognition, it
is impossible to evaluate how well T2 discrimi-
nated recognition results. However, we can evalu-
ate the effect of that resumption by comparing UBI
percentages between the PBR and Baseline sys-
tems. We first present evidence that T2 is most ac-
tive during longer recognitions, and then show that
longer Baseline recognitions have a lower UBI
percentage than longer PBR recognitions specif-
ically because of T2 resumptions. ?Recognitions?
refer to speech recognition results, with ?longer?
or ?shorter? referring to the clock time between
speech detection and the final recognition result.
We first report the PBR and Baseline response
and recognition time. We separate the PBR barge-
in recognitions into two groups: State 2?State 3,
where the system never transitions from State 2
to State 1, and State 2?State 1, where the sys-
tem resumes the prompt during recognition, tran-
sitioning from State 2 to State 1. The cumulative
percentages of the time from speech detection to
final recognition are shown in Figure 5. We find
that the State 2?State 3 recognitions are far faster
Figure 6: UBI % by minimum recognition time
than the Baseline recognitions, which in turn are
far faster than the State 2?State 1 recognitions.
The difference between PBR and Baseline recog-
nitions implies that T2 has greater activation dur-
ing longer recognitions. Given this, the overall
barge-in response time for PBR should be faster
than the Baseline (as the PBR system is resum-
ing where the Baseline is silent). Indeed this is
the case: the PBR system?s overall mean/median
response time is 1.58/1.53 seconds whereas Base-
line has a mean/median response time of 2.61/1.8
seconds.
The goal of T2 is for the system to resume when
recognition is proceeding poorly, and we have
shown that it is primarily being activated during
longer recognitions. If T2 is functioning properly,
recognition length should be inversely related to
recognition performance, and longer recognitions
should be less likely to be understood. Further-
more, if T2 resumption improves the user?s expe-
rience then longer PBR recognitions should per-
form better than Baseline recognitions of compa-
rable length. Figure 6 presents the UBI percent-
age by the minimum time for recognitions that
reach State 2. We find that, when all recogni-
tions are accounted for (0 second minimum), the
Baseline has a higher rate of UBI. However, as
recognition time increases the Baseline UBI per-
centage decreases (suggesting successful T2 func-
tioning) whereas the PBR UBI percentage actu-
ally increases. Since longer PBR recognitions are
dominated by T2 resumptions, we speculate this
improvement is driven by users repeating or initi-
ating new speech that leads to understanding suc-
cess, as the PBR system is responding where the
Baseline system is silent.
4.4 Resumption
The PBR model relies on resumption to recover
from poor recognitions, either produced in State 2
or State 3. Instead of a resumption, the Baseline
390
Figure 7: Sub-Task Abandonment Rate. NUBI is
different at p < 0.003
system initiates a clarifying sub-dialogue when a
barge-in recognition is not understood. We com-
pare these two behaviors using the call abandon-
ment rate ? the user hangs-up ? of sub-tasks
with and without NUBI. Here, we exclude the Bus
Schedule sub-task as it is the goal state.
Figure 7 shows the call abandonment rate for
sub-tasks that either have or do not have NUBI.
We find that there is a significant difference in
abandoned calls for NUBI sub-tasks between the
two systems (33% vs 48%, p < 0.003 using a ?2
test), but that there is no difference for the calls
that do not have NUBI (7.6% vs 8.4%). This re-
sult shows that prompt resumption is viewed far
more favorably by users than initiating a clarify-
ing sub-dialogue.
5 Discussion and Conclusion
The above results offer strong evidence that the
PBR model increases task success and efficiency,
and we found that all three states contribute to
the improved performance by creating a more ro-
bust, responsive, and natural interaction. T1 pre-
diction in State 1 reduced the number of spurious
prompt suspensions, T2 prediction in State 2 led to
improved understanding performance, and prompt
resumption (States 2 and 3) reduced the number of
abandoned calls.
An important feature of the Prediction-based
Barge-in Response model is that, while it lever-
ages incremental speech processing for barge-in
processing, it does not require an incremental di-
alogue manager to drive its behavior. Since the
model is also domain independent and does not
require access to internal dialogue manager com-
ponents, it can easily be incorporated into any ex-
isting dialogue system. However, one limitation of
the current model is that the prediction thresholds
are hand-crafted. We also believe that substan-
tial improvements can be made by explicitly at-
tempting to predict eventual understanding instead
of using the stability score and partial production
rate as a proxy. Furthermore, the PBR model does
not distinguish between the causes of the non-
understanding, specifically whether the input con-
tained in-domain user speech, out-of-domain user
speech, or background noise. This case is specifi-
cally applicable in domains where system and user
speech are in the same channel, such as interact-
ing via speaker phone. In this context, the system
should be able to initiate a clarifying sub-dialogue
and release the turn, as the system must be more
sensitive to the shared acoustic environment and
so its current prompt may be less important than
the user?s non-understood utterance.
The results challenge a potential assumption re-
garding barge-in: that barge-in indicates greater
user pro-activity and engagement with the task.
One of the striking findings was that dialogues
with barge-in are slower and less successful than
dialogues without barge-in. This suggests that,
for current systems, dialogues with barge-in are
more indicative of environmental difficulty than
user pro-activity. The superior performance of
the PBR model, which is explicitly resistant to
non-system directed speech, implies that domi-
nant barge-in models will have increasingly lim-
ited utility as spoken dialogue systems become
more prevalent and are used in increasingly dif-
ficult environments. Furthermore, within the con-
text of overall dialogue systems, the PBR model?s
performance emphasizes the importance of contin-
uous processing for future systems.
This paper has proposed and evaluated the
Prediction-based Barge-in Response model. This
model?s behavior is driven by continuously pre-
dicting whether a barge-in recognition will be un-
derstood successfully, and combines incremental
speech processing techniques with a prompt re-
sumption procedure. Using a live dialogue task
with real users, we evaluated this model against
the standard barge-in model and found that it led
to improved performance in both task success and
efficiency.
Acknowledgments
Many thanks to Vincent Goffin for help with this
work, and to the anonymous reviewers for their in-
sightful comments and critique. We acknowledge
funding from the NSF under grant IIS-0713698.
391
References
T. Baumann, M. Atterer, and D. Schlangen. 2009. As-
sessing and improving the performance of speech
recognition for incremental systems. In Proc.
NAACL: HLT, pages 380?388. Association for Com-
putational Linguistics.
V. Goffin, C. Allauzen, E. Bocchieri, D. Hakkani-Tur,
A. Ljolje, S. Parthasarathy, M. Rahim, G. Riccardi,
and M. Saraclar. 2005. The AT&T WATSON
speech recognizer. In Proceedings of ICASSP, pages
1033?1036.
James G Martin and Winifred Strange. 1968. The per-
ception of hesitation in spontaneous speech. Percep-
tion & Psychophysics, 3(6):427?438.
Ian McGraw and Alexander Gruenstein. 2012. Es-
timating word-stability during incremental speech
recognition. In in Proc. of Interspeech 2012.
A. Raux, B. Langner, D. Bohus, A.W. Black, and
M. Eskenazi. 2005. Lets go public! taking a spo-
ken dialog system to the real world. In in Proc. of
Interspeech 2005.
A. Raux. 2008. Flexible Turn-Taking for Spoken Dia-
log Systems. Ph.D. thesis, CMU.
Richard C Rose and Hong Kook Kim. 2003. A
hybrid barge-in procedure for more reliable turn-
taking in human-machine dialog systems. In Auto-
matic Speech Recognition and Understanding, 2003.
ASRU?03. 2003 IEEE Workshop on, pages 198?203.
IEEE.
E.O. Selfridge and P.A. Heeman. 2010. Importance-
Driven Turn-Bidding for spoken dialogue systems.
In Proc. of ACL 2010, pages 177?185. Association
for Computational Linguistics.
E.O. Selfridge, I. Arizmendi, P.A. Heeman, and J.D.
Williams. 2011. Stability and accuracy in incre-
mental speech recognition. In Proceedings of the
SIGdial 2011.
E.O. Selfridge, I. Arizmendi, P.A. Heeman, and J.D.
Williams. 2012. Integrating incremental speech
recognition and pomdp-based dialogue systems. In
Proceedings of the SIGdial 2012.
Nikko Stro?m and Stephanie Seneff. 2000. Intelligent
barge-in in conversational systems. Procedings of
ICSLP.
Jason D Williams. 2012. A critical analysis of two sta-
tistical spoken dialog systems in public use. In Spo-
ken Language Technology Workshop (SLT), 2012
IEEE, pages 55?60. IEEE.
Fan Yang and Peter A. Heeman. 2010. Initiative con-
flicts in task-oriented dialogue?. Computer Speech
Language, 24(2):175 ? 189.
392
A Appendix
This diagram represents the possible operating positions the Prediction-based Barge-in Response
model can be in. If the prompt is complete, the PBR model applies the dialogue policy to the final
recognition result and initiates the on-policy speech act. If the prompt was finished without being paused
it decrements R. In the latter case (barge-in), it operates using the three states as described in Section 2.
When a partial is recognized the Stability Score is computed and compared to the T1 threshold parame-
ter. If the score is below T1 the partial is discarded. Otherwise, if the model is in State 1 (the prompt is
on) the prompt is paused, a timer is started, and control transitions to State 2. If the model is in State 2
the timer is restarted. After transitioning to State 2, control only returns to State 1 if the timer exceeds
T2. At this time, the prompt is resumed and the resumption parameter R is incremented. Control im-
mediately transitions to State 3 if a final recognition result is received. The result is evaluated by the
dialogue manager, and the new speech act is returned. If the speech act indicates the recognition was not
understood successfully, the system either resumes (if in State 1) or continues (if in State 2). In the case
of resumption, R is incremented. If the new speech act indicates understanding success, the new speech
is immediately produced.
393
