Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 847?857, Prague, June 2007. c?2007 Association for Computational Linguistics
Multiple Alignment of Citation Sentences with
Conditional Random Fields and Posterior Decoding
Ariel S. Schwartz?
EECS, Computer Science Division
UC Berkeley
Berkeley, CA 94720-1776
sariel@cs.berkeley.edu
Anna Divoli, Marti A. Hearst
School of Information
UC Berkeley
Berkeley, CA 94720-4600
{hearst,divoli}@ischool.berkeley.edu
Abstract
In scientific literature, sentences that cite re-
lated work can be a valuable resource for
applications such as summarization, syn-
onym identification, and entity extraction.
In order to determine which equivalent en-
tities are discussed in the various citation
sentences, we propose aligning the words
within these sentences according to semantic
similarity. This problem is partly analogous
to the problem of multiple sequence align-
ment in the biosciences, and is also closely
related to the word alignment problem in sta-
tistical machine translation. In this paper
we address the problem of multiple citation
concept alignment by combining and mod-
ifying the CRF based pairwise word align-
ment system of Blunsom & Cohn (2006)
and a posterior decoding based multiple se-
quence alignment algorithm of Schwartz &
Pachter (2007). We evaluate the algorithm
on hand-labeled data, achieving results that
improve on a baseline.
1 Introduction
The scientific literature of biomedicine, genomics,
and other biosciences is a rich, complex, and con-
tinually growing resource. With appropriate infor-
mation extraction and retrieval tools, bioscience re-
searchers can use the contents of the literature to
further their research goals. With online full text
?Current address: Department of Bioengineering, Univer-
sity of California, San Diego, La Jolla, CA 92093-0412. Email:
sariel@ucsd.edu.
of journal articles finally becoming the norm, new
forms of citation analysis become possible.
Nearly every statement in biology articles is
backed up by at least one citation, and, conversely,
it is quite common for papers in the bioscience do-
main to be cited by 30?100 other papers. The cited
facts are typically stated in a more concise way in the
citing papers than in the original papers. Since the
same facts are repeatedly stated in different ways in
different papers, statistical models can be trained on
existing citation sentences to identify similar facts in
unseen text. Citation sentences also have the poten-
tial to be useful for text summarization and database
curation. Figure 1 shows an example of three differ-
ent citation sentences to the same target paper.
Most citation analysis work focuses on the cita-
tion network structure, to determine which papers
are most central, or uses co-citation analysis to de-
termine which papers are similar to one another in
content (White, 2004; Liu, 1993; Garfield, 1955;
Lipetz, 1965; Giles et al, 1998). In this paper we
focus instead on analyzing the sentences that sur-
round the citations to related work, which we termed
citances in Nakov et al (2004). In that paper we
note that one subproblem for using citances for au-
tomated analysis is to identify the different concepts
mentioned; a given paper may be cited for more than
one fact or relation.
Citances often state similar information using
varying words and phrases. In order to build con-
cise summaries, those entities and relations that are
expressed in different ways should be matched up,
or aligned, so that subsequent processing steps will
know what the core concepts are. In this paper we
847
Exam
ple o
f una
ligne
d cit
ance
s
?In r
espo
nse t
o ge
noto
xics
tress
, Ch
k1 a
nd C
hk2 
phos
phor
ylate
Cdc
25A
 on N
-term
inal 
sites
 and
 targ
et it 
rapid
ly fo
r ubi
quiti
n-de
pend
ent d
egra
datio
n (M
ailan
det 
al, 2
000,
 200
2; 
Mol
inari
et al
, 200
0 ; Fa
lcke
t al, 
2001
; Shi
muta
et al
, 200
2; B
usin
oet 
al, 2
003)
, wh
ich i
s 
thou
ght t
o be
 cen
tral t
o the
 S an
d G2
 cell
 cyc
le ch
eckp
oints
 (Ba
rtek
and 
Luk
as, 2
003;
 
Don
zelli
and 
Drae
tta, 2
003 )
.?
?Giv
en th
at C
hk1 
prom
otes
 Cdc
25A
 turn
over
 in r
espo
nse t
o DN
Ada
mag
e in 
vivo
 
(Fal
cke
t al. 
2001
; Sor
ense
n et 
al. 2
003)
 and
that 
Chk
1 is 
requ
ired 
for C
dc25
A 
ubiq
uitin
ation
by S
CF?-T
RCP
 in v
itro,
 we 
expl
ored
 the 
role 
of C
dc25
A 
phos
phor
ylati
onin
the u
biqu
itina
tion
proc
ess.?
?Sin
ce ac
tivat
ed p
hosp
hory
lated
Chk
2-T68
is in
volv
ed in
 pho
spho
rylat
iona
nd 
degr
adat
ion o
f Cd
c25A
 (Fal
cke
t al.,
 200
1 , Fa
lcke
t al.,
2002
; Ba
rtek
and 
Luk
as, 
2003
), we
 also
 exa
mine
d the
 leve
ls of
Cdc
25A
 in 2
fTG
H an
d U3
A ce
lls e
xpos
ed to
 
?-IR.?
Figure 1: Example of three unaligned citances.
Alig
nme
nt af
ter n
orm
aliza
tion
resp
onse
geno
toxi
cstr
essC
hk1
 Chk
2ph
osph
oryl
ateC
dc25
AN
 term
inal
 site
s tar
get 
rapi
dly u
biqu
itin
depe
nden
tdeg
rada
tion
thou
ght 
cent
ral S
 G2 
cell 
cycl
e ch
eckp
oint
s
Give
n Ch
k1p
rom
otes
 Cdc
25A
turn
over
resp
onse
DNA
 dam
age
vivo
 Chk
1re
quir
ed
Cdc
25A
ubiq
uitin
atio
nSC
F be
ta T
RCP
 vitr
o ex
plor
edr
ole C
dc25
Aph
osph
oryl
atio
n
ubiq
uitin
atio
npr
oces
s
activ
ated
 pho
spho
ryla
tedC
hk2
T68
invo
lved
 pho
spho
ryla
tion
degr
adat
ionC
dc25
A
exam
ined
leve
ls C
dc25
A2f
TGH
 U3A
 cell
s exp
osed
 gam
ma I
R
Figure 2: Example of three normalized aligned ci-
tances. Homologous entities are colored the same.
Unaligned entities are black.
build on the work of Nakov et al (2004) by tackling
the entity normalization step.
The citance alignment problem is partially anal-
ogous to the problem of multiple alignment of bi-
ological sequences (Durbin et al, 1998). In both
cases the goal is to align homologous entities that
are derived from the same ancestral entity. While in
biology homology is well-defined in the molecular
level, in the citances case it is defined in the seman-
tic level, which is much more subjective. Given a
group of citances that cite the same target paper, we
loosely define semantic homology as a symmetric,
transitive, and reflexive relation between two enti-
ties (words or phrases) in the same or different ci-
tance that have similar semantics in the context of
the cited paper.
Figure 1 shows an example of three citances that
cite the same target paper (Falck et al, 2001). A
multiple alignment of the entities in the same ci-
tances (after removal of stopwords) is shown in Fig-
ure 2. Homologous entities are colored the same.
This small example illustrates some of the main
challenges of multiple citance alignment (MCA).
While orthographic similarity can help to identify
semantic homology (e.g., phosphorylate and phos-
phorylation), it can also be misleading (e.g., cell cy-
cle and U3A cells). In addition, semantic homology
might not include any orthographic clues (e.g., geno-
toxic stress and DNA damage).
Unlike global multiple sequence alignment
(MSA) in genomics, where each character can be
aligned to at most one character in every other se-
quence, in multiple citance alignment, each word
can be aligned to any number of words in other sen-
tences. Another major difference between the two
problems is the fact that while the sequential order-
ing of characters must be maintained in multiple se-
quence alignment, this is not the case for multiple
citance alignment.
MCA is also related to the problem of word align-
ment in statistical machine translation (SMT) (Och
and Ney, 2003). However, unlike SMT alignment,
MCA aligns multiple citances in the same language
rather than a pair of sentences in different languages.
In this paper we present an MCA algorithm that
is based on an extension to the posterior decoding
algorithm for MSA called AMAP (Schwartz et al,
2006; Schwartz and Pachter, 2007), with an under-
lying pairwise alignment model based on the CRF
SMT alignment of Blunsom & Cohn (2006).
2 Multiple citance alignments
Let G , {C1, C2, . . . , CK} be a group of K ci-
tances that cite the same target paper, where the ith
citance is a sequence of words Ci , Ci1C
i
2 ? ? ?C
i
ni ,
and ci , {ci1, c
i
2, . . . , c
i
ni} is the set of word indices
of Ci. A pairwise citance alignment of Ci and Cj
is an equivalence (symmetric, reflexive, and transi-
tive) relation ?ij on the set ci ? cj . The expres-
sion cik ?ij c
j
l means that according to the pairwise
alignment?ij word k in citance Ci and word l in ci-
tance Cj are aligned. A multiple citance alignment
(MCA) is an equivalence relation ?,
(?
ij ?ij
)+
on the set
?
i c
i, which is the transitive closure of
the union of all pairwise alignments of citance pairs
in G. Taking the transitive closure and not only
the union of all pairwise alignments ensures that the
MCA is an equivalence relation.
An MCA ? defines a partition of the set of all
word indices c ,
?
ik {c
i
k}, which is of size n ,
848
|c| =
?
i n
i. Therefore, the number of distinct
MCAs of G is the number of partitions of a set of
size n. This number is called the nth Bell number
(Rota, 1964)
Bn ,
1
e
??
k=0
kn
k!
. (1)
Asymptotically,Bn grows faster than an exponential
but slower than a factorial. For example B100 ?
10116. Obviously, enumerating all possible MCAs
is impractical even for small problems.
3 Probabilistic model for MCA
Unlike biological sequences, for which pair-HMMs
are a natural choice for modeling evolutionary pro-
cesses between two sequences, there is no simple
generative model that can be used for modeling
pairwise citance alignment. Most of the work on
pairwise alignment of sentences at the word level
has been done in the statistical machine translation
(SMT) community.
Och & Ney (2003) present an overview and com-
parison of the most common models used for SMT
word alignments. Out of the models they describe,
the HMM models are the most expressive mod-
els that can compute posterior probabilities using
the forward-backward algorithm. However, unlike
sequence alignments, there are no ordering con-
straints in word alignments, and the alignments are
many-to-many as opposed to one-to-one. Therefore,
the SMT HMM models cannot be based on pair-
HMMs, which generate two sentences simultane-
ously. Rather, they are directional models that model
the probability of generating a target sentence given
a source sentence. In other words they only model
many-to-one alignments, recovering the many-to-
many alignments in a preprocessing step. Therefore,
SMT HMMs can only compute the posterior proba-
bilities P (cik ; c
j
l |C
i, Cj) and P (cjl ; c
i
k|C
i, Cj),
where the relation ; represents the (directional)
event that a source word is translated into a target
word. Nevertheless, recently such posterior proba-
bilities have been used in SMT word alignment sys-
tem as an alternative to Viterbi decoding, and helped
to improve the performance of such systems (Ma-
tusov et al, 2004; Liang et al, 2006).
Generative models like HMMs have several lim-
itations. First, they require relatively large train-
ing data, which is difficult to attain in case of SMT
word alignment, and even more so in the case of
MCA. Second, generative models explicitly model
the inter-dependence of different features, which re-
duces the ability to incorporate multiple arbitrary
features into the model. Since orthographic similar-
ity is not a strong enough indication for semantic ho-
mology in MCA, we would like to be able to incor-
porate multiple inter-dependent features into a single
model, including orthographic, contextual, ontolog-
ical, and lexical features.
Recently, several authors have described dis-
criminative SMT alignment models (Moore, 2005;
Lacoste-Julien et al, 2006; Blunsom and Cohn,
2006). However, to the best of our knowledge only
the model of Blunsom & Cohn (2006), which is
based on a Conditional Random Field (CRF) (Laf-
ferty et al, 2001), can compute word indices pairs?
directional posterior probabilities, like those com-
puted by the HMM models. Therefore, we decided
to adopt the CRF-based model to the MCA problem.
3.1 Conditional random fields for word
alignment
The model of Blunsom & Cohn (2006) is based on
a linear chain CRF, which can be viewed as the
undirected version of an HMM. The CRF models
a many-to-one pairwise alignment, in which every
source word can get algned to zero or one target
words, but every word in the target sentence can be
the target of multiple source words. CRFs define
a conditional distribution over a latent labeling se-
quence given observation sequence(s). In the case
of CRF for word alignment, the observed sequences
are the source and target sentences (citances), and
the latent labeling sequence is the mapping of source
words to target word-indices. Given a source citance
Ci of length ni, and a target citance Cj of length nj ,
the many-to-one alignment of Ci to Cj is the rela-
tion ;. Since this is a many-to-one alignment, ;
can be represented by a vector a of length ni. The
CRF models the probability of the alignment a con-
ditioned on Ci and Cj as follows:
P?(a|C
i, Cj) =
exp
(?
t
?
k ?kfk(t, at?1, at, C
i, Cj)
)
Z?(Ci, Cj)
, (2)
849
where f , {fk} are the model?s features, ? , {?k}
are the features? weights, and Z?(Ci, Cj) is the par-
tition (normalization) function which is defined as:
Z?(C
i, Cj) ,
?
a
exp
(
?
t
?
k
?kfk(t, at?1, at, C
i, Cj)
)
.
(3)
Parameters are estimated from fully observed data
(manually aligned citances) using a maximum a pos-
teriori estimate. The parameter estimation proce-
dure is described in more details in the original pa-
per. Blunsom & Cohn (2006) use Viterbi decoding
to find an alignment of two sentences given a trained
CRF model, a? , argmaxa P?(a|C
i, Cj). How-
ever, the posterior probabilities of the labels at each
position can be calculated as well using the forward-
backward algorithm:
P?(c
i
l ; c
j
k|C
i, Cj) = P?(al = c
j
k|C
i, Cj) =
?l(c
j
k|C
i, Cj)?l(c
j
k|C
i, Cj)
Z?(Ci, Cj)
(4)
where ?l and ?l are the forward and backward vec-
tors that are computed with the forward-backward
algorithm (Lafferty et al, 2001).
3.2 The posterior decoding algorithm for MCA
Ultimately, the success of an MCA algorithm should
be judged by its effect on the success of the citance
analysis systems that use MCAs as their input. How-
ever, measuring this effect directly is difficult, since
high-level tasks such as summarization are difficult
to evaluate objectively. More to the point, it is dif-
ficult to quantify the contribution of the MCA ac-
curacy to the accuracy of the high-level system that
uses it. A more practical alternative is to measure the
accuracy of MCAs directly using a meaningful ac-
curacy measure, under the simplifying assumption
that there is a strong correlation between the mea-
sured MCA accuracy and the performance of the
high-level application.
We argue that a useful utility function should be
correlated (or even identical) to the accuracy mea-
sure used to evaluate the performance of an algo-
rithm. In addition, the utility function should be
easily decomposable, to enable direct optimization
using posterior-decoding. Although any accuracy
measure that is acceptable as a single performance
measure can be used to guide the design of the util-
ity function, metric-based accuracy measures have
several noticeable advantages. First, a metric for-
malizes the intuitive notion of distance. Hence, an
accuracy measure which is based on a metric fol-
lows the intuition that reducing the distance to the
correct answer should increase the accuracy of the
predicted answer. Therefore, defining a metric space
for the objects of a given problem leads to a nat-
ural definition of accuracy. Another advantage of
using a metric-based accuracy measure is the abil-
ity to provide bounds in the search space using the
triangle inequality. For example, while searching for
the answer with the optimal (metric-based) expected
utility, a step of length x can only change the ex-
pected utility as well as the actual utility by at most
?x units. Examples of more complex bounds us-
ing metric loss functions are described in (Schlu?ter
et al, 2005) and (Domingos, 2000).
Schwartz et al (2006) define the alignment met-
ric accuracy (AMA), which is a utility function for
one-to-one MSA. Intuitively, AMA measures the
fraction of characters that are aligned correctly ac-
cording to the reference alignment, either to another
character or to a gap (null). We extend the definition
of AMA to the case of many-to-many MCA.
A good utility function for MCA should give par-
tial credit to word positions that align to some of the
correct word positions while penalizing for aligning
to wrong word positions. To help define such a util-
ity function we define the following. Let mij?(c
j
l ) ,
{cik ? c
i|cik ? c
j
l } be the set of all word positions
in citance Ci that align to word position l in citance
Cj according to MCA ?. We can then define the
following utility function for the MCA ?p of the ci-
tance group G given a reference MCA ?r:
UAMA(?
r,?p) ,
?
ijl|i6=j Uset agreement
(
mij?r(c
j
l ),m
ij
?p(c
j
l )
)
n(K ? 1)
, (5)
where n is the number of word indices in G, K ,
|G| is the number of citances in the group, and
Uset agreement is any utility function for agreement
between sets that assigns values in the range [0, 1].
850
Uset agreement can be viewed as a ?score? assigned
to each word position based on the agreement be-
tween the two alignments with regards to the other
word positions that align to it. Using a 0?1 loss as
the set agreement score is equivalent to the original
AMA. Other utility functions, such as Dice, Jaccard
and Hamming can be used as Uset agreement. How-
ever, only metric-based utility functions will result
in a metric-based UAMA utility function. It is easy
to see that 1 ? UAMA satisfies all the requirements
of a metric, i.e., it is non-negative, equals zero if
and only if ?r=?p, symmetric, and obeys the trian-
gle inequality, since if the triangle inequality holds
for 1 ? Uset agreement, it must hold for a sum of
1 ? Uset agreement values. (We refer the reader to
Schwartz (2007) for a longer discussion of the prop-
erties of the different utility functions.) We define
the AMA for MCA by setting the Uset agreement to
be the Braun-Blanquet coefficient (Braun-Blanquet,
1932), which is defined as:
UBraun?Blanquet
(
mij?r(c
j
l ),m
ij
?p(c
j
l )
)
,
?
???
???
1 if mij?r(c
j
l ) = ?
and mij?p(c
j
l ) = ?
|mij?r (c
j
l )?m
ij
?p (c
j
l )|
max{|mij?r (c
j
l )|,|m
ij
?p (c
j
l )|}
otherwise
.
(6)
Caillez & Kuntz (1996) show that the Braun-
Blanquet coefficient is based on a metric.
As with the MSA case, a family of utility func-
tions can be defined to enable control of the re-
call/precision trade-off. Unlike MSA, in the case of
MCA two free parameters are needed, in order to
have better control of the trade-off using posterior-
decoding. In addition to a gap-factor that controls
the threshold at which unaligned words start to get
aligned, a match-factor is added to enable control of
the number of word-positions each word aligns to.
The result is the following utility function:
U?,?(?
r,?p) ,
1
n(K ? 1)
?
ijl|i6=j
(
?|m
ij
?p (c
j
l )|
|mij?r(c
j
l ) ?m
ij
?p(c
j
l )|
max
{
|mij?r(c
j
l )|, |m
ij
?p(c
j
l )|, 1
}+
?1{mij?r(c
j
l ) = m
ij
?p(c
j
l ) = ?}
)
, (7)
where ? ? [0,?) is a gap-factor, and ? ? (0,?) is
a match factor. The neutral value for both parame-
ters is 1. Increasing ? results in increased utility to
sparser MCAs, while reducing ? increases the util-
ity of denser alignments. However, in the case of
MCA, the gap-factor only affects the first aligned
word position, but it cannot affect the number of
word positions each word is aligned to. The match-
factor adds this functionality by rewarding MCAs
that align words to multiple word positions when
? > 1, and penalizing such MCAs when ? < 1.
Given a group of K citances G and a trained
CRF model, the goal of the MCA algorithm is to
find the MCA ??, argmax?p E?tU?,?(?
t,?p)
that maximizes the expected utility. Since search-
ing the space of possible MCAs exhaustively is in-
feasible, we resort to a simple heuristic for predict-
ing an MCA. Instead of searching for a global opti-
mum, the predicted MCA is defined as the equiva-
lence (symmetric transitive) closure of the union of
multiple local optima. For each target word posi-
tion cjl and every source citance C
i the combina-
tion of source word positions ci? that maximize the
expected set-agreement score of cjl is added to the
predicted MCA. Formally, let P(ci) be the power-
set of ci, then we define the predicted MCA as
?p,
(
;p ?(;p)?1
)+
, where;p is defined as:
;p,
?
ijl|i6=j
{cjl } ? argmax
ci??P(ci)
Emij
?t
(cjl )
?
??|c
i
?|
|mij?t(c
j
l ) ? c
i
?|
max
{
|mij?t(c
j
l )|, |c
i
?|, 1
}+
?1{mij?t(c
j
l ) = c
i
? = ?}
)
. (8)
The value of ;p can be computed from the CRF
directional posterior probabilities as follows:
;p=
?
ijl|i6=j
{cjl } ? argmax
ci??P(ci)
?
ci??P(ci)
P
(
mij?t(c
j
l ) = c
i
?
)
(
?|c
i
?|
|ci? ? c
i
?|
max {|ci?|, |ci?|, 1}
+ ?1{ci? = c
i
? = ?}
)
,
(9)
851
and using an independence assumption we get:
;p?
?
ijl|i6=j
{cjl } ? argmax
ci??P(ci)
?
ci??P(ci)
?
?
?
cik
(
P?(c
i
k ; c
j
l |C
i, Cj)1{cik ? c
i
?}+
(1? P?(c
i
k ; c
j
l |C
i, Cj))1{cik /? c
i
?}
)
)
(
?|c
i
?|
|ci? ? c
i
?|
max {|ci?|, |ci?|, 1}
+ ?1{ci? = c
i
? = ?}
)
.
(10)
Note that although the directional posterior prob-
abilities are used to generate the predicted MCA,
the result is a many-to-many alignment, since the
union is done over all pairs of sequences in both
directions. The calculation in Equation (10) can
be computationally intensive in practice, as it re-
quires |P(ci)|2 = 22n
i
operations for each word
position cjl and citance C
i. This can be over-
come by restricting the combinations of source word
positions (ci? and c
i
?) to include only the the top
MAX SOURCES source words with a minimum
posterior probability of MIN PROB to align to cjl
(P?(cik ; c
j
l |C
i, Cj) ? MIN PROB). In our im-
plementation we set MAX SOURCES to 8 and
MIN PROB to 0.01. Additionally, the probabilities
of each combination ci? can be calculated only once,
since it is independent of ci?. This reduces the to-
tal computational complexity of calculating ?p to
O
(
216(K2 ?K)maxni
{
ni
})
.
4 Data sets
Since citance alignment is a new task, we had to
create our own evaluation and training sets. We re-
stricted the domain of the target papers to molec-
ular interactions, a domain which is actively re-
searched in the biosciences text mining community
(Hirschman et al, 2002). The biologist in our group
annotated citances to 6 target papers. The training
set consisted of 40 citances to 4 different target pa-
pers (10 citances each; we wanted to have variety in
the training set). The development set consisted of
51 citances to the fifth target paper, and the test set
contained 45 citances to the sixth target paper.
For each target paper we downloaded the full text
of those papers citing it that were available in HTML
format. The link structure of the cited references in
the HTML documents allowed us to automatically
extract citances to a given target paper. We defined a
citance to be the full sentence that contains a citation
to the target paper. Each citance was then tokenized,
and normalized by removing all stopwords from a
predefined list.
One goal of the annotation was to cover as much
of the content of the citances as possible. Another
goal was consistency; our biologist manually fol-
lowed a small number of rules to determine seman-
tic similarity. Distinct semantic units (words or
phrases) were identified and given an annotation ID.
Within each group of citances, words or phrases that
share semantic similarity were annotated with the
same ID.
Using the manually annotated citance groups,
pairwise word alignments were generated for every
source-target pair of citances from every group. That
resulted in a training, development, and test sets
of 180, 1275, and 990 pairwise alignments respec-
tively.
Alignments that were used for development and
testing were generated as many-to-many alignments.
However, many-to-many alignments are not suit-
able for the training the many-to-one CRF align-
ment model. When a given source word cik aligns
to multiple words in the target citance, the CRF
model chooses only one target word as a true pos-
itive, while incorrectly treating the other true posi-
tive target words as true negatives. To alleviate this
problem, in such cases we replaced all true-positive
target words other than the first with ?*?, thus forcing
them to act as real true negatives for the purpose of
training. This adjustment does not solve the inher-
ent limitation of the CRF?s many-to-one modeling of
a many-to-many alignment, but it prevents learning
incorrect weights for good features.
5 Feature engineering
The CRF alignment model can combine multiple
overlapping features. We evaluated the effectiveness
of different features by training models on the train-
ing set and evaluating their performance on the de-
velopment set. We considered variations of features
852
that were part of the original system of Blunsom &
Cohn (2006), and also designed new features that are
specific to the problem of MCA.
Orthographic features
We used the following orthographic features from
the original system of Blunsom & Cohn (2006) (be-
low all features are either Boolean indicator func-
tions (b) or real valued (r)):
(b) exact string similarity of source-target words;
(b) every possible source-target pair of length 3 prefixes;
(b) exact string match of length 3 prefixes;
(b) exact string match of length 3 suffixes;
(r) absolute difference in word lengths;
(b) both words are shorter than 4 characters.
In addition, the following orthographic features
were added: indicator that both words include capi-
tal letters, and normalized edit-similarity of the two
words (1?
edit distance(cik,c
j
l )
max{|cik|,|c
j
l |}
).
Markov features
We used the following Markov features from the
original system:
(r) absolute jump width (abs(at?at?1?1), which measures
the distance between the target words of adjacent source
words;
(r) positive jump width (max{at ? at?1 ? 1, 0});
(r) negative jump width (max{at?1 + 1? at, 0});
(b) transition from null aligned source-word to non-null
aligned source-word;
(b) transition from non-null aligned source-word to null
aligned source-word;
(b) transition from null aligned source-word to null aligned
source-word.
In addition we added the following Markov fea-
tures in order to model the tendency of certain words
to be part of longer phrases:
(b) source-word aligns to the same target-word as the previ-
ous source-word;
(b) source-word aligns to the same target-word as the next
source-word;
(b) transition from non-null aligned source-word to non-null
aligned source-word.
Sentence position: We included the relative sen-
tence position feature from the original system,
which is defined as abs( at|cj | ?
t
ci ). Although it was
not expected to be relevant for MCA, since the ci-
tances are not expected to align along the diagonal,
this feature slightly improved the performance of the
development set.
Null: An indicator function for leaving a source-
word unaligned was retained from the original sys-
tem. This is an essential feature since without it the
CRF tends to over-align words, and produces mean-
ingless posterior probabilities.
Ontological features: Orthographic and posi-
tional features alone do not cover all cases of se-
mantic homology. We therefore included features
that are based on domain specific ontologies.
Using an automated script we mapped specific
words and phrases in every citance to MeSH1 terms,
Gene identifiers from Entrez Gene,2 UniProt,3 and
OMIM.4 We then added features indicating when
the source and target words are annotated with the
same MeSH term or the same gene identifier. We
tried numerous features that compare MeSH terms
based on their distance in the ontology, and other
features that indicate whether a word is part of a
longer term. However, none of these feature were
selected for the final system.
In addition to biological ontologies we added a
feature for semantic word similarity between the
source and target words, based on the Lin (1998)
WordNet similarity measure.
6 Results
We modified the CRF alignment system of Blun-
som & Cohn (2006) to support MCA by incorpo-
rating the posterior decoding algorithm from Sec-
tion 3.2 into the existing system. The CRF model
was trained using the features that were selected us-
ing the development set, on a dataset that included
the training and development MCAs. All the perfor-
mance results in this section are reported on the test
set, which includes 990 pairs of citances (45?44/2),
with a total of 34188 words (8547 ? 44). On aver-
age, 20% of the source words are aligned to at least
one other target word in a given reference pairwise
alignment. Since the union of all the pairwise align-
ments results in only a single test MCA, it is hard
to make strong arguments about the performance
1http://www.nlm.nih.gov/mesh/
2http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene
3http://www.pir.uniprot.org/
4http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=OMIM
853
00.10.20.30.40.50.60.70.80.91 0.
3
0.4
0.5
0.6
0.7
0.8
Reca
ll
Precision
Viterb
i_Inte
rsect
ion
Viterb
i_Uni
on
Poste
rior d
ecod
ing
Figure 3: Recall/Precision curve of pairwise ci-
tance alignments comparing Viterbi to posterior
decoding.
of the system in general. Therefore, we concen-
trate our discussion on general trends, and do not
claim that the specific performance numbers we re-
port here are statistically significant. As a point of
comparison, the SMT community has been evalu-
ating performance of word-alignment systems on an
even smaller dataset of 447 pairs of non-overlapping
sentences (Mihalcea and Pedersen, 2003).
We first analyze the performance of the system
on pairwise citance alignments. Instead of tak-
ing the equivalence closure of ;p we take only
the symmetric closure. The result is 990 many-
to-many pairwise alignments. In order to evalu-
ate the effectiveness of the posterior-decoding al-
gorithm, we generate the Viterbi alignments using
the same CRF model. The Viterbi many-to-many
pairwise alignments are then generated by combin-
ing equivalent pairs of many-to-one alignments us-
ing three different standard symmetrization methods
for word-alignment?union, intersection, and the re-
fined method of Och & Ney (2003).
Figure 3 shows the recall/precision trade-off of
the pairwise posterior-decoding and Viterbi align-
ments. The curve for the posterior-decoding align-
ments was produced by varying the gap and match
factors. For the Viterbi alignments, only three re-
sults could be generated (one for each symmetriza-
tion method). However, since the refined method
produced a very similar result to the union, only
the union is displayed in the figure. The impor-
tant observation is that while posterior-decoding en-
ables refined control over the recall/precision trade-
off, the Viterbi decoding generates only three align-
ments, which cover only a small fraction of the curve
at its high precision range. The union of Viterbi
alignments achieves 0.531 recall at 0.913 preci-
sion, which is similar result to the 0.540 recall at
0.909 precision achieved using posterior-decoding
with gap-factor and match-factor set to 1. However,
unlike Viterbi, posterior-decoding produces align-
ments with much higher recall levels, by increas-
ing the match-factor and decreasing the gap-factor.
For example setting the gap-factor to 0.1 and match-
factor to 1.2 results in alignments with 0.636 recall
at 0.517 precision, and setting them to 0.05 and 1.5
results in 0.742 recall at 0.198 precision. Generally,
the gap and match factor affect the accuracy of the
alignments as expected. In particular, the alignments
with the best AMA (0.889) and the best F1-measure
(0.678) are generated when the gap match factor are
set to their natural values (1,1), which theoretically
should maximize the expected AMA.
The performance of the pairwise alignments
validates the underlying probabilistic model,
showing it behaves as theoretically expected.
However, the union of all pairwise alignments
is not a valid MCA. To evaluate the MCA
posterior decoding algorithm, we compared it
to baseline MCAs. The baseline MCAs are
constructed by using only the normalized-edit-
distance
edit distance(cik,c
j
l )
max{|cik|,|c
j
l |}
, and defining cik ;
?
cjl if and only if normalized edit distance(c
i
k, c
j
l ) ?
?, where ? is a distance threshold. The fi-
nal baseline MCA is constructed by taking the
equivalence closure of all pairwise alignments,
??,
(
;? ?(;?)?1)
)+
. The ? parameter can
be used to control the recall/precision trade-off,
since increasing it adds more position-pairs to the
alignment, thus increasing recall, while decreasing
it increases precision.
Figures 4 compares the performance of the CRF
posterior-decoding MCAs with the baseline MCAs.
The different MCAs were produced by varying the
gap and match factors in the case of the posterior-
decoding, and ? for the baseline MCAs. The CRF
curve clearly dominates the baseline curve. How-
ever, they do overlap in range between 0.52 and
0.55 recall (0.84 and 0.90 precision). This is prob-
854
00.10.20.30.40.50.60.70.80.91 0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Reca
ll
Precision
CRF
Base
line
Figure 4: Recall/Precision curve of MCAs
comparing CRF with posterior decoding to
normalized-edit-distance baseline.
ably a range in which for this particular MCA the
orthographic similarity is the most dominant fea-
ture. While the baseline curve drops sharply after
that range, the posterior-decoding curve keeps im-
proving recall up to 0.636 at 0.748 precision, be-
fore a major drop in precision. The additional recall
is due to the ability of the CRF model to incorpo-
rate multiple overlapping features. In particular, the
domain-specific features are important for aligning
words and phrases that have little or no orthographic
similarity. At the other end of the overlap range, the
posterior-decoding achieves better precision than the
baseline for the same recall levels. For example, the
posterior decoding gets 0.381 recall at 0.982 preci-
sion compared with 0.346 at 0.937 for the baseline.
Unlike the pairwise alignment case, the neutral
settings of the gap and match factors did not result in
the best AMA score. This is due to the equivalence
closure heuristic that results in MCAs that are too
dense, since a single link between two equivalence
classes causes them to merge. The best AMA score
(0.886) is obtained by reducing the gap-factor to 0.5
and match-factor to 0.45, in order to compensate for
the effect of the equivalence closure heuristic. For
comparison, the best F1-measure (0.690) is achieved
by setting the gap and match factors to 0.75.
An error analysis on the latter MCA shows that
out of 1400 unique errors, 1194 (85.3%) are false
negatives (FN) and 206 (14.7%) false positives (FP).
Most errors (more than 600) are due to misalign-
ment of subtypes (e.g., cdc, cdc6, cdc25A), oppo-
sites (e.g., phosphorylated and unphosphorylated)
and complex entities (e.g., cell cycle v.s. cell line).
In addition, a large portion of FN errors are due to
not aligning entities that belong to just four equiva-
lence classes (e.g., 97 FN errors caused by terms in
the class of motif, site and domain). Other types of
errors include not aligning plural and singular forms
of the same entities, aligning only part of multi-
word entities, and incorrectly aligning orthographi-
cally similar entities that belong to different classes.
7 Conclusions
We have shown how to derive a posterior-decoding
algorithm that aims at maximizing the expected util-
ity for the MCA problem, as a substitute for the
sequence-annealing algorithm for MSA. Adding a
gap and match factor to the utility function allows
control over the recall/precision trade-off when us-
ing posterior-decoding. Another advantage of opti-
mizing the expected utility with posterior-decoding
methods is the decoupling from the probabilistic
model that generated the posterior probabilities.
This allows the use of CRFs instead of HMMs with
a similar posterior decoding algorithm.
Our experiments were limited by the size of the
labeled data. However, the results support the the-
oretical predictions, and demonstrate the advantage
of posterior-decoding over Viterbi decoding.
Since citances are still a relatively unexplored re-
source, it is still unclear whether the formulation we
presented here for citance alignment is the most use-
ful for applications that use citances for compara-
tive analysis of bioscience text. Unlike biological
sequence alignment, citance alignments are much
more subjective, as they depend on a loose defini-
tion of semantic homology between entities. Even
the definition of the basic entities can vary, since in
many cases noun-compounds and other multi-word
entities seem to be a more natural choice for basic el-
ements of semantic homology and alignment. How-
ever, automatic segmentation and entity recognition
are still difficult tasks in the bioscience text domain
and so new methods are worth investigating.
Acknowledgements: We thank Phil Blunsom and
Trevor Cohn for sharing their CRF-based word
alignment code. This research was supported in part
by NSF DBI 0317510.
855
References
Phil Blunsom and Trevor Cohn. 2006. Discrimina-
tive word alignment with conditional random fields.
In Proceedings of the 21st International Conference
on Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics,
pages 65?72, Sydney, Australia, July. Association for
Computational Linguistics.
Josias Braun-Blanquet. 1932. Plant sociology: the study
of plant communities. McGraw-Hill, New York.
Francis Caillez and Pascale Kuntz. 1996. A contribution
to the study of the metric and euclidean structures of
dissimilarities. Psychometrika, 61(2):241?253.
Pedros Domingos. 2000. A unified bias-variance de-
composition and its applications. In Proceedings
of the Seventeenth International Conference on Ma-
chine Learning, pages 231?238, Stanford, CA. Mor-
gan Kaufmann.
Richard Durbin, Sean R. Eddy, Anders Krogh, and
Graeme Mitchison. 1998. Biological sequence analy-
sis. Probablistic models of proteins and nucleic acids.
Cambridge University Press.
Jacob Falck, Niels Mailand, Randi G. Syljuasen, Jiri
Bartek, and Jiri Lukas. 2001. The ATM-Chk2-
Cdc25A checkpoint pathway guards against radiore-
sistant DNA synthesis. Nature, 410(6830):842?847.
Eugene Garfield. 1955. Citation indexes for science: A
new dimension in documentation through association
of ideas. Science, 122(3159):108?111.
C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence.
1998. Citeseer: an automatic citation indexing sys-
tem. In Proceedings of the third ACM conference on
Digital libraries, pages 89?98. ACM Press.
Lynette Hirschman, Jong C. Park, Junichi Tsujii, Lim-
soon Wong, and Cathy H. Wu. 2002. Accomplish-
ments and challenges in literature data mining for bi-
ology. Bioinformatics, 18(12):1553?1561.
Simon Lacoste-Julien, Ben Taskar, Dan Klein, and
Michael I. Jordan. 2006. Word alignment via
quadratic assignment. In Proceedings of the Human
Language Technology Conference of the NAACL, Main
Conference, pages 112?119, New York City, USA,
June. Association for Computational Linguistics.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic models
for segmenting and labeling sequence data. In Proc.
18th International Conf. on Machine Learning, pages
282?289. Morgan Kaufmann, San Francisco, CA.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of the Human
Language Technology Conference of the NAACL, Main
Conference, pages 104?111, New York City, USA,
June. Association for Computational Linguistics.
Dekang Lin. 1998. An information-theoretic definition
of similarity. In Proc. 15th International Conf. on Ma-
chine Learning, pages 296?304. Morgan Kaufmann,
San Francisco, CA.
Ben-Ami Lipetz. 1965. Improvements of the selectiv-
ity of citation indexes to science literature through in-
clusion of citation relationship indicators. American
Documentation, 16:81?90.
Mengxiong Liu. 1993. Progress in documentation. the
complexities of citation practice: A review of citation
studies. Journal of Documentation, 49(4):370?408.
Evgeny Matusov, Richard Zens, and Hermann Ney.
2004. Symmetric word alignments for statistical ma-
chine translation. In COLING ?04: Proceedings of the
20th international conference on Computational Lin-
guistics, page 219, Morristown, NJ, USA. Association
for Computational Linguistics.
Rada Mihalcea and Ted Pedersen. 2003. An evaluation
exercise for word alignment. In Rada Mihalcea and
Ted Pedersen, editors, HLT-NAACL 2003 Workshop:
Building and Using Parallel Texts: Data Driven Ma-
chine Translation and Beyond, pages 1?10, Edmonton,
Alberta, Canada, May 31. Association for Computa-
tional Linguistics.
Robert C. Moore. 2005. A discriminative framework for
bilingual word alignment. In HLT/EMNLP, pages 81?
88.
Preslav I. Nakov, Ariel S. Schwartz, and Marti A. Hearst.
2004. Citances: Citation sentences for semantic anal-
ysis of bioscience text. In SIGIR?04 Workshop on
Search and Discovery in Bioinformatics.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Gian-Carlo Rota. 1964. The number of partitions of a
set. The American Mathematical Monthly, 71(5):498?
504, may.
Ralf Schlu?ter, Thomas Scharrenbach, Volker Steinbiss,
and Hermann Ney. 2005. Bayes risk minimization
using metric loss functions. In Proceedings of the
European Conference on Speech Communication and
Technology, Interspeech, pages 1449?1452, Portugal,
September.
Ariel S. Schwartz and Lior Pachter. 2007. Multiple
alignment by sequence annealing. Bioinformatics,
23(2):e24?29.
856
Ariel S. Schwartz, Eugene W. Myers, and Lior Pachter.
2006. Alignment metric accuracy. arXiv:q-
bio.QM/0510052.
Ariel S. Schwartz. 2007. Posterior Decoding Meth-
ods for Optimization and Accuracy Control of Multiple
Alignments. Ph.D. thesis, EECS Department, Univer-
sity of California, Berkeley.
Howard D. White. 2004. Citation analysis and discourse
analysis revisited. Applied Linguistics, 25(1):89?116.
857
Supporting Annotation Layers for Natural Language Processing
Preslav Nakov, Ariel Schwartz, Brian Wolf
Computer Science Division
University of California, Berkeley
Berkeley, CA 94720
{nakov,sariel}@cs.berkeley.edu
Marti Hearst
SIMS
University of California, Berkeley
Berkeley, CA 94720
hearst@sims.berkeley.edu
Abstract
We demonstrate a system for flexible
querying against text that has been anno-
tated with the results of NLP processing.
The system supports self-overlapping and
parallel layers, integration of syntactic and
ontological hierarchies, flexibility in the
format of returned results, and tight inte-
gration with SQL. We present a query lan-
guage and its use on examples taken from
the NLP literature.
1 Introduction
Today most natural language processing (NLP)
algorithms make use of the results of previous
processing steps. For example, a word sense disam-
biguation algorithm may combine the output of a to-
kenizer, a part-of-speech tagger, a phrase boundary
recognizer, and a module that classifies noun phrases
into semantic categories. Currently there is no stan-
dard way to represent and store the results of such
processing for efficient retrieval.
We propose a framework for annotating text with
the results of NLP processing and then querying
against those annotations in flexible ways. The
framework includes a query language and an in-
dexing architecture for efficient retrieval, built on
top of a relational database management system
(RDBMS). The model allows for both hierarchical
and overlapping layers of annotation as well as for
querying at multiple levels of description.
In the remainder of the paper we describe related
work, illustrate the annotation model and the query
language and describe the indexing architecture and
the experimental results, thus showing the feasibility
of the approach for a variety of NLP tasks.
2 Related Work
There are several specialized tools for indexing and
querying treebanks. (See Bird et al (2005) for an
overview and critical comparisons.) TGrep21 is a
a grep-like utility for the Penn Treebank corpus of
parsed Wall Street Journal texts. It allows Boolean
expressions over nodes and regular expressions in-
side nodes. Matching uses a binary index and is
performed recursively starting at the top node in the
query. TIGERSearch2 is associated with the German
syntactic corpus TIGER. The tool is more typed than
TGrep2 and allows search over discontinuous con-
stituents that are common in German. TIGERSearch
stores the corpus in a Prolog-like logical form and
searches using unification matching. LPath is an
extension of XPath with three features: immedi-
ate precedence, subtree scoping and edge alignment.
The queries are executed in an SQL database (Lai
and Bird, 2004). Other tree query languages include
CorpusSearch, Gsearch, Linguist?s Search Engine,
Netgraph, TIQL, VIQTORYA etc.
Some tools go beyond the tree model and al-
low multiple intersecting hierarchies. Emu (Cas-
sidy and Harrington, 2001) supports sequential lev-
els of annotations over speech datasets. Hierarchi-
cal relations may exist between tokens in different
levels, but precedence is defined only between el-
ements within the same level. The queries cannot
1http://tedlab.mit.edu/?dr/Tgrep2/
2http://www.ims.uni-stuttgart.de/projekte/TIGER/TIGERSearch/
express immediate precedence and are executed us-
ing a linear search. NiteQL is the query language
for the MATE annotation workbench (McKelvie et
al., 2001). It is highly expressive and, similarly to
TIGERSearch, allows quering of intersecting hier-
archies. However, the system uses XML for stor-
age and retrieval, with an in-memory representation,
which may limit its scalability.
Bird and Liberman (2001) introduce an abstract
general annotation approach, based on annotation
graphs.3 The model is best suited for speech data,
where time constraints are limited within an inter-
val, but it is unnecessarily complex for supporting
annotations on written text.
3 The Layered Query Language
Our framework differs from others by simultane-
ously supporting several key features:
? Multiple overlapping layers (which cannot be
expressed in a single XML file), including self-
overlapping (e.g., a word shared by two phrases
from the same layer), and parallel layers, as
when multiple syntactic parses span the same
text.
? Integration of multiple intersecting hierarchies
(e.g., MeSH, UMLS, WordNet).
? Flexible results format.
? Tight integration with SQL, including applica-
tion of SQL operators over the returned results.
? Scalability to large collections such as MED-
LINE (containing millions of documents).4
While existing systems possess some of these fea-
tures, none offers all of them.
We assume that the underlying text is fairly static.
While we support addition, removal and editing of
annotations via a Java API, we do not optimize for
efficient editing, but instead focus on compact rep-
resentation, easy query formulation, easy addition
and removal of layers, and straightforward trans-
lation into SQL. Below we illustrate our Layered
Query Language (LQL) using examples from bio-
science NLP.5
3http://agtk.sourceforge.net/
4http://www.nlm.nih.gov/pubs/factsheets/medline.html
5See http://biotext.berkeley.edu/lql/ for a formal description
of the language and additional examples.
Figure 1 illustrates the layered annotation of a
sentence from biomedical text. Each annotation rep-
resents an interval spanning a sequence of charac-
ters, using absolute beginning and ending positions.
Each layer corresponds to a conceptually different
kind of annotation (e.g., word, gene/protein6, shal-
low parse). Layers can be sequential, overlapping
(e.g., two concepts sharing the same word), and hi-
erarchical (either spanning, when the intervals are
nested as in a parse tree, or ontologically, when the
token itself is derived from a hierarchical ontology).
Word, POS and shallow parse layers are sequen-
tial (the latter can skip or span multiple words). The
gene/protein layer assigns IDs from the LocusLink
database of gene names.7 For a given gene there are
as many LocusLink IDs as the number of organisms
it is found in (e.g., 4 in the case of the gene Bcl-2).
The MeSH layer contains entities from the hier-
archical medical ontology MeSH (Medical Subject
Headings).8 The MeSH annotations on Figure 1 are
overlapping (share the word cell) and hierarchical
both ways: spanning, since blood cell (with MeSH
id D001773) orthographically spans the word cell
(id A11), and ontologically, since blood cell is a kind
of cell and cell death (id D016923) is a kind of Bio-
logical Phenomena.
Given this annotation, we can extract potential
protein-protein interactions from MEDLINE text.
One simple approach is to follow (Blaschke et al,
1999), who developed a list of verbs (and their de-
rived forms) and scanned for sentences containing
the pattern PROTEIN ... INTERACTION-VERB ...
PROTEIN. This can be expressed in LQL as follows:
FROM
[layer=?sentence? { ALLOW GAPS }
[layer=?protein?] AS prot1
[layer=?pos? && tag_type="verb" &&
content=?activates?]
[layer=?protein?] AS prot2
] SELECT prot1.content, prot2.content
This example extracts sentences containing a pro-
tein name in the gene/protein layer, followed by any
sequence of words (because of ALLOW GAPS), fol-
lowed by the interaction verb activates, followed by
any sequence of words, and finally followed by an-
6Genes and their corresponding proteins often share the
same name and the difference between them is often elided.
7http://www.ncbi.nlm.nih.gov/LocusLink
8http://www.nlm.nih.gov/mesh/meshhome.html
Figure 1: Illustration of the annotation layers. The full parse, sentence and section layers are not shown.
other protein name. All possible protein matches
within the same sentence will be returned. The re-
sults are presented as pairs of protein names.
Each query level specifies a layer (e.g., sentence,
part-of-speech, gene/protein) and optional restric-
tions on the attribute values. A binding statement
is allowed after the layer?s closing bracket. We
can search for more than one verb simultaneously,
e.g., by changing the POS layer of the query above
to [layer=?pos? && (content=?activates?
|| content=?inhibit? || content=?binds?)].
Further, a wildcard like content ? ?activate%?
can match the verb forms activate, activates and
activated. We can also use double quotes " to make
the comparison case insensitive. Finally, since LQL
is automatically translated into SQL, SQL code
can be written to surround the LQL query and to
reference its results, thus allowing the use of SQL
operators such as GROUP BY, COUNT, DISTINCT,
ORDER BY, etc., as well as set operations like UNION.
Now consider the task of extracting interactions
between chemicals and diseases. Given the sen-
tence ?Adherence to statin prevents one coronary
heart disease event for every 429 patients.?, we
want to extract the relation that statin (potentially)
prevents coronary heart disease. The latter is in
the MeSH hierarchy (id D003327) with tree codes
C14.280.647.250 and C14.907.553.470.250, while
the former is listed in the MeSH supplementary con-
cepts (ID C047068). In fact, the whole C subtree
in MeSH contains diseases and all supplementary
MeSH concepts represent chemicals. So we can find
potentially useful sentences (to be further processed
by another algorithm) using the following query:
FROM
[layer=?sentence? {NO ORDER, ALLOW GAPS}
[layer=?shallow_parse? && tag_type=?NP?
[layer=?chemicals?] AS chem $
]
[layer=?shallow_parse? && tag_type=?NP?
[layer=?MeSH? && label BELOW "C"] AS dis $
]
] AS sent
SELECT chem.content,dis.content,sent.content
This looks for sentences containing two NPs in any
order without overlaps (NO ORDER) and separated by
any number of intervening elements. We further re-
quire one of the NPs to end (ensured by the $ sym-
bol) with a chemical, and the other (the disease) to
end with a MeSH term from the C subtree.
4 System Architecture
Our basic model is similar to that of TIPSTER (Gr-
ishman, 1996): each annotation is stored as a record,
which specifies the character-level beginning and
ending positions, the layer and the type. The ba-
sic table9 contains the following columns: (1) an-
notation id; (2) doc id; (3) section: title, abstract
or body; (4) layer id: layer identifier (word, POS,
shallow parse, sentence, etc.); (5) start char pos:
beginning character position, relative to section and
doc id; (6) end char pos: ending character posi-
tion; (7) tag type: a layer-specific token identifier.
After evaluating various different extensions
of the structure above, we have arrived at one
with some additional columns, which improves
cross-layer query performance: (8) sentence id;
(9) word id; (10) first word pos; and (11)
last word pos. Columns (9)-(11) treat the word
layer as atomic and require all annotations to coin-
cide with word boundaries.
Finally, we use two types of composite indexes:
forward, which looks for positions in a given docu-
ment, and inverted, which supports searching based
on annotation values.10 An index lookup can be per-
formed on any column combination that corresponds
to an index prefix. An RDBMS? query optimizer
estimates the optimal access paths (index and table
scans), and join orders based on statistics collected
over the stored records. In complex queries a com-
bination of forward (F) and inverted (I) indexes is
typically used. The particular ones we used are:11
(F) +doc id+section+layer id+sentence
+first word pos+last word pos+tag type
(I) +layer id+tag type+doc id+section+sentence
+first word pos+last word pos
(I) +word id+layer id+tag type+doc id+section
+sentence+first word pos
We have experimented with the system on a col-
lection of 1.4 million MEDLINE abstracts, which
include 10 million sentences annotated with 320
million multi-layered annotations. The current data-
base size is around 70 GB. Annotations are indexed
as they are inserted into the database.
9There are some additional tables mapping token IDs to en-
tities (the string in case of a word, the MeSH label(s) in case of
a MeSH term etc.)
10These inverted indexes can be seen as a direct extension of
the widely used inverted file indexes in traditional IR systems.
11There is also an index on annotation id, which allows for
annotating relations between annotations.
Our initial evaluation shows variation in the exe-
cution time, depending on the kind and complexity
of the query. Response time for simple queries is
usually less than a minute, while for more complex
ones it can be much longer. We are in the process of
further investigating and tuning the system.
5 Conclusions and Future Work
We have provided a mechanism to effectively store
and query layers of textual annotations, focusing
on compact representation, easy query formulation,
easy addition and removal of layers, and straight-
forward translation into SQL. Using a collection of
1.4 MEDLINE abstracts, we have evaluated vari-
ous structures for data storage and have arrived at
a promising one.
We have also designed a concise language (LQL)
to express queries that span multiple levels of anno-
tation structure, allowing users to express queries in
a syntax that closely resembles the underlying anno-
tation structure. We plan to release the software to
the research community for use in their own annota-
tion and querying needs.
Acknowledgements This research was supported
by NSF DBI-0317510 and a gift from Genentech.
References
Steven Bird and Mark Liberman. 2001. A formal framework
for linguistic annotation. Speech Communication, 33(1-
2):23?60.
Steven Bird, Yi Chen, Susan Davidson, Haejoong Lee, and
Yifeng Zheng. 2005. Extending XPath to support linguis-
tic queries. In Proceedings of PLANX, pages 35?46.
Christian Blaschke, Miguel Andrade, Christos Ouzounis, and
Alfonso Valencia. 1999. Automatic extraction of biological
information from scientific text: Protein-protein interactions.
In Proceedings of ISMB, pages 60?67.
Steve Cassidy and Jonathan Harrington. 2001. Multi-level an-
notation in the Emu speech database management system.
Speech Communication, 33(1-2):61?77.
Ralph Grishman. 1996. Building an architecture: a CAWG
saga. Advances in Text Processing: Tipster Program Ph. II.
Catherine Lai and Steven Bird. 2004. Querying and updating
treebanks: A critical survey and requirements analysis. In
Proceedings Australasian Language Technology Workshop,
pages 139?146.
David McKelvie, Amy Isard, Andreas Mengel, Morten Moeller,
Michael Grosse, and Marion Klein. 2001. The MATE work-
bench - an annotation tool for XML coded speech corpora.
Speech Communication, 33(1-2):97?112.
Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 134?135,
New York City, June 2006. c?2006 Association for Computational Linguistics
Summarizing Key Concepts using Citation Sentences
Ariel S. Schwartz and Marti Hearst
EECS and SIMS
University of California at Berkeley
Berkeley, CA 94720
sariel@cs.berkeley.edu, hearst@sims.berkeley.edu
Citations have great potential to be a valuable re-
source in mining the bioscience literature (Nakov et
al., 2004). The text around citations (or citances)
tends to state biological facts with reference to the
original papers that discovered them. The cited facts
are typically stated in a more concise way in the
citing papers than in the original. We hypothesize
that in many cases, as time goes by, the citation
sentences can more accurately indicate the most im-
portant contributions of a paper than its original ab-
stract.
One can use various NLP tools to identify and
normalize the important entities in (a) the abstract
of the original article, (b) the body of the original
article, and (c) the citances to the article. We hy-
pothesize that grouping entities by their occurrence
in the citances represents a better summary of the
original paper than using only the first two sources
of information.
To help determine the utility of the approach, we
are applying it to the problem of identifying arti-
cles that discuss critical residue functionality, for use
in PhyloFacts a phylogenomic database (Sjolander,
2004).
Consider the article shown in Figure 1. This paper
is a prominent one, published in 1992, with nearly
500 papers citing it. For about 200 of these papers,
we downloaded the sentences that surround the cita-
tion within the full text. Some examples are shown
in Figure 2.
We are developing a statistical model that will
group these entities into potentially overlapping
groups, where each group represents a central idea
in the original paper. In the example shown, some of
the citances emphasize what the paper reports about
the structural elements of the SH2 domain, whereas
other emphasize its findings on interactions and oth-
ers focus on the critical residues.
Often several articles are cited in the same citance,
so it is important to untangle which entities belong
to which citation; by pursuing overlapping sets, our
model should be able to eliminate most spurious ref-
erences.
The same entity is often described in many differ-
ent ways. Prior work has shown how to use redun-
dant information across citations to help normalize
entities (Wellner et al, 2004; Pasula et al, 2003);
similar techniques may work with entities men-
tioned in citances. This can be combined with prior
work on normalizing entity names in bioscience text,
e.g, (Morgan et al, 2004). For a detailed review of
related work see (Nakov et al, 2004).
By emphasizing entities the model potentially
misses important relationships between the entities.
It remains to be determined whether or not relation-
ships must be modeled explicitly in order to create a
useful summary.
134
References
A. A. Morgan, L. Hirschman, M. Colosimo, A. S. Yeh, and J. B. Colombe. 2004. Gene name identification and normalization
using a model organism database. Journal of Biomedical Informatics, 37(6):396?410.
P. I. Nakov, A. S. Schwartz, and M. Hearst. 2004. Citances: Citation sentences for semantic analysis of bioscience text. In
Proceedings of the SIGIR?04 workshop on Search and Discovery in Bioinformatics.
H. Pasula, B. Marthi, B. Milch, S. Russell, and I. Shiptser. 2003. Identity uncertainty and citation matching. Advances In Neural
Information Processing Systems, 15.
K. Sjolander. 2004. Phylogenomic inference of protein molecular function: advances and challenges. Bioinf., 20(2):170?179.
B. Wellner, A. McCallum, F. Peng, and M. Hay. 2004. An integrated, conditional model of information extraction and coreference
with application to citation graph construction. In 20th Conference on Uncertainty in Artificial Intelligence (UAI).
Waksman G, Kominos D, Robertson SC, Pant N, Baltimore D, Birge RB, Cowburn D, Hanafusa H,
Mayer BJ, Overduin M, et al, Abstract Crystal structure of the phosphotyrosine recognition domain
SH2 of v-src complexed with tyrosine-phosphorylated peptides.
Nature. 1992 Aug 20;358(6388):646-53. [PMID: 1379696]
Three-dimensional structures of complexes of the SH2 domain of the v-src oncogene product with two
phosphotyrosyl peptides have been determined by X-ray crystallography at resolutions of 1.5 and 2.0
A, respectively. A central antiparallel beta-sheet in the structure is flanked by two alpha-helices, with
peptide binding mediated by the sheet, intervening loops and one of the helices. The specific recognition
of phosphotyrosine involves amino-aromatic interactions between lysine and arginine side chains and the
ring system in addition to hydrogen-bonding interactions with the phosphate.
Figure 1: Target article for summarization.
Binding of IFNgamma R and gp130 phosphotyrosine peptides to the STAT SH2 domains was mod-
eled by using the coordinates of peptides pYIIPL (pY, phosphotyrosine) and pYVPML bound to the
phospholipase C-gamma 1 and v-src kinase SH2 domains, respectively (#OTHER CITATION, #TAR-
GET CITATION).
The ligand-binding surface of the SH2 domain of the Lck nonreceptor protein tyrosine kinase con-
tains two pockets, one for the Tyr(P) residue and another for the amino acid residue three positions
C-terminal to it, the +3 amino acid (#OTHER CITATION, #TARGET CITATION).
Given the inherent specificity of SH2 phosphopeptide interactions (#TARGET CITATION), a high
degree of selectivity is possible for STAT dimerizations and for STAT activation by different ligand-
receptor combinations.
In fact, the v-src SH2 domain was previously shown to bind a peptide pYVPML of the platelet-derived
growth factor receptor in a rather unconventional manner (#TARGET CITATION).
Figure 2: Sample citances pointing to target article, with some key terms highlighted.
135
