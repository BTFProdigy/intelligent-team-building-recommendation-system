Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 54?59,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Resolution of Referents Groupings in Practical Dialogues 
 
 
Alexandre Denis,  Guillaume Pitel,  Matthieu Quignard 
LORIA  
BP239 F-54206 Vandoeuvre-l?s-nancy, France 
denis@loria.fr,pitel@loria.fr,quignard@loria.fr 
 
  
Abstract 
This paper presents an extension to the 
Reference Domain Theory (Salmon-Alt, 
2001) in order to solve plural references. 
While this theory doesn?t take plural 
reference into account in its original 
form, this paper shows how several 
entities can be grouped together by 
building a new domain and how they can 
be accessed later on. We introduce the 
notion of super-domain, representing the 
access structure to all the plural referents 
of a given type. 
1 Introduction 
In the course of a discourse or a dialogue, 
referents introduced separately could be 
referenced with a single plural expression 
(pronoun, demonstratives, etc.). The grouping of 
these referents may depend on many factors: it 
may be explicit if they were syntactically 
coordinated or juxtaposed or implicit if they just 
share common semantic features (Eschenbach et 
al., 1989). Time is also an important factor while 
it may be difficult to group old mentioned 
referents with new ones. Because of this 
multiplicity of factors, choosing the right 
discursive grouping for a referential plural 
expression is ambiguous, and this ambiguity 
needs to be explicitly described.  
We present a model of grouping based on 
reference domains theory (Salmon-Alt, 2001) 
that considers that a reference operation consists 
of extracting a referent in a domain. However the 
original theory barely takes into account plural 
reference. This paper shows how several entities 
can be grouped together by building a new 
domain and how they can be accessed later on. It 
introduces also the notion of super-domain D+ 
that represents the access structure to all the 
plural referents of type D. This work is currently 
being implemented and evaluated in the MEDIA 
project of the EVALDA framework, a national 
french understanding evaluation campaign 
(Devillers, 2004). 
2 Groupings of Referents  
Several kinds of clues can specify that referents 
should be grouped together, or at least could be 
grouped together. These clues may occur at 
several language levels, from the noun phrase 
level to the rhetorical structure level. We have 
not explored in detail the different ways of 
groupings entities together in a discourse or 
dialogue. What is described here are just some of 
the phenomenon we got confronted with while 
developing a reference resolution module for a 
dialogue understanding system. 
 Explicit Coordination - The most basic 
way to explicitly express the grouping of two 
or more referents is using a connector such as 
and, or, as well as, etc.  
?Good afternoon, I would like to book a 
single room and a double room? 
 Implicit Sentential Coordination - An 
implicit coordination occurs when two or 
more referents of the same kind are present in 
one sentence, without explicit connector 
between them. ?Does the hotel de la gare 
have a restaurant, like the Holiday Inn?? 
 Implicit Discursive Coordination ? 
Such a coordination occurs when several 
reference are evoked in separate sentences. 
The grouping must be done based on 
rhetorical structuring. Here we consider short 
pieces of dialogue, admitting only one level 
of implicit discursive coordination.  ?I would 
like an hotel close to the sea... I also need an 
hotel downtown... And the hotels have to 
accept dogs.? 
54
 Repetitions/Specifications ? In some 
particular cases, groupings make explicit a 
previous expression. For instance ?Two 
rooms. A single room, a double room?. 
3 Reference Domain Theory 
We are willing to try a pragmatic approach to 
reference resolution in practical multimodal 
dialogues (Gieselman, 2004). For example we 
need to process frequent phenomena like 
ordinals for choosing in a list (discursive, or 
visual) or otherness when re-evoking old 
referents. Hence keeping the track of the way the 
context is modified when introducing a referent 
or referring, is mandatory. The Reference 
Domains Theory (Salmon-Alt, 2001) supposes 
that every act of reference is related to a certain 
domain of interpretation. It endorses the 
cognitive grammar concept of domain, defined  
as a cognitive structure presupposed by the 
semantics of the expression (Kumar et al, 2003).  
In other words, a referring expression has to be 
interpreted in a given domain, highlighting and 
specifying a particular referent in this domain. A 
reference domain is composed of a group of 
entities in the hearer?s memory which can be 
discursive referents, visual objects, or concepts. 
It describes how each entity could be addressed 
through a referential expression.  
This theory views the referring process as a 
dynamic extraction of a referent in a domain 
instead of a binding between two entities 
(Salmon-Alt, 2000). Hence doing a reference act 
consists in isolating a particular entity from other 
rejected candidates, amongst all the accessible 
entities composing the domain (Olson, 1970). 
This dynamic discrimination relies on projecting 
an access structure focusing the referent in the 
domain.  The domain then becomes salient for 
further interpretations. The preferences for 
choosing a suitable domain are inspired from the 
Relevance theory (Sperber & Wilson, 1986) 
taking into account such focalization and 
salience.  
Landragin & Romary (2003) have also studied 
the usage of reference domains in order to model 
a visual scene. The grouping factors for visual 
objects are those given by the Gestalt theory, 
proximity, similarity, and good continuation. 
Each perceptual groups or groups designated by 
a gesture could be the base domain for an 
extraction. Referential expressions work the 
same way either the domains are discursive, 
perceptual or gestural, they extract and highlight 
referents in these domains. See (Landragin et al, 
2001) for a review of perceptual groupings.  
4 Basic Type 
A referential domain is defined by:  
? a set of entities accessible through this 
domain (ground of domain), 
? a description subsuming the description 
of all these entities (type of domain), 
? a set of access structures to these 
entities. 
For instance: ?the Ibis hotel (h1) and the hotel 
Lafayette (h2)? forms a referential domain, 
whose type would be Hotel, and whose 
accessible entities would be h1 and h2, 
themselves defined as domains of type Hotel. 
These two hotels could be accessed later on by 
their names. 
4.1 Access structures 
We suppose that the distinction between the 
referents from the excluded alternatives requires 
highlighting a discrimination criterion opposing 
them. This criterion behaves like a partition of 
the accessible entities, grouping them together 
according to their similarities and their 
differences. A partition may have one of its parts 
focused. There are, at least, three kinds of 
discrimination criteria: 
? discrimination on description. Entities 
can be discriminated by their type, their 
properties, or by the relations they have with 
other entities. For example the name of the 
hotels is a discrimination criterion in ?the Ibis 
hotel and the hotel Lafayette?. 
? discrimination on focus. Entities can 
also be discriminated by the focus they have 
when they are mentioned in the discourse or 
designed by a gesture. For example, ?this 
room? would select a focused referent in a 
domain, whereas ?the other room? would 
select a non-focused one. 
? discrimination on time of occurrence. 
Entities can finally be discriminated by their 
occurrence in the discourse. For example ?the 
second hotel? would discriminate this hotel 
by its rank in the domain. 
4.2 Classical resolution algorithm 
Each activated domain belongs to list of domains 
ordered along their recentness (the referential 
55
space).  The resolution algorithm consists of two 
phases: 
1. Searching a suitable, preferred domain in 
the referential space when interpreting a 
referring expression. The suitability is 
defined by the minimal conditions the domain 
has to conform to in order to be the base of an 
interpretation (particular description, or 
presence of a particular access structure with 
focus or not). The main preference factor is 
the minimization of the access cost 
(recentness or salience), however other 
criteria like thematic structure could be taken 
into account and will be future work. Each 
domain is tested according to the constraints 
given by the referential expression. We allow 
several layers of constraints for each type of 
expression : if the stronger constraints are not 
met, then weaker constraints are tried. 
2. Extracting a referent and restructuring the 
referential space, taking into account this 
extraction. It not only focuses the referent in 
its domain, but also moves the domain itself 
to a more recent place. When one referent 
acquires the focus, the alternative  members 
of the same partition loose it. 
This generic scheme is instantiated for each type 
of access modes (a modality plus an expression). 
For example a definite ?the N? will search for a 
domain in which a particular entity of type ?N? 
can be discriminated, and the restructuring 
consists in focalizing in this domain the referent 
found. See (Landragin & Romary, 2003) for a 
description of the different access modes. 
The algorithm highlights the two types of 
ambiguities, domain or referent ambiguities, 
which occur when there is no preference 
available to make a choice between multiples 
entities in the first or the second phase. We guess 
that natural ambiguities should eventually be 
solved through the dialogue between the agents 
of the communication.  
5 Super-Domains 
In order to take groupings into account in the 
Reference Domains Theory, we introduce two 
constructs in our formal toolbox. Indeed, having 
only one kind of domain construct doesn?t allow 
for a correct distinction between different 
referent statuses.  
First we distinguish plural and simple domains. 
The simple domains D serve as bases for 
profiling, or highlighting, a subpart, or related 
part of a simple referent. For instance, if D = 
Room, then one can profile a Price from D. The 
plural domains D* serve as either as a generic 
base or as a plural representative for profiling 
a simple domain D. A generic base is mandatory 
in our model to support the insertion of new 
extra-linguistic referents evoked with an 
indefinite construct (for instance ?I saw a black 
bird on the roof?), while plural representatives 
are used for explicit groupings. A domain D*1 
can also be profiled from a D*0, provided D*1 
profiles a subset of the elements of D*0. 
Second, we introduce the notion of super-
domain D+, from which a D* can be profiled. 
The relations allowed between domains are  
represented on figure 1. A super-domain D+ is 
the domain of all groupings D*, including a 
special D*all grouping which is the representative 
of all evoked instances of a given category. This 
configuration is not intended to deal with long 
dialogues where several, trans-sentential 
groupings occur, and where older groupings may 
become out of access. Doing this would require 
a rhetorically driven structuring of the D*all.  
 
Figure 1: Access structure of Reference 
Domains 
 
As Reference Domain Theory is primarily 
targeted toward extra-linguistic referents 
occurring in practical dialogue, the construction 
of the domain trees, representing the supposed 
structuring of referents accessibility, is based on 
ontology. As a consequence, for each ?natural? 
type and each subtype (for instance 
Room?Single), a domain tree is potentially 
created (actually, one can easily imagine how 
this creation may be driven ?on-demand?). 
Another evolution from the initial Reference 
Domain Theory is the possibility to focalize 
several items of a partition. Indeed, since the 
resolution algorithm can focalize a whole plural 
domain, all elements of this domain must be 
focalized in all the plural domains they occur in. 
In order to refer to plural entities the idea is to 
build plural domains dynamically : when some 
sentence-level grouping, either implicit or 
explicit occurs or when a plural extra-linguistic 
referent is evoked, a D* is created and focussed 
D+ 
D* D D* 
D+ : super-domain 
D* : plural domain 
D  : simple domain 
 
        : gives access to 
56
in D+, with each of its components as children, 
when possible (that is, when each component is 
described). When new extra-linguistic referents 
(singular or plural) are evoked, they are 
individually profiled under the D*all 
corresponding to their types (that is, their 
?natural? type, and all the subtypes they are 
eligible to). 
In short, for all referents of type D: 
? they become subdomains of D*all 
? if they are plural referents, they also build 
up a focalized subdomain of D+
 
?
 all the referents of a given type are then 
grouped together under a new focalized 
subdomain of D+.  
  Figure 2 illustrates the state of the Hotel+ 
domain tree after a scenario with three dialogue 
acts, the first one introducing Hotel1, the second 
one inserting a grouping of Hotel2 and Hotel3. 
and the third one referring to it.  
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2: A domain tree built from a scenario 
above (focus in bold) 
The operations are the following : 
U1 : Hotel1 becomes a subdomain of Hotel*all 
which gains focus in Hotel+. 
S1 : Hotel2 and Hotel3 become subdomains of 
Hotel*all. In addition Hotel2 and Hotel3 are 
grouped in Hotel*1 which gains the focus in 
Hotel+ while Hotel*all loses it. 
U2 : The pronoun is solved in Hotel+, and Hotel*1 
is retrieved. 
One can see that Hotel*all is inaccessible by a  
generic expression like a demonstrative without 
modifiers but only by a special expression like 
"all the hotels". In our point of view, the reason 
is that the grouping Hotel*1 lowers the salience 
of Hotel*all. 
6 Implementation  
We used description logics for modelling 
domains and domain-reasoning. One has to deal 
with plural entities and can follow (Franconi, 93) 
by using collection theory, representing 
collections as individuals and membership by a 
role (plus plural quantifiers). But we should use 
another way considering that the inference 
engine we use, Racer (Haarslev and M?ller, 03), 
does not take into account ALCS. Hence we 
tried representing the domains by concepts, 
given their semantic are set of individuals. The 
domain D+ corresponds to the concept D, and 
the domain-subdomain relation is a 
subsumption. All basic manipulation with 
domains could be done using Tbox assertions. 
Additionnally, a partition structure is simply a 
sequence of subdomains which are different 
from each other (disjoint concepts) and whose 
elements could be focussed. The algorithm goes 
through the referential space and tests each 
domain in the recency order against the 
constraints given by the referential expression. 
Conceptual tests on the description and 
partitional tests on the focus or possible 
discriminations are made to retrieve the domain 
and the referent. If none are found, they may be 
created by accomodation. Groupings are created 
only for explicit coordinations, implicit 
sentential coordinations (two referents could be 
grouped if they have the same basic type) and 
some kind of specifications.  
Domains and groupings creation entails the 
creation of new concepts in the Tbox. Each 
concept insertion requires a costly 
reclassification, therefore we preferred an 
approximation considering only that new 
groupings assert primitive concepts. Other 
domains are concept terms i.e. descriptions 
which do not have to be asserted in the Tbox 
automatically. 
Implicit discursive groupings are not 
implemented considering the need of a rhetorical 
structure  (like in SDRT, Asher 93) or a mental 
space model. The following example shows the 
needs : 
 U1 : I would like an hotel (h1) 
 S1 : I propose you the hotel Ibis (h2) and 
 the Lafayette hotel (h3). 
Hotel h1 could very hardly be grouped with h2 
and h3, even by ?all these hotels? (or maybe by a 
third speaker). We guess among other factors 
that they belong to different levels of 
interpretation, h1 in the domain of the desires of 
Hotel+ 
Hotel*all Hotel*1 
Hotel1 Hotel2 Hotel3 
U1: The Ibis Hotel (Hotel1) is too expensive 
S1: Maybe the Hotel Lafayette (Hotel2) or 
the Hotel de la cloche (Hotel3) 
U2: Those hotels are too far from the airport. 
 
57
the user, and the others in the domain of existing 
hotels. The link between the two domains is 
possible if one knows that S1 is an answer of to 
U's request. Such discrimination criterion and 
high level domains are not yet implemented. 
Instead we concentrated on extra-linguistic 
referents which are assumed to be interpreted in 
the real/system world (like hotels, rooms). We 
are currently testing the approach to see if it 
could be extended to any type of entities 
provided accurate discrimination criteria (like 
the predication). 
7 Example 
A sample dialogue (table 1) is analyzed through 
the preceding algorithm. This example shows 
how the referents introduced in an explicit 
coordination could be referenced as a whole ?the 
two hotels?, or extracted discriminately by an 
ordinal ?the second one? or by an otherness 
expression ?the other one?. All the subdomains 
of H+ (i.e. the plural domains of hotels) are 
indicated after each interpretation using a 
simplified notation. Only the ordered list of 
accessible entities and their focalization (bold) 
are noted for each subdomain. For instance 
H*all= (h1, h2, h3) means that the domain H*all is 
focalized in H+, and that h3 is focalized in H*all. 
Table 1: Example of dialogue (focus in bold) 
 
In order to interpret U1, U2 or U3 one needs to 
rely on the previous structuring of H+. In U1, the 
previously focalized domain H*1 is preferred to 
be the base for interpreting ?the second one? 
because of the order discrimination. This leads 
to extracting h1 hence focalizing it in H*1 but 
also in H*0 and in H*all. In U2, H*1 cannot be the 
base for interpreting ?the third one? because no 
entity could be discriminate this way. Therefore 
the only suitable domain is H*all. It is also 
impossible to interpret U3 : ?the other one? in 
H*1 because of the lack of a focus discrimination 
between h1 and h2.  
It is however possible to choose H*all for the 
domain of interpretation: the excluded referents 
h1 and h2 are unfocused while h3 gains focus. 
 
8 Evaluation in progress 
This work is currently being evaluated in the 
MEDIA/EVALDA framework, a national 
understanding evaluation campaign. (Devillers et 
al., 04). It aims to evaluate the semantic and 
referential abilities of systems with various 
approaches of natural language processing. The 
results of each system are compared to manually 
annotated utterances transcribed from a Woz 
corpus in a hotel reservation task. For the 
referential facet, referential expressions 
(excluding indefinites, and proper names) are 
annotated by a semantic description of their 
referents. 
Our system which relies on a symbolic approach 
using deep parsing and description logics for 
semantic currently scores 64% (f-measure) for 
identifying and describing accurately the 
referents. We guess that such evaluation will be 
an occasion for us to test different hypothesis on  
reference resolution using domains (for exemple 
different criteria for grouping). However we do 
not have yet more precise results on plurals and 
ordinals specifically.  
9 Conclusion 
The extension we made to the Reference 
Domains Theory is still limited because it 
considers only extra-linguistic referents, i.e. 
those also having an existence outside discourse. 
In addition the trans-sentential groupings are not 
fully studied yet. We guess that such groupings 
should need a rhetorical description of the 
discourse or dialogue. In spite of its limits, the 
extension can render dynamic effects allowing 
ordinals and otherness in plural contexts. An 
Dialogue H+ 
U: Is there a bathroom at 
the Ibis hotel (h1) and the 
hotel Lafayette (h2)? 
H*0 = (h1, h2) 
H*all = (h1, h2) 
S: No they don't have 
bathrooms 
H*0 = (h1, h2) 
H*all = (h1, h2) 
S: But I propose you the 
Campanile hotel (h3) 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
U: Hmm no, how much 
were the two hotels? 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
S: The hotel Lafayette is 
100 euros, the Ibis hotel is 
75 euros 
H*1 = (h2, h1) 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
U1: Ok, I take the second 
one 
H*1 = (h2, h1) 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
U2: Ok, I take the third 
one 
U3 : and the other one ? 
H*1 = (h2, h1) 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
58
implementation in description logics is  currently 
being evaluated in the MEDIA/EVALDA 
framework. 
References 
Nicholas Asher. 1993. Reference to Abstract Objects   
in English: A Philosophical Semantics for Natural 
Language Metaphysics. In Studies in Linguistics 
and Philosophy, Kluwer, Dordrecht. 
Laurence Devillers, H?l?ne Maynard, St?phanie 
Rosset, Patrice Paroubek, Kevin McTait, Djamel 
Mostefa, Khalid Choukri, Caroline Bousquet, 
Laurent Charnay, Nadine Vigouroux, Fr?d?ric 
B?chet, Laurent Romary, Jean-Yves Antoine, 
Jeanne Villaneau, Myriam Vergnes, and J?r?me 
Goulian. 2004. The French MEDIA/EVALDA 
Project : the Evaluation of the Understanding 
Capability of Spoken Language Dialog System. In 
Proceedings of LREC 2004, Lisbon, Portugal. 
Carola Eschenbach, Christopher Habel, Michael 
Herweg, Klaus Rehk?mper. 1989. Remarks on 
plural anaphora. In Proc. Fourth Conference of the 
European Chapter of the Association for 
Computational Linguistics. 
Enrico Franconi. 1993. A treatment of plurals and 
plural quantifications based on a theory of 
collections. Minds and Machines (3)4:453-474, 
Kluwer Academic Publishers, November 1993 
Petra Gieselmann: 2004. Reference Resolution 
Mechanisms in Dialogue Management. In: 
Proceedings of the Eighth Workshop on the 
Semantics and Pragmatics of Dialogue 
(CATALOG), Barcelona, 2004. 
Volker Haarslev, and Ralf M?ller. 2003. Racer: A 
Core Inference Engine for the Semantic Web. In 
Proceedings of the 2nd International Workshop on 
Evaluation of Ontology-based Tools (EON2003), 
located at the 2nd International Semantic Web 
Conference ISWC 2003, Sanibel Island, Florida, 
USA, October 20, 2003, pp. 27-36. 
Ashwani Kumar, Susanne Salmon-Alt, and Laurent 
Romary. 2003. Reference resolution as a 
facilitating process towards robust multimodal 
dialogue management: A cognitive grammar 
approach. In International Symposium on 
Reference Resolution and Its Application to 
Question Answering and Summarization. 
Fr?d?ric Landragin, and Laurent Romary. 2003. 
Referring to Objects Through Sub-Contexts in 
Multimodal Human-Computer Interaction. In Proc. 
Seventh Workshop on the Semantics and 
Pragmatics of Dialogue (DiaBruck'03), 
Saarbr?cken, Germany, 2003, pp. 67-74. 
Fr?d?ric Landragin, Nadia Bellalem and Laurent 
Romary. 2001. Visual Salience and Perceptual 
Grouping in Multimodal Interactivity. In: First 
International Workshop on Information 
Presentation and Natural Multimodal Dialogue, 
Verona, Italy, 2001 
David R. Olson. 1970. Language and Thought: 
Aspects of a Cognitive Theory of Semantics. 
Psychological Review, 77/4, 257-273. 
Susanne Salmon-alt. 2000. Interpreting referring 
expressions by restructuring context. Proc. ESSLLI 
2000, Student Session, Birmingham, UK, August 
2000. 
Susanne Salmon-Alt. 2001. Reference Resolution 
within the Framework of Cognitive Grammar. 
Proc. International Colloquium on Cognitive 
Science, San Sebastian, Spain 
Dan Sperber and Deirdre Wilson. 1986. Relevance, 
Communication and Cognition. Basil Blackwell, 
Oxford. 
59
Using MMIL for the High Level Semantic Annotation of the
French MEDIA Dialogue Corpus.?
Lina Maria Rojas-Barahona
LORIA/INRIA, France
lina.rojas@loria.fr
Thierry Bazillon
Univ. Avignon, France
thierry.bazillon@univ-avignon.fr
Matthieu Quignard
LORIA/INRIA, France
matthieu.quignard@loria.fr
Fabrice Lefevre
Univ. Avignon, France
fabrice.lefevre@univ-avignon.fr
Abstract
The MultiModal Interface Language formalism (MMIL) has been selected as the High Level
Semantic (HLS) formalism for annotating the French MEDIA dialogue corpus. This corpus is com-
posed of human-machine dialogues in the domain of hotel reservation and tourist information. Utter-
ances in dialogues have been previously annotated with a concept-value flat semantics for studying
and evaluating spoken language understanding modules in dialogue systems. We are now interested
in investigating the use of more complex representations to improve the understanding capability.
The MMIL intermediate language is a high level semantic formalism that bears relevant linguistic
information, from syntax up to discourse. This representation should increase the expressivity of
the current annotation though at the expense of the annotation process complexity. In this paper we
present our first attempt in defining the annotation guidelines for the HLS annotation of the MEDIA
corpus and its effect on the annotation process itself, revealed by annotators? disagreements due to
the different levels of hierarchy and the granularity of the features defined in MMIL.
1 Introduction
MMIL is an ontology-oriented representation language that has been used in several natural language
processing (NLP) applications, Denis et al (2010). It permits the integration of divergent resources in
distributed systems as well as the representation of various levels of linguistic analysis. In this work we
are particularly interested in exploring the representation of these linguistic levels for analyzing utter-
ances in the context of human-machine interactions. To be able to evaluate the representation on a large
set of data the French MEDIA dialogue corpus is used, Bonneau-Maynard et al (2005). The MEDIA
corpus collects about 70 hours of spontaneous speech in the task of hotel room reservation and tourist
information. It has been created using a Wizard-of-Oz technique, as a consequence, the utterances are
made of many disfluencies, hesitations, false starts, truncations or fillers words (e.g., euh or ben). Thus,
the syntactic analysis is relevant for keeping valuable information for further processing (e.g., reference
resolution). The semantics describe fine grained predicates, arguments and features based on the domain
knowledge. Similarly, the possibility of link references for pragmatic analysis and the representation of
the illocutionary force of utterances are relevant to improve the understanding in NLP applications. We
selected MMIL for the semantic annotation because it supports the representation of all these features.
Although these features enrich the semantic annotation of utterances in the corpus, they also increase
the complexity of the annotation and compromise the agreement between annotators. The possibility
of representing different instantiations in MMIL has been the main cause of disagreement between an-
notators. On the one hand, linguists tend to annotate the surface form of the utterance. On the other
?This work is supported by the French Agence Nationale de la Recherche (ANR) and is part of the Project PORT-MEDIA
(www.port-media.org).
375
hand, application designers are more biased towards its canonical representation by keeping relevant
task oriented actions and features. The trade-off between these two lines of representation is significant
for building appropriately the annotation guidelines for the semantic annotation. The annotation would
keep the most valuable information in a multilevel representation for enhancing the understanding ca-
pability of NLP applications. In this paper we introduce briefly MMIL and we describe the annotation
methodology and the inter-annotation agreement.
2 The High Level Representation
MMIL permits the representation of communicative actions that are represented as components. A com-
ponent is a structure that gathers the communicative event and its propositional content. Components
are made up of two main types of entities: events, which are entities anchored in the time dimension,
and participants, which are entities not bounded by time. Entities are linked together by relations and
are described by sets of features (i.e. pairs of attribute-value), Denis et al (2010). Every component
has a unique communicative event with the illocutionary force represented by means of the dialogueAct
feature. The propositional content is represented as a main event with its arguments, which can be either
events or participants, linked to the communicative event by a relation propContent. In this represen-
tation, predicates are usually represented as events and predicate arguments are usually represented as
participants. Relations between participants and events usually describe the thematic roles.
French: "/1euh vous venez de dire que pre?ce?demment qu? il n? a y avait plus de chambres disponibles a` ces dates et maintenant
vous en avez/2 donc je voulais juste m? assurer qu? au Novotel vous avez bien une chambre double euh pour un couple avec un
enfant avec une baignoire dans la chambre euh il me il me faut un Parc ?a? proximite? et euh cent dix euros maximum la nuit
est-ce-que vous pouvez ve?rifier"
English:"/1um you just said earlier that there are not more rooms available on these dates and now there are/2 so I just
wanted to be sure that you have at the Novotel a double room for uh a couple with one child with a bath in the room uh I
need a park nearby and uh hundred and ten euros up at night is that you can check"
Figure 1: Example of a complex utterance of the MEDIA Corpus.
Speak
Inform
Comprendre
(Understand)
negative
Coordination
adversative
State
State
negative
Pe?riodeDe
Temps
(Time)
demonstrat.
Chambre
(Room)
disponible
propContent
patient
member
memberpatient
aPe?riodeRe?servation
Speak
RequestAck
State
Chambre
(Room)
indefinite
Hotel
Couple
location.
Relative
proche
(near)
parc
(park)
Enfant
(Child)
Prix
(Price)
inferieur
(lower)
110
euros
propContent
patient
aBe?ne?ficiaires
attribute
aLocalisation
aPrix
Figure 2: HLS as an abstraction of the meaning of the French utterance shown in Figure 1. Left: this component expresses the inform
of a misunderstanding of the first segment (?/1" in Figure 1). Right: this component is a request acknowledgment, representing the second
segment(?/2" in Figure 1). Note that events are exemplify by square boxes while participants are exemplify by ellipses.
376
Let us focus on the MMIL representation for a typical utterance of the MEDIA corpus, given in
Figure 1. In this utterance the user first announces an inconsistency, then asks for clarification. Thus,
two MMIL components with different communicative actions, inform and request acknowledgment, have
been used, as shown in Figure 2. The component on the left has a main event that describes the misun-
derstanding expressed in the first segment1 of the utterance. It is represented by the ontological concept
?Understand" and by the syntactic feature polarity with the negative value. It also contains a coordinated
entity mirroring an adversative coordination between two events, state. The event state represents the
status of something, therefore the negated state event can be understood as ?there are not more rooms
available on these dates" while the positive state represents ?now there are". The participants symbolize
the arguments ?rooms" and ?dates" respectively. The component on the right expresses the clarification
request of the second segment. It verifies the status of the hotel with the specific constraints.
3 The Annotation Methodology
In the process of defining the annotation guidelines, we elaborated a specification document that de-
scribes the representation of dialogue acts, events and exemplifies the high-level semantics. Moreover, it
delves into the methodology that might be applied for the automatic and manual annotation. Afterwards,
a linguist expert and a project designer were in charge of defining the annotation guidelines. For this
purpose, they annotated manually a subset of utterances which were supposed to be representative of
the most complex aspects of the HLS annotation, in terms of their semantic constituents. 330 utterances
were selected. They are all directly related to the reservation task (first two rows in Figure 4) and mostly
occurred in the first 3 turns of the dialogues when the user is describing his goal, defined as an overall
objective along with a set of constraints. Hereafter, we present the preliminary evaluation of the experts?
agreement on these utterances.
The annotation process has been supported by an annotation tool: ATool. It accesses two knowledge-
bases, one for the MMIL formalism and the other for the MEDIA domain. The latter is adapted from
the MEDIA evaluation campaign, Bonneau-Maynard et al (2006). ATool permits annotators to navi-
gate through utterances, while displaying the MMIL representation. Annotators can design the MMIL
components graphs, define the MMIL entities by associating features, values and segment. ATool will
suggest the possible features and values for the MMIL formalism and for the domain according to the
knowledge-bases ensuring the integrity of the constructed MMIL components in the annotation.
The MEDIA corpus is rich in expressions that evoke several communicative actions. Figure 4 shows
a few examples. For the purpose of the task, we are interested in the underlying meaning of sentences,
thus politeness and indirectness are discarded from the HLS representation. For this reason, in requests
the speaker is the patient, while the hearer is the agent (see Figure 4). Because when translating the
utterance into its deep instantiation, the speaker will benefit from the execution of the action, while the
hearer has the obligation to perform the action. All the expressions in the corpus that bear the seman-
tics of ?command for a reservation" (e.g., je veux re?server, je souhaite re?server, je voudrais faire une
re?servation, j?aimerais faire une re?servation, all equivalent to I would like to reserve), have been normal-
ized with the deep component shown in Figure 3, exemplifying unequivocally the user?s desire to request
for a reservation. The possible arguments and roles have been detailed in the domain knowledge-base.
As a consequence the knowledge-base defines relations between hotels, rooms, customers, prices, equip-
ments, services, locations and dates. Besides, the grammatical relations and features, such as coordina-
tion, have been defined in the MMIL knowledge-base. Coordination is indicated with the ?coordtype"
feature and it is used in cases of conjunction (je veux une chambre simple et deux chambres double, I
want a single room and two double bedrooms), disjunction (Paris ou en proche banlieue, in Paris or
suburbs) or adversation (en ville mais pas trop loin de la mer, in the city but not too far from the sea).
For annotating events we can find the main verb in the utterance and represent it as the main event
in MMIL by following a domain-specific classification of verbs, from which Figure 4 shows some
equivalences among dialogue acts and verbs. For each participant or event, several features can be
1Segments are sequence of words that are depicted as ?/i", where i is the number of the segment.
377
Speak
Request
Reserver
je arg0 argi
propContent
patient[0]
patient[1] patient[n]
Figure 3: Canonical representation of a booking request in
MEDIA.
D. Act EvType Examples Semantic Roles
Request Reserver re?server [la chambre] aObjetRe?serve?
re?server [pour le
troisie`me
week-end de novembre
une nuit]
aPe?riodeRe?servation
[a? Clermont-Ferrand] aLocalisation
[pour quatre chambres
doubles]
aObjetRe?serve?
Inform Inform [j?] ai des informations
supple?mentaires
agent
Request Inform [j?] aurais aim?l? avoir
exactement [les dates]
patient[0],
patient[1]
Request State [Il] est [?a? combien] patient, aPrix
Request Repeter pouvez-[vous] re?pe?ter agent
Inform Repeter [je] vais me re?pe?ter agent
Accept oui
Reject non
Figure 4: Some of the observed dialogue acts and main
events with their arguments in the corpus.
added. The most important of them are ?object type" (for participants) or ?event type" (for events),
which specify their ontological concepts. They may be re?server (reserve), h?tel (hotel), chambre (room),
pe?riodedetemps (time), ville (city), person, adulte (adult), enfant (child), localisationnomme?e (places),
among others. There are more specific features, for instance, the journey dates, hotel features (e.g.,
name, standing, services, etc). Some of these features have predefined values, such as the gender of an
object (either masculine or feminine). On the other side, features such as cardinality, have not predefined
values, in that case, the annotator has to manually indicate the correct value.
Obviously, the annotation task difficulty increases with the utterance?s complexity. The representa-
tion is rather tedious to define in elliptical utterances, such as multiple reservations, in which implicit
and explicit information must be taken under consideration. Furthermore, the MMIL formalism does
not support the association of discontinuous segments to entities, generating some imprecisions in the
HLS annotation. For instance, in je voudrais une chambre pour deux personnes euh simple (I would
like a room for two people uh simple),?une chambre" (a room) and ?simple" should be linked to an
unique participant, having as object type (?Room") and as type of room ?simple". However, given that
the speaker has not mentioned ?simple"right after ?chambre", there is a new element imbricated between
them: ?pour deux personnes". As a result, the annotator must integrate the subsegment ?pour deux per-
sonnes" in the ?Room" participant. Even though this subsegment is also associated to the ?Personne"
participant.
4 Results
When analyzing the sample of 330 utterances that were annotated, we found a perfect agreement be-
tween annotators in the detection of dialogue-acts, main events, as well as main arguments. In constrast,
when measuring fine-grained features inside components we found eight types of disagreement, namely
conjunctions, disjunctions, creation of participant for simple features, groups of features inside entities,
features of entities, values of features, relation names and relation among entities. The most frequent
cases concern the first two, which refer to coordination: conjunctions (20%) and disjunctions (5%). The
inter-annotator agreement for the coordinate entities was computed, obtaining the kappa measure, Car-
letta (1996), of 0.25 for conjunctions and 0.15 for disjunctions, meaning a fair and slight agreement
respectively. Although the other cases were less frequent, the inter-annotator agreement was even lower,
indicating no agreement.
In spite of the disagreement, when measuring the global similarity between the MMIL components
created by both annotators we found a high score of 98%. This metric measures the graph similarity
378
by computing the similarity between entities and relations, including the fine-grained features inside
entities. The speech-act, main-event and main arguments are in compliance with the specifications in
both annotations.
Case Annotator 1 Annotator 2
Conjunctions 68 56
Disjunctions 18 10
Part. for simple feats. 11 0
Grouping feats. 0 2
Case Discrepancy
Features 4
Features? values 5
Name of relations. 5
Relation among entities. 2
Figure 5: Left: the Table displays the number of utterances by annotator for the listed cases. Annotator 1, is the liguist expert, Annotator 2
is the project designer. Right: fhe Table shows the number of utterances with a completely discrepant annotation: different features for same
entities, different values for same features, different relation between same entities and entities related differently in a component.
These issues show that the disagreement cases were less frequent. So far, annotators have not being
so rigourous when segmenting the text inside features. Therefore, segmentation needs to be checked in
both annotations. After this experiment, we are defining the final certified annotation and deriving the
annotation guidelines formally.
5 Discussion
Defining the annotation guidelines for high level semantic representation is controversial. The multiple
features that can be represented in the selected MMIL formalism, as well as the multiple instantiations
offer different possibilities for representing the same utterance. In general representing spoken utterances
is cumbersome, because of the linguist phenomena present in spontaneous speech. As a consequence,
annotators have to deal not only with the explicit, but also with the implicit information, and in some
cases the representations might be subjective. For these reasons, we defined the standard for the annota-
tion, and based on it, we carried out an annotation experiment on a sample of 330 complex utterances,
directly related to the reservation task; involving two annotator profiles i.e., a linguist and a project
designer. Afterwards, we measured the similarity between the annotated MMIL components and the
inter-annotation agreement obtaining a 98% of similarity and only eight major cases of disagreement,
coordination discrepancy being the most frequent. Right now, we are refining the final annotation guide-
lines based on these results. This first experiment analyzes the most complex and numerous utterances
in the corpus covering reservation requests and affirmations. Subsequently, misunderstanding, questions
and clarifications will be analyzed following the same methodology. As a result, we will be able to
reduce the disagreement between annotators in order to produce the annotation of the whole MEDIA
corpus, which will be made freely available to the research community.
References
Bonneau-Maynard, H., C. Ayache, F. Bechet, A. Denis, A. Kuhn, F. Lefe`vre, D. Mostefa, M. Quignard, S. Ros-
set, C. Servan, , and J. Villaneau (2006). Results of the french evalda-media evaluation campaign for literal
understanding. In 5th International Conference on Language Resources and Evaluation (LREC2006).
Bonneau-Maynard, H., S. Rosset, C. Ayache, A. Kuhn, and D. Mostefa (2005). Semantic annotation of the french
media dialog corpus. In INTERSPEECH-2005, 3457-3460.
Carletta, J. (1996). Assessing agreement on classification tasks: the kappa statistic. Comput. Linguist. 22(2),
249?254.
Denis, A., L. M. Rojas-Barahona, and M. Quignard. (2010). Extending MMIL semantic representation: Ex-
periments in dialogue systems and semantic annotation of corpora. In proceedings of the Fifth Joint ISO-
ACL/SIGSEM Workshop on Interoperable Semantic Annotation (ISA-5), Hong Kong, January 2010.
379
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 332?334,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
An Incremental Architecture for the Semantic Annotation of Dialogue
Corpora with High-Level Structures. A case of study for the MEDIA corpus.?
Lina Maria Rojas-Barahona and Matthieu Quignard
LORIA/INRIA, France
{lina.rojas,matthieu.Quignard}@loria.fr
Abstract
The semantic annotation of dialogue cor-
pora permits building efficient language un-
derstanding applications for supporting en-
joyable and effective human-machine interac-
tions. Nevertheless, the annotation process
could be costly, time-consuming and compli-
cated, particularly the more expressive is the
semantic formalism. In this work, we propose
a bootstrapping architecture for the semantic
annotation of dialogue corpora with rich struc-
tures, based on Dependency Syntax and Frame
Semantics.
1 Introduction
We propose a cooperative architecture that incre-
mentally generates and improves the annotation of
the French MEDIA dialogue corpus with high-level
semantics (HLS), as a result of the cooperation of
several linguistic modules. MEDIA is a French cor-
pus that has collected about 70 hours of spontaneous
speech from the task of hotel room reservation. It
contains transcribed utterances1 that have been man-
ually segmented2 and annotated with a flat seman-
tics i.e.,concept-value pairs (Bonneau-Maynard et
al., 2005).
?This work is supported by the Agence Nationale de la
Recherche (ANR) in France and is part of the French Project
PORT-MEDIA.
1Utterances with ellipsis, disfluencies, false starts, reformu-
lations, repetitions and ungrammaticalities and special charac-
ters such as the symbol ?*? that indicates uncertainty due to
noise in the communication channel.
2The term Segment means sequence of words in utterances.
The HLS semantics, namely the MultiModal In-
terface Language formalism (MMIL) (Denis et al,
2010), augments the expressivity of the flat seman-
tics by representing communicative actions, predi-
cates, arguments and fine-grained features. Commu-
nicative actions are components built up from two
types of entity (i.e. events and participants), which
are linked together by relations and described by
sets of features (attribute-value pairs). It is possible
to identify in entities a set of main features, which
can be domain-specific. For the semantic annota-
tion, components are mapped to segments in utter-
ances. Figure 1 shows the canonical representation
of an utterance in the corpus in compliance with the
specifications for the annotation3.
2 The Architecture
The architecture (Figure 2) for the automatic anno-
tation has been formulated as a post-interpretation
process that takes place after the syntactic analysis
and semantic role labeling (SRL). Two linguistic re-
sources interact within the architecture, the corpus
and the Frames4. Four linguistic modules are in-
volved in the annotation: the Part-Of-Speech (POS)
tagger, the parsing, the semantic-role labeling (SRL)
and the HLS Builder. The common knowledge base
comprises two knowledge-bases (one for the domain
and the other for the HLS formalism) together with a
relational database management system (RDBMS).
The knowledge bases assure the coherence of the an-
3http://www.port-media.org/doku.php?id=
mmil_for_annotating_media
4Frames is the process in which the frames and frame ele-
ments (FE) are defined.
332
Speak
Request
Reserver
(Reserve)
Personne
(People)
Chambre
(Room)
indef.
je (I)
Ville
(City)
Niort
propContent
patient
aObjetRe?serve?
aBe?ne?ficiaires
aLocalisation
Entities Segment Features=Value
Communicative Act:Request je voudrais ... a` Niort
Main Event:Reserve faire une re?servation
Participant 1:Pronoun je
Participant 2:Chambre d? une chambre
une refType=indefinite
chambre objType=Chambre
Figure 1: HLS representation for the French utterance ?je voudrais
faire une re?servation d? une chambre pour une personne a` Niort? (So I
would like to make a reservation for a room for one person in Niort).
It shows a request to reserve: the communicative action is Request the
main event is Reserve. Note that the beneficiary and the patient are two
different roles, the beneficiary is the person, not necessarily the same
speaker, who will use the object reserved (e.g. rooms). The patient is
the speaker. The segmentation of the HLS Component is presented in
the Table, the component is mapped to the whole utterance. The fine-
grained segmentation of features is shown for the Participant 2.
notation while the database assures persistence and
data integrity. The database stores the corpus, the
frames, the results at each level of analysis, as well
as the progress in the annotation. The persistence
permits progressively optimizing the algorithms un-
til the desired annotation is obtained and integrated
into the corpus files. The corpus manager is in
charge of the resources management. Last but not
least, two annotation tools were built: one for the
SRL gold standard (web-based) and the other for the
HLS gold standard (standalone).
Syntactic Analysis. We decided to employ sta-
tistical approaches that could learn the irregularities
of spoken language: the French Tree-Tagger5 and
the dependency-based MALT-PARSER (Nivre et al,
2007). The parser has been trained with 1449 utter-
ances annotated according to the annotation guide-
lines described in (Cerisara and Gardent, 2009).
5http://www.ims.uni-stuttgart.de/
?schmid/
Figure 2: General Architecture for the HLS Annotation.
Definition of Frames. Frame Semantics, (Baker
et al, 1998) arranges common background knowl-
edge for situations by grouping verbal, nominal
causative and non-causative predicates. Neverthe-
less, paraphrases are more used in spoken language
than explicitly uttered nouns, adjectives or verbs for
referring to a situation (e.g.?ask?, ?request? or ?de-
mand?). Here we introduce the term: Frame Evok-
ing Phrase (FEP) for evoking frames and we in-
clude syntactic templates that mirror these phrases
in frames and frame elements (FE). Table 1 summa-
rizes the differences between PORT-MEDIA frames
and FrameNet (Baker et al, 1998).
FrameNet PORT-MEDIA
Frames
Lexical Units Lexical Units, POS tags and templates
MEDIA Flat Semantics
Frame Elements
Lexical Units, Phrase Type Lexical Units, POS tags, templates
and Grammatical Function and dependency relation
Semantic Type Semantic Type
and MEDIA flat semantics
Table 1: Static Characteristics of Frames in FrameNet
and in PORT-MEDIA.
Semantic Role Labeling. We built a rule-based
semantic role labeling for detecting frames and FE
(roles) by using dependency tree-template pattern
matchers that exploit the information already com-
pressed in frames. The SRL detects the bound-
aries of FEP and FE by measuring the syntactic and
semantic similarity between the utterance and the
frame.
HLS Builder.The HLS Builder is the last phase in
the annotation process: it is rule-based and it takes
utterances in the corpus with their flat semantics, de-
333
pendency trees and predicates-arguments and builds
the HLS representation (See Figure 1), according to
the specifications for the annotation and the knowl-
edge bases. The dialogue act and main event in
HLS components can be detected from the predi-
cates. Similarly, secondary events and participants
with their features can be detected from the roles and
the flat semantics.
3 Evaluation and Discussion
For evaluating the system we separately com-
puted the accuracy of its linguistic components.
The parser achieved a label attachment score
(LAS) (Nivre et al, 2007) of 86.16%, with a train-
ing set of 1097 utterances and a test-set of 100 utter-
ances. The SRL was evaluated with metrics adapted
from the CONLL 2005 evaluation (Carreras and
Ma`rquez, 2005) for supporting FEP and allowing
overlapped FEP for different frames. The LAS was
computed by comparing the semantic dependencies
of system?s and gold?s propositions6 and their seg-
ments. The gold standard comprises 115 utterances
annotated with the major frames in the domain:
Request, Reserve and Attributes. The F1-measure
computed for propositions with exactly the same
segments was 56.66%. When verifying whether the
segments contain the same syntactic governor, the
SRL achieves a better score: 71.30%. Finally, vary-
ing the number of excluded words in both segments7
yielded a constant increase of the F1-measure un-
til a maximum of 84.27%. The HLS annotation
was evaluated by measuring the similarity between
gold?s and system?s components with a gold stan-
dard of 330 complex utterances related to the reser-
vation task. When rigorously measuring the equal-
ity of components8, we obtained a F1-measure of
57.79%. Measuring equality of components with-
out being so rigorous with features? segmentation,
yielded a slightly higher score 63.31%. Finally,
when measuring equality of components by taking
6A proposition is a structure containing the predicate, their
arguments and the semantic relation between them.
7From 1 to n words not common in both segments.
8Two HLS components are equal if their entities and rela-
tions are equal. Two entities are equal if they have the same
segment and features (feature name and feature value) and if
these features are mapped to the same segments in the utter-
ance. Two relations are equal if they have the same source and
target entities as well as the same name
into account only the main features of entities, we
obtained a higher score: 70.65%.
We proposed an architecture for corpus manage-
ment that allows incremental updates over persistent
information until a more accurate semantic annota-
tion is obtained. The preliminary results show a gen-
eral agreement when defining the main features and
the main entities in HLS components and a disagree-
ment when segmenting fine-grained features. We
observed that the system tends to create new entities
when it detects repetitions or references in long ut-
terances. Defining a more precise segmentation pol-
icy in the manual annotation guidelines, augmenting
the training data for parsing, as well as integrating
reference resolution and disambiguation techniques,
will enhance the annotation process. An appealing
research direction would be to integrate and evaluate
machine learning components in the architecture.
References
He?le`ne Bonneau-Maynard and Matthieu Quignard and
Alexandre Denis. 2005. MEDIA: A semantically an-
notated corpus of task oriented dialogs in French. Lan-
guage Resources and Evaluation.
Alexandre Denis and Lina M. Rojas-Barahona and
Matthieu Quignard. 2010. Extending MMIL Seman-
tic Representation: Experiments in Dialogue Systems
and Semantic Annotation of Corpora. In: Proceedings
of the Fifth ISO-ACL/SIGSEM Workshop on Interoper-
able Semantic Annotation (ISA-5), Hong Kong.
Collin Baker and Charles Fillmore and John Lowe. 1998.
The Berkeley FrameNet Project. Proceedings of the
17th International Conference on Computational lin-
guistics, 86?90. Association for Computational Lin-
guistics.
Joakim Nivre and Johan Hall and Sandra Ku?bler and
Ryan McDonald and Jens Nilsson and Sebastian
Riedel and Deniz Yuret. 2007. The CoNLL 2007
Shared Task on Dependency Parsing. Proceedings of
the CoNLL Shared Task Session of EMNLP-CoNLL
2007. Prague, Czech Republic:915?932. Association
for Computational Linguistics.
Christophe Cerisara and Claire Gardent. 2009. Anal-
yse syntaxique du franc?ais parle?. Journe?e the?matique
ATALA Quels analyseurs syntaxiques pour le franc?ais.
Xavier Carreras and Llu??s Ma`rquez. 2005. Introduc-
tion to the CoNLL-2005 shared task: Semantic role
labeling. CONLL ?05: Proceedings of the Ninth Con-
ference on Computational Natural Language Learning.
152?164. Association for Computational Linguistics.
334
