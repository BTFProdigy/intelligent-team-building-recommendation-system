Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1?11,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Event-based Time Label Propagation for Automatic Dating of News Articles
Tao Ge Baobao Chang? Sujian Li Zhifang Sui
Key Laboratory of Computational Linguistics, Ministry of Education
School of Electronics Engineering and Computer Science, Peking University
No.5 Yiheyuan Road, Haidian District, Beijing, P.R.China, 100871
{getao,chbb,lisujian,szf}@pku.edu.cn
Abstract
Since many applications such as timeline sum-
maries and temporal IR involving temporal
analysis rely on document timestamps, the
task of automatic dating of documents has
been increasingly important. Instead of using
feature-based methods as conventional mod-
els, our method attempts to date documents
in a year level by exploiting relative tempo-
ral relations between documents and events,
which are very effective for dating documents.
Based on this intuition, we proposed an event-
based time label propagation model called
confidence boosting in which time label in-
formation can be propagated between docu-
ments and events on a bipartite graph. The ex-
periments show that our event-based propaga-
tion model can predict document timestamps
in high accuracy and the model combined with
a MaxEnt classifier outperforms the state-of-
the-art method for this task especially when
the size of the training set is small.
1 Introduction
Time is an important dimension of any informa-
tion space and can be useful in information re-
trieval, question-answering systems and timeline
summaries. In the applications involving tempo-
ral analysis, document timestamps are very useful.
For instance, temporal information retrieval mod-
els take into consideration the document?s creation
time for document retrieval and ranking (Kalczyn-
ski and Chou, 2005; Berberich et al, 2007) for bet-
ter dealing with time-sensitive queries; some infor-
?Corresponding author
mation retrieval applications such as Google Scholar
can list articles published during the time a user
specifies for better satisfying users? needs. In addi-
tion, timeline summarization techniques (Hu et al,
2011; Binh Tran et al, 2013) and some event-event
ordering models (Chambers and Jurafsky, 2008;
Yoshikawa et al, 2009) also rely on the timestamps.
Unfortunately, many documents on the web do not
have a credible timestamp, as Chambers (2012) re-
ported. Therefore, it is significant to date docu-
ments, that is to predict document creation time.
One typical method for dating document is based
on temporal language models, which were first used
for dating by de Jong et al (2005). They learned
language models (unigram) for specific time periods
and scored articles with normalized log-likelihood
ratio scores. The other typical approach for the task
was proposed by Nathanael Chambers (2012). In
Chambers?s work, discriminative classifiers ? max-
imum entropy (MaxEnt) classifiers were used by
incorporating linguistic features and temporal con-
straints for training, which outperforms the previous
temporal language models on a subset of Gigaword
Corpus (Graff et al, 2003).
However, the conventional methods have some
limitations because they predict creation time of
documents mainly based on feature-based models
without understanding content of documents, which
may lead to wrong predictions in some cases. For
instance, assume that D1 and D2 are documents
whose content is given as follows:
(D1) Sudan last year accused Eritrea of
backing an offensive by rebels in the east-
ern border region.
1
(D2) Two years ago, Sudan accused Er-
itrea of backing an offensive by rebels in
the eastern border region.
SinceD1 andD2 share many important features, the
previous dating methods are very likely to predict
the same timestamp for the two documents. How-
ever, it will be easy to infer that the creation time of
D1 should be one year earlier than that of D2 if we
analyze the content of the two documents.
Unlike the previous methods, this paper exploits
relative temporal relations between events and doc-
uments for dating documents on the basis of an un-
derstanding of document content.
It is known that each event in a news article has
a relative temporal relation with the document. By
analyzing the relative temporal relation, time of the
event can be known if we know the document times-
tamp; on the other hand, if the time of an event is
known, it can also be used to predict the creation
time of documents mentioning the event, which can
be best demonstrated with the above-mentioned ex-
ample of D1 and D2. In the example, ?last year?
is an important cue to infer that the event mentioned
by the documents occurred in 2002 if we know the
timestamp of D1 is 2003. With the information that
the event occurred in 2002, it can also be inferred
from the temporal expression ?Two years ago? that
D2 was written in 2004. In this way, the timestamp
of the labeled document (D1) is propagated to the
unlabeled document (D2) through the event both of
them mention, which is the main intuition of this pa-
per.
In fact, this intuition seems practical to date doc-
uments on the web because web data is very re-
dundant. Many documents on the web can be con-
nected via events because an event is usually men-
tioned by different documents. According to our
analysis of a collection of news articles spanning 5
years, it is found that an event is mentioned by 3.44
news articles on average; on the other hand, a doc-
ument usually refers to multiple events. Therefore,
if one knows a document timestamp, time of events
the document mentions can be obtained by analyz-
ing the relative temporal relations between the doc-
ument and the events. Likewise, if the time of an
event is known, then it can be used to predict cre-
ation time of the documents which mention it.
Based on the intuition, we proposed an event-
based time label propagation model called confi-
dence boosting in which timestamps are propagated
according to relative temporal relations between
documents and events. In this way, documents can
be dated with an understanding of content so that
this model can date document more credibly. To our
knowledge, it is the first time that the relative tempo-
ral relations between documents and events are ex-
ploited for dating documents, which is proved to be
effective by the experimental results.
2 Event-based Time Label Propogation
As mentioned above, the relative temporal relations
between documents and events are useful for dat-
ing documents. By analyzing the temporal relations,
even if there are only a small number of documents
labeled with timestamps, this information can be
propagated to documents connected with them on a
bipartite graph using breadth first traversal (BFS).
Figure 1: An example of BFS-based propagation
As shown in figure 1, there are two kinds of nodes
in the bipartite graph. A document node is a single
document while an event node represents an event.
The edge between a document node and an event
node means that the document mentions the event.
Also, the edge carries the information of the rela-
tive temporal relation between the document and the
event. The label propagation from node i to node j
will occur if BFS condition which is defined as fol-
lows is satisfied:{
eij ? E
i ? L and j /? L
(BFS condition)
When the timestamp of i is propagated to j:
Y (j) = Y (i) + ?(i, j)
L = L ? {j}
where E is the set of edges of the bipartite graph,
eij denotes the edge between node i and j, L is the
set of nodes which have been already labeled with
timestamps, Y (i) is the year of node i and ?(i, j) is
the relative temporal relation between node i and j.
2
In figure 1, the timestamp of document D1 is 2003,
which is known. This information can be propagated
to its adjacent nodes i.e. the event nodes it men-
tions according to the relative temporal relations.
Then, these event nodes propagate their timestamps
to other documents which mention them. By re-
peating this process, the timestamp of the document
can be propagated to documents which are reachable
from the initially labeled document on the bipartite
graph.
Although the BFS-based propagation process can
propagate timestamps from few labeled documents
to a large number of unlabeled ones, it has two short-
comings for this task. First, once one timestamp is
propagated incorrectly, this error will lead to more
mistakes in the following propagations. If such an
error occurred at the beginning of the propagation
process, it would lead to propagation of errors. Sec-
ond, BFS-based method cannot address conflict of
predictions during propagation, which is shown in
figure 2.
Figure 2: Conflict of predictions during propagation
To address the problems of the BFS-based
method, we proposed a novel propagation model
called confidence boosting model which improves
the BFS-based model by optimizing the global con-
fidence of the bipartite graph. In the confidence
boosting model, every node in the bipartite graph
has a confidence which measures the credibility of
the predicted timestamp of the node. When the
timestamp of a node is propagated to other nodes,
its confidence will be also propagated to the tar-
get nodes with some loss. The loss of confi-
dence is called confidence decay. Formally, the
confidence decay process is described as follows:
c(j) = c(i)? ?(i, j)
where c(i) denotes confidence of node i and
?(i, j) is the decay factor from node i to
node j. For guaranteeing that timestamps
can be propagated on the bipartite graph cred-
ibly, we define the following condition which
is called CB (Confidence Boosting) condition:{
eij ? E
c(i)? ?(i, j) > c(j)
(CB condition)
In the confidence boosting model, propagation from
node i to node j will occur only if CB condition is
satisfied. When timestamps are propagated on the
bipartite graph, timestamps and confidence of nodes
will be updated dynamically. A node with high con-
fidence is more active than nodes with low confi-
dence to propagate its timestamp because a node
with high confidence is more likely to satisfy the CB
condition for propagating its timestamp. Moreover,
a prediction with low confidence can be corrected by
the prediction with high confidence. Therefore, the
confidence boosting model can address both prop-
agation of errors and conflict of predictions which
cannot be tackled by the BFS-based model.
However, there are challenges for running such
propagation models in practice. First, the relative
temporal relations between documents and events
are usually unavailable. Second, events extracted
from different documents do not have any connec-
tion even if they refer to the same event. There-
fore, each event is connected with only one docu-
ment in the bipartite graph and thus cannot prop-
agate its timestamp to other documents unless we
perform event coreference resolution. Third, propa-
gations from generic events are very likely to lead to
propagation errors because generic events can hap-
pen in any year. Also, how to set the confidence and
decay factors reasonably in practice for a confidence
boosting model is worthy of investigation. All these
challenges for the propagation models and their cor-
responding solutions will be discussed in Section 3.
3 Details of Event-based Propagation
Models
In this section, details of the event-based time la-
bel propagation models including challenges and
their corresponding solutions are presented. We first
discuss the event extraction and processing involv-
ing relative temporal relation mining, event coref-
erence resolution and distinguishing specific extrac-
tions from generic ones in Section 3.1. Then, we
show the confidence boosting algorithm in detail in
Section 3.2.
3
3.1 Event extraction and processing
As mentioned in previous sections, events play a key
role in the propagation models. We define an event
as a Subject-Predicate-Object (SPO) triple. To ex-
tract events from raw text, an open information ex-
traction software - ReVerb (Fader et al, 2011) is
used. ReVerb is a program that automatically iden-
tifies and extracts relationships from English sen-
tences. It takes raw text as input and outputs SPO
triples which are called extractions.
However, extractions extracted by ReVerb cannot
be used directly for our propagation models for three
main reasons. First, the relative temporal relations
between documents and the extractions are unavail-
able. Second, the extractions extracted from differ-
ent documents do not have any connection even if
they refer to the same event. Third, propagations
from generic events are very likely to lead to propa-
gation errors.
For addressing the three challenges for the prop-
agation models, we first presented a rule-based
method for mining the relative temporal relations be-
tween extractions and documents in Section 3.1.1.
Then, an efficient event coreference resolution
method is introduced in Section 3.1.2. Finally, the
method for distinguishing specific extractions from
generic ones is shown in Section 3.1.3.
3.1.1 Relative temporal relation mining
We used a rule-based method to extract temporal
expressions and used Stanford parser (De Marneffe
et al, 2006) to analyze association between the tem-
poral expressions and the extractions. Specifically,
we define that an extraction is associated with a tem-
poral expression if there is an arc from the predicate
of the extraction to the temporal expression in the
dependency tree. For a certain extraction, there are
the following four cases whose instances are shown
in table 1 for handling.
Case 1: The extraction is associated with an abso-
lute temporal expressions with year mentions in the
sentence.
In this case, the time of the extraction is equal to
the year mention:
Y (ex) = Y earMention
For the example in table 1, Y (ex) = 1999.
Case 2: The extraction is associated with a relative
temporal expression (not involving year) in the sen-
Case Instance
1 In 1999, South Korea exported 89,000
tons of pork to Japan.
2
In April, however, the BOI investments
showed marked improvement.
Last month, Kazini vowed to resign his
top army job.
3 Julius Erving moved with his family to
Florida three years ago.
4 The meeting focused on ways to revive
the stalled Mideast peace process.
Table 1: Instances of various temporal expressions
tence.
In this case, the time of the extraction is equal to
the creation time of the document:
Y (ex) = Y (d)
Case 3: The extraction is associated with a relative
temporal expression (involving specific year gap) in
the sentence.
In this case, the time of the extraction is computed
as follows:
Y (ex) = Y (d)? Y earGap
For the example in table 1, Y (ex) = Y (d)? 3.
Case 4: The extraction is not associated with any
temporal expression in the sentence or the other
cases.
In this case, it is difficult to recognize the rela-
tive temporal relations. However, timeliness can be
leveraged to determine the relations as a heuristic
method. It is known that timeliness is an important
feature of news so that events reported by a news ar-
ticle usually took place a couple of days or weeks
before the article was written. Therefore, we heuris-
tically consider the year of the extraction is the same
with that of its source document in this case:
Y (ex) = Y (d)
In the cases except case 1, the relative tempo-
ral relation between an extraction and the docu-
ment it comes from can be determined. To evalu-
ate the performance of the rule-based method, we
sampled 3,000 extractions from documents written
in the year of 1995-1999 of Gigaword corpus and
manually labeled these extractions with a timestamp
based on their context and their corresponding docu-
ment timestamps as golden standard. Table 2 shows
4
the accuracy of each case which will be used as a
part of the decay factor in the confidence boosting
model.
Case Accuracy
1 0.774(168/217)
2 0.994(844/849)
3 0.836(281/336)
4 0.861(1376/1598)
Total 0.890(2669/3000)
Table 2: Accuracy of the four cases
We define the set of these determined relative tem-
poral relations R as follows:
R = {rd,ex|d = doc(ex), ex ? C2 ? C3 ? C4}
rd,ex =< d, ex, ?(d, ex) >
?(d, ex) = ??(ex, d) = {0,?1,?2,?3, ...}
where Ck is the set of extractions in case k and
doc(ex) is the document which extraction ex comes
from. rd,ex is a triple describing the relative tempo-
ral relation between d and ex. For example, triple
rd,ex =< d, ex,?1 > means that the time of ex-
traction ex is one year before the time of document
d.
3.1.2 Event coreference resolution
Extractions from different documents have no
connections. However, there are a great number of
extractions referring to the same event. For find-
ing such coreferential event extractions efficiently,
hierarchical agglomerative clustering (HAC) is used
to cluster highly similar extractions into one cluster.
We use cosine to measure the similarity between ex-
tractions and select bag of words as features. Note
that it is less meaningful to cluster the extractions
from the same document because coreferential ex-
tractions from the same document are not helpful for
timestamp propagations. For this reason, similarity
between extractions from the same documents is set
to 0.
For HAC, selection of threshold is important. If
the threshold is set too high, only a few extractions
can be clustered despite high purity; on the contrary,
if the threshold is set too low, purity of clusters will
descend. In fact, selection of threshold is a trade-off
between the precision and recall of event corefer-
ence resolution. For selecting a suitable threshold,
extractions from documents written in 1995-1999
are used as a development set.
In practice, it is difficult for us to directly evalu-
ate the performance of the coreference resolution of
event extractions without golden standard which re-
quires much labors for manual annotations. Alterna-
tively, entropy which measures the purity of clusters
is used for evaluation because it can indirectly re-
flect the precision of coreference resolution to some
extent:
Entropy = ?
?
j
nj
n
?
i
P (i, j)? log2 P (i, j)
where P (i, j) is the probability of finding an extrac-
tion whose timestamp is i in the cluster j, nj is the
number of items in cluster j and n is the total num-
ber of extractions. Note that timestamp of an extrac-
tion is assigned based on its document timestamp
using the method proposed in Section 3.1.1.
Figure 3 shows the effect of selection of the
threshold on cluster performance. It can be found
that when the threshold reaches 0.8, the entropy
starts descending gently and is low enough. Since
we want to find as many coreferential extractions as
possible on the premise that the precision is good,
the threshold is set to 0.8. Note that extractions
which are single in one cluster will be filtered out
because they do not have any connections with any
other documents.
0.6 0.65 0.7 0.75 0.8 0.85 0.90.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
0.6
0.65
Threshold
Ent
ropy
Figure 3: Entropy of clusters under different thresholds
3.1.3 Distinguishing specific events from
generic ones
Not all extractions extracted by ReVerb refer to
a specific event. For instance, the extraction ?Ger-
many?s DAX index was down 0.2 percent? is un-
desirable for our task because it refers to a generic
5
event and this event may occur in any year. In other
words, it is not able to indicate a certain timestamp
and thus propagations from a generic event node are
very likely to result in propagation errors. In con-
trast, the extraction ?some of the provinces in China
were hit by SARS? refers to a specific event which
took place in 2003. For our task, such specific event
extractions which are associated with one certain
timestamp are desirable. For the sake of distinguish-
ing such extractions from the generic ones, a Max-
Ent classifier is used to classify extractions as either
specific ones or generic ones.
Training Set Generation A training set is indis-
pensable for training a MaxEnt classifier. In order
to generate training examples, we performed HAC
discussed in Section 3.1.2 for event coreference res-
olution on extractions from all documents written
in May and June of 1995-1999 and then analyzed
each cluster. If extractions in a cluster have different
timestamps, then the extractions in this cluster will
be labeled as generic extractions (negative); other-
wise, extractions in the cluster are labeled as spe-
cific ones (positive). In this way, the training set can
be generated without manually labeling. To avoid
bias of positive and negative examples, we sampled
3,500 positive examples and 3,500 negative exam-
ples to train the model.
Feature Selection The following features were se-
lected for training:
Named Entities: People and places are often dis-
cussed during specific time periods, particularly in
news genre. Intuitively, if an extraction contains
specific named entities then this extraction is less
likely to be a generic event. If an extraction con-
tains named entities, types and uninterrupted tokens
of the named entities will be included as features.
Numeral: According to our analysis of the train-
ing set generated by the above-mentioned method,
generic extractions usually contain numerals. For
example, the extraction ?15 people died in this ac-
cident? and the extraction ?225 people died in this
accident? have the same tokens except numerals and
they are labeled as a generic event because they are
clustered into one group due to high similarity but
they in fact refer to different events happening in
different years. Therefore, if an extraction contains
numerals, the feature ?NUM? will be included.
Bag of words: Bag of words can also be an indicator
of specific extractions and generic ones. For exam-
ple, an extraction containing ?stock?, ?index?, ?fell?
and ?exchange? is probably a generic one.
The model obtained after training can be used to
predict whether an extraction is a specific one. We
define P (S = 1|ex) as the probability that an ex-
traction is a specific one, which can be provided by
the classifier. Extractions whose probability to be a
specific one is less than 0.05 are filtered out. For the
other extractions, this probability is used as a part of
the decay factor in the confidence boosting model,
which will be discussed in detail in Section 3.2.
3.2 Confidence boosting
After extracting and processing the event extrac-
tions, relative temporal relations between documents
and events can be constructed. This can be for-
mally represented by a bipartite graph G=?V,E?.
There are two kinds of nodes on the bipartite graph:
document nodes and event nodes. Slightly dif-
ferent with the event node mentioned in Section
2, an event node in practice is a cluster of coref-
erential extractions and it can be connected with
multiple document nodes. Note that the bipar-
tite graph does not contain any isolate node. For
briefness, we define DNode as the set of docu-
ment nodes and ENode as the set of event nodes.
The set of edges E is formally defined as follows:
E = {eij , eji|i ? DNode, j ? ENode, ri,j ? R}
where R is the set of relative temporal relations de-
fined as Section 3.1.1.
3.2.1 Confidence and decay factor
As mentioned in Section 2, the confidence of a
node measures the credibility of the predicted times-
tamp. According to the definition, we set the confi-
dence of initially labeled nodes to 1 and set confi-
dence of nodes without any timestamp to 0 in prac-
tice. When the timestamp of a node is propagated
to another node, its confidence will be propagated to
the target node with some loss, as discussed in Sec-
tion 2. The confidence loss is caused by two factors
in practice. The first one is the credibility of the rel-
ative temporal relation between two nodes and the
other one depends on whether an extraction refers to
a specific event.
Relative temporal relations between documents
6
and extractions we mined using the rule-based
method in Section 3.1.1 are not absolutely correct.
The credibility of the relations has an effect on the
confidence decay. Formally, we used pi(i, j) to de-
note the credibility of the relative temporal relation
between node i and node j. The credibility of a rel-
ative temporal relation in each case can be estimated
through table 2. If the credibility of the relative tem-
poral relation between i and j is low, propagation
from node i to j probably leads to error. Therefore,
the confidence loss should be much in this case. On
contrary, if the relation is highly credible, it will be
less likely that propagation errors occur. Therefore,
the confidence loss should be little.
In addition, whether an extraction refers to a
generic event or a specific one exerts an impact on
the confidence loss. If an extraction refers to a
generic event, then the extractions in the same clus-
ter with it probably have different timestamps. Since
our propagation model assumes that extractions in a
cluster are coreferent and thus they should have the
same timestamp, propagations from a generic event
node are very likely to result in propagation errors.
Therefore, the timestamp of a generic event node
in fact is less credible for propagations and confi-
dence of such event nodes should be low for limiting
propagations from the nodes. For this reason, prop-
agation from a document node to a generic event
node leads to much loss of confidence. We define
the probability that an event node refers to a specific
event as follows:
P (S = 1|enode) =
1
|C|
?
ex?C
P (S = 1|ex)
where C is the set of extractions in the event node
and P (S = 1|ex) is the probability that an extrac-
tion refers to a specific event, which can be provided
by the MaxEnt classifier discussed in Section 3.1.3.
Considering the two factors for confidence loss,
we formally define the decay factor by (1).
?(s, t) = (1)
{
pi(s, t) if t ? DNode
pi(s, t)? P (S = 1|t) otherwise
3.2.2 Confidence boosting algorithm
In confidence boosting model, the propagation
from i to j will occur only if the CB condition is
Figure 4: Algorithm of confidence boosting
satisfied. The confidence boosting propagation pro-
cess can be described as figure 4.
Whenever timestamps are propagated to other
nodes, the global confidence of the bipartite graph
will increase. For this reason, this propagation pro-
cess is called confidence boosting. In this model,
a node with high confidence is more active than
nodes with low confidence to propagate its times-
tamp. Moreover, a prediction with low confidence
can be corrected by the prediction with high con-
fidence. Therefore, the confidence boosting model
can alleviate the problem of propagation of errors
to some extent and handle conflict of predictions.
Thus, it can propagate timestamps more credibly
than the BFS-based model. It can also be proved
that each node on the bipartite graph must reach the
highest confidence it can reach so that the global
confidence of the bipartite graph must be optimal
when the confidence boosting propagation process
ends regardless of propagation orders, which will be
discussed in Section 3.2.3.
3.2.3 Proof of the optimality of confidence
boosting
Proof by contradiction can be used to prove that
propagation orders do not affect the optimality of the
confidence boosting model.
Proof Assume by contradiction that there is some
node that does not reach its highest confidence it can
reach when a confidence boosting process in propa-
gation order A ends:
?vt s.t. cA(vt) < c?(vt)
where cA(vt) is the confidence of vt when the
propagation process in order A ends and c?(vt) is
the highest confidence that vt can reach. Assume
that (v1, v2, ? ? ? , vt?1, vt) is the optimal propagation
7
path from the propagation source node v1 to the
node vt that leads to the highest confidence of vt,
which means that c?(vt) = c?(vt?1) ? ?(vt?1, vt),
c?(vt?1) = c?(vt?2) ? ?(vt?2, vt?1), ..., c?(v2) =
c?(v1) ? ?(v1, v2). Then according to CB condi-
tion, since cA(vt?1) ? ?(vt?1, vt) ? cA(vt) <
c?(vt) = c?(vt?1) ? ?(vt?1, vt), the inequality
cA(vt?1) < c?(vt?1) must hold. Similarly, it can be
easily inferred that cA(vt?2) < c?(vt?2) and finally
cA(v1) < c?(v1). Since v1 is the source node whose
timestamp is initially labeled and its confidence is 1,
the inequality cA(v1) < c?(v1) cannot hold. Thus,
the assumption that cA(vt) < c?(vt) cannot be sat-
isfied. Therefore, it can be proved that each node
on the bipartite graph must reach the highest con-
fidence it can reach so that the global confidence of
the bipartite graph must be optimal when confidence
boosting propagation process ends no matter what
order time labels are propagated in.
4 Experiments
In this section, we evaluate the performance of our
time label propagation models and different auto-
matic document dating models on the Gigaword
dataset. We first present the experimental setting.
Then we show experimental results and perform an
analysis.
4.1 Experimental Setting
Dataset To simulate the environment of the web
where data is very redundant, we use all documents
written in April, June, July and September of 2000-
2004 of Gigaword Corpus as dataset instead of sam-
pling a subset of documents from each period. The
dataset contains 900,199 news articles.
Pre-processing Many extractions extracted by Re-
Verb are short and uninformative and do not carry
any valuable information for propagating temporal
information. Also, some extractions do not refer
to events which already happened. These extrac-
tions may affect the performance of event corefer-
ence resolution and the rule-based method proposed
in Section 3.1.1 for mining relative temporal rela-
tions. Therefore, we filter out these undesirable ex-
tractions in advance with a rule-based method. The
rules are shown in table 3. This preprocessing re-
moves large numbers of ?bad? extractions which are
undesirable for our task. As a result, not only com-
putation efficiency but also precision of event coref-
erence resolution will be improved.
Rule1 If the number of tokens of the extrac-
tion is less than 5 then this extraction
will be filtered out.
Rule2 If the maximum idf of terms of the ex-
traction is less than 3.0 then this ex-
traction will be filtered out.
Rule3 If the tense of the extraction is not past
tense then this extraction will be fil-
tered out.
Rule4 If the extraction is the content of di-
rect quotation then this extraction will
be filtered out.
Table 3: Pre-processing Rules
|DNode| 550,124
|ENode| 968,064
|E| 3,104,666
Table 4: Basic information of the bi-partite graph
Basic information of the document-event bipartite
graph constructed is shown in table 4.
Evaluation To evaluate the performance of the
propagation models for the task of dating on differ-
ent sizes of the training set, we used different sizes
of the labeled documents for training and consid-
ered the remaining documents as the test set. Note
that the training set is randomly sampled from the
dataset. To be more persuasive, we repeated above
experiments for five times.
However, in the time label propagation process,
not all documents can be labeled. For those doc-
uments which cannot be labeled in the process of
propagation, a MaxEnt classifier serves as a comple-
mentary approach to predict their timestamps. For
the MaxEnt classifier, unigrams and named entities
are simply selected as features and the initially la-
beled documents as well as documents labeled dur-
ing propagation process are used for training.
Baseline methods are temporal language models
proposed by de Jong et al (2005) and the state-of-
the-art discriminative classifier with linguistic fea-
tures and temporal constraints which was proposed
8
Initially Labeled 1k 5k 10k 50k 100k 200k 500k
Reached Min 443980 448653 453022 484562 518603 599724 732701
Reached Max 444266 448998 454028 484996 519333 579878 732799
Reached Avg 444107 448742 453786 484622 519110 579835 732758
Prop Ratio 444.1 89.7 45.4 9.7 5.2 2.9 1.5
Prop acc(BFS) 0.438 0.515 0.551 0.646 0.691 0.725 0.775
Prop acc(CB) 0.494 0.569 0.603 0.701 0.746 0.776 0.807
Table 5: Performance of Propagation
Initially Labeled 1k 5k 10k 50k 100k 200k 500k
Temporal LMs 0.277 0.323 0.353 0.412 0.422 0.425 0.420
Maxent(Unigrams) 0.326 0.378 0.407 0.486 0.517 0.553 0.590
Maxent(Unigrams+NER) 0.331 0.383 0.418 0.506 0.549 0.590 0.665
Chambers?s 0.331 0.386 0.423 0.524 0.571 0.615 0.690
BFS+Maxent 0.459 0.508 0.533 0.595 0.626 0.658 0.707
CB+Maxent 0.486 0.535 0.559 0.624 0.655 0.685 0.726
Table 6: Overall accuracy of dating models
by Nathanael Chambers (2012). In Chambers?s joint
model, the interpolation parameter ? is set to 0.35
which is considered optimal in his work.
4.2 Experimental Results
Table 5 shows the performance of propagation mod-
els where Reached denotes the number of docu-
ments labeled when the propagation process ends,
prop ratio and prop accuracy are defined as follows:
Prop Ratio =
#ReachedDocNodes
#LabeledDocNodes
Prop Accuracy =
#CorrectDocNodes?#LabeledDocNodes
#ReachedDocNodes?#LabeledDocNodes
where #LabeledDocNodes is the number of ini-
tially labeled document nodes which are documents
in the training set and #ReachedDocNodes is the
number of document nodes labeled when the propa-
gation process ends.
Note that prop ratio and accuracy in table 5 are
the mean of the prop ratio and accuracy of the five
groups of experiments. It is clear that confidence
boosting model improves the prop accuracy over
BFS-based model. When only 1,000 documents
are initially labeled with timestamps, the confidence
boosting model can propagate their timestamps to
more than 400,000 documents with an accuracy of
0.494, approximately 12.8% relative improvement
over the BFS counterpart, which proves effective-
ness of the confidence boosting model.
However, as shown in table 5, hardly can the prop-
agation process propagate timestamps to all doc-
uments. One reason is that the number of docu-
ment nodes on the bipartite graph is only 550,124,
approximately 61.1% of all documents. The other
documents may not mention events which are also
mentioned by other documents, which means they
are isolate and thus are excluded from the bipartite
graph. Also, the event coreference resolution phase
does not guarantee finding all coreferential extrac-
tions; in other words, recall of event coreference res-
olution is not 100%. The other reason is that some
documents are unreachable from the initially labeled
nodes even if they are in the bipartite graph.
The overall accuracy of different dating models
is shown in table 6. As with table 5, overall accu-
racy in table 6 is the average performance of mod-
els in the five groups of experiments. As reported
by Nathanael Chambers (2012), the discriminative
classifier performs much better than the temporal
language models on the Gigaword dataset. In the
case of 500,000 training examples, the Maxent clas-
sifier using unigram features outperforms the tem-
poral language models by 40.5% relative accuracy.
If the size of the training set is large enough, named
9
entities and linguistic features as well as temporal
constraints will improve the overall accuracy sig-
nificantly. However, if the size of the training set
is small, these features will not result in much im-
provement.
Compared with the previous models, the propaga-
tion models predict the document timestamps much
more accurately especially in the case where the size
of the training set is small. When the size of the
training set is 1,000, our BFS-based model and con-
fidence boosting model combined with the MaxEnt
classifier outperform Chambers?s joint model which
is considered the state-of-the-art model for the task
of automatic dating of documents by 38.7% and
46.8% relative accuracy respectively. This is be-
cause the feature-based methods are not very reli-
able especially when the size of the training set is
small. In contrast, our propagation models can pre-
dict timestamps of documents with an understand-
ing of document content, which allows our method
to date documents more credibly than the baseline
methods. Also, by comparing table 5 with table 6,
it can be found that prop accuracy is almost always
higher than overall accuracy, which also verifies that
the propagation models are more credible for dat-
ing document than the feature-based models. More-
over, data is so redundant that a great number of
documents can be connected with events they share.
Therefore, even if a small number of documents are
labeled, the labeled information can be propagated
to large numbers of articles through the connections
between documents and events according to relative
time relations. Even if the size of the training set
is large, e.g. 500,000, our propagation models still
outperform the state-of-the-art dating method. Ad-
ditionally, some event nodes on the bipartite graph
may be labeled with a timestamp during the process
of propagation as a byproduct. The temporal infor-
mation of the events would be useful for other tem-
poral analysis tasks.
5 Related Work
In addition to work of de Jong et al (2005) and
Chambers (2012) introduced in previous sections,
there is also other research focusing on the task of
document dating. Kanhabua and Norvag (2009) im-
proved temporal language models by incorporating
temporal entropy and search statistics and apply-
ing two filtering techniques to the unigrams in the
model. Kumar et al (2011) is also based on the
temporal language models, but more historically-
oriented, which models the timeline from the present
day back to the 18th century. In addition, they used
KL-divergence instead of normalized log likelihood
ratio to measure differences between a document
and a time period?s language model.
However, these methods are based on tempo-
ral language models so they also suffer from the
problem of the method of de Jong et al (2005).
Therefore, they inevitably make wrong predictions
in some cases, just as mentioned in Section 1. Com-
pared with these methods, our event-based propaga-
tion models exploit relative temporal relations be-
tween documents and events for dating document
on a basis of an understanding of document content,
which is more reasonable and also proved to be more
effective by the experimental results.
6 Conclusion
The main contribution of this paper is exploiting
relative temporal relations between events and doc-
uments for the document dating task. Different
with the conventional work which dates documents
with feature-based methods, we proposed an event-
based time label propagation model called confi-
dence boosting in which timestamps are propagated
on a document-event bipartite graph according to
relative temporal relations between documents and
events for dating documents on a basis of an under-
standing of document content. We discussed chal-
lenges for the propagation models and gave the cor-
responding solutions in detail. The experimental re-
sults show that our event-based propagation model
can predict document timestamps in high accuracy
and the model combined with a MaxEnt classifier
outperforms the state-of-the-art method on a data-
redundant dataset.
Acknowledgements
We thank the anonymous reviewers for their valu-
able suggestions. This paper is supported by
NSFC Project 61075067, NSFC Project 61273318
and National Key Technology R&D Program (No:
2011BAH10B04-03).
10
References
Klaus Berberich, Srikanta Bedathur, Thomas Neumann,
and Gerhard Weikum. 2007. A time machine for
text search. In Proceedings of the 30th annual in-
ternational ACM SIGIR conference on Research and
development in information retrieval, pages 519?526.
ACM.
Giang Binh Tran, Mohammad Alrifai, and Dat
Quoc Nguyen. 2013. Predicting relevant news events
for timeline summaries. In Proceedings of the 22nd
international conference on World Wide Web compan-
ion, pages 91?92. International World Wide Web Con-
ferences Steering Committee.
Nathanael Chambers and Dan Jurafsky. 2008. Jointly
combining implicit constraints improves temporal or-
dering. In Proceedings of the Conference on Empir-
ical Methods in Natural Language Processing, pages
698?706. Association for Computational Linguistics.
Nathanael Chambers. 2012. Labeling documents with
timestamps: Learning from their time expressions. In
Proceedings of the 50th Annual Meeting of the Asso-
ciation for Computational Linguistics: Long Papers-
Volume 1, pages 98?106. Association for Computa-
tional Linguistics.
FMG de Jong, Henning Rode, and Djoerd Hiemstra.
2005. Temporal language models for the disclosure
of historical text. Royal Netherlands Academy of Arts
and Sciences.
Marie-Catherine De Marneffe, Bill MacCartney, Christo-
pher D Manning, et al 2006. Generating typed de-
pendency parses from phrase structure parses. In Pro-
ceedings of LREC, volume 6, pages 449?454.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1535?1545. Association for Computational Linguis-
tics.
David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda.
2003. English gigaword. Linguistic Data Consortium,
Philadelphia.
Po Hu, Minlie Huang, Peng Xu, Weichang Li, Adam K
Usadi, and Xiaoyan Zhu. 2011. Generating
breakpoint-based timeline overview for news topic ret-
rospection. In Data Mining (ICDM), 2011 IEEE 11th
International Conference on, pages 260?269. IEEE.
Pawel Jan Kalczynski and Amy Chou. 2005. Temporal
document retrieval model for business news archives.
Information processing management, 41(3):635?650.
Nattiya Kanhabua and Kjetil N?rva?g. 2009. Us-
ing temporal language models for document dating.
In Machine Learning and Knowledge Discovery in
Databases, pages 738?741. Springer.
Abhimanu Kumar, Matthew Lease, and Jason Baldridge.
2011. Supervised language modeling for temporal res-
olution of texts. In Proceedings of the 20th ACM in-
ternational conference on Information and knowledge
management, pages 2069?2072. ACM.
Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asa-
hara, and Yuji Matsumoto. 2009. Jointly identifying
temporal relations with markov logic. In Proceedings
of the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference on
Natural Language: Volume 1-Volume 1, pages 405?
413. Association for Computational Linguistics.
11
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 293?303,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Max-Margin Tensor Neural Network for Chinese Word Segmentation
Wenzhe Pei Tao Ge Baobao Chang
?
Key Laboratory of Computational Linguistics, Ministry of Education
School of Electronics Engineering and Computer Science, Peking University
Beijing, P.R.China, 100871
{peiwenzhe,getao,chbb}@pku.edu.cn
Abstract
Recently, neural network models for nat-
ural language processing tasks have been
increasingly focused on for their ability
to alleviate the burden of manual feature
engineering. In this paper, we propose a
novel neural network model for Chinese
word segmentation called Max-Margin
Tensor Neural Network (MMTNN). By
exploiting tag embeddings and tensor-
based transformation, MMTNN has the
ability to model complicated interactions
between tags and context characters. Fur-
thermore, a new tensor factorization ap-
proach is proposed to speed up the model
and avoid overfitting. Experiments on the
benchmark dataset show that our model
achieves better performances than previ-
ous neural network models and that our
model can achieve a competitive perfor-
mance with minimal feature engineering.
Despite Chinese word segmentation being
a specific case, MMTNN can be easily
generalized and applied to other sequence
labeling tasks.
1 Introduction
Unlike English and other western languages, Chi-
nese do not delimit words by white-space. There-
fore, word segmentation is a preliminary and im-
portant pre-process for Chinese language process-
ing. Most previous systems address this problem
by treating this task as a sequence labeling prob-
lem where each character is assigned a tag indi-
cating its position in the word. These systems
are effective because researchers can incorporate a
large body of handcrafted features into the models.
However, the ability of these models is restricted
?
Corresponding author
by the design of features and the number of fea-
tures could be so large that the result models are
too large for practical use and prone to overfit on
training corpus.
Recently, neural network models have been in-
creasingly focused on for their ability to mini-
mize the effort in feature engineering. Collobert et
al. (2011) developed the SENNA system that ap-
proaches or surpasses the state-of-the-art systems
on a variety of sequence labeling tasks for English.
Zheng et al (2013) applied the architecture of
Collobert et al (2011) to Chinese word segmenta-
tion and POS tagging and proposed a perceptron-
style algorithm to speed up the training process
with negligible loss in performance.
Workable as previous neural network models
seem, a limitation of them to be pointed out is
that the tag-tag interaction, tag-character inter-
action and character-character interaction are not
well modeled. In conventional feature-based lin-
ear (log-linear) models, these interactions are ex-
plicitly modeled as features. Take phrase ???
?(play basketball)? as an example, assuming we
are labeling character C
0
=???, possible features
could be:
f
1
=
{
1 C
?1
=??? and C
1
=??? and y
0
=?B?
0 else
f
2
=
{
1 C
0
=??? and y
0
=?B? and y
?1
=?S?
0 else
To capture more interactions, researchers have de-
signed a large number of features based on linguis-
tic intuition and statistical information. In previ-
ous neural network models, however, hardly can
such interactional effects be fully captured rely-
ing only on the simple transition score and the sin-
gle non-linear transformation (See section 2). In
order to address this problem, we propose a new
model called Max-Margin Tensor Neural Network
(MMTNN) that explicitly models the interactions
293
between tags and context characters by exploiting
tag embeddings and tensor-based transformation.
Moreover, we propose a tensor factorization ap-
proach that effectively improves the model effi-
ciency and prevents from overfitting. We evalu-
ate the performance of Chinese word segmentation
on the PKU and MSRA benchmark datasets in the
second International Chinese Word Segmentation
Bakeoff (Emerson, 2005) which are commonly
used for evaluation of Chinese word segmentation.
Experiment results show that our model outper-
forms other neural network models.
Although we focus on the question that how
far we can go without using feature engineering
in this paper, the study of deep learning for NLP
tasks is still a new area in which it is currently
challenging to surpass the state-of-the-art with-
out additional features. Following Mansur et al
(2013), we wonder how well our model can per-
form with minimal feature engineering. There-
fore, we integrate additional simple character bi-
gram features into our model and the result shows
that our model can achieve a competitive perfor-
mance that other systems hardly achieve unless
they use more complex task-specific features.
The main contributions of our work are as fol-
lows:
? We propose a Max-Margin Tensor Neu-
ral Network for Chinese word segmentation
without feature engineering. The test re-
sults on the benchmark dataset show that our
model outperforms previous neural network
models.
? We propose a new tensor factorization ap-
proach that models each tensor slice as the
product of two low-rank matrices. Not only
does this approach improve the efficiency of
our model but also it avoids the risk of over-
fitting.
? Compared with previous works that use a
large number of handcrafted features, our
model can achieve a competitive perfor-
mance with minimal feature engineering.
? Despite Chinese word segmentation being a
specific case, our approach can be easily gen-
eralized to other sequence labeling tasks.
The remaining part of this paper is organized as
follows. Section 2 describes the details of con-
ventional neural network architecture. Section 3
Figure 1: Conventional Neural Network
describes the details of our model. Experiment re-
sults are reported in Section 4. Section 5 reviews
the related work. The conclusions are given in
Section 6.
2 Conventional Neural Network
2.1 Lookup Table
The idea of distributed representation for symbolic
data is one of the most important reasons why the
neural network works. It was proposed by Hin-
ton (1986) and has been a research hot spot for
more than twenty years (Bengio et al, 2003; Col-
lobert et al, 2011; Schwenk et al, 2012; Mikolov
et al, 2013a). Formally, in the Chinese word seg-
mentation task, we have a character dictionary D
of size |D|. Unless otherwise specified, the char-
acter dictionary is extracted from the training set
and unknown characters are mapped to a special
symbol that is not used elsewhere. Each character
c ? D is represented as a real-valued vector (char-
acter embedding) Embed(c) ? R
d
where d is the
dimensionality of the vector space. The charac-
ter embeddings are then stacked into a embedding
matrix M ? R
d?|D|
. For a character c ? D that
has an associated index k, the corresponding char-
acter embedding Embed(c) ? R
d
is retrieved by
the Lookup Table layer as shown in Figure 1:
Embed(c) = Me
k
(1)
Here e
k
? R
|D|
is a binary vector which is zero in
all positions except at k-th index. The Lookup Ta-
ble layer can be seen as a simple projection layer
where the character embedding for each context
294
character is achieved by table lookup operation ac-
cording to their indices. The embedding matrix
M is initialized with small random numbers and
trained by back-propagation. We will analyze in
more detail about the effect of character embed-
dings in Section 4.
2.2 Tag Scoring
The most common tagging approach is the win-
dow approach. The window approach assumes
that the tag of a character largely depends on its
neighboring characters. Given an input sentence
c
[1:n]
, a window of size w slides over the sentence
from character c
1
to c
n
. We set w = 5 in all
experiments. As shown in Figure 1, at position
c
i
, 1 ? i ? n, the context characters are fed into
the Lookup Table layer. The characters exceeding
the sentence boundaries are mapped to one of two
special symbols, namely ?start? and ?end? sym-
bols. The character embeddings extracted by the
Lookup Table layer are then concatenated into a
single vector a ? R
H
1
, where H
1
= w ? d is
the size of Layer 1. Then a is fed into the next
layer which performs linear transformation fol-
lowed by an element-wise activation function g
such as tanh, which is used in our experiments:
h = g(W
1
a+ b
1
) (2)
where W
1
? R
H
2
?H
1
, b
1
? R
H
2
?1
, h ? R
H
2
. H
2
is a hyper-parameter which is the number of hid-
den units in Layer 2. Given a set of tags T of size
|T |, a similar linear transformation is performed
except that no non-linear function is followed:
f(t|c
[i?2:i+2]
) = W
2
h+ b
2
(3)
where W
2
? R
|T |?H
2
, b
2
? R
|T |?1
.
f(t|c
[i?2:i+2]
) ? R
|T |
is the score vector for each
possible tag. In Chinese word segmentation, the
most prevalent tag set T is BMES tag set, which
uses 4 tags to carry word boundary information. It
uses B, M, E and S to denote the Beginning, the
Middle, the End of a word and a Single character
forming a word respectively. We use this tag set in
our method.
2.3 Model Training and Inference
Despite sharing commonalities mentioned above,
previous work models the segmentation task dif-
ferently and therefore uses different training and
inference procedure. Mansur et al (2013) mod-
eled Chinese word segmentation as a series of
classification task at each position of the sentence
in which the tag score is transformed into proba-
bility using softmax function:
p(t
i
|c
[i?2:i+2]
) =
exp(f(t
i
|c
[i?2:i+2]
))
?
t
?
exp(f(t
?
|c
[i?2:i+2]
))
The model is then trained in MLE-style which
maximizes the log-likelihood of the tagged data.
Obviously, it is a local model which cannot cap-
ture the dependency between tags and does not
support to infer the tag sequence globally.
To model the tag dependency, previous neural
network models (Collobert et al, 2011; Zheng
et al, 2013) introduce a transition score A
ij
for
jumping from tag i ? T to tag j ? T . For a
input sentence c
[1:n]
with a tag sequence t
[1:n]
, a
sentence-level score is then given by the sum of
transition and network scores:
s(c
[1:n]
, t
[1:n]
, ?) =
n
?
i=1
(A
t
i?1
t
i
+f
?
(t
i
|c
[i?2:i+2]
))
(4)
where f
?
(t
i
|c
[i?2:i+2]
) indicates the score output
for tag t
i
at the i-th character by the network with
parameters ? = (M,A,W
1
, b
1
,W
2
, b
2
). Given
the sentence-level score, Zheng et al (2013)
proposed a perceptron-style training algorithm in-
spired by the work of Collins (2002). Compared
with Mansur et al (2013), their model is a global
one where the training and inference is performed
at sentence-level.
Workable as these methods seem, one of the
limitations of them is that the tag-tag interaction
and the neural network are modeled seperately.
The simple tag-tag transition neglects the impact
of context characters and thus limits the ability
to capture flexible interactions between tags and
context characters. Moreover, the simple non-
linear transformation in equation (2) is also poor
to model the complex interactional effects in Chi-
nese word segmentation.
3 Max-Margin Tensor Neural Network
3.1 Tag Embedding
To better model the tag-tag interaction given the
context characters, distributed representation for
tags instead of traditional discrete symbolic repre-
sentation is used in our model. Similar to character
embeddings, given a fixed-sized tag set T , the tag
embeddings for tags are stored in a tag embedding
matrix L ? R
d?|T |
, where d is the dimensionality
295
Figure 2: Max-Margin Tensor Neural Network
of the vector space (same with character embed-
dings). Then the tag embedding Embed(t) ? R
d
for tag t ? T with index k can be retrieved by the
lookup operation:
Embed(t) = Le
k
(5)
where e
k
? R
|T |?1
is a binary vector which is
zero in all positions except at k-th index. The tag
embeddings start from a random initialization and
can be automatically trained by back-propagation.
Figure 2 shows the new Lookup Table layer with
tag embeddings. Assuming we are at the i-th char-
acter of a sentence, besides the character embed-
dings, the tag embeddings of the previous tags are
also considered
1
. For a fast tag inference, only
the previous tag t
i?1
is used in our model even
though a longer history of tags can be considered.
The concatenation operation in Layer 1 then con-
catenates the character embeddings and tag em-
bedding together into a long vector a. In this way,
the tag representation can be directly incorporated
in the neural network so that the tag-tag interac-
tion and tag-character interaction can be explicitly
modeled in deeper layers (See Section 3.2). More-
over, the transition score in equation (4) is not
necessary in our model, because, by incorporating
tag embedding into the neural network, the effect
of tag-tag interaction and tag-character interaction
are covered uniformly in one same model. Now
1
We also tried the architecture in which the tag embedding
of current tag is also considered, but this did not bring much
improvement and runs slower
Figure 3: The tensor-based transformation in
Layer 2. a is the input from Layer 1. V is the
tensor parameter. Each dashed box represents one
of the H
2
-many tensor slices, which defines the
bilinear form on vector a.
equation (4) can be rewritten as follows:
s(c
[1:n]
, t
[1:n]
, ?) =
n
?
i=1
f
?
(t
i
|c
[i?2:i+2]
, t
i?1
)
(6)
where f
?
(t
i
|c
[i?2:i+2]
, t
i?1
) is the score output for
tag t
i
at the i-th character by the network with pa-
rameters ?. Like Collobert et al (2011) and Zheng
et al (2013), our model is also trained at sentence-
level and carries out inference globally.
3.2 Tensor Neural Network
A tensor is a geometric object that describes rela-
tions between vectors, scalars, and other tensors.
It can be represented as a multi-dimensional array
of numerical values. An advantage of the tensor
is that it can explicitly model multiple interactions
in data. As a result, tensor-based model have been
widely used in a variety of tasks (Salakhutdinov et
al., 2007; Krizhevsky et al, 2010; Socher et al,
2013b).
In Chinese word segmentation, a proper model-
ing of the tag-tag interaction, tag-character inter-
action and character-character interaction is very
important. In linear models, these kinds of inter-
actions are usually modeled as features. In con-
ventional neural network models, however, the in-
put embeddings only implicitly interact through
the non-linear function which can hardly model
the complexity of the interactions. Given the ad-
vantage of tensors, we apply a tensor-based trans-
formation to the input vector. Formally, we use a
3-way tensor V
[1:H
2
]
? R
H
2
?H
1
?H
1
to directly
model the interactions, where H
2
is the size of
296
Layer 2 and H
1
= (w + 1) ? d is the size of con-
catenated vector a in Layer 1 as shown in Figure
2. Figure 3 gives an example of the tensor-based
transformation
2
. The output of a tensor product is
a vector z ? R
H
2
where each dimension z
i
is the
result of the bilinear form defined by each tensor
slice V
[i]
? R
H
1
?H
1
:
z = a
T
V
[1:H
2
]
a; z
i
= a
T
V
[i]
a =
?
j,k
V
[i]
jk
a
j
a
k
(7)
Since vector a is the concatenation of character
embeddings and the tag embedding, equation (7)
can be written in the following form:
z
i
=
?
p,q
?
j,k
V
[i]
(p,q,j,k)
E
[p]
j
E
[q]
k
where E
[p]
j
is the j-th element of the p-th embed-
ding in Lookup Table layer and V
[i]
(p,q,j,k)
is the cor-
responding coefficient for E
[p]
j
and E
[q]
k
in V
[i]
.
As we can see, in each tensor slice i, the em-
beddings are explicitly related in a bilinear form
which captures the interactions between charac-
ters and tags. The multiplicative operations be-
tween tag embeddings and character embeddings
can somehow be seen as ?feature combination?,
which are hand-designed in feature-based models.
Our model learns the information automatically
and encodes them in tensor parameters and em-
beddings. Intuitively, we can interpret each slice
of the tensor as capturing a specific type of tag-
character interaction and character-character inter-
action.
Combining the tensor product with linear trans-
formation, the tensor-based transformation in
Layer 2 is defined as:
h = g(a
T
V
[1:H
2
]
a+W
1
a+ b
1
) (8)
where W
1
? R
H
2
?H
1
, b
1
? R
H
2
?1
, h ? R
H
2
.
In fact, equation (2) used in previous work is a
special case of equation (8) when V is set to 0.
3.3 Tensor Factorization
Despite tensor-based transformation being effec-
tive for capturing the interactions, introducing
tensor-based transformation into neural network
models to solve sequence labeling task is time pro-
hibitive since the tensor product operation drasti-
cally slows down the model. Without consider-
ing matrix optimization algorithms, the complex-
ity of the non-linear transformation in equation (2)
2
The bias term is omitted in Figure 3 for simplicity
Figure 4: Tensor product with tensor factorization
is O(H
1
H
2
) while the tensor operation complex-
ity in equation (8) is O(H
2
1
H
2
). The tensor-based
transformation is H
1
times slower. Moreover, the
additional tensor could bring millions of param-
eters to the model which makes the model suf-
fer from the risk of overfitting. To remedy this,
we propose a tensor factorization approach that
factorizes each tensor slice as the product of two
low-rank matrices. Formally, each tensor slice
V
[i]
? R
H
1
?H
1
is factorized into two low rank
matrix P
[i]
? R
H
1
?r
and Q
[i]
? R
r?H
1
:
V
[i]
= P
[i]
Q
[i]
, 1 ? i ? H
2
(9)
where r  H
1
is the number of factors. Substi-
tuting equation (9) into equation (8), we get the
factorized tensor function:
h = g(a
T
P
[1:H
2
]
Q
[1:H
2
]
a+W
1
a+ b
1
) (10)
Figure 4 illustrates the operation in each slice of
the factorized tensor. First, vector a is projected
into two r-dimension vectors f
1
and f
2
. Then the
output z
i
for each tensor slice i is the dot-product
of f
1
and f
2
. The complexity of the tensor op-
eration is now O(rH
1
H
2
). As long as r is small
enough, the factorized tensor operation would be
much faster than the un-factorized one and the
number of free parameters would also be much
smaller, which prevent the model from overfitting.
3.4 Max-Margin Training
We use the Max-Margin criterion to train our
model. Intuitively, the Max-Margin criterion pro-
vides an alternative to probabilistic, likelihood-
based estimation methods by concentrating di-
rectly on the robustness of the decision boundary
of a model (Taskar et al, 2005). We use Y (x
i
)
to denote the set of all possible tag sequences for
297
a given sentence x
i
and the correct tag sequence
for x
i
is y
i
. The parameters of our model are
? = {W
1
, b
1
,W
2
, b
2
,M,L, P
[1:H
2
]
, Q
[1:H
2
]
}. We
first define a structured margin loss 4(y
i
, y?) for
predicting a tag sequence y? for a given correct tag
sequence y
i
:
4(y
i
, y?) =
n
?
j
?1{y
i,j
6= y?
j
} (11)
where n is the length of sentence x
i
and ? is a dis-
count parameter. The loss is proportional to the
number of characters with an incorrect tag in the
proposed tag sequence, which increases the more
incorrect the proposed tag sequence is. For a given
training instance (x
i
, y
i
), we search for the tag se-
quence with the highest score:
y
?
= argmax
y??Y (x)
s(x
i
, y?, ?) (12)
where the tag sequence is found and scored by the
Tensor Neural Network via the function s in equa-
tion (6). The object of Max-Margin training is that
the highest scoring tag sequence is the correct one:
y
?
= y
i
and its score will be larger up to a margin
to other possible tag sequences y? ? Y (x
i
):
s(x, y
i
, ?) ? s(x, y?, ?) +4(y
i
, y?)
This leads to the regularized objective function for
m training examples:
J(?) =
1
m
m
?
i=1
l
i
(?) +
?
2
||?||
2
l
i
(?) = max
y??Y (x
i
)
(s(x
i
, y?, ?) +4(y
i
, y?))
?s(x
i
, y
i
, ?)) (13)
By minimizing this object, the score of the correct
tag sequence y
i
is increased and score of the high-
est scoring incorrect tag sequence y? is decreased.
The objective function is not differentiable due
to the hinge loss. We use a generalization of gra-
dient descent called subgradient method (Ratliff et
al., 2007) which computes a gradient-like direc-
tion. The subgradient of equation (13) is:
?J
??
=
1
m
?
i
(
?s(x
i
, y?
max
, ?)
??
?
?s(x
i
, y
i
, ?)
??
)+??
where y?
max
is the tag sequence with the highest
score in equation (13). Following Socher et al
(2013a), we use the diagonal variant of AdaGrad
PKU MSRA
Identical words 5.5? 10
4
8.8? 10
4
Total words 1.1? 10
6
2.4? 10
6
Identical characters 5? 10
3
5? 10
3
Total characters 1.8? 10
6
4.1? 10
6
Table 1: Details of the PKU and MSRA datasets
Window size w = 5
Character(tag) embedding size d = 25
Hidden unit number H
2
= 50
Number of factors r = 10
Initial learning rate ? = 0.2
Margin loss discount ? = 0.2
Regularization ? = 10
?4
Table 2: Hyperparameters of our model
(Duchi et al, 2011) with minibatchs to minimize
the objective. The parameter update for the i-th
parameter ?
t,i
at time step t is as follows:
?
t,i
= ?
t?1,i
?
?
?
?
t
?=1
g
2
?,i
g
t,i
(14)
where ? is the initial learning rate and g
?
? R
|?
i
|
is the subgradient at time step ? for parameter ?
i
.
4 Experiment
4.1 Data and Model Selection
We use the PKU and MSRA data provided by the
second International Chinese Word Segmentation
Bakeoff (Emerson, 2005) to test our model. They
are commonly used by previous state-of-the-art
models and neural network models. Details of the
data are listed in Table 1. For evaluation, we use
the standard bake-off scoring program to calculate
precision, recall, F1-score and out-of-vocabulary
(OOV) word recall.
For model selection, we use the first 90% sen-
tences in the training data for training and the rest
10% sentences as development data. The mini-
batch size is set to 20. Generally, the number of
hidden units has a limited impact on the perfor-
mance as long as it is large enough. We found
that 50 is a good trade-off between speed and
model performance. The dimensionality of char-
acter (tag) embedding is set to 25 which achieved
the best performance and faster than 50- or 100-
dimensional ones. We also validated on the num-
ber of factors for tensor factorization. The per-
formance is not boosted and the training time in-
298
P R F OOV
CRF 87.8 85.7 86.7 57.1
NN 92.4 92.2 92.3 60.0
NN+Tag Embed 93.0 92.7 92.9 61.0
MMTNN 93.7 93.4 93.5 64.2
Table 3: Test results with different configurations.
NN stands for the conventional neural network.
NN+Tag Embed stands for the neural network
with tag embeddings.
creases drastically when the number of factors is
larger than 10. We hypothesize that larger factor
size results in too many parameters to train and
hence perform worse. The final hyperparameters
of our model are set as in Table 2.
4.2 Experiment Results
We first perform a close test
3
on the PKU dataset
to show the effect of different model configura-
tions. We also compare our model with the CRF
model (Lafferty et al, 2001), which is a widely
used log-linear model for Chinese word segmen-
tation. The input feature to the CRF model is sim-
ply the context characters (unigram feature) with-
out any additional feature engineering. We use
an open source toolkit CRF++
4
to train the CRF
model. All the neural networks are trained us-
ing the Max-Margin approach described in Sec-
tion 3.4. Table 3 summarizes the test results.
As we can see, by using Tag embedding, the F-
score is improved by +0.6% and OOV recall is
improved by +1.0%, which shows that tag embed-
dings succeed in modeling the tag-tag interaction
and tag-character interaction. Model performance
is further boosted after using tensor-based trans-
formation. The F-score is improved by +0.6%
while OOV recall is improved by +3.2%, which
denotes that tensor-based transformation captures
more interactional information than simple non-
linear transformation.
Another important result in Table 3 is that our
neural network models perform much better than
CRF-based model when only unigram features are
used. Compared with CRF, there are two differ-
ences in neural network models. First, the discrete
feature vector is replaced with dense character em-
beddings. Second, the non-linear transformation
3
No other material or knowledge except the training data
is allowed
4
http://crfpp.googlecode.com/svn/
trunk/doc/index.html?source=navbar
?(one) ?(Li) ?(period)
?(two) ?(Zhao) ?(comma)
?(three) ?(Jiang) ?(colon)
?(four) ?(Kong) ?(question mark)
?(five) ?(Feng) ?(quotation mark)
?(six) ?(Wu) ?(Chinese comma)
Table 4: Examples of character embeddings
is used to discover higher level representation. In
fact, CRF can be regarded as a special neural net-
work without non-linear function (Wang and Man-
ning, 2013). Wang and Manning (2013) conduct
an empirical study on the effect of non-linearity
and the results suggest that non-linear models are
highly effective only when distributed representa-
tion is used. To explain why distributed represen-
tation captures more information than discrete fea-
tures, we show in Table 4 the effect of character
embeddings which are obtained from the lookup
table of MMTNN after training. The first row lists
three characters we are interested in. In each col-
umn, we list the top 5 characters that are near-
est (measured by Euclidean distance) to the cor-
responding character in the first row according to
their embeddings. As we can see, characters in
the first column are all Chinese number characters
and characters in the second column and the third
column are all Chinese family names and Chinese
punctuations respectively. Therefore, compared
with discrete feature representations, distributed
representation can capture the syntactic and se-
mantic similarity between characters. As a re-
sult, the model can still perform well even if some
words do not appear in the training cases.
We further compare our model with previous
neural network models on both PKU and MSRA
datasets. Since Zheng et al (2013) did not
report the results on the these datasets, we re-
implemented their model and tested it on the test
data. The results are listed in the first three rows
of Table 5, which shows that our model achieved
higher F-score than the previous neural network
models.
4.3 Unsupervised Pre-training
Previous work found that the performance can
be improved by pre-training the character em-
beddings on large unlabeled data and using the
obtained embeddings to initialize the charac-
ter lookup table instead of random initialization
299
Models PKU MSRA
P R F OOV P R F OOV
(Mansur et al, 2013) 87.1 87.9 87.5 48.9 92.3 92.2 92.2 53.7
(Zheng et al, 2013) 92.8 92.0 92.4 63.3 92.9 93.6 93.3 55.7
MMTNN 93.7 93.4 93.5 64.2 94.6 94.2 94.4 61.4
(Mansur et al, 2013) + Pre-training 91.2 92.7 92.0 68.8 93.1 93.1 93.1 59.7
(Zheng et al, 2013) + Pre-training 93.5 92.2 92.8 69.0 94.2 93.7 93.9 64.1
MMTNN + Pre-training 94.4 93.6 94.0 69.0 95.2 94.6 94.9 64.8
Table 5: Comparison with previous neural network models
(Mansur et al, 2013; Zheng et al, 2013). Mikolov
et al (2013b) show that pre-trained embeddings
can capture interesting semantic and syntactic in-
formation such as king?man+woman ? queen
on English data. There are several ways to learn
the embeddings on unlabeled data. Mansur et al
(2013) used the model proposed by Bengio et al
(2003) which learns the embeddings based on neu-
ral language model. Zheng et al (2013) followed
the model proposed by Collobert et al (2008).
They constructed a neural network that outputs
high scores for windows that occur in the cor-
pus and low scores for windows where one char-
acter is replaced by a random one. Mikolov et
al. (2013a) proposed a faster skip-gram model
word2vec
5
which tries to maximize classification
of a word based on another word in the same sen-
tence. In this paper, we use word2vec because pre-
liminary experiments did not show differences be-
tween performances of these models but word2vec
is much faster to train. We pre-train the embed-
dings on the Chinese Giga-word corpus (Graff and
Chen, 2005). As shown in Table 5 (last three
rows), both the F-score and OOV recall of our
model boost by using pre-training. Our model still
outperforms other models after pre-training.
4.4 Minimal Feature Engineering
Although we focus on the question that how far we
can go without using feature engineering in this
paper, the study of deep learning for NLP tasks
is still a new area in which it is currently chal-
lenging to surpass the state-of-the-art without ad-
ditional features. To incorporate features into the
neural network, Mansur et al (2013) proposed
the feature-based neural network where each con-
text feature is represented as feature embeddings.
The idea of feature embeddings is similar to that
of character embeddings described in section 2.1.
5
https://code.google.com/p/word2vec/
Model PKU MSRA
Best05(Chen et al, 2005) 95.0 96.0
Best05(Tseng et al, 2005) 95.0 96.4
(Zhang et al, 2006) 95.1 97.1
(Zhang and Clark, 2007) 94.5 97.2
(Sun et al, 2009) 95.2 97.3
(Sun et al, 2012) 95.4 97.4
(Zhang et al, 2013) 96.1 97.4
MMTNN 94.0 94.9
MMTNN + bigram 95.2 97.2
Table 6: Comparison with state-of-the-art systems
Formally, we assume the extracted features form a
feature dictionary D
f
. Then each feature f ? D
f
is represented by a d-dimensional vector which is
called feature embedding. Following their idea,
we try to find out how well our model can perform
with minimal feature engineering.
A very common feature in Chinese word seg-
mentation is the character bigram feature. For-
mally, at the i-th character of a sentence c
[1:n]
, the
bigram features are c
k
c
k+1
(i ? 3 < k < i + 2).
In our model, the bigram features are extracted in
the window context and then the corresponding
bigram embeddings are concatenated with char-
acter embeddings in Layer 1 and fed into Layer
2. In Mansur et al (2013), the bigram embed-
dings are pre-trained on unlabeled data with char-
acter embeddings, which significantly improves
the model performance. Given the long time for
pre-training bigram embeddings, we only pre-train
the character embeddings and the bigram embed-
dings are initialized as the average of character
embeddings of c
k
and c
k+1
. Further improve-
ment could be obtained if the bigram embeddings
are also pre-trained. Table 6 lists the segmenta-
tion performances of our model as well as pre-
vious state-of-the-art systems. When bigram fea-
tures are added, the F-score of our model improves
300
from 94.0% to 95.2% on PKU dataset and from
94.9% to 97.2% on MSRA dataset. It is a com-
petitive result given that our model only use sim-
ple bigram features while other models use more
complex features. For example, Sun et al (2012)
uses additional word-based features. Zhang et al
(2013) uses eight types of features such as Mu-
tual Information and Accessor Variety and they
extract dynamic statistical features from both an
in-domain corpus and an out-of-domain corpus us-
ing co-training. Since feature engineering is not
the main focus of this paper, we did not experi-
ment with more features.
5 Related Work
Chinese word segmentation has been studied with
considerable efforts in the NLP community. The
most popular approach treats word segmentation
as a sequence labeling problem which was first
proposed in Xue (2003). Most previous systems
address this task by using linear statistical mod-
els with carefully designed features such as bi-
gram features, punctuation information (Li and
Sun, 2009) and statistical information (Sun and
Xu, 2011). Recently, researchers have tended to
explore new approaches for word segmentation
which circumvent the feature engineering by au-
tomatically learning features with neural network
models (Mansur et al, 2013; Zheng et al, 2013).
Our study is consistent with this line of research,
however, our model explicitly models the interac-
tions between tags and context characters and ac-
cordingly captures more semantic information.
Tensor-based transformation was also used in
other neural network models for its ability to cap-
ture multiple interactions in data. For example,
Socher et al (2013b) exploited tensor-based func-
tion in the task of Sentiment Analysis to cap-
ture more semantic information from constituents.
However, given the small size of their tensor ma-
trix, they do not have the problem of high time
cost and overfitting problem as we faced in mod-
eling a sequence labeling task like Chinese word
segmentation. That?s why we propose to decrease
computational cost and avoid overfitting with ten-
sor factorization.
Various tensor factorization (decomposition)
methods have been proposed recently for tensor-
based dimension reduction (Cohen et al, 2013;
Van de Cruys et al, 2013; Chang et al, 2013).
For example, Chang et al (2013) proposed the
Multi-Relational Latent Semantic Analysis. Sim-
ilar to LSA, a low rank approximation of the ten-
sor is derived using a tensor decomposition ap-
proch. Similar ideas were also used for collab-
orative filtering (Salakhutdinov et al, 2007) and
object recognition (Ranzato et al, 2010). Our ten-
sor factorization is related to these work but uses
a different tensor factorization approach. By in-
troducing tensor factorization into the neural net-
work model for sequence labeling tasks, the model
training and inference are speeded up and overfit-
ting is prevented.
6 Conclusion
In this paper, we propose a new model called Max-
Margin Tensor Neural Network that explicitly
models the interactions between tags and context
characters. Moreover, we propose a tensor fac-
torization approach that effectively improves the
model efficiency and avoids the risk of overfitting.
Experiments on the benchmark datasets show that
our model achieve better results than previous neu-
ral network models and that our model can achieve
a competitive result with minimal feature engi-
neering. In the future, we plan to further extend
our model and apply it to other structure predic-
tion problems.
Acknowledgments
This work is supported by National Natural
Science Foundation of China under Grant No.
61273318 and National Key Basic Research Pro-
gram of China 2014CB340504.
References
Yoshua Bengio, R?ejean Ducharme, Pascal Vincent, and
Christian Jauvin. 2003. A neural probabilistic lan-
guage model. Journal of Machine Learning Re-
search, 3:1137?1155.
Kai-Wei Chang, Wen-tau Yih, and Christopher Meek.
2013. Multi-relational latent semantic analysis. In
Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing, pages
1602?1612, Seattle, Washington, USA, October.
Association for Computational Linguistics.
Aitao Chen, Yiping Zhou, Anne Zhang, and Gordon
Sun. 2005. Unigram language model for chi-
nese word segmentation. In Proceedings of the 4th
SIGHAN Workshop on Chinese Language Process-
ing, pages 138?141. Association for Computational
Linguistics Jeju Island, Korea.
301
Shay B Cohen, Giorgio Satta, and Michael Collins.
2013. Approximate pcfg parsing using tensor de-
composition. In Proceedings of NAACL-HLT, pages
487?496.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and exper-
iments with perceptron algorithms. In Proceedings
of the ACL-02 conference on Empirical methods in
natural language processing-Volume 10, pages 1?8.
Association for Computational Linguistics.
Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: Deep
neural networks with multitask learning. In Pro-
ceedings of the 25th international conference on
Machine learning, pages 160?167. ACM.
Ronan Collobert, Jason Weston, L?eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. The Journal of Machine Learning Re-
search, 12:2493?2537.
John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. The Journal of Ma-
chine Learning Research, 999999:2121?2159.
Thomas Emerson. 2005. The second international chi-
nese word segmentation bakeoff. In Proceedings of
the Fourth SIGHAN Workshop on Chinese Language
Processing, volume 133.
David Graff and Ke Chen. 2005. Chinese gigaword.
LDC Catalog No.: LDC2003T09, ISBN, 1:58563?
230.
Geoffrey E Hinton. 1986. Learning distributed repre-
sentations of concepts. In Proceedings of the eighth
annual conference of the cognitive science society,
pages 1?12. Amherst, MA.
Alex Krizhevsky, Geoffrey E Hinton, et al 2010. Fac-
tored 3-way restricted boltzmann machines for mod-
eling natural images. In International Conference
on Artificial Intelligence and Statistics, pages 621?
628.
John Lafferty, Andrew McCallum, and Fernando CN
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data.
Zhongguo Li and Maosong Sun. 2009. Punctuation as
implicit annotations for chinese word segmentation.
Computational Linguistics, 35(4):505?512.
Mairgup Mansur, Wenzhe Pei, and Baobao Chang.
2013. Feature-based neural language model and
chinese word segmentation. In Proceedings of
the Sixth International Joint Conference on Natural
Language Processing.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013a. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013b. Linguistic regularities in continuous space
word representations. In Proceedings of NAACL-
HLT, pages 746?751.
Marc?Aurelio Ranzato, Alex Krizhevsky, and Geof-
frey E Hinton. 2010. Factored 3-way restricted
boltzmann machines for modeling natural images.
Nathan D Ratliff, J Andrew Bagnell, and Martin A
Zinkevich. 2007. (online) subgradient methods for
structured prediction.
Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey
Hinton. 2007. Restricted boltzmann machines for
collaborative filtering. In Proceedings of the 24th in-
ternational conference on Machine learning, pages
791?798. ACM.
Holger Schwenk, Anthony Rousseau, and Mohammed
Attik. 2012. Large, pruned or continuous space
language models on a gpu for statistical machine
translation. In Proceedings of the NAACL-HLT 2012
Workshop: Will We Ever Really Replace the N-gram
Model? On the Future of Language Modeling for
HLT, pages 11?19. Association for Computational
Linguistics.
Richard Socher, John Bauer, Christopher D Manning,
and Andrew Y Ng. 2013a. Parsing with composi-
tional vector grammars. In Annual Meeting of the
Association for Computational Linguistics (ACL).
Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. 2013b. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. EMNLP.
Weiwei Sun and Jia Xu. 2011. Enhancing chinese
word segmentation using unlabeled data. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 970?979. As-
sociation for Computational Linguistics.
Xu Sun, Yaozhong Zhang, Takuya Matsuzaki, Yoshi-
masa Tsuruoka, and Jun?ichi Tsujii. 2009. A dis-
criminative latent variable chinese segmenter with
hybrid word/character information. In Proceedings
of Human Language Technologies: The 2009 An-
nual Conference of the North American Chapter
of the Association for Computational Linguistics,
pages 56?64. Association for Computational Lin-
guistics.
Xu Sun, Houfeng Wang, and Wenjie Li. 2012. Fast on-
line training with frequency-adaptive learning rates
for chinese word segmentation and new word detec-
tion. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 253?262, Jeju Island,
302
Korea, July. Association for Computational Linguis-
tics.
Ben Taskar, Vassil Chatalbashev, Daphne Koller, and
Carlos Guestrin. 2005. Learning structured predic-
tion models: A large margin approach. In Proceed-
ings of the 22nd international conference on Ma-
chine learning, pages 896?903. ACM.
Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel
Jurafsky, and Christopher Manning. 2005. A condi-
tional random field word segmenter for sighan bake-
off 2005. In Proceedings of the Fourth SIGHAN
Workshop on Chinese Language Processing, volume
171.
Tim Van de Cruys, Thierry Poibeau, and Anna Ko-
rhonen. 2013. A tensor-based factorization model
of semantic compositionality. In Proceedings of
NAACL-HLT, pages 1142?1151.
Mengqiu Wang and Christopher D Manning. 2013.
Effect of non-linear deep architecture in sequence
labeling. In Proceedings of the Sixth International
Joint Conference on Natural Language Processing.
Nianwen Xue. 2003. Chinese word segmentation as
character tagging. Computational Linguistics and
Chinese Language Processing, 8(1):29?48.
Yue Zhang and Stephen Clark. 2007. Chinese seg-
mentation with a word-based perceptron algorithm.
In ANNUAL MEETING-ASSOCIATION FOR COM-
PUTATIONAL LINGUISTICS, volume 45, page 840.
Ruiqiang Zhang, Genichiro Kikui, and Eiichiro
Sumita. 2006. Subword-based tagging by condi-
tional random fields for chinese word segmentation.
In Proceedings of the Human Language Technol-
ogy Conference of the NAACL, Companion Volume:
Short Papers, pages 193?196. Association for Com-
putational Linguistics.
Longkai Zhang, Houfeng Wang, Xu Sun, and Mairgup
Mansur. 2013. Exploring representations from un-
labeled data with co-training for Chinese word seg-
mentation. In Proceedings of the 2013 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 311?321, Seattle, Washington, USA,
October. Association for Computational Linguistics.
Xiaoqing Zheng, Hanyang Chen, and Tianyu Xu.
2013. Deep learning for Chinese word segmenta-
tion and POS tagging. In Proceedings of the 2013
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 647?657, Seattle, Wash-
ington, USA, October. Association for Computa-
tional Linguistics.
303
