Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 48?51,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Annotation of Events and Temporal Expressions in French Texts
Andre? Bittar
Universite? Paris Diderot ? ALPAGE
30 rue du Cha?teau des Rentiers
75013 Paris
France
andre.bittar@linguist.jussieu.fr
Abstract
We present two modules for the recogni-
tion and annotation of temporal expres-
sions and events in French texts accord-
ing to the TimeML specification language.
The Temporal Expression Tagger we have
developed is based on a large coverage
cascade of finite state transducers and our
Event Tagger on a set of simple heuris-
tics applied over local context in a chunked
text. We present results of a preliminary
evaluation and compare them with those
obtained by a similar system.
1 Introduction
TimeML (Pustejovsky et al, 2003) is a specifica-
tion language for the annotation and normaliza-
tion of temporal information in natural language
texts. The annotation scheme allows for the anno-
tation of events (<EVENT>), the tagging of temporal
expressions and the normalization of their values
(<TIMEX3>), as well as the annotation of tempo-
ral, aspectual and subordinating relations which
may exist among them (<TLINK>, <ALINK> and
<SLINK>, respectively). The linguistic markers of
these relations can also be marked up (<SIGNAL>).
A set of resources, including automatic and man-
ual annotation tools and several reference corpora
have been developed around the TimeML lan-
guage. Evita (Saur?? et al, 2005) is an applica-
tion for automatically recognizing and annotating
events in texts, based primarily on symbolic meth-
ods and linguistic data (input is a chunked text),
although with some integration of statistical data.
Its creators report precision of 74.03% and recall
of 87.31% for an overall F-score of 80.12% for
the task of event identification. GUTime (Mani
and Wilson, 2000) annotates temporal expressions
according to the TimeML schema and normalizes
their values. The system achieves F-scores of 85%
and 82% for identification and normalization of
temporal expressions, respectively. Further infor-
mation is available on the TimeML project web-
site1.
2 A System for TimeML Annotation in
French
(Parent et al, 2008) provide the description and
evaluation of a system for the TimeML annota-
tion of events and temporal expressions in French
texts. The processing of temporal expressions is
carried out on a text having undergone a part-of-
speech tagging, morphological analysis and shal-
low syntactic analysis. The system functions by
application of a cascade of 90 rules applied over
20 levels. Contrary to the Evita system developed
for English, the event detection module relies on a
full dependency parse as input for the event recog-
nition task. The authors claim an advantage over
chunker-based approaches with respect to the an-
notation of markable adjectives due to the fact that
the dependency relation between copula verb and
predicative adjective is available. The authors pro-
vide evaluation results according to grammatical
category over a development corpus, made up of
35 biographical texts and 22 sports articles, and an
evaluation (?unseen?) corpus, consisting of an un-
specified number of news articles from the website
of the E?cole Polytechnique de Montre?al. The eval-
uation results, by grammatical category and global
figures, are given in Table 1.
Development corpus Evaluation corpus
Cat Prec Rec F-sc Prec Rec F-sc
Noun 61.5 40.0 48.4 54.7 53.7 54.2
Verb 94.1 97.3 95.7 65.6 90.9 76.2
Adj 66.7 77.8 71.8 N/A N/A N/A
Global 86.8 80.6 83.5 62.5 77.7 69.3
Table 1: Evaluation results according to corpora
The system performs best on the annotation of
1http://www.timeml.org
48
event verbs and encounters the most difficulties
in the annotation of event nominals. Adjectives
are relatively well processed over the development
corpus, but no adjectives were annotated by the
human annotator in the evaluation corpus, so no
results were calculated. As for the annotation of
temporal expressions, precision is 83% and recall
79%, for an F-score of 81% over an evaluation cor-
pus containing 544 human-annotated temporal ex-
pressions and an F-score of 50% for the normal-
ization of values. These figures are comparable to
those cited for GUTime for English.
3 Annotation Modules
In this section, we describe an annotation system,
similar to that of (Parent et al, 2008) described
above, although based on a rich cascade of finite
state transducers and a shallow syntactic analysis,
as opposed to a full dependency parse. The sys-
tem is made up principally of two modules, the
first tagging temporal expressions (section 3.1),
the second identifying and annotating event ex-
pressions (section 3.2).
3.1 Temporal Expression Tagger
This module carries out the tagging and nor-
malization of temporal expressions. The mod-
ule consists of a large-coverage set of finiste
state transducers developed with the Unitex2 cor-
pus processor. The transducers in this large-
coverage grammar, applied to raw text, recognize
patterns of dates, times, duration and frequency
and tag expressions with the appropriately typed
<TIMEX3>. A transducer matching expressions not
to be marked up was also created. This trans-
ducer tags with the label <GARBAGE> expressions
such as phone numbers, which could otherwise
match numerical dates. The ambiguous word e?te?
(been/summer), when preceded by an adverb or
the auxiliary verb avoir is tagged as <GARBAGE>,
as it has its verb rather than noun reading in this
context. Other expressions tagged as <GARBAGE>
include the common expression les 35 heures (the
French 35 hour week) and names of streets con-
taining a date, such as la place du 13 Mai, etc.
The normalization script, written in Perl, calcu-
lates the standard values of temporal expressions,
including underspecified deictic expressions, and
2Unitex is a graphical corpus processing program, avail-
able for download under GNU General Public Licence at
http://www-igm.univ-mlv.fr/? unitex/
removes annotations on items marked <GARBAGE>.
The script consists of a set of substitution func-
tions for each type of temporal expression tagged
by the transducers. Each function converts the
content of the expression into a TimeML stan-
dard value and inserts it in the value attribute
of each <TIMEX3> tag. This module is available
for download at http://www.linguist.univ-paris-
diderot.fr/? abittar. This approach differs from that
of (Parent et al, 2008) in that it relies almost en-
tirely on lexical processing.
An evaluation was carried out on a subset of the
corpus used to evaluate the similar module de-
scribed in section 2. Our corpus consists of the 45
news articles from the Agence France Press used
in the training and test sets described by (Parent
et al, 2008). Figures for the evaluation are given
in Table 2. The column labeled ?Loose? repre-
sents the number of matches which cover an in-
complete span of the expression, for example un
mois (one month) instead of un mois et demi (a
month and a half ). The column ?Strict? is for ex-
act matches. The ?Value? column represents the
correctly normalized values for the temporal ex-
pressions detected, calculated over strict matches.
Human Found Loose Strict Value
Number 592 575 508 484 317
Precision - - 85.8 84.2 55.0
Recall - - 88.4 81.8 44.9
F-score - - 87.1 83.0 49.4
Table 2: Evaluation results for the Temporal Ex-
pression Tagger
These figures are much in line with those of
the system described in (Parent et al, 2008).
Performance is slightly lower on loose matches
(F-score 87.1 versus 91.0), but we achieve better
results on strict matches (F-score 83.0 versus
81.0). This could be explained by the fact that we
did not develop our grammar on the same type
of source text, but shows that the grammar has
a good coverage of the variants of each type of
expression.
Sources of noise include age values tagged as
durations, e.g. M. Dupont, 58 ans (Mr. Dupont, 58
years old) (11 errors), and numerical values taken
to be years, e.g. l?aste?ro??de 2001 UU92 (Asteroid
2001 UU92) (8 errors). Silence occurs mostly
on coordinated date expressions or sequences,
e.g. les 4, 5 et 6 fe?vrier (the 4th, 5th and 6th
of February) (11 errors) or expressions taking a
49
?vague? normalized value, e.g. dans le passe? (in
the past) (15 errors).
Results for the normalization of values for tem-
poral expressions are practically identical to the
other system for French. The majority of errors
produced by our system (97 out of 167) are due
to the fact that our normalization script does not
yet fully deal with underspecified weekday ex-
pressions, such as jeudi soir (Thursday evening).
In the hand-annotated corpus these expressions
are fully resolved, with year, month and day
values specified, e.g. 2002-01-15TEV, whereas
we provide a correct, but not completely resolved
value, which specifies the day of the week, e.g.
2002-WXX-4TEV. Excluding this difference in
processing boosts precision to 73.6 and recall
to 60.1 (F-score 66.85) for the normalization
of values. We are currently working on fully
normalizing these values.
3.2 Event Tagger
This module tags event expressions with the
<EVENT> tag and classifies the events according
to the ontology defined for TimeML. It also de-
tects negative polarity contexts, as well as any as-
pectual or modal properties of certain verbal con-
structions. Input is a text having undergone part-
of-speech tagging, an inflectional morphological
analysis and shallow syntactic analysis, carried
out by Macaon, a modular processing pipeline for
French3. The Event tagger consists of several lev-
els of processing - a layer of lexical processing, ba-
sically a lexical lookup for nouns and verb classes,
and a layer of contextual processing consisting
in the application of heuristics for detecting and
eliminating event candidates and classifying them.
This module relies on certain lexical resources.
For the detection of event nominals, a lexicon con-
taining nouns with at least one event interpretation
is used. Many of the entries in this lexicon are am-
biguous as they may also have a non-event inter-
pretation. For example, repas (meal) has an object
interpretation as well as an event reading. This
highlights the need for disambiguation of nomi-
nals. The noun lexicon is based on the VerbAc-
tion lexicon (Hathout et al, 2002) which provided
9 200 unique deverbal noun lemmas. We fur-
ther enriched the lexicon through semi-automated
3Macaon is freely available for download at
http://pageperso.lif.univ-mrs.fr/? alexis.nasr/macaon/.
search engine queries, such as X a eu lieu (X took
place) and lors du/de la/des X (during the X),
where X is likely to be an event nominal. An ini-
tial application of this method yielded 769 unique
noun lemmas which were not in VerbAction -
mostly rare or non-deverbal nouns, such as antico-
agulothe?rapie (anticoagulation therapy) and an-
niversaire (birthday). The noun lexicon is of com-
parable size to that used in Evita.
We created by hand a verb lexicon which is used to
perform classification of verbal events. It contains
200 lemmas for verbs in 6 of the 7 TimeML event
classes4. Verbs were initially added to the lexi-
con by translating those proposed in the TimeML
classifcation for English. The list of verbs was en-
riched by querying the dictionary of synonyms at
the Universite? de Caen5. The lexicon is small for
the time being and will need to be increased to en-
sure better coverage for classification. Like the
noun lexicon, the lexicon of verbs contains am-
biguities as certain verbs may belong to different
classes or may not have an event reading in cer-
tain contexts. For example, the verb expliquer (to
explain) belongs to the class REPORTING when it
introduces a complementizer phrase in que (that)
headed by an event (Max a explique? qu?il avait
commis une erreur - Maca explained that he had
made a mistake). This is the class attributed by
the lexicon. However, when it has a human sub-
ject and an event in object position (Le manager a
explique? le renouvellemetn de l?e?quipe - the man-
ager explained the renewal of the team), it must be
annotated with the class I ACTION. Finally, if this
verb has events in both subject and object position
(Le re?chauffement climatique explique la fonte des
calottes glacie`res - global warming explains the
melting of the ice caps), it is to be annotated with
the class CAUSE. The system is thus confronted
with the non-trivial problem of word sense disam-
biguation to identify the correct readings of nouns
and verbs in the text. Initially, we tackle this prob-
lem for verbs with a number of heuristics, applied
to local chunk context, for each of the TimeML
verb classes in the lexicon. A total of 16 heuristics
are used for choosing candidates for markup with
the <EVENT> tag and 30 heuristics for classifying
the events and determining values for the aspect,
modality and polarity attributes. For example,
in the case of the verb expliquer given above, the
4As the class OCCURRENCE is the default class, it has no
entries in the lexicon
5http://www.crisco.unicaen.fr/cgi-bin/cherches.cgi
50
heuristics include a search for the complementizer
que in the chunk after the verb and a search for
an event nominal chunk directly to the left of the
verb chunk (approximation of subject position).
Further heuristics are used to eliminate verbs and
nouns which do not have an event reading. For ex-
ample, event nominal chunks which do not have
a determiner, such as in prisonier de guerre (pris-
oner of war), are not considered as candidates as
they do not denote event instances, but rather event
types, and cannot be attributed a specific temporal
localisation. A set of heuristics is used to detect
predicative adjectives, like in Jean e?tait malade
(Jean was sick), which are potential candidates for
markup with the <EVENT> tag. For example, if the
preceding verb is a copula, the adjective is flagged
as a markable.
To evaluate our event tagger we used a corpus of
30 hand-annotated news articles from the newspa-
per Le Monde. The corpus was split into a devel-
opment set of 20 documents (11 224 tokens, 1 187
EVENT tags) and a test set of 10 documents (5 916
tokens, 583 EVENT tags). Overall, the corpus con-
tains 1 205 verbal, 471 nominal, 62 adjectival and
18 prepositional phrase EVENT tags.
Development corpus Evaluation corpus
Category Prec Rec F-sc Prec Rec F-sc
Noun 50.2 94.5 72.4 54.0 95.1 74.5
Verb 87.7 92.3 90.0 86.5 91.1 88.8
Adjective 60.0 72.4 66.2 46.0 82.1 64.1
Table 3: Evaluation results for the Event Tagger
The results shown in Table 3 are fairly homoge-
nous over both the development and test sets. The
detection of event verbs performs slightly lower
than that of the other system for French, although
the evaluations were carried out on different cor-
pora. For nominals, our system makes a vast im-
provement on the performance of the other sys-
tem described in this paper (an F-score of 74.5
versus 54.2 over the respective test sets). The
large-coverage lexicon of event nominals allows
for a good recall, although precision remains low
as more disambiguation is required to filter out
nominals with non-event readings. Performance
on adjectival events is lower than the other system,
although not as bad as might have been expected.
This is likely due to the difference in depth of syn-
tactic analysis available to each system.
4 Conclusion
We have presented a comparative evaluation of
two systems for the TimeML annotation of events
and temporal expressions in French texts. Results
show that a lexical approach to annotating tempo-
ral expressions performs generally just as well as
an approach based on a shallow syntactic analy-
sis. For event detection, the benefits of a full de-
pendency parse are apparent, especially for the de-
tection of markable adjectives, although compara-
ble performance can be obtained with a chunked
text as input. The benefits of a large-coverage lex-
icon for identifying event nominals are evident,
although without effective disambiguation tech-
niques precision remains very low. This is one
point which requires particular attention and more
elaborate guidelines for the annotation of event
nominals would be of great value. Figures from
the evaluation give a rough indication of perfor-
mance across systems, however, a validated refer-
ence corpus for French is yet to be developed in or-
der to give more meaningful comparisons. These
are issues we are currently addressing.
References
Nabil Hathout, Fiammetta Namer, and Georgette Dal.
2002. An Experimental Constructional Database:
The MorTAL Project. In Paul Boucher, editor,
Many Morphologies, pages 178?209. Cascadilla,
Somerville, Mass., USA.
Inderjeet Mani and George Wilson. 2000. Processing
of news. In Proceedings of the 38th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 69?76, Hong Kong, October. Association
for Computational Linguistics.
Gabriel Parent, Michel Gagnon, and Philippe Muller.
2008. Annotation d?expressions temporelles et
d?e?ve?nements en franc?ais. In Actes de TALN 2008,
Avignon, France, June.
James Pustejovsky, Jose? Casta no, Robert Ingria, Roser
Saur??, Robert Gaizauskas, Andrea Setzer, and Gra-
ham Katz. 2003. TimeML: Robust Specification of
Event and Temporal Expressions in Text. In Pro-
ceedings of IWCS-5, Fifth International Workshop
on Computational Semantics.
Roser Saur??, Robert Knippen, Marc Verhagen, and
James Pustejovsky. 2005. Evita: A Robust Event
Recognizer for QA Systems. In Proceedings of
HLT/EMNLP 2005, pages 700?707.
51
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 130?134,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
French TimeBank: An ISO-TimeML Annotated Reference Corpus
Andre? Bittar
Alpage
Univ. Paris Diderot
andre.bittar@linguist.jussieu.fr
Pascal Amsili
LLF
Univ. Paris Diderot
amsili@linguist.jussieu.fr
Pascal Denis
Alpage
INRIA
pascal.denis@inria.fr
Laurence Danlos
Alpage
Univ. Paris Diderot
danlos@linguist.jussieu.fr
Abstract
This article presents the main points in the cre-
ation of the French TimeBank (Bittar, 2010),
a reference corpus annotated according to the
ISO-TimeML standard for temporal annota-
tion. A number of improvements were made
to the markup language to deal with linguistic
phenomena not yet covered by ISO-TimeML,
including cross-language modifications and
others specific to French. An automatic pre-
annotation system was used to speed up the
annotation process. A preliminary evaluation
of the methodology adopted for this project
yields positive results in terms of data quality
and annotation time.
1 Introduction
The processing of temporal information (events,
time expressions and relations between these enti-
ties) is essential for overall comprehension of nat-
ural language discourse. Determining the temporal
structure of a text can bring added value to numer-
ous NLP applications (information extraction, Q&A
systems, summarization...). Progress has been made
in recent years in the processing of temporal data,
notably through the ISO-TimeML standard (ISO,
2008) and the creation of the TimeBank 1.2 cor-
pus (Pustejovsky et al 2006) for English. Here we
present the French TimeBank (FTiB), a corpus for
French annotated in ISO-TimeML. We also present
the methodology adopted for the creation of this re-
source, which may be generalized to other annota-
tion tasks. We evaluate the effects of our methodol-
ogy on the quality of the corpus and the time taken
in the task.
2 ISO-TimeML
ISO-TimeML (ISO, 2008) is a surface-based lan-
guage for the marking of events (<EVENT> tag) and
temporal expressions (<TIMEX3>), as well as the
realization of the temporal (<TLINK>), aspectual
(<ALINK>) and modal subordination (<SLINK>)
relations that exist among these entities. The tags?
attributes capture semantic and grammatical features
such as event class, tense, aspect and modality, and
the type and normalized interpretative value of tem-
poral expressions. The <SIGNAL> tag is used to an-
notate relation markers, such as before and after. A
set of resources for English has been developed over
the years, including an annotated corpus, TimeBank
1.2 (TB1.2)1, which has become a reference for tem-
poral annotation in English.
3 Improving ISO-TimeML
We propose a number of improvements to ISO-
TimeML to deal with as yet untreated phenom-
ena. These include both cross-language annotation
guidelines, as well as guidelines specific to French.
All these guidelines are implemented in the FTiB.
Cross-language Improvements : ISO-TimeML
currently provides for the annotation of event
modality by capturing the lemma of a modal on
a subordinated event tag in the modality at-
tribute. Inspired by the fact that in French, modal-
ity is expressed by fully inflected verbs, we pro-
pose that those verbs be tagged as modal, and we
1Annotated according to the TimeML 1.2 specification, as
opposed to the more recent ISO-TimeML.
130
provide a set of normalized values for the modal-
ity attribute, within a manual annotation context,
that reflect the classic classes of linguistic modality
(Palmer, 1986): NECESSITY and POSSIBILITY
(epistemic), OBLIGATION and PERMISSION (de-
ontic). We also provide a way of capturing the dif-
ference between support verb constructions with
a neutral aspectual value (mener une attaque (carry
out an attack)) and those with an inchoative as-
pectual value (lancer une attaque (launch an at-
tack)). ISO-TimeML encodes the relation between
the verb and its nominal argument via a <TLINK>
of type IDENTITY. We encode aspectual variants
in the FTiB by using an <ALINK>. A signifi-
cant proportion (13/36) of the annotated <ALINK>
tags in the FTiB (36%) are used in this case. A
third improvement we propose is the introduction of
the event class EVENT CONTAINER2 to distinguish
predicates that take an event nominal as subject.
In TB1.2, these predicates were sometimes marked,
but not distinguished from the OCCURRENCE class.
The distinction is appropriate as these predicates
have events as arguments, unlike OCCURRENCEs.
The relative frequency of this class (19 occurrences)
compared to the standard PERCEPTION class (10)
also justifies its use. Although not yet dealt with
in ISO-TimeML, aspectual periphrases, such as
en train de + Vinf (akin to the English progres-
sive -ing), adding an aspectual value to an event,
are captured in the FTiB in the aspect attribute
for events. We also propose a new value for as-
pect, PROSPECTIVE, encoding the value of the
construction aller + Vinf (going to + Vinf ), as in
le soleil va exploser (the sun is going to explode).
Improvements for French : a correspondence had
to be made between the ISO-TimeML schema and
the grammatical tense system of French, in particu-
lar, to account for tenses such as the passe? compose?
(PAST tense value, as opposed to the present per-
fect used in English) and imparfait (IMPERFECT,
not present in English as a morphological tense).
French modal verbs behave differently to English
modal auxiliaries as they can be conjugated in all
tenses, fall within the scope of aspectual, negative
polarity and other modal operators. Unlike in TB1.2,
2After the terminology of (Vendler, 1967)
modal verbs (and adjectives), are marked <EVENT>
in FTiB and have the class MODAL. 72 events (3.4%)
are annotated with this class in the FTiB.
4 Methodology
Text sampling : the source texts for the FTiB were
selected from the Est Re?publicain corpus of journal-
istic texts.3 The journalistic genre was chosen for
its relatively high frequency of events and temporal
expressions. Texts were sampled from 7 different
sub-genres4, the distributions of which are shown in
Table 1. Certain sub-genres appear in higher pro-
portions than others, for two main reasons. Firstly,
to favor comparison with TB1.2 (which is made up
of news articles). Secondly, because the news gen-
res are relatively diverse in style compared to the
other sub-genres, which follow a certain format (e.g.
obituaries). We present some of the correlations be-
tween sub-genre and linguistic content in Section 5.
Sub-genre Doc # Doc % Token # Token %
Annmt. 22 20.2% 1 679 10.4%
Bio. 1 0.9% 186 1.1%
Intl. news 32 29.4% 5 171 31.9%
Loc. news 19 17.5% 4 370 27.0%
Natl. news 25 22.9% 3 347 20.7%
Obituary 2 1.8% 313 1.9%
Sport 8 7.3% 1 142 7.0%
Total 109 100% 16 208 100%
Table 1: Proportions of sub-genres in the FTiB.
Automatic pre-annotation : To speed up the an-
notation process, we carried out an automatic pre-
annotation of markables (events, temporal expres-
sions and some relation markers), followed by man-
ual correction. Relations were annotated entirely by
hand, as this task remains very difficult to automate.
Below we describe the two modules developed for
pre-annotation.
The TempEx Tagger marks temporal expressions
<TIMEX3> and sets the tag?s attributes, and anno-
tates certain <SIGNAL> tags. This module con-
sists of a set of Unitex (Paumier, 2008) transduc-
ers that are applied to raw text. We adapted and
3Available at http://www.cnrtl.fr.
4These are announcement, biography, international news,
local news, national news, obituary and sport.
131
EVENT 
correction
Adjudication Adjudication
Coherence 
check
TIMEX3 
correction
SIGNAL 
correction
Pre-
annotated 
text
Annotated 
Markables
Annotated 
Markables + 
LINKs
Gold 
Standard
LINK 
annotation
Figure 1: Schema of the annotation strategy.
enriched a pre-existing set of transducers for anno-
tating temporal expressions in French (Gross, 2002)
for our purposes. Marked expressions are classified
according to their ISO-TimeML type5 and the val-
ues of certain attributes are calculated. The value
attribute is only set during normalization, carried out
after the detection phase. A script calculates normal-
ized values for marked expressions, including index-
icals, such as lundi dernier (last Monday) or l?anne?e
prochaine (next year) (with the article?s publication
date as reference point). A comparative evaluation
with the DEDO system of (Parent et al 2008) shows
very similar performance (for exact match on tag
span and for the value attribute) over the same
evaluation corpus (Table 2).
System Prec. Rec. F-sc.
Match TempEx 84.2 81.8 83.0
DEDO 83.0 79.0 81.0
Value TempEx 55.0 44.9 49.4
DEDO 56.0 45.0 50.0
Table 2: Comparative evaluation of the TempEx Tagger
for exact match on tag span and value calculation.
The Event Tagger marks up events (<EVENT> tag)
and certain relation markers through the application
of a sequence of rules acting on the local chunk con-
text. The rules eliminate unlikely candidates or tag
appropriate ones, based on detailed lexical resources
and various contextual criteria. Input is a text pre-
processed with POS tags, morphological analysis
and chunking (carried out with the Macaon process-
5DATE (e.g. 15/01/2001, le 15 janvier 1010, jeudi, demain),
TIME (ex. 15h30, midi), DURATION (ex. trois jours, un an) ou
SET (ex. tous les jours, chaque mardi)
ing pipeline (Nasr et al 2010)). A reliable com-
parison with the DEDO system, to our knowledge
the only other system for this task in French, was
unfortunately not possible. Evaluations were made
on different, yet comparable, corpora, so results are
merely indicative. For event tagging, our system
scored a precision of 62.5 (62.5 for DEDO), recall
of 89.4 (77.7) and an F-score of 75.8 (69.3). There
is room for improvement, although the system still
yields significant gains in total annotation time and
quality. An experiment to evaluate the effects of the
pre-annotation showed a near halving of annotation
time compared to manual annotation, as well as a
significant reduction of human errors (Bittar, 2010).
Unfortunately, it was not possible to reliably com-
pare the performance of the Event Tagger with the
similar module by (Parent et al 2008) (DEDO), to
our knowledge the only other system developed for
this task for French. Evaluations of each system
were carried out on different, although similar, cor-
pora. Thus, results remain merely indicative. For the
task of event recognition, our system scored a preci-
sion of 62.5 (62.5 for DEDO), recall of 89.4 (77.7)
and an F-score of 75.8 (69.3).
Manual annotation and validation : after pre-
annotation of markables, texts were corrected by 3
human annotators (2 per text), using the Callisto6
and Tango7 tools, designed for this task. Figure 1
shows the process undergone by each document.
The final step of the process is a coherence check
of the temporal graph in each document, carried out
6http://callisto.mitre.org/
7http://timeml.org/site/tango/tool.html
132
via application of Allen?s algorithm (Allen, 1983)
and graph saturation (Tannier & Muller, 2008). Us-
ing the same method, we found 18 incoherent graphs
among the 183 files of the TB1.2 corpus for English.
At this stage, the corpus contained 8 incoherencies,
which were all eliminated by hand. Manually elim-
inating incoherencies is an arduous task, and per-
forming an online coherence check during annota-
tion of relations would be extremely useful in a man-
ual annotation tool. All files were validated against
a DTD, provided with the corpus.
5 French TimeBank
Our aim for the FTiB is to provide a corpus of
comparable size to TB1.2 (approx. 61 000 to-
kens). Version 1.0 of FTiB, presented here and
made available online8 in January 2011, represents
about 14 of the target tokens. Figure 2 shows that
proportions of annotated elements for French are
mostly very similar to those in TB1.2. This sug-
gests the annotation guidelines were applied in a
similar way in both corpora and that, for the journal-
istic genre, the distributions of the various marked
elements are similar in French and English. By far
the most common relation type in the French corpus
is the <TLINK>. Among these, 1 175 are marked
between two event arguments (EVENT-EVENT),
722 between an event and a temporal expression
(EVENT-TIMEX3), and 486 between two temporal
expressions (TIMEX3-TIMEX3).
Figure 2: Annotated content of the FTiB and TB1.2.
Inter-annotator agreement was measured over the
entire FTiB corpus and compared with reported
agreement for TB1.2.9. F-scores for agreement
8Via the INRIA GForge at https://gforge.inria.
fr/projects/fr-timebank/.
9Available at http://www.timeml.org/site/
timebank/documentation-1.2.html Note that fig-
'$7( 7,0( '85$7,21 6(7
*HQUH
7
,
0
(
;


7
\
S
H


Figure 3: Distribution of <TIMEX3> types by sub-genre.
&
O
D
V
V


,B67$7(
$63(&78$/
,B$&7,21
3(5&(371
67$7(
02'$/
&$86(
2&&855(1&(
5(3257,1*
(&217$,1(5
ELRLQWOORFDO
QDWORELWVSRUW
DQQ
Figure 4: Distribution of <EVENT> classes by sub-genre.
are significantly higher for the French corpus on
<EVENT> and <TIMEX3> tag spans than for
TB1.2, and very slightly lower for <SIGNAL>. Fig-
ures for tag attributes are higher for TB1.2, as a
much looser metric10 was used for agreement, so
comparison is not yet possible. The same measure
will need to be implemented to afford an accurate
comparison.
ures were only calculated for a small subset of the entire
corpus, unlike for the FTiB, for which all data was used.
10Agreement for TB1.2 was only calculated over tags with
matching spans and wrong attributes on non-matching spans
were not penalized. For the FTiB, all tags were considered and
all attributes for non-matching tag spans were penalized.
133
Corpus
<TIMEX3> <EVENT> <SIGNAL>
Span Attr Span Attr Span
FTiB .89 .86 .86 .85 .75
TB 1.2 .83 (.95) .78 (.95) .77
Table 3: Inter-annotator agreement (F-scores).
Sub-genre and linguistic content : a preliminary
study showed correlations between the various sub-
genres chosen for the corpus and the annotations
in the texts. For example, Figure 3 shows a high
proportion of TIMEs in announcement texts (46%
of the corpus total)11, while DURATIONs are in-
frequent (2%), but appear in higher proportions in
news (21?32%) and sports (13,5%). DATEs are by
far the most frequently marked (80%), with SETs
being the least. In Figure 4, the preponderance of
the OCCURRENCE class is obvious (62.1% of all
events). REPORTING is most frequent in local and
international news. Announcements stand out yet
again, with the highest number and highest propor-
tion of the class EVENT CONTAINER. These ini-
tial observations argue in favor of text sampling to
achieve a diversity of temporal information in a cor-
pus and suggest such features may prove useful in
text classification.
6 Conclusion
Our experiences show ISO-TimeML is a stable lan-
guage and, with some modification, is applicable
to French. The FTiB is a valuable resource that
will surely stimulate development and evaluation of
French temporal processing systems, providing es-
sential data for training machine learning systems.
An initial survey of the data suggests temporal in-
formation may be useful for text classification. Our
methodology is time-efficient and ensures data qual-
ity and usability (coherence). It could be adopted to
create temporally annotated corpora for other lan-
guages as well as being adapted and generalized to
other annotation tasks.
11This is particularly significant given the low proportion of
the total corpus tokens in this sub-genre.
References
ISO 2008. ISO DIS 24617-1: 2008 Language Resource
Management - Semantic Annotation Framework - Part 1:
Time and Events. International Organization for Stan-
dardization, Geneva, Switzerland.
Andre? Bittar 2010. Building a TimeBank for French:
a Reference Corpus Annotated According to the ISO-
TimeML Standard.. PhD thesis. Universite? Paris Diderot,
Paris, France.
Andre? Bittar 2009. Annotation of Temporal Informa-
tion in French Texts.. Computational Linguistics in the
Netherlands (CLIN 19).
Se?bastien Paumier 2008. Unitex 2.0 User Manual..
Universite? Paris Est Marne-la-Valle?e, Marne-la-Valle?e,
France.
Gabriel Parent, Michel Gagnon and Philippe Muller
2008. Annotation d?expressions temporelles et
d?e?ve?nements en franc?ais. Actes de TALN 2008.
Avignon, France.
Alexis Nasr, Fre?de?ric Be?chet and Jean-Franc?ois Rey
2010. MACAON : Une cha??ne linguistique pour le trait-
meent de graphes de mots. Actes de TALN 2010. Mon-
treal, Canada.
James F. Allen. 1983. Maintaining Knowledge About
Temporal Intervals. Communications of the ACM. 26:11
832-843.
Xavier Tannier and Philippe Muller 2008. Evalua-
tion Metrics for Automatic Temporal Annotation of Texts.
Proceedings of the Sixth International Language Re-
sources and Evaluation (LREC?08) Marrakech, Mo-
rocco.
Frank Robert Palmer 1986. Mood and Modality Cam-
bridge University Press Cambridge, UK.
James Pustejovsky, Marc Verhagen, Roser Saur??, Jes-
sica Littman, Robert Gaizauskas, Graham Katz, Inderjeet
Mani, Robert Knippen and Andrea Setzer 2006. Time-
Bank 1.2 Linguistic Data Consortium
Nabil Hathout, Fiammetta Namer and Georgette Dal
2002. An Experimental Constructional Database: The
MorTAL Project Many Morphologies 178?209 Paul
Boucher ed. Somerville, Mass., USA
Zeno Vendler 1967 Linguistics and Philosophy Cornell
University Press Ithaca, NY, USA
Maurice Gross 2002 Les de?terminants nume?raux, un
exemple : les dates horaires Langages 145 Larousse
Paris, France
134
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 730?739,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Finding Salient Dates for Building Thematic Timelines
Re?my Kessler
LIMSI-CNRS
Orsay, France
kessler@limsi.fr
Xavier Tannier
Univ. Paris-Sud,
LIMSI-CNRS
Orsay, France
xtannier@limsi.fr
Caroline Hage`ge
Xerox Research Center Europe
Meylan, France
hagege@xrce.xerox.com
Ve?ronique Moriceau
Univ. Paris-Sud, LIMSI-CNRS
Orsay, France
moriceau@limsi.fr
Andre? Bittar
Xerox Research Center Europe
Meylan, France
bittar@xrce.xerox.com
Abstract
We present an approach for detecting salient
(important) dates in texts in order to auto-
matically build event timelines from a search
query (e.g. the name of an event or person,
etc.). This work was carried out on a corpus
of newswire texts in English provided by the
Agence France Presse (AFP). In order to ex-
tract salient dates that warrant inclusion in an
event timeline, we first recognize and normal-
ize temporal expressions in texts and then use
a machine-learning approach to extract salient
dates that relate to a particular topic. We fo-
cused only on extracting the dates and not the
events to which they are related.
1 Introduction
Our aim here was to build thematic timelines for
a general domain topic defined by a user query.
This task, which involves the extraction of important
events, is related to the tasks of Retrospective Event
Detection (Yang et al, 1998), or New Event Detec-
tion, as defined for example in Topic Detection and
Tracking (TDT) campaigns (Allan, 2002).
The majority of systems designed to tackle this
task make use of textual information in a bag-of-
words manner. They use little temporal informa-
tion, generally only using document metadata, such
as the document creation time (DCT). The few sys-
tems that do make use of temporal information (such
as the now discontinued Google timeline), only ex-
tract absolute, full dates (that feature a day, month
and year). In our corpus, described in Section 3.1,
we found that only 7% of extracted temporal expres-
sions are absolute dates.
We distinguish our work from that of previous re-
searchers in that we have focused primarily on ex-
tracted temporal information as opposed to other
textual content. We show that using linguistic tem-
poral processing helps extract important events in
texts. Our system extracts a maximum of temporal
information and uses only this information to detect
salient dates for the construction of event timelines.
Other types of content are used for initial thematic
document retrieval. Output is a list of dates, ranked
from most important to least important with respect
to the given topic. Each date is presented with a set
of relevant sentences.
We can see this work as a new, easily evaluable
task of ?date extraction?, which is an important com-
ponent of timeline summarization.
In what follows, we first review some of the re-
lated work in Section 2. Section 3 presents the re-
sources used and gives an overview of the system.
The system used for temporal analysis is described
in Section 4, and the strategy used for indexing and
finding salient dates, as well as the results obtained,
are given in Section 51.
2 Related Work
The ISO-TimeML language (Pustejovsky et al,
2010) is a specification language for manual anno-
tation of temporal information in texts, but, to the
best of our knowledge, it has not yet actually been
used in information retrieval systems. Neverthe-
1This work has been partially funded by French National
Research Agency (ANR) under project Chronolines (ANR-10-
CORD-010). We would like to thank the French News Agency
(AFP) for providing us with the corpus.
730
less, (Alonso et al, 2007; Alonso, 2008; Kanhabua,
2009) and (Mestl et al, 2009), among others, have
highlighted that the analysis of temporal informa-
tion is often an essential component in text under-
standing and is useful in a wide range of informa-
tion retrieval applications. (Harabagiu and Bejan,
2005; Saquete et al, 2009) highlight the importance
of processing temporal expressions in Question An-
swering systems. For example, in the TREC-10 QA
evaluation campaign, more than 10% of questions
required an element of temporal processing in order
to be correctly processed (Li et al, 2005a). In multi-
document summarization, temporal processing en-
ables a system to detect redundant excerpts from
various texts on the same topic and to present re-
sults in a relevant chronological order (Barzilay and
Elhadad, 2002). Temporal processing is also useful
for aiding medical decision-making. (Kim and Choi,
2011) present work on the extraction of temporal in-
formation in clinical narrative texts. Similarly, (Jung
et al, 2011) present an end-to-end system that pro-
cesses clinical records, detects events and constructs
timelines of patients? medical histories.
The various editions of the TDT task have given
rise to the development of different systems that de-
tect novelty in news streams (Allan, 2002; Kumaran
and Allen, 2004; Fung et al, 2005). Most of these
systems are based on statistical bag-of-words mod-
els that use similarity measures to determine prox-
imity between documents (Li et al, 2005b; Brants
et al, 2003). (Smith, 2002) used spatio-temporal in-
formation from texts to detect events from a digital
library. His method used place/time collocations and
ranked events according to statistical measures.
Some efforts have been made for automatically
building textual and graphical timelines. For ex-
ample, (Allan et al, 2001) present a system that
uses measures of pertinence and novelty to con-
struct timelines that consist of one sentence per date.
(Chieu and Lee, 2004) propose a similar system that
extracts events relevant to a query from a collection
of documents. Important events are those reported
in a large number of news articles and each event is
constructed according to one single query and rep-
resented by a set of sentences. (Swan and Allen,
2000) present an approach to generating graphical
timelines that involves extracting clusters of noun
phrases and named entities. More recently, (Yan et
al., 2011b; Yan et al, 2011a) used a summarization-
based approach to automatically generate timelines,
taking into account the evolutionary characteristics
of news.
3 Resources and System Overview
3.1 AFP Corpus
For this work, we used a corpus of newswire texts
provided by the AFP French news agency. The En-
glish AFP corpus is composed of 1.3 million texts
that span the 2004-2011 period (511 documents/day
in average and 426 millions words). Each document
is an XML file containing a title, a date of creation
(DCT), set of keywords, and textual content split
into paragraphs.
3.2 AFP Chronologies
AFP ?chronologies? (textual event timelines) are a
specific type of articles written by AFP journal-
ists in order to contextualize current events. These
chronologies may concern any topic discussed in the
media, and consist in a list of dates (typically be-
tween 10 and 20) associated with a text describing
the related event(s). Figure 1 shows an example of
such a chronology. Further examples are given in
Figure 2. We selected 91 chronologies satisfying the
following constraints:
? All dates in the chronologies are between 2004
and 2011 to be sure that the related events
are described in the corpus. For example,
?Chronology of climax to Vietnam War? was
excluded because its corresponding dates do
not appear in the content of the articles.
? All dates in the chronology are anterior to the
chronology?s creation date. For example, the
chronology ?Space in 2005: A calendar?, pub-
lished in January 2005 and listing scheduled
events, was not selected (because almost no
rocket launches finally happened on the ex-
pected day).
? The temporal granularity of the chronology is
the day. For example, ?A timeline of how the
London transport attacks unfolded?, relating
the events hour by hour, is not in our focus.
731
<NewsML Version="1.2">
<NewsItem xml:lang="en">
<HeadLine>Key dates in Thai-
land?s political crisis</HeadLine>
<DateId>20100513T100519Z</DateId>
<NameLabel>Thailand-politics</NameLabel>
<DataContent>
<p>The following is a timeline of events since
the protests began, soon after Thailand?s Supreme
Court confiscated 1.4 billion dollars of Thaksin?s
wealth for abuse of power.</p>
<p>March 14: Tens of thousands of Red Shirts
demonstrate in the capital calling for Abhisit?s gov-
ernment to step down, [...]</p>
<p>March 28: The government and the Reds en-
ter into talks but hit a stalemate after two days
[...]</p>
<p>April 3: Tens of thousands of protesters move
from Bangkok?s historic district into the city?s com-
mercial heart [...]</p>
<p>April 7: Abhisit declares state of emergency
in capital after Red Shirts storm parliament.</p>
<p>April 8: Authorities announce arrest warrants
for protest leaders.</p>
. . .
</DataContent>
</NewsItem>
</NewsML>
Figure 1: Example of an AFP manual chronology.
For learning and evaluation purposes, all
chronologies were converted to a single XML
format. Each document was manually associated
with a user search query made up of the keywords
required to retrieve the chronology.
3.3 System Overview
Figure 3 shows the general architecture of the sys-
tem. First, pre-processing of the AFP corpus tags
and normalizes temporal expressions in each of the
articles (step ? in the Figure). Next, the corpus is
indexed by the Lucene search engine2 (step ?).
Given a query, a number of documents are re-
trieved by Lucene (?). These documents can be fil-
tered (?), and dates are extracted from the remain-
ing documents. These dates are then ranked in order
to show the most important ones to the user (?), to-
2http://lucene.apache.org
- Chronology of 18 months of trouble in Ivory Coast
- Chechen rebels? history of hostage-takings
- Iraqi political wrangling since March 7 election
- Athletics: Timeline of men?s 800m world record
- Major accidents in Chinese mines
- Space in 2005: A calendar
- Developments in Iranian nuclear standoff
- Chronology of climax to Vietnam War
- Timeline of ex-IMF chief?s sex attack case
- A timeline of how the London transport attacks un-
folded
Figure 2: Examples of AFP chronologies.
Figure 3: System overview.
gether with the sentences that contain them.
4 Temporal and Linguistic Processing
In this section, we describe the linguistic and tempo-
ral information extracted during the pre-processing
phase and how the extraction is carried out. We
rely on the powerful linguistic analyzer XIP (A??t-
Mokhtar et al, 2002), that we adapted for our pur-
poses.
4.1 XIP
The linguistic analyzer we use performs a deep syn-
tactic analysis of running text. It takes as input
XML files and analyzes the textual content enclosed
in the various XML tags in different ways that are
specified in an XML guide (a file providing instruc-
tions to the parser, see (Roux, 2004) for details).
XIP performs complete linguistic processing rang-
ing from tokenization to deep grammatical depen-
dency analysis. It also performs named entity recog-
732
nition (NER) of the most usual named entity cat-
egories and recognizes temporal expressions. Lin-
guistic units manipulated by the parser are either
terminal categories or chunks. Each of these units
is associated with an attribute-value matrix that con-
tains the unit?s relevant morphological, syntactic and
semantic information. Linguistic constituents are
linked by oriented and labelled n-ary relations de-
noting syntactic or semantic properties of the input
text. A Java API is provided with the parser so that
all linguistic structures and relations can be easily
manipulated by Java code.
In the following subsections, we give details of
the linguistic information that is used for the detec-
tion of salient dates.
4.2 Named Entity Recognition
Named Entity (NE) Recognition is one of the out-
puts provided by XIP. NEs are represented as unary
relations in the parser output. We used the exist-
ing NE recognition module of the English grammar
which tags the following NE types: location names,
person names and organization names. Ambigu-
ous NE types (ambiguity between type location or
organization for country names for instance) are
also considered.
4.3 Temporal Analysis
A previous module for temporal analysis was de-
veloped and integrated into the English grammar
(Hage`ge and Tannier, 2008), and evaluated during
TempEval campaign (Verhagen et al, 2007). This
module was adapted for tagging salient dates. Our
goal with temporal analysis is to be able to tag and
normalize3 a selected subset of temporal expressions
(TEs) which we consider to be relevant for our task.
This subset of expressions is described in the follow-
ing sections.
4.3.1 Absolute Dates
Absolute dates are dates that can be normalized
without external or contextual knowledge. This is
the case, for instance, of ?On January 5th 2003?.
In these expressions, all information needed for nor-
malization is contained in the linguistic expression.
3We call normalization the operation of turning a temporal
expression into a formated, fully specified representation. This
includes finding the absolute value of relative dates.
However, absolute dates are relatively infrequent in
our corpus (7%), so in order to broaden the cover-
age for the detection of salient dates, we decided to
consider relative dates, which are far more frequent.
4.3.2 DCT-relative Dates
DCT-relative temporal expressions are those
which are relative to the creation date of the docu-
ment. This class represents 40% of dates extracted
from the AFP corpus. Unlike the absolute dates, the
linguistic expression does not provide all the infor-
mation needed for normalization. External informa-
tion is required, in particular, the date which corre-
sponds to the moment of utterance. In news articles,
this is the DCT. Two sub-classes of relative TEs can
be distinguished. The first sub-class only requires
knowledge of the DCT value to perform the normal-
ization. This is the case of expressions like next Fri-
day, which correspond to the calendar date of the
first Friday following the DCT. The second sub-class
requires further contextual knowledge for normal-
ization. For example, on Friday will correspond ei-
ther to last Friday or to next Friday depending on
the context where this expression appears (e.g. He
is expected to come on Friday corresponds to next
Friday while He arrived on Friday corresponds to
last Friday). In such cases, the tense of the verb
that governs the TE is essential for normalization.
This information is provided by the linguistic analy-
sis carried out by XIP.
4.3.3 Underspecified Dates
Considering the kind of corpus we deal with
(news), we decided to consider TEs whose granu-
larity is at least equal to a day. As a result, TEs
were normalized to a numerical YYYYMMDD for-
mat (where YYYY corresponds to the year, MM to
the month and DD to the day). In case of TEs with
a granularity superior to the day or month, DD and
MM fields remain unspecified accordingly. How-
ever, these underspecified dates are not used in our
experiments.
4.4 Modality and Reported Speech
An important issue that can affect the calculation of
salient dates is the modality associated with time-
stamped events in text. For instance, the status of a
salient date candidate in a sentence like ?The meet-
733
ing takes place on Friday? has to be distinguished
from the one in ?The meeting should take place on
Friday? or ?The meeting will take place on Friday,
Mr. Hong said?. The time-stamped event meeting
takes place is factual in the first example and can
be taken as granted. In the second and third exam-
ples, however, the event does not necessarily occur.
This is expressed by the modality introduced by the
modal auxiliary should (second example), or by the
use of the future tense or reported speech (third ex-
ample). We annotate TEs with information regard-
ing the factuality of the event they modify. More
specifically, we consider the following features:
Events that are mentioned in the future: If a
time-stamped event is in the future tense, we add a
specific attribute MODALITY with value FUTURE to
the corresponding TE annotation.
Events used with a modal verb: If a time-
stamped event is introduced by a modal verb such
as should or would, then attribute MODALITY to the
corresponding TE annotation has the value MODAL.
Reported speech verbs: Reported speech verbs
(or verbs of speaking) introduce indirect or reported
speech. We dealt with time-stamped events gov-
erned by a reported speech verb, or otherwise ap-
pearing in reported speech. Once again, XIP?s lin-
guistic analysis provided the necessary information,
including the marking of reported speech verbs and
clause segmentation of complex sentences. If a rel-
evant TE modifies a reported speech verb, the anno-
tation of this TE contains a specific attribute, DE-
CLARATION=?YES?. If the relevant TE modifies
a verb that appears in a clause introduced by a re-
ported speech verb then the annotation contains the
attribute REPORTED=?YES?.
Note that the different annotations can be com-
bined (e.g. modality and reported speech can occur
for a same time-stamped event). For example, the
TE Friday in ?The meeting should take place on Fri-
day, Mr. Hong said? is annotated with both modality
and reported speech attributes.
4.5 Corpus-dependent Special Cases
While we developed the linguistic and temporal an-
notators, we took into account some specificities of
our corpus. We decided that the TEs today and
<DCT value="20050105"/>
<EC TYPE="TIMEX" value="unknown">The year
2004</EC> was the deadliest <EC TYPE="TIMEX"
value="unknown">in a decade</EC> for journalists
around the world, mainly because of the number of reporters
killed in <EC TYPE="LOCORG">Iraq</EC>, the
media rights group <EN TYPE="ORG">Reporters
Sans Frontieres</EN> (Reporters Without Bor-
ders) said <EC TYPE="DATE" SUBTYPE="REL"
REF="ST" DECLARATION="YES" value
="20050105">Wednesday</EC>.
Figure 4: Example of XIP output for a sample article.
now were not relevant for the detection of salient
dates. In the AFP news corpus, these expressions
are mostly generic expressions synomymous with
nowadays and do not really time-stamp an event
with respect to the DCT. Another specificity of the
corpus is the fact that if the DCT corresponds to a
Monday, and if an event in a past tense is described
with the associated TE on Monday or Monday, it
means that this event occurs on the DCT day itself,
and not on the Monday before. We adapted the TE
normalizer to these special cases.
4.6 Implementation and Example
As said previously, a NER module is integrated into
the XIP parser, which we used ?as is?. The TE tag-
ger and normalizer was adapted from (Hage`ge and
Tannier, 2008). We used the Java API provided with
the parser to perform the annotation and normal-
ization of TEs. The output for the linguistic and
temporal annotation consists in XML files where
only selected information is kept (structural infor-
mation distinguishing headlines from news content,
DCT), and enriched with the linguistic annotations
described before (NEs and TEs with relevant at-
tributes corresponding to the normalization and typ-
ing). Information concerning modality, future tense
and reported speech, appears as attributes on the TE
tag. Figure 4 shows an example of an analyzed ex-
cerpt of a news article.
In this news excerpt, only one TE (Wednesday) is
normalized as both The year 2004 and in a decade
are not considered to be relevant. The first one being
a generic TE and the second one being of granular-
ity superior to a year. The annotation of the relevant
TE has the attribute indicating that it time-stamps an
event realized by a reported speech verb. The nor-
734
malized value of the TE corresponds to the 5th of
January 2005, which is a Wednesday. NEs are also
annotated.
In the entire AFP corpus, 11.5 millions temporal
expressions were detected, among which 845,000
absolute dates (7%) and 4.6 millions normalized
relative dates (40%). Although we have not yet
evaluated our tagging of relative dates, the system
on which our current date normalization is based
achieved good results in the TempEval (Verhagen et
al., 2007) campaign.
5 Experiments and Results
In Section 5.1, we propose two baseline approaches
in order to give a good idea of the difficulty of the
task (Section 5.4 also discusses this point). In Sec-
tion 5.2, we present our experiments using simple
filtering and statistics on dates calculated by Lucene.
Finally, Section 5.3 gives details of our experiments
with a learning approach. In our experiments, we
used three different values to rank dates:
? occ(d) is the number of textual units (docu-
ments or sentences) containing the date d.
? Lucene provides ranked documents together
with their relevance score. luc(d) is the sum of
Lucene scores for textual units containing the
date d.
? An adaptation of classical tf.idf for dates:
tf.idf(d) = f(d).log
N
df(d)
where f(d) is the number of occurrences of
date d in the sentence (generally, f(d) = 1), N
is the number of indexed sentences and df(d)
is the number of sentences containing date d.
In all experiments (including baselines), timelines
have been built by considering only dates between
the first and the last dates of the corresponding man-
ual chronology. Processing runs were evaluated on
manually-written chronologies (see Section 3.2) ac-
cording to Mean Average Precision (MAP), which
is a widely accepted metric for ranked lists. MAP
gives a higher weight to higher ranked elements than
lower ranked elements. Significance of evaluation
results are indicated by the p-value results of the Stu-
dent?s t-test (t(90) = 1.9867).
Baselines ?only DCTs?
Model BLoccDCT BL
luc
DCT BL
tf.idf
DCT
MAP Score 0.5036 0.5521 0.5523
Baselines ?only absolute dates?
Model BLoccabs BL
luc
abs BL
tf.idf
abs
MAP Score 0.2627 0.2782 0.2778
Baselines ?absolute dates or alternatively DCTs?
Model BLoccmix BL
luc
mix BL
tf.idf
mix
MAP Score 0.4005 0.4110 0.4135
Table 1: MAP results for baseline runs.
5.1 Baseline Runs
BLDCT . Indexing and search were done at docu-
ment level (i.e. each AFP article, with its title
and keywords, is a document). Given a query,
the top 10,000 documents were retrieved. In
these runs, only the DCT for each document
was considered. Dates were ranked by one of
the three values described above (occ, luc or
tf.idf ) leading to runs BLoccDCT , BL
luc
DCT and
BLtfidfDCT .
BLabs. Indexing and search were done at sentence
level (document title and keywords are added
to sentence text). Given a query, the top 10,000
sentences were retrieved. Only absolute dates
in these sentences were considered. We thus
obtained runs BLoccabs, BL
luc
abs and BL
tfidf
abs .
Note that in this baseline, as well as in all the
subsequent runs, the information unit was the
sentence because a date was associated to a
small part of the text. The rest of the document
generally contained text that was not related to
the specific date.
BLmix. Same as BLabs, except that sentences con-
taining no absolute dates were considered and
associated to the DCT.
Table 1 shows results for these baseline runs.
Using only DCTs with Lucene scores or tf.idf(d)
already yielded interesting results, with MAP
around 0.55.
5.2 Salient Date Extraction with XIP Results
and Simple Filtering
In these experiments, we considered a Lucene index
to be built as follows: each document was taken to
735
Model MAP Score Model MAP Score
Salient date runs with all dates
SDluc 0.6962 SDtf.idf 0.6982
Salient dates runs with filtering
SDlucR 0.6975 SD
tf.idf
R 0.6996
SDlucF 0.6967 SD
tf.idf
F 0.6993
??
SDlucM 0.6978 SD
tf.idf
M 0.7005
?
SDlucD 0.7066
?? SDtf.idfD 0.7091
??
SDlucFMD 0.7086
?? SDtf.idfFMD 0.7112
??
SDlucRFMD 0.7127
?? SDtf.idfRFMD 0.7146
??
Table 2: MAP results for salient date extraction with XIP
and simple filtering. The significance of the improvement
due to filtering wrt no filtering is indicated by the Student
t-test (?: p < 0.05 (significant); ??: p < 0.01 (highly
significant)). The improvement due to using tf.idf(d) as
opposed to occ(d) is also highly significant.
be a sentence containing a normalized date. This
sentence was indexed with the title and keywords of
the AFP article containing it. Given a query, the top
10,000 documents were retrieved. Combinations be-
tween the following filtering operations were pos-
sible, by removing all dates associated with a re-
ported speech verb (R), a modal verb (M ) and/or
a future verb (F ). All these filtering operations were
intended to remove references to events that were
not certain, thereby minimizing noise in results.
These processing runs are named SD runs, with
indices representing the filtering operations. For ex-
ample, a run obtained by filtering modal and future
verbs is called SDM,F . In all combinations, dates
were ranked by the sum of Lucene scores for these
sentences (luc) or by tf.idf4.
Table 2 presents the results for this series of ex-
periments. MAP values are much higher than for
baselines. Using tf.idf(d) is only very slightly bet-
ter than luc. Filtering operations bring significant
improvement but the benefits of these different tech-
niques have to be further investigated.
5.3 Machine-Learning Runs
We used our set of manually-written chronologies
as a training corpus to perform machine learning
experiments. We used IcsiBoost5, an implementa-
4We do not present runs where dates are ranked by the num-
ber of times they appear in retrieved sentences (occ), as we did
for baselines, since results are systematically lower.
5http://code.google.com/p/icsiboost/
tion of adaptative boosting (AdaBoost (Freund and
Schapire, 1997)).
In our approach, we consider two classes: salient
dates are dates that have an entry in the manual
chronologies, while non-salient dates are all other
dates. This choice does, however, represent an im-
portant bias. The choices of journalists are indeed
very subjective, and chronologies must not exceed a
certain length, which means that relevant dates can
be thrown away. These issues will be discussed in
Section 5.4.
The classifier instances were not all sentences re-
trieved by the search engine. Using all sentences
would not yield a useful feature set. We rather ag-
gregated all sentences corresponding to the same
date before learning the classifier. Therefore, each
instance corresponded to a single date, and features
were figures concerning the set of sentences contain-
ing this date.
Features used in this series of runs are as follows:
1. Features representing the fact that the more
a date is mentioned, the more important it is
likely to be: 1) Sum of the Lucene scores for
all sentences containing the date 2) Number of
sentences containing the date 3) Ratio between
the total weights of the date and weights of all
returned dates 4) Ratio between the frequency
of the date and frequency of all returned dates;
2. Features representing the fact that an important
event is still written about, a long time after it
occurs: 1) Distance between the date and the
most recent mention of this date 2) Distance be-
tween the date and the DCT;
3. Other features: 1) Lucene?s best ranking of the
date 2) Number of times where the date is ab-
solute in the text 3) Number of times where
the date is relative (but normalized) in the text
4) Total number of keywords of the query in the
title, sentence and named entities of retrieved
documents 5) Number of times where the date
modifies a reported speech verb or is extracted
from reported speech.
We did not aim to classify dates, but rather to rank
them. Instead, we used the predicted probability
P (d) returned by the classifier, and mixed it with
the Lucene score of sentences, or with date tf.idf :
736
Model MAP Score
Machine-Learning Runs
MLlucbase 0.7033
MLluc 0.7905 ??
MLtf.idf 0.7918 ??
Table 3: MAP results for salient date extraction with
machine-learning. MLlucbase used Lucene scores and only
the first set of features described above. MLluc and
MLtf.idf used the three sets of features. They are both
highly significant under the t-test (p ? 6.10?4) wrt re-
spectively SDluc and SDtf.idf .
score(d) = P (d)? val(d)
where val(d) is either luc(d) or tf.idf(d).
Because the task is very subjective and (above
all) because of the low quantity of learning data, we
prefered not to opt for a ?learning to rank? approach.
We evaluated this approach with a classic 4-fold
cross-validation. Our 91 chronologies were ran-
domly divided into 4 sub-samples, each of them be-
ing used once as test data. The final scores, pre-
sented in Table 3, are the average of these 4 pro-
cesses. As shown in this table, the learning approach
improves MAP results by about 0.05 point.
5.4 Discussion and Final Experiment
Chronologies hand-written by journalists are a very
useful resources for evaluation of our system, as they
are completely dissociated from our research and are
an exact representation of the output we aim to ob-
tain. However, assembling such a chronology is a
very subjective task, and no clear method for evalu-
ation agreement between two journalists seems im-
mediately apparent. Only experts can build such
chronologies, and calculating this agreement would
require at least two experts from each domain, which
are hard to come by. One may then consider our sys-
tem as a useful tool for building a chronology more
objectively.
To illustrate this point, we chose four specific top-
ics6 and showed one of our runs on each topic to an
AFP expert for these subjects. We asked him to as-
sess the first 30 dates of these runs.
6Namely, ?Arab revolt timeline for Morocco?, ?Kyrgyzs-
tan unrest timeline?, ?Lebanon?s new government: a timeline?,
?Libya timeline?.
Topic APC APE
Morocco 0.5847 0.5718
Kyrgyzstan 0.6125 0.9989
Libya 0.7856 1
Lebanon 0.4673 0.7652
Table 4: Average precision results for manual evaluation
on 4 topics, against the original chronologies (APC), and
the expert assessment (APE).
Table 4 presents results for this evaluation, com-
paring average precision values obtained 1) against
the original, manual chronologies (APC), and 2)
against the expert assessment (APE). These values
show that, for 3 runs out of 4, many dates returned
by the system are considered as valid by the expert,
even if not presented in the original chronology.
Even if this experiment is not strong enough to
lead to a formal conclusion (post-hoc evaluation
with only 4 topics and a single assessor), this tends
to show that our system produces usable outputs and
that our system can be of help to journalists by pro-
viding them with chronologies that are as useful and
objective as possible.
6 Conclusion and Future Work
This article presents a task of ?date extraction? and
shows the importance of taking temporal informa-
tion into consideration and how with relatively sim-
ple temporal processing, we were able to indirectly
point to important events using the temporal infor-
mation associated with these events. Of course, as
our final goal consists in the detection of important
events, we need to take into account the textual con-
tent. In future work, we envisage providing, together
with the detection of salient dates, a semantic analy-
sis that will help determine the importance of events.
Another interesting direction in which we soon aim
to work is to consider all textual excerpts that are as-
sociated with salient dates, and use clustering tech-
niques to determine if textual excerpts correspond to
the same event or not. Finally, as our news corpus
is available both for English and French (compara-
ble corpus, not necessarily translations), we aim to
investigate cross-lingual extraction of salient dates
and salient events.
737
References
Salah A??t-Mokhtar, Jean-Pierre Chanod, and Claude
Roux. 2002. Robustness beyond Shallowness: Incre-
mental Deep Parsing. Natural Language Engineering,
8:121?144.
James Allan, Rahul Gupta, and Vikas Khandelwal. 2001.
Temporal summaries of new topics. In Proceedings of
the 24th annual international ACM SIGIR conference
on Research and development in information retrieval,
SIGIR ?01, pages 10?18.
James Allan, editor. 2002. Topic Detection and Tracking.
Springer.
Omar Alonso, Ricardo Baeza-Yates, and Michael Gertz.
2007. Exploratory Search Using Timelines. In
SIGCHI 2007 Workshop on Exploratory Search and
HCI Workshop.
Omar Rogelio Alonso. 2008. Temporal information re-
trieval. Ph.D. thesis, University of California at Davis,
Davis, CA, USA. Adviser-Gertz, Michael.
Regina Barzilay and Noemie Elhadad. 2002. Infer-
ring Strategies for Sentence Ordering in Multidocu-
ment News Summarization. Journal of Artificial In-
telligence Research, 17:35?55.
Thorsten Brants, Francine Chen, and Ayman Farahat.
2003. A system for new event detection. In Proceed-
ings of the 26th annual international ACM SIGIR con-
ference on Research and development in informaion
retrieval, SIGIR ?03, pages 330?337, New York, NY,
USA. ACM.
Hai Leong Chieu and Yoong Keok Lee. 2004. Query
based event extraction along a timeline. In Proceed-
ings of the 27th annual international ACM SIGIR con-
ference on Research and development in information
retrieval, SIGIR ?04, pages 425?432.
Yoav Freund and Robert E. Schapire. 1997. A Decision-
Theoretic Generalization of On-Line Learning and an
Application to Boosting. Journal of Computer and
System Sciences, 55(1):119?139.
Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Philip S. Yu,
and Hongjun Lu. 2005. Parameter free bursty events
detection in text streams. In VLDB ?05: Proceedings
of the 31st international conference on Very large data
bases, pages 181?192.
Caroline Hage`ge and Xavier Tannier. 2008. XTM: A Ro-
bust Temporal Text Processor. In Computational Lin-
guistics and Intelligent Text Processing, proceedings
of 9th International Conference CICLing 2008, pages
231?240, Haifa, Israel, February. Springer Berlin /
Heidelberg.
Sanda Harabagiu and Cosmin Adrian Bejan. 2005.
Question Answering Based on Temporal Inference. In
Proceedings of the Workshop on Inference for Textual
Question Answering, Pittsburg, Pennsylvania, USA,
July.
Hyuckchul Jung, James Allen, Nate Blaylock, Will
de Beaumont, Lucian Galescu, and Mary Swift. 2011.
Building timelines from narrative clinical records: ini-
tial results based-on deep natural language under-
standing. In Proceedings of BioNLP 2011 Workshop,
BioNLP ?11, pages 146?154, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Nattiya Kanhabua. 2009. Exploiting temporal infor-
mation in retrieval of archived documents. In Pro-
ceedings of the 32nd Annual International ACM SIGIR
Conference on Research and Development in Informa-
tion Retrieval, SIGIR 2009, Boston, MA, USA, July 19-
23, 2009, page 848.
Youngho Kim and Jinwook Choi. 2011. Recogniz-
ing temporal information in korean clinical narra-
tives through text normalization. Healthc Inform Res,
17(3):150?5.
Giridhar Kumaran and James Allen. 2004. Text clas-
sification and named entities for new event detection.
In SIGIR ?04: Proceedings of the 27th annual in-
ternational ACM SIGIR conference on Research and
development in information retrieval, pages 297?304.
ACM.
Wei Li, Wenjie Li, Qin Lu, and Kam-Fai Wong. 2005a.
A Preliminary Work on Classifying Time Granulari-
ties of Temporal Questions. In Proceedings of Second
international joint conference in NLP (IJCNLP 2005),
Jeju Island, Korea, oct.
Zhiwei Li, Bin Wang, Mingjing Li, and Wei-Ying Ma.
2005b. A Probabilistic Model for Restrospective
News Event Detection. In Proceedings of the 28th
Annual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval, Sal-
vador, Brazil. ACM Press, New York City, NY, USA.
Thomas Mestl, Olga Cerrato, Jon ?lnes, Per Myrseth,
and Inger-Mette Gustavsen. 2009. Time Challenges -
Challenging Times for Future Information Search. D-
Lib Magazine, 15(5/6).
James Pustejovsky, Kiyong Lee, Harry Bunt, and Lau-
rent Romary. 2010. Iso-timeml: An international
standard for semantic annotation. In Nicoletta Calzo-
lari (Conference Chair), Khalid Choukri, Bente Mae-
gaard, Joseph Mariani, Jan Odijk, Stelios Piperidis,
Mike Rosner, and Daniel Tapias, editors, Proceed-
ings of the Seventh International Conference on Lan-
guage Resources and Evaluation (LREC?10), Valletta,
Malta, may. European Language Resources Associa-
tion (ELRA).
Claude Roux. 2004. Annoter les documents XML avec
un outil d?analyse syntaxique. In 11e`me Confrence
annuelle de Traitement Automatique des Langues Na-
turelles, Fe`s, Morocco, April. ATALA.
738
Estela Saquete, Jose L. Vicedo, Patricio Mart??nez-Barco,
Rafael Mun?oz, and Hector Llorens. 2009. Enhancing
QA Systems with Complex Temporal Question Pro-
cessing Capabilities. Journal of Articifial Intelligence
Research, 35:775?811.
David A. Smith. 2002. Detecting events with date and
place information in unstructured text. In JCDL ?02:
Proceedings of the 2nd ACM/IEEE-CS joint confer-
ence on Digital libraries, pages 191?196, New York,
NY, USA. ACM.
Russell Swan and James Allen. 2000. Automatic genera-
tion of overview timelines. In Proceedings of the 23rd
annual international ACM SIGIR conference on Re-
search and development in information retrieval, SI-
GIR ?00, pages 49?56, New York, NY, USA. ACM.
Marc Verhagen, Robert Gaizauskas, Franck Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. SemEval-2007 - 15: TempEval Temporal Rela-
tion Identification. In Proceedings of SemEval work-
shop at ACL 2007, Prague, Czech Republic, June. As-
sociation for Computational Linguistics, Morristown,
NJ, USA.
Rui Yan, Liang Kong, Congrui Huang, Xiaojun Wan, Xi-
aoming Li, and Yan Zhang. 2011a. Timeline gen-
eration through evolutionary trans-temporal summa-
rization. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Processing,
EMNLP 2011, 27-31 July 2011, Edinburgh, UK, pages
433?443.
Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,
Xiaoming Li, and Yan Zhang. 2011b. Evolution-
ary timeline summarization: a balanced optimization
framework via iterative substitution. In Proceeding
of the 34th International ACM SIGIR Conference on
Research and Development in Information Retrieval,
SIGIR 2011, Beijing, China, July 25-29, 2011, pages
745?754.
Y. Yang, T. Pierce, and J. G. Carbonell. 1998. A study on
retrospective and on-line event detection. In Proceed-
ings of the 21st Annual International ACM SIGIR Con-
ference on Research and Development in Information
Retrieval, Melbourne, Australia, August. ACM Press,
New York City, NY, USA.
739
