Coling 2008: Companion volume ? Posters and Demonstrations, pages 161?164
Manchester, August 2008
?Build Your Own? Spoken Dialogue Systems:
Automatically Generating ISU Dialogue Systems from Business User
Resources
Oliver Lemon, Xingkun Liu, and Helen Hastie
School of Informatics
University of Edinburgh
Informatics Forum
10 Crichton Street
Edinburgh, EH8 9AB
{olemon,xliu4,hhastie}@inf.ed.ac.uk
Abstract
Building effective spoken dialogue sys-
tems (SDS) is currently a complex task
requiring expert knowledge. Our tools
give control of SDS application develop-
ment to non-experts, who need only use
a Graphical User Interface or GUI to de-
velop state-of-the-art ?Information State
Update? (ISU) dialogue systems. Behind
the GUI is a set of Advanced Dialogue
Tools (ADT) that generate complete SDS
based on Business User Resources. These
resources include a database and a Pro-
cess Model that captures the structure of
an application, for example, banking or
restaurant information. Also generated
are speech recognition Language Models
and grammars for robust interpretation of
spontaneous speech. We will demonstrate
how our simple GUI allows developers to
easily and quickly create and modify SDS
without the need for expensive speech ap-
plication service providers. This demon-
stration shows the interface, the ADT com-
ponents, and discusses some of the re-
search issues involved. We also show an
example application built with the tools: a
tourist information system running on an
ultra-mobile PC.
1 Introduction
As automated call centres are becoming more and
more commonplace, new challenges are emerg-
ing such as having to rely on expensive service
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
providers to build systems, the inability to quickly
and easily modify live systems, and the time and
cost needed to create new SDS applications. This
paper describes a solution to these problems using
our Advanced Dialogue Tools (ADT). This pro-
totype system allows developers to take already
established business user resources such as Busi-
ness Process Models (BPM) and databases, and
use them to automatically generate spoken dia-
logue systems. Simple customisations can then
be made through the easy-to-use ADT interface or
GUI, which is example-driven. This radically new
way of creating spoken dialogue systems will put
control into the hands of the business user who is
familiar with customer needs and business goals,
thus improving usability and making spoken dia-
logue systems more widely and rapidly available.
Currently, VoiceXML is widely used for such
tasks. However, VoiceXML applications are dif-
ficult to build and maintain, because develop-
ers must anticipate and represent every possi-
ble dialogue path in the finite-state VoiceXML
model. ADT will generate VoiceXML dynami-
cally, but the easy-to-use interface allows devel-
opers to select, deploy, and monitor different ad-
vanced dialogue strategies without needing to code
VoiceXML directly. We apply the ?Information
State Update? (ISU) approach (Lemon, 2004) that
enables more robust, flexible and natural conver-
sations than VoiceXML. ISU uses a more concise
and maintainable representation of dialogue flow,
based on rules operating over dialogue contexts,
which can generalise to unforeseen states.
2 The ADT Architecture
Figure 1 shows the ADT architecture whereby the
main algorithm takes business user resources and
databases as input and uses these to automatically
161
generate the spoken dialogue system. Figure 2
shows part of one such resource, namely a BPM
for hotel bookings. First the caller will hear an
introduction, then they will be asked what price
range they want, and then whether they want a ho-
tel in the centre of town or not. Advantages of us-
ing BPMs include the fact that graphical interfaces
and authoring environments are widely available
for them, for example: Eclipse, IBM Websphere-
Process Server, BEA WeblogicWorkshop etc.. In
addition, Business User Resources can contain a
lot of additional information as well as call flows
including context, multi-media, and multiple cus-
tomer interactions.
Figure 1: The ADT Architecture
Figure 2: Part of an example Business Process
Model for searching for Hotels
The resulting spoken dialogue system deploys
the following main modules:
? Speech Recogniser module, e.g. ATK/HTK
(Young, 2007; Young, 1995) or Nuance (Nu-
ance, 2002)
? Spoken Language Understanding module,
e.g. Grammatical Framework (GF) parser
(Ranta, 2004)
? BPM and Database modules
? Speech synthesiser e.g. Festival (Taylor et al,
1998) or Cereproc (Aylett and Pidcock, 2007)
2.1 Generic Dialogue Modelling
Sophisticated research systems have been devel-
oped only for specific applications and cannot be
easily transferred to another, even very similar task
or domain. The problem of components being do-
main specific is especially prevalent in the core
area of dialogue management. For example MIT?s
Pegasus and Mercury systems (Seneff, 2002) have
dialogue managers (DM) that use approximately
350 domain-specific hand-coded rules each. The
sheer amount of labour required to construct sys-
tems prevents them from being more widely and
rapidly deployed. Our solution uses BPMs and
related authoring tools to specify domain-specific
dialogue interactions which are combined with a
domain-general dialogue manager. Specifically,
the DM consults the BPM to determine what task-
based steps to take next, such as asking for a cin-
ema name. General aspects of dialogue, such as
confirmation and clarification strategies, are han-
dled by the domain-general DM. Values for con-
straints on transitions and branching in the BPM,
for example ?present insurance option if the user is
business-class?, are compiled into domain-specific
parts of the DM?s update rules. XML format is
used for BPMs, and they are compiled into finite
state machines consulted by the spoken dialogue
system through the BPM module. The domain-
general DM was mostly abstracted from the TALK
system (Lemon et al, 2006).
2.2 Compiling Grammars for Business User
Resources and Databases
For Spoken Language Understanding, ADT cur-
rently uses Grammatical Framework (GF) (Ranta,
2004) which is a language for writing multilingual
grammars, on top of which various applications
such as machine translation and human-machine
interaction have been built. A GF grammar not
only defines syntactic well-formedness, but also
semantic content.
Using ADT, system developers do not have to
write a single line of GF grammar code. The sys-
162
tem compiles all database entries and their proper-
ties into the appropriate ?slot-filling? parts of the
GF grammar for each specific BPM.
For example, a generated GF rule is:
Bpm generalTypeRule 4:
town info hotels name->Utt=>{ s = np.s}
This rule was generated because ?name? is a
database field for the subtask hotels in the
?town info? BPM. It specifies that all hotel names
are valid utterances.
A core GF grammar has been developed to cover
basic information-seeking interactions. This is
combined with a domain-specific grammar which
is automatically generated from the BPM, database
and the example utterances provided by the devel-
oper in the GUI. Finally, GF is a robust parser ? it
skips all disfluencies and unknown words to pro-
duce an interpretation of the user input if one ex-
ists.
2.3 Speech Recognition and Text To Speech
The grammars for Spoken Language Understand-
ing generated by ADT are also compiled to
grammar-based language models (LM) for speech
recognition. ADT is plug-and-play and adheres to
industry standards such as GSML, GrXML. This
allows for greater flexibility since the application
developer is not tied to one recogniser or TTS en-
gine. For this demonstration, the speech recog-
niser is ATK (Young, 2007; Young, 1995) and
the speech synthesiser is Cereproc (Aylett and Pid-
cock, 2007). Future work will involve automati-
cally generating context sensitive language models
(Lemon and Gruenstein, 2004).
2.4 ADT GUI
As mentioned above, the prototype ADT GUI can
be used to define system prompts and add likely
user responses to the grammar. Figure 3 shows the
developer associating ?spotter? phrases with sub-
tasks in the BPM. Here the developer is associating
the phrases ?hotels, hotel, stay, room, night, sleep?
and ?rooms? with the hotels task. This means that,
for example, if the user says ?I need a place to
stay?, the hotel-booking BPM will be triggered.
Note that multi-word phrases may also be defined.
The defined spotters are automatically compiled
into the GF grammar for parsing and speech recog-
nition. By default all the lexical entries for answer-
types for the subtasks will already be present as
Figure 3: Example: using the ADT GUI to define
?spotter? phrases for different BPM subtasks
spotter phrases. ADT also checks for possible am-
biguities, for example whether ?pizza? is a spot-
ter for both cuisine type for a restaurant task and
food type for a shopping task, and it uses clarifica-
tion sub-dialogues to resolve them at runtime.
Figure 4 shows the developer?s overview of the
subtasks of a BPM, in this case hotel information.
The developer can navigate this representation and
edit it to define prompts and manipulate the asso-
ciated databases.
Figure 4: Sub-dialogue structure generated from
the Hotel booking BPM
Figure 5 shows the developer specifying the
required linguistic information to automate the
ask price subtask of the hotels BPM. Here the de-
veloper specifies the system prompt for the infor-
mation ?Do you want something cheap or expen-
sive??; a phrase for implicit confirmation of pro-
vided values ?a [X] hotel?, where [X] is the seman-
tics of the speech recognition hypothesis for the
user input; and a clarifying phrase for this subtask
163
Figure 5: Example: using ADT to define prompts,
answer sets, and database mappings for the
ask price subtask of the BPM in Figure 4
?Do you mean the hotel price?? for use when dis-
ambiguating between two or more tasks. The de-
veloper also specifies here the answer type that will
resolve the system prompt. There are many pre-
defined answer-types extracted from the databases
associated with the BPM, and the developer can
select and/or edit these. Optionally, they can give
additional example phrases that users might say
to answer the prompt, and these are automatically
added to the GF grammar.
2.5 Usability
Several demonstration systems have been built us-
ing ADT with an average development time of un-
der an hour. However, our planned evaluation will
test the ability of novice users, with some knowl-
edge of BPMs and databases, to iteratively develop
their own ISU dialogue systems.
3 Summary
This paper describes the Advanced Dialogue Tools
for creating Information State Update based dia-
logue systems automatically from Business User
Resources such as BPMs and databases. The tools
include automatic generation of grammars for ro-
bust interpretation of spontaneous speech, and uses
the application databases and BPMs to generate
lexical entries and grammar rules for speech recog-
nition language modelling. We also demonstrate
an easy-to-use prototype interface that allows the
user to easily and quickly modify aspects of the
dialogue, thus eliminating the need for third party
service providers. This paper describes ADT, its
main components, and some of the research issues
involved in its development.
4 Acknowledgement
This project is funded by a Scottish Enterprise
Proof of Concept Grant (project number 8-ELM-
004).
References
Aylett, Matthew P. and Christopher J. Pidcock. 2007.
The cerevoice characterful speech synthesiser sdk.
In AISB, pages 174?8.
Lemon, Oliver and Alexander Gruenstein. 2004. Mul-
tithreaded context for robust conversational inter-
faces: context-sensitive speech recognition and in-
terpretation of corrective fragments. ACM Trans-
actions on Computer-Human Interaction (ACM
TOCHI), 11(3):241? 267.
Lemon, Oliver, Kallirroi Georgila, James Henderson,
and Matthew Stuttle. 2006. An ISU dialogue system
exhibiting reinforcement learning of dialogue poli-
cies: generic slot-filling in the TALK in-car system.
In Proceedings of EACL, pages 119?122.
Lemon, Oliver. 2004. Context-sensitive speech recog-
nition in Information-State Update dialogue systems:
results for the grammar switching approach. In Pro-
ceedings of the 8th Workshop on the Semantics and
Pragmatics of Dialogue, CATALOG?04, pages 49?
55.
Nuance, 2002. http://www.nuance.com. As of 1 Feb
2002.
Ranta, A. 2004. Grammatical framework. a type-
theoretical grammar formalism. Journal of Func-
tional Programming, 14(2):145?189.
Seneff, Stephanie. 2002. Response Planning and Gen-
eration in the Mercury Flight Reservation System.
Computer Speech and Language, 16.
Taylor, P., A. Black, and R. Caley. 1998. The architec-
ture of the the Festival speech synthesis system. In
Third International Workshop on Speech Synthesis,
Sydney, Australia.
Young, Steve. 1995. Large vocabulary continuous
speech recognition: A review. In Proceedings of
the IEEE Workshop on Automatic Speech Recogni-
tion and Understanding, pages 3?28.
Young, Steve. 2007. ATK: An Application Toolkit
for HTK, Version 1.6. Technical report, Cambridge
University Engineering Department.
164
DUDE: a Dialogue and Understanding Development Environment,
mapping Business Process Models to Information State Update dialogue
systems
Oliver Lemon and Xingkun Liu
School of Informatics
University of Edinburgh
 
olemon,xliu4  @inf.ed.ac.uk
Abstract
We demonstrate a new development environ-
ment1 ?Information State Update? dialogue
systems which allows non-expert developers
to produce complete spoken dialogue sys-
tems based only on a Business Process Model
(BPM) describing their application (e.g. bank-
ing, cinema booking, shopping, restaurant in-
formation). The environment includes au-
tomatic generation of Grammatical Frame-
work (GF) grammars for robust interpretation
of spontaneous speech, and uses application
databases to generate lexical entries and gram-
mar rules. The GF grammar is compiled to
an ATK or Nuance language model for speech
recognition. The demonstration system allows
users to create and modify spoken dialogue
systems, starting with a definition of a Busi-
ness ProcessModel and ending with a working
system. This paper describes the environment,
its main components, and some of the research
issues involved in its development.
1 Introduction: Business Process
Modelling and Contact Centres
Many companies use ?business process models?
(BPMs) to specify communicative (andmany other) ac-
tions that must be performed in order to complete vari-
ous tasks (e.g. verify customer identity, pay a bill). See
for example BPEL4WS 2 (Andrews, 2003). These rep-
resentations specify states of processes or tasks, transi-
tions between the states, and conditions on transitions
(see e.g. the cinema booking example in figure 1). Typ-
ically, a human telephone operator (using a presenta-
tion of a BPM on a GUI) will step through these states
with a customer, during a telephone interaction (e.g. in
a contact centre), in order to complete a business pro-
cess. Note, however, that BPM representations do not
1This research is supported by Scottish Enterprise under
the Edinburgh-Stanford Link programme. We thank Graham
Technology for their collaboration.
2Business Process Execution Language for Web Services.
traditionally model dialogue context, so that (as well as
speech recognition, interpretation, and production) the
human operator is responsible for:
 contextual interpretation of incoming speech
 maintaining and updating dialogue context
 dialogue strategy (e.g. implicit/explicit confirma-
tion, initiative management).
Figure 1: Part of an example Business Process Model
(cinema booking) in the GT-X7 system (Graham Tech-
nology plc, 2005) (version 1.8.0).
A major advantage of current BPM systems (as well
as their support for database access and enterprise sys-
tem integration etc.) is their graphical development
and authoring environments. See for example figure
1 from the GT-X7 system (Graham Technology plc,
2005), version 1.8.0. This shows part of a BPM for a
cinema booking process. First (top left ?introduction?
node) the caller should hear an introduction, then (as
long as there is a ?ContinueEvent?) they will be asked
for the name of a cinema (?cinemaChoice?), and then
for the name of a film (?filmChoice?) and so on until
the correct cinema tickets are payed for.
These systems allow non-experts to construct, mod-
ify, and rapidly deploy process models and the result-
ing interactions, including interactions with back-end
99
databases. For example, a manager may decide (after
deployment of a banking application) that credit should
now only be offered to customers with a credit rating of
5 or greater, and this change can be made simply by re-
vising a condition on a state transition, presented as an
arc in a process diagram. Thus the modelling environ-
ment allows for easy specification and revision of in-
teractions. The process models are also hierarchical, so
that complex processes can be built from nested com-
binations of simple interactions. By using these sorts
of graphical tools, non-experts can deploy and man-
age complex business processes to be used by thou-
sands of human contact centre operatives. However,
many of these interactions are mundane and tedious for
humans, and can easily be carried out by automated
dialogue systems. We estimate that around 80% of
contact-centre interactions involve simple information-
gathering dialogues such as acquiring customer con-
tact details. These can be handled robustly by Infor-
mation State Update (ISU) dialogue systems (Larsson
and Traum, 2000; Bos et al, 2003). Our contribution
here is to allow non expert developers to build ISU sys-
tems using only the BPMs and databases that they are
already familiar with, as shown in figure 2.
Figure 2: The DUDE development process
1.1 Automating Contact Centres with DUDE
Automation of contact centre interactions is a realis-
tic aim only if state-of-the art dialogue management
technology is employed. Currently, several compa-
nies are attempting to automate contact centers via sim-
ple speech-recognition-based interfaces using Voice
XML. However, this is much like specification of dia-
logue managers using finite state networks, a technique
which is known to be insufficient for flexible dialogues.
The main problem is that most traditional BPM sys-
tems lack a representation of dialogue context.3 Here
we show how to elaborate business process models
with linguistic information of various types (e.g. how
to generate appropriate clarification questions), and we
show an ISU dialogue management component, which
tracks dialogue context and takes standard BPMs as in-
put to its discourse planner. Developers can now make
use of the dialogue context (Information State) using
DUDE to define process conditions that depend on IS
features (e.g. user answer, dialogue-length, etc.).
3Footnote: The manufacturer of the GT-X7 system (Gra-
ham Technology plc, 2005) has independently created the
agent247(TM) Dialogue Modelling component with dynamic
prompt and Grammar generation for Natural Language Un-
derstanding.
Customers are now able to immediately declare their
goals (?I want to change my address?) rather than hav-
ing to laboriously navigate a series of multiple-choice
options. This sort of ?How may I help you?? sys-
tem is easily within current dialogue system expertise
(Walker et al, 2000), but has not seen widespread com-
mercial deployment. Another possibility opened up by
the use of dialogue technology is the personalization
of the dialogue with the customer. By interacting with
a model of the customer?s preferences a dialogue in-
terface is able to recommend appropriate services for
the customer (Moore et al, 2004), as well as modify its
interaction style.
2 DUDE: a development environment
DUDE targets development of flexible and robust ISU
dialogue systems from BPMs and databases. Its main
components are:
 A graphical Business Process Modelling Tool
(Graham Technology plc, 2005) (java)
 DIPPER generic dialogue manager (Bos et al,
2003) (java or prolog)
 MySQL databases
 a development GUI (java), see section 2.2
The spoken dialogue systems produced by DUDE all
run using the Open Agent Architecture (OAA) (Cheyer
and Martin, 2001) and employ the following agents in
addition to DIPPER:
 Grammatical Framework (GF) parser (Ranta,
2004) (java)
 BPM agent (java) and Database agent (java)
 HTK speech recognizer (Young, 1995) using ATK
(or alternatively Nuance)
 Festival2 speech synthesizer (Taylor et al, 1998)
We now highlight generic dialogue management, the
DUDE developer GUI, and the use of GF.
2.1 DIPPER and generic dialogue management
Many sophisticated research systems are developed for
specific applications and cannot be transferred to an-
other, even very similar, task or domain. The prob-
lem of components being domain specific is espe-
cially severe in the core area of dialogue manage-
ment. For example MIT?s Pegasus and Mercury sys-
tems (Seneff, 2002) have dialogue managers which use
approximately 350 domain-specific hand-coded rules
each. The sheer amount of labor required to con-
struct systems prevents them from being more widely
and rapidly deployed. Using BPMs and related au-
thoring tools to specify dialogue interactions addresses
this problem and requires the development of domain-
general dialogue managers, where BPMs represent
application-specific information.
100
We have developed a generic dialogue manager
(DM) using DIPPER. The core DM rules cover mixed
initiative dialogue for multiple tasks (e.g. a BPM with
several sub-processes), explicit and implicit confirma-
tion, help, restart, repeat, and quit commands, and
presentation and refinement of database query results.
This is a domain-neutral abstraction of the ISU dia-
logue managers implemented for the FLIGHTS and
TALK systems (Moore et al, 2004; Lemon et al,
2006).
The key point here is that the DM consults the BPM
to determinewhat task-based steps to take next (e.g. ask
for cinema name), when appropriate. Domain-general
aspects of dialogue (e.g. confirmation and clarification
strategies) are handled by the core DM. Values for con-
straints on transitions and branching in the BPM (e.g.
present insurance option if the user is business-class)
are compiled into domain-specific parts of the Informa-
tion State. We use an XML format for BPMs, and com-
pile them into finite state machines (the BPM agent)
consulted by DIPPER for task-based dialogue control.
2.2 The DUDE developer GUI
Figures 3 to 5 show different screens from the DUDE
GUI for dialogue system development. Figure 3 shows
the developer associating ?spotter? phrases with sub-
tasks in the BPM. Here the developer is associating
the phrases ?hotels, hotel, stay, room, night, sleep? and
?rooms? with the hotels task. This means that, for
example, if the user says ?I need a place to stay?, the
hotel-booking BPM will be triggered. (Note that multi-
word phrases may also be defined). The defined spot-
ters are automatically compiled into the GF grammar
for parsing and speech recognition. By default all the
lexical entries for answer-types for the subtasks will al-
ready be present as spotter phrases. DUDE checks for
possible ambiguities (e.g. if ?sushi? is a spotter for both
cuisine type for a restaurant subtask and food type for
a shopping process) and uses clarification subdialogues
to resolve them at runtime.
Figure 3: Example: using DUDE to define ?spotter?
phrases for different BPM subtasks
Figure 4 shows the developer?s overview of the sub-
tasks of a BPM (here, hotel information). The devel-
oper can navigate this representation and edit it to de-
fine prompts and manipulate the associated databases.
Figure 4: A Business Process Model viewed by DUDE
Figure 5 shows the developer specifying the required
linguistic information to automate the ?ask price? sub-
task of the hotel-information BPM. Here the developer
specifies the system prompt for the information (?Do
you want something cheap or expensive??), a phrase
for implicit confirmation of provided values (here ?a
[X] hotel?, where [X] is the semantics of the ASR hy-
pothesis for the user input), and a clarifying phrase for
this subtask (e.g. ?Do you mean the hotel price??) for
use when disambiguating between 2 or more tasks. The
developer also specifies here the answer type that will
resolve the system prompt. There are many predefined
answer-types extracted from the databases associated
with the BPMs, and the developer can select and/or edit
these. They can also give additional (optional) example
phrases that users might employ to answer the prompt,
and these are automatically added to the GF grammar.
Figure 5: Example: using DUDE to define prompts,
answer sets, and database mappings for the ?ask price?
subtask of the BPM in figure 4
A similar GUI allows the developer to specify
101
database access and result presentation phases of the
dialogue, if they are present in the BPM.
2.3 The Grammatical Framework: compiling
grammars from BPMs, DBs, and example sets
GF (Ranta, 2004) is a language for writing multilin-
gual grammars, on top of which various applications
such as machine translation and human-machine inter-
action have been built. A GF grammar not only defines
syntactic well-formedness, but also semantic content.
Using DUDE, system developers do not have to
write a single line of GF grammar code. We have de-
veloped a core GF grammar for information-seeking
dialogues (this supports a large fragment of spoken En-
glish, with utterances such as ?Uh I think I think I want
a less expensive X and uhhh a Y on DATE please? and
so on). In addition, we compile all database entries and
their properties into the appropriate ?slot-filling? parts
of the GF grammar for each specific BPM.
For example, a generated GF rule is:
Bpm generalTypeRule 4:
town info hotels name->Utt=->   s = np.s  .
This means that all hotel names are valid utterances,
and it is generated because ?name? is a DB field for
the subtask ?hotels? in the ?town info? BPM.
Finally, we allow developers to give example sen-
tences showing how users might respond to system
prompts. If these are not already covered by the exist-
ing grammar we automatically generate rules to cover
them. Finally GF, is a robust parser ? it skips all dis-
fluencies and unknown words to produce an interpre-
tation of the user input if one exists. Note that the
GF grammars developed by DUDE can be compiled to
speech-recognition language models for both Nuance
and HTK/ATK (Young, 1995).
2.4 Usability
We have built several demonstration systems using
DUDE. We are able to build a new system in under
an hour, but our planned evaluation will test the abil-
ity of novice users (with some knowledge of BPMs
and databases) to iteratively develop their own ISU di-
alogue systems.
3 Summary
We demonstrate a development environment for ?Infor-
mation State Update? dialogue systems which allows
non-expert developers to produce complete spoken di-
alogue systems based only on Business Process Models
(BPM) describing their applications. The environment
includes automatic generation of Grammatical Frame-
work (GF) grammars for robust interpretation of spon-
taneous speech, and uses the application databases to
generate lexical entries and grammar rules. The GF
grammar is compiled to an ATK language model for
speech recognition (Nuance is also supported). The
demonstration system allows users to create and mod-
ify spoken dialogue systems, starting with a definition
of a Business Process Model (e.g. banking, cinema
booking, shopping, restaurant information) and ending
with a working system. This paper describes the en-
vironment, its main components, and some of the re-
search issues involved in its development.
References
Tony Andrews. 2003. Business process execution
language for web services, version 1.1, http://www-
106.ibm.com/developerworks/library/ws-bpel/.
Technical report, IBM developer works.
Johan Bos, Ewan Klein, Oliver Lemon, and Tetsushi
Oka. 2003. DIPPER: Description and Formalisation
of an Information-StateUpdate Dialogue SystemAr-
chitecture. In 4th SIGdial Workshop on Discourse
and Dialogue, pages 115?124, Sapporo.
Adam Cheyer and David Martin. 2001. The Open
Agent Architecture. Journal of Autonomous Agents
and Multi-Agent Systems, 4(1/2):143?148.
Graham Technology plc. 2005. GT-X7 v.1.8.0
from Graham Technology plc [without the
agent247(TM) Dialogue and NLP Engine].
www.grahamtechnology.com.
Staffan Larsson and David Traum. 2000. Information
state and dialogue management in the TRINDI Dia-
logue Move Engine Toolkit. Natural Language En-
gineering, 6(3-4):323?340.
Oliver Lemon, Kallirroi Georgila, James Henderson,
andMatthew Stuttle. 2006. An ISU dialogue system
exhibiting reinforcement learning of dialogue poli-
cies: generic slot-filling in the TALK in-car system.
In Proceedings of EACL, page to appear.
Johanna Moore, Mary Ellen Foster, Oliver Lemon, and
Michael White. 2004. Generating tailored, compar-
ative descriptions in spoken dialogue. In The 17th
International FLAIRS Conference (Florida Artifical
Intelligence Research Society).
A. Ranta. 2004. Grammatical framework. a type-
theoretical grammar formalism. Journal of Func-
tional Programming, 14(2):145?189.
Stephanie Seneff. 2002. Response Planning and Gen-
eration in the Mercury Flight Reservation System.
Computer Speech and Language, 16.
P. Taylor, A. Black, and R. Caley. 1998. The architec-
ture of the the Festival speech synthesis system. In
Third International Workshop on Speech Synthesis,
Sydney, Australia.
M. A. Walker, I. Langkilde, J. Wright, A. Gorin, and
D. Litman. 2000. Learning to Predict Problematic
Situations in a Spoken Dialogue System: Experi-
ments with How May I Help You? In Proceedings
of the NAACL 2000, Seattle.
Steve Young. 1995. Large vocabulary continuous
speech recognition: A review. In Proceedings of
the IEEE Workshop on Automatic Speech Recogni-
tion and Understanding, pages 3?28.
102
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 148?151,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
Automatic Generation of Information State Update Dialogue Systems that
Dynamically Create Voice XML, as Demonstrated on the iPhone
Helen Hastie, Xingkun Liu and Oliver Lemon
School of Informatics
University of Edinburgh
{hhastie,xliu4,olemon}@inf.ed.ac.uk
Abstract
We demonstrate DUDE1 (Dialogue
and Understanding Development En-
vironment), a prototype development
environment that automatically generates
dialogue systems from business-user
resources and databases. These generated
spoken dialogue systems (SDS) are then
deployed on an industry standard Voice
XML platform. Specifically, the deployed
system works by dynamically generating
context-sensitive Voice XML pages. The
dialogue move of each page is determined
in real time by the dialogue manager,
which is an Information State Update
engine. Firstly, we will demonstrate the
development environment which includes
automatic generation of speech recogni-
tion grammars for robust interpretation of
spontaneous speech, and uses the appli-
cation database to generate lexical entries
and grammar rules. A simple graphical
interface allows users (i.e. developers) to
easily and quickly create and the modify
SDS without the need for expensive
service providers. Secondly, we will
demonstrate the deployed system which
enables participants to call up and speak
to the SDS recently created. We will also
show a pre-built application running on
the iPhone and Google Android phone for
searching for places such as restaurants,
hotels and museums.
1Patent Pending
1 Introduction
With the advent of new mobile platforms such as
the iPhone and Google Android, there is a need for
a new way to interact with applications and search
for information on the web. Google Voice Search
is one such example. However, we believe that
this simple ?one-shot? search using speech recog-
nition is not optimal for the user. A service that
allows the user to have a dialogue via their phone
opens up a wider set of possibilities. For exam-
ple, the user may be visiting a foreign city and
would like to have a discussion about the types
of restaurants, their cuisine, their price-range and
even ask for recommendations from the system or
their friends on social networking sites. The Di-
alogue Understanding Development Environment
or DUDE makes this possible by providing a flex-
ible, natural, mixed initiative dialogue using an in-
formation state update dialogue engine (Bos et al,
2003).
Currently, if a company wishes to deploy such
a spoken dialogue system, they have to employ
a costly service provider with a long turn around
time for any changes to the system, even minor
ones such as a special promotion offer. In addi-
tion, there is steep competition on application sites
such as Google Market Place and Apple App Store
which are populated with very cheap applications.
DUDE?s Development Environment takes existing
business-user resources and databases and auto-
matically generates the dialogue system. This re-
duces development time and, therefore, costs and
opens up the technology to a wider user-base. In
addition, the DUDE environment is so easy to use
that it gives the control back into the business-user
and away from independent services providers.
In this paper, we describe the architecture and
148
technology of the DUDE Development Environ-
ment and then discuss how the deployed system
works on a mobile platform.
2 The DUDE Development Environment
Figure 1 shows the DUDE Development Envi-
ronment architecture whereby the main algorithm
takes the business-user resources and databases as
input and uses these to automatically generate the
spoken dialogue system which includes a Voice
XML generator. Advantages of using business-
user resources such as Business Process Mod-
els (BPM) (Williams, 1967) include the fact that
graphical interfaces and authoring environments
are widely available (e.g. Eclipse). In addition,
business-user resources can contain a lot of addi-
tional information as well as call flow including
context, multi-media and multiple customer inter-
actions.
Figure 1: The DUDE Architecture
2.1 Spoken Dialogue System Generation
Many sophisticated research systems are devel-
oped for specific applications and cannot be eas-
ily transferred to another, even very similar task or
domain. The problem of components being do-
main specific is especially prevalent in the core
area of dialogue management. For example MIT?s
Pegasus and Mercury systems (Seneff, 2002) have
dialogue managers (DM) that use approximately
350 domain-specific hand-coded rules each. The
sheer amount of labour required to construct sys-
tems prevents them from being more widely and
rapidly deployed. We present a solution whereby
BPMs and related authoring tools are used to spec-
ify domain-specific dialogue interactions which
are combined with domain-general dialogue man-
agers. Specifically, the DM consults the BPM to
determine what task-based steps to take next, such
as asking for price range after establishing pre-
ferred cuisine type. General aspects of dialogue,
such as confirmation and clarification strategies,
are handled by the domain-general DM. Values
for constraints on transitions and branching in the
BPM, for example ?present insurance offer if the
user is business-class?, are compiled into domain-
specific parts of the Information State. XML for-
mat is used for BPMs, and they are compiled into
finite state machines consulted by the spoken dia-
logue system. The domain-general dialogue man-
ager was mostly abstracted from the TALK system
(Lemon et al, 2006).
Using DUDE, developers do not have to write
a single line of grammar code. There are three
types of grammars: (1) a core grammar, (2) a
grammar generated from the database and BPM,
and (3) dynamically generated grammars created
during the dialogue. The core grammar (1) was
developed to cover basic information-seeking in-
teractions. In addition (2), the system com-
piles relevant database entries and their proper-
ties into the appropriate ?slot-filling? parts of a
SRGS GRXML (Speech Recognition Grammar
Specification) grammar for each specific BPM
node. Task level grammars are used to allow a
level of mixed initiative, for example, if the sys-
tem asks ?what type of cuisine?? the user can
reply with cuisine and also any other slot type,
such as, ?cheap Italian?. The dynamically gen-
erated grammars (3), such as for restaurants cur-
rently being recommended, minimizes grammar
size and makes the system more efficient. In ad-
dition to the above-mentioned grammars, devel-
opers are able to provide task spotter phrases and
synonyms reflecting how users might respond by
using the DUDE Development Environment. If
these are not already covered by the existing gram-
mar, DUDE automatically generates rules to cover
them.
The generated SRGS GRXML grammars are
used to populate the Voice XML pages and conse-
quently used by the Voice XML Platform Speech
recogniser. In this case, we deploy our system to
the Voxeo Platform (http://www.voxeo.com). As
well as the W3C standard SRGS GRXML, DUDE
is able to generate alternative grammar specifica-
tions such as SRGS ABNF (Augmented Backus-
Naur Form), JSGF ABNF (Java Speech Grammar
Format) and Nuance?s GSL (Grammar Specifica-
149
Figure 2: Example: using the DUDE Development Environment to define spotter phrases and other
information for the different BPM tasks
tion Language).
2.2 The Development Environment
As mentioned above, the DUDEDevelopment En-
vironment can be used to define system prompts
and add task spotter phrases and synonyms to the
grammars. Figure 2 shows the GUI with the BPM
on the left hand side and the properties pane for
the restaurants task on the right hand side. In this
pane the developer can define the system prompt,
the information to be presented to the user and the
spotter phrases. Here the developer is associating
the phrases ?restaurants, restaurant, somewhere to
eat....? with the restaurant task. This means that
if the user says ?I want somewhere to eat?, the
restaurant part of the BPM will be triggered. Note
that multi-word phrases may also be defined. The
defined spotters are automatically compiled into
the grammar for parsing and speech recognition.
By default all the lexical entries for answer-types
for the subtasks will already be present as spotter
phrases. DUDE checks for possible ambiguities,
for example if ?pizza? is a spotter for both cui-
sine type for a restaurant task and food type for a
shopping task, the system uses a clarification sub-
dialogue to resolve them at runtime.
Figure 3 shows the developer specifying the re-
quired linguistic information to automate the cui-
sine subtask of the restaurants task. Here the de-
veloper specifies the system prompt ?What type
of cuisine do you want?? and a phrase for im-
plicit confirmation of provided values, e.g. ?a [X]
restaurant?, where [X] is a variable that will be
replaced with the semantics of the speech recogni-
tion hypothesis for the user input. The developer
also specifies here the answer type that will resolve
the system prompt. There are predefined answer-
types extracted from the databases, and the devel-
oper can select and/or edit these, adding phrases
and synonyms. In addition, they have the ability
to define their own answer-types.
Figure 3: Example: using the DUDE Develop-
ment Environment to define prompts, answer sets,
and database mappings for the cuisine subtask
150
3 Deployment of the Generated Spoken
Dialogue System
The second part of the demonstration shows
a pre-built multimodal application running on
the iPhone (http://www.apple.com) and Google
Android phone (http://code.google.com//android).
This application allows the user to have a dialogue
about places of interest using The List website
(http://www.list.co.uk). Figure 4 shows screen-
shots of the iPhone, firstly with The List home-
page and then a page with content on Bar Roma,
an ?italian restaurant in Edinburgh? as requested
by the user through spoken dialogue.
Figure 4: DUDE-generated iPhone List Applica-
tion pushing relevant web content
Figure 5 shows the architecture of this system
whereby the DUDE server runs the spoken dia-
logue system (as outputted from the DUDEDevel-
opment Environment). This system dynamically
generates Voice XML pages whose dialogue move
and grammar is determined by the Information
State Update Dialogue Model. These Voice XML
pages are sent in real time to the Voice XML plat-
form (in our case Voxeo) which the user talks to by
placing a regular phone call. In addition, DUDE
communicates the relevant URL via a server con-
nection.
4 Summary
This paper describes a demonstration of the
DUDE Development Environment and its result-
ing spoken dialogue systems as deployed on a mo-
bile phone, specifically the iPhone and Google
Android. With the emergence of web-enabled
smart-phones, a new and innovative interactive
method is needed that combines web-surfing and
Figure 5: Architecture of deployed DUDE Appli-
cation on a mobile phone (e.g. the iPhone)
dialogue in order to get the user exactly the infor-
mation required in real time.
5 Acknowledgement
This project is funded by a Scottish Enterprise
Proof of Concept Grant (project number 8-ELM-
004). We gratefully acknowledge The List for giv-
ing us data for our prototype application.
References
Johan Bos, Ewan Klein, Oliver Lemon, and Tetsushi
Oka. 2003. DIPPER: Description and Formalisa-
tion of an Information-State Update Dialogue Sys-
tem Architecture. In 4th SIGdial Workshop on Dis-
course and Dialogue, pages 115?124, Sapporo.
Adam Cheyer and David Martin. 2001. The Open
Agent Architecture. Journal of Autonomous Agents
and Multi-Agent Systems, 4(1/2):143?148.
Oliver Lemon, Kallirroi Georgila, James Henderson,
and Matthew Stuttle. 2006. An ISU dialogue sys-
tem exhibiting reinforcement learning of dialogue
policies: generic slot-filling in the TALK in-car sys-
tem. In Proceedings of EACL, pages 119?122.
Stephanie Seneff. 2002. Response Planning and Gen-
eration in the Mercury Flight Reservation System.
Computer Speech and Language, 16.
S Williams. 1967. Business process modeling im-
proves administrative control. Automation, pages
44?50.
151
The Queen?s Agents: Using Collaborating Object-Based Dialogue Agents  
in the Queen?s Communicator 
Ian O?Neill, Philip Hanna, Xingkun Liu 
School of Computer Science  
Queen?s University 
Belfast BT7 1NN, N. Ireland 
{i.oneill, p.hanna, 
xingkun.liu}@qub.ac.uk 
Michael McTear 
School of Computing and 
Mathematics 
University of Ulster 
Jordanstown, BT37 0QB, N. Ireland 
mf.mctear@ulster.ac.uk 
 
Abstract 
A dialogue manager provides the decision 
making at the heart of a spoken dialogue 
system. In an object-oriented approach to 
dialogue management, generic behaviour, such 
as confirming new or modified information that 
has been supplied by the user, is inherited by 
more specialised classes.  These specialised 
classes either encapsulate behaviour typical of a 
particular business domain (service agents) or 
make available dialogue abilities that may be 
required in many business domains (support 
agents).  In this paper we consider the interplay 
between the agents? generic and specialised 
behaviour and consider the manner in which 
service and support agents collaborate within 
and across their respective groups. 
1 Object-orientation and cross-domain, 
mixed initiative dialogue 
Object-orientation provides an intuitive 
separation of, on the one hand, inheritable generic 
functionality and, on the other hand, domain-
specific, specialized functionality that is supported 
by the generic elements of the system.  Applied to 
the area of natural language dialogue, this has 
enabled us to create a generic, automated dialogue 
confirmation strategy ? based on confirmation 
statuses and discourse pegs (see Section 3.3) ? 
which supports domain-specific strategies to gather 
and provide information relating to particular 
transactions ? for example booking a hotel or 
finding out about cinema times.  Heuristics, or 
expert rules, specific to each transaction domain, 
prompt the user for significant missing information 
or assist the user by providing choices from a 
database (e.g. names of available hotels). 
Thus, while our generic confirmation strategy 
ensures that information newly supplied by the 
user is confirmed, and information changed is 
reconfirmed, and so on, the nature of that 
information may differ significantly from domain 
to domain.  Likewise the system may respond to 
confirmed information in quite different ways 
depending on the domain ? as it either completes a 
domain-specific transaction or attempts to elicit 
important missing information from the user.   
In the Queen?s Communicator dialogue system, 
expertise for different transaction domains is 
encapsulated within corresponding expert classes 
or ?agents?.  We have used this to our advantage by 
enabling the system to transfer between domains 
either at the user?s or the system?s initiative ? in a 
mixed initiative dialogue either the user or the 
system may introduce new topics. Agents are able 
to announce their abilities to the system at large, or 
indeed to the user.  Thus, when key words or 
phrases uttered by the user indicate that the topic 
of conversation has turned, for example, from 
accommodation booking to payment, the system?s 
DomainSpotter (see Section 4) can ask the agents 
if any of them deal with payments.  The most 
suitable agent is then given the task of managing 
the specialised subdialogue.  
2 Spoken dialogue management 
A spoken dialogue system typically comprises a 
number of components: an automatic speech 
recogniser, a semantic parser, a dialogue manager 
(DM), a database ?back-end?, a natural language 
generator, and a text-to-speech engine.  The focus 
of our present research is the development of an 
object-based DM that can support mixed initiative 
dialogues that involve a number of business 
domains.  
Our DM operates within the DARPA1 
Communicator architecture, which is based on the 
Galaxy hub ? a software router  developed by the 
Spoken Language Systems group at MIT  
(www.sls.csail.mit.edu/sls/technologies/galaxy.shtml) 
and subsequently released as an open source 
package in collaboration with the MITRE 
Corporation (fofoca.mitre.org).  In the ?Queen?s 
Communicator? dialogue system, our newly 
developed DM interacts with a number of off-the-
shelf components. For semantic parsing we use 
Phoenix (W. Ward, 1994), available from the 
                                                     
1 Defense Advanced Research Projects Agency 
University of Colorado?s ?CU Communicator? 
download (communicator.colorado.edu).  For 
recognition we use the Microsoft English ASR 
Version 5 Engine as supplied with Windows XP.  
Synthesised speech is provided by Festival 
(www.cstr.ed.ac.uk/projects/festival/), also taken 
from the CU download.  Figure 1 shows a typical 
Communicator configuration. 
 The DM itself embodies decision-making 
similar to that of a human interlocutor as it queries, 
responds to and informs the user. Moreover, in 
mixed initiative dialogues that deal with more than 
one domain (e.g. enquiries about accommodation 
and events, and supporting exchanges about 
payment and addresses), the system has the 
additional task of identifying the (ongoing) topic of 
the dialogue and applying appropriate dialogue 
management expertise. 
3 Object-based dialogue agents 
3.1 A multi-agent approach to dialogue 
management 
In order to enable mixed initiative interactions 
across domains, we model the system?s behaviour 
as a collaboration between the cohort of 
implemented agents.  Other developers have also 
adopted an agent-based approach to dialogue, 
though sometimes dialogue agents each perform 
very simple tasks rather than engage in extensive 
discourse: in (Turunen and Hakulinen, 2001) for 
example, simple generic error-handling agents, 
based on Java and XML, ask the user to repeat 
misunderstood input.  In our case an agent is a 
specialist in a particular transactional area ? e.g. 
booking accommodation or eliciting an address.  
An agent uses its own domain-specific ?expert-
rules? to elicit information (e.g. information for 
making a hotel booking) that is then stored in a 
specialised dialogue frame.  Each agent thus 
encapsulates a skillset for a substantial dialogue or 
subdialogue.     
Like the Communicator team at Carnegie Mellon 
University, we view the dialogue product (the 
knowledge to be elicited) as a tree-like structure 
(Rudnicky and Xu, 1999) ? though for us the nodes 
are complete dialogue frames rather than 
individual data items.  In the Queen?s 
Communicator the discourse structure evolves 
dynamically as agents are selected by a 
DomainSpotter, in the light of the user?s utterances 
or as a consequence of the agents? own rules.  It is 
this process, rather than an overarching dialogue 
plan or agenda, that drives the discourse forward, 
sometimes across domain boundaries.  We do, 
however, maintain an ExpertFocusStack, which 
contains, in sequence, the name of the agent that is 
currently handling the dialogue and the names of 
agents that have last handled the dialogue and have 
unfinished business: this allows the system to 
quickly identify the current handler and to pass 
control back, once the current handling agent is 
finished. 
3.2 Inherited and domain-specific behaviour 
Our dialogue manager is implemented as a suite 
of Java classes (see Figure 2).  The object-based 
approach (Booch, 1994) (O?Neill and McTear, 
2000) has afforded us certain advantages.  The 
domain specialists or ?Experts? within our system 
? AccommodationExpert, TheatreExpert, 
CinemaExpert, CreditCardExpert, etc. ? all inherit 
generic dialogue handling skills from a 
DiscourseManager, whose role is to ensure that 
new information provided by the user is at least 
implicitly confirmed, and information that is 
changed or negated is subjected to more detailed, 
explicit confirmation (O?Neill and McTear, 2002) 
(O?Neill et al 2003).  The domain experts 
encapsulate specialised behaviour, which can be 
readily extended by additional classes.  There are 
two families of domain experts: 
y ?service agents? that provide front-line services 
to the user  ? like AccommodationExpert, 
whose behaviour emulates that of a human 
booking clerk, and 
y ?support agents? like CreditCardExpert that are 
able to elicit information required to complete 
one of the front-line service transactions. 
We refer to the corresponding discourse 
segments as ?service? and ?support? dialogues 
respectively.  By assigning the agents (and the 
corresponding dialogues) to one of two families we 
give ourselves the option of restricting user-led 
transitions between main and ancillary 
transactions. However, the overall objective of our 
implementation is to maintain a high degree of 
flexibility in the manner in which the system reacts 
to unsolicited user utterances. 
3.3 Using frames of information 
The agents, whether they provide service or 
support, collect and manipulate frames of 
Speech Recogniser
Natural Language
Semantic Parser
Dialogue Manager
Natural Language
Generator
Speech synthesiser
Database
Galaxy
hub
 
Figure 1. DARPA Communicator architecture. 
 
information related to their own sphere of 
competence.   The frames consist of Attribute 
objects, each of which stores:  
y the type and elicited value of a single piece of 
information (datum);  
y the confirmation status of the datum (e.g. 
new_for_system);  
y the level to which the datum has been 
confirmed (through repetition, or by the user?s 
affirmative response to a system prompt ? the 
level is represented by a simple numeric 
?peg?);  
y and the system intention regarding the datum 
(e.g. implicitly confirm new information; 
explicitly confirm information that has been 
negated; ask the user to specify information 
that is still required) (Heisterkamp and 
McGlashan, 1996). 
The Attribute objects thus give a multi-facetted 
view of each piece of information that it is being 
considered by the system.  The evolving domain-
specific (and thus generally agent-specific) frames 
of Attributes are maintained on a DiscourseStack 
within the DiscourseHistory object.  The agents 
use this stack to implement the inherited generic 
confirmation strategy. The frames of information 
are typically populated in the course of several 
discourse turns, as new or additional information is 
acquired from successive user-system interactions.   
Once it is handling a particular discourse segment, 
an agent uses its inherited confirmation strategy to 
compare the latest values in its current dialogue 
frame with the corresponding values and system 
intentions in the previous iteration of that frame.  
Thus the agent is able to determine which values 
have been confirmed (e.g. the user has not 
challenged an implicit confirmation request by the 
system) and which have been modified or negated. 
3.4 Applying expert rules 
In addition to its inherited confirmation 
strategies, each of the domain Experts, whether a 
service agent or a support agent, has its own expert 
rules, contained in one or more expert rule 
sequences.  Typically the expert rule sequences 
will be of one of two kinds: 
y ?user-focussed rules?, which determine the 
agent?s reaction to particular combinations of 
information supplied by the user ? must the 
system now ask a follow-up question, must it 
perform a database look-up, or can it conclude 
a transaction ? ? and  
y ?database-focussed rules?, which represent the 
agent?s dialogue furthering strategy when 
database queries based on user-supplied 
combinations of information fail: because of 
its access to database content, the system may 
be able to modify a user-supplied constraint 
and so formulate a database query that will 
succeed (e.g. the system might suggest a four-
star hotel if it cannot meet the user?s request 
for a five-star hotel in a particular locality.) 
These rules, encapsulated within the appropriate 
agent (e.g. AccommodationExpert), are applied to 
information that the agent has ?phrase-spotted? and 
placed in the appropriate dialogue frame (e.g. an 
AccommodationDialogueFrame). Sequences of 
rules, encapsulated within service and support 
agents and tested to see which rule can fire in the 
current discourse state, collectively embody the 
kinds of domain-specific behaviour that 
characterise a human expert. 
DiscourseHistory 
 
-- store generated dialog  
 frames 
-- contains 
UtteranceStore, 
InfoStore, and 
DiscourseStack 
* 
DialogServer 
 
-- provide Galaxy hub  
 interface 
DialogManager 
 
-- contains a number of  
 EnquiryExpert subclass  
 instances 
-- contains a DiscourseHistory  
 instance shared between  
 the instantiated experts. 
-- contains a DomainSpotter  
 instances to exercise high- 
 level control over experts. 
Discourse 
Manager 
-- implement generic  
    confirmation strategy 
 
EnquiryExpert 
 
-- generic processing  
 enquires 
-- enables an expert to  
 act as a service or  
 support agent 
 
DialogFrame 
 
-- provide generic dialog 
frame functionality 
 
Event 
DialogFrame 
 
-- event-specific dialog  
    frame 
Acco 
DialogFrame 
 
-- accommodation- 
    specific dialog frame 
Attribute 
 
-- individual dialog frame  
 attribute 
ExpertRuleSequence 
 
-- collection of related  
 expert rules 
 
DBRequest 
 
-- encapsulate expert  
  initiated DB request 
 
Accommodation 
Expert 
 
-- accommodation  
 enquiry expertise 
 
EventExpert 
 
-- domain-specific  
    processing for events 
TheatreExpert 
 
 
 
-- domain-specific theatre  
    enquiry expertise 
CinemaExpert 
 
 
 
-- domain-specific cinema  
 enquiry expertise 
1 1 
* 
Creates 
1 
1 1 * 
Invoice 
PaymentExpert 
 
 
-- domain-specific   
 cheque processing 
Cinema 
DialogFrame 
 
 
-- cinema-specific dialog   
    frame 
CreditCard 
PaymentExpert 
 
-- domain-specific credit- 
    card processing 
CreditCard 
DialogFrame 
 
 
-- credit-card specific  
    dialog frame 
Payment 
DialogFrame 
 
-- payment specific 
dialog frame 
PaymentExpert 
 
-- generic-payment  
 processing 
Theatre 
DialogFrame 
 
 
-- theatre-specific dialog  
    frame 
ExpertRule 
 
-- individual database-  
 or user-focussed rule 
 
1 
1 1 
* 
1 
* 1 
1 
Service Agent Hierarchy Support Agent Hierarchy Dialog Frame Hierarchy 
DomainSpotter 
 
-- determine and  
 maintain enquiry 
f
 
Figure 2: Class diagram of the dialogue manager. 
4 Finding the right agent 
4.1 Apppointing an initial handling agent 
To begin the dialogue, in order to identify the 
most appropriate ?handling agent?, the 
DomainSpotter supplies each service agent with 
the output of the semantic parse that represents the 
user?s utterance. As it attempts to find an initial 
handling agent, the DomainSpotter considers only 
service agents (like AccommodationExpert or 
CinemaExpert) and not support agents (like 
CreditCardExpert).  The service agents represent 
the primary transaction types (booking a hotel 
room, enquiring about a movie, etc.) that the 
system handles: the system is not, for example, 
intended to allow the user to process their credit 
account, though it may elicit credit card details in 
support of a service (a hotel booking for instance).  
Such restrictions help the system ground its 
primary functions with the user.  Each service 
agent scores the parse of the initial user utterance 
against the semantic categories that it can process 
(each agent has a range of integer values ? degrees 
of relevance ? that it will assign to different 
domain-specific parse tags) and returns the score to 
the DomainSpotter.  The service agent that scores 
highest is the one that the DialogManager asks to 
apply its domain-specific heuristics to the more 
detailed processing of the enquiry.  For example, 
an AccommodationExpert might score highest and 
so become handling agent if the user has been 
asking about hotels in Belfast.  Specialised agents 
give a higher score for specialised parser tags than 
generic agents.  For example, a user request ?I?d 
like to go to see Finding Nemo.? might parse as: 
event_enquiry:[Event_type].[Movies].FINDING 
NEMO. Although the EventExpert could award a 
score for event_enquiry, the CinemaExpert, as a 
child of EventExpert, would award a score not 
only for event_enquiry, but for Movies as well, and 
so would be the winner. 
4.2 Finding out what the system can do 
If the DomainSpotter is unable to identify a 
winning agent, it will ask the user to choose 
between the domains in closest contention.  
Indeed, if the user?s enquiry is so vague as to give 
no domain-related information (?I?d like to make 
an enquiry.?), the DomainSpotter will ask the user 
to choose from one of its highest level service 
agents: ?Please choose between event booking or 
accommodation booking.? ? the words in italics are 
actually provided by the service agents.  The 
DomainSpotter is in effect relaying to the user 
information that the system components know 
about themselves: it is part of the system?s design 
philosophy that higher level components are 
largely ignorant of the precise capabilities of lower 
level components. Similarly, if a service agent 
needs to avail of a support agent in a particular 
area, it tells the DomainSpotter to find it an expert 
that handles the particular specialism (payments, 
for instance): it does not name a specific expert 
object.  So that its area of expertise can be 
identified, each agent has, as one of its attributes, a 
vector of the specialisms it deals with.  The 
intention is that additional lower level expertise 
can be added to the system in such a way that 
higher level behaviour (i.e. requesting the 
expertise) remains unchanged.  Where more than 
one expert (e.g. CreditCardExpert and 
InvoiceExpert) can deal with the requested 
specialism (e.g. payments), the DomainSpotter 
asks the user to choose. 
4.3 Transferring control between service and 
support 
In order to maintain the enquiry focus we use an 
ExpertFocusStack in the DiscouseHistory.  Once 
an agent is selected to handle the current discourse 
segment, it is pushed on to the top of the stack.  
The agent then uses its expert rules to elicit all the 
information needed to complete its discourse 
segment: an AccommodationExpert, for example, 
will be looking for all information needed to 
complete an accommodation booking.  Depending 
on the rules it encapsulates, a service agent may 
require help from a support agent.  For example, if 
an AccommodationExpert has confirmed sufficient 
information to proceed with a reservation, it will 
request help from an agent whose specialism is 
payment, and the DomainSpotter will look for one   
Let us pursue this example further. The 
PaymentExpert is identified as an appropriate 
payment handler, and is placed above 
AccommodationExpert on the ExpertFocusStack.  
However, let us suppose that eliciting payment 
details first involves eliciting address details, and 
so the PaymentExpert in its turn asks the 
DomainSpotter to find it an agent specialising in 
address processing ? in this case the 
AddressExpert.  The AddressExpert now goes to 
the top of the ExpertFocusStack, above the 
PaymentExpert.  Just like any other agent the 
AddressExpert has its own rules that allow it to 
accept typical combinations of information 
supplied (prompted or unprompted) by the user 
and to ask appropriate follow-up questions for 
whatever information is still missing.  Once a 
support agent has all the information it needs, one 
of its rules will fire to ?pass control back?, along 
with a ?finished? message, to whatever agent was 
below it on the ExpertFocusStack.  The ?finished? 
agent is removed from the stack.  Thus 
AddressExpert will pass control back to 
PaymentExpert in this example, whose rules, if the 
user does not introduce a new topic, will continue 
to fire until all necessary payment information has 
been elicited and the payment subdialogue can be 
concluded ? at which point control is passed back 
to the AccommodationExpert. 
4.4 Dialogue frames and user-led focus shifts 
However, a mixed initiative dialogue manager 
needs to be able to cope with user-initiated shifts 
of discourse focus. For example, a user may supply 
address information unprompted while the 
system?s intention is first to elicit the information 
shown on the user?s credit card.  At present we 
permit transfer of dialogue control between service 
agents: a user may, for example, want to discuss an 
event booking more or less in parallel with making 
accommodation arrangements.  In order to ground 
the dialogue by eliciting information in a definite 
context, we impose some restrictions on user-
initiated shifts of focus between support dialogues, 
and between support and service dialogues.  
Dialogue frames are instrumental in implementing 
these policies. 
Dialogue frames help identify the support 
dialogues associated with each service dialogue: 
the specification of each frame type (e.g. an 
AccommodationDialogueFrame) indicates the type 
of each of its Attributes, some of which may 
themselves be links to other frames (e.g. a 
PaymentDialogueFrame).  Dialogue frames that 
are associated with service dialogues can be 
expanded into a tree-like structure by recursively 
traversing the various support frames that are 
linked to the service dialog frame.  For those 
frames which have already been in the discourse 
focus (i.e. frames representing dialogue tasks that 
have already been the subject of user-system 
interaction), this is a straightforward task.   
Additionally the frames of possible future handling 
agents can be predicted and included within the 
tree through the use of the DomainSpotter.  For 
example, at the outset of an accommodation 
enquiry, the related service dialogue frame will not 
generally contain an explicitly linked payment 
frame. However, the DomainSpotter is able to 
determine which agents can provide payment 
support, and so the system generates a number of 
potential discourse paths relating to payment. Key 
words in the user?s utterances determine which 
path is in fact used and which payment-related 
frames are linked to the accommodation frame.    
As the dialogue evolves, the DomainSpotter 
tests which agents are best placed to handle the 
user?s last utterance: the tree of dialogue frames 
indicates to the DomainSpotter which support 
agents have been or may be involved in the current 
service enquiry, and should therefore be 
considered; the DomainSpotter will poll service 
agents as a matter of course.  If the user?s utterance 
is scored most highly by a support agent (relevant 
to the current service) whose topic has already 
been in the discourse focus, the user can return to 
this topic (the shift may indicate the user?s 
intention to add to or modify information that was 
previously supplied). As a safeguard, the system 
places on the ExpertFocusStack any support agents 
whose rules fired on the previous path to the 
revisited agent, and these support agents will be 
allowed to test their rules again (new address 
information, for instance, may affect a credit card 
option ? e.g. if the revised address is in UK, the 
CreditCardExpert may mention UK cardholder 
offers, etc.).  The system uses the linked dialogue 
frames of topics that have already been in the 
discourse focus to determine the order in which 
such support experts should be placed on to the 
ExpertFocusStack   
 Other requests for shifts of focus from and 
between support agents are generally deferred 
(?Thanks, I?ll take the address details in a 
moment??), until the rules of the current support 
expert allow transfer.  The system does not ignore 
the contents of the utterance that led to the 
deferral: the DiscourseHistory contains an 
UtteranceStore, a stack of the parses of the user?s 
utterances.  When it takes control of the dialogue, 
because one of the handling expert?s rules has 
allowed it to, an agent first looks to the 
UtteranceStore to see if there is any unprocessed 
information that it can handle.  If there is, it takes 
the unprocessed parsed information and begins its 
processing as usual with its inherited confirmation 
strategy and its domain-specific expert rules (?So 
you said the street address was 18 Malone Road. 
Can I have the city please??). 
5 The Queen?s Communicator in action 
The following portion of dialogue is typical of 
the exchanges currently supported by the system.  
User utterances are shown as U1, U2, etc.  System 
utterances (S1a,?, S2, etc.) are taken from our 
new natural language generation (NLG) module, 
which we are continuing to develop.  The NLG 
module takes as its input the semantic constructs 
output from the DM.  These constructs are shown 
thus: MESSAGE: process?, etc.  A brief 
commentary, indicating which main features of the 
DM are being called into play, is given at key 
points in the dialogue and is printed in italics. 
 
U1: I?d like to book a three-star hotel in Belfast 
from the fifteenth of August to the twentieth of 
August.  
Key words like three-star and hotel fall within 
the accommodation domain, and are scored by the 
AccommodationExpert .  Accordingly the Domain-
Spotter appoints the AccommodationExpert 
?handling agent?.  The AccommodationExpert 
populates its AccommodationDialogFrame with 
whatever relevant information has been supplied 
by the user. 
 
S1a:  OK, let's start a new accommodation 
booking. OK, that's a three-star hotel in Belfast 
from 2004-08-15 until 2004-08-20.  Please wait... 
 
MESSAGE: process accommodation  
   booking 
MESSAGE: GIVEN  
         AccoType [ HOTEL  ]  
         AccoClass [ three-star  ]  
         Location [ BELFAST  ]  
         DateFrom [ 2004-08-15 ]  
         DateTo [ 2004-08-20 ]  
MESSAGE: database enquiry initiated 
 
The AccommodationExpert uses the generic 
confirmation strategies that it has inherited from 
the DiscourseManager to implicitly confirm new 
values, and it uses its own domain-specific rules to 
initiate a database lookup that will retrieve names 
of hotels that match the user?s criteria.  
 
S1b: You can choose between the following: the  
Jurys or Lisdara. Which would you prefer? 
 
PROMPT: SPECIFY  
AccoName [ jurys  ]  
         [ lisdara  ] 
 
U2:  Could you make that a four-star? 
Although the system in its utterance suggests 
that the user should select one of the hotel names 
retrieved from the database, the user may provide 
information different to that which was requested, 
since this is a mixed initiative system.  In this case 
the user changes the star-rating, instead of 
selecting a hotel name. 
   S2: Ok, got it. So that's a four-star? 
 
MESSAGE: user changed value  
         AccoClass [ four-star  ]  
QUERY: confirm changes 
 
Again, using its inherited confirmation strategy, 
the AccommodationExpert compares the value for 
the star-rating in the previous frame with the star-
rating in the current frame and performs a ?repair- 
confirm? on the changed value.   
 
U3: Yes, that?s right. 
 
S3a:  Please wait... 
 
MESSAGE: database enquiry initiated 
 
   S3b:  You can choose between the following: the  
Europa,  Malone Lodge,  Stormont or Holiday Inn. 
Which would you prefer? 
 
PROMPT: SPECIFY  
        AccoName [  europa  ] 
               [  malone-lodge  ]  
               [  stormont  ]  
               [  holiday-inn  ]     
 
U4:  I?ll go for a double room at the Europa. 
 
S4:  So that's the four-star Europa hotel in 
Belfast with a double room, from 2004-08-15 until 
2004-08-20. Is that correct? 
 
MESSAGE: explicit confirm values 
         AccoName [ europa  ]  
         AccoType [ HOTEL  ]     
         AccoClass [ four-star  ] 
         Location [ BELFAST  ]  
         AccoRoomType [ double  ]  
         DateFrom [ 2004-08-15 ]  
         DateTo [ 2004-08-20 ]  
QUERY: CONFIRM values 
 
In the current system implementation the 
handling agent explicitly confirms all ?key? values 
needed to conclude a major segment of the 
discourse ? once these have been supplied by the 
user.   
 
U5:  Make that a single room. 
In this case, however, the user again changes 
his/her mind.  The immediate next steps in the 
dialogue (not shown here) would be to reconfirm 
the ?key? values, including the newly changed 
value; then ask if the user wishes to check 
availability and reserve; and if so elicit payment 
details with the aid of the PaymentExpert and 
AddressExpert components... 
6 Related work 
Although some currently available dialogue 
systems use object components in accordance with 
the latest software engineering orthodoxy ? (Allen 
et al, 2000) ? little published research addresses 
the question of how established techniques of 
object-oriented software engineering (Booch, 
1994) (Booch et al, 1998) can contribute to the 
dialogue management task.   
Some research groups confirm the suitability of 
Java for the development of interactive, agent-
based systems ? for example COLLAGEN (Rich et 
al. 2001).  Indeed, the COLLAGEN architecture, 
like that of the Queen?s Communicator, manages 
discourse using a ?focus stack?, a classical idea in 
the theory of discourse structure (Grosz and 
Sidner, 1986).  
For dialogues that are not primarily transaction- 
based or frame-based, and where the system must 
establish the user?s broader objectives before 
offering advice or presenting options, a discourse 
management strategy based on problem-solving 
(PS) objects (objectives, recipes, actions and 
resources) is appropriate (Blaylock et al, 2003).  
We are currently investigating means of using PS 
objects to orient a dialogue, before using expertise 
like that currently encapsulated in our domain 
agents to complete those frame-filling tasks that 
are needed to support the user?s objectives.  
7 Conclusions 
We have decomposed the cross-domain dialogue 
management task intuitively into a number of sub-
dialogues, each conducted by an implemented 
domain specialist with its own expert rules and 
associated frame of information to collect.  By 
using inheritance we easily establish a common 
approach to dialogue management, independent of 
domain: all experts inherit the same confirmation 
strategy.  Through inheritance we ensure that 
domain experts have common characteristics: they 
all have sequences of ?expert rules? that they can 
apply to user-supplied information to determine 
what the system should do next.  Domain spotting 
enables us to identify appropriate dialogue 
handling expertise for each of the user?s utterances.  
Since our DomainSpotter actively looks for 
relevant expertise amongst the cohort of service 
and support agents, new expertise can readily be 
added without disturbing the system?s fundamental 
dialogue management strategies.  Additionally, 
division of the available experts into (front-line) 
service agents and (ancillary) support experts helps 
us maintain discourse context by deferring user-led 
shifts of focus that interrupt coherent data 
elicitation.   
Future developments are likely to include: 
addition of new dialogue domains (e.g. travel); and   
incorporation of multiple dialogue strategies (using 
frames for mixed initiative transactions, PS objects 
for collaborative problem solving, and finite state 
transition networks for system-led interaction). 
Multimodal input will also be considered, 
including input relating to the user?s emotional 
state, as a factor for dynamically determining an 
appropriate dialogue strategy for a particular 
discourse segment.  
8 Acknowledgements 
This research is supported by the EPSRC under 
grant number GR/R91632/01. 
References  
J. Allen, D. Byron, M. Dzikovska, G. Ferguson, L. 
Galescu and A. Stent. 2000. An Architecture for 
a Generic Dialogue Shell.  Natural Language 
Engineering 6 (3?4), pp. 1-16, Cambridge 
University Press. 
N. Blaylock, J. Allen and G. Ferguson. 2003.  
Managing communicative intentions with 
collaborative problem solving.  Current and New 
Directions in Discourse and Dialogue (eds. J. 
van Kuppevelt and R. Smith), pp. 63 ? 84, 
Kluwer, Dordrecht. 
G. Booch. 1994. Object-Oriented Analysis and 
Design with Applications (2nd Edition).  
Benjamin/Cummings, Redwood City, CA. 
G. Booch, J. Rumbaugh and I. Jacobson. 1998. The 
Unified Modeling Language User Guide.  
Addison Wesley Longman, Reading, MA. 
B. Grosz and C. Sidner. 1986. Attention, 
Intentions, and the Structure of Discourse. 
Computational Linguistics, 12:3, pp. 175 ? 204, 
Cambridge, MA. 
P. Heisterkamp and S. McGlashan. 1996. Units of 
Dialogue Management: An Example. 
Proceedings of ICSLP96, pp. 200?203, 
Philadelphia. 
I. O?Neill and M. McTear. 2000. Object-Oriented 
Modelling of Spoken Language Dialogue 
Systems.  Natural Language Engineering 6 (3?
4), pp. 341?362, Cambridge University Press. 
I. O?Neill and M. McTear.  2002.  A Pragmatic 
Confirmation Mechanism for an Object-Based 
Spoken Dialogue Manager. Proceedings of 
ICSLP-2002, Vol. 3, pp. 2045?2048. Denver, 
CO. 
I. O?Neill, P. Hanna, X. Liu and M. McTear. 2003.  
The Queen?s Communicator: an Object-Oriented 
Dialogue Manager.  Proceedings of Eurospeech 
2003, pp. 593?596, Geneva. 
C. Rich, C. Sidner and N. Lesh. 2001. 
COLLAGEN: Applying Collaborative Discourse 
Theory to Human-Computer Interaction. 
Artificial Intelligence Magazine, Vol 22, Issue 4, 
pp. 15-25, Menlo Park, CA. 
A. Rudnicky and W. Xu. 1999. An agenda-based 
dialog management architecture for spoken 
language systems. Proceedings of IEEE 
Automatic Speech Recognition and  
Understanding Workshop, p. I?337. 
M. Turunen and J. Hakulinen. 2001. Agent-Based 
Adaptive Interaction and Dialogue Management 
Architecture for Speech Applications. Text 
Speech and Dialogue?Proceedings of the Fourth 
International Conference TSD, pp. 357?364.  
W. Ward. 1994. Extracting information in 
spontaneous speech. Proceedings of ICSLP 94, 
pp. 83?86, Yokohama. 
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 46?50,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
A Statistical Spoken Dialogue System using Complex User Goals and
Value Directed Compression
Paul A. Crook, Zhuoran Wang, Xingkun Liu and Oliver Lemon
Interaction Lab
School of Mathematical and Computer Sciences (MACS)
Heriot-Watt University, Edinburgh, UK
{p.a.crook, zhuoran.wang, x.liu, o.lemon}@hw.ac.uk
Abstract
This paper presents the first demonstration
of a statistical spoken dialogue system that
uses automatic belief compression to rea-
son over complex user goal sets. Reasoning
over the power set of possible user goals al-
lows complex sets of user goals to be rep-
resented, which leads to more natural dia-
logues. The use of the power set results in a
massive expansion in the number of belief
states maintained by the Partially Observ-
able Markov Decision Process (POMDP)
spoken dialogue manager. A modified form
of Value Directed Compression (VDC) is
applied to the POMDP belief states produc-
ing a near-lossless compression which re-
duces the number of bases required to rep-
resent the belief distribution.
1 Introduction
One of the main problems for a spoken dialogue
system (SDS) is to determine the user?s goal (e.g.
plan suitable meeting times or find a good Indian
restaurant nearby) under uncertainty, and thereby
to compute the optimal next system dialogue ac-
tion (e.g. offer a restaurant, ask for clarification).
Recent research in statistical SDSs has success-
fully addressed aspects of these problems through
the application of Partially Observable Markov
Decision Process (POMDP) approaches (Thom-
son and Young, 2010; Young et al 2010). How-
ever POMDP SDSs are currently limited by the
representation of user goals adopted to make sys-
tems computationally tractable.
Work in dialogue system evaluation, e.g.
Walker et al(2004) and Lemon et al(2006),
shows that real user goals are generally sets of
items, rather than a single item. People like to
explore possible trade offs between the attributes
of items.
Crook and Lemon (2010) identified this as a
central challenge for the field of spoken dialogue
systems, proposing the use of automatic compres-
sion techniques to allow for extended accurate
representations of user goals. This paper presents
a proof of concept of these ideas in the form of a
complete, working spoken dialogue system. The
POMDP dialogue manager (DM) of this demon-
stration system uses a compressed belief space
that was generated using a modified version of the
Value Directed Compression (VDC) algorithm
as originally proposed by Poupart (2005). This
demonstration system extends work presented by
Crook and Lemon (2011) in that it embeds the
compressed complex user goal belief space into a
working system and demonstrates planning (and
acting) in the compressed space.
2 Complex User Goals
The type of SDS task that we focus on is a limited-
domain query-dialogue, also known as a ?slot fill-
ing? task. The spoken dialogue system has knowl-
edge about some set of objects where these ob-
jects have attributes and these attributes can take
several values. An object can thus be described
by a conjunction of attribute-value pairs. A di-
alogue progresses with the system obtaining re-
quirements from the user which are specified in
terms of attribute values. The system should even-
tually present objects (search results) based upon
its understanding of the user?s requirement. The
dialogue ends when the user accepts one of the
domain objects.
Prior work on POMDP SDSs has assumed that
a user has a narrowly constrained goal (as speci-
46
User goal: cheap central Thai or expensive French
S: Hello, how can I help you?
U: I?m looking for a cheap central Thai restaurant.
S: You?re looking for budget, city centre, Thai
restaurants. ?
U: Or an expensive French restaurant anywhere.
S: You?re looking for non-budget French restaurants.
What ?
U: And cheap, city centre, Thai.
S: You?re looking for budget, city centre, Thai
restaurants. What about ?
U: (SIGH) And French.
S: You?re looking for budget, city centre, French
restaurants. What about ?
U: (HANG UP)
Table 1: Example dialogue using simple user goals.
S=System, U=User. ??? indicates the user barged in.
fied in terms of the domain objects) and thus the
role of the DM is one of reducing uncertainty un-
til its belief is strongly focused on a particular do-
main object. This has the unfortunate effect of
forcing users to select one domain object in order
to progress the dialogue, see Table 1. Note that the
example given is problematic not only because the
user wants two different food types but because
they have different requirements associated with
each, i.e. Thai restaurants should be in the centre
and cheap, while any French restaurants should be
expensive1 and can be located anywhere. To our
knowledge such a combination of goals with dif-
ferent attribute values cannot be straightforwardly
handled by comparable state-of-the-art statistical
SDSs which appear in the literature.
Crook and Lemon (2011) suggest that rather
than the DM assuming that the user has a single
narrowly constrained goal in mind, it should as-
sume that they want any possible sub-set of the
complete set of domain objects. Thus, instead
of maintaining the POMDP belief over individual
domain objects, it should be maintained over the
power set of domain objects. As an example see
Table 3 which is the power set for a domain with
three objects that can take two attributes u, v with
associated values u1, u2, u3 and v1 respectively.
The power set representation allows the
demonstration system to straightforwardly handle
previously problematic dialogues. See Table 2.
Of course this approach significantly expands the
1Interpreted as non-budget by the system since its
database only classifies restaurants as budget or non-budget.
User goal: cheap central Thai or expensive French
S: Hello, how can I help you?
U: I?m looking for a cheap central Thai restaurant.
S: You?re looking for budget, city centre, Thai
restaurants. ?
U: Or an expensive French restaurant anywhere.
S: You?re looking for budget, city centre, Thai
restaurants or non-budget French. What about
Chang Thai in Old Town?? Chang Thai?s set lunch
price is ? 7.95 ?
U: What alternatives do you have?
S: What about the Plumed Horse in Leith?? The
Plumed Horse is a Michelin starred French ...
Table 2: Example dialogue using complex user goals.
S=System, U=User. ?Old Town is part of the city cen-
tre. ?Leith is outside the centre.
state space of possible user goals, with the num-
ber of goal sets being equal to 2|domain objects| .
2.1 Automatic Compression
Even considering limited domains, POMDP state
spaces for SDSs grow very quickly. Thus the cur-
rent state-of-the-art in POMDP SDSs uses a vari-
ety of handcrafted compression techniques, such
as making several types of independence assump-
tion as discussed above.
Crook and Lemon (2010) propose replacing
handcrafted compressions with automatic com-
pression techniques. The idea is to use princi-
pled statistical methods for automatically reduc-
ing the dimensionality of belief spaces, but which
preserve useful distributions from the full space,
and thus can more accurately represent real user?s
goals.
2.2 VDC Algorithm
The VDC algorithm (Poupart, 2005) uses Krylov
iteration to compute a reduced state space. It finds
a set of linear basis vectors that can reproduce the
value2 of being in any of the original POMDP
states. Where, if a lossless VDC compression is
possible, the number of basis vectors is less than
the original number of POMDP states.
The intuition here is that if the value of taking
an action in a given state has been preserved then
planning is equally as reliable in the compressed
space as the in full space.
The VDC algorithm requires a fully specified
POMDP, i.e. ?S,A,O, T,?,R? where S is the set
2The sum of discounted future rewards obtained through
following some series of actions.
47
state goal set meaning: user?s goal is
s1 ? (empty set) none of the domain objects
s2 u=u1?v=v1 domain object 1
s3 u=u2?v=v1 domain object 2
s4 u=u3?v=v1 domain object 3
s5 (u=u1?v=v1) ? (u=u2?v=v1) domain objects 1 or 2
s6 (u=u1?v=v1) ? (u=u3?v=v1) domain objects 1 or 3
s7 (u=u2?v=v1) ? (u=u3?v=v1) domain objects 2 or 3
s8 (u=u1?v=v1) ? (u=u2?v=v1) ? (u=u3?v=v1) any of the domain objects
Table 3: Example of complex user goal sets.
of states, A is the set of actions, O is the set of ob-
servations, T conditional transition probabilities,
? conditional observation probabilities, and R is
the reward function. Since it iteratively projects
the rewards associated with each state and action
using the state transition and observation proba-
bilities, the compression found is dependent on
structures and regularities in the POMDP model.
The set of basis vectors found can be used to
project the POMDP reward, transition, and obser-
vation probabilities into the reduced state space
allowing the policy to be learnt and executed in
this state space.
Although the VDC algorithm (Poupart, 2005)
produces compressions that are lossless in terms
of the states? values, the set of basis vectors found
(when viewed as a transformation matrix) can be
ill-conditioned. This results in numerical instabil-
ity and errors in the belief estimation. The com-
pression used in this demonstration was produced
using a modified VDC algorithm that improves
the matrix condition by approximately selecting
the most independent basis vectors, thus improv-
ing numerical stability. It achieves near-lossless
state value compression while allowing belief es-
timation errors to be minimised and traded-off
against the amount of compression. Details of this
algorithm are to appear in a forthcoming publica-
tion.
3 System Description
3.1 Components
Input and output to the demonstration system is
using standard open source and commercial com-
ponents. FreeSWITCH (Minessale II, 2012) pro-
vides a platform for accepting incoming Voice
over IP calls, routing them (using the Media Re-
source Control Protocol (MRCP)) to a Nuance 9.0
Automatic Speech Recogniser (Nuance, 2012).
Output is similarly handled by FreeSWITCH
routing system responses via a CereProc Text-to-
Speech MRCP server (CereProc, 2012) in order
to respond to the user.
The heart of the demonstration system consists
of a State-Estimator server which estimates the
current dialogue state using the compressed state
space previously produced by VDC, a Policy-
Executor server that selects actions based on
the compressed estimated state, and a template
based Natural Language Generator server. These
servers, along with FreeSWITCH, use ZeroC?s
Internet Communications Engine (Ice) middle-
ware (ZeroC, 2012) as a common communica-
tions platform.
3.2 SDS Domain
The demonstration system provides a restaurant
finder system for the city of Edinburgh (Scot-
land, UK). It presents search results from a real
database of over 600 restaurants. The search
results are based on the attributes specified by
the user, currently; location, food type and
budget/non-budget.
3.3 Interface
The demonstration SDS is typically accessed over
the phone network. For debugging and demon-
stration purposes it is possible to visualise the
belief distribution maintained by the DM as dia-
logues progress. The compressed version of the
belief distribution is not a conventional proba-
bility distribution3 and its visualisation is unin-
formative. Instead we take advantage of the re-
versibility of the VDC compression and project
the distribution back onto the full state space. For
an example of the evolution of the belief distribu-
tion during a dialogue see Figure 1.
3The values associated with the basis vectors are not con-
fined to the range [0? 1].
48
#4096
10?7 10?6 10?5 0.0001 0.001
(a) Initial uniform distribution over the power set.
#2048
#2048
10?7 10?6 10?5 0.0001 0.001
(b) Distribution after user responds to greet.
#512
#3584
10?11 10?9 10?7 10?5 0.001
(c) Distribution after second user utterance.
Figure 1: Evolution of the belief distribution for the
example dialogue in Table 2. The horizontal length of
each bar corresponds to the probability of that com-
plex user goal state. Note that the x-axis uses a log-
arithmic scale to allow low probability values to be
seen. The y-axis is the set of complex user goals or-
dered by probability. Lighter shaded (green) bars indi-
cate complex user goal states corresponding to ?cheap,
central Thai? and ?cheap, central Thai or expensive
French anywhere? in figures (b) and (c) respectively.
The count ?#? indicates the number of states in those
groups.
4 Conclusions
We present a demonstration of a statistical SDS
that uses automatic belief compression to reason
over complex user goal sets. Using the power set
of domain objects as the states of the POMDP
DM allows complex sets of user goals to be rep-
resented, which leads to more natural dialogues.
To address the massive expansion in the number
of belief states, a modified form of VDC is used
to generate a compression. It is this compressed
space which is used by the DM for planning and
acting in response to user utterances. This is the
first demonstration of a statistical SDS that uses
automatic belief compression to reason over com-
plex user goal sets.
VDC and other automated compression tech-
niques reduce the human design load by automat-
ing part of the current POMDP SDS design pro-
cess. This reduces the knowledge required when
building such statistical systems and should make
them easier for industry to deploy.
Such compression approaches are not only ap-
plicable to SDSs but should be equally relevant
for multi-modal interaction systems where sev-
eral modalities are being combined in user-goal
or state estimation.
5 Future Work
The current demonstration system is a proof
of concept and is limited to a small number
of attributes and attribute-values. Part of our
ongoing work involves investigation of scaling.
For example, increasing the number of attribute-
values should produce more regularities across
the POMDP space. Does VDC successfully ex-
ploit these?
We are in the process of collecting corpora
for the Edinburgh restaurant domain mentioned
above with the aim that the POMDP observation
and transition statistics can be derived from data.
As part of this work we have launched a long
term, public facing outlet for testing and data col-
lection, see http:\\www.edinburghinfo.
co.uk. It is planned to make future versions of
the demonstration system discussed in this paper
available via this public outlet.
Finally we are investigating the applicability
of other automatic belief (and state) compression
techniques for SDSs, e.g. E-PCA (Roy and Gor-
don, 2002).
49
Acknowledgments
The research leading to these results was funded
by the Engineering and Physical Sciences Re-
search Council, UK (EPSRC) under project no.
EP/G069840/1 and was partially supported by the
EC FP7 projects Spacebook (ref. 270019) and
JAMES (ref. 270435).
References
CereProc. 2012. http://www.cereproc.com/.
Paul A. Crook and Oliver Lemon. 2010. Representing
uncertainty about complex user goals in statistical
dialogue systems. In proceedings of SIGdial.
Paul A. Crook and Oliver Lemon. 2011. Lossless
Value Directed Compression of Complex User Goal
States for Statistical Spoken Dialogue Systems. In
Proceedings of the Twelfth Annual Conference of
the International Speech Communication Associa-
tion (Interspeech).
Oliver Lemon, Kallirroi Georgila, and James Hender-
son. 2006. Evaluating Effectiveness and Portabil-
ity of Reinforcement Learned Dialogue Strategies
with real users: the TALK TownInfo Evaluation. In
IEEE/ACL Spoken Language Technology.
Anthony Minessale II. 2012. FreeSWITCH. http:
//www.freeswitch.org/.
Nuance. 2012. Nuance Recognizer. http://www.
nuance.com.
P. Poupart. 2005. Exploiting Structure to Efficiently
Solve Large Scale Partially Observable Markov De-
cision Processes. Ph.D. thesis, Dept. Computer Sci-
ence, University of Toronto.
N. Roy and G. Gordon. 2002. Exponential Family
PCA for Belief Compression in POMDPs. In NIPS.
B. Thomson and S. Young. 2010. Bayesian update
of dialogue state: A POMDP framework for spoken
dialogue systems. Computer Speech and Language,
24(4):562?588.
Marilyn Walker, S. Whittaker, A. Stent, P. Maloor,
J. Moore, M. Johnston, and G. Vasireddy. 2004.
User tailored generation in the match multimodal
dialogue system. Cognitive Science, 28:811?840.
S. Young, M. Gas?ic?, S. Keizer, F. Mairesse, B. Thom-
son, and K. Yu. 2010. The Hidden Information
State model: a practical framework for POMDP
based spoken dialogue management. Computer
Speech and Language, 24(2):150?174.
ZeroC. 2012. The Internet Communications Engine
(Ice). http://www.zeroc.com/ice.html.
50
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1009?1018,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Optimising Information Presentation for Spoken Dialogue Systems
Verena Rieser
University of Edinburgh
Edinburgh, United Kingdom
verena.rieser@ed.ac.uk
Oliver Lemon
Heriot-Watt University
Edinburgh, United Kingdom
o.lemon@hw.ac.uk
Xingkun Liu
Heriot-Watt University
Edinburgh, United Kingdom
x.liu@hw.ac.uk
Abstract
We present a novel approach to Informa-
tion Presentation (IP) in Spoken Dialogue
Systems (SDS) using a data-driven statis-
tical optimisation framework for content
planning and attribute selection. First we
collect data in a Wizard-of-Oz (WoZ) ex-
periment and use it to build a supervised
model of human behaviour. This forms
a baseline for measuring the performance
of optimised policies, developed from this
data using Reinforcement Learning (RL)
methods. We show that the optimised poli-
cies significantly outperform the baselines
in a variety of generation scenarios: while
the supervised model is able to attain up to
87.6% of the possible reward on this task,
the RL policies are significantly better in 5
out of 6 scenarios, gaining up to 91.5% of
the total possible reward. The RL policies
perform especially well in more complex
scenarios. We are also the first to show
that adding predictive ?lower level? fea-
tures (e.g. from the NLG realiser) is im-
portant for optimising IP strategies accord-
ing to user preferences. This provides new
insights into the nature of the IP problem
for SDS.
1 Introduction
Work on evaluating SDS suggests that the Infor-
mation Presentation (IP) phase is the primary con-
tributor to dialogue duration (Walker et al, 2001),
and as such, is a central aspect of SDS design.
During this phase the system returns a set of items
(?hits?) from a database, which match the user?s
current search constraints. An inherent problem
in this task is the trade-off between presenting
?enough? information to the user (for example
helping them to feel confident that they have a
good overview of the search results) versus keep-
ing the utterances short and understandable.
In the following we show that IP for SDS can
be treated as a data-driven joint optimisation prob-
lem, and that this outperforms a supervised model
of human ?wizard? behaviour on a particular IP
task (presenting sets of search results to a user).
A similar approach has been applied to the
problem of Referring Expression Generation in di-
alogue (Janarthanam and Lemon, 2010).
1.1 Previous work on Information
Presentation in SDS
Broadly speaking, IP for SDS can be divided into
two main steps: 1) IP strategy selection and 2)
Content or Attribute Selection. Prior work has
presented a variety of IP strategies for structur-
ing information (see examples in Table 1). For ex-
ample, the SUMMARY strategy is used to guide the
user?s ?focus of attention?. It draws the user?s at-
tention to relevant attributes by grouping the cur-
rent results from the database into clusters, e.g.
(Polifroni and Walker, 2008; Demberg and Moore,
2006). Other studies investigate a COMPARE strat-
egy, e.g. (Walker et al, 2007; Nakatsu, 2008),
while most work in SDS uses a RECOMMEND strat-
egy, e.g. (Young et al, 2007). In a previous proof-
of-concept study (Rieser and Lemon, 2009) we
show that each of these strategies has its own
strengths and drawbacks, dependent on the partic-
ular context in which information needs to be pre-
sented to a user. Here, we will also explore pos-
sible combinations of the strategies, for example
SUMMARY followed by RECOMMEND, e.g. (Whittaker
et al, 2002), see Figure 1.
Prior work on Content or Attribute Selection
has used a ?Summarize and Refine? approach (Po-
lifroni and Walker, 2008; Polifroni and Walker,
2006; Chung, 2004). This method employs utility-
based attribute selection with respect to how each
attribute (e.g. price or food type in restaurant
1009
search) of a set of items helps to narrow down
the user?s goal to a single item. Related work ex-
plores a user modelling approach, where attributes
are ranked according to user preferences (Dem-
berg and Moore, 2006; Winterboer et al, 2007).
Our data collection (see Section 3) and training en-
vironment incorporate these approaches.
The work in this paper is the first to ap-
ply a data-driven method to this whole decision
space (i.e. combinations of Information Presenta-
tion strategies as well as attribute selection), and to
show the utility of both lower-level features (e.g.
from the NLG realiser) and higher-level features
(e.g. from Dialogue Management) for this prob-
lem. Previous work has only focused on individual
aspects of the problem (e.g. how many attributes
to generate, or when to use a SUMMARY), using a
pipeline model for SDS with DM features as input,
and where NLG has no knowledge of lower level
features (e.g. behaviour of the realiser). In Section
4.3 we show that lower level features significantly
influence users? ratings of IP strategies. In the fol-
lowing we use a Reinforcement Learning (RL) as a
statistical planning framework (Sutton and Barto,
1998) to explore the contextual features for mak-
ing these decisions, and propose a new joint opti-
misation method for IP strategies combining con-
tent structuring and attribute selection.
2 NLG as planning under uncertainty
We follow the overall framework of NLG as plan-
ning under uncertainty (Lemon, 2008; Rieser and
Lemon, 2009; Lemon, 2010), where each NLG ac-
tion is a sequential decision point, based on the
current dialogue context and the expected long-
term utility or ?reward? of the action. Other re-
cent approaches describe this task as planning, e.g.
(Koller and Petrick, 2008), or as contextual de-
cision making according to a cost function (van
Deemter, 2009), but not as a statistical planning
problem, where uncertainty in the stochastic envi-
ronment is explicitly modelled. Below, we apply
this framework to Information Presentation strate-
gies in SDS using Reinforcement Learning, where
the example task is to present a set of search results
(e.g. restaurants) to users. In particular, we con-
sider 7 possible policies for structuring the content
(see Figure 1): Recommending one single item,
comparing two items, summarising all of them,
or ordered combinations of those actions, e.g. first
summarise all the retrieved items and then recom-
mend one of them. The IP module has to decide
which action to take next, how many attributes to
mention, and when to stop generating.
Figure 1: Possible Information Presentation struc-
tures (X=stop generation)
3 Wizard-of-Oz data collection
In an initial Wizard-of-Oz (WoZ) study, we asked
humans (our ?wizards?) to produce good IP ac-
tions in different dialogue contexts, when interact-
ing in spoken dialogues with other humans (the
?users?), who believed that they were talking to an
automated SDS. The wizards were experienced re-
searchers in SDS and were familiar with the search
domain (restaurants in Edinburgh). They were in-
structed to select IP structures and attributes for
NLG so as to most efficiently allow users to find a
restaurant matching their search constraints. They
also received prior training on this task.
The task for the wizards was to decide which
IP structure to use next (see Section 3.2 for a
list of IP strategies to choose from), which at-
tributes to mention (e.g. cuisine, price range, lo-
cation, food quality, and/or service quality), and
whether to stop generating, given varying num-
bers of database matches, varying prompt reali-
sations, and varying user behaviour. Wizard ut-
terances were synthesised using a state-of-the-art
text-to-speech engine. The user speech input was
delivered to the wizard using Voice Over IP. Figure
2 shows the web-based interface for the wizard.
3.1 Experimental Setup and Data collection
We collected 213 dialogues with 18 subjects and 2
wizards (Liu et al, 2009). Each user performed a
total of 12 tasks, where no task set was seen twice
by any one wizard. The majority of users were
from a range of backgrounds in a higher educa-
tion institute, in the age range 20-30, native speak-
ers of English, and none had prior experience of
1010
Figure 2: Wizard interface. [A:] The wizard selects attribute values as specified by the user?s query. [B:] The retrieved
database items are presented in an ordered list. We use a User Modelling approach for ranking the restaurants, see e.g. (Polifroni
and Walker, 2008). [C:] The wizard then chooses which strategy and which attributes to generate next, by clicking radio buttons.
The attribute/s specified in the last user query are pre-selected by default. The strategies can only be combined in the orders as
specified in Figure 1. [D:] An utterance is automatically generated by the NLG realiser every time the wizard selects a strategy,
and is displayed in an intermediate text panel. [E:] The wizard can decide to add the generated utterance to the final output
panel or to start over again. The text in the final panel is sent to the user via TTS, once the wizard decides to stop generating.
Strategy Example utterance
SUMMARY no
UM
I found 26 restaurants, which have Indian cuisine. 11 of the restaurants are in the expensive price
range. Furthermore, 10 of the restaurants are in the cheap price range and 5 of the restaurants
are in the moderate price range.
SUMMARY UM 26 restaurants meet your query. There are 10 restaurants which serve Indian food and are in the
cheap price range. There are also 16 others which are more expensive.
COMPARE by
Item
The restaurant called Kebab Mahal is an Indian restaurant. It is in the cheap price range. And
the restaurant called Saffrani, which is also an Indian restaurant, is in the moderate price range.
COMPARE by
Attribute
The restaurant called Kebab Mahal and the restaurant called Saffrani are both Indian restaurants.
However, Kebab Mahal is in the cheap price range while Saffrani is moderately priced.
RECOMMEND The restaurant called Kebab Mahal has the best overall quality amongst the matching restau-
rants. It is an Indian restaurant, and it is in the cheap price range.
Table 1: Example realisations, generated when the user provided cuisine=Indian, and where the
wizard has also selected the additional attribute price for presentation to the user.
Spoken Dialogue Systems. After each task the
user answered a questionnaire on a 6 point Lik-
ert scale, regarding the perceived generation qual-
ity in that task. The wizards? IP strategies were
highly ranked by the users on average (4.7), and
users were able to select a restaurant in 98.6% of
the cases. No significant difference between the
wizards was observed.
The data contains 2236 utterances in total: 1465
wizard utterances and 771 user utterances. We au-
tomatically extracted 81 features (e.g #sentences,
#DBhits, #turns, #ellipsis)1 from the XML logfiles
after each dialogue. Please see (Rieser et al, 2009)
1The full corpus and list of features is available at
https://www.classic-project.org/corpora/
for more details.
3.2 NLG Realiser
In the Wizard-of-Oz environment we implemented
a NLG realiser for the chosen IP structures and
attribute choices, in order to realise the wizards?
choices in real time. This generator is based on
data from the stochastic sentence planner SPaRKy
(Stent et al, 2004). We replicated the variation ob-
served in SPaRKy by analysing high-ranking ex-
ample outputs (given the highest possible score
by the SPaRKy judges) and implemented the vari-
ance using dynamic sentence generation. The real-
isations vary in sentence aggregation, aggregation
operators (e.g. ?and?, period, or ellipsis), contrasts
1011
(e.g. ?however?, ?on the other hand?) and referring
expressions (e.g. ?it?, ?this restaurant?) used. The
length of an utterance also depends on the num-
ber of attributes chosen, i.e. the more attributes the
longer the utterance. All of these variations were
logged.
In particular, we realised the following IP strate-
gies (see examples in Table 1):
? SUMMARY of all matching restaurants with
or without a User Model (UM), following
(Polifroni and Walker, 2008). The approach
using a UM assumes that the user has cer-
tain preferences (e.g. cheap) and only tells
him about the relevant items, whereas the
approach with no UM lists all the matching
items.
? COMPARE the top 2 restaurants by Item (i.e.
listing all the attributes for the first item and
then for the other) or by Attribute (i.e. di-
rectly comparing the different attribute val-
ues).
? RECOMMEND the top-ranking restaurant (ac-
cording to UM).
Note that there was no discernible pattern in
the data about the wizards? decisions between
the UM/no UM and the byItem/byAttribute ver-
sions of the strategies. In this study we will
therefore concentrate on the higher level decisions
(SUMMARY vs. COMPARE vs. RECOMMEND) and model
these different realisations as noise in the realiser.
3.3 Supervised Baseline strategy
We analysed the WoZ data to explore the best-
rated strategies (the top scoring 50%, n = 205)
that were employed by humans for this task. Here
we used a variety of Supervised Learning meth-
ods to create a model of the highly rated wizard
behaviour. Please see (Rieser et al, 2009) for fur-
ther details. The best performing method was Rule
Induction (JRip). 2 The model achieved an accu-
racy of 43.19% which is significantly (p < .001)
better than the majority baseline of always choos-
ing SUMMARY (34.65%). 3 The resulting rule set is
shown in Figure 3.
2The WEKA implementation of (Cohen, 1995)?s RIPPER.
3Note that the low accuracy is due to data sparsity and
diverse behaviour of the wizards. However, in (Rieser et al,
2009) we show that this model is significantly different from
the policy learned using the worse scoring 50%.
IF (dbHits <= 9)& (prevNLG = summary):
THEN nlgStrategy=compare;
IF (dbHits = 1):
THEN nlgStrategy= Recommend;
IF(prevNLG=summaryRecommend)&(dbHits>=10):
THEN nlgStrategy= Recommend;
ELSE nlgStrategy=summary;
Figure 3: Rules learned by JRip for the wizard
model (?dbHits?= number of database matches,
?prevNLG?= previous NLG action)
The features selected by this model were only
?high-level? features, i.e. the input (previous ac-
tion, number of database hits) that an IP module
receives as input from a Dialogue Manager (DM).
We further analysed the importance of different
features using feature ranking and selection meth-
ods (Rieser et al, 2009), finding that the human
wizards in this specific setup did not pay signifi-
cant attention to any lower level features, e.g. from
surface realisation, although the generated output
was displayed to them (see Figure 2).
Nevertheless, note that the supervised model
achieves up to 87.6% of the possible reward on
this task, as we show in Section 5.2, and so can
be considered a serious baseline against which to
measure performance. Below, we will show that
Reinforcement Learning (RL) produces a signifi-
cant improvement over the strategies present in the
original data, especially in cases where RL has ac-
cess to ?lower level? features of the context.
4 The Simulation / Learning
Environment
Here we ?bootstrap? a simulated training environ-
ment from the WoZ data, following (Rieser and
Lemon, 2008).
4.1 User Simulations
User Simulations are commonly used to train
strategies for Dialogue Management, see for ex-
ample (Young et al, 2007). A user simulation for
NLG is very similar, in that it is a predictive model
of the most likely next user act. 4 However, this
NLG predicted user act does not actually change
the overall dialogue state (e.g. by filling slots) but
it only changes the generator state. In other words,
4Similar to the internal user models applied in recent
work on POMDP (Partially Observable Markov Decision
Process) dialogue managers (Young et al, 2007; Henderson
and Lemon, 2008; Gasic et al, 2008) for estimation of user
act probabilities.
1012
the NLG user simulation tells us what the user is
most likely to do next, if we were to stop generat-
ing now.
We are most interested in the following user re-
actions:
1. select: the user chooses one of the pre-
sented items, e.g. ?Yes, I?ll take that one.?.
This reply type indicates that the Informa-
tion Presentation was sufficient for the user
to make a choice.
2. addInfo: The user provides more at-
tributes, e.g. ?I want something cheap.?. This
reply type indicates that the user has more
specific requests, which s/he wants to specify
after being presented with the current infor-
mation.
3. requestMoreInfo: The user asks for
more information, e.g. ?Can you recommend
me one??, ?What is the price range of the
last item??. This reply type indicates that the
system failed to present the information the
user was looking for.
4. askRepeat: The user asks the system to
repeat the same message again, e.g. ?Can you
repeat??. This reply type indicates that the
utterance was either too long or confusing for
the user to remember, or the TTS quality was
not good enough, or both.
5. silence: The user does not say anything.
In this case it is up to the system to take ini-
tiative.
6. hangup: The user closes the interaction.
We build user simulations using n-gram mod-
els of system (s) and user (u) acts, as first
introduced by (Eckert et al, 1997). In or-
der to account for data sparsity, we apply dif-
ferent discounting (?smoothing?) techniques in-
cluding back-off, using the CMU Statistical Lan-
guage Modelling toolkit (Clarkson and Rosen-
feld, 1997). We construct a bi-gram model5
for the users? reactions to the system?s IP struc-
ture decisions (P (au,t|IPs,t)), and a tri-gram
(i.e. IP structure + attribute choice) model for
predicting user reactions to the system?s com-
bined IP structure and attribute selection deci-
sions: P (au,t|IPs,t, attributess,t).
5Where au,t is the predicted next user action at time t,
IPs,t was the system?s Information Presentation action at t,
and attributess,t is the attributes selected by the system at t.
We evaluate the performance of these models
by measuring dialogue similarity to the original
data, based on the Kullback-Leibler (KL) diver-
gence, as also used by, e.g. (Cuaya?huitl et al,
2005; Jung et al, 2009; Janarthanam and Lemon,
2009). We compare the raw probabilities as ob-
served in the data with the probabilities generated
by our n-gram models using different discounting
techniques for each context, see table 2. All the
models have a small divergence from the origi-
nal data (especially the bi-gram model), suggest-
ing that they are reasonable simulations for train-
ing and testing NLG policies.
The absolute discounting method for the bi-
gram model is most dissimilar to the data, as is the
WittenBell method for the tri-gram model, i.e. the
models using these discounting methods have the
highest KL score. The best performing methods
(i.e. most similar to the original data), are linear
discounting for the bi-gram model and GoodTur-
ing for the tri-gram. We use the most similar user
models for system training, and the most dissimi-
lar user models for testing NLG policies, in order
to test whether the learned policies are robust and
adaptive to unseen dialogue contexts.
discounting method bi-gram US tri-gram US
WittenBell 0.086 0.512
GoodTuring 0.086 0.163
absolute 0.091 0.246
linear 0.011 0.276
Table 2: Kullback-Leibler divergence for the dif-
ferent User Simulations (US)
4.2 Database matches and ?Focus of
attention?
An important task of Information Presentation is
to support the user in choosing between all the
available items (and ultimately in selecting the
most suitable one) by structuring the current infor-
mation returned from the database, as explained in
Section 1.1. We therefore model the user?s ?fo-
cus of attention? as a feature in our learning ex-
periments. This feature reflects how the differ-
ent IP strategies structure information with dif-
ferent numbers of attributes. We implement this
shift of the user?s focus analogously to discover-
ing the user?s goal in Dialogue Management: ev-
ery time the predicted next user act is to add in-
1013
formation (addInfo), we infer that the user is
therefore only interested in a subset of the previ-
ously presented results and so the system will fo-
cus on this new subset of database items in the rest
of the generated utterance. For example, the user?s
focus after the SUMMARY (with UM) in Table 1 is
DBhits = 10, since the user is only interested in
cheap, Indian places.
4.3 Data-driven Reward function
The reward/evaluation function is constructed
from the WoZ data, using a stepwise linear regres-
sion, following the PARADISE framework (Walker
et al, 2000). This model selects the features
which significantly influenced the users? ratings
for the NLG strategy in the WoZ questionnaire.
We also assign a value to the user?s reactions
(valueUserReaction), similar to optimising task
success for DM (Young et al, 2007). This reflects
the fact that good IP strategies should help the
user to select an item (valueUserReaction =
+100) or provide more constraints addInfo
(valueUserReaction = ?0), but the user should
not do anything else (valueUserReaction =
?100). The regression in equation 1 (R2 =
.26) indicates that users? ratings are influenced by
higher level and lower level features: Users like to
be focused on a small set of database hits (where
#DBhits ranges over [1-100]), which will enable
them to choose an item (valueUserReaction),
while keeping the IP utterances short (where
#sentence is in the range [2-18]):
Reward = (?1.2)?#DBhits (1)
+(.121)? valueUserReaction
?(1.43)?#sentence
Note that the worst possible reward for an NLG
move is therefore (?1.20?100)? (.121?100)?
(18 ? 1.43) = ?157.84. This is achieved by pre-
senting 100 items to the user in 18 sentences6, in
such a way that the user ends the conversation un-
successfully. The top possible reward is achieved
in the rare cases where the system can immedi-
ately present 1 item to the user using just 2 sen-
tences, and the user then selects that item, i.e. Re-
ward =?(1.20?1)+(.121?100)?(2?1.43) =
8.06
6Note that the maximum possible number of sentences
generated by the realizer is 18 for the full IP sequence SUM-
MARY+COMPARE+RECOMMEND using all the attributes.
5 Reinforcement Learning experiments
We now formulate the problem as a Markov De-
cision Process (MDP), where states are NLG di-
alogue contexts and actions are NLG decisions.
Each state-action pair is associated with a transi-
tion probability, which is the probability of mov-
ing from state s at time t to state s? at time t+1 af-
ter having performed action a when in state s. This
transition probability is computed by the environ-
ment model (i.e. the user simulation and realiser),
and explicitly captures the uncertainty in the gen-
eration environment. This is a major difference
to other non-statistical planning approaches. Each
transition is also associated with a reinforcement
signal (or ?reward?) rt+1 describing how good the
result of action a was when performed in state s.
The aim of the MDP is to maximise long-term ex-
pected reward of its decisions, resulting in a policy
which maps each possible state to an appropriate
action in that state.
We treat IP as a hierarchical joint optimisation
problem, where first one of the IP structures (1-
3) is chosen and then the number of attributes is
decided, as shown in Figure 4. At each genera-
tion step, the MDP can choose 1-5 attributes (e.g.
cuisine, price range, location, food quality, and/or
service quality). Generation stops as soon as the
user is predicted to select an item, i.e. the IP task
is successful. (Note that the same constraint is op-
erational for the WoZ baseline.)
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
ACTION:
?
?IP:
?
?
?
SUMMARY
COMPARE
RECOMMEND
?
?
?
{
attr: 1-5
}
?
?
STATE:
?
?
?
?
?
?
?
?
?
?
?
attributes:
{
1-15
}
sentence:
{
2-18
}
dbHitsFocus:
{
1-100
}
userSelect:
{
0,1
}
userAddInfo:
{
0,1
}
userElse:
{
0,1
}
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 4: State-Action space for the RL-NLG
problem
States are represented as sets of NLG dia-
logue context features. The state space comprises
?lower-level? features about the realiser behaviour
(two discrete features representing the number of
attributes and sentences generated so far) and three
binary features representing the user?s predicted
next action, as well as ?high-level? features pro-
1014
vided by the DM (e.g. current database hits in the
user?s focus (dbHitsFocus)). We trained the
policy using the SHARSHA algorithm (Shapiro and
Langley, 2002) with linear function approximation
(Sutton and Barto, 1998), and the simulation envi-
ronment described in Section 4. The policy was
trained for 60,000 iterations.
5.1 Experimental Set-up
We compare the learned strategies against the WoZ
baseline as described in Section 3.3. For attribute
selection we choose a majority baseline (randomly
choosing between 3 or 4 attributes) since the at-
tribute selection models learned by Supervised
Learning on the WoZ data didn?t show significant
improvements.
For training, we used the user simulation model
most similar to the data, see Section 4.1. For
testing, we test with the different user simulation
model (the one which is most dissimilar to the
data).
We first investigate how well IP structure (with-
out attribute choice) can be learned in increas-
ingly complex generation scenarios. A genera-
tion scenario is a combination of a particular kind
of NLG realiser (template vs. stochastic) along
with different levels of variation introduced by cer-
tain features of the dialogue context. In general,
the stochastic realiser introduces more variation
in lower level features than the template-based re-
aliser. The Focus model introduces more varia-
tion with respect to #DBhits and #attributes as de-
scribed in Section 4.2. We therefore investigate
the following cases:
1.1. IP structure choice, Template realiser:
Predicted next user action varies according to
the bi-gram model (P (au,t|IPs,t)); Number
of sentences and attributes per IP strategy is
set by defaults, reflecting a template-based
realiser.
1.2. IP structure choice, Stochastic realiser:
IP structure where number of attributes per
NLG turn is given at the beginning of each
episode (e.g. set by the DM); Sentence gen-
eration according to the SPaRKy stochastic
realiser model as described in Section 3.2.
We then investigate different scenarios for
jointly optimising IP structure (IPS) and attribute
selection (Attr) decisions.
2.1. IPS+Attr choice, Template realiser:
Predicted next user action varies according
to tri-gram (P (au,t|IPs,t, attributess,t))
model; Number of sentences per IP structure
set to default.
2.2. IPS+Attr choice, Template realiser+Focus model:
Tri-gram user simulation with Template re-
aliser and Focus of attention model with
respect to #DBhits and #attributes as
described in section 4.2.
2.3. IPS+Attr choice, Stochastic realiser: Tri-
gram user simulation with sentence/attribute
relationship according to Stochastic realiser
as described in Section 3.2.
2.4. IPS+Attr choice, Stochastic realiser+Focus:
i.e. the full model = Predicted next user ac-
tion varies according to tri-gram model+
Focus of attention model + Sentence/attribute
relationship according to stochastic realiser.
5.2 Results
We compare the average final reward (see Equa-
tion 1) gained by the baseline against the trained
RL policies in the different scenarios for each
1000 test runs, using a paired samples t-test. The
results are shown in Table 3. In 5 out of 6 scenar-
ios the RL policy significantly (p < .001) outper-
forms the supervised baseline. We also report on
the percentage of the top possible reward gained
by the individual policies, and the raw percentage
improvement of the RL policy. Note that the best
possible (100%) reward can only be gained in rare
cases (see Section 4.3).
The learned RL policies show that lower level
features are important in gaining significant im-
provements over the baseline. The more complex
the scenario, the harder it is to gain higher rewards
for the policies in general (as more variation is in-
troduced), but the relative improvement in rewards
also increases with complexity: the baseline does
not adapt well to the variations in lower level fea-
tures whereas RL learns to adapt to the more chal-
lenging scenarios. 7
An overview of the range of different IP strate-
gies learned for each setup can be found in Table 4.
Note that these strategies are context-dependent:
the learner chooses how to proceed dependent on
7Note, that the baseline does reasonably well in scenarios
with variation introduced by only higher level features (e.g.
scenario 2.2).
1015
Scenario
Wizard Baseline
average Reward
RL average Reward
RL % - Baseline %
= % improvement
1.1 -15.82(?15.53) -9.90***(?15.38) 89.2% - 85.6%= 3.6%
1.2 -19.83(?17.59) -12.83***(?16.88) 87.4% - 83.2%= 4.2%
2.1 -12.53(?16.31) -6.03***(?11.89) 91.5% - 87.6%= 3.9%
2.2 -14.15(?16.60) -14.18(?18.04) 86.6% - 86.6%= 0.0%
2.3 -17.43(?15.87) -9.66***(?14.44) 89.3% - 84.6%= 4.7%
2.4 -19.59(?17.75) -12.78***(?15.83) 87.4% - 83.3%= 4.1%
Table 3: Test results for 1000 dialogues, where *** denotes that the RL policy is significantly (p < .001)
better than the Baseline policy.
the features in the state space at each generation
step.
Scenario strategies learned
1.1
RECOMMEND
COMPARE
COMPARE+RECOMMEND
SUMMARY
SUMMARY+COMPARE
SUMMARY+RECOMMEND
SUMMARY+COMPARE+RECOMMEND.
1.2
RECOMMEND
COMPARE
COMPARE+RECOMMEND
SUMMARY
SUMMARY+COMPARE
SUMMARY+RECOMMEND
SUMMARY+COMPARE+RECOMMEND.
2.1
RECOMMEND(5)
SUMMARY(2)
SUMMARY(2)+COMPARE(4)
SUMMARY(2)+COMPARE(1)
SUMMARY(2)+COMPARE(4)+RECOMMEND(5)
SUMMARY(2)+COMPARE(1)+RECOMMEND(5)
2.2
RECOMMEND(5)
SUMMARY(4)
SUMMARY(4)+RECOMMEND(5)
2.3
RECOMMEND(2)
SUMMARY(1)
SUMMARY(1)+COMPARE(4)
SUMMARY(1)+COMPARE(1)
SUMMARY(1)+COMPARE(4)+RECOMMEND(2)
2.4
RECOMMEND(2)
SUMMARY(2)
SUMMARY(2)+COMPARE(4)
SUMMARY(2)+RECOMMEND(2)
SUMMARY(2)+COMPARE(4)+RECOMMEND(2)
SUMMARY(2)+COMPARE(1)+RECOMMEND(2)
Table 4: RL strategies learned for the different sce-
narios, where (n) denotes the number of attributes
generated.
For example, the RL policy for scenario 1.1
learned to start with a SUMMARY if the initial num-
ber of items returned from the database is high
(>30). It will then stop generating if the user is
predicted to select an item. Otherwise, it contin-
ues with a RECOMMEND. If the number of database
items is low, it will start with a COMPARE and then
continue with a RECOMMEND, unless the user selects
an item. Also see Table 4. Note that the WoZ strat-
egy behaves as described in Figure 3.
In addition, the RL policy for scenario 1.2
learns to adapt to a more complex scenario:
the number of attributes requested by the DM
and produced by the stochastic sentence re-
aliser. It learns to generate the whole sequence
(SUMMARY+COMPARE+RECOMMEND) if #attributes is
low (<3), because the overall generated utterance
(final #sentences) is still relatively short. Other-
wise the policy is similar to the one for scenario
1.1.
The RL policies for jointly optimising IP strat-
egy and attribute selection learn to select the num-
ber of attributes according to the generation sce-
narios 2.1-2.4. For example, the RL policy learned
for scenario 2.1 generates a RECOMMEND with 5 at-
tributes if the database hits are low (<13). Oth-
erwise, it will start with a SUMMARY using 2 at-
tributes. If the user is predicted to narrow down
his focus after the SUMMARY, the policy continues
with a COMPARE using 1 attribute only, otherwise it
helps the user by presenting 4 attributes. It then
continues with RECOMMEND(5), and stops as soon
as the user is predicted to select one item.
The learned policy for scenario 2.1 generates
5.85 attributes per NLG turn on average (i.e. the
cumulative number of attributes generated in the
whole NLG sequence, where the same attribute
may be repeated within the sequence). This strat-
egy primarily adapts to the variations from the user
simulation (tri-gram model). For scenario 2.2 the
average number of attributes is higher (7.15) since
the number of attributes helps to narrow down the
user?s focus via the DBhits/attribute relationship
specified in section 4.2. For scenario 2.3 fewer
attributes are generated on average (3.14), since
here the number of attributes influences the sen-
tence realiser, i.e. fewer attributes results in fewer
sentences, but does not impact the user?s focus.
In scenario 2.4 all the conditions mentioned above
influence the learned policy. The average number
of attributes selected is still low (3.19).
In comparison, the average (cumulative) num-
1016
ber of attributes for the WoZ baseline is 7.10. The
WoZ baseline generates all the possible IP struc-
tures (with 3 or 4 attributes) but is restricted to use
only ?high-level? features (see Figure 3). By beat-
ing this baseline we show the importance of the
?lower-level? features. Nevertheless, this wizard
policy achieves up to 87.6% of the possible reward
on this task, and so can be considered a serious
baseline against which to measure performance.
The only case (scenario 2.2) where RL does not
improve significantly over the baseline is where
lower level features do not play an important role
for learning good strategies: scenario 2.2 is only
sensitive to higher level features (DBhits).
6 Conclusion
We have presented a new data-driven method for
Information Presentation (IP) in Spoken Dialogue
Systems using a statistical optimisation frame-
work for content structure planning and attribute
selection. This work is the first to apply a data-
driven optimisation method to the IP decision
space, and to show the utility of both lower-level
and higher-level features for this problem.
We collected data in a Wizard-of-Oz (WoZ)
experiment and showed that human ?wizards?
mostly pay attention to ?high-level? features from
Dialogue Management. The WoZ data was used
to build statistical models of user reactions to
IP strategies, and a data-driven reward function
for Reinforcement Learning (RL). We show that
lower level features significantly influence users?
ratings of IP strategies. We compared a model of
human behaviour (the ?human wizard baseline?)
against policies optimised using Reinforcement
Learning, in a variety of scenarios. Our optimised
policies significantly outperform the IP structuring
and attribute selection present in the WoZ data, es-
pecially when performing in complex generation
scenarios which require adaptation to, e.g. number
of database results, utterance length, etc. While
the human wizards were able to attain up to 87.6%
of the possible reward on this task, the RL poli-
cies are significantly better in 5 out of 6 scenarios,
gaining up to 91.5% of the total possible reward.
We have also shown that adding predictive
?lower level? features, e.g. from the NLG realiser
and a user reaction model, is important for learn-
ing optimal IP strategies according to user pref-
erences. Future work could include the predicted
TTS quality (Boidin et al, 2009) as a feature.
We are now working on testing the learned poli-
cies with real users, outside of laboratory condi-
tions, using a restaurant-guide SDS, deployed as a
VOIP service. Previous work in SDS has shown
that results for Dialogue Management obtained
with simulated users are able to transfer to eval-
uations with real users (Lemon et al, 2006).
This methodology provides new insights into
the nature of the IP problem, which has previously
been treated as a module following dialogue man-
agement with no access to lower-level context fea-
tures. The data-driven planning method applied
here promises a significant upgrade in the perfor-
mance of generation modules, and thereby of Spo-
ken Dialogue Systems in general.
Acknowledgments
The research leading to these results has received
funding from the European Community?s Seventh
Framework Programme (FP7/2007-2013) under
grant agreement no. 216594 (CLASSiC project
www.classic-project.org) and from the
EPSRC, project no. EP/G069840/1.
References
Cedric Boidin, Verena Rieser, Lonneke van der Plas,
Oliver Lemon, and Jonathan Chevelu. 2009. Pre-
dicting how it sounds: Re-ranking alternative in-
puts to TTS using latent variables (forthcoming). In
Proc. of Interspeech/ICSLP, Special Session on Ma-
chine Learning for Adaptivity in Spoken Dialogue
Systems.
Grace Chung. 2004. Developing a flexible spoken dia-
log system using simulation. In Proc. of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL).
P.R. Clarkson and R. Rosenfeld. 1997. Statisti-
cal Language Modeling Using the CMU-Cambridge
Toolkit. In Proc. of ESCA Eurospeech.
William W. Cohen. 1995. Fast effective rule induction.
In Proceedings of the 12th International Conference
on Machine Learning (ICML).
Heriberto Cuaya?huitl, Steve Renals, Oliver Lemon, and
Hiroshi Shimodaira. 2005. Human-computer dia-
logue simulation using hidden markov models. In
Proc. of the IEEE workshop on Automatic Speech
Recognition and Understanding (ASRU).
Vera Demberg and Johanna D. Moore. 2006. Infor-
mation presentation in spoken dialogue systems. In
Proceedings of EACL.
1017
W. Eckert, E. Levin, and R. Pieraccini. 1997. User
modeling for spoken dialogue system evaluation. In
Proc. of the IEEE workshop on Automatic Speech
Recognition and Understanding (ASRU).
M. Gasic, S. Keizer, F. Mairesse, J. Schatzmann,
B. Thomson, and S. Young. 2008. Training and
Evaluation of the HIS POMDP Dialogue System in
Noise. In Proc. of SIGdial Workshop on Discourse
and Dialogue.
James Henderson and Oliver Lemon. 2008. Mixture
Model POMDPs for Efficient Handling of Uncer-
tainty in Dialogue Management. In Proc. of ACL.
Srinivasan Janarthanam and Oliver Lemon. 2009. A
Two-tier User Simulation Model for Reinforcement
Learning of Adaptive Referring Expression Genera-
tion Policies. In Proc. of SIGdial.
Srini Janarthanam and Oliver Lemon. 2010. Learn-
ing to adapt to unknown users: Referring expression
generation in spoken dialogue systems. In Proceed-
ings of ACL.
Sangkeun Jung, Cheongjae Lee, Kyungduk Kim, Min-
woo Jeong, and Gary Geunbae Lee. 2009. Data-
driven user simulation for automated evaluation of
spoken dialog systems. Computer, Speech & Lan-
guage, 23:479?509.
Alexander Koller and Ronald Petrick. 2008. Experi-
ences with planning for natural language generation.
In ICAPS.
Oliver Lemon, Kallirroi Georgila, and James Hender-
son. 2006. Evaluating Effectiveness and Portabil-
ity of Reinforcement Learned Dialogue Strategies
with real users: the TALK TownInfo Evaluation. In
IEEE/ACL Spoken Language Technology.
Oliver Lemon. 2008. Adaptive Natural Language
Generation in Dialogue using Reinforcement Learn-
ing. In Proceedings of SEMdial.
Oliver Lemon. 2010. Learning what to say and how to
say it: joint optimization of spoken dialogue man-
agement and Natural Language Generation. Com-
puter, Speech & Language, to appear.
Xingkun Liu, Verena Rieser, and Oliver Lemon. 2009.
A wizard-of-oz interface to study information pre-
sentation strategies for spoken dialogue systems. In
Proc. of the 1st International Workshop on Spoken
Dialogue Systems.
Crystal Nakatsu. 2008. Learning contrastive connec-
tives in sentence realization ranking. In Proc. of
SIGdial Workshop on Discourse and Dialogue.
Joseph Polifroni and Marilyn Walker. 2006. Learning
database content for spoken dialogue system design.
In Proc. of the IEEE/ACL workshop on Spoken Lan-
guage Technology (SLT).
Joseph Polifroni and Marilyn Walker. 2008. Inten-
sional Summaries as Cooperative Responses in Di-
alogue Automation and Evaluation. In Proceedings
of ACL.
Verena Rieser and Oliver Lemon. 2008. Learn-
ing Effective Multimodal Dialogue Strategies from
Wizard-of-Oz data: Bootstrapping and Evaluation.
In Proc. of ACL.
Verena Rieser and Oliver Lemon. 2009. Natural Lan-
guage Generation as Planning Under Uncertainty for
Spoken Dialogue Systems. In Proc. of EACL.
Verena Rieser, Xingkun Liu, and Oliver Lemon. 2009.
Optimal Wizard NLG Behaviours in Context. Tech-
nical report, Deliverable 4.2, CLASSiC Project.
Dan Shapiro and P. Langley. 2002. Separating skills
from preference: Using learning to program by re-
ward. In Proc. of the 19th International Conference
on Machine Learning (ICML).
Amanda Stent, Rashmi Prasad, and Marilyn Walker.
2004. Trainable sentence planning for complex in-
formation presentation in spoken dialog systems. In
Association for Computational Linguistics.
R. Sutton and A. Barto. 1998. Reinforcement Learn-
ing. MIT Press.
Kees van Deemter. 2009. What game theory can do
for NLG: the case of vague language. In 12th Eu-
ropean Workshop on Natural Language Generation
(ENLG).
Marilyn A. Walker, Candace A. Kamm, and Diane J.
Litman. 2000. Towards developing general mod-
els of usability with PARADISE. Natural Language
Engineering, 6(3).
M. Walker, R. Passonneau, and J. Boland. 2001. Quan-
titative and qualitative evaluation of DARPA Com-
municator spoken dialogue systems. In Proc. of
the Annual Meeting of the Association for Compu-
tational Linguistics (ACL).
Marilyn Walker, Amanda Stent, Franc?ois Mairesse, and
Rashmi Prasad. 2007. Individual and domain adap-
tation in sentence planning for dialogue. Journal of
Artificial Intelligence Research (JAIR), 30:413?456.
Steve Whittaker, Marilyn Walker, and Johanna Moore.
2002. Fish or Fowl: A Wizard of Oz evaluation
of dialogue strategies in the restaurant domain. In
Proc. of the International Conference on Language
Resources and Evaluation (LREC).
Andi Winterboer, Jiang Hu, Johanna D. Moore, and
Clifford Nass. 2007. The influence of user tailoring
and cognitive load on user performance in spoken
dialogue systems. In Proc. of the 10th International
Conference of Spoken Language Processing (Inter-
speech/ICSLP).
SJ Young, J Schatzmann, K Weilhammer, and H Ye.
2007. The Hidden Information State Approach to
Dialog Management. In ICASSP 2007.
1018
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 49?54,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
A Web-based Evaluation Framework for Spatial Instruction-Giving Systems
Srinivasan Janarthanam, Oliver Lemon, and Xingkun Liu
Interaction Lab
School of Mathematical and Computer Sciences
Heriot Watt University, Edinburgh
sc445,o.lemon,x.liu@hw.ac.uk
Abstract
We demonstrate a web-based environment for
development and testing of different pedes-
trian route instruction-giving systems. The
environment contains a City Model, a TTS
interface, a game-world, and a user GUI in-
cluding a simulated street-view. We describe
the environment and components, the metrics
that can be used for the evaluation of pedes-
trian route instruction-giving systems, and the
shared challenge which is being organised us-
ing this environment.
1 Introduction
Generating navigation instructions in the real world
for pedestrians is an interesting research problem
for researchers in both computational linguistics
and geo-informatics (Dale et al, 2003; Richter and
Duckham, 2008). These systems generate verbal
route directions for users to go from A to B, and
techniques range from giving ?a priori? route direc-
tions (i.e. all route information in a single turn) and
incremental ?in-situ? instructions, to full interactive
dialogue systems (see section 4). One of the major
problems in developing such systems is in evaluat-
ing them with real users in the real world. Such eval-
uations are expensive, time consuming and painstak-
ing to organise, and are carried out not just at the end
of the project but also during the development cycle.
Consequently, there is a need for a common platform
to effectively compare the performances of verbal
navigation systems developed by different teams us-
ing a variety of techniques (e.g. a priori vs. in-situ
or rule-based vs. machine learning).
This demonstration system brings together exist-
ing online data resources and software toolkits to
create a low-cost framework for evaluation of pedes-
trian route instruction systems. We have built a
web-based environment containing a simulated real
world in which users can simulate walking on the
streets of real cities whilst interacting with differ-
ent navigation systems. This evaluation framework
will be used in the near future to evaluate a series of
instruction-giving dialogue systems.
2 Related work
The GIVE challenge developed a 3D virtual in-
door environment for development and evaluation
of indoor pedestrian navigation instruction systems
(Koller et al, 2007; Byron et al, 2007). In this
framework, users can walk through a building with
rooms and corridors, similar to a first-person shooter
game. The user is instructed by a navigation sys-
tem that generates route instructions. The basic idea
was to have several such navigation systems hosted
on the GIVE server and evaluate them in the same
game worlds, with a number of users over the in-
ternet. Conceptually our work is very similar to the
GIVE framework, but its objective is to evaluate sys-
tems that instruct pedestrian users in the real world.
The GIVE framework has been successfully used for
comparative evaluation of several systems generat-
ing instructions in virtual indoor environments.
Another system, ?Virtual Navigator?, is a simu-
lated 3D environment that simulates the real world
for training blind and visually impaired people to
learn often-used routes and develop basic naviga-
tion skills (McGookin et al, 2010). The framework
49
uses haptic force-feedback and spatialised auditory
feedback to simulate the interaction between users
and the environment they are in. The users simulate
walking by using arrow keys on a keyboard and by
using a device that works as a 3D mouse to simulate
a virtual white cane. Auditory clues are provided
to the cane user to indicate for example the differ-
ence between rush hour and a quiet evening in the
environment. While this simulated environment fo-
cusses on the providing the right kind of tactile and
auditory feedback to its users, we focus on provid-
ing a simulated environment where people can look
at landmarks and navigate based on spatial and vi-
sual instructions provided to them.
User simulation modules are usually developed
to train and test reinforcement learning based in-
teractive spoken dialogue systems (Janarthanam and
Lemon, 2009; Georgila et al, 2006; Schatzmann et
al., 2006). These agents replace real users in interac-
tion with dialogue systems. However, these models
simulate the users? behaviours in addition to the en-
vironment in which they operate. Users? dialogue
and physical behaviour are dependent on a number
of factors such as a user?s preferences, goals, knowl-
edge of the environment, environmental constraints,
etc. Simulating a user?s behaviour realistically based
on many such features requires large amounts of
data. In contrast to this approach, we propose a sys-
tem where only the spatial and visual environment is
simulated.
See section 4 for a discussion of different pedes-
trian navigation systems.
3 Architecture
The evaluation framework architecture is shown in
figure 1. The server side consists of a broker module,
navigation system, gameworld server, TTS engine,
and a city model. On the user?s side is a web-based
client that consists of the simulated real-world and
the interaction panel.
3.1 Game-world module
Walking aimlessly in the simulated real world can be
a boring task. Therefore, instead of giving web users
navigation tasks from A to B, we embed navigation
tasks in a game-world overlaid on top of the simu-
lated real world. We developed a ?treasure hunting?
game which consists of users solving several pieces
of a puzzle to discover the location of the treasure
chest. In order to solve the puzzle, they interact with
game characters (e.g. a pirate) to obtain clues as to
where the next clue is. This sets the user a number of
navigation tasks to acquire the next clues until they
find the treasure. In order to keep the game interest-
ing, the user?s energy depletes as time goes on and
they therefore have limited time to find the treasure.
Finally, the user?s performance is scored to encour-
age users to return. The game characters and enti-
ties like keys, chests, etc. are laid out on real streets
making it easy to develop a game without develop-
ing a game-world. New game-worlds can be easily
scripted using Javascript, where the location (lati-
tude and longitude) and behaviour of the game char-
acters are defined. The game-world module serves
game-world specifications to the web-based client.
3.2 Broker
The broker module is a web server that connects the
web clients to their corresponding different naviga-
tion systems. This module ensures that the frame-
work works for multiple users. Navigation systems
are instantiated and assigned to new users when they
first connect to the broker. Subsequent messages
from the users will be routed to the assigned navi-
gation system. The broker communicates with the
navigation systems via a communication platform
thereby ensuring that different navigation systems
developed using different languages (such as C++,
Java, Python, etc) are supported.
3.3 Navigation system
The navigation system is the central component of
this architecture, which provides the user instruc-
tions to reach their destinations. Each navigation
system is run as a server remotely. When a user?s
client connects to the server, it instantiates a navi-
gation system object and assigns it to the user ex-
clusively. Every user is identified using a unique id
(UUID), which is used to map the user to his/her re-
spective navigation system. The navigation system
is introduced in the game scenario as a buddy sys-
tem that will help the user in his objective: find the
treasure. The web client sends the user?s location to
the system periodically (every few seconds).
50
Figure 1: Evaluation framework architecture
3.4 TTS engine
Alongside the navigation system we use the Cere-
proc text-to-speech engine that converts the utter-
ances of the system into speech. The URL of the
audio file is then sent to the client?s browser which
then uses the audio plugin to play the synthesized
speech to the user. The TTS engine need not be used
if the output modality of the system is just text.
3.5 City Model
The navigation system is supported by a database
called the City Model. The City Model is a GIS
database containing a variety of data required to sup-
port navigation tasks. It has been derived from an
open-source data source called OpenStreetMaps1. It
consists of the following:
? Street network data: the street network data
consists of nodes and ways representing junc-
tions and streets.
? Amenities: such as ATMs, public toilets, etc.
? Landmarks: other structures that can serve as
landmarks. E.g. churches, restaurants, etc.
The amenities and landmarks are represented as
nodes (with latitude and longitude information). The
City Model interface API consists of a number of
1www.openstreetmaps.org
subroutines to access the required information such
as the nearest amenity, distance or route from A to B,
etc. These subroutines provide the interface between
the navigation systems and the database.
3.6 Web-based client
The web-based client is a JavaScript/HTML pro-
gram running on the user?s web browser software
(e.g. Google Chrome). A snapshot of the webclient
is shown in figure 2. It has two parts: the streetview
panel and the interaction panel.
Streetview panel: the streetview panel presents a
simulated real world visually to the user. When
the page loads, a Google Streetview client (Google
Maps API) is created with an initial user coordinate.
Google Streetview is a web service that renders a
panoramic view of real streets in major cities around
the world. This client allows the web user to get a
panoramic view of the streets around the user?s vir-
tual location. A gameworld received from the server
is overlaid on the simulated real world. The user can
walk around and interact with game characters using
the arrow keys on his keyboard or the mouse. As the
user walks around, his location (stored in the form
of latitude and longitude coordinates) gets updated
locally. Streetview also returns the user?s point of
view (0-360 degrees), which is also stored locally.
Interaction panel: the web-client also includes an
51
interaction panel that lets the user interact with his
buddy navigation system. In addition to user lo-
cation information, users can also interact with the
navigation system using textual utterances or their
equivalents. We provide users with two types of in-
teraction panel: a GUI panel and a text panel. In the
GUI panel, there are GUI objects such as buttons,
drop-down lists, etc. which can be used to construct
requests and responses to the system. By clicking
the buttons, users can send abstract semantic repre-
sentations (dialogue actions) that are equivalent to
their textual utterances. For example, the user can
request a route to a destination by selecting the street
name from a drop down list and click on the Send
button. Similarly, users can click on ?Yes?, ?No?,
?OK?, etc. buttons to respond to the system?s ques-
tions and instructions. In the text panel, on the other
hand, users are free to type any request or response
they want. Of course, both types of inputs are parsed
by the navigation system. We also plan to add an ad-
ditional input channel that can stream user speech to
the navigation system in the future.
4 Candidate Navigation Systems
This framework can be used to evaluate a variety
of navigation systems. Route navigation has been
an interesting research topic for researchers in both
geoinformatics and computational linguistics alike.
Several navigation prototype systems have been de-
veloped over the years. Although there are several
systems that do not use language as a means of com-
munication for navigation tasks (instead using geo-
tagged photographs (Beeharee and Steed, 2006; Hi-
ley et al, 2008), haptics (Bosman et al, 2003), mu-
sic (Holland et al, 2002; Jones et al, 2008), etc), we
focus on systems that generate instructions in natu-
ral language. Therefore, our framework does not in-
clude systems that generate routes on 2D/3D maps
as navigation aids.
Systems that generate text/speech can be further
classified as follows:
? ?A priori? systems: these systems generate
route instructions prior to the users touring the
route. These systems describe the entire route
before the user starts navigating. Several web
services exist that generate such lists of step-
by-step instructions (e.g. Google/Bing direc-
tions).
? ?In-situ? or incremental route instruction sys-
tems: these systems generate route instructions
incrementally along the route. e.g. CORAL
(Dale et al, 2003). They keep track of the
user?s location and issue the next instruction
when the user reaches the next node on the
planned route. The next instruction tells the
user how to reach the new next node. Some
systems do not keep track of the user, but re-
quire the user to request the next instruction
when they reach the next node.
? Interactive navigation systems: these systems
are both incremental and interactive. e.g.
DeepMap (Malaka and Zipf, 2000). These
systems keep track of the user?s location and
proactively generate instructions based on user
proximity to the next node. In addition, they
can interact with users by asking them ques-
tions about entities in their viewshed. For ex-
ample ?Can you see a tower at about 100 feet
away??. Questions like these will let the system
assess the user?s location and thereby adapt its
instruction to the situated context.
5 Evaluation metrics
Navigation systems can be evaluated using two
kinds of metrics using this framework. Objective
metrics such as time taken by the user to finish
each navigation task and the game, distance trav-
elled, number of wrong turns, etc. can be directly
measured from the environment. Subjective met-
rics based on each user?s ratings of different features
of the system can be obtained through user satisfac-
tion questionnaires. In our framework, users are re-
quested to fill in a questionnaire at the end of the
game. The questionnaire consists of questions about
the game, the buddy, and the user himself, for exam-
ple:
? Was the game engaging?
? Would you play it again (i.e. another similar
gameworld)?
? Did your buddy help you enough?
52
Figure 2: Snapshot of the web client
? Were the buddy instructions easy to under-
stand?
? Were the buddy instructions ever wrong or mis-
placed?
? If you had the chance, will you choose the same
buddy in the next game?
? How well did you know the neighbourhood of
the gameworld before the game?
6 Evaluation scenarios
We aim to evaluate navigation systems under a vari-
ety of scenarios.
? Uncertain GPS: GPS positioning available in
smartphones is erroneous (Zandbergen and
Barbeau, 2011). Therefore, one scenario for
evaluation would be to test how robustly nav-
igation systems handle erroneous GPS signals
from the user?s end.
? Output modalities: the output of navigation
systems can be presented in two modalities:
text and speech. While speech may enable a
hands-free eyes-free navigation, text displayed
on navigation aids like smartphones may in-
crease cognitive load. We therefore believe it
will be interesting to evaluate the systems in
both conditions and compare the results.
? Noise in user speech: for systems that take
as input user speech, it is important to handle
noise in such a channel. Noise due to wind and
traffic is most common in pedestrian scenarios.
Scenarios with different levels of noise settings
can be evaluated.
? Adaptation to users: returning users may have
learned the layout of the game world. An inter-
esting scenario is to examine how navigation
systems adapt to user?s increasing spatial and
visual knowledge.
Errors in GPS positioning of the user and noise
in user speech can be simulated at the server end,
thereby creating a range of challenging scenarios to
evaluate the robustness of the systems.
7 The Shared Challenge
We plan to organise a shared challenge for outdoor
pedestrian route instruction generation, in which a
variety of systems can be evaluated. Participating
research teams will be able to use our interfaces
and modules to develop navigation systems. Each
team will be provided with a development toolkit
53
and documentation to setup the framework in their
local premises for development purposes. Devel-
oped systems will be hosted on our challenge server
and a web based evaluation will be organised in con-
sultation with the research community (Janarthanam
and Lemon, 2011).
8 Demonstration system
At the demonstration, we will present the evaluation
framework along with a demo navigation dialogue
system. The web-based client will run on a laptop
using a high-speed broadband connection. The nav-
igation system and other server modules will run on
a remote server.
Acknowledgments
The research has received funding from the
European Community?s Seventh Framework
Programme (FP7/2007-2013) under grant
agreement no. 216594 (SPACEBOOK project
www.spacebookproject.org).
References
Ashweeni K. Beeharee and Anthony Steed. 2006. A nat-
ural wayfinding exploiting photos in pedestrian navi-
gation systems. In Proceedings of the 8th conference
on Human-computer interaction with mobile devices
and services (2006).
S. Bosman, B. Groenendaal, J. W. Findlater, T. Visser,
M. de Graaf, and Panos Markopoulos. 2003. Gen-
tleGuide: An Exploration of Haptic Output for Indoors
Pedestrian Guidance. In Proceedings of 5th Interna-
tional Symposium, Mobile HCI 2003, Udine, Italy.
D. Byron, A. Koller, J. Oberlander, L. Stoia, and
K. Striegnitz. 2007. Generating Instructions in Vir-
tual Environments (GIVE): A challenge and evaluation
testbed for NLG. In Proceedings of the Workshop on
Shared Tasks and Comparative Evaluation in Natural
Language Generation.
Robert Dale, Sabine Geldof, and Jean-Philippe Prost.
2003. CORAL : Using Natural Language Generation
for Navigational Assistance. In Proceedings of the
Twenty-Sixth Australasian Computer Science Confer-
ence (ACSC2003), 4th7th February, Adelaide, South
Australia.
Kallirroi Georgila, James Henderson, and Oliver Lemon.
2006. User simulation for spoken dialogue systems:
Learning and evaluation. In Proceedings of Inter-
speech/ICSLP, pages 1065?1068.
Harlan Hiley, Ramakrishna Vedantham, Gregory Cuel-
lar, Alan Liuy, Natasha Gelfand, Radek Grzeszczuk,
and Gaetano Borriello. 2008. Landmark-based pedes-
trian navigation from collections of geotagged photos.
In Proceedings of the 7th International Conference on
Mobile and Ubiquitous Multimedia (MUM) 2008.
S. Holland, D. Morse, and H. Gedenryd. 2002. Audio-
gps: Spatial audio navigation with a minimal atten-
tion interface. Personal and Ubiquitous Computing,
6(4):253?259.
Srini Janarthanam and Oliver Lemon. 2009. A User Sim-
ulation Model for learning Lexical Alignment Policies
in Spoken Dialogue Systems. In European Workshop
on Natural Language Generation.
Srini Janarthanam and Oliver Lemon. 2011. The
GRUVE Challenge: Generating Routes under Uncer-
tainty in Virtual Environments. In Proceedings of
ENLG / Generation Challenges.
M. Jones, S. Jones, G. Bradley, N. Warren, D. Bainbridge,
and G. Holmes. 2008. Ontrack: Dynamically adapt-
ing music playback to support navigation. Personal
and Ubiquitous Computing, 12(7):513?525.
A. Koller, J. Moore, B. Eugenio, J. Lester, L. Stoia,
D. Byron, J. Oberlander, and K. Striegnitz. 2007.
Shared Task Proposal: Instruction Giving in Virtual
Worlds. In Workshop on Shared Tasks and Compar-
ative Evaluation in Natural Language Generation.
Rainer Malaka and Er Zipf. 2000. Deep Map - chal-
lenging IT research in the framework of a tourist in-
formation system. In Information and Communication
Technologies in Tourism 2000, pages 15?27. Springer.
D. McGookin, R. Cole, and S. Brewster. 2010. Vir-
tual navigator: Developing a simulator for independent
route learning. In Proceedings of Workshop on Haptic
Audio Interaction Design 2010, Denmark.
Kai-Florian Richter and Matt Duckham. 2008. Simplest
instructions: Finding easy-to-describe routes for navi-
gation. In Proceedings of the 5th international confer-
ence on Geographic Information Science.
Jost Schatzmann, Karl Weilhammer, Matt Stuttle, and
Steve Young. 2006. A survey of statistical user sim-
ulation techniques for reinforcement-learning of dia-
logue management strategies. The Knowledge Engi-
neering Review, 21:97?126.
P. A. Zandbergen and S. J. Barbeau. 2011. Positional
accuracy of assisted gps data from high-sensitivity
gps-enabled mobile phones. Journal of Navigation,
64(3):381?399.
54
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1660?1668,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Evaluating a City Exploration Dialogue System Combining
Question-Answering and Pedestrian Navigation
Srinivasan Janarthanam1, Oliver Lemon1, Phil Bartie2, Tiphaine Dalmas2,
Anna Dickinson2, Xingkun Liu1, William Mackaness2, and Bonnie Webber2
1 The Interaction Lab, Heriot-Watt University
2 Edinburgh University
sc445@hw.ac.uk
Abstract
We present a city navigation and tourist
information mobile dialogue app with in-
tegrated question-answering (QA) and ge-
ographic information system (GIS) mod-
ules that helps pedestrian users to nav-
igate in and learn about urban environ-
ments. In contrast to existing mobile apps
which treat these problems independently,
our Android app addresses the prob-
lem of navigation and touristic question-
answering in an integrated fashion using
a shared dialogue context. We evaluated
our system in comparison with Samsung
S-Voice (which interfaces to Google nav-
igation and Google search) with 17 users
and found that users judged our system to
be significantly more interesting to inter-
act with and learn from. They also rated
our system above Google search (with the
Samsung S-Voice interface) for tourist in-
formation tasks.
1 Introduction
We present a mobile dialogue system (an Android
app) called Spacebook that addresses the problem
of pedestrian navigation and tourist information in
urban environments. There has been little prior
work that addresses these two problems - naviga-
tion and tourist information provision - in an inte-
grated way. By navigation, we refer to the prob-
lem of finding appropriate destinations to go to
and the task of wayfinding to reach them and by
tourist information provision we refer to the prob-
lem of meeting the informational needs of a user
about entities such as museums, statues and fa-
mous personalities. A dialogue system such as this
could serve as a personal tour guide to pedestrian
tourists as they walk around unknown cities. With
the proliferation of smartphones, there has been a
number of mobile apps developed to address these
problems. However these apps have the following
problems: first, they demand the user?s visual at-
tention because they predominantly present infor-
mation on a mobile screen. This can be dangerous
in urban environments, as well as being distract-
ing. Second, these apps address the problems of
navigation and tourist information independently
and therefore do not have a shared interaction con-
text. This means that users cannot switch between
information and navigation tasks in a natural and
fluid manner.
User1: Take me to the National Museum.
System2: The National Museum is about 300m away..
System3: At the KFC, turn left on to South Bridge
System4 : Near you is the statue of David Hume.
User2: Who is David Hume.
System5: David Hume was a Scottish philosopher....
User3: Tell me more about David Hume.
System6: He was one of the most important figures in..
System7: You should be able to see the museum ...
User4: Tell me more about the museum.
System8: The National Museum of Scotland is a....
Table 1: An example interaction with the evalu-
ated system
In contrast to many existing mobile apps,
Spacebook has a speech-only interface and ad-
dresses both problems in an integrated way. We
conjecture that with a speech-only interface, users
can immerse themselves in exploring the city,
and that because of the shared context they can
switch between navigation and tourist information
tasks more easily. Using the navigational context,
Spacebook pushes point-of-interest information
which can then initiate tourist information tasks
using the QA module. Table 1 presents an example
interaction with our system showing the integrated
use of navigation and question-answering capabil-
1660
ities. Utterances System4-8 show the system?s ca-
pability to push information about nearby points-
of-interest (PoI) during a navigation task and an-
swer followup questions using the QA system (in
utterances User2 and User3). The final 3 utter-
ances show a natural switch between navigation to
an entity and QA about that entity.
We investigate whether our system using a com-
bination of geographical information system (GIS)
and natural language processing (NLP) technolo-
gies would be a better companion to pedestrian
city explorers than the current state-of-the-art mo-
bile apps. We hypothesize that, (1) users will find
our speech-only interface to navigation efficient as
it allows them to navigate without having to re-
peatedly look at a map and (2), that users will
find a dialogue interface which integrates touris-
tic question-answering and navigation within a
shared context to be useful for finding information
about entities in the urban environment. We first
present some related work in section 2. We de-
scribe the architecture of the system in section 3.
We then present our experimental design, results
and analysis in sections 5, 6 and 7.
2 Related work
Mobile apps such as Siri, Google Maps Naviga-
tion, Sygic, etc. address the problem of naviga-
tion while apps like Triposo, Guidepal, Wikihood,
etc. address the problem of tourist information by
presenting the user with descriptive information
about various points of interest (PoI) in the city.
While some exploratory apps present snippets of
information about a precompiled list of PoIs, other
apps dynamically generate a list of PoIs arranged
based on their proximity to the users. Users can
also obtain specific information about PoIs using
Search apps. Also, since these navigation and ex-
ploratory/search apps do not address both prob-
lems in an integrated way, users need to switch
between them and therefore lose interaction con-
text.
While most apps address these two problems
independently, some like Google Now, Google
Field Trip, etc, mix navigation with exploration.
But such apps present information primarily vi-
sually on the screen for the user to read. Some
of these are available for download at the Google
Play Android app store1. Several dialogue and
natural language systems have addressed the issue
1https://play.google.com/store
of pedestrian navigation (Malaka and Zipf, 2000;
Raubal and Winter, 2002; Dale et al, 2003; Bar-
tie and Mackaness, 2006; Shroder et al, 2011;
Dethlefs and Cuaya?huitl, 2011). There has also
been recent interest in shared tasks for generat-
ing navigation instructions in indoor and urban en-
vironments (Byron et al, 2007; Janarthanam and
Lemon, 2011). Some dialogue systems deal with
presenting information concerning points of inter-
est (Ko et al, 2005; Kashioka et al, 2011) and in-
teractive question answering (Webb and Webber,
2009).
In contrast, Spacebook has the objective of
keeping the user?s cognitive load low and prevent-
ing users from being distracted (perhaps danger-
ously so) from walking in the city (Kray et al,
2003). Also, it allows users to interleave the two
sub-tasks seamlessly and can keep entities dis-
cussed in both tasks in shared context (as shown
in Table 1).
3 Architecture
The architecture of the Spacebook system is
shown in figure 1. Our architecture brings to-
gether Spoken Dialogue Systems (SDS), Geo-
graphic Information Systems (GIS) and Question-
Answering (QA) technologies (Janarthanam et al,
2012). Its essentially a spoken dialogue system
(SDS) consisting of an automatic speech recog-
niser (ASR), a semantic parser, an Interaction
Manager, an utterance generator and a text-to-
speech synthesizer (TTS). The GIS modules in
this architecture are the City Model, the Visibility
Engine, and the Pedestrian tracker. Users commu-
nicate with the system using a smartphone-based
client app (an Android app) that sends users? po-
sition, pace rate, and spoken utterances to the sys-
tem, and delivers synthesised system utterances to
the user.
Figure 1: System Architecture
1661
3.1 Dialogue interface
The dialogue interface consists of a speech recog-
nition module, an utterance parser, an interaction
manager, an utterance generator and a speech syn-
thesizer. The Nuance 9 speech recogniser with
a domain specific language model was used for
speech recognition. The recognised speech is cur-
rently parsed using a rule-based parser into dia-
logue acts and semantic content.
The Interaction Manager (IM) is the central
component of this architecture, which provides
the user with navigational instructions, pushes PoI
information and manages QA questions. It re-
ceives the user?s input in the form of a dialogue
act (DA), the user?s location (latitude and longi-
tude) and pace rate. Based on these inputs and the
dialogue context, it responds with system output
dialogue act, based on a dialogue policy. The IM
initiates the conversation with a calibration phase
where the user?s initial location and orientation are
obtained. The user can then initiate tasks that in-
terest him/her. These tasks include searching for
an entity (e.g. a museum or a restaurant), request-
ing navigation instructions to a destination, ask-
ing questions about the entities in the City Model,
and so on. When the user is mobile, the IM iden-
tifies points of interest2 on the route proximal to
the user. We call this ?PoI push?. The user is en-
couraged to ask for more information if he/she is
interested. The system also answers adhoc ques-
tions from the user (e.g. ?Who is David Hume??,
?What is the Old College??, etc) (see section 3.4).
Navigation instructions are given in-situ by ob-
serving user?s position continuously, in relation
to the next node (street junction) on the current
planned route, and they are given priority if in con-
flict with a PoI push at the same time. Navigation
instructions use landmarks near route nodes when-
ever possible (e.g. ?When you reach Clydesdale
Bank , keep walking forward?). The IM also in-
forms when users pass by recognisable landmarks,
just to reassure them that they are on track (e.g.
?You will pass by Tesco on the right?). In addition
to navigation instructions, the IM also answers
users? questions concerning the route, his/her lo-
cation, and location of and distance to the various
entities. Finally, the IM uses the city model?s Vis-
ibility Engine (VE) to determine whether the des-
tination is visible to the user (see section 3.3).
2Using high scoring ones when there are many, based on
tourist popularity ratings in the City Model.
The shared spatial and dialogue context em-
ploys a feature-based representation which is up-
dated every 1 second (for location), and after every
dialogue turn. Spatial context such as the user?s
coordinates, street names, PoIs and landmarks
proximal to the user, etc are used by PoI push-
ing and navigation. The dialogue context main-
tains the history of landmarks and PoIs pushed,
latest entities mentioned, etc to resolve anaphoric
references in navigation and QA requests, and to
deliver coherent dialogue responses. The IM re-
solves anaphoric references by keeping a record
of entities mentioned in the dialogue context. It
also engages in clarification sub-dialogues when
the speech recognition confidence scores are low.
The IM stores the name and type information for
each entity (such as landmark, building, etc) men-
tioned in navigation instructions and PoI pushes.
Subsequent references to these entities using ex-
pressions such as ?the museum?, ?the cafe? etc
are resolved by searching for the latest entity of
the given type. Pronouns are resolved to the last
mentioned entity.
The IM also switches between navigation, PoI
push, and QA tasks in an intelligent manner by
using the shared context to prioritise its utterances
from these different tasks. The utterance genera-
tor is a Natural Language Generation module that
translates the system DA into surface text which is
converted into speech using the Cereproc Text-to-
Speech Synthesizer using a Scottish female voice.
The only changes made were minor adjustments
to the pronunciation of certain place names.
3.2 Pedestrian tracker
Urban environments can be challenging with lim-
ited sky views, and hence limited line of sight
to satellites, in deep urban corridors. There is
therefore significant uncertainty about the user?s
true location reported by GNSS sensors on smart-
phones (Zandbergen and Barbeau, 2011). This
module improves on the reported user position
by combining smartphone sensor data (e.g. ac-
celerometer) with map matching techniques, to
determine the most likely location of the pedes-
trian (Bartie and Mackaness, 2012).
3.3 City Model
The City Model is a spatial database containing
information about thousands of entities in the city
of Edinburgh (Bartie and Mackaness, 2013). This
data has been collected from a variety of exist-
1662
ing resources such as Ordnance Survey, Open-
StreetMap, Google Places, and the Gazetteer for
Scotland. It includes the location, use class, name,
street address, and where relevant other properties
such as build date and tourist ratings. The model
also includes a pedestrian network (streets, pave-
ments, tracks, steps, open spaces) which is used
by an embedded route planner to calculate min-
imal cost routes, such as the shortest path. The
city model also consists of a Visibility Engine
that identifies the entities that are in the user?s
vista space (Montello, 1993). To do this it ac-
cesses a digital surface model, sourced from Li-
DAR, which is a 2.5D representation of the city
including buildings, vegetation, and land surface
elevation. The Visibility Engine uses this dataset
to offer a number of services, such as determining
the line of sight from the observer to nominated
points (e.g. which junctions are visible), and de-
termining which entities within the city model are
visible. Using these services, the IM determines if
the destination is visible or not.
3.4 Question-Answering server
The QA server currently answers a range of def-
inition and biographical questions such as, ?Tell
me more about the Scottish Parliament?, ?Who
was David Hume??, ?What is haggis??, and re-
quests to resume (eg. ?Tell me more?). QA
is also capable of recognizing out of scope re-
quests, that is, either navigation-related questions
that can be answered by computations from the
City Model and dealt with elsewhere in the sys-
tem (?How far away is the Scottish Parliament??,
?How do I get there??), or exploration queries
that cannot be handled yet (?When is the can-
non gun fired from the castle??). Question clas-
sification is entirely machine learning-based using
the SMO algorithm (Keerthi et al, 1999) trained
over 2013 annotated utterances. Once the question
has been typed, QA proceeds to focus detection
also using machine learning techniques (Mikhail-
sian et al, 2009). Detected foci include possi-
bly anaphoric expressions (?Who was he??, ?Tell
me more about the castle?). These expressions
are resolved against the dialogue history and ge-
ographical context. QA then proceeds to a tex-
tual search on texts from the Gazetteer of Scotland
(Gittings, 2012) and Wikipedia, and definitions
from WordNet glosses. The task is similar to TAC
KBP 2013 Entity Linking Track and named en-
tity disambiguation (Cucerzan, 2007). Candidate
answers are reranked using a trained confidence
score with the top candidate used as the final an-
swer. These are usually long, descriptive answers
and are provided as a flow of sentence chunks that
the user can interrupt (see table 2). The Interaction
Manager queries the QA model and pushes infor-
mation when a salient PoI is in the vicinity of the
user.
?Edinburgh?s most famous and historic thoroughfare,
which has formed the heart of the Old Town since
mediaeval times. The Royal Mile includes Castlehill,
the Lawnmarket, the Canongate and the Abbey Strand,
but, is officially known simply as the High Street.?
Table 2: QA output: query on ?Royal Mile?
3.5 Mobile client
The mobile client app, installed on an Android
smartphone (Samsung Galaxy S3), connects the
user to the dialogue system using a 3G data con-
nection. The client senses the user?s location us-
ing positioning technology using GNSS satellites
(GPS and GLONASS) which is sent to the dia-
logue system at the rate of one update every two
seconds. It also sends pace rate of the user from
the accelerometer sensor. In parallel, the client
also places a phone call using which the user com-
municates with the dialogue system.
4 Baseline system
The baseline system chosen for evaluation was
Samsung S-Voice, a state-of-the-art commercial
smartphone speech interface. S-Voice is a Sam-
sung Android mobile phone app that allows a user
to use the functionalities of device using a speech
interface. For example, the user can say ?Call
John? and it will dial John from the user?s con-
tacts. It launches the Google Navigation app when
users request directions and it activates Google
Search for open ended touristic information ques-
tions. The Navigation app is capable of providing
instructions in-situ using speech. We used the S-
Voice system for comparison because it provided
an integrated state-of-the-art interface to use both
a navigation app and also an information-seeking
app using the same speech interface. Users were
encouraged to use these apps using speech but
were allowed to use the GUI interface when us-
ing speech wasn?t working (e.g. misrecognition of
local names). Users obtained the same kind of in-
1663
formation (i.e. navigation directions, descriptions
about entities such as people, places, etc) from the
baseline system as they would from our system.
However, our system interacted with the user us-
ing the speech modality only.
5 Experimental design
Spacebook and the baseline were evaluated in the
summer of 2012. We evaluated both systems with
17 subjects in the streets of Edinburgh. There
were 11 young subjects (between 20 and 26 years,
mean=22 ? 2) and 6 older subjects (between 50
and 71 years, mean=61 ? 11). They were mostly
native English speakers (88%). 59% of the users
were regular smartphone users and their mean
overall time spent in the city was 76 months. The
test subjects had no previous experience with the
proposed system. They were recruited via email
adverts and mail shots. Subjects were given a task
sheet with 8 tasks in two legs (4 tasks per leg).
These tasks included both navigation and tourist
information tasks (see table 3). Subjects used our
system for one of the legs and the baseline system
for the other and the order was balanced. Each leg
took up to 30 mins to finish and the total duration
including questionnaires was about 1.5 hours. Fig-
ure 2 shows the route taken by the subjects. The
route is about 1.3 miles long. Subjects were fol-
lowed by the evaluator who made notes on their
behaviour (e.g. subject looks confused, subject
looks at or manipulates the phone, subject looks
around, etc).
Subjects filled in a demographic questionnaire
prior to the experiment. After each leg, they filled
in a system questionnaire (see appendix) rating
their experience. After the end of the experi-
ment, they filled out a comparative questionnaire
and were debriefed. They were optionally asked
to elaborate on their questionnaire ratings. Users
were paid ?20 after the experiment was over.
6 Results
Subjects were asked to identify tasks that they
thought were successfully completed. The per-
ceived task success rates of the two systems were
compared for each task using the Chi square test.
The results show that there is no statistically sig-
nificant difference between the two systems in
terms of perceived task success although the base-
line system had a better task completion rate in
tasks 1-3, 5 and 6. Our system performed better in
Figure 2: Task route
tourist information tasks (4, 7) (see table 4).
Task Our system Baseline p
T1 (N) 77.7 100 0.5058
T2 (TI) 88.8 100 0.9516
T3 (N) 100 100 NA
T4 (TI) 100 87.5 0.9516
T5 (N+TI) 62.5 100 0.1654
T6 (N+TI) 87.5 100 0.9516
T7 (TI) 100 55.5 0.2926
T8 (N) 75.0 88.8 0.9105
Table 4: % Perceived Task success - task wise
comparison (N - navigation task, TI - Tourist In-
formation task)
The system questionnaires that were filled out
by users after each leg were analysed. These
consisted of questions concerning each system to
be rated on a six point Likert scale (1-Strongly
Disagree, 2-Disagree, 3-Somewhat Disagree, 4-
Somewhat Agree, 5-Agree, 6-Strongly Agree).
The responses were paired and tested using a
Wilcoxon Sign Rank test. Median and Mode for
each system and significance in differences are
shown in table 5. Results show that although
our system is not performing significantly better
than the baseline system (SQ1-SQ10 except SQ7),
users seem to find it more understanding (SQ7)
and more interesting to interact with (SQ11) than
the baseline. We grouped the subjects by age
group and tested their responses. We found that
the young subjects (age group 20-26), also felt that
1664
Leg 1
(Task 1) Ask the system to guide you to the Red Fort restaurant.
(Task 2) You?ve heard that Mary Queen of Scots lived in Edinburgh. Find out about her.
(Task 3) Walk to the university gym.
(Task 4) Near the gym there is an ancient wall with a sign saying ?Flodden Wall?. Find out what that is.
Leg 2
(Task 5) Try to find John Knox House and learn about the man.
(Task 6) Ask the system to guide you to the Old College. What can you learn about this building?
(Task 7) Try to find out more about famous Edinburgh people and places, for example, David Hume,
John Napier, and Ian Rankin. Try to find information about people and places that you are personally
interested in or that are related to what you see around you.
(Task 8) Ask the system to guide you back to the Informatics Forum.
Table 3: Tasks for the user
they learned something new about the city using it
(SQ12) (p < 0.05) while the elderly (age group
50-71) didn?t. We also found statistically signifi-
cant differences in smartphone users rating for our
system on their learning compared to the baseline
(SQ12).
Subjects were also asked to choose between the
two systems given a number of requirements such
as ease of use, use for navigation, tourist infor-
mation, etc. There was an option to rank the sys-
tems equally (i.e. a tie). They were presented with
the same requirements as the system questionnaire
with one additional question - ?Overall which sys-
tem do you prefer?? (CQ0). Users? choice of sys-
tem based on a variety of requirements is shown
in table 6. Users? choice counts were tested us-
ing Chi-square test. Significant differences were
found in users? choice of system for navigation
and tourist information requirements. Users pre-
ferred the baseline system for navigation (CQ2)
and our system for touristic information (CQ3) on
the city. Although there was a clear choice of sys-
tems based on the two tasks, there was no signifi-
cant preference of one system over the other over-
all (CQ0). They chose our system as the most in-
teresting system to interact with (CQ11) and that
it was more informative than the baseline (CQ12).
Figure 3 shows the relative frequency between
user choices on comparative questions.
7 Analysis
Users found it somewhat difficult to navigate using
Spacebook (see comments in table 7). Although
the perceived task success shows that our system
was able to get the users to their destination and
there was no significant difference between the
two systems based on their questionnaire response
on navigation, they pointed out a number of issues
and suggested a number of modifications. Many
Figure 3: Responses to comparative questions
users noted that a visual map and the directional
arrow in the baseline system was helpful for nav-
igation. In addition, they noted that our system?s
navigation instructions were sometimes not satis-
factory. They observed that there weren?t enough
instructions coming from the system at street junc-
tions. They needed more confirmatory utterances
(that they are walking in the right direction) (5
users) and quicker recovery and notification when
walking the wrong way (5 users). They observed
that the use of street names was confusing some-
times. Some users also wanted a route summary
before the navigation instructions are given.
The problem with Spacebook?s navigation pol-
icy was that it did not, for example, direct the
user via easily visible landmarks (e.g. ?Head to-
wards the Castle?), and relies too much on street
names. Also, due to the latency in receiving GPS
information, the IM sometimes did not present in-
structions soon enough during evaluation. Some-
times it received erroneous GPS information and
therefore got the user?s orientation wrong. These
problems will be addressed in the future version.
Some users did find navigation instructions use-
ful because of the use of proximal landmarks such
1665
Question B Mode B Median S Mode S Median p
SQ1 - Ease of use 4 4 5 4 0.8207
SQ2 - Navigation 4 4 5 4 0.9039
SQ3 - Tourist Information 2 3 4 4 0.07323
SQ4 - Easy to understand 5 5 5 5 0.7201
SQ5 - Useful messages 5 4 5 4 1
SQ6 - Response time 5 5 2 2 0.2283
SQ7 - Understanding 3 3 5 4 0.02546
SQ8 - Repetitive 2 3 2 3 0.3205
SQ9 - Aware of user environment 5 5 4 4 0.9745
SQ10 - Cues for guidance 5 5 5 5 0.1371
SQ11 - Interesting to interact with 5 4 5 5 0.01799
SQ12 - Learned something new 5 4 5 5 0.08942
Table 5: System questionnaire responses (B=Baseline, S=our system)
Task Baseline Our system Tie p-
Preferred Preferred value
CQ0 23.52 35.29 41.17 0.66
CQ1 35.29 29.41 35.29 0.9429
CQ2 64.70 0 35.29 0.004
CQ3 17.64 64.70 17.64 0.0232
CQ4 35.29 29.41 23.52 0.8187
CQ5 23.52 52.94 23.52 0.2298
CQ6 23.52 29.41 35.29 0.8187
CQ7 17.64 47.05 35.29 0.327
CQ8 29.41 23.52 47.05 0.4655
CQ9 29.41 52.94 17.64 0.1926
CQ10 47.05 29.41 23.52 0.4655
CQ11 5.88 76.47 17.64 0.0006
CQ12 0 70.58 29.41 0.005
Table 6: User?s choice on comparative questions
(CQ are the same questions as SQ but requesting
a ranking of the 2 systems)
as KFC, Tesco, etc. (popular chain stores). Some
users also suggested that our system should have
a map and that routes taken should be plotted on
them for reference. Based on the ratings and ob-
servations made by the users, we conclude that our
first hypothesis that Spacebook would be more ef-
ficient for navigation than the baseline because of
its speech-only interface was inconclusive. We be-
lieve so because users? poor ratings for Spacebook
may be due to the current choice of dialogue pol-
icy for navigation. It may be possible to reassure
the user with a better dialogue policy with just the
speech interface. However, this needs further in-
vestigation.
Users found the information-search task inter-
esting and informative when they used Spacebook
(see sample user comments in table 8). They
also found push information on nearby PoIs un-
expected and interesting as they would not have
found them otherwise. Many users believed that
this could be an interesting feature that could help
tourists. They also found that asking questions and
finding answers was much easier with Spacebook
compared to the baseline system, where some-
times users needed to type search keywords in.
Another user observation was that they did not
have to stop to listen to information presented
by our system (as it was in speech) and could
carry on walking. However, with the baseline sys-
tem, they had to stop to read information off the
screen. Although users in general liked the QA
feature, many complained that Spacebook spoke
too quickly when it was presenting answers. Some
users felt that the system might lose context of the
navigation task if presented with a PoI question.
In contrast, some others noted Spacebook?s ability
to interleave the two tasks and found it to be an
advantage.
Users? enthusiasm for our system was observed
when (apart from the points of interest that were
in the experimental task list) they also asked spon-
taneous questions about James Watt, the Talbot
Rice gallery, the Scottish Parliament and Edin-
burgh Castle. Some of the PoIs that the system
pushed information about were the Royal College
of Surgeons, the Flodden Wall, the Museum of
Childhood, and the Scottish Storytelling Centre.
Our system answered a mean of 2.5 out of 6.55
questions asked by users in leg 1 and 4.88 out of
8.5 questions in leg 2. Please note that an utter-
ance is sent to QA if it is not parsed by the parser
and therefore some utterances may not be legit-
mate questions themselves. Users were pushed a
mean of 2.88 and 6.37 PoIs during legs 1 and 2.
There were a total of 17 ?tell me more? requests
requesting the system to present more information
(mean=1.35 ? 1.57).
Evaluators who followed the subjects noted that
the subjects felt difficulty using the baseline sys-
tem as they sometimes struggled to see the screen
1666
1. ?It?s useful when it says ?Keep walking? but it should say it more often.?
2. ?[Your system] not having a map, it was sometimes difficult to check how aware it was of my environment.?
3. ?[Google] seemed to be easier to follow as you have a map as well to help.?
4. ?It told me I had the bank and Kentucky Fried Chicken so I crossed the road because I knew it?d be somewhere over
beside them. I thought ?OK, great. I?m going the right way.? but then it didn?t say anything else. I like those kind of
directions because when it said to go down Nicolson Street I was looking around trying to find a street sign.?
5. ?The system keeps saying ?when we come to a junction, I will tell you where to go?, but I passed junctions and it
didn?t say anything. It should say ?when you need to change direction, I will tell you.??
6. ?I had to stop most of the times for the system to be aware of my position. If walking very slowly, its awareness of
both landmarks and streets is excellent.?
Table 7: Sample user comments on the navigation task
1. ?Google doesn?t *offer* any information. I would have to know what to ask for...?
2. ?Since many information is given without being asked for (by your system), one can discover new places and
landmarks even if he lives in the city. Great feature!!?
3. ?I didn?t feel confident to ask [your system] a question and still feel it would remember my directions?
4. ?Google could only do one thing at a time, you couldn?t find directions for a place whilst learning more.?
5. ?If she talked a little bit slower [I would use the system for touristic purposes]. She just throws masses of information
really, really quickly.?
Table 8: Sample user comments on the tourist information task
in bright sunlight. They sometimes had difficulty
identifying which way to go based on the route
plotted on the map. In comparison, subjects did
not have to look at the screen when they used
our system. Based on the ratings and observa-
tions made by the users about our system?s tourist
information features such as answering questions
and pushing PoI information, we have support for
our second hypothesis: that users find a dialogue
interface which integrates question-answering and
navigation within a shared context to be useful for
finding information about entities in the urban en-
vironment.
8 Future plans
We plan to extend Spacebook?s capabilities to ad-
dress other challenges in pedestrian navigation and
tourist information. Many studies have shown
that visible landmarks provide better cues for nav-
igation than street names (Ashweeni and Steed,
2006; Hiley et al, 2008). We will use visible
landmarks identified using the visibility engine to
make navigation instructions more effective, and
we plan to include entities in dialogue and visual
context as candidates for PoI push, and to imple-
ment an adaptive strategy that will estimate user
interests and push information that is of interest
to them. We are also taking advantage of user?s
local knowledge of the city to present navigation
instructions only for the part of the route that the
user does not have any knowledge of. These fea-
tures, we believe, will make users? experience of
the interface more pleasant, useful and informa-
tive.
9 Conclusion
We presented a mobile dialogue app called Space-
book to support pedestrian users in navigation
and tourist information gathering in urban envi-
ronments. The system is a speech-only interface
and addresses navigation and tourist information
in an integrated way, using a shared dialogue con-
text. For example, using the navigational context,
Spacebook can push point-of-interest information
which can then initiate touristic exploration tasks
using the QA module.
We evaluated the system against a state-of-the-
art baseline (Samsung S-Voice with Google Navi-
gation and Search) with a group of 17 users in the
streets of Edinburgh. We found that users found
Spacebook interesting to interact with, and that
it was their system of choice for touristic infor-
mation exploration tasks. These results were sta-
tistically significant. Based on observations and
user ratings, we conclude that our speech-only
system was less preferred for navigation and more
preferred for tourist information tasks due to fea-
tures such as PoI pushing and the integrated QA
module, when compared to the baseline system.
Younger users, who used Spacebook, even felt that
they learned new facts about the city.
Acknowledgments
The research leading to these results was funded by the Eu-
ropean Commission?s Framework 7 programme under grant
1667
agreement no. 270019 (SPACEBOOK project).
References
K. B. Ashweeni and A. Steed. 2006. A natural
wayfinding exploiting photos in pedestrian naviga-
tion systems. In Proceedings of the 8th conference
on Human-computer interaction with mobile devices
and services.
P. Bartie and W. Mackaness. 2006. Development
of a speech-based augmented reality system to sup-
port exploration of cityscape. Transactions in GIS,
10:63?86.
P. Bartie and W. Mackaness. 2012. D3.4 Pedestrian
Position Tracker. Technical report, The SPACE-
BOOK Project (FP7/2011-2014 grant agreement no.
270019).
P. Bartie and W. Mackaness. 2013. D3.1.2 The Space-
Book City Model. Technical report, The SPACE-
BOOK Project (FP7/2011-2014 grant agreement no.
270019).
D. Byron, A. Koller, J. Oberlander, L. Stoia, and
K. Striegnitz. 2007. Generating Instructions in Vir-
tual Environments (GIVE): A challenge and evalua-
tion testbed for NLG. In Proceedings of the Work-
shop on Shared Tasks and Comparative Evaluation
in Natural Language Generation.
S. Cucerzan. 2007. Large-scale named entity disam-
biguation based on Wikipedia data. In Proceedings
of EMNLP-CoNLL.
R. Dale, S. Geldof, and J. Prost. 2003. CORAL : Using
Natural Language Generation for Navigational As-
sistance. In Proceedings of ACSC2003, Australia.
Nina Dethlefs and Heriberto Cuaya?huitl. 2011. Hierar-
chical Reinforcement Learning and Hidden Markov
Models for Task-Oriented Natural Language Gener-
ation. In Proc. of ACL.
B. Gittings. 2012. The Gazetteer for Scotland -
http://www.scottish-places.info.
H. Hiley, R. Vedantham, G. Cuellar, A. Liuy,
N. Gelfand, R. Grzeszczuk, and G. Borriello. 2008.
Landmark-based pedestrian navigation from collec-
tions of geotagged photos. In Proceedings of the
7th Int. Conf. on Mobile and Ubiquitous Multimedia
(MUM).
S. Janarthanam and O. Lemon. 2011. The GRUVE
Challenge: Generating Routes under Uncertainty in
Virtual Environments. In Proceedings of ENLG.
S. Janarthanam, O. Lemon, X. Liu, P. Bartie, W. Mack-
aness, T. Dalmas, and J. Goetze. 2012. Integrat-
ing location, visibility, and Question-Answering in
a spoken dialogue system for Pedestrian City Explo-
ration. In Proc. of SIGDIAL 2012, S. Korea.
H. Kashioka, T. Misu, E. Mizukami, Y. Shiga,
K. Kayama, C. Hori, and H. Kawai. 2011. Multi-
modal Dialog System for Kyoto Sightseeing Guide.
In Asia-Pacific Signal and Information Processing
Association Annual Summit and Conference.
S.S. Keerthi, S. K. Shevade, C. Bhattacharyya, and
K. R. K. Murthy. 1999. Improvements to Platt?s
SMO Algorithm for SVM Classifier Design. Neural
Computation, 3:637?649.
J. Ko, F. Murase, T. Mitamura, E. Nyberg, M. Tateishi,
I. Akahori, and N. Hataoka. 2005. CAMMIA: A
Context-Aware Spoken Dialog System for Mobile
Environments. In IEEE ASRU Workshop.
C. Kray, K. Laakso, C. Elting, and V. Coors. 2003.
Presenting Route Instructions on Mobile Devices.
In Proceedings of IUI 03, Florida.
R. Malaka and A. Zipf. 2000. Deep Map - challenging
IT research in the framework of a tourist information
system. In Information and Communication Tech-
nologies in Tourism 2000, pages 15?27. Springer.
A. Mikhailsian, T. Dalmas, and R. Pinchuk. 2009.
Learning foci for question answering over topic
maps. In Proceedings of ACL 2009.
D. Montello. 1993. Scale and multiple psychologies
of space. In A. U. Frank and I. Campari, editors,
Spatial information theory: A theoretical basis for
GIS.
M. Raubal and S. Winter. 2002. Enriching wayfinding
instructions with local landmarks. In Second Inter-
national Conference GIScience. Springer, USA.
C.J. Shroder, W. Mackaness, and B. Gittings. 2011.
Giving the Right Route Directions: The Require-
ments for Pedestrian Navigation Systems. Transac-
tions in GIS, pages 419?438.
N. Webb and B. Webber. 2009. Special Issue on Inter-
active Question Answering: Introduction. Natural
Language Engineering, 15(1):1?8.
P. A. Zandbergen and S. J. Barbeau. 2011. Posi-
tional Accuracy of Assisted GPS Data from High-
Sensitivity GPS-enabled Mobile Phones. Journal of
Navigation, 64(3):381?399.
1668
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 142?151,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
?The day after the day after tomorrow?? A machine learning approach to
adaptive temporal expression generation:
training and evaluation with real users
Srinivasan Janarthanam, Helen Hastie, Oliver Lemon, Xingkun Liu
Interaction Lab
School of Mathematical and Computer Sciences (MACS)
Heriot-Watt University
{sc445, h.hastie, o.lemon, x.liu}@hw.ac.uk
Abstract
Generating Temporal Expressions (TE) that
are easy to understand, unambiguous, and rea-
sonably short is a challenge for humans and
Spoken Dialogue Systems. Rather than devel-
oping hand-written decision rules, we adopt a
data-driven approach by collecting user feed-
back on a variety of possible TEs in terms
of task success, ambiguity, and user prefer-
ence. The data collected in this work is freely
available to the research community. These
data were then used to train a simulated user
and a reinforcement learning policy that learns
an adaptive Temporal Expression generation
strategy for a variety of contexts. We evalu-
ate our learned policy both in simulation and
with real users and show that this data-driven
adaptive policy is a significant improvement
over a rule-based adaptive policy, leading to
a 24% increase in perceived task completion,
while showing a small increase in actual task
completion, and a 16% decrease in call dura-
tion. This means that dialogues are more ef-
ficient and that users are also more confident
about the appointment that they have agreed
with the system.
1 Introduction
Temporal Expressions are linguistic expressions that
are used to refer to a date and are often a source of
confusion in human-human, human-computer and
text interactions such as emails and instant messag-
ing. For example, ?Let?s meet next Sunday?? ?do
you mean Sunday this week or a week on Sunday??.
(Mccoy and Strube, 1999) state that changes in tem-
poral structure in text are often indicated by either
cue words and phrases (e.g. ?next Thursday?, ?this
week?, ?tomorrow?), a change in grammatical time
of the verb (e.g. present tense versus future tense),
or changes in aspect (e.g. atomic versus extended
events versus states as defined by (Moens and Steed-
man, 1988)). In this study, we will concentrate on
the first of these phenomena, generating TEs with
the optimal content and lexical choice.
Much work in the field of Natural Language Pro-
cessing concerns understanding and resolving these
temporal expressions in text (Gerber et al, 2002;
Pustejovsky et al, 2003; Ahn et al, 2007; Mazur
and Dale, 2007; Han et al, 2006), however, little
work has looked at how best to plan and realise tem-
poral expressions in order to minimize ambiguity
and confusion in a Spoken Dialogue System (SDS).
(Reiter et al, 2005) presented a data driven ap-
proach to generating TEs to refer to time in weather
forecast information where appropriate expressions
were identified using contextual features using su-
pervised learning. We adopt an adaptive, data-driven
reinforcement learning approach instead. Similar
data-driven approaches have been applied to infor-
mation presentation (Rieser et al, 2010; Walker et
al., 2007) where each Natural Language Generation
(NLG) action is a sequential decision point, based on
the current dialogue context and expected long-term
reward of that action. A data-driven approach has
also been applied to the problem of referring expres-
sion generation in dialogue for expert and novice-
users of a SDS (Janarthanam and Lemon, 2010).
However, to date, there has been no previous work
on adaptive data-driven approaches for temporal re-
ferring expression generation, where uncertainty in
142
the stochastic environment is explicitly modelled.
The data-driven approach to temporal expression
generation presented here is in the context of ap-
pointment scheduling dialogues. The fact that there
are multiple ways that a time slot can be referred to
leads to an interesting NLG problem of how best to
realise a TE for a particular individual in a particular
context for certain domains. For example, the fol-
lowing expressions all vary in terms of length, ambi-
guity, redundant information and users? preference:
?next Friday afternoon? or ?Friday next week at the
same time?, or ?in the afternoon, a week on Friday?.
Temporal Expressions contain two types of refer-
ences: absolute references such as ?Tuesday? and
?12th January?, and relative references such as ?to-
morrow? and ?this Tuesday?. Generating TEs there-
fore, involves both in selecting appropriate pieces of
information (date, day, time, month, and week) to
present and deciding how to present them (absolute
or relative reference).
Our objective here is to convey a target appoint-
ment slot to users using an expression that is optimal
in terms of the trade-off between understandability,
length and user preference.
2 Methodology
We address the issue of generating TEs by adopting
a data-driven approach that has four stages. Firstly,
we define Temporal Expression Units (TEU) as de-
scribed in Section 2.1. Secondly, we design and im-
plement a web-based data collection, gathering met-
rics on the TEUs in various contexts for a variety
of date types (Section 3). Thirdly, we train a user
simulation and use it to learn a policy using rein-
forcement learning techniques that generates the op-
timal combination of TEUs for each context (Sec-
tion 4). Finally, we deploy and evaluate this pol-
icy in a Spoken Dialogue System for appointment
scheduling and show that our learned policy per-
forms better than a hand-written, adaptive one (re-
sults presented in Section 5).
2.1 Temporal Expression Units
For this study, TEs are broken down into 5 cate-
gories or units (TEUs) presented in a fixed order:
DAY, DATE, MONTH, WEEK and TIME. Each of
these units can be expressed relative to the current
TEU Choices
DAY abs, rel, rc, nn
DATE abs, nn
MONTH abs, nn
WEEK abs, rel, nn
TIME abs, rc
Table 1: TEU choices where abs is absolute, rel is rela-
tive, rc is relative to context and nn is none
day and to the current context (i.e. previously men-
tioned dates). Specifically, there are 3 unit attributes:
absolute (e.g. DAY=abs ?Tuesday?); relative to cur-
rent day (e.g. DAY=rel ?tomorrow?); and relative to
context (e.g. DAY=rc ?the following day?).
Certain restrictions on possible TEU combina-
tions were imposed, for example, DATE=rc and
DAY=rel were combined to be just DAY=rel, and
some combinations were omitted on the basis that
it is highly unlikely that they would be uttered
in natural speech, for example WEEK=rel and
MONTH=abs would result in ?this week in Septem-
ber?. Finally, every TE has to contain a time (am or
pm for this application). The possible combinations
are summarised in Table 1.
3 Data Collection
The data collection experiment was in two parts
(Task 1 and Task 2) and was designed using the We-
bexp experimental software1. Webexp is a client-
server set up where a server application hosts the ex-
periment and stores the experimental files, logs and
results. The client side runs an applet on the user?s
web-browser.
In Task 1, participants listened to an audio file
containing a TE generated from absolute and rela-
tive TEUs (see Figure 1). No relative-context (rc)
TEUs were used in Task 1 since the dialogue ex-
cerpt presented was in isolation and therefore had
no context. Each participant was asked to listen to
10 different audio files in a sequence corresponding
to a variety of dates randomly chosen from 8 pos-
sible dates. The participant then had to identify the
correct appointment slot that the system is referring
to. There is scope for the participant to add multi-
ple answers in order to capture potential ambiguity
1http://www.webexp.info
143
Figure 1: Screen shot of Task 1 in the on-line data collection experiment
of a TE, and we report on this below. The 8 dates
that were used to generate the TEs fell into a two
week period in a single month which is in-line with
the evaluation set-up of the appointment scheduling
SDS discussed in Section 5.3.
For each date, the TE was randomly picked from a
set of 30 possible combinations of TEUs. Each TEU
was generated by a rule-based realiser and synthe-
sized using the Baratinoo synthesizer (France Tele-
com, 2011). This realiser generates text from a can-
didate list for each TEU based on the given date.
For example, if the slot currently being discussed
is Tuesday 7th, the realiser would generate ?tomor-
row? for DAY=rel; if the date in discussion was
Wednesday 8th then DAY=rel would be realised as
?the day after tomorrow?. There was potential for
overlap of stimuli, as any given TE for any given
date may be assessed by more than one participant.
Task 2 of the experiment was in two stages. In the
first stage (Task 2A), the participants are given to-
day?s date and the following dialogue excerpt; Op-
erator: ?We need to send out an engineer to your
home. The first available appointment is . . .? (see
Figure 2). They are then asked to listen to 5 audio
files of the system saying different TEs for the same
date and asked to rate preference on a scale of 1-6
(where 1 is bad and 6 is great.) For the second stage
(Task 2B), the dialogue is as follows; Operator: ?so
you can?t do Wednesday 8th September in the morn-
ing.? and then the participants are asked to listen
to 5 more audio files that are generated TEs includ-
ing relative context such as ?how about Thursday at
the same time??. This two-stage process is then re-
peated 4 times for each participant.
Table 2 summarizes the metrics collected in the
different parts of the experiment. The metric Dis-
tance is calculated in terms of the number of slots
from the current date to the target date (TD). In-
stances were grouped into four distance groups: G1:
TD is 1-2 slots away; G2: TD is 3-6 slots away; G3:
TD is 7-11 slots away and G4: TD more than 11
slots away. P replay is calcuated by the total num-
ber of replays divided by the total number of plays
for that temporal expression, i.e. the probability that
the temporal expression played is requested to be re-
played. P ambiguous is calculated by the number of
times a given temporal expression is given more than
1 interpretation divided by the total number of times
that the same given referring expression is answered.
In total there were 73 participants for Task 1 and
144
Figure 2: Screen shot of Task 2 in the on-line data collection experiment
730 TE samples collected. Although Task 2 directly
followed on from Task 1, there was a significant
drop out rate as only 48 participants completed the
second task resulting in 1,920 TE samples. Partici-
pants who completed both tasks were rewarded by a
chance to win an Amazon voucher.
3.1 Data Analysis
Figure 3 shows various metrics with respect to TE
absoluteness and relativeness is the number of ab-
solute and relative TEUs respectively. These two
graphs represent the state space that the genera-
tion policy described in Section 4 is exploring, trad-
ing off between various features such as Length,
taskSuccess and userPref.
As we can see, there is a tendency for average
taskSuccess to increase as absoluteness increases
whereas, for relativeness the distribution is more
even. The TE with the greatest taskSuccess has an
absoluteness of 4 and zero relativeness: DATE=abs,
MONTH=abs, WEEK=abs, TIME=abs (e.g. ?11th
September, the week starting the 10th, between 8am
and 10am?) and the TE with the least taskSuccess
has an absoluteness of only 2, again with no rela-
tiveness: DATE=abs, TIME=abs, (e.g. ?8th between
8am and 10am?).
Average userPref stays level and then decreases
if absoluteness is 5. We infer from this that al-
though long utterances that are completely explicit
are more clear in terms of taskSuccess, they are not
necessarily preferred by users. This is likely due
to TE length increasing. On average, the inclusion
of one relative expression is preferred over none at
all or two. The most preferred TE has an abso-
luteness of 3 with a relativeness of 2: DAY=rel,
DATE=abs, MONTH=abs, WEEK=rel, TIME=abs
(e.g. ?Tomorrow the 7th of September, this week,
between 8am and 10am?).
145
Figure 3: Graph showing the trade-offs between various metrics with respect to absoluteness and relativeness (number
of absolute/relative TEUs) in terms of probabilities or normalised values.
Metric Description Task
P ambiguous Probability that the expres-
sion is ambiguous to the
user
1
taskSuccess Correct slot identified 1
P replay Probability of replay (mea-
sure of understandability)
1 & 2
Length Expression length in terms
of number of TEUs that
are non null divided by the
total number of possible
TEUs (5)
1 & 2
wordLength Expression length in words
normalised over max num
of words (15)
1 & 2
userPref Preference rating of audio
from 1-6
2
Distance Distance from target date
(TD) to current date in
terms of number of slots
1 & 2
Table 2: Metrics collected in various parts of the experi-
ment
The probability of ambiguity and replay does not
seem to be affected by absoluteness. The most am-
biguous TE has an absoluteness of 3 and zero rela-
tiveness: DAY=abs MONTH=abs TIME=abs, (e.g.
?Tuesday September between 8am and 10am?) in-
dicating that a date is needed for precision. The
TEs that the participants were most likely to replay
tended to be short e.g. ?Tomorrow at the same time?.
This may be due to the clarity of the speech synthe-
siser.
4 Learning a TE generation policy
Reinforcement learning is a machine learning ap-
proach based on trial and error learning, in which
a learning agent learns to map sequences of ?opti-
mal? actions to environment or task states (Sutton
and Barto, 1998). In this framework the problem
of generating temporal expressions is presented as
a Markov Decision Process. The goal of the learn-
ing agent is to learn to choose those actions that ob-
tain maximum expected reward in the long run. In
this section, we present the reinforcement learning
setup for learning temporal expression generation
policies.
4.1 Actions and States
In this learning setup, we focus only on generating
the formal specification and treat the set of TEU
choices as the sequential actions of the learning
agent. Table 1 presents the choices that are available
for each TEU.
The actions are taken based on two factors: the
146
distance (in terms of time slots: morning or after-
noon appointments) between (1) the current date
and the target slot and (2) the current date and the
slot in context. Based on the distance, the target
slot was classified to belong to one of the four dis-
tance groups (G1-G4). The slot in context repre-
sents whether there was any other slot already men-
tioned in the conversation so far, so that the system
has an option to use ?relative context? expressions
to present day and time information. Information
concerning the target slot?s group and the slot in con-
text make up the state space of the Markov Decision
Process (MDP).
4.2 User Simulation
We built a user simulation to simulate the dialogue
behaviour of a user in appointment scheduling con-
versations based on the data from real users de-
scribed in Section 3. It responds to the TE used
by the system to refer to an appointment slot. It
responds by either accepting, rejecting, or clarify-
ing the offered slot based on the user?s own calen-
dar of available slots. For instance, the simulated
user rejects an offered slot if the user is not avail-
able at that time. If they accept or reject an offered
slot, the user is assumed to understand the TE unam-
biguously. However, if the user is unable to resolve
the appointment slot from the TE, it responds with a
clarification request. The simulation responded with
a dialogue action (Au,t) to TEs based on the sys-
tem?s dialogue act (As,t), system?s TE (TEs,t). The
following probabilistic model was used to generate
user dialogue actions:
P (Au,t|As,t, TEs,t, G,C,Cal)
In addition to TEs,t and As,t, other factors such as
distance between the target slot and the current slot
(G), the previous slot in context (C), and the user?s
calendar (Cal) were also taken into account. G is ei-
ther G1, G2, G3 or G4 as explained in Section 3. The
User?s dialogue action (Au,t) is one of the three: Ac-
cept slot, Reject slot or Request Clarification. The
probability of clarification request was calculated as
the average of the ambiguity and replay probabilities
seen in real user data.
4.3 Reward function
The learning agent was rewarded for each TE that it
generated. The reward given to the agent was based
on trade-offs between three variables: User prefer-
ence (UP), Length of the temporal expression (L),
and Clarification request probability (CR). UP for
each TE is obtained from Task 2 of the data collec-
tion. In the following reward function, UP is nor-
malised to be between 0 and 1. L is based on number
of TEUs used. The maximum number of TEUs that
can be used is 5 (i.e. DAY, DATE, WEEK, MONTH,
TIME). L is calculated as follows:
Length of TE (L) = No. of used TEUsMax. no. of TEUs
The clarification request (CR) is set to be 1 if the
user responds to the TE with a Request Clarification
and 0 otherwise. Reward is therefore calculated on
a turn-by-turn basis using the following formula:
Reward = UP ? 10.0 ? L ? 10.0 ? CR ? 10.0
In short, we chose a reward function that penalises
TEs that are long and ambiguous, and which rewards
TEs that users prefer. It also indirectly rewards task
success by penalising ambiguous TEs resulting in
clarification requests. This trade-off structure is evi-
dent from the data collection where TEs that are too
long are dispreferred by the users (see Figure 3). The
maximum possible reward is 6 (i.e. UP=1, CR=0,
L=2/5) and the minimum is -20 (i.e. UP=0, CR=1,
L=1). Note that other reward functions could be ex-
plored in future work, for example maximising only
for user preference or length.
4.4 Training
We trained a TE generation policy using the above
user simulation model for 10,000 runs using the
SARSA reinforcement learning algorithm (Sutton
and Barto, 1998). During the training phase, the
learning agent generated and presented TEs to the
user simulation. When a dialogue begins, there is no
appointment slot in context (i.e. C = 0). However,
if the user rejects the first slot, the dialogue system
sets C to 1 and presents the next slot. This is again
reset at the beginning of the next dialogue. The
agent was rewarded at the end of every turn based
on the user?s response, length of the TE, and user
preference scores as shown above. It gradually ex-
plored all possible combinations of TEUs and identi-
fied those TEUs in different contexts that maximize
147
Figure 4: Learning curve
the long-term reward. Figure 4 shows the learning
curve of the agent.
Table 3 presents the TE generation policy learned
by the agent. As one can observe, it used a mini-
mum number of TEUs to avoid length penalties in
the reward. In all cases, MONTH and WEEK in-
formation have not been presented at all. For target
slots that were closest (in group G1) and the farthest
(in group G4), it used relative forms of day (e.g. ?to-
morrow?, ?next Tuesday?, etc.). This is probably
because users dispreferred day information for in-
between slots (e.g. ?the day after the day after to-
morrow?). Also, MONTH information may have
been considered to be irrelevant due to the fact that
the two week window over which the data has been
collected do not span over two different months.
5 Evaluation
In this section, we present the baseline policies that
were evaluated along with the learned policy. We
then present the results of evaluation.
Slots Specification learned
1-2 DAY=rel;DATE=abs;MONTH=nn;
> 11 WEEK=nn;TIME=abs
3-11 DAY=nn;DATE=abs;MONTH=nn;
WEEK=nn;TIME=abs
Table 3: Learned policy
5.1 Baseline policies
The following are the baseline TEG policies:
1. Absolute policy: always use absolute for-
mats for all TEUs (i.e. DAY=abs; DATE=abs;
MONTH=abs; WEEK=abs; TIME=abs)
2. Minimal policy: always use a minimal format
with only date, month and time information in
their absolute forms (i.e. DAY=nn; DATE=abs;
MONTH=abs; WEEK=nn; TIME=abs)
3. Random policy: select possible formats ran-
domly for each TEU.
148
TEG Policy Average reward
Learned -0.071* (?3.75)
Absolute -4.084 (?4.36)
Minimal -1.340 (?4.2)
Random -8.21 (?7.72)
Table 4: Evaluation with simulated users (* p < 0.05,
two-tailed independent samples t-test)
5.2 Results
We evaluated the learned policy and the three other
hand-coded baseline TE generation policies with our
user simulation model. Each policy generated 1,000
TEs in different states. Table 4 present the results
of evaluation with simulated users. On average, the
learned policy scores higher than all the baseline
policies and the differences between the average re-
ward of the learned policy and the other baselines
are statistically significant. This shows that target
slots can be presented using different TEs depending
on how far they are from the current date and such
adaptation can produce less ambiguous, shorter and
user preferred expressions.
5.3 Evaluation with real users
The policy was also integrated into an NLG com-
ponent of a deployed Appointment Scheduling spo-
ken dialogue system. Please note that this is differ-
ent from the web environment in which the training
data was collected. Our data-driven policy was acti-
vated when the system informs the user of an avail-
able time slot. This system was compared to the
exact same system but with a rule-based adaptive
baseline system. In the rule-based policy MONTH,
DATE and TIME were always absolute, DAY was
relative if the target date was less than three days
away (i.e. ?today, tomorrow, day after tomorrow?),
and WEEK was always relative (i.e. ?this week, next
week?). All 5 information units were included in the
realisation (e.g. ?Thursday the 15th July in the after-
noon, next week?) although the order was slightly
different (DAY-DATE-MONTH-TIME-WEEK).
In this domain, the user tries to make an appoint-
ment for an engineer to visit their home. Each user
is given a set of 2-week calendars which shows their
availability and the goal is to arrange an appoint-
ment when both they and the engineer are available.
There were 12 possible scenarios that were evenly
rotated across participants and systems. Each sce-
nario is categorised in terms of scheduling difficulty
(Hard/Medium/Easy). Scheduling difficulty is cal-
culated for User Difficulty (UD) and System Diffi-
culty (SD) separately to assess the system?s mixed
initiative ability. Scheduling difficulty is calculated
as the ordinal of the first session that is free for both
the User and the System. Hard scenarios are with an
ordinal of 3 or 4; Medium with an ordinal of 2, and
Easy with an ordinal of 1. There are 4 scenarios in
each of these difficulty categories for both the user
and system. To give an example, in Scenario 10,
the user can schedule an appointment on Wednes-
day afternoon but he/she also has one free session
on the previous Tuesday afternoon when the engi-
neer is busy therefore UD = 2. For the system, in
this scenario, the first free session it has is on the
Wednesday afternoon therefore SD=1. In this case,
the scenario is easier for the system than the user be-
cause the system could just offer the first session that
it has free.
605 dialogues were collected and analysed. The
system was evaluated by employees at France Tele-
com and students of partner universities who have
never used the appointment scheduling system be-
fore. After each scenario, participants were then
asked to fill out a questionnaire on perceived task
success and 5 user satisfaction questions on a 6-
point Likert Scale (Walker et al, 2000). Results
from the real user study are summarised in Table 5.
The data-driven policy showed significant improve-
ment in Perceived Task Success (+23.7%) although
no significant difference was observed between the
two systems in terms of Actual Task Success (Chi-
square test, df=1). Perceived Task Success is users?
perception of whether they completed the task suc-
cessfully or not. Overall user satisfaction (the aver-
age score of all the questions) was also significantly
higher (+5%)2. Dialogues with the learned policy
were significantly shorter with lower Call Duration
in terms of time (-15.7%)2 and fewer average words
per system turn (-23.93%)2. Figure 5 shows the
length results in time for systems of varying UD and
SD. We can see that the data-driven adaptive policy
consistently results in a shorter dialogue across all
levels of difficulty. In summary, these results show
that using a policy trained on the data collected here
149
Parameters Learned Baseline
TEG TEG
Actual Task Success 80.05% 78.57%
Perceived Task Success 74.86%* 60.50%
User satisfaction 4.51* 4.30
No. system turns 22.8 23.2
Words per system turn 13.16* 17.3
Call duration 88.60 sec * 105.11 sec
Table 5: Results with real users (* statistically significant
difference at p<0.05)
results in shorter dialogues and greater confidence
in the user that they have had a successful dialogue.
Although the learned policy was trained to generate
optimal TEs within a two week window and there-
fore is not general policy for all TE generation prob-
lems, we believe that the data-driven approach that
we have followed can generalise to other TE gener-
ation tasks.
Figure 5: Graph comparing length of dialogues for user
(UD) and system difficulty (SD)
6 Conclusion
We have presented a principled statistical learning
method for generating Temporal Expressions (TEs)
that refer to appointment slots in natural language
utterances. We presented a method for gathering
data on TEs with an on-line experiment and showed
how we can use these data to generate TEs us-
ing a Markov Decision Process which can be opti-
mised using reinforcement learning techniques. We
showed that a TEG policy learned using our frame-
2independent two-tailed t-test p < 0.05
work performs signifcantly better than hand-coded
adaptive policies with real users as well as with sim-
ulated users.
The data collected in this work has been freely
released to the research community in 20113.
Acknowledgements
The research leading to these results has received
funding from the EC?s 7th Framework Programme
(FP7/2007-2013) under grant agreement no. 216594
(CLASSiC project www.classic-project.
org), (FP7/2011-2014) under grant agreement no.
248765 (Help4Mood project), (FP7/2011-2014) un-
der grant agreement no. 270435 (JAMES project),
(FP7/2011-2014) under grant agreement no. 270019
(SpaceBook project), and from the EPSRC, project
no. EP/G069840/1. We would also like to thank our
CLASSiC project colleagues at Cambridge Univer-
sity and France Telecom / Orange Labs.
References
D. Ahn, J. van Rantwijk, and M. de Rijke. 2007. A
Cascaded Machine Learning Approach to Interpret-
ing Temporal Expressions. In Proceedings of NAACL-
HLT 2007.
France Telecom. 2011. Baratinoo expressive speech syn-
thesiser. http://tts.elibel.tm.fr.
L. Gerber, L. Ferro, I. Mani, B. Sundheim, G. Wilson,
and R. Kozierok. 2002. Annotating Temporal Infor-
mation: From Theory to Practice. In Proceedings of
HLT.
B. Han, D. Gates, and L. Levin. 2006. Understanding
temporal expressions in emails. In HLT-NAACL 2006.
Srinivasan Janarthanam and Oliver Lemon. 2010. Learn-
ing to adapt to unknown users: referring expression
generation in spoken dialogue systems. In ACL ?10.
P. Mazur and R. Dale. 2007. The DANTE Temporal Ex-
pression Tagger. In Proceedings of the 3rd Language
and Technology Conference, Poznan, Poland.
Kathleen F. Mccoy and Michael Strube. 1999. Taking
time to structure discourse: Pronoun generation be-
yond accessibility. In Proc. of the 21th Annual Con-
ference of the Cognitive Science Society.
M. Moens and M. Steedman. 1988. Temporal ontology
and temporal reference. In Computational Linguistics,
volume 14(2), pages 15?28.
3Sec 2.6 at http://www.macs.hw.ac.uk/ilabarchive/classicproject/data/
150
J. Pustejovsky, J. Castano, R. Ingria, R. Sauri,
R. Gaizauskas, A. Setzer, G. Katz, and D. Radev.
2003. TimeML: Robust specification of event and
temporal expressions in text. In AAAI Spring Sympo-
sium on New Directions in Question-Answering, Stan-
ford, CA.
E. Reiter, S. Sripada, J. Hunter, and J. Yu. 2005. Choos-
ing words in computer-generated weather forecasts.
Artificial Intelligence, 167:137169.
Verena Rieser, Oliver Lemon, and Xingkun Liu. 2010.
Optimising information presentation for spoken dia-
logue systems. In Proc. ACL 2010.
R. Sutton and A. Barto. 1998. Reinforcement Learning.
MIT Press.
Marilyn A. Walker, Candace A. Kamm, and Diane J. Lit-
man. 2000. Towards Developing General Models of
Usability with PARADISE. Natural Language Engi-
neering, 6(3).
Marilyn Walker, Amanda Stent, Franc?ois Mairesse, and
Rashmi Prasad. 2007. Individual and domain adap-
tation in sentence planning for dialogue. Journal of
Artificial Intelligence Research (JAIR), 30:413?456.
151
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 134?136,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Integrating Location, Visibility, and Question-Answering in a Spoken
Dialogue System for Pedestrian City Exploration
Srinivasan Janarthanam1, Oliver Lemon1, Xingkun Liu1, Phil Bartie2,
William Mackaness2, Tiphaine Dalmas3 and Jana Goetze4
1Interaction Lab, Heriot-Watt University, Edinburgh
2 School of GeoSciences, University of Edinburgh
3School of Informatics, University of Edinburgh
4KTH Royal Institute of Technology, Stockholm, Sweden
sc445,o.lemon,x.liu@hw.ac.uk, philbartie@gmail.com,
william.mackaness@ed.ac.uk,
tiphaine.dalmas@aethys.com, jagoetze@kth.se
Abstract
We demonstrate a spoken dialogue-based in-
formation system for pedestrians. The system
is novel in combining geographic information
system (GIS) modules such as a visibility en-
gine with a question-answering (QA) system,
integrated within a dialogue system architec-
ture. Users of the demonstration system can
use a web-based version (simulating pedes-
trian movement using StreetView) to engage
in a variety of interleaved conversations such
as navigating from A to B, using the QA func-
tionality to learn more about points of interest
(PoI) nearby, and searching for amenities and
tourist attractions. This system explores a va-
riety of research questions involving the inte-
gration of multiple information sources within
conversational interaction.
1 Motivation
Although navigation and local information are avail-
able to users through smartphone apps, there are still
important problems such as how such information is
delivered safely and proactively, and without cogni-
tively overloading the user. (Kray et al, 2003) sug-
gested that cognitive load of information presented
in textual and speech-based interfaces is medium
and low respectively when compared to more com-
plicated visual interfaces. Our objective, therefore,
is to build a hands-free and eyes-free system that en-
gages the pedestrian user by presenting all informa-
tion and receiving user requests through speech only.
In addition, and in contrast to other mobile ap-
plications, this system is conversational ? meaning
that it accumulates information over time, and plans
its utterances to achieve long-term goals. It inte-
grates with a city model and a visibility engine (Bar-
tie and Mackaness, 2012) to identify points of inter-
ests and visibile landmarks for presentation, a pedes-
trian tracker to improve the GPS positioning of the
user and a question-answering (QA) system to en-
able users to explore information about the city more
freely than with a graphical interface.
Table 1 presents an example dialogue interaction
with the system showing the use of visibility infor-
mation and Question-Answering.
User: Take me to Princes Street.
System: Turn left on to South Bridge and
walk towards the tower in front of you.
...
System: Near you is the famous statue of David Hume.
User: Tell me more about David Hume.
System: David Hume is a Scottish philosopher....
Table 1: An example interaction with the system
2 Related work
There are several mobile apps such as Triposo, Trip-
wolf, and Guidepal that provide point of interest
information, and apps such as Google Navigation
that provide navigation instructions to users. How-
ever, they demand the user?s visual attention because
they predominantly present information on a mobile
screen. In contrast, ours is a speech only interface
in order to keep the user?s cognitive load low and
avoid users from being distracted (perhaps danger-
134
ously so) from their primary task.
Generating navigation instructions in the real
world for pedestrians is an interesting research
problem in both computational linguistics and geo-
informatics (Dale et al, 2003; Richter and Duck-
ham, 2008). CORAL is an NLG system that gener-
ates navigation instructions incrementally upon user
requests based on the user?s location (Dale et al,
2003). DeepMap is a system that interacts with
the user to improve positioning using GUI controls
(Malaka and Zipf, 2000). SmartKom is a dialogue
system that presents navigation information multi-
modally (Reithinger et al, 2003). There are also
several mobile apps developed to help low-vision
users with navigation instructions (see (Stent et al,
2010) for example). In contrast to these earlier sys-
tems we present navigational, point-of-interest and
amenity information in an integrated way with users
interacting eyes-free and hands-free through a head-
set connected to a smartphone.
3 Architecture
The architecture of the current system is shown in
figure 1. The server side consists of a dialogue in-
terface (parser, interaction manager, and generator),
a City Model, a Visibility Engine, a QA server and a
Pedestrian tracker. On the user?s side is a web-based
client that consists of the simulated real-world and
the interaction panel.
Figure 1: System Architecture
3.1 Dialogue interface
The dialogue interface consists of an utterance
parser, an interaction manager and an utterance gen-
erator. The interaction manager is the central com-
ponent of this architecture, which provides the user
navigational instructions and interesting PoI infor-
mation. It receives the user?s input in the form of a
dialogue act and the user?s location in the form of
latitude and longitude information. Based on these
inputs and the dialogue context, it responds with sys-
tem output dialogue act (DA), based on a dialogue
policy. The utterance generator is a natural language
generation module that translates the system DA into
surface text, using the Open CCG toolkit (White et
al., 2007).
3.2 Pedestrian tracker
Global Navigation Satellite Systems (GNSS) (e.g.
GPS, GLONASS) provide a useful positioning so-
lution with minimal user side setup costs, for loca-
tion aware applications. However urban environ-
ments can be challenging with limited sky views,
and hence limited line of sight to the satellites, in
deep urban corridors. There is therefore signifi-
cant uncertainty about the user?s true location re-
ported by GNSS sensors on smartphones (Zandber-
gen and Barbeau, 2011). This module improves on
the reported user position by combining smartphone
sensor data (e.g. accelerometer) with map matching
techniques, to determine the most likely location of
the pedestrian (Bartie and Mackaness, 2012).
3.3 City Model
The city model is a spatial database containing in-
formation about thousands of entities in the city of
Edinburgh. These data have been collected from a
variety of existing resources such as Ordnance Sur-
vey, OpenStreetMap and the Gazetteer for Scotland.
It includes the location, use class, name, street ad-
dress, and where relevant other properties such as
build date. The model also includes a pedestrian net-
work (streets, pavements, tracks, steps, open spaces)
which can be used to calculate minimal cost routes,
such as the shortest path.
3.4 Visibility Engine
This module identifies the entities that are in the
user?s vista space (Montello, 1993). To do this it
accesses a digital surface model, sourced from Li-
DAR, which is a 2.5D representation of the city in-
cluding buildings, vegetation, and land surface ele-
vation. The visibility engine uses this dataset to offer
a number of services, such as determining the line
135
of sight from the observer to nominated points (e.g.
which junctions are visible), and determining which
entities within the city model are visible. These met-
rics can be then used by the interaction manager
to generate effective navigation instructions. E.g.
?Walk towards the castle?, ?Can you see the tower
in front of you??, ?Turn left after the large building
on your left after the junction? and so on.
3.5 Question-Answering server
The QA server currently answers a range of defini-
tion questions. E.g., ?Tell me more about the Scot-
tish Parliament?, ?Who was David Hume??, etc. QA
identifies the entity focused on in the question us-
ing machine-learning techniques (Mikhailian et al,
2009), and then proceeds to a textual search on texts
from the Gazetteer of Scotland and Wikipedia, and
definitions from WordNet glosses. Candidates are
reranked using a trained confidence score with the
top candidate used as the final answer. This answer
is provided as a flow of sentence chunks that the user
can interrupt. This information can also be pushed
by the system when a salient entity appears in the
user?s viewshed.
4 Web-based User interface
For the purposes of this (necessarily non-mobile)
demonstration, we present a web-based interface
that simulates users walking in a 3D city environ-
ment. Users will be able to provide speech or text
input (if the demonstration environment is too noisy
for usable speech recognition as is often the case at
conference demonstration sessions).
The web-based client is a JavaScript/HTML pro-
gram running on the user?s web browser. For a
detailed description of this component, please re-
fer to (Janarthanam et al, 2012). It consists of two
parts: the Streetview panel and the Interaction panel.
The Streetview panel presents a simulated real world
visually to the user. A Google Streetview client
(Google Maps API) is created with an initial user
coordinate which then allows the web user to get
a panoramic view of the streets around the user?s
virtual location. The user can walk around using
the arrow keys on his keyboard or the mouse. The
system?s utterances are synthesized using Cereproc
text-to-speech engine and presented to the user.
Acknowledgments
The research has received funding from the Eu-
ropean Community?s 7th Framework Programme
(FP7/2007-2013) under grant agreement no. 270019
(SPACEBOOK project http://www.spacebook-
project.eu/).
References
P. Bartie and W. Mackaness. 2012. D3.4 Pedestrian Po-
sition Tracker. Technical report, The SPACEBOOK
Project (FP7/2011-2014 grant agreement no. 270019).
R. Dale, S. Geldof, and J. Prost. 2003. CORAL : Using
Natural Language Generation for Navigational Assis-
tance. In Proceedings of ACSC2003, South Australia.
S. Janarthanam, O. Lemon, and X. Liu. 2012. A web-
based evaluation framework for spatial instruction-
giving systems. In Proc. of ACL 2012, South Korea.
C. Kray, K. Laakso, C. Elting, and V. Coors. 2003. Pre-
senting route instructions on mobile devices. In Pro-
ceedings of IUI 03, Florida.
R. Malaka and A. Zipf. 2000. Deep Map - challenging IT
research in the framework of a tourist information sys-
tem. In Information and Communication Technologies
in Tourism 2000, pages 15?27. Springer.
A. Mikhailian, T. Dalmas, and R. Pinchuk. 2009. Learn-
ing foci for question answering over topic maps. In
Proceedings of ACL 2009.
D. Montello. 1993. Scale and multiple psychologies of
space. In A. U. Frank and I. Campari, editors, Spatial
information theory: A theoretical basis for GIS.
N. Reithinger, J. Alexandersson, T. Becker, A. Blocher,
R. Engel, M. Lckelt, J. Mller, N. Pfleger, P. Poller,
M. Streit, and V. Tschernomas. 2003. SmartKom -
Adaptive and Flexible Multimodal Access to Multiple
Applications. In Proceedings of ICMI 2003, Vancou-
ver, B.C.
K. Richter and M. Duckham. 2008. Simplest instruc-
tions: Finding easy-to-describe routes for navigation.
In Proceedings of the 5th Intl. Conference on Geo-
graphic Information Science.
A. J. Stent, S. Azenkot, and B. Stern. 2010. Iwalk: a
lightweight navigation system for low-vision users. In
Proc. of the ASSETS 2010.
M. White, R. Rajkumar, and S. Martin. 2007. Towards
Broad Coverage Surface Realization with CCG. In
Proc. of the UCNLG+MT workshop.
P. A. Zandbergen and S. J. Barbeau. 2011. Positional
Accuracy of Assisted GPS Data from High-Sensitivity
GPS-enabled Mobile Phones. Journal of Navigation,
64(3):381?399.
136
Proceedings of the SIGDIAL 2013 Conference, pages 151?153,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
A Multithreaded Conversational Interface for Pedestrian Navigation and
Question Answering
Srinivasan Janarthanam1, Oliver Lemon1, Xingkun Liu1, Phil Bartie2,
William Mackaness2, Tiphaine Dalmas3
1Interaction Lab, Heriot-Watt University, Edinburgh
2 School of GeoSciences, University of Edinburgh
3School of Informatics, University of Edinburgh
sc445,o.lemon,x.liu@hw.ac.uk, philbartie@gmail.com,
william.mackaness@ed.ac.uk, tiphaine.dalmas@aethys.com
Abstract
We demonstrate a conversational interface
that assists pedestrian users in navigat-
ing within urban environments and acquir-
ing tourist information by combining spo-
ken dialogue system, question-answering
(QA), and geographic information sys-
tem (GIS) technologies. In contrast to
existing mobile applications which treat
these problems independently, our An-
droid agent addresses the problem of navi-
gation and touristic question-answering in
an integrated fashion using a shared dia-
logue context with multiple interleaved di-
alogue threads. In this paper, we present
the architecture and features of our lat-
est system, extended from an earlier ver-
sion which was built and evaluated with
real users (Janarthanam et al, 2013). The
new features include navigation based on
visible landmarks, navigation adapted to
the user?s previous route knowledge, and
tourist information pushing based on vis-
ible and proximal points-of-interest. The
system also uses social media to infer
?popularity? of geographical entities.
1 Introduction
We demonstrate a conversational interface that ad-
dresses the problems of pedestrian navigation and
Question Answering (QA) in urban environments,
which is an extended version of the system eval-
uated in (Janarthanam et al, 2013). Our system
brings together Spoken Dialogue Systems (SDS)
and Question Answering (QA) with Geographic
Information Systems (GIS) for user positioning
and tracking, city modelling and urban visibility
modelling. There has been little prior work that
addresses these problems - navigation, visibility,
and tourist information provision - in an integrated
way. By navigation, we refer to the problem of
finding appropriate destinations to go to and the
task of wayfinding to reach them (Golledge, 1992;
Raubal and Winter, 2002) and by tourist informa-
tion provision we refer to the problem of meet-
ing the informational needs of a user about enti-
ties such as museums, statues, famous personal-
ities, etc. With the proliferation of smartphones,
there has been a number of mobile apps developed
to address these problems. However, these apps
have the following problems: first, they demand
the user?s visual attention because they predom-
inantly present information on a mobile screen.
This can be dangerous in urban environments, as
well as being distracting. Second, these apps ad-
dress the problems of navigation and tourist infor-
mation independently and do not employ a shared
interaction context. This means that users cannot
switch between tourist information and navigation
tasks in a natural and fluid manner.
User1: Take me to the National Museum.
System2: The National Museum is about 300 meters away ...
System3: At the KFC, turn left on to South Bridge ...
System4 : Near you is the statue of David Hume.
User2: Who is David Hume.
System5: David Hume was a Scottish philosopher....
User3: Tell me more about David Hume.
System6: He was one of the most important figures in.. ...
System7: You should be able to see the museum in front of you.
User4: Tell me more about the museum.
System8: The National Museum of Scotland is a....
Table 1: An example interaction with SpaceBook
In contrast to existing mobile apps, we present
a system that has a speech-only interface and ad-
dresses navigation and QA in an integrated way.
Table 1 presents an example interaction with
our system showing the integrated use of navi-
gation and question-answering capabilities. Ut-
151
terance System4-8 shows the system?s capability
to push information from the QA system about
nearby points-of-interest (PoI) during a navigation
task, which the user can then follow-up on (in ut-
terances User2 and User3). The final 3 utterances
show a natural switch between navigation to an en-
tity and QA about that entity.
2 Related work
Mobile applications such as Siri, Google Maps
Navigation, Sygic, etc. address the problem of
navigation while applications like Triposo, Guide-
pal, Wikihood, etc. address the problem of tourist
information by presenting the user with descrip-
tive information about various points of interest
(PoI) in the city. While some exploratory applica-
tions present snippets of information about a pre-
compiled list of PoI, others applications dynam-
ically generate a list of PoI arranged based on
their proximity to the users. Users can also ob-
tain specific information about PoI using Search
applications. Also, since these navigation and ex-
ploratory/search applications do not address both
problems in an integrated way, users need to
switch between them and therefore lose interac-
tion context.
While most applications address these two
problems independently, some like Google Now,
Google Field Trip, etc, mix navigation with ex-
ploration. However, such applications present in-
formation primarily visually on the screen for the
user to read. In contrast, our system has the objec-
tive of keeping the user?s cognitive load low and
preventing users from being distracted (perhaps
dangerously so) from walking in the city (Kray et
al., 2003). Also, our system allows users to inter-
leave the two sub-tasks seamlessly and can keep
entities discussed in both tasks in shared context
(as shown in Table 1).
Several systems have addressed the issue of
pedestrian navigation (Malaka and Zipf, 2000;
Dale et al, 2003; Heinroth and Buhler, 2008).
Some dialogue systems deal with presenting in-
formation concerning points of interest (Ko et al,
2005; Misu and Kawahara, 2007; Kashioka et al,
2011). In contrast to all these earlier work, we
demonstrate a system that deals with both naviga-
tion and tourist information issues in an integrated
fashion.
Figure 1: System Architecture
3 Multithreaded dialogue management
The architecture of the current system is shown
in figure 1. The Interaction Manager (IM) is
the central component of this architecture, which
provides the user with navigational instructions,
pushes PoI information and manages QA ques-
tions. It receives the user?s input in the form of
a dialogue act (DA) from the ASR module and
the user?s location (latitude and longitude), orien-
tation and speed from the Pedestrian Tracker mod-
ule. Based on these inputs and the dialogue con-
text, the IM responds with a system output dia-
logue act. The Interaction Manager manages the
conversation using five coversational threads: di-
alogue control, response, navigation, question an-
swering, and PoI pushing. These different threads
represent the state of different dimensions of the
user-system conversation that interleave with each
other. Each of these threads generates a dialogue
action based on a dialogue policy. A dialogue pol-
icy is a mapping between dialogue states and dia-
logue actions, which are semantic representations
of what the system wants to say next. Dialogue
actions from the five threads are stored in five sep-
arate queues.
The queues are assigned priorities that decide
the order in which items from the queues will
be popped. For instance, informing the user of
a PoI could be delayed if the user needs to be
given an instruction to turn at the junction he is
approaching. For this reason, priority is assigned
to dialogue threads as follows.
Priority 1. Dialogue control (calibration phase,
repeat request, clarifications etc)
Priority 2. Responding to user requests
Priority 3. System initiated navigation task actions
Priority 4. Responses to User initiated QA actions
Priority 5. PoI Push actions
152
Dialogue control The IM initiates the conversa-
tion with a calibration phase where the user?s ini-
tial location and orientation are obtained. In this
phase, the IM requests the user to walk a few yards
so that the pedestrian tracker can sense the user?s
location and orientation. During the course of the
coversation, the IM uses this thread to manage
repeat requests, issues with unparsed user utter-
ances, utterances that have low ASR confidence,
and so on. The dialogue control thread is used to
manage reference resolution in cases where refer-
ring expressions are underspecified.
Navigation The IM identifies the location of the
destination entity and queries the City Model for a
route plan. The plan provides information such as
numbers of exits at junctions, the exit number the
user should take, turn angle, popularity index of
the street, and the slope of the road. In an attempt
to adapt the route instructions to user route knowl-
edge, the IM first picks the most popular street in
the plan and asks the users if they can get to the
street on their own. Also, the IM queries the Visi-
bility Engine (VE) for highly salient visible land-
marks (computed using Flickr tags) that can used
to direct the user. Instructions based on visible
landmarks are given whenever possible.
Question Answering The system also answers
ad hoc questions from the user (e.g. ?Who is David
Hume??, ?What is the Old College??, etc). These
are sent to the QA server and answered based on
responses from the QA server. The dialogue pol-
icy here is to answer the user?s question with the
first snippet available and ask the user to request
for more if interested.
Pushing PoI Information When the user is mo-
bile, the IM identifies points of interest on the
route based on two factors: proximity and visibil-
ity. Proximity push is done by checking for PoIs
near the user using high-scoring ones when there
are many, based on tourist popularity ratings in the
City Model. Visibility push is done by querying
the VE for salient entities visible to the user that
may be worth pushing. The dialogue policy is to
introduce the PoI entity along with visual descrip-
tors if available. The IM queries the QA server for
snippets on entity and if available, pushes them the
first snippet to the user. The user is encouraged to
ask for more if interested.
4 Conclusion
We demonstrate a mobile conversational system
to support pedestrian users in navigation and
question-answering tasks in urban environments.
The system is a speech-only interface and inter-
leaves navigation and tourist information in an in-
tegrated way, using a shared dialogue context. For
example, using the navigational context, our sys-
tem can push point-of-interest information which
can then initiate touristic exploration tasks using
the QA module. An evaluation of an earlier ver-
sion was reported in (Janarthanam et al, 2013).
Acknowledgments
The research leading to these results was funded by the Eu-
ropean Commission?s Framework 7 programme under grant
agreement no. 270019 (SPACEBOOK project).
References
R. Dale, S. Geldof, and J. Prost. 2003. CORAL : Using Nat-
ural Language Generation for Navigational Assistance. In
Proceedings of ACSC2003, South Australia.
R. G. Golledge. 1992. Place recognition and wayfinding:
Making sense of space. Geoforum, 23.
T. Heinroth and D. Buhler. 2008. Arrigator: evaluation of
a speech-based pedestrian navigation system. In Proceed-
ings of 4th International Conference on Intelligent Envi-
ronments, 2008.
S. Janarthanam, O. Lemon, P. Bartie, T. Dalmas, A. Dick-
inson, X. Liu, W. Mackaness, and B. Webber. 2013.
Evaluating a city exploration dialogue system combining
question-answering and pedestrian navigation. In Proc.
ACL 2013.
H. Kashioka, T. Misu, E. Mizukami, Y. Shiga, K. Kayama,
C. Hori, and H. Kawai. 2011. Multimodal Dialog System
for Kyoto Sightseeing Guide. In Asia-Pacific Signal and
Information Processing Association Conference.
J. Ko, F. Murase, T. Mitamura, E. Nyberg, M. Tateishi,
I. Akahori, and N. Hataoka. 2005. CAMMIA: A Context-
Aware Spoken Dialog System for Mobile Environments.
In IEEE Automatic Speech Recognition and Understand-
ing Workshop.
C. Kray, K. Laakso, C. Elting, and V. Coors. 2003. Present-
ing route instructions on mobile devices. In Proceedings
of IUI 03, Florida.
R. Malaka and A. Zipf. 2000. Deep Map - challenging IT
research in the framework of a tourist information sys-
tem. In Information and Communication Technologies in
Tourism 2000, pages 15?27. Springer.
T. Misu and T. Kawahara. 2007. An Interactive Framework
for Document Retrieval and Presentation with Question-
Answering Function in Restricted Domain. In Proc. of
the 26th IEA/AIE conference, pages 126?134.
M. Raubal and S. Winter. 2002. Enriching wayfinding in-
structions with local landmarks. In Second International
Conference GIScience. Springer, Boulder, USA.
153
Proceedings of the SIGDIAL 2013 Conference, pages 154?156,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Demonstration of the Parlance system: a data-driven,
incremental, spoken dialogue system for interactive search
Helen Hastie, Marie-Aude Aufaure?, Panos Alexopoulos, Heriberto Cuay?huitl, Nina Dethlefs,
Milica Gasic, James Henderson, Oliver Lemon, Xingkun Liu, Peter Mika, Nesrine Ben Mustapha,
Verena Rieser, Blaise Thomson, Pirros Tsiakoulis, Yves Vanrompay, Boris Villazon-Terrazas, Steve Young
email: h.hastie@hw.ac.uk. See http://parlance-project.eu for full list of affiliations
Abstract
The Parlance system for interactive
search processes dialogue at a micro-
turn level, displaying dialogue phe-
nomena that play a vital role in hu-
man spoken conversation. These di-
alogue phenomena include more nat-
ural turn-taking through rapid sys-
tem responses, generation of backchan-
nels, and user barge-ins. The Par-
lance demonstration system differen-
tiates from other incremental systems
in that it is data-driven with an infras-
tructure that scales well.
1 Introduction
The Parlance system provides interactive
search through a Spoken Dialogue System
(SDS). This SDS aims to be incremental to al-
low for more natural spoken interaction. Tra-
ditionally, the smallest unit of speech process-
ing for interactive systems has been a full ut-
terance with strict, rigid turn-taking. The
Parlance architecture, however, is an incre-
mental framework that allows for processing
of smaller ?chunks? of user input, which en-
ables one to model dialogue phenomena such
as barge-ins and backchannels. This work is
carried out under the FP7 EC project Par-
lance 1, the goal of which is to develop inter-
active search through speech in multiple lan-
guages. The domain for the demonstration
system is interactive search for restaurants in
San Francisco. An example dialogue is given
in Table 1.
?Authors are in alphabetical order
1http://www.parlance-project.eu
SYS Thank you for calling the Parlance Restaurant
system. You may ask for information by cuisine
type, price range or area. How may I help you?
USR I want to find an Afghan restaurant.........which is
in the cheap price range.
SYS .......................................................[uhuhh]........
The Helmand Palace is a cheerful setting for au-
thentic Afghan cuisine.
USR What is the address and phone number?
SYS The address 2424 Van Ness Ave ....
Table 1: Example dialogue excerpt for restaurant in-
formation in San Francisco
2 Background
Previous work includes systems that can deal
with ?micro-turns? (i.e. sub-utterance process-
ing units), resulting in dialogues that are more
fluid and responsive. This has been backed up
by a large body of psycholinguistic literature
that indicates that human-human interaction
is in fact incremental (Levelt, 1989).
It has been shown that incremental dia-
logue behaviour can improve the user experi-
ence (Skantze and Schlangen, 2009; Baumann
et al, 2011; Selfridge et al, 2011) and en-
able the system designer to model several di-
alogue phenomena that play a vital role in
human discourse (Levelt, 1989) but have so
far been absent from systems. These dialogue
phenomena that will be demonstrated by the
Parlance system include more natural turn-
taking through rapid system responses, gener-
ation of backchannels and user barge-ins. The
system differentiates from other incremental
systems in that it is entirely data-driven with
an infrastructure that potentially scales well.
3 System Architecture
Figure 1 gives an overview of the Par-
lance system architecture, which maintains
154
LOCAL SEARCH ENGINE
AUTOMATIC SPEECH RECOGNITION
NLG
AUDIO I/O
TTS
BACKCHANNEL GENERATOR
IM
MIM
HUB
KNOWLEDGE BASE
WavePackets
1-Best Words
Segmentlabel
N-Best Phrase List
WavePackets
Micro-Turn Dialogue Act
System Dialogue Act
String Packets
StringPackets
VoIP Interface (PJSIP)
N-best Dialogue Act Units
 API call ( + metadata)
Search Response
Partial Dialogue Act (in case of interruption)
PartialString(in case of interruption)SPOKEN LANGUAGE UNDERSTANDING Decode from t0 to t1
Figure 1: Overview of the Parlance system
architecture
the modularity of a traditional SDS while at
the same time allowing for complex interaction
at the micro-turn level between components.
Each component described below makes use
of the PINC (Parlance INCremental) dialogue
act schema. In this scheme, a complete dia-
logue act is made up of a set of primitive di-
alogue acts which are defined as acttype-item
pairs. The PINC dialogue act scheme supports
incrementality by allowing SLU to incremen-
tally output primitive dialogue acts whenever
a complete acttype-item pair is recognised with
sufficient confidence. The complete dialogue
act is then the set of these primitive acts out-
put during the utterance.
3.1 Recognition and Understanding
The Automatic Speech Recogniser (ASR) and
Spoken Language Understanding (SLU) com-
ponents operate in two passes. The audio in-
put is segmented by a Voice Activity Detec-
tor and then coded into feature vectors. For
the first pass of the ASR2, a fast bigram de-
coder performs continuous traceback generat-
ing word by word output. During this pass,
while the user is speaking, an SLU module
called the ?segment decoder? is called incre-
2http://mi.eng.cam.ac.uk/research/dialogue/
ATK_Manual.pdf
mentally as words or phrases are recognised.
This module incrementally outputs the set of
primitive dialogue acts that can be detected
based on each utterance prefix. Here, the ASR
only provides the single best hypothesis, and
SLU only outputs a single set of primitive dia-
logue acts, without an associated probability.
On request from the Micro-turn Interaction
Manager (MIM), a second pass can be per-
formed to restore the current utterance using a
trigram language model, and return a full dis-
tribution over the complete phrase as a con-
fusion network. This is then passed to the
SLU module which outputs the set of alter-
native complete interpretations, each with its
associated probability, thus reflecting the un-
certainty in the ASR-SLU understanding pro-
cess.
3.2 Interaction Management
Figure 1 illustrates the role of the Micro-turn
Interaction Manager (MIM) component in the
overall Parlance architecture. In order to
allow for natural interaction, the MIM is re-
sponsible for taking actions such as listening to
the user, taking the floor, and generating back-
channels at the micro-turn level. Given various
features from different components, the MIM
selects a micro-turn action and sends it to the
IM and back-channel generator component to
generate a system response.
Micro-turn Interaction Manager A
baseline hand-crafted MIM was developed
using predefined rules. It receives turn-taking
information from the TTS, the audio-output
component, the ASR and a timer, and updates
turn-taking features. Based on the current
features and predefined rules, it generates
control signals and sends them to the TTS,
ASR, timer and HUB. In terms of micro-turn
taking, for example, if the user interrupts
the system utterance, the system will stop
speaking and listen to the user. The system
also outputs a short back-channel and stays in
user turn state if the user utterance provides
limited information.
Interaction Manager Once the MIM has
decided when the system should take the floor,
it is the task of the IM to decide what to say.
The IM is based on the partially observable
155
Markov decision process (POMDP) frame-
work, where the system?s decisions can be op-
timised via reinforcement learning. The model
adopted for Parlance is the Bayesian Update
of Dialogue State (BUDS) manager (Thom-
son and Young, 2010). This POMDP-based
IM factors the dialogue state into condition-
ally dependent elements. Dependencies be-
tween these elements can be derived directly
from the dialogue ontology. These elements
are arranged into a dynamic Bayesian network
which allows for their marginal probabilities
to be updated during the dialogue, compris-
ing the belief state. The belief state is then
mapped into a smaller-scale summary space
and the decisions are optimised using the nat-
ural actor critic algorithm.
HUB The HUB manages the high level flow
of information. It receives turn change infor-
mation from the MIM and sends commands
to the SLU/IM/NLG to ?take the floor? in the
conversation and generate a response.
3.3 Generation and TTS
We aim to automatically generate language,
trained from data, that is (1) grammatically
well formed, (2) natural, (3) cohesive and (4)
rapidly produced at runtime. Whilst the first
two requirements are important in any dia-
logue system, the latter two are key require-
ments for systems with incremental processing,
in order to be more responsive. This includes
generating back-channels, dynamic content re-
ordering (Dethlefs et al, 2012), and surface
generation that models coherent discourse phe-
nomena, such as pronominalisation and co-
reference (Dethlefs et al, 2013). Incremen-
tal surfacce generation requires rich context
awareness in order to keep track of all that has
been generated so far. We therefore treat sur-
face realisation as a sequence labelling task and
use Conditional Random Fields (CRFs), which
take semantically annotated phrase structure
trees as input, in order to represent long dis-
tance linguistic dependencies. This approach
has been compared with a number of compet-
itive state-of-the art surface realisers (Deth-
lefs et al, 2013), and can be trained from
minimally labelled data to reduce development
time and facilitate its application to new do-
mains.
The TTS component uses a trainable HMM-
based speech synthesizer. As it is a paramet-
ric model, HMM-TTS has more flexibility than
traditional unit-selection approaches and is es-
pecially useful for producing expressive speech.
3.4 Local Search and Knowledge Base
The domain ontology is populated by the local
search component and contains restaurants in
5 regional areas of San Francisco. Restaurant
search results are returned based on their lon-
gitude and latitude for 3 price ranges and 52
cuisine types.
4 Future Work
We intend to perform a task-based evaluation
using crowd-sourced users. Future versions
will use a dynamic Knowledge Base and User
Model for adapting to evolving domains and
personalised interaction respectively.
Acknowledgements
The research leading to this work was funded by the EC
FP7 programme FP7/2011-14 under grant agreement
no. 287615 (PARLANCE).
References
T. Baumann, O. Buss, and D. Schlangen. 2011. Eval-
uation and Optimisation of Incremental Processors.
Dialogue and Discourse, 2(1).
Nina Dethlefs, Helen Hastie, Verena Rieser, and Oliver
Lemon. 2012. Optimising Incremental Generation
for Spoken Dialogue Systems: Reducing the Need
for Fillers. In Proceedings of INLG, Chicago, USA.
N. Dethlefs, H. Hastie, H. Cuay?huitl, and O. Lemon.
2013. Conditional Random Fields for Responsive
Surface Realisation Using Global Features. In Pro-
ceedings of ACL, Sofia, Bulgaria.
W. Levelt. 1989. Speaking: From Intenion to Articu-
lation. MIT Press.
E. Selfridge, I. Arizmendi, P. Heeman, and J. Williams.
2011. Stability and Accuracy in Incremental Speech
Recognition. In Proceedings of SIGDIAL, Portland,
Oregon.
G. Skantze and D. Schlangen. 2009. Incremental Dia-
logue Processing in a Micro-Domain. In Proceedings
of EACL, Athens, Greece.
B Thomson and S Young. 2010. Bayesian update of
dialogue state: A POMDP framework for spoken
dialogue systems. Computer Speech and Language,
24(4):562?588.
156
Proceedings of the SIGDIAL 2014 Conference, pages 260?262,
Philadelphia, U.S.A., 18-20 June 2014. c?2014 Association for Computational Linguistics
The Parlance Mobile Application for Interactive Search in
English and Mandarin
Helen Hastie, Marie-Aude Aufaure?, Panos Alexopoulos,
Hugues Bouchard, Catherine Breslin, Heriberto Cuay?huitl, Nina Dethlefs,
Milica Ga?i?, James Henderson, Oliver Lemon, Xingkun Liu, Peter Mika, Nesrine Ben Mustapha,
Tim Potter, Verena Rieser, Blaise Thomson, Pirros Tsiakoulis, Yves Vanrompay,
Boris Villazon-Terrazas, Majid Yazdani, Steve Young and Yanchao Yu
email: h.hastie@hw.ac.uk. See http://parlance-project.eu for full list of affiliations
Abstract
We demonstrate a mobile application in
English and Mandarin to test and eval-
uate components of the Parlance di-
alogue system for interactive search un-
der real-world conditions.
1 Introduction
With the advent of evaluations ?in the wild?,
emphasis is being put on converting re-
search prototypes into mobile applications that
can be used for evaluation and data col-
lection by real users downloading the ap-
plication from the market place. This is
the motivation behind the work demonstrated
here where we present a modular framework
whereby research components from the Par-
lance project (Hastie et al., 2013) can be
plugged in, tested and evaluated in a mobile
environment.
The goal of Parlance is to perform inter-
active search through speech in multiple lan-
guages. The domain for the demonstration
system is interactive search for restaurants in
Cambridge, UK for Mandarin and San Fran-
cisco, USA for English. The scenario is that
Mandarin speaking tourists would be able to
download the application and use it to learn
about restaurants in English speaking towns
and cities.
2 System Architecture
Here, we adopt a client-server approach as il-
lustrated in Figure 1 for Mandarin and Figure
2 for English. The front end of the demon-
stration system is an Android application that
calls the Google Automatic Speech Recogni-
tion (ASR) API and sends the recognized user
utterance to a server running the Interaction
?Authors are in alphabetical order
Manager (IM), Spoken Language Understand-
ing (SLU) and Natural Language Generation
(NLG) components.
Figure 1: Overview of the Parlance Man-
darin mobile application system architecture
Figure 2: Overview of the Parlance En-
glish mobile application system architecture
extended to use the Yahoo API to populate
the application with additional restaurant in-
formation
When the user clicks the Start button, a di-
alogue session starts. The phone application
first connects to the Parlance server (via
the Java Socket Server) to get the initial sys-
tem greeting which it speaks via the Google
260
Text-To-Speech (TTS) API. After the system
utterance finishes the recognizer starts to lis-
ten for user input to send to the SLU compo-
nent. The SLU converts text into a semantic
interpretation consisting of a set of triples of
communicative function, attribute, and (op-
tionally) value1. Probabilities can be associ-
ated with candidate interpretations to reflect
uncertainty in either the ASR or SLU. The
SLU then passes the semantic interpretation
to the IM within the same server.
Chinese sentences are composed of strings of
characters without any space to mark words as
other languages do, for example:
In order to correctly parse and understand
Chinese sentences, Chinese word segmenta-
tions must be performed. To do this segmen-
tation, we use the Stanford Chinese word seg-
mentor2, which relies on a linear-chain condi-
tional random field (CRF) model and treats
word segmentation as a binary decision task.
The Java Socket Server then sends the seg-
mented Chinese sentence to the SLU on the
server.
The IM then selects a dialogue act, accesses
the database and in the case of English passes
back the list of restaurant identification num-
bers (ids) associated with the relevant restau-
rants. For the English demonstration system,
these restaurants are displayed on the smart
phone as seen in Figures 4 and 5. Finally,
the NLG component decides how best to re-
alise the restaurant descriptions and sends the
string back to the phone application for the
TTS to realise. The example output is illus-
trated in Figure 3 for Mandarin and Figure 4
for English.
As discussed above, the Parlance mobile
application can be used as a test-bed for com-
paring alternative techniques for various com-
ponents. Here we discuss two such compo-
nents: IM and NLG.
1This has been implemented for English; Mandarin
uses the rule-based Phoenix parser.
2http://nlp.stanford.edu/projects/chinese-
nlp.shtml
Figure 3: Screenshot and translation of the
Mandarin system
Figure 4: Screenshot of dialogue and the list
of recommended restaurants shown on a map
and in a list for English
2.1 Interaction Management
The Parlance Interaction Manager is based
on the partially observable Markov decision
process (POMDP) framework, where the sys-
tem?s decisions can be optimised via reinforce-
ment learning. The model adopted for Par-
lance is the Bayesian Update of Dialogue
State (BUDS) manager (Thomson and Young,
2010). This POMDP-based IM factors the di-
alogue state into conditionally dependent ele-
ments. Dependencies between these elements
can be derived directly from the dialogue on-
tology. These elements are arranged into a dy-
namic Bayesian network which allows for their
marginal probabilities to be updated during
the dialogue, comprising the belief state. The
belief state is then mapped into a smaller-scale
summary space and the decisions are optimised
using the natural actor critic algorithm. In the
Parlance application, hand-crafted policies
261
Figure 5: Screenshot of the recommended
restaurant for the English application
can be compared to learned ones.
2.2 Natural Language Generation
As mentioned above, the server returns the
string to be synthesised by the Google TTS
API. This mobile framework allows for testing
of alternative approaches to NLG. In particu-
lar, we are interested in comparing a surface re-
aliser that uses CRFs against a template-based
baseline. The CRFs take semantically anno-
tated phrase structure trees as input, which it
uses to keep track of rich linguistic contexts.
Our approach has been compared with a num-
ber of competitive state-of-the art surface real-
izers (Dethlefs et al., 2013), and can be trained
from example sentences with annotations of se-
mantic slots.
2.3 Local Search and Knowledge Base
For the English system, the domain database is
populated by the search Yahoo API (Bouchard
and Mika, 2013) with restaurants in San Fran-
sisco. These restaurant search results are
returned based on their longitude and lati-
tude within San Francisco for 5 main areas, 3
price categories and 52 cuisine types contain-
ing around 1,600 individual restaurants.
The Chinese database has been partially
translated from an English database for restau-
rants in Cambridge, UK and search is based
on 3 price categories, 5 areas and 35 cuisine
types having a total of 157 restaurants. Due
to the language-agnostic nature of the Par-
lance system, only the name and address
fields needed to be translated.
3 Future Work
Investigating application side audio compres-
sion and audio streaming over a mobile in-
ternet connection would enable further assess-
ment of the ASR and TTS components used
in the original Parlance system (Hastie et
al., 2013). This would allow for entire research
systems to be plugged directly into the mobile
interface without the use of third party ASR
and TTS.
Future work also involves developing a feed-
back mechanism for evaluation purposes that
does not put undue effort on the user and put
them off using the application. In addition,
this framework can be extended to leverage
hyperlocal and social information of the user
when displaying items of interest.
Acknowledgements
The research leading to this work was funded
by the EC FP7 programme FP7/2011-14
under grant agreement no. 287615 (PAR-
LANCE).
References
H. Bouchard and P. Mika. 2013. Interactive hy-
perlocal search API. Technical report, Yahoo
Iberia, August.
N. Dethlefs, H. Hastie, H. Cuay?huitl, and
O. Lemon. 2013. Conditional Random Fields
for Responsive Surface Realisation Using Global
Features. In Proceedings of the 51st Annual
Meeting of the Association for Computational
Linguistics (ACL), Sofia, Bulgaria.
H. Hastie, M.A. Aufaure, P. Alexopoulos,
H. Cuay?huitl, N. Dethlefs, M. Gasic,
J. Henderson, O. Lemon, X. Liu, P. Mika,
N. Ben Mustapha, V. Rieser, B. Thomson,
P. Tsiakoulis, Y. Vanrompay, B. Villazon-
Terrazas, and S. Young. 2013. Demonstration
of the PARLANCE system: a data-driven
incremental, spoken dialogue system for in-
teractive search. In Proceedings of the 14th
Annual Meeting of the Special Interest Group
on Discourse and Dialogue (SIGDIAL), Metz,
France, August.
B. Thomson and S. Young. 2010. Bayesian up-
date of dialogue state: A POMDP framework
for spoken dialogue systems. Computer Speech
and Language, 24(4):562?588.
262
