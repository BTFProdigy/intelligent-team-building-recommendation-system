Proceedings of NAACL HLT 2009: Short Papers, pages 177?180,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
 
 
Towards Effective Sentence Simplification for  
Automatic Processing of Biomedical Text  
 
Siddhartha Jonnalagadda*, Luis Tari**, J?rg Hakenberg**, Chitta Baral**, Graciela Gonzalez* 
*Department of Biomedical Informatics, Arizona State University, Phoenix, AZ 85004, USA. 
**Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85281, USA. 
 Corresponding author: ggonzalez@asu.edu 
 
 
 
 
Abstract 
The complexity of sentences characteristic to 
biomedical articles poses a challenge to natu-
ral language parsers, which are typically 
trained on large-scale corpora of non-technical 
text. We propose a text simplification process, 
bioSimplify, that seeks to reduce the complex-
ity of sentences in biomedical abstracts in or-
der to improve the performance of syntactic 
parsers on the processed sentences. Syntactic 
parsing is typically one of the first steps in a 
text mining pipeline. Thus, any improvement 
in performance would have a ripple effect 
over all processing steps. We evaluated our 
method using a corpus of biomedical sen-
tences annotated with syntactic links. Our em-
pirical results show an improvement of 2.90% 
for the Charniak-McClosky parser and of 
4.23% for the Link Grammar parser when 
processing simplified sentences rather than the 
original sentences in the corpus. 
1 Introduction 
It is typical that applications for biomedical text 
involve the use of natural language syntactic pars-
ers as one of the first steps in processing. Thus, the 
performance of the system as a whole is largely 
dependent on how well the natural language syn-
tactic parsers perform.  
One of the challenges in parsing biomedical text is 
that it is significantly more complex than articles in 
typical English text. Different analysis show other 
problematic characteristics, including inconsistent 
use of nouns and partial words (Tateisi & Tsujii, 
2004), higher perplexity measures (Elhadad, 2006), 
greater lexical density, plus increased number of 
relative clauses and prepositional phrases (Ge-
moets, 2004), all of which correlate with dimi-
nished comprehension and higher text difficulty.  
These characteristics also lead to performance 
problems in terms of computation time and accura-
cy for parsers that are trained on common English 
text corpus. 
  We identified three categories of sentences: 1) 
normal English sentences, like in Newswire text, 
2) normal biomedical English sentences ? those 
sentences which can be parsed without a problem 
by Link Grammar-, and 3) complex biomedical 
English sentences ? those sentences which can?t be 
parsed by Link Grammar. Aside from the known 
characteristics mentioned before, sentences in the 
third group tended to be longer (18% of them had 
more than 50 words, while only 8% of those in 
group 2 and 2% of those in group 1 did). It has 
been observed that parsers perform well with sen-
tences of reduced length (Chandrasekar & Srini-
vas, 1997; Siddharthan, 2006).  
  In this paper, we explore the use of text simplifi-
cation as a preprocessing step for general parsing 
to reduce length and complexity of biomedical sen-
tences in order to enhance the performance of the 
parsers.  
2 Methods  
There are currently many publicly available corpo-
ra of biomedical texts, the most popular among 
them being BioInfer, Genia, AImed, HPRD 50, 
IEPA, LLL and BioCreative1-PPI. Among these 
corpora, BioInfer includes the most comprehensive 
collection of sentences and careful annotation for 
links of natural parser, in both the Stanford and 
Link Grammar schemes. Therefore, we chose the 
BioInfer corpus, version 1.1.0 (Pyysalo et al, 
2007), containing 1100 sentences for evaluating 
the effectiveness of our simplification method on 
177
  
the performance of syntactic parsers. The method 
includes syntactic and non-syntactic transforma-
tions, detailed next. 
2.1 Non-syntactic transformation 
We group here three steps of our approach: 1. pre-
processing through removal of spurious phrases; 2. 
replacement of gene names; 3. replacement of 
noun phrases. 
  To improve the correctness of the parsing, each 
biomedical sentence is first preprocessed to re-
move phrases that are not essential to the sentence. 
This includes removal of section indicators, which 
are phrases that specify the name of the section at 
the beginning of the sentence, plus the removal of 
phrases in parentheses (such as citations and num-
bering in lists). Also, partially hyphenated words 
are transformed by combining with the nearest 
word that follows or precedes the partial hyphe-
nated word to make a meaningful word. For in-
stance, the phrase ?alpha- and beta-catenin? is 
transformed into ?alpha-catenin and beta-catenin?. 
  Occurrences of multi-word technical terms and 
entity names involved in biomedical processes are 
common in biomedical text. Such terms are not 
likely to appear in the dictionary of a parser (per-
plexity is high), and will force it to use morpho-
guessing and unknown word guessing. This is time 
consuming and prone to error. Thus, unlike typical 
text simplification that emphasizes syntactic trans-
formation of sentences, our approach utilizes a 
named entity recognition engine, BANNER  
(Leaman & Gonzalez, 2008), to replace multi-word 
gene names with single-word placeholders.  
 Replacement of gene names with single elements 
is not enough, however, and grammatical category 
(i.e. singular or plural) of the element has to be 
considered. Lingpipe (Alias-i, 2006), a shallow 
parser for biomedical text, identifies noun phrases 
and replaces them with single elements. A single 
element is considered singular when the following 
verb indicates a third-person singular verb or the 
determiner preceded by the element is either ?a? or 
?an?. Otherwise it is considered as plural and an 
?s? is attached to the end of the element. 
2.2 Syntactic transformation 
The problem of simplifying long sentences in 
common English text has been studied before, not-
ably by Chandrasekar & Srinivas (1997) and Sidd-
harthan (2006). However, the techniques used in 
these studies might not totally solve the issue of 
parsing biomedical sentences. For example, using 
Siddharthan?s approach, the biological finding 
?The Huntington's disease protein interacts with 
p53 and CREB-binding protein and represses tran-
scription?, and assuming multi-word nouns such as 
?CREB-binding protein? do not present a problem, 
would be simplified to: 
?The Huntington's disease protein interacts with 
p53. The Huntington's disease protein interacts 
with CREB-binding protein. The Huntington's 
disease protein represses transcription.?  
 Our method transforms it to ?GENE1 interacts 
with GENE2 and GENE3 and represses transcrip-
tion.? Both decrease the average sentence length, 
but the earlier distorts the biological meaning 
(since the Huntington?s disease protein might not 
repress transcription on its own), while the latter 
signifies it. 
  While replacement of gene names and noun 
phrases can reduce the sentence length, there are 
Figure 1 ? Linkages after simplification of the original sentence 
? GENE1: human CREB binding protein 
? GENE2: CBP 
? GENE3s: CBP 
? REPNP1s: RTS patients 
Original sentence ST: The gene for the human CREB binding protein, the transcriptional coactivator CBP,   
is included in the RT1 cosmid, and mutations in CBP have recently been identified in RTS patients. 
ST1: 
ST2: 
c1 
c3 c4 
c2 
178
  
cases when the sentences are still too complex to 
be parsed efficiently. We developed a simple algo-
rithm that utilizes linkages (specific grammatical 
relationships between pairs of words in a sentence) 
of the Link Grammar parser (Sleator, 1998) and 
punctuations for splitting sentences into clauses. 
An example in Figure 1 illustrates the main part of 
the algorithm. Each linkage has a primary link type 
in CAPITAL followed by secondary link type in 
short. The intuition behind the algorithm is to try to 
identify independent clauses from complex sen-
tences. The first step is to split the sentence ST into 
clauses c1, c2, c3 and c4 based on commas. c1 is 
parsed using the Link Grammar parser, but c1 can-
not be a sentence as there is no ?S? link in the lin-
kage of c1. c2 is then attached to c1 and the linkage 
of ?c1, c2? does not contain a ?S? link as well. ?c1, 
c2, c3.? is recognized as a sentence, since the lin-
kage contains an ?S? link, indicating that it is a 
sentence, as well as the linkage of c4. So the algo-
rithm returns two sentences ST1 and ST2 for ST. 
3 Results 
Our method has the greatest impact on the perfor-
mance of Link Grammar (LG), which lies at the 
core of BioLG (Pyysalo et al, 2006). However, it 
also has a significant impact on the self-training 
biomedical parser by McClosky & Charniak (CM), 
which is currently the best parser available for 
biomedical text.  
3.1 Rudimentary statistics of the results of sim-
plification: After the simplification algorithm was 
tested on the 1100 annotated sentences of the Bio-
Infer corpus, there were 1159 simplified sentences 
because of syntactic transformation (section 2.2). 
The number of words per sentence showed a sharp 
drop of 20.4% from 27.0 to 21.5. The Flesh-
Kincaid score for readability dropped from 17.4 to 
14.2. The Gunning Fog index also dropped by 
18.3% from 19.7 to 16.1. 
Pre-
processing 
Replacement 
of gene names 
Replacement of 
noun phrases 
Syntactic  
Simplification 
359  1082  915  91 
Table 1: Sentences processed in each stage 
 
3.2 Impact of simplification on the efficiency of 
parsing: We inputted the BioInfer corpus to LG 
and CM. If LG cannot find a complete linkage, it 
invokes its panic mode, where sentences are re-
turned with considerably low accuracy. Out of the 
1100 original sentences in the corpus, 219 went 
into panic mode. After processing, only 39 out of 
1159 simplified sentences triggered panic mode (a 
16.4% improvement in efficiency). The average 
time for parsing a sentence also dropped from 7.36 
secs to 1.70 secs after simplification.  
 
3.3 Impact of simplification on the accuracy of 
parsing: Let ?g, ?o and ?s, respectively be the 
sets containing the links of the gold standard, the 
output generated by the parser on original sen-
tences and the output generated by the parser on 
simplified sentences. We denote a link of type ? 
between the tokens ?1 and ?2 by (?,?1,?2). In the 
case of the original sentences, the tokens ?1and ?2 
are single-worded. So, (?,?1,?2) is a true positive 
iff (?,?1,?2) belongs to both ?g and ?o, false posi-
tive iff it only belongs to ?o and false negative iff 
it only belongs to ?g. In the case of simplified sen-
tences, the tokens ?1and ?2 can have multiple 
words. So, (?,?1,?2) which belongs to ?s is a true 
positive iff (?,??1,??2) belongs to ?g where ??1 
and ??2 are respectively one of the words in ?1 and 
?2. Additionally, (?,?1,?2) which belongs to ?g is 
not a false negative if ?1 and ?2 are parts of a sin-
gle token of a simplified sentence. For measuring 
the performance of a parser, the nature of linkage 
is most relevant in the context of the sentence in 
consideration. So, we calculate precision and recall 
for each sentence and average them over all sen-
tences to get the respective precision and recall for 
the collection.  
 
 Precision Recall f-measure 
CM 77.94% 74.08% 75.96% 
BioSimplify + 
CM 
82.51% 75.51% 78.86% 
Improvement   4.57% 1.43% 2.90% 
    
LG 72.36% 71.65% 72.00% 
BioSimplify + 
LG 
78.30% 74.27% 76.23% 
Improvement   5.94% 2.62% 4.23% 
Table 2: Accuracy of McClosky & Charniak (CM) and 
Link Grammar (LG) parsers based on Stanford depen-
dencies, with and without simplified sentences.  
 
  In order to compare the effect of BioSimplify on 
the two parsers, a converter from Link Grammar to 
Stanford scheme was used (Pyysalo et al 2007: 
precision and recall of 98% and 96%). Results of 
179
  
this comparision are shown in Table 2. On CM and 
LG, we were able to achieve a considerable im-
provement in the f-measures by 2.90% and 4.23% 
respectively. CM demonstrated an absolute error 
reduction of 4.1% over its previous best on a dif-
ferent test set. Overall, bioSimplify leverages pars-
ing of biomedical sentences, increasing both the 
efficiency and accuracy. 
4 Related work 
During the creation of BioInfer, noun phrase ma-
cro-dependencies were determined using a simple 
rule set without parsing. Some of the problems re-
lated to parsing noun phrases were removed by 
reducing the number of words by more than 20%. 
BioLG enhances LG by expansion of lexicons and 
the addition of morphological rules for biomedical 
domain. Our work differs from BioLG not only in 
utilizing a gene name recognizer, a specialized 
shallow parser and syntactic transformation, but 
also in creating a preprocessor that can improve the 
performance of any parser on biomedical text. 
  The idea of improving the performance of deep 
parsers through the integration of shallow and deep 
parsers has been reported in (Crysmann et al, 
2002; Daum et al, 2003; Frank et al, 2003) for 
non-biomedical text. In BioNLP, extraction sys-
tems (Jang et al, 2006; Yakushiji et al, 2001) used 
shallow parsers to enhance the performance of 
deep parsers. However, there is a lack of evalua-
tion of the correctness of the dependency parses, 
which is crucial to the correctness of the extracted 
systems. We not only evaluate the correctness of 
the links, but also go beyond the problem of rela-
tionship extraction and empower future researchers 
in leveraging their parsers (and other extraction 
systems) to get better results. 
5 Conclusion and Future work 
We achieved an f-measure of 78.86% using CM on 
BioInfer Corpus which is a 2.90% absolute reduc-
tion in error. We achieved a 4.23% absolute reduc-
tion in error using LG. According to the measures 
described in section 3.1, the simplified sentences 
of BioInfer outperform the original ones by more 
than 18%. Our method can also be used with other 
parsers. As future work, we will demonstrate the 
impact of our simplification method on other text 
mining tasks, such as relationship extraction. 
Acknowledgments 
We thank Science Foundation Arizona (award 
CAA 0277-08 Gonzalez) for partly supporting this 
research. SJ also thanks Bob Leaman and Anoop 
Grewal for their guidance. 
References  
Chandrasekar, R., & Srinivas, B. (1997). Automatic 
induction of rules for text simplification. Knowledge-
Based Systems, 10, 183-190.  
Crysmann, B., Frank, A., Kiefer, B., Muller, S., Neu-
mann, G., et al (2002). An integrated architecture for 
shallow and deep processing. ACL'02. 
Daum, M., Foth, K., & Menzel, W. (2003). Constraint 
based integration of deep and shallow parsing tech-
niques. EACL'03.  
Elhadad, No?mie (2006) User-Sensitive Text Summari-
zation: Application to the Medical Domain. 
Ph.D. Thesis, Columbia University. Available at 
www.dbmi.columbia.edu/noemie/papers/thesis.pdf 
Frank, A., Becker M, et al,. (2003). Integrated shallow 
and deep parsing: TopP meets HPSG. ACL'03. 
Gemoets, D., Rosemblat, G., Tse, T., Logan, R., Assess-
ing Readability of Consumer Health Information: An 
Exploratory Study. MEDINFO 2004. 
Jang, H., Lim, J., Lim, J.-H., Park, S.-J., Lee, K.-C. and 
Park, S.-H. (2006) Finding the evidence for protein-
protein interactions from PubMed abstracts, Bioin-
formatics, 22, e220-226. 
Leaman, R., & Gonzalez, G. (2008). BANNER: An 
executable survery of advances in biomedical named 
entity recognition. 652-663.  
Manning, C. D., & Sch?tze, H. (1999). Foundations of 
statistical natural language processing MIT Press. 
McClosky, D., & Charniak, E. (2008) Self-training for 
biomedical parsing. ACL?08. 
Pyysalo, S., Ginter, F., Haverinen, K., Heimonen, J., 
Salakoski, T., & Laippala, V. (2007) On the unifica-
tion of syntactic annotations under the stanford de-
pendency scheme.. ACL?07. 
Pyysalo, S., Salakoski, T., Aubin, S., & Nazarenko, A. 
(2006). Lexical adaptation of link grammar to the 
biomedical sublanguage: A comparative evaluation 
of three approaches. BMC Bioinformatics, 7, S2.  
Siddharthan, A. (2006). Syntactic simplification and 
text cohesion. Res  Lang  Comput, 4(1), 77-109.  
Sleator, D. (1998) Link Grammar Documentation 
Tateisi, Y., & Tsujii, J. (2004). Part-of-speech annota-
tion of biology research abstracts. LREC, 1267-1270.  
Yakushiji, A., Tateisi, Y., Miyao, Y., & Tsujii, J. 
(2001). Event extraction from biomedical papers using a 
full parser. PSB'01, 6, 408-419. 
180
Proceedings of the Workshop on BioNLP: Shared Task, pages 86?94,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Molecular event extraction from Link Grammar parse trees
Jo?rg Hakenberg1, Ille?s Solt2, Domonkos Tikk2,3, Luis Tari1,
Astrid Rheinla?nder3, Quang Long Ngyuen3, Graciela Gonzalez1, and Ulf Leser3
1Arizona State University, Tempe, AZ 85283, USA,
2Budapest University of Technology and Economics, 1117 Budapest, Hungary,
3Humboldt Universita?t zu Berlin, 10099 Berlin, Germany.
Abstract
We present an approach for extracting molec-
ular events from literature based on a deep
parser, using in a query language for parse
trees. Detected events range from gene ex-
pression to protein localization, and cover a
multitude of different entity types, including
genes/proteins, binding sites, and locations.
Furthermore, our approach is capable of rec-
ognizing negation and the speculative char-
acter of extracted statements. We first parse
documents using Link Grammar (BioLG) and
store the parse trees in a database. Events are
extracted using a newly developed query lan-
guage with traverses the BioLG linkages be-
tween trigger terms, arguments, and events.
The concrete queries are learnt from an an-
notated corpus. On BioNLP Shared Task data,
we achieve an overall F1-measure of 29.6%.
1 Introduction
Biomedical text mining aims at making the wealth
of information available in publications available for
systematic, automatic studies. An important area of
biomedical text mining is concerned with the ex-
traction of relationships between biological entities,
especially the extraction of protein?protein inter-
actions from PubMed abstracts (Krallinger et al,
2008). The BioNLP?09 Shared Task addresses the
problem of extracting nine different types of molec-
ular events (Kim et al, 2009) and thus targets a
problem that is considerable less-well studied than
protein-protein interactions. Such molecular events
include statements about the expression level of
genes, the binding sites of proteins, and the up/down
regulation of genes, among others. All events fo-
cus on genes/proteins and may include only a single
protein (e.g., protein catabolism), multiple proteins
(e.g., binding), and other arguments (e.g., phospho-
rylation site; protein location). The most complex
type of event considered in the task are regulations,
which may refer to other events (negative regulation
of gene expression) and may also include causes as
arguments. The task also addresses the problem that
experimental findings often are described in a defen-
sive manner (?Our results suggest ...?) or may appear
in negated context. This meta-information about an
extracted event should be taken into account when
text mining results are used in automated analysis
pipelines, but recognizing the degree of confidence
that can be put into an event adds further complex-
ity to the task. Overall, the three tasks in BioNLP?09
are: 1) event detection and characterization, 2) event
argument recognition, and 3) recognition of nega-
tions and speculations.
The approach we present in this paper addresses
all three tasks. Essentially, our system consists of
three components: A deep parser, a query language
for parse trees, and a set of queries that extract spe-
cific events from parse trees. First, we use the Bio-
LG parser (Pyysalo et al, 2006) for parsing sen-
tences into a graph-like structure. Essentially, Bio-
LG recognizes the syntactic structure of a sentence
and represents this information in a tree. It adds links
between semantically connected elements, such as
the links between a verb and its object and sub-
ject. Second, we store the result of BioLG in a re-
lational database. This information is accessed by a
special-purpose query language (Tu et al, 2008) that
86
 


	

 






	





BioNLP 2007: Biological, translational, and clinical language processing, pages 153?160,
Prague, June 2007. c?2007 Association for Computational Linguistics
What?s in a gene name?
Automated refinement of gene name dictionaries
Jo?rg Hakenberg
Bioinformatics Group, Biotechnological Centre
Technische Universita?t Dresden, 01307 Dresden, Germany
hakenberg@informatik.hu-berlin.de
Abstract
Many approaches for named entity recogni-
tion rely on dictionaries gathered from cu-
rated databases (such as Entrez Gene for
gene names.) Strategies for matching entries
in a dictionary against arbitrary text use ei-
ther inexact string matching that allows for
known deviations, dictionaries enriched ac-
cording to some observed rules, or a com-
bination of both. Such refined dictionar-
ies cover potential structural, lexical, ortho-
graphical, or morphological variations. In
this paper, we present an approach to au-
tomatically analyze dictionaries to discover
how names are composed and which varia-
tions typically occur. This knowledge can
be constructed by looking at single entries
(names and synonyms for one gene), and
then be transferred to entries that show simi-
lar patterns in one or more synonyms. For
instance, knowledge about words that are
frequently missing in (or added to) a name
(?antigen?, ?protein?, ?human?) could au-
tomatically be extracted from dictionaries.
This paper should be seen as a vision paper,
though we implemented most of the ideas
presented and show results for the task of
gene name recognition. The automatically
extracted name composition rules can eas-
ily be included in existing approaches, and
provide valuable insights into the biomedi-
cal sub-language.
1 Introduction
Recognition of named entities (NER), such as names
referring to genes and proteins, forms a major build-
ing block for text mining systems. Especially in
the life sciences, a large amount of different entity
types and their instances exist. Two basic strategies
for NER are classification- and dictionary-based ap-
proaches. Classifiers learn (or are given) models to
decide whether a sequence of tokens refers to an
entity or not. Such decisions are based on various
forms of input, for instance, tokens and their se-
quence in a sentence, part-of-speech tags, charac-
teristic suffixes, and trigger keywords1 (Hakenberg
et al, 2005). Models can be learned from a given
training sample. Dictionary-based approaches rely
on curated word lists containing (all known) repre-
sentatives of an entity type. Manual or automated
refinement of the dictionary and inexact matching
strategies allow to cover a broad spectrum of name
variations (Hanisch et al, 2005). Classification-
based approaches have proven to be very robust to-
wards unseen tokens and names, because they also
incorporate knowledge on names of the given class
in general1 (Crim et al, 2005). Dictionaries, on
the other hand, reflect the knowledge about an en-
tity class at a given time, and such approaches can-
not find instances unknown to them. However, the
main advantage of dictionary-based NER is that they
bring the explicit possibility to map recognized en-
tities to the source of the entries (most times, a
database.) This alleviates the task of named entity
1For example, a protein name often is/has a proper noun;
many enzymes end with ??ase?; ?domain of? is often followed
by a protein name.
153
identification (NEI) that is needed to annotate texts
properly or link text-mined facts to database entries.
In this paper, we want to concentrate on
dictionary-based approaches and present ideas of
how these could be automatically refined and en-
riched. In such a setting, named entity recognition
functions as a method of ?spotting? entities in a text,
after which further identification (disambiguation)
is needed. NER components thus should guarantee
very high recall rates with a reasonable precision.
NEI then refines the predictions of NER, eliminat-
ing false positive annotations and identifying names.
That such a setup would perform quite well is re-
flected, for example, in a study presented by Xu et
al. (2007). They showed that sophisticated disam-
biguation strategies currently yield up to 93.9% pre-
cision (for mouse genes; yeast: 89.5%, fly: 77.8%.)
Participants in the BioCreAtIvE 2 challenge showed
similar values for human genes (up to 84.1% preci-
sion, 87.5% recall, or 81.1% F1), see Morgan and
Hirschman (2007) for a summary.
Hand-coded rules for creating spelling variations
have been proposed before, see section on Related
Work. Such rules are applied to synonyms to gen-
erate morphological and orthographical variations
(?Fas ligand?? ?Fas ligands? and ?Ifn gamma??
?Ifn-??, respectively). In the same manner, systems
use known patterns for structural changes of names
and mappings for lexical variations to enrich exist-
ing dictionaries (?CD95R? ? ?receptor of CD95?
and ?gastric alcohol dehydrogenase? ? ?stomach
alcohol dehydrogenase?). Our research question in
this paper is, how such rules can be learned automat-
ically from dictionaries that contain entries of the
same entity class with multiple, typical synonyms
each. Learning about the composition of names
comes down to an analysis of known names. A
human, given the same task, would look through a
lot of examples to derive term formation patterns.
Questions to ask are:
? What are frequent orthographical and morpho-
logical variations?
? Which parts of a name get abbreviated?
? How are abbreviations formed?
? Which identical abbreviations can be observed
in multiple names?
? In which way can a name structurally and lexi-
cally change?
? Which are the parts of a name that can be ex-
changed with other terms or skipped entirely?
? Which are the important parts of a name, which
are additional descriptive elements?
In this paper, we demonstrate methods to analyze
names in order to find the semantically important
parts. We map these parts to potential syntactic vari-
ations thereof observed within a name and its syn-
onyms. We assess the frequency of such mappings
(exchange of tokens, different ordering of tokens,
etc.) and transfer this knowledge to all other names
in the same dictionary. In this setup, understanding
a name results in a structured decomposition of the
name. Such decompositions provide knowledge on
how to find (and identify) the name in arbitrary text,
as they give insights into its mandatory, unique, and
ambiguous2 parts.
This paper should be seen as a vision paper,
though we implemented most of the ideas presented
herein and show first results. We first explain the
idea behind learning name composition rules, mo-
tivated by manual curation as described in Related
Work. We then explain the basic techniques needed
for our analysis. We show how single entries (a
name and all its synonyms) can be analyzed to find
composition rules, and how these can be transferred
to other entries. Preliminary results using some of
the ideas presented here are also given. We con-
clude this paper with a discussion of the experimen-
tal methodology and an outlook.
1.1 Related Work
Current survey articles cover the spectrum of re-
cent methods and results for biomedical named en-
tity recognition and identification (Cohen and Hersh,
2005; Leser and Hakenberg, 2005). A recent as-
sessment of named entity recognition and identifi-
cation was done during the BioCreAtIvE 2 evalua-
tion3. Official results will be available in April 2007.
Naturally, a number of systems proposed before are
highly related to the method presented in this paper.
Hanisch et al (2005) proposed the ProMiner system
to recognize and identify protein names in text. They
observed that the ordering of tokens in a name oc-
cur quite frequently, but do not change the seman-
2The latter two as compared to the whole dictionary.
3See http://biocreative.sourceforge.net .
154
tics of the overall name. They presented a model for
protein names, partitioning tokens into token classes
according to their semantic significance: modifiers
(?receptor?), specifiers (?alpha?), non-descriptive
tokens (?fragment?), standard tokens (?TNF?), plus
common English words and interpunctuation. To
evaluate the significance of tokens, they count their
respective frequencies in a dictionary. Hanisch et al
extract a dictionary using various knowledge source
(HGNC etc.) and expand and prune it afterwards.
Expansion and pruning are based on manually de-
fined rules (separating numbers and words, expand-
ing known unambiguous synonyms with known syn-
onyms, applying curation lists maintained by biolog-
ical experts, predefined regular expressions). The fi-
nal matching procedure found names by comparing
(expanded) tokens and their classes to arbitrary text,
where some token classes were mandatory for the
identification and others could be missing. ProMiner
yielded results between 78 and 90% F1-measure on
the BioCreAtIvE 1 (Task 1B), depending on the
organism-specific sub-task. The highest recall was
found to be 84.1% for fly, 81.4% for mouse, and
84.8% for yeast genes.
We used a similar method, relying entirely on
manually defined rules for name variations, for the
BioCreAtIvE 2 GN task (Hakenberg et al, 2007).
We expanded the dictionary applying these rules to
every synonym (treating abbreviations and spelled-
out names slightly different). This yielded a recall of
92.7 and 87.5% on the training and test sets, respec-
tively (F1: 81.1%). In the aftermath of BioCreAtIvE
2, we now try to improve this high recall values fur-
ther, by automatically analyzing the whole dictio-
nary of gene names instead of manually composing
useful rules in a trial?and?error approach.
2 Methods
We first want to present the overall idea of learning
name composition rules, guided by specific exam-
ples. We first show how comparison of synonyms
known for one gene name yields insights into the
?meaning? of the gene, and produces rules for struc-
tural and lexical variations of its name(s). After-
wards, we explain how such rules can be exchanged
between different genes and add to the understand-
ing of each genes ?meaning.?
2.1 Techniques
We apply several techniques to the analysis of
names. To detect abbreviations by pairwise compar-
ison of synonyms, we use the algorithm proposed by
Schwartz and Hearst (2003) as the core component4.
We changed some of the details so that, for instance,
the first letter of the potential abbreviation has to
match the first letter of the proposed long form. We
perform the detection of abbreviations not only on
whole synonyms, but also on parts of each name
(like for ?TNF-alpha stimulated ABC protein?), so
that this property of Schwartz and Hearst?s algo-
rithm (S&H) is recovered. A trivial adaptation also
reveals which parts of an abbreviation (one or more
characters) map to which parts of the long form (one
token, one partial token.) As S&H allows for miss-
ing tokens in the long form, we can also add the pos-
sibility for (few) characters in the abbreviation not
being reflected in the long form.
To detect inexact matches (that is, slight vari-
ations in morphology or orthography), we use an
adaptation of the biological sequence alignment al-
gorithm (Needleman and Wunsch, 1970). Using the
computed alignment score, this yields an immediate
quantification of the similarity of two terms.
We compare the sequence of identified name parts
(parts of a name where a mapping from this part to
a part of the other synonym exists) in order to find
parts that can be skipped or exchanged with each
other. In addition, this yields insights into potential
permuations of all parts of a name, and shows where
certain parts typically do or do not occur.
2.2 Representation
Representation of information extracted by parsing
i) a synonym or ii) all synonyms of a gene becomes
a crucial basic part of our approach. Concepts have
to be found in a name, for instance,
? substance: ?serotonin?,
? type: ?receptor?,
? function: ?transcription factor?, or
? family-member: ?family-member number 6?.
Also, for these concepts, rules have to be learned
that match them against text (or vice versa): an ?R?
hints on a receptor, a ?6? at the end of a name (for in-
stance, a noun phrase) hints on a family-member or
4The original algorithm decides whether a given short form
can be explained by a given long form.
155
Type Example token Example name
Descriptor antigen, ligand, inhibitor P-30 antigen
Modifier factor, family member, type BRG1-associated factor
Specifier alpha, IX, A TNF alpha
Source d, HUMAN, p dHNF-4
Table 1: Types of tokens that frequently occur in gene names. Also see Hanisch et al (2005), though they introduce different
conventions.
type. We rely on semantic types, which are defined
using descriptions automatically identified from the
syntax (lists of variations), rather than pure syntac-
tical ones. This helps during classification of identi-
fied concepts: a syntactical concept would map ?s?
to ?serotonin?; but additionally, we need to express
that the given gene demands any arbitrary form of
a reference to a substance, which is serotonin, in its
name. Whether this occurs as the substance?s name
itself, an abbreviation, or synonym of the substance,
and at which position in a text5, then becomes less
important concerning the matching strategy. Table 1
sums up some of the known types of tokens and ex-
amples we want to distinguish. Note that the proper
type definition cannot automatically be assigned to
a concept. Concepts can be identified as belong-
ing to the same type only because they share certain
properties (can be skipped, is a numerical entity, is a
mandatory tokens that occurs at the end of a name.)
In Table 1, the descriptors ?antigen? and ?ligand?,
for instance, appear to be of the same type, but anal-
ysis will reveal that while the mention of ?antigen?
in a name is skipped frequently, ?ligand? represents
a mandatory concept in many synonyms.
For the remainder of this paper, we subsequently
break down a gene into the basic concepts described
in one or more of its name. First, a gene is iden-
tified by a set of names (synonyms). Second, each
name consists of multiple parts; proper separation
and identification is a crucial step. Third, each part
of a name then represents a certain concept that is
typical for the gene. A gene is defined by all identi-
fied concepts. While a gene name part stores the in-
formation on where and if it occurs in the sequence
of parts that ultimately form the (or rather a) name
of the gene, concepts store information about vari-
ations. Knowledge about name parts and concepts
is then transferred within each respective level only.
Each such potential transfer we call a composition
5Maybe within a somewhat confined neighborhood, for in-
stance, in the current paragraph or in the abstract of the text.
rule. An example, which we will also discuss in
the next section, is the gene FASLG. Is has multiple
synonyms, ?FASLG? being one of those. This name
can be separated into the parts ?FAS? and ?LG?. The
first part has the concept ?FAS?, which can appear
in the variations ?Fas?, ?fas?, or ?CD95?, as we will
see later; the second part has the concept ?LG?, a
possible variation is ?ligand?:
FASLG
FAS
FAS
Fas
CD95
fas
LG
L
ligand
LG
FAS  LG
(from top to bottom, levels depict the name, parts,
concepts, and variations of each concept.)
2.3 Analysis of intra-gene variations
In this section we explain how we discover concepts
and their appearances (exact tokens) within a set of
synonyms under the assumption that they all belong
to the same gene. Basically, this means that we
can allow for more mismatches, lacking parts, or the
like, as for comparing names of different genes.
Reconsider the example of the aforementioned
FASLG gene (356)6. We show the synonyms known
according to Entrez Gene in Table 2. Pairwise anal-
ysis of the synonyms provides insights as shown in
Table 3.
Recombining the extracted concepts and using
different variations for either, we can achieve some
new potential names, for instance, FasL (capitaliza-
tion) and CD95 ligand (replaced ?L? with identified
6In the following, we will always show each gene?s official
symbol first and then known synonyms. Numbers in brackets
refer to Entrez Gene IDs.
156
Apoptosis antigen ligand APTL apoptosis (APO-1) antigen ligand 1
Apoptosis (APO-1) ligand 1 APT1LG1 FAS antigen ligand
Apoptosis ligand CD178 Fas ligand (TNF superfamily, member 6)
CD95L FASL TNFL6 HUMAN
fas ligand FASLG TNFSF6
FAS ligand TNFL6 Tumor necrosis factor ligand superfamily member 6
Table 2: Synonyms of the FASLG gene that we use in our examples.
Synonyms Composition rule learned No.
FASL + FAS ligand L ? ligand 1
FASLG + FAS ligand LG ? ligand 2
FAS ligand + fas ligand FAS ? fas 3
FASL + CD95L FAS ? CD95 4
Tumor necrosis factor ligand superfamily member 6 + T ? Tumor, N ? necrosis 5a,b
TNFSF6 F ? factor, SF ? superfamily 5c,d
?member? before a number can be left out 5e
Apoptosis antigen ligand + Apoptosis ligand ?antigen? can be left out 6
FAS antigen ligand + FAS ligand ?antigen? can be left out 7
Apoptosis (APO-1) ligand 1 + Apoptosis ligand ?1? at end can be left out 8
TNFL6 + TNFL6 HUMAN ? HUMAN? can be added to a name 9
Fas ligand (TNF superfamily, member 6) + FAS ligand Fas ? FAS 10
Apoptosis ligand + APTL Apoptosis ? APT 11
Apoptosis (APO-1) ligand 1 + APT1LG1 ligand 1 ? LG1 12
Table 3: Pairwise analysis of some synonyms for FASLG and some insights gained. Conclusions shown in the bottom part can be
drawn using insights from the first part only. Rules like ?X can be left out? imply that the opposite can also happen, ?X can be
added?, and vice versa. Multiple detections of the same rule (no. 6& 7) increase its support, so the application of rules could be
weighted accordingly.
long form) for the FASLG gene. In cases where nei-
ther part of a name can be mapped onto parts of an-
other name, then no rule should be generated: com-
paring ?CD178 antigen? to ?CD95 ligand? should
not result in the variation ?CD178 ligand?. On the
other hand, after removal of ?antigen? (rules no. 6
& 7 in Table 3), ?CD178? represents a variation
of ?CD95 ligand? (which in this case was already
known from Entrez Gene.) In the following sections,
we explain the detection of different kinds of varia-
tions in more detail and show examples.
Abbreviations
Detecting abbreviations is a crucial initial step in our
analyses. Many variations are explained only across
abbreviations and their long forms. More important,
comparing abbreviations and long forms identifies
the parts of either name, which can then be com-
pared to parts of other names. Taking HIF1A (3091)
as an example, we find the synonyms ?HIF1 al-
pha?, ?HIF-1 alpha?, ?HIF-1alpha?, and ?Hypoxia-
inducible factor 1 alpha?. Schwartz and Hearst?s al-
gorithm easily reveals that ?1 alpha?, ?1alpha?, and
?1A? all map to each other; ?H? can be mapped to
?Hypoxia?, and so on. All in all, we learned that
?Hypoxia-inducible factor 1A? could be a potential
synonym for HIF1A.
We now look at the OR1G1 gene (8390). Con-
sider two of its synonyms, ?Olfactory receptor
1G1?, and ?olfactory receptor, family 1, subfamily
G, member 1?. Comparing the official symbol with
the first synonym, it becomes clear that ?OR? abbre-
viates ?Olfactory receptor? using S&H. Comparing
the synonyms, we find direct correspondences be-
tween both ?1?s and ?G?. AS we are still within one
gene, is is safe to assume that all in all, ?1G1? ab-
breviates ?family 1, subfamily G, member 1?. This
implies that concepts stating that we are within a
gene family (subfamily, members) can be missing
? whereas the respective values (?1?, ?G?, ?1?) are
mandatory.
Another abbreviation that commonly occurs in
gene names is the (abbreviated) mention of the or-
ganism (on the species level). For example, the
gene GIMAP4 (55303) has ?HIMAP4?, ?IMAP4?,
?IAN1?, ?hIAN1?, and ?human immune associated
nucleotide 1? as known synonyms. From synonyms
1 and 2 we can infer that an ?H? can be added to a
name (just like ? HUMAN?, see Table 3.) The same
is true for ?h? (synonyms 3 and 4.) Comparing syn-
onyms 1 or 4 to 5 leads to the conclusion that ?H?
157
and ?h? both abbreviate ?human.?
Lexical variations
In the set of synonyms for ADHFE1 (137872), we
find ?Fe-containing alcohol dehydrogenase 1? and
?alcohol dehydrogenase, iron containing, 1?. Split-
ting these synonyms into their respective parts and
then comparing both sets reveals that all but one part
each can be exactly mapped to a corresponding part
in the other synonym. From this almost exact match,
we can conclude that the parts ?Fe? and ?iron? are
synonyms of each other, potentially representing the
same concept, and easy to confirm for a human.
In the same manner, we will find that ?1B? can be
sometimes expressed as ?2?, and that ?adaptor? and
?Adapter? are orthographic variations of each other,
by looking at some synonyms for AP1S2 (8905):
- Adapter-related protein complex 1 sigma 1B subunit
- adaptor-related protein complex 1 sigma 2 subunit
- adaptor-related protein complex 1, sigma 1B subunit
To detect these two changes, we first need to map
parts to each other and then compare the names
based on the sequence of the parts.
Structural variations
Changes in the structure of a name can be deduced
when a safe mapping between most parts of a name
exist. For the HMMR gene (3161), we find two ev-
idences for such a variation, which also lead to the
conclusion that ?for? is an optional part. However,
in our system, we would retain information concern-
ing the positioning of ?for? (at least, tendencies like
?not the first? and ?not the last? part.)
- Receptor for hyaluronan-mediated motility
- hyaluronan-mediated motility receptor
- Hyaluronan mediated motility receptor
- intracellular hyaluronic acid binding protein
- hyaluronan-mediated motility receptor (RHAMM)
Analysis of this example also finds that ?hyaluro-
nan? can start with an upper case letter (and that
this occurs only when it is the first part of the
name. ?RHAMM? is the abbreviation for ?Recep-
tor for hyaluronan-mediated motility?, as revealed
by S&H. This leads to the next conclusion, that ab-
breviations can immediately follow a gene name.
Descriptive elements
Comparing the sequence of identified name parts
(parts of a name where a mapping from this part to
a part of the other synonym exists) yields dissimi-
larities that result either from a dropped/added name
part, or from a lexical variation. Consider the fol-
lowing example:
Fas antigen ligand
FASLG
}
}
?
Inexact matching immediately identifies the map-
ping from ?Fas? to ?FAS?; abbreviation detec-
tion and/or alignment yields ?ligand? as a long
form/variation of ?LG.? The sequence of name parts
if the same in both synonyms, with an added ?anti-
gen? in the first synonym. An extracted composition
rule could thus be that ?antigen? is of additional, de-
scriptive value only, and can be skipped. Knowing
this, the first synonym should also match the strings
?Fas ligand? and ?FAS ligand? (in fact, both should.)
Another example is ZG24P (259291) with its syn-
onym ?uncharacterized gastric protein ZG24P?. As
the official symbol clearly is an abbreviation (single
word, upper case letters, numbers) and matches the
last part of the synonym, we can assume that the first
part is either another synonym or a mere descriptive
element that explains the real gene name. Indeed,
patterns like ?uncharacterized ... protein? or ?hypo-
thetical protein? appear frequently as first parts of
gene names.
2.4 Analysis of inter-gene variations
As we have so far analyzed synonyms of one and the
same gene to extract knowledge on name composi-
tion, we can now apply this knowledge to the whole
set of gene names. This means, that we add knowl-
edge gained by analyzing one gene to other genes,
wherever applicable. Essentially, this comes down
to finding corresponding concepts in two or more
genes? names, and joining the information contained
in each concept. If within one gene name it became
clear that ?L? and ?ligand? represent the same con-
cept, and for another gene ?L? and ?LG? are vari-
ations of the same concept, then a combined con-
cept would have all three variations. The combined
concept then replaces the old concepts. We apply
the same idea to name parts, for which information
about their ordering etc. was extracted.
Inter-gene analysis also reveals the main distinc-
tive features of single gene names or groups of
names (for instance, families.) Some names dif-
fer only in Arabic/Roman numbers or in Greek let-
158
ters. Potentially they belong to the same group, as
different members or subtypes. Knowing how to
find one family member implicitly means knowing
how to find the others. Thus, it helps identify cru-
cial parts (for the family name) and distinctive parts
(for the exact member.) A matching strategy could
thus try to find the family name and then look for
any reference to a number. Knowledge about this
kind of relationships has to be encoded in the dictio-
nary, however. Spotting a gene family?s name with-
out any specific number could lead to the assign-
ment of the first member to the match, see Table 3,
rule no. 8 (or dismissing the name, depending on
user-specific demands). Such information can also
be used for disambiguating names. Analyzing the
names ?CD95 ligand? and ?CD95 receptor? of two
different genes, it can be concluded that ?CD95? by
itself contains not enough information to justify the
identification of either gene directly. Finding other
?receptor?s in the dictionary will also mark ?recep-
tor? as a concept crucial, but not sufficient, for iden-
tifying a gene?s name in text. For ?CD95?, on the
other hand, we have shown before that this token
might be exchanged with others.
Knowledge about (partial) abbreviations, like in
aforementioned ?HIF? = ?Hypoxia-inducible fac-
tor? and ?OR? = ?olfactory receptor?, can be trans-
ferred to all synonyms from other entries in the dic-
tionary that have the same long or short forms (but
possibly do not mention the respective other in any
synonym.) Similarly, presumed lexical variations
(?gastric? versus ?stomach?) that have been found
for one gene name (one concept) can be included
in all corresponding concepts to spread the informa-
tion that ?gastric? can appear as ?stomach? in text.
This is necessary to detect the name ?stomach alco-
hol dehydrogenase?, where the corresponding En-
trez Gene entry (ADH7, 131) does have the token
?stomach? in any of its synonyms.
Also, synonyms mentioning the species (like
?hIAN1? to depict human) are not contained for
every entry. Learning that ?h? can be added to a
gene name helps recognizing such a variation in text
for other names (the dictionary lacks the variation
?hFasL? of FASLG, which is sometimes used.)
3 Evaluation and Conclusions
We evaluated some ideas presented in this paper on
the BioCreAtIvE 2 (BC2) dataset for the gene nor-
malization task. For the purpose of this study, we
were interested in how our method would perform
concerning the recall, as compared to methods based
on hand-curated dictionary refinement. We con-
ducted the following experiment: the BC2 GN gold
standard consists of references to abstracts (PubMed
IDs), genes identified in each abstract (Entrez Gene
IDs) and text snippets that comprise each gene?s
name. For one abstract, there could be multiple, dif-
ferent snippets representing the same gene, ADH7
(131): ?stomach alcohol dehydrogenase?, ?class IV
alcohol dehydrogenase?, or ?sigma-ADH?, all in the
same abstract. For identification, it was sufficient in
BC2 to report the ID, regardless of number of occur-
rences or name variations.
As the method presented in this paper lacks a
matching strategy for spotting of names, we per-
formed our initial evaluation on the text snippets
only. Finding the right ID for each snippet thus
ultimately yielded the recall performance. In the
above example, we would try to identify ID 131
three times, counting every miss as a false nega-
tive. The methods presented above were able to
yield a recall of 73.1%. With the original BC2 eval-
uation scheme, we achieve a recall of 84.2%. Com-
pared to the highest result for our system with a
manually refined dictionary, this figure is more than
8% lower. This shows that still, many name varia-
tions are not recognized. Some errors could be ac-
counted to ranges or enumerations of gene names
(?SMADs 1, 5 and 8?), others to not far enough
reaching analyses: for detecting ?SMAD8?, we only
had the synonyms ?SMAD8A?, ?SMAD8B?, and
?SMAD9? for the correct gene in the dictionary (all
are synonyms for the same gene, according to Entrez
Gene). It should thus have been learned that the let-
ter ?A? can be left out (similar to ?1?, see rule no. 8
in Table 3.) Another undetected example is ?G(olf)
alpha? (GNAL, 2774). Rules to restrict either of the
synonyms
- Guanine nucleotide-binding protein G(olf), alpha subunit
- guanine nucleotide binding protein (G protein),
alpha stimulating activity polypeptide, olfactory type
- Adenylate cyclase-stimulating G alpha protein, olfactory type
- Guanine nucleotide-binding protein, alpha-subunit, olfactory
type
159
to this mentioning in text could have been deduced
as follows:
(1) Learn in another gene: description before
?protein? can be left out ? ?G(olf), alpha subunit?
could be a name of its own.
(2) Learn in this or another gene: ?alpha subunit?
can be expressed as ?alpha? (or ?subunit? skipped)
? ?G(olf) alpha? could be a name.
We see that most orthographical and morpholog-
ical variations (Greek symbols/English words, sin-
gular/plural forms, capitalization) can be integrated
quite easily in matching techniques. The general
knowledge about such variations is far-reaching and
can be applied to most domains. In contrast, struc-
tural and lexical variations are much harder to pin-
point and express in general ways; mostly, such pos-
sible variations are specific to a sub-domain and thus
present the main challenge for our method.
The ideas discussed in this paper originated from
work on the aforementioned BioCreAtIvE 2 task.
In that work, we used manually designed rules to
generate variations of gene names. Hanisch et
al. (Hanisch et al, 2005) and other groups propose
similar methods all based on human observation and
experience leading to refined dictionaries. As many
causes for name variations are easy to spot and ex-
press, we concluded it was entirely possible to gain
such insights in an automated manner. Left undeter-
mined is the potential impact of composition rules
on machine-learning techniques that use dictionar-
ies as input for features.
However, the methodology should work for other
task using the same or similar initial observations
(This remains to be proven.) We are currently ap-
plying the method to the analysis of Gene Ontology
terms (Ashburner et al, 2000). There, many terms
are mere descriptions of concepts than precise la-
bels, and there are less additional synonyms (with
structural and lexical variations.) A good starting
point for assessing possible patterns in name com-
position could also be the MeSH controlled vocabu-
lary. Entries in MeSH typically contain many struc-
tural and lexical variations, a deeper understanding
of which bears more insights than of orthographical
or morphological variations.
Readers of this manuscript should either gain
more insights into name compositions of gene
names ?in order to help refining dictionaries based
on manual rule sets?, or be convinced that the idea
of learning composition rules can be tackled in auto-
mated ways, promising examples of and basic tech-
niques for which we discussed herein.
Supplementary information
The extracted set of rules for name variations and an
extended dictionary for human genes, originating from
Entrez Gene, are available at http://www.informatik.hu-
berlin.de/?hakenber/publ/suppl/ . The dictionary can directly be
used for matching entries against text and covers 32,980 genes.
The main Java classes are available on request from the authors.
References
Michael Ashburner, Catherine A. Ball, Judith A. Blake, David
Botstein, Heather Butler, et al 2000. Gene Ontology: Tool
for the Unification of Biology. Nature Genetics, 25:25?29.
Aaron M. Cohen and William R. Hersh. 2005. A survey of
current work in biomedical text mining. Briefings in Bioin-
formatics, 6(1):57?71.
Jeremiah Crim, Ryan McDonald, and Fernando Pereira. Auto-
matically annotating documents with normalized gene lists.
2005. BMC Bioinformatics, 6(Suppl 1):S13.
Jo?rg Hakenberg, Steffen Bickel, Conrad Plake, Ulf Brefeld, Ha-
gen Zahn, Lukas Faulstich, Ulf Leser, and Tobias Scheffer.
2005. Systematic feature evaluation for gene name recogni-
tion. BMC Bioinformatics, 6(Suppl 1):S9.
Jo?rg Hakenberg, Loic Royer, Conrad Plake, Hendrik Strobelt.
2007. Me and my friends: gene mention normalization with
background knowledge. Proc 2nd BioCreative Challenge
Evaluation Workshop, April 23-25 2007, Madrid, Spain.
Daniel Hanisch, Katrin Fundel, Heinz-Theodor Mevissen, Ralf
Zimmer, Juliane Fluck ProMiner: rule-based protein and
gene entity recognition. 2005. BMC Bioinformatics,
6(Suppl 1):S14.
Ulf Leser and Jo?rg Hakenberg. 2005. What Makes a Gene
Name? Named Entity Recognition in the Biomedical Liter-
ature. Briefings in Bioinformatics, 6(4):357?369.
Donna Maglott, Jim Ostell, Kim D. Pruitt, and Tatiana
Tatusova. 2005. Entrez Gene: gene?centered information
at NCBI. Nucleic Acids Research, 33(Database Issue):D54?
D58.
Alexander Morgan and Lynette Hirschman. 2007. Overview of
BioCreative II Gene Normalization. In: Proc 2nd BioCre-
ative Challenge Evaluation Workshop, April 23-25 2007,
Madrid, Spain.
Saul B. Needleman and Christian D. Wunsch. 1970. A general
method applicable to the search for similarities in the amino
acid sequence of two proteins. J. Mol. Biol., 48(3):443?53.
Ariel S. Schwartz and Marti A. Hearst. 2003. A simple algo-
rithm for identifying abbreviation definitions in biomedical
text. Proc Pac Sym Bio, 451?462.
Hua Xu, Jung-Wei Fan, George Hripcsak, Eneida A. Mendonc?a,
Marianthi Markatou, and Carol Friedman. 2007. Gene sym-
bol disambiguation using knowledge-based profiles. Bioin-
formatics, 23(8):1015?1022.
160
