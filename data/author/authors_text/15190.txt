Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 121?126,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Building trainable taggers in a web-based, UIMA-supported NLP
workbench
Rafal Rak, BalaKrishna Kolluru and Sophia Ananiadou
National Centre for Text Mining
School of Computer Science, University of Manchester
Manchester Interdisciplinary Biocentre
131 Princess St, M1 7DN, Manchester, UK
{rafal.rak,balakrishna.kolluru,sophia.ananiadou}@manchester.ac.uk
Abstract
Argo is a web-based NLP and text mining
workbench with a convenient graphical user
interface for designing and executing process-
ing workflows of various complexity. The
workbench is intended for specialists and non-
technical audiences alike, and provides the
ever expanding library of analytics compliant
with the Unstructured Information Manage-
ment Architecture, a widely adopted interop-
erability framework. We explore the flexibil-
ity of this framework by demonstrating work-
flows involving three processing components
capable of performing self-contained machine
learning-based tagging. The three components
are responsible for the three distinct tasks of 1)
generating observations or features, 2) train-
ing a statistical model based on the generated
features, and 3) tagging unlabelled data with
the model. The learning and tagging compo-
nents are based on an implementation of con-
ditional random fields (CRF); whereas the fea-
ture generation component is an analytic ca-
pable of extending basic token information to
a comprehensive set of features. Users de-
fine the features of their choice directly from
Argo?s graphical interface, without resorting
to programming (a commonly used approach
to feature engineering). The experimental re-
sults performed on two tagging tasks, chunk-
ing and named entity recognition, showed that
a tagger with a generic set of features built
in Argo is capable of competing with task-
specific solutions.
1 Introduction
The applications of automatic recognition of cate-
gories, or tagging, in natural language processing
(NLP), range from part of speech tagging to chunk-
ing to named entity recognition and complex scien-
tific discourse analyses. Currently, there is a variety
of tools capable of performing these tasks. A com-
monly used approach involves the use of machine
learning to first build a statistical model based on a
manually or semi-automatically tagged sample data
and then to tag new data using this model. Since
the machine learning algorithms for building mod-
els are well established, the challenge shifted to fea-
ture engineering, i.e., developing task-specific fea-
tures that form the basis of these statistical models.
This task is usually accomplished programmatically
which pose an obstacle to a non-technically inclined
audience. We alleviate this problem by demonstrat-
ing Argo1, a web-based platform that allows the user
to build NLP and other text analysis workflows via
a graphical user interface (GUI) available in a web
browser. The system is equipped with an ever grow-
ing library of text processing components ranging
from low-level syntactic analysers to semantic an-
notators. It also allows for including user-interactive
components, such as an annotation editor, into oth-
erwise fully automatic workflows. The interoper-
ability of processing components is ensured in Argo
by adopting Unstructured Information Management
Architecture (UIMA) (Ferrucci and Lally, 2004) as
the system?s framework. In this work we explore the
capabilities of this framework to support machine
1http://nactem.ac.uk/Argo
121
learning components for tagging textual content.
In the following section we present related work.
Section 3 provides background information on Argo
and its relationship to UIMA. The details of the three
machine learning components are discussed in Sec-
tion 4. Section 5 provides evaluation, whereas Sec-
tion 6 concludes the paper.
2 Related work
Language processing tools with machine learning
capabilities for tagging textual content have been
distributed by various groups in form of either stan-
dalone applications or application programming in-
terfaces (API). Packages such as Lingpipe2, Mal-
let3, Stanford NLP tools4 and OpenNLP5 have been
extensively used by the NLP and text mining com-
munities (Kolluru et al, 2011; Corbett and Murray-
Rust, 2006). However, such tools inherently impose
inconveniences on users, such as a lack of GUI, of-
ten arduous manual installation procedures, profi-
ciency in programming or familiarity with the de-
tails of machine learning algorithms.
These limitations are overcome by GUI-equipped,
workflow-supporting platforms that often directly
use the solutions provided by the former tools. The
notable examples of such platforms designed specif-
ically for NLP and text mining tasks are GATE
(Cunningham et al, 2002), a suite of text process-
ing and annotation tools, and U-Compare (Kano et
al., 2010), a standalone application supporting the
UIMA framework that formed the inspiration for
Argo.
Although the GUI platforms provide machine
learning solutions, these are usually limited to us-
ing pre-trained models and providing a rich set of
features for training requires resorting to program-
ming. Argo, on the other hand, allows the users to
train their own models with either a generic set of
features or customisable features without having to
write a single line of code. This capability is pro-
vided in Argo entirely through its GUI.
2http://alias-i.com/lingpipe
3http://mallet.cs.umass.edu
4http://nlp.stanford.edu/software/index.shtml
5http://opennlp.apache.org
Figure 1: Screen capture of Argo?s web-based inter-
face.
3 Argo and UIMA
Argo?s main user interface consists of three panels
as shown in Figure 1. The left-hand panel includes
user-owned or shared storable objects; the middle
panel is a drawing space for constructing workflows
and the right-hand panel displays context-dependent
information. The storable objects are categorised
into workflows, represented as block diagrams of
interconnected processing components, documents
that represent the user?s space intended for upload-
ing resources and saving processing results, and ex-
ecutions that provide past and live workflow exe-
cution details and access points to user-interactive
components should such be present in a workflow.
Component interoperability in Argo is ensured by
UIMA which defines common structures and inter-
faces. A typical UIMA processing pipeline consists
of a collection reader, a set of analysis engines and a
consumer. The role of a collection reader is to fetch
a resource (e.g., a text document) and deposit it in
a common annotation structure, or CAS, as the sub-
ject of annotation. Analysis engines then process the
subject of annotation stored in the CAS and populate
the CAS with their respective annotations. The con-
sumer?s role is to transform some or all of the an-
notations and/or the subject of annotation from the
CAS and serialise it into some storable format.
Readers, analysers and consumers are represented
graphically in Argo as blocks with incoming only,
incoming and outgoing, and outgoing only ports, re-
spectively, visible in the middle of Figure 1.
122
(a) Training (b) Tagging
Figure 2: Two generic workflows demonstrating
the use of the Feature Generator component for (a)
training and (b) tagging.
4 Machine learning components in Argo
In order to ensure flexibility in building workflows,
we split the machine learning capability into three
distinct processing components, namely feature gen-
erator, model trainer and tagger. The trainer and
the tagger are intrinsic machine learning compo-
nents, whereas the feature generator is a convenient
and customisable processing component capable of
building a feature space for a user-defined domain.
From UIMA?s perspective, the feature generator
and the tagger are both analysis engines whose pur-
pose is to analyse the incoming CASes and en-
rich them with additional annotations; whereas the
trainer is a consumer that transforms the information
stored in CASes into a statistical model.
A typical use of the three components is shown
in Figure 2. The three components are repre-
sented as the Feature Generator, CRF++ Trainer and
CRF++ Tagger blocks. Figure 2a shows a pro-
cess of building a statistical model supported by
a document reader, common, well-established pre-
processing components (in this case, to establish
boundaries of sentences and tokens), and the previ-
ously mentioned editor for manually creating anno-
tations6. The manual annotations serve to generate
tags/labels which are used in the training process to-
gether with the features produced by Feature Gener-
ator. The trained model is then used in the workflow
shown in Figure 2b to tag new resources. Although
the tagging workflow automatically recognises the
labels of interest (based on the model supplied in
CRF++ Tagger), in practice, the labels need further
correction, hence the use of Annotation Editor after
the tagger.
4.1 Training and tagging
At present, our implementation of the training and
tagging components is based on the conditional ran-
dom fields (CRF) (Lafferty et al, 2001). Our choice
is dictated by the fact that CRF models are currently
one of the best models for tagging and efficient algo-
rithms to compute marginal probabilities and n-best
sequences are freely available.
We used the CRF++ implementation7 and
wrapped it into two UIMA-compatible components,
CRF++ Trainer and CRF++ Tagger. The trainer
deals with the optimisation of feature parameters,
whereas word observations are produced by Feature
Generator, as described in the following section.
4.2 From annotations to features
The Feature Generator component is an intermedi-
ary between annotations stored in CASes and the
training component. This component is customis-
able via the component?s settings panel, parts of
which are shown in Figure 3. The panel allows the
user to 1) identify the stream of tokens8 (Figure 3a),
2) identify the stream of token sequences (usually
6The preprocessing and manual annotation components
could be replaced with CAS Reader, a component capable of
supplying the workflow with a previously annotated set of doc-
uments.
7http://code.google.com/p/crfpp/
8The definition of token depends on the selected UIMA an-
notation type. It may range from a simple span of text to a
complex lexical or semantic structure.
123
(a) Selecting a token annotation type
(b) Defining features
Figure 3: Feature Generator settings panel allows
the user to (a) select labels for machine learning and
(b) define features.
sentences), and 3) define features or token observa-
tions (Figure 3b).
Each feature definition consists of a name, a token
field, an optional list of token field transformations,
and an optional set of context windows. The name
is only for the user?s convenience of identifying in-
dividual feature definitions. The token field is the
primary subject of transformations (if any) and it is
one of the data fields of the selected token annota-
tion type. For instance, the token annotation type
may define data fields such as part of speech, chunk,
or lemma. By default, the system selects ?covered
text?, i.e., the span of text covered by an annotation,
since this data field is available for any annotation.
If no transformation is declared, the string rep-
Figure 4: UML diagram of transformation types
resentation of the token field?s value ultimately be-
comes the value of the generated feature. If the
user declares one or more transformations then these
are applied on the token field?s value in sequence,
i.e., an outcome of the preceding transformation be-
comes an input of the following one. Figure 4 shows
the various transformations currently available in the
system.
Context windows allow for enriching the current
token?s feature set by introducing observations from
surrounding tokens as n-grams. For example, the
selected feature definition in Figure 3b, ?surface has
symbols?, declares the covered text as the feature?s
basis and defines two transformations and two con-
text windows. The two transformations will first
transform the covered text to a collapsed shape (e.g.,
?NF-kappa? will become ?A#a?) and then produce
?Y? or ?N? depending on whether the collapsed
shape matches the simple regular expression ?#?
(e.g., ?A#a? will become ?Y?). The two context win-
dows define six unigrams and four bigrams, which
will ultimately result in this single feature defini-
tion?s producing ten observations for training.
5 Evaluation
We show the performance of taggers trained with
two distinct sets of features, basic and extended.
The basic set of features uses token fields such as
the covered text and the part of speech without any
transformations or context n-grams. The extended
set makes the full use of Feature Generator?s settings
and enriches the basic set with various transforma-
tions and context n-grams. The transformations in-
124
Dataset Setup P R F
CoNLL Best 94.29 94.01 94.13
L2 IOBES 92.20 93.43 92.81
L2 IOB 92.14 93.27 92.70
L1 IOBES 91.95 93.17 92.55
L1 IOB 91.83 93.11 92.46
Baseline 72.58 82.14 77.07
BioNLP/ Best 76.00 69.40 72.6
NLPBA L1 IOBES 66.22 65.06 65.63
L2 IOB 66.06 64.87 65.46
L1 IOB 66.05 64.61 65.32
L2 IOBES 65.77 64.79 65.28
Baseline 52.60 43.60 47.70
Table 1: Performance of various setups (L1 vs L2,
and IOB vs IOBES) on the chunking and NER tasks.
The setups are ordered by F-score.
Dataset Setup P R F
CoNLL Basic 73.80 84.50 78.78
Extended 92.20 93.43 92.81
BioNLP/ Basic 37.06 48.13 41.88
NLPBA Extended 66.22 65.06 65.63
Table 2: Comparison of setups with basic and ex-
tended features for the chunking and NER tasks.
clude surface shape, length, prefixes, suffixes, and
the presence of various combinations of letters, dig-
its and symbols. The context n-grams include uni-
grams for all feature definitions and bigrams for se-
lected ones. Figure 3b shows a sample of the actual
extended set.
We use two datasets, one prepared for the CoNLL
2000 shared task (Tjong et al, 2000) and another
prepared for the BioNLP/NLPBA 2004 shared task
(Kim et al, 2004). They represent two different
tagging tasks, chunking and named entity recog-
nition, respectively. The CoNLL 2000 chunking
dataset involves 10 labels and comes pre-tokenised
with 211,727 tokens in the training set and 47,377
tokens in the test set. The dataset alo provides part-
of-speech tags for each token. The BioNLP/NLPBA
2004 named entity recognition dataset involves five
biology-related labels and consists of 472,006 and
96,780 tokens in the training and testing sets, re-
spectively. Contrary to the former dataset, there is
no other information supporting the tokens in the
BioNLP/NLPBA dataset. To compensate for it we
automatically generated part of speech and chunk la-
bels for each token.
The chosen datasets/tasks are by no means an
exhaustive set of representative comparative-setup
datasets available. Our goal is not to claim the su-
periority of our approach over the solutions reported
in the respective shared tasks. Instead, we aim to
show that our generic setup is comparable to those
task-tuned solutions.
We further explore the options of both Feature
Generator and CRF++ Trainer by manipulating la-
belling formats (IOB vs IOBES (Kudo and Mat-
sumoto, 2001)) for the former and parameter esti-
mation algorithms (L2- vs L1-norm regularisation)
for the latter. Ultimately, there are 32 setups as the
result of the combinations of the two feature sets, the
two datasets, the two labelling formats and the two
estimation algorithms.
5.1 Results
Table 1 shows the precision, recall and f-scores of
our extended-feature setups against each other as
well as with reference to the best and baseline solu-
tions as reported in the respective shared tasks. The
gap to the best performing solution for the chunking
task is about 1.3% points in F-score, ahead of the
baseline by 15.7% points. Respectively for the NER
task, our best setup stands behind the best reported
solution by about 7% points, ahead of the baseline
by about 18% points. In both instances our solution
would be placed in the middle of the reported rank-
ings, which is a promising result, especially that our
setups are based solely on the tokens? surface form,
part of speech, and (in the case of the NER task)
chunk. In contrast, the best solutions for the NER
task involve the use of dictionaries and advanced
analyses such as acronym resolution.
The tested combinations of the labelling formats
and parameter estimation algorithms showed to be
inconclusive, with a difference between the best and
worst setups of only 0.35% points for both tasks.
The advantage of using the extended set of fea-
tures over the basic set is clearly illustrated in Table
2. The performance of the basic set on the chunking
dataset is only at the level of the baseline, whereas
for the NER task it falls nearly 6% points behind the
125
Dataset Setup L2 L1
CoNLL Extended IOB 555 187
Basic IOB 134 70
Extended IOBES 528 209
Basic IOBES 139 72
BioNLP/ Extended IOB 865 179
NLPBA Basic IOB 226 72
Extended IOBES 860 201
Basic IOBES 217 79
Table 3: Number of iterations needed for the optimi-
sation algorithm to converge.
baseline (which comes as no surprise given that the
baseline system is a string match of entities found in
the training set).
Table 3 shows the number of iterations9 needed
for the optimisation algorithm of the trainer to con-
verge. The advantage of the L1 regularisation is
apparent with nearly two to five times less itera-
tions needed when compared to the L2 regularisa-
tion. Given the close F-scores achieved by the two
family of setups, the L1 regularisation becomes a
clear winner in our experimentation setup.
6 Conclusions
Argo?s strength is manifested by its online avail-
ability, an intuitive graphical user interface available
from a web browser, convenience in building even
most complex text processing workflows, and the
availability of trainable machine learning compo-
nents. The Feature Generator component, customis-
able entirely through a GUI, provides the flexibility
needed to extend the basic set of features without
resorting to programming. The experiment results
showed that an extended, yet generic, set of features
can be taken to competitive levels in terms of effec-
tiveness.
7 Acknowledgements
This work was partially supported by Biotechnol-
ogy and Biological Sciences Research Council (BB-
9We do not report detailed CPU times due to experimenting
on resource-shared machines. Such a setup makes direct side-
by-side comparisons largely skewed. As a reference we note
that the workflows completed in 15 minutes to about 11 hours
depending on a feature space size and machine load.
SRC BB/G53025X/1 From Text to Pathways) and
Korea Institute of Science and Technology Informa-
tion (KISTI Text Mining and Pathways).
References
P. Corbett and P. Murray-Rust. 2006. High-throughput
identification of chemistry in life science texts. Comp
Life, pages 107?118. LNBI 4216.
H. Cunningham, D. Maynard, K. Bontcheva, and
V. Tablan. 2002. GATE: A framework and graphi-
cal development environment for robust NLP tools and
applications. In Proc. of the 40th Anniversary Meeting
of the Association for Computational Linguistics.
D. Ferrucci and A. Lally. 2004. UIMA: An Architec-
tural Approach to Unstructured Information Process-
ing in the Corporate Research Environment. Natural
Language Engineering, 10(3-4):327?348.
Y. Kano, R. Dorado, L. McCrochon, S. Ananiadou, and
J. Tsujii. 2010. U-Compare: An integrated language
resource evaluation platform including a comprehen-
sive UIMA resource library. In Proc. of the Seventh
International Conference on Language Resources and
Evaluation (LREC 2010), pages 428?434.
J.-D. Kim, T. Ohta, Y. Tsuruoka, Y. Tateisi, and N. Col-
lier. 2004. Introduction to the bio-entity recogni-
tion task at jnlpba. In Proc. of the International
Joint Workshop on Natural Language Processing in
Biomedicine and its Applications, JNLPBA ?04, pages
70?75, Geneva, Switzerland. Association for Compu-
tational Linguistics.
B. Kolluru, S. Nakjang, R. P. Hirt, A. Wipat, and S. Ana-
niadou. 2011. Automatic extraction of microorgan-
isms and their habitats from free text using text min-
ing workflows. Journal of Integrative Bioinformatics,
8(2):184.
T. Kudo and Y. Matsumoto. 2001. Chunking with sup-
port vector machines. In Proc. of the second meeting
of the North American Chapter of the Association for
Computational Linguistics on Language technologies,
NAACL ?01, pages 1?8, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
J. Lafferty, A. Mccallum, and F. Pereira. 2001. Condi-
tional Random Fields: Probabilistic Models for Seg-
menting and Labeling Sequence Data. In Proc. 18th
International Conf. on Machine Learning, pages 282?
289. Morgan Kaufmann, San Francisco, CA.
K. S. Tjong, F. Erik, and S. Buchholz. 2000. Introduc-
tion to the CoNLL-2000 shared task: chunking. In
Proc. of the 2nd workshop on Learning language in
logic and the 4th Conference on Computational nat-
ural language learning, pages 127?132, Morristown,
NJ, USA. Association for Computational Linguistics.
126
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 115?120,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Development and Analysis of NLP Pipelines in Argo
Rafal Rak, Andrew Rowley, Jacob Carter, and Sophia Ananiadou
National Centre for Text Mining
School of Computer Science, University of Manchester
Manchester Institute of Biotechnology
131 Princess St, M1 7DN, Manchester, UK
{rafal.rak,andrew.rowley,jacob.carter,sophia.ananiadou}@manchester.ac.uk
Abstract
Developing sophisticated NLP pipelines
composed of multiple processing tools
and components available through differ-
ent providers may pose a challenge in
terms of their interoperability. The Un-
structured Information Management Ar-
chitecture (UIMA) is an industry stan-
dard whose aim is to ensure such in-
teroperability by defining common data
structures and interfaces. The architec-
ture has been gaining attention from in-
dustry and academia alike, resulting in a
large volume of UIMA-compliant process-
ing components. In this paper, we demon-
strate Argo, a Web-based workbench for
the development and processing of NLP
pipelines/workflows. The workbench is
based upon UIMA, and thus has the poten-
tial of using many of the existing UIMA
resources. We present features, and show
examples, of facilitating the distributed de-
velopment of components and the analysis
of processing results. The latter includes
annotation visualisers and editors, as well
as serialisation to RDF format, which en-
ables flexible querying in addition to data
manipulation thanks to the semantic query
language SPARQL. The distributed devel-
opment feature allows users to seamlessly
connect their tools to workflows running
in Argo, and thus take advantage of both
the available library of components (with-
out the need of installing them locally) and
the analytical tools.
1 Introduction
Building NLP applications usually involves a se-
ries of individual tasks. For instance, the ex-
traction of relationships between named entities
in text is preceded by text segmentation, part-of-
speech recognition, the recognition of named enti-
ties, and dependency parsing. Currently, the avail-
ability of such atomic processing components is
no longer an issue; the problem lies in ensur-
ing their compatibility, as combining components
coming from multiple repositories, written in dif-
ferent programming languages, requiring different
installation procedures, and having incompatible
input/output formats can be a source of frustration
and poses a real challenge for developers.
Unstructured Information Management Archi-
tecture (UIMA) (Ferrucci and Lally, 2004) is a
framework that tackles the problem of interoper-
ability of processing components. Originally de-
veloped by IBM, it is currently an Apache Soft-
ware Foundation open-source project1 that is also
registered at the Organization for the Advance-
ment of Structured Information Standards (OA-
SIS)2. UIMA has been gaining much interest from
industry and academia alike for the past decade.
Notable repositories of UIMA-compliant tools
include U-Compare component library3, DKPro
(Gurevych et al, 2007), cTAKES (Savova et
al., 2010), BioNLP-UIMA Component Reposi-
tory (Baumgartner et al, 2008), and JULIE Lab?s
UIMA Component Repository (JCoRe) (Hahn et
al., 2008).
In this work we demonstrate Argo4, a Web-
based (remotely-accessed) workbench for collabo-
rative development of text-processing workflows.
We focus primarily on the process of development
and analysis of both individual processing com-
ponents and workflows composed of such compo-
nents.
The next section demonstrates general features
of Argo and lays out several technical details about
1http://uima.apache.org
2http://www.oasis-open.org/committees/uima
3http://nactem.ac.uk/ucompare/
4http://argo.nactem.ac.uk
115
UIMA that will ease the understanding of the re-
maining sections. Sections 3?5 discuss selected
features that are useful in the development and
analysis of components and workflows. Section 6
mentions related efforts, and Section 7 concludes
the paper.
2 Overview of Argo
Argo comes equipped with an ever-growing li-
brary of atomic processing components that can be
put together by users to form meaningful pipelines
or workflows. The processing components range
from simple data serialisers to complex text an-
alytics and include text segmentation, part-of-
speech tagging, parsing, named entity recognition,
and discourse analysis.
Users interact with the workbench through a
graphical user interface (GUI) that is accessible
entirely through a Web browser. Figure 1 shows
two views of the interface: the main, resource
management window (Figure 1(a)) and the work-
flow diagramming window (Figure 1(b)). The
main window provides access to emphdocuments,
workflows, and processes separated in easily ac-
cessible panels.
The Documents panel lists primarily user-
owned files that are uploaded (through the GUI)
by users into their respective personal spaces on
the remote host. Documents may also be gener-
ated as a result of executing workflows (e.g., XML
files containing annotations), in which case they
are available for users to download.
The Workflows panel lists users? workflows,
i.e., the user-defined arrangements of processing
components together with their settings. Users
compose workflows through a flexible, graphi-
cal diagramming editor by connecting the com-
ponents (represented as blocks) with lines signi-
fying the flow of data between components (see
Figure 1(b)). The most common arrangement is to
form a pipeline, i.e., each participating component
has at most one incoming and at most one out-
going connection; however, the system also sup-
ports multiple branching and merging points in the
workflow. An example is shown in Figure 2 dis-
cussed farther in text. For ease of use, components
are categorized into readers, analytics, and con-
sumers, indicating what role they are set to play in
a workflow. Readers are responsible for delivering
data for processing and have only an outgoing port
(represented as a green triangle). The role of an-
(a) Workflow management view
(b) Worflow diagram editor view
Figure 1: Screenshots of Argo Web browser con-
tent.
alytics is to modify incoming data structures and
pass them onto following components in a work-
flow, and thus they have both incoming and outgo-
ing ports. Finally, the consumers are responsible
for serialising or visualising (selected or all) anno-
tations in the data structures without modification,
and so they have only an incoming port.
The Processes panel lists resources that are cre-
ated automatically when workflows are submit-
ted for execution by users. Users may follow the
progress of the executing workflows (processes) as
well as manage the execution from this panel. The
processing of workflows is carried out on remote
servers, and thus frees users from using their own
processing resources.
2.1 Argo and UIMA
Argo supports and is based upon UIMA and thus
can run any UIMA-compliant processing compo-
nent. Each such component defines or imports
type systems and modifies common annotation
structures (CAS). A type system is the represen-
116
tation of a data model that is shared between com-
ponents, whereas a CAS is the container of data
whose structure complies with the type system. A
CAS stores feature structures, e.g., a token with
its text boundaries and a part-of-speech tag. Fea-
ture structures may, and often do, refer to a sub-
ject of annotation (Sofa), a structure that (in text-
processing applications) stores the text. UIMA
comes with built-in data types including primitive
types (boolean, integer, string, etc.), arrays, lists,
as well as several complex types, e.g., Annotation
that holds a reference to a Sofa the annotation is
asserted about, and two features, begin and end,
for marking boundaries of a span of text. A devel-
oper is free to extend any of the complex types.
2.2 Architecture
Although the Apache UIMA project provides an
implementation of the UIMA framework, Argo
incorporates home-grown solutions, especially in
terms of the management of workflow processing.
This includes features such as workflow branching
and merging points, user-interactive components
(see Section 4), as well as distributed processing.
The primary processing is carried out on a
multi-core server. Additionally, in order to in-
crease computing throughput, we have incorpo-
rated cloud computing capabilities into Argo,
which is designed to work with various cloud
computing providers. As a proof of concept,
the current implementation uses HTCondor, an
open-source, high-throughput computing software
framework. Currently, Argo is capable of switch-
ing the processing of workflows to a local cluster
of over 3,000 processor cores. Further extensions
to use the Microsoft Azure5 and Amazon EC26
cloud platforms are also planned.
The Argo platform is available entirely us-
ing RESTful Web services (Fielding and Taylor,
2002), and therefore it is possible to gain access
to all or selected features of Argo by implement-
ing a compliant client. In fact, the ?native? Web
interface shown in Figure 1 is an example of such
a client.
3 Distributed Development
Argo includes a Generic Listener component that
permits execution of a UIMA component that is
running externally of the Argo system. It is pri-
5http://www.windowsazure.com
6http://aws.amazon.com/ec2
marily intended to be used during the develop-
ment of processing components, as it allows a de-
veloper to rapidly make any necessary changes,
whilst continuing to make use of the existing com-
ponents available within Argo, which may other-
wise be unavailable if developing on the devel-
oper?s local system. Any component that a user
wishes to deploy on the Argo system has to un-
dergo a verification process, which could lead to
a slower development lifecycle without the avail-
ability of this component.
Generic Listener operates in a reverse manner
to a traditional Web service; rather than Argo con-
necting to the developer?s component, the compo-
nent connects to Argo. This behaviour was de-
liberately chosen to avoid network-related issues,
such as firewall port blocking, which could be-
come a source of frustration to developers.
When a workflow, containing a Generic Lis-
tener, is executed within Argo, it will continue
as normal until the point at which the Generic
Listener receives its first CAS object. Argo will
prompt the user with a unique URL, which must
be supplied to the client component run by the
user, allowing it to connect to the Argo workflow
and continue its execution.
A skeleton Java project has been provided to as-
sist in the production of such components. It con-
tains a Maven structure, Eclipse IDE project files,
and required libraries, in addition to a number of
shell scripts to simplify the running of the compo-
nent. The project provides both a command-line
interface (CLI) and GUI runner applications that
take, as arguments, the name of the class of the lo-
cally developed component and the URL provided
by Argo, upon each run of a workflow containing
the remote component.
An example of a workflow with a Generic Lis-
tener is shown in Figure 2. The workflow is de-
signed for the analysis and evaluation of a solu-
tion (in this case, the automatic extraction of bio-
logical events) that is being developed locally by
the user. The reader (BioNLP ST Data Reader)
provides text documents together with gold (i.e.,
manually created) event annotations prepared for
the BioNLP Shared Task7. The annotations are
selectively removed with the Annotation Remover
and the remaining data is sent onto the Generic
Listener component, and consequently, onto the
developer?s machine. The developer?s task is to
7http://2013.bionlp-st.org/
117
Figure 2: Example of a workflow for development,
analysis, and evaluation of a user-developed solu-
tion for the BioNLP Shared Task.
connect to Argo, retrieve CASes from the run-
ning workflow, and for each CAS recreate the re-
moved annotations as faithfully as possible. The
developer can then track the performance of their
solution by observing standard information ex-
traction measures (precision, recall, etc.) com-
puted by the Reference Evaluator component that
compares the original, gold annotations (coming
from the reader) against the developer?s annota-
tions (coming from the Generic Listener), and
saves these measures for each document/CAS into
a tabular-format file. Moreover, the differences
can be tracked visually though the interactive Brat
BioNLP ST Comparator component, discussed in
the next section.
4 Annotation Analysis and Manipulation
Traditionally, NLP pipelines (including existing
UIMA-supporting platforms), once set up, are
executed without human involvement. One of
the novelties in Argo is an introduction of user-
interactive components, a special type of analytic
that, if present in a workflow, cause the execu-
tion of the workflow to pause. Argo resumes the
execution only after receiving input from a user.
This feature allows for manual intervention in the
otherwise automatic processing by, e.g., manipu-
lating automatically created annotations. Exam-
ples of user-interactive components include Anno-
tation Editor and Brat BioNLP ST Comparator.
The Brat BioNLP ST Comparator component
Figure 3: Example of an annotated fragment of
a document visualised with the Brat BioNLP ST
Comparator component. The component high-
lights (in red and green) differences between two
sources of annotations.
Figure 4: Example of manual annotation with the
user-interactive Annotation Editor component.
expects two incoming connections from compo-
nents processing the same subject of annotation.
As a result, using brat visualisation (Stenetorp et
al., 2012), it will show annotation structures by
laying them out above text and mark differences
between the two inputs by colour-coding missing
or additional annotations in each input. A sam-
ple of visualisation coming from the workflow in
Figure 2 is shown in Figure 3. Since in this par-
ticular workflow the Brat BioNLP ST Comparator
receives gold annotations (from the BioNLP ST
Data Reader) as one of its inputs, the highlighted
differences are, in fact, false positives and false
negatives.
Annotation Editor is another example of a user-
interactive component that allows the user to add,
delete or modify annotations. Figure 4 shows the
editor in action. The user has an option to cre-
ate a span-of-text annotation by selecting a text
fragment and assigning an annotation type. More
complex annotation types, such as tokens with
part-of-speech tags or annotations that do not re-
fer to the text (meta-annotations) can be created
or modified using an expandable tree-like struc-
ture (shown on the right-hand side of the figure),
which makes it possible to create any annotation
118
(a) Select query
neAText neACat neBText neBCat count
Ki-67 Protein p53 Protein 85
DC CellType p53 Protein 61
DC CellType KCOT Protein 47
(b) Results (fragment)
(c) Insert query
Figure 5: Example of (a) a SPARQL query that returns biological interactions; (b) a fragment of retrieved
results; and (c) a SPARQL query that creates new UIMA feature structures. Namespaces and data types
are omitted for brevity.
structure permissible by a given type system.
5 Querying Serialised Data
Argo comes with several (de)serialisation com-
ponents for reading and storing collections of
data, such as a generic reader of text (Document
Reader) or readers and writers of CASes in XMI
format (CAS Reader and CAS Writer). One of
the more useful in terms of annotation analysis
is, however, the RDF Writer component as well
as its counterpart, RDF Reader. RDF Writer se-
rialises data into RDF files and supports several
RDF formats such as RDF/XML, Turtle, and N-
Triple. A resulting RDF graph consists of both the
data model (type system) and the data itself (CAS)
and thus constitutes a self-contained knowledge
base. RDF Writer has an option to create a graph
for each CAS or a single graph for an entire collec-
tion. Such a knowledge base can be queried with
languages such as SPARQL8, an official W3C
Recommendation.
Figure 5 shows an example of a SPARQL query
that is performed on the output of an RDF Writer
in the workflow shown in Figure 1(b). This work-
flow results in several types of annotations in-
cluding the boundaries of sentences, tokens with
part-of-speech tags and lemmas, chunks, as well
as biological entities, such as DNA, RNA, cell
line and cell type. The SPARQL query is meant
to retrieve pairs of seemingly interacting biolog-
ical entities ranked according to their occurrence
in the entire collection. The interaction here is
(na??vely) defined as co-occurrence of two entities
in the same sentence. The query includes pat-
terns for retrieving the boundaries of sentences
(syn:Sentence) and two biological entities
(sem:NamedEntity) and then filters out the
crossproduct of those by ensuring that the two en-
8http://www.w3.org/TR/2013/REC-sparql11-overview-
20130321/
119
tities are enclosed in a sentence. As a result, the
query returns a list of biological entity pairs ac-
companied by their categories and the number of
appearances, as shown in Figure 5(b). Note that
the query itself does not list the four biological cat-
egories; instead, it requests their common seman-
tic ancestor sem:NamedEntity. This is one of
the advantages of using semantically-enabled lan-
guages, such as SPARQL.
SPARQL also supports graph manipulation.
Suppose a user is interested in placing the re-
trieved biological entity interactions from our run-
ning example into the UIMA structure Relation-
ship that simply defines a pair of references to
other structures of any type. This can be accom-
plished, without resorting to programming, by is-
suing a SPARQL insert query shown in Figure
5(c). The query will create triple statements com-
pliant with the definition of Relationship. The re-
sulting modified RDF graph can then be read back
to Argo by the RDF Reader component that will
convert the new RDF graph back into a CAS.
6 Related Work
Other notable examples of NLP platforms that
provide graphical interfaces for managing work-
flows include GATE (Cunningham et al, 2002)
and U-Compare (Kano et al, 2010). GATE is
a standalone suite of text processing and annota-
tion tools and comes with its own programming
interface. In contrast, U-Compare?similarly to
Argo?uses UIMA as its base interoperability
framework. The key features of Argo that distin-
guish it from U-Compare are the Web availabil-
ity of the platform, primarily remote processing
of workflows, a multi-user, collaborative architec-
ture, and the availability of user-interactive com-
ponents.
7 Conclusions
Argo emerges as a one-stop solution for develop-
ing and processing NLP tasks. Moreover, the pre-
sented annotation viewer and editor, performance
evaluator, and lastly RDF (de)serialisers are in-
dispensable for the analysis of processing tasks
at hand. Together with the distributed develop-
ment support for developers wishing to create their
own components or run their own tools with the
help of resources available in Argo, the workbench
becomes a powerful development and analytical
NLP tool.
Acknowledgments
This work was partially funded by the MRC Text
Mining and Screening grant (MR/J005037/1).
References
W A Baumgartner, K B Cohen, and L Hunter. 2008.
An open-source framework for large-scale, flexible
evaluation of biomedical text mining systems. Jour-
nal of biomedical discovery and collaboration, 3:1+.
H Cunningham, D Maynard, K Bontcheva, and
V Tablan. 2002. GATE: A framework and graphical
development environment for robust NLP tools and
applications. In Proceedings of the 40th Anniver-
sary Meeting of the Association for Computational
Linguistics.
D Ferrucci and A Lally. 2004. UIMA: An Ar-
chitectural Approach to Unstructured Information
Processing in the Corporate Research Environment.
Natural Language Engineering, 10(3-4):327?348.
R T Fielding and R N Taylor. 2002. Principled de-
sign of the modern Web architecture. ACM Trans.
Internet Technol., 2(2):115?150, May.
I Gurevych, M Mu?hlha?user, C Mu?ller, J Steimle,
M Weimer, and T Zesch. 2007. Darmstadt knowl-
edge processing repository based on uima. In Pro-
ceedings of the First Workshop on Unstructured
Information Management Architecture, Tu?bingen,
Germany.
U Hahn, E Buyko, R Landefeld, M Mu?hlhausen,
M Poprat, K Tomanek, and J Wermter. 2008. An
Overview of JCORE, the JULIE Lab UIMA Compo-
nent Repository. In Language Resources and Eval-
uation Workshop, Towards Enhanc. Interoperability
Large HLT Syst.: UIMA NLP, pages 1?8.
Y Kano, R Dorado, L McCrochon, S Ananiadou, and
J Tsujii. 2010. U-Compare: An integrated language
resource evaluation platform including a compre-
hensive UIMA resource library. In Proceedings of
the Seventh International Conference on Language
Resources and Evaluation, pages 428?434.
G K Savova, J J Masanz, P V Ogren, J Zheng, S Sohn,
K C Kipper-Schuler, and C G Chute. 2010. Mayo
clinical Text Analysis and Knowledge Extraction
System (cTAKES): architecture, component evalua-
tion and applications. Journal of the American Med-
ical Informatics Association, 17(5):507?513.
P Stenetorp, S Pyysalo, G Topic?, T Ohta, S Ananiadou,
and J Tsujii. 2012. brat: a web-based tool for nlp-
assisted text annotation. In Proceedings of the 13th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 102?107,
Avignon, France.
120
Proceedings of BioNLP Shared Task 2011 Workshop, pages 26?35,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
Overview of the Infectious Diseases (ID) task of
BioNLP Shared Task 2011
Sampo Pyysalo? Tomoko Ohta? Rafal Rak?? Dan Sullivan? Chunhong Mao?
Chunxia Wang? Bruno Sobral? Jun?ichi Tsujii? Sophia Ananiadou??
?Department of Computer Science, University of Tokyo, Tokyo, Japan
?Virginia Bioinformatics Institute, Virginia Tech, Blacksburg, Virginia, USA
?School of Computer Science, University of Manchester, Manchester, UK
?National Centre for Text Mining, University of Manchester, Manchester, UK
?Microsoft Research Asia, Beijing, China
{smp,okap}@is.s.u-tokyo.ac.jp jtsujii@microsoft.com
{dsulliva,cmao,cwang,sobral}@vbi.vt.edu
{rafal.rak,sophia.ananiadou}@manchester.ac.uk
Abstract
This paper presents the preparation, resources,
results and analysis of the Infectious Diseases
(ID) information extraction task, a main task
of the BioNLP Shared Task 2011. The ID
task represents an application and extension
of the BioNLP?09 shared task event extrac-
tion approach to full papers on infectious dis-
eases. Seven teams submitted final results to
the task, with the highest-performing system
achieving 56% F-score in the full task, com-
parable to state-of-the-art performance in the
established BioNLP?09 task. The results in-
dicate that event extraction methods general-
ize well to new domains and full-text publi-
cations and are applicable to the extraction of
events relevant to the molecular mechanisms
of infectious diseases.
1 Introduction
The Infectious Diseases (ID) task of the BioNLP
Shared Task 2011 (Kim et al, 2011a) is an infor-
mation extraction task focusing on the biomolecu-
lar mechanisms of infectious diseases. The primary
target of the task is event extraction (Ananiadou et
al., 2010), broadly following the task setup of the
BioNLP?09 Shared Task (BioNLP ST?09) (Kim et
al., 2009).
The task concentrates on the specific domain of
two-component systems (TCSs, or two-component
regulatory systems), a mechanism widely used by
bacteria to sense and respond to the environment
(Thomason and Kay, 2000). Typical TCSs con-
sist of two proteins, a membrane-associated sensor
kinase and a cytoplasmic response regulator. The
sensor kinase monitors changes in the environment
while the response regulator mediates an adaptive
response, usually through differential expression of
target genes (Mascher et al, 2006). TCSs have many
functions, but those of particular interest for infec-
tious disease researchers include virulence, response
to antibiotics, quorum sensing, and bacterial cell at-
tachment (Krell et al, 2010). Not all TCS functions
are well known: in some cases, TCSs are involved
in metabolic processes that are difficult to precisely
characterize (Wang et al, 2010). TCSs are of in-
terest also as drugs designed to disrupt TCSs may
reduce the virulence of bacteria without killing it,
thus avoiding the potential selective pressure of an-
tibiotics lethal to some pathogenic bacteria (Gotoh
et al, 2010). Information extraction techniques may
support better understanding of these fundamental
systems by identifying and structuring the molecu-
lar processes underlying two component signaling.
The ID task seeks to address these opportuni-
ties by adapting the BioNLP ST?09 event extraction
model to domain scientific publications. This model
was originally introduced to represent biomolecu-
lar events relating to transcription factors in human
blood cells, and its adaptation to a domain that cen-
trally concerns both bacteria and their hosts involves
a variety of novel aspects, such as events concerning
whole organisms, the chemical environment of bac-
teria, prokaryote-specific concepts (e.g. regulons as
elements of gene expression), as well as the effects
of biomolecules on larger-scale processes involving
hosts such as virulence.
26
2 Task Setting
The ID task broadly follows the task definition and
event types of the BioNLP ST?09, extending it with
new entity categories, correspondingly broadening
the scope of events, and introducing a new class of
events, high-level biological processes.
2.1 Entities
The ID task defines five core types of entities:
genes/gene products, two-component systems, reg-
ulons/operons, chemicals, and organisms. Follow-
ing the general policy of the BioNLP Shared Task,
the recognition of the core entities is not part of
the ID task. As named entity recognition (NER)
is considered in other prominent domain evaluations
(Krallinger et al, 2008), we have chosen to isolate
aspects of extraction performance relating to NER
from the main task of interest, event extraction, by
providing participants with human-created gold an-
notations for core entities. These annotations are
briefly presented in the following.
Mentions of names of genes and their products
(RNA and proteins) are annotated with a single
type, without differentiating between subtypes, fol-
lowing the guidelines of the GENIA GGP corpus
(Ohta et al, 2009). This type is named PRO-
TEIN to maintain consistency with related tasks
(e.g. BioNLP ST?09), despite slight inaccuracy
for cases specifically referencing RNA or DNA
forms. Two-component systems, consisting of two
proteins, frequently have names derived from the
names of the proteins involved (e.g. PhoP-PhoR
or SsrA/SsrB). Mentions of TCSs are annotated as
TWO-COMPONENT-SYSTEM, nesting PROTEIN an-
notations if present. Regulons and operons are col-
lections of genes whose expression is jointly regu-
lated. Like the names of TCSs, their names may de-
rive from the names of the involved genes and pro-
teins, and are annotated as embedding PROTEIN an-
notations when they do. The annotation does not
differentiate between the two, marking both with a
single type REGULON-OPERON.
In addition to these three classes relating to genes
and proteins, the core entity annotation recognizes
the classes CHEMICAL and ORGANISM. All men-
tions of formal and informal names of atoms, inor-
ganic compounds, carbohydrates and lipids as well
as organic compounds other than amino acid and nu-
cleic acid compounds (i.e. gene/protein-related com-
pounds) are annotated as CHEMICAL. Mentions of
names of families, genera, species and strains as
well as non-name references with comparable speci-
ficity are annotated as ORGANISM.
Finally, the non-specific type ENTITY1 is defined
for marking entities that specify additional details of
events such as the binding site in a BINDING event or
the location an entity moves to in a LOCALIZATION
event. Unlike the core entities, annotations of the
generic ENTITY type are not provided for test data
and must be detected by participants addressing the
full task.
2.2 Relations
The ID task involves one relation, EQUIV, defin-
ing entities (of any of the core types) to be equiv-
alent. This relation is used to annotate abbreviations
and local aliases and it is not a target of extraction,
but provided for reference and applied in evaluation,
where references to any of a set of equivalent entities
are treated identically.
2.3 Events
The primary extraction targets of the ID task are the
event types summarized in Table 1. These are a su-
perset of those targeted in the BioNLP ST?09 and its
repeat, the 2011 GE task (Kim et al, 2011b). This
design makes it possible to study aspects of domain
adaptation by having the same extraction targets in
two subdomains of biomedicine, that of transcrip-
tion factors in human blood cells (GE) and infectious
diseases. The events in the ID task extend on those
of GE in the inclusion of additional entity types
as participants in previously considered event types
and the introduction of a new type, PROCESS. We
next briefly discuss the semantics of these events,
defined (as in GE) with reference to the community-
standard Gene Ontology (Ashburner et al, 2000).
We refer to (Kim et al, 2008; Kim et al, 2009) for
the ST?09/GE definitions.
1In terms of the GENIA ontology, ENTITY is used to mark
e.g. PROTEIN DOMAIN OR REGION references. Specific types
were applied in manual annotation, but these were replaced
with the generic ENTITY in part to maintain consistency with
BioNLP ST?09 data and to reduce the NER-related demands
on participating systems by not requiring the assignment of de-
tailed types.
27
Type Core arguments Additional arguments
GENE EXPRESSION Theme(PROTEIN or REGULON-OPERON)
TRANSCRIPTION Theme(PROTEIN or REGULON-OPERON)
PROTEIN CATABOLISM Theme(PROTEIN)
PHOSPHORYLATION Theme(PROTEIN) Site(ENTITY)
LOCALIZATION Theme(Core entity) AtLoc(ENTITY), ToLoc(ENTITY)
BINDING Theme(Core entity)+ Site(ENTITY)+
PROCESS Participant(Core entity)?
REGULATION Theme(Core entity / Event), Cause(Core entity / Event)? Site(ENTITY), CSite(ENTITY)
POSITIVE REGULATION Theme(Core entity / Event), Cause(Core entity / Event)? Site(ENTITY), CSite(ENTITY)
NEGATIVE REGULATION Theme(Core entity / Event), Cause(Core entity / Event)? Site(ENTITY), CSite(ENTITY)
Table 1: Event types and their arguments. The type of entity allowed as argument is specified in parenthesis. ?Core en-
tity? is any of PROTEIN, TWO-COMPONENT-SYSTEM, REGULON-OPERON, CHEMICAL, or ORGANISM. Arguments
that can be filled multiple times marked with ?+?, non-mandatory core arguments with ??? (all additional arguments
are non-mandatory).
The definitions of the first four types in Table 1
are otherwise unchanged from the ST?09 definitions
except that GENE EXPRESSION and TRANSCRIP-
TION extend on the former definition in recogniz-
ing REGULON-OPERON as an alternative unit of ex-
pression. LOCALIZATION, taking only PROTEIN
type arguments in the ST?09 definition, is allowed
to take any core entity argument. This expanded
definition remains consistent with the scope of the
corresponding GO term (GO:0051179). BINDING
is similarly extended, giving it a scope largely con-
sistent with GO:0005488 (binding) but also encom-
passing GO:0007155 (cell adhesion) (e.g. a bac-
terium binding another) and protein-organism bind-
ing. The three regulation types (REGULATION,
POSITIVE REGULATION, and NEGATIVE REGULA-
TION) likewise allow the new core entity types as
arguments, but their definitions are otherwise un-
changed from those in ST?09, that is, the GENIA on-
tology definitions. As in these resources, regulation
types are used not only for the biological sense but
also to capture statements of general causality (Kim
et al, 2008). As in ST?09, all events of types dis-
cussed above require a Theme argument: only events
involving an explicitly stated theme (of an appropri-
ate type) should be extracted. All other arguments
are optional.
The PROCESS type, new to ID, is used to annotate
high-level processes such as virulence, infection and
resistance that involve infectious organisms. This
type differs from the others in that it has no manda-
tory arguments: the targeted processes should be ex-
tracted even if they have no explicitly stated partici-
pants, reflecting that they are of interest even without
the further specification. When stated, the involved
participants are captured using the generic role type
Participant. Figure 1 shows an illustration of some
of the the ID task extraction targets.
We term the first five event types in Table 1 taking
exactly one Theme argument as their core argument
simple events. In analysis we further differentiate
non-regulation events (the first seven) and regulation
(the last three), which is known to represent partic-
ular challenges for extraction in involving events as
arguments, thus creating nested event structures.
2.4 Event modifications
The ID task defines two event modification ex-
traction targets, NEGATION and SPECULATION.
These modifications mark events as being explic-
itly negated (e.g. virB is not expressed) or stated in
a speculative context (e.g. virB may be expressed).
Both may apply simultaneously. The modification
definitions are identical to the ST?09 ones, includ-
ing the representation in which modifications (un-
like events) are not assigned text bindings.
3 Data
The ID task data were newly annotated for the
BioNLP Shared Task and are not based on any previ-
ously released resource. Annotation was performed
by two teams, one in Tsujii laboratory (University
of Tokyo) and one in Virginia Bioinformatics Insti-
tute (Virginia Tech). The entity and event annotation
28
Figure 1: Example event annotation. The association of a TCS with an organism is captured through an event structure
involving a PROCESS (?virulence?) and POSITIVE REGULATION. Regulation types are used to capture also statements
of general causality such as ?is essential for? here. (Simplified from PMC ID 2358977)
Journal # Published
PLoS Pathogens 9 2006?2010
PLoS One 7 2008?2010
BMC Genomics 3 2008?2010
PLoS Genetics 2 2007?2010
Open Microbiology J. 2 2008?2010
BMC Microbiology 2 2008?2009
Other 5 2007?2008
Table 2: Corpus composition. Journals in which selected
articles were published with number of articles (#) and
publication years.
design was guided by previous studies on NER and
event extraction in a closely related domain (Pyysalo
et al, 2010; Ananiadou et al, 2011).
3.1 Document selection
The training and test data were drawn from the pri-
mary text content of recent full-text PMC open ac-
cess documents selected by infectious diseases do-
main experts (Virginia Tech team) as representative
publications on two-component regulatory systems.
Table 2 presents some characteristics of the corpus
composition. To focus efforts on natural language
text likely to express novel information, we excluded
tables, figures and their captions, as well as methods
sections, acknowledgments, authors? contributions,
and similar meta-content.
3.2 Annotation
Annotation was performed in two primary stages,
one for marking core entities and the other for events
and secondary entities. As a preliminary processing
step, initial sentence segmentation was performed
with the GENIA Sentence Splitter2. Segmentation
errors were corrected during core entity annotation.
Core entity annotation was performed from the
basis of an automatic annotation created using se-
lected existing taggers for the target entities. The
2http://www-tsujii.is.s.u-tokyo.ac.jp/
?y-matsu/geniass/
Entity type prec. rec. F
PROTEIN 54.64 39.64 45.95
CHEMICAL 32.24 19.05 23.95
ORGANISM 90.38 47.70 62.44
TWO-COMPONENT-SYSTEM 87.69 47.24 61.40
Table 3: Automatic core entity tagging performance.
following tools and settings were adopted, with pa-
rameters tuned on initial annotation for two docu-
ments:
PROTEIN: NeMine (Sasaki et al, 2008) trained on
the JNLPBA data (Kim et al, 2004) with threshold
0.05, filtered to only GENE and PROTEIN types.
ORGANISM: Linnaeus (Gerner et al, 2010) with
?variant matching? for species names variants.
CHEMICAL: OSCAR3 (Corbett and Murray-Rust,
2006) with confidence 90%.
TWO-COMPONENT-SYSTEM: Custom regular ex-
pressions.
Initial automatic tagging was not applied for en-
tities of the REGULON-OPERON type or the generic
ENTITY type (for additional event arguments). All
automatically generated annotations were at least
confirmed through manual inspection, and the ma-
jority of the automatic annotations were revised in
manual annotation. Table 3 summarizes the tag-
ging performance of the automatic tools as measured
against the final human-annotated training and de-
velopment datasets.3
Annotation for the task extraction targets ? events
and event modifications ? was created entirely man-
ually without automatic annotation support to avoid
any possible bias toward specific extraction meth-
ods or approaches. The Tsujii laboratory team orga-
3It should be noted that these results are low in part due to
differences in annotation criteria (see e.g. (Wang et al, 2009))
and to data tagged using the ID task annotation guidelines not
being applied for training; training on the newly annotated data
is expected to allow notably more accurate tagging.
29
Item Train Devel Test Total
Articles 15 5 10 30
Sentences 2,484 709 1,925 5118
Words 74,439 21,225 57,489 153,153
Core entities 6,525 1,976 4,239 12,740
Events 2,088 691 1,371 4150
Modifications 95 45 74 214
Table 4: Statistics of the ID corpus.
nized the annotation effort, with a coordinating an-
notator with extensive experience in event annota-
tion (TO) leading annotator training and annotation
scheme development. Detailed annotation guide-
lines (Pyysalo et al, 2011) extending on the GE-
NIA annotation guidelines were developed jointly
with all annotators and refined throughout the an-
notation effort. Based on measurements of inter-
annotator consistency between annotations indepen-
dently created by the two teams, made throughout
annotator training and primary annotation (exclud-
ing final corpus cleanup), we estimate the consis-
tency of the final entity annotation to be no lower
than 90% F-score and that of the event annotation to
be no lower than 75% F-score for the primary eval-
uation criteria (see Section 4).
3.3 Datasets and statistics
Initial annotation was produced for the selected sec-
tions (see Section 3.1) in 33 full-text articles, of
which 30 were selected for the final dataset as repre-
sentative of the extraction targets. These documents
were split into training, development and test sets of
15, 5 and 10 documents, respectively. Participants
were provided with all training and development set
annotations and test set core entity annotations. The
overall statistics of the datasets are given in Table 4.
As the corpus consists of full-text articles, it con-
tains a somewhat limited number of articles, but in
other terms it is of broadly comparable size to the
largest of the BioNLP ST corpora: the corpus word
count, for example, corresponds to that of a cor-
pus of approximately 800 PubMed abstracts, and the
core entity count is comparable to that in the ST?09
data. However, for reasons that may relate in part to
the domain, the event count is approximately a third
of that for the ST?09 data. In addition to having less
training data, the entity/event ratio is thus consider-
ably higher (i.e. there are more candidates for each
true target), suggesting that the ID data could be ex-
pected to provide a more challenging extraction task.
4 Evaluation
The performance of participating systems was
evaluated in terms of events using the standard
precision/recall/F-score metrics. For the primary
evaluation, we adopted the standard criteria defined
in the BioNLP?09 shared task. In brief, for deter-
mining whether a reference annotation and a pre-
dicted annotation match, these criteria relax exact
matching for event triggers and arguments in two
ways: matching of text-bound annotation (event
triggers and ENTITY type entities) allows limited
boundary variation, and only core arguments need to
match in nested event arguments for events to match.
For details of the matching criteria, please refer to
Kim et al (2009).
The primary evaluation for the task requires the
extraction of all event arguments (both core and ad-
ditional; see Table 1) as well as event modifications
(NEGATION and SPECULATION). This is termed
the full task. We additionally report extraction re-
sults for evaluation where both the gold standard ref-
erence data and the submission events are reduced
to only core arguments, event modifications are re-
moved, and resulting duplicate events removed. We
term this the core task. In terms of the subtask divi-
sion applied in the BioNLP?09 Shared Task and the
GE task of 2011, the core task is analogous to sub-
task 1 and the full task analogous to the combination
of subtasks 1?3.
5 Results
5.1 Participation
Final results to the task were successfully submitted
by seven participants. Table 5 summarizes the in-
formation provided by the participating teams. We
note that full parsing is applied in all systems, with
the specific choice of the parser of Charniak and
Johnson (2005) with the biomedical domain model
of McClosky (2009) and conversion into the Stan-
ford Dependency representation (de Marneffe et al,
2006) being adopted by five participants. Further,
five of the seven systems are predominantly machine
learning-based. These can be seen as extensions of
trends that were noted in analysis of the BioNLP
30
NLP Events Other resources
Rank Team Org Word Parse Trig. Arg. Group. Modif. Corpora Other
1 FAUST 3NLP
CoreNLP,
SnowBall
McCCJ + SD (UMass+Stanford as features) GE word clusters
2 UMass 1NLP
CoreNLP,
SnowBall
McCCJ + SD Joint, dual dec.+MIRA 1-best - GE -
3 Stanford 3NLP CoreNLP McCCJ + SD MaxEnt Joint, MSTParser - GE word clusters
4 ConcordU 2NLP - McCCJ + SD dict rules rules rules -
triggers and
hedge words
5 UTurku 1BI Porter McCCJ + SD SVM SVM SVM SVM - hedge words
6 PNNL
1CS, 1NLP,
2BI
Porter Stanford SVM SVM rules - GE UMLS, triggers
7 PredX 1CS, 1NLP LGP LGP dict rules rules - - UMLS, triggers
Table 5: Participants and summary of system descriptions. Abbreviations: Trig./Arg./Group./Modif.=event trigger
detection/argument detection/argument grouping/modification detection, BI=Bioinformatician, NLP=Natural Lan-
guage Processing researcher, CS=Computer scientist, CoreNLP=Stanford CoreNLP, Porter=Porter stemmer, Snow-
ball=Snowball stemmer McCCJ=McClosky-Charniak-Johnson parser, LGP=Link Grammar Parser, SD=Stanford De-
pendency conversion, UMLS=UMLS resources (e.g. lexicon, metamap)
ST?09 participation. In system design choices, we
note an indication of increased use of joint models
as opposed to pure pipeline designs, with the three
highest-ranking systems involving a joint model.
Several participants compiled dictionaries of
event trigger words and two dictionaries of hedge
words from the data. Four teams, including the three
top-ranking, used the GE task corpus as supplemen-
tary material, indicating that the GE annotations are
largely compatible with ID ones (see detailed results
below). This is encouraging for future applications
of the event extraction approach: as manual annota-
tion requires considerable effort and time, the ability
to use existing annotations is important for the feasi-
bility of adaptation of the approach to new domains.
While several participants made use of support-
ing syntactic analyses provided by the organizers
(Stenetorp et al, 2011), none applied the analyses
for supporting tasks, such as coreference or entity
relation extraction results ? at least in cases due to
time constraints (Kilicoglu and Bergler, 2011).
5.2 Evaluation results
Table 6 presents the primary results by event type,
and Table 7 summarizes these results. The full
task requires the extraction of additional arguments
and event modifications and involves multiple novel
challenges from previously addressed domain tasks
including a new subdomain, full-text documents,
several new entity types and a new event category.
Team recall prec. F-score
FAUST 48.03 65.97 55.59
UMass 46.92 62.02 53.42
Stanford 46.30 55.86 50.63
ConcordU 49.00 40.27 44.21
UTurku 37.85 48.62 42.57
PNNL 27.75 52.36 36.27
PredX 22.56 35.18 27.49
Table 7: Primary evaluation results.
Nevertheless, extraction performance for the top
systems is comparable to the state-of-the-art results
for the established BioNLP ST?09 task (Miwa et al,
2010) as well as its repetition as the 2011 GE task
(Kim et al, 2011b), where the highest overall result
for the primary evaluation criteria was also 56% F-
score for the FAUST system (Riedel et al, 2011).
This result is encouraging regarding the ability of
the extraction approach and methods to generalize
to new domains as well as their applicability specifi-
cally to texts on the molecular mechanisms of infec-
tious diseases.
We note that there is substantial variation in the
relative performance of systems for different en-
tity types. For example, Stanford (McClosky et
al., 2011) has relatively low performance for simple
events but achieves the highest result for PROCESS,
while UTurku (Bjo?rne and Salakoski, 2011) results
show roughly the reverse. This suggests further po-
tential for improvement from system combinations.
31
FAUST UMass Stanford ConcordU UTurku PNNL PredX Size
GENE EXPRESSION 70.68 66.43 54.00 56.57 64.88 53.33 0.00 512
TRANSCRIPTION 69.66 68.24 60.00 70.89 57.14 0.00 53.85 77
PROTEIN CATABOLISM 75.00 72.73 20.00 66.67 33.33 11.76 0.00 33
PHOSPHORYLATION 64.00 66.67 40.00 54.55 60.61 64.29 40.00 69
LOCALIZATION 33.33 14.29 31.58 20.00 66.67 20.69 0.00 49
Simple event total 68.47 63.55 52.72 56.78 62.67 43.87 18.18 740
BINDING 31.30 34.62 23.44 40.00 22.22 20.00 28.28 156
PROCESS 65.69 62.26 73.57 67.17 41.57 51.04 53.27 901
Non-regulation total 63.78 60.68 63.59 62.43 46.39 47.34 43.65 1797
REGULATION 35.44 30.49 17.67 19.43 22.96 0.00 2.16 267
POSITIVE REGULATION 47.50 49.49 34.78 23.41 41.28 24.60 21.02 455
NEGATIVE REGULATION 58.86 60.45 44.44 47.96 52.11 25.70 9.49 260
Regulation total 47.07 46.65 33.02 28.87 39.49 18.45 9.71 982
Subtotal 57.28 55.03 52.09 46.60 43.33 37.53 28.38 2779
NEGATION 0.00 0.00 0.00 22.92 32.91 0.00 0.00 96
SPECULATION 0.00 0.00 0.00 3.23 15.00 0.00 0.00 44
Modification total 0.00 0.00 0.00 11.82 26.89 0.00 0.00 140
Total 55.59 53.42 50.63 44.21 42.57 36.27 27.49 2919
Table 6: Primary evaluation F-scores by event type. The ?size? column gives the number of annotations of each type
in the given data (training+development). Best result for each type shown in bold.
The best performance for simple events and for
PROCESS approaches or exceeds 70% F-score, ar-
guably approaching a sufficient level for user-facing
applications of the extraction technology. By con-
trast, BINDING and regulation events, found chal-
lenging in ST?09 and GE, remain problematic also
in the ID task, with best overall performance below
50% F-score. Only two teams, UTurku and Con-
cordU (Kilicoglu and Bergler, 2011), attempted to
extract event modifications, with somewhat limited
performance. The difficulty of correct extraction of
event modifications is related in part to the recursive
nature of the problem (similarly as for nested reg-
ulation events): to extract a modification correctly,
the modified event must also be extracted correctly.
Further, only UTurku predicted any instances of sec-
ondary arguments. Thus, teams other than UTurku
and ConcordU addressed only the core task extrac-
tion targets. With the exception of ConcordU, all
systems clearly favor precision over recall (Table 7),
in many cases having over 15% point higher preci-
sion than recall. This a a somewhat unexpected in-
version, as the ConcordU system is one of the two
rule-based in the task, an approach typically associ-
ated with high precision.
The five top-ranking systems participated also in
the GE task (Kim et al, 2011b), which involves a
subset of the ID extraction targets. This allows ad-
ditional perspective into the relative performance of
the systems. While there is a 13% point spread in
overall results for the top five systems here, in GE
all these systems achieved F-scores ranging between
50?56%. The results for FAUST, UMass and Stan-
ford were similar in both tasks, while the ConcordU
result was 6% points higher for GE and the UTurku
result over 10% points higher for GE, ranking third
after FAUST and UMass. These results suggest that
while the FAUST and UMass systems in particular
have some systematic (e.g. architectural) advantage
at both tasks, much of the performance difference
observed here between the top three systems and
those of ConcordU and UTurku is due to strengths
or weaknesses specific to ID. Possible weaknesses
may relate to the treatment of multiple core entity
types (vs. only PROTEIN in GE) or challenges re-
lated to nested entity annotations (not appearing in
GE). A possible ID-specific strength of the three
top-ranking systems is the use of GE data for train-
ing: Riedel and McCallum (2011) report an esti-
mated 7% point improvement and McClosky et al
(2011) a 3% point improvement from use of this
data; McGrath et al (2011) estimate a 1% point im-
provement from direct corpus combination. The in-
tegration strategies applied in training these systems
32
Team recall prec. F-score ?
FAUST 50.62 66.06 57.32 1.73
UMass 49.45 62.11 55.06 1.64
Stanford 48.87 56.03 52.20 1.57
ConcordU 50.77 43.25 46.71 2.50
UTurku 38.79 49.35 43.44 0.87
PNNL 29.36 52.62 37.69 1.42
PredX 23.67 35.18 28.30 0.81
Table 8: Core task evaluation results. The ? column
gives the F-score difference to the corresponding full task
(primary) result.
could potentially be applied also with other systems,
an experiment that could further clarify the relative
strengths of the various systems. The top-ranking
five systems all participated also in the EPI task
(Ohta et al, 2011), for which UTurku ranked first
with FAUST having comparable performance for the
core task. While this supports the conclusion that
ID performance differences do not reflect a simple
universal ranking of the systems, due to many sub-
stantial differences between the ID and EPI setups it
is not straightforward to identify specific reasons for
relative differences to performance at EPI.
Table 8 summarizes the core task results. There
are only modest and largely consistent differences to
the corresponding full task results, reflecting in part
the relative sparseness of additional arguments: in
the training data, for example, only approximately
3% of instances of event types that can potentially
take additional arguments had at least one additional
argument. While event modifications represent a
further 4% of full task extraction targets not required
for the core task, the overall low extraction perfor-
mance for additional arguments and modifications
limits the practical effect of these annotation cate-
gories on the performance difference between sys-
tems addressing only the core targets and those ad-
dressing the full task.
6 Discussion and Conclusions
We have presented the preparation, resources, re-
sults and analysis of the Infectious Diseases (ID)
task of the BioNLP Shared Task 2011. A corpus
of 30 full-text publications on the two-component
systems subdomain of infectious diseases was cre-
ated for the task in a collaboration of event annota-
tion and domain experts, adapting and extending the
BioNLP?09 Shared Task (ST?09) event representa-
tion to the domain.
Seven teams submitted final results to the ID task.
Despite the novel challenges of full papers, four new
entity types, extension of event scopes and the intro-
duction of a new event category for high-level pro-
cesses, the highest results for the full ID task were
comparable to the state-of-the-art performance on
the established ST?09 data, showing that the event
extraction approach and present systems generalize
well and demonstrating the feasibility of event ex-
traction for the infectious diseases domain. Analy-
sis of results suggested further opportunities for im-
proving extraction performance by combining the
strengths of various systems and the use of other
event resources.
The task design takes into account the needs
of supporting practical applications, and its results
and findings will be adopted in future development
of the Pathosystems Resource Integration Center4
(PATRIC). Specifically, PATRIC will combine do-
main named entity recognition and event extraction
to mine the virulence factor literature and integrate
the results with literature search and retrieval ser-
vices, protein feature analysis, and systems such as
Disease View.5 Present and future advances at the
ID event extraction task can thus assist biologists in
efforts of substantial public health interest.
The ID task will be continued as an open
shared task challenge with data, supporting re-
sources, and evaluation tools freely available from
the shared task site, http://sites.google.
com/site/bionlpst/.
Acknowledgments
This work was supported by Grant-in-Aid for Spe-
cially Promoted Research (MEXT, Japan). This
project has been funded in whole or in part with Fed-
eral funds from the National Institute of Allergy and
Infectious Diseases, National Institutes of Health,
Department of Health and Human Services, under
Contract No. HHSN272200900040C, awarded to
BWS Sobral.
4http://patricbrc.org
5See for example http://patricbrc.org/portal/
portal/patric/DiseaseOverview?cType=
taxon&cId=77643
33
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology, 28(7):381?390.
Sophia Ananiadou, Dan Sullivan, William Black, Gina-
Anne Levow, Joseph J. Gillespie, Chunhong Mao,
Sampo Pyysalo, BalaKrishna Kolluru, Junichi Tsujii,
and Bruno Sobral. 2011. Named entity recognition
for bacterial type IV secretion systems. PLoS ONE,
6(3):e14780.
M Ashburner, CA Ball, JA Blake, D Botstein, H Butler,
JM Cherry, AP Davis, K Dolinski, SS Dwight, JT Ep-
pig, MA Harris, DP Hill, L Issel-Tarver, A Kasarskis,
S Lewis, JC Matese, JE Richardson, M Ringwald,
GM Rubin, and G Sherlock. 2000. Gene ontology:
tool for the unification of biology. Nature genetics,
25:25?29.
Jari Bjo?rne and Tapio Salakoski. 2011. Generaliz-
ing biomedical event extraction. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL?05), pages 173?180.
Peter Corbett and Peter Murray-Rust. 2006. High-
throughput identification of chemistry in life science
texts. Computational Life Sciences II, pages 107?118.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating Typed
Dependency Parses from Phrase Structure Parses. In
Proceedings of the Fifth International Conference
on Language Resources and Evaluation (LREC?06),
pages 449?454.
Martin Gerner, Goran Nenadic, and Casey M. Bergman.
2010. LINNAEUS: a species name identification sys-
tem for biomedical literature. BMC bioinformatics,
11(1):85+, February.
Yasuhiro Gotoh, Yoko Eguchi, Takafumi Watanabe, Sho
Okamoto, Akihiro Doi, and Ryutaro Utsumi. 2010.
Two-component signal transduction as potential drug
targets in pathogenic bacteria. Current Opinion in Mi-
crobiology, 13(2):232?239. Cell regulation.
Halil Kilicoglu and Sabine Bergler. 2011. Adapting a
general semantic interpretation approach to biological
event extraction. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka,
Yuka Tateisi, and Nigel Collier, editors. 2004. Intro-
duction to the bio-entity recognition task at JNLPBA,
Geneva, Switzerland.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
lterature. BMC Bioinformatics, 9(1):10.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop, pages
1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, and Jun?ichi Tsujii. 2011a. Overview
of BioNLP Shared Task 2011. In Proceedings of
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-
nori Yonezawa. 2011b. Overview of the Genia Event
task in BioNLP Shared Task 2011. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
M. Krallinger, A. Morgan, L. Smith, F. Leitner, L. Tan-
abe, J. Wilbur, L. Hirschman, and A. Valencia.
2008. Evaluation of text-mining systems for biology:
overview of the Second BioCreative community chal-
lenge. Genome biology, 9(Suppl 2):S1.
Tino Krell, Jess Lacal, Andreas Busch, Hortencia Silva-
Jimnez, Mara-Eugenia Guazzaroni, and Juan Luis
Ramos. 2010. Bacterial sensor kinases: Diversity in
the recognition of environmental signals. Annual Re-
view of Microbiology, 64(1):539?559.
Thorsten Mascher, John D. Helmann, and Gottfried Un-
den. 2006. Stimulus perception in bacterial signal-
transducing histidine kinases. Microbiol. Mol. Biol.
Rev., 70(4):910?938.
David McClosky, Mihai Surdeanu, and Christopher Man-
ning. 2011. Event extraction as dependency parsing
for bionlp 2011. In Proceedings of the BioNLP 2011
Workshop Companion Volume for Shared Task, Port-
land, Oregon, June. Association for Computational
Linguistics.
David McClosky. 2009. Any Domain Parsing: Auto-
matic Domain Adaptation for Natural Language Pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
Liam McGrath, Kelly Domico, Courtney Corley, and
Bobbie-Jo Webb-Robertson. 2011. Complex biologi-
cal event extraction from full text using signatures of
linguistic and semantic features. In Proceedings of
34
the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and
Jun?ichi Tsujii. 2010. Evaluating dependency repre-
sentation for event extraction. In Proceedings of COL-
ING?10, pages 779?787.
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009. Incorporating
GENETAG-style annotation to GENIA corpus. In
Proceedings of BioNLP?09, pages 106?107.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011.
Overview of the Epigenetics and Post-translational
Modifications (EPI) task of BioNLP Shared Task
2011. In Proceedings of the BioNLP 2011 Workshop
Companion Volume for Shared Task, Portland, Oregon,
June. Association for Computational Linguistics.
Sampo Pyysalo, Tomoko Ohta, Han-Cheol Cho, Dan Sul-
livan, Chunhong Mao, Bruno Sobral, Jun?ichi Tsujii,
and Sophia Ananiadou. 2010. Towards event extrac-
tion from full texts on infectious diseases. In Proceed-
ings of BioNLP?10, pages 132?140.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sulli-
van, Chunhong Mao, Chunxia Wang, Bruno Sobral,
Jun?ichi Tsujii, and Sophia Ananiadou. 2011. An-
notation guidelines for infectious diseases event cor-
pus. Technical report, Tsujii Laboratory, University of
Tokyo. To appear.
Sebastian Riedel and Andrew McCallum. 2011. Ro-
bust biomedical event extraction with dual decompo-
sition and minimal domain adaptation. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, Portland, Oregon, June. Association for
Computational Linguistics.
Sebastian Riedel, David McClosky, Mihai Surdeanu, An-
drew McCallum, and Chris Manning. 2011. Model
combination for event extraction in bionlp 2011. In
Proceedings of the BioNLP 2011 Workshop Compan-
ion Volume for Shared Task, Portland, Oregon, June.
Association for Computational Linguistics.
Yutaka Sasaki, Yoshimasa Tsuruoka, John McNaught,
and Sophia Ananiadou. 2008. How to make the most
of NE dictionaries in statistical NER. BMC bioinfor-
matics, 9 Suppl 11.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
BioNLP Shared Task 2011: Supporting Resources. In
Proceedings of the BioNLP 2011 Workshop Compan-
ion Volume for Shared Task, Portland, Oregon, June.
Association for Computational Linguistics.
Peter Thomason and Rob Kay. 2000. Eukaryotic sig-
nal transduction via histidine-aspartate phosphorelay.
J Cell Sci, 113(18):3141?3150.
Yue Wang, Jin-Dong Kim, Rune S?tre, Sampo Pyysalo,
and Jun?ichi Tsujii. 2009. Investigating heteroge-
neous protein annotations toward cross-corpora uti-
lization. BMC Bioinformatics, 10(403).
Chunxia Wang, Jocelyn Kemp, Isabel O. Da Fonseca,
Raymie C. Equi, Xiaoyan Sheng, Trevor C. Charles,
and Bruno W. S. Sobral. 2010. Sinorhizobium
meliloti 1021 loss-of-function deletion mutation in
chvi and its phenotypic characteristics. Molecular
Plant-Microbe Interactions, 23(2):153?160.
35
Proceedings of the BioNLP Shared Task 2013 Workshop, pages 67?75,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
Overview of the Pathway Curation (PC) task of BioNLP Shared Task 2013
Tomoko Ohta 1, Sampo Pyysalo 1, Rafal Rak 1, Andrew Rowley1, Hong-Woo Chun2,
Sung-Jae Jung 2,3, Chang-Hoo Jeong 2 Sung-Pil Choi 2,3, Jun?ichi Tsujii 4,Sophia Ananiadou 1
1National Centre for Text Mining and School of Computer Science, University of Manchester
2Software Research Center, Korea Institute of Science and Technology Information (KISTI)
3Department of Applied Information Science, University of Science and Technology (UST)
4Microsoft Research Asia, Beijing, China
Abstract
We present the Pathway Curation (PC)
task, a main event extraction task of
the BioNLP shared task (ST) 2013.
The PC task concerns the automatic ex-
traction of biomolecular reactions from
text. The task setting, representation
and semantics are defined with respect
to pathway model standards and ontolo-
gies (SBML, BioPAX, SBO) and docu-
ments selected by relevance to specific
model reactions. Two BioNLP ST 2013
participants successfully completed the
PC task. The highest achieved F-
score, 52.8%, indicates that event extrac-
tion is a promising approach to support-
ing pathway curation efforts. The PC
task continues as an open challenge with
data, resources and tools available from
http://2013.bionlp-st.org/
1 Introduction
Following developments in molecular biology, bi-
ological phenomena are increasingly understood
on the molecular level, as the products of complex
systems of molecular reactions. Pathway mod-
els formalizing biomolecules and their reactions
in machine readable representations are a key way
of sharing and communicating human understand-
ing of these phenomena and of developing com-
putational models of biological systems (Kitano,
2002). Many pathway models integrate knowl-
edge from hundreds or thousands of scientific pub-
lications, and their curation requires substantial
manual effort. To support this effort, we have de-
veloped PathText (Kemper et al, 2010) which pro-
vides a seamless environment integrating a path-
way visualizer, text mining systems and annota-
tion tools. Furthermore, automatic processing of
the domain literature could thus potentially play
pyruvate kinase catalyzes the conversion of PEP to pyruvate.
GGP +Regulation Conversion Chem ChemicalThemeCause Theme Product
Figure 1: Event representation for a conversion re-
action.
an important role in the support of pathway cura-
tion.
Information extraction targeting biomolecular
reactions has been a major focus of efforts in
biomedical natural language processing, with sev-
eral tasks, resources, and tools addressing in par-
ticular protein-protein interactions (Krallinger et
al., 2007; Pyysalo et al, 2008; Tikk et al, 2010).
However, most such efforts have employed sim-
ple representations, such as entity pairs, that are
not sufficient for capturing molecular reactions to
the level of detail required to support the curation
of pathway models. Additionally, previous efforts
have not directly involved the semantics (e.g. re-
action type definitions) of such models. Perhaps
in part due to these reasons, natural language pro-
cessing and information extraction methods have
not been widely embraced by biomedical pathway
curation communities (Ohta et al, 2011c; Ohta et
al., 2011a).
We believe that the extraction of structured
event representations (Figure 1) pursued in the
BioNLP Shared Tasks offers many opportuni-
ties to make significant contributions to support
the development, evaluation and maintenance of
biomolecular pathways. The Pathway Curation
(PC) task, a main task of the BioNLP Shared Task
2013, is proposed as a step toward realizing these
opportunities. The PC task aims to evaluate the ap-
plicability of event extraction systems to pathway
curation and to encourage the further development
of methods for related tasks. The design of the
task aims to address current issues in information
extraction for pathway curation by explicitly bas-
ing its representation and extraction targets on ma-
67
GTP GDP
GAPs
re1
re1 Protein Molecule MoleculeReactantModifier ProductConversion GAPs catalyze the hydrolysis of GTP to GDP.GGP +Reg Conversion Chem Chem
Cause ThemeTheme Product
(a) CONVERSION
p38 gamma Pp38 gamma
MKK6
re1
re1
MKK6 phosphorylates p38 gamma.Protein Protein
Protein
Modifier Reactant
Product
Phosphorylation MKK6 phosphorylates p38 gamma.GGP Phosphorylation GGP
Cause Theme
(b) PHOSPHORYLATION
NF-kappaB
p65
p50
p65
p50re1
p65 binds to p50.
GGP Bind GGPTheme Theme2
p65-p50 complex formation.
Complex BindingProduct
p65 and p50 form p65-p50 complex.
Protein Protein NC binding ComplexReactant2 Product
Reactant
(c) BINDING
Figure 2: Illustration of pathway reaction (left), matching representation as an idealized text-bound event
structure (middle) and applied event representation for statements actually appearing in text (right).
jor standards developed in the biomolecular path-
way curation community, such as SBML (Hucka
et al, 2003) and BioPAX (Mi et al, 2011), and
ontologies such as the Systems Biology Ontology1
(SBO) (Courtot et al, 2011). Further, The corpus
texts are selected on the basis of relevance to a se-
lection of pathway models from PANTHER Path-
way DB2 (Mi and Thomas, 2009) and BioMod-
els3 (Li et al, 2010) repositories. The PC task set-
ting and its document selection protocol aim to ac-
count for both signalling and metabolic pathways,
the latter of which has received comparatively lit-
tle attention in recent domain IE efforts (Li et al,
2013).
2 Task setting
The PC task is formulated as an event extraction
task (Ananiadou et al, 2010) following the general
representation and task setting first introduced in
the BioNLP ST 2009 (Kim et al, 2011). The pri-
mary aim is the extraction of event structures, or
events, each of which can involve any number of
physical entities or other events in specific roles.
The event representation is sufficiently expres-
sive to allow the definition of event structures that
closely parallel the definition of reactions in path-
way representations such as SBML and BioPAX.
These pathway representations differentiate be-
tween three primary groups of reaction partici-
pants: reactants (?inputs?), products (?outputs?),
and modifiers, where the specific roles of modi-
fiers can be further identified to differentiate e.g.
1http://www.ebi.ac.uk/sbo/main/
2http://www.pantherdb.org/pathway/
3http://www.ebi.ac.uk/biomodels-main/
reaction catalysts from inhibitors. Correspond-
ingly, the PC task applies the Theme role defined
in previous BioNLP ST tasks to capture reactants,
introduces a new Product role for products, and
applies the previously defined Cause role and reg-
ulatory events to capture modifiers (Figure 2; see
also Section 2.3).
It is important to note that while the event repre-
sentation allows a one-to-one mapping to reactions
in principle, an annotation scheme cannot guar-
antee that actual statements in text map to fully
specified reactions: in free-form text, authors fre-
quently omit mention of some entities taking part
in reactions, perhaps most typically to avoid re-
dundancies such as in ?p38? is phosphorylated
into phospho-p38?? (Figure 2b). Representations
extracted from explicit statements in text will thus
in some cases omit aspects of the corresponding
complete reactions in pathway models.
Systems addressing the PC task are expected to
extract events of specific types given 1) free-form
text and 2) gold standard annotation for mentions
of physical entities in that text. The task annota-
tions also include equivalence relations and event
modifications, a secondary extraction target. The
annotation types are detailed below.
2.1 Entities
The entity annotation marks mentions of physical
entities using start and end offsets in text (contigu-
ous span) and a type selected from a fixed set. The
following four entity types are marked in the PC
task: SIMPLE CHEMICAL, annotated with refer-
ence to the Chemical Entities of Biological Inter-
est (ChEBI) resource (Degtyarenko et al, 2008);
68
Entity type Scope Reference Ontology ID
SIMPLE CHEMICAL simple, non-repetitive chemical entities ChEBI SBO:0000247
GENE OR GENE PRODUCT genes, RNA and proteins gene/protein DBs SBO:0000246
COMPLEX entities of non-covalently linked components complex DBs SBO:0000253
CELLULAR COMPONENT parts of cell and extracellular environment GO-CC SBO:0000290
Table 1: Entity types, definitions, and reference resources.
Event type Core arguments Additional arguments Ontology ID
CONVERSION Theme:Molecule, Product:Molecule SBO:0000182
PHOSPHORYLATION Theme:Molecule, Cause:Molecule Site:SIMPLE CHEMICAL SBO:0000216
DEPHOSPHORYLATION Theme:Molecule, Cause:Molecule Site:SIMPLE CHEMICAL SBO:0000330
(Other modifications, such as ACETYLATION, defined similarly.)
LOCALIZATION Theme:Molecule At/From/ToLoc:CELL. COMP. GO:0051179
TRANSPORT Theme:Molecule From/ToLoc:CELL. COMP. SBO:0000185
GENE EXPRESSION Theme:GENE OR GENE PRODUCT GO:0010467
TRANSCRIPTION Theme:GENE OR GENE PRODUCT SBO:0000183
TRANSLATION Theme:GENE OR GENE PRODUCT SBO:0000184
DEGRADATION Theme:Molecule SBO:0000179
BINDING Theme:Molecule, Product:COMPLEX SBO:0000177
DISSOCIATION Theme:COMPLEX, Product:Molecule SBO:0000180
REGULATION Theme:ANY, Cause:ANY GO:0065007
POSITIVE REGULATION Theme:ANY, Cause:ANY
GO:0048518,
GO:0044093
ACTIVATION Theme:Molecule, Cause:ANY SBO:0000412
NEGATIVE REGULATION Theme:ANY, Cause:ANY
GO:0048519,
GO:0044092
INACTIVATION Theme:Molecule, Cause:ANY SBO:0000412
PATHWAY Participant:Molecule SBO:0000375
Table 2: Event types and arguments. ?Molecule? refers to an entity annotation of any of the types
SIMPLE CHEMICAL, GENE OR GENE PRODUCT, or COMPLEX, and ?ANY? refers to an annotation of
any type, either entity or event. The indentation corresponds to ontological relationships between the
event types: for example, PHOSPHORYLATION is-a CONVERSION and TRANSCRIPTION part-of
GENE EXPRESSION.
GENE OR GENE PRODUCT, annotated with refer-
ence to gene and protein databases such as UniProt
(Consortium, 2011), Entrez Gene (Maglott et al,
2005) and PFam (Finn et al, 2010); COMPLEX,
annotated with reference to database resources
covering complexes; and CELLULAR COMPO-
NENT, annotated following the scope of the Gene
Ontology cellular component subontology
(Ashburner et al, 2000) (Table 1). For discussion
of the relation between these types and the repre-
sentations applied in pathway models, we refer to
Ohta et al (2011c).
In terms of mention types in text, the annotation
for SIMPLE CHEMICAL, GENE OR GENE PROD-
UCT and COMPLEX covers entity name mentions
only, while the annotation for CELLULAR COM-
PONENT covers entity name mentions, nominal
mentions, and adjectival references (e.g. ?mito-
chondrial?).
2.2 Relations
The PC task defines one relation type, Equiv
(equivalence), which can hold between entity
mitogen-activated protein kinase (MAPK, also known as ERK)
Gene or gene product GGP GGPEquivEquiv
Figure 3: Example Equiv annotation.
mentions of the same type and specifies that they
refer to the same real-world entity (Figure 3).
These relations are only applied to determine if
two events match during evaluation, where entities
connected by an Equiv relation are considered in-
terchangeable. Gold standard Equiv relations are
applied also for test data, and systems participat-
ing in the task are not expected to extract these
relations.
2.3 Events
The event annotation marks references to reac-
tions, processes and comparable associations in
scope of the annotation using the event represen-
tation. For the definition and scope of the event
annotation, we rely primarily on the Systems Biol-
ogy Ontology (SBO), drawing some general types
not in scope of this ontology from the Gene Ontol-
ogy (GO). Table 2 presents the event types anno-
69
Pathway Repository ID Publication
mTOR BioModels MODEL1012220002 (Caron et al, 2010)
mTORC1 upstream regulators BioModels MODEL1012220003 (Caron et al, 2010)
TLR BioModels MODEL2463683119 (Oda and Kitano, 2006)
Yeast Cell Cycle BioModels MODEL1011020000 (Kaizu et al, 2010)
Rb BioModels MODEL4132046015 (Calzone et al, 2008)
EGFR BioModels MODEL2463576061 (Oda et al, 2005)
Human Metabolic Network BioModels MODEL6399676120 (Duarte et al, 2007)
NF-kappaB pathway - - (Oda et al, 2008)
p38 MAPK PANTHER DB P05918 -
p53 PANTHER DB P00059 -
p53 feedback loop pathway PANTHER DB P04392 -
Wnt signaling pathway PANTHER DB P00057 -
Table 3: Pathway models used to select documents for the task, with pathway repository model identifiers
and publications presenting each model (when applicable).
tated in the PC task and their arguments. We refer
again to Ohta et al (2011c) for detailed discussion
of the relation between these types and other rep-
resentations applied in pathway models.
The role in which each event argument (entity
or other event) participates in an event is specified
as one of the following:
Theme entity/event that undergoes the effects of
the event. For example, the entity that is tran-
scribed in a TRANSCRIPTION event or transported
in a TRANSPORT event.
Cause entity/event that is causally active in the
event. Marks, for example, ?P1? in ?P1 inhibits P2
expression?.
AtLoc,FromLoc,ToLoc : location in which the
Theme entity of a LOCALIZATION event is local-
ized (At) in LOCALIZATION events not involving
movement or is transported (or moves) from/to
(From/To) in LOCALIZATION and TRANSPORT
events involving movement.
Site site on the Theme entity that is modified in
the event. Can be specified for modification events
such as PHOSPHORYLATION.
Participant general role type identifying an en-
tity that participates in some underspecified way in
a high-level process. Only applied for the PATH-
WAY type.
2.4 Event modifications
In addition to events, the PC task defines a sec-
ondary extraction target, event modifications. Two
modification types are defined: NEGATION and
SPECULATION. Both are binary flags that mod-
ify events, the former marking an event as be-
ing explicitly stated as not occurring (e.g. ?P is
not phosphorylated?) and the latter as being stated
in a speculative context (?P may be phosphory-
lated.?). Both are defined in terms of annotation
scope and semantics identically as in the BioNLP
ST?09 (Kim et al, 2009).
2.5 Evaluation
The PC task evaluation applies the standard evalu-
ation criteria established in the BioNLP ST 2009.
These criteria relax exact matching between gold
and predicted events in two aspects: approximate
trigger boundary matching, and approximate re-
cursive event matching. The former allows pre-
dicted event triggers to differ from gold triggers
by one word, and the latter requires recursively re-
ferred events to only match in their core arguments
(see Table 2). We refer to Kim et al (2011) for a
detailed definition of these criteria.
3 Corpus
This section presents the PC task corpus and its
annotation process.
3.1 Document selection
To assure that the documents annotated for the PC
task corpus are relevant to pathway reactions, we
applied two complementary approaches, both se-
lecting documents on the basis of relevance to a
specific pathway reaction. First, we selected from
the BioModels repository those pathway models
with the largest numbers of manually created an-
notations referencing a specific PubMed document
identifier. For each of these models, we extracted
literature references, selected a random subset,
downloaded the documents, and manually filtered
to select abstracts that explicitly discuss relevant
molecular reactions. Second, as only a small sub-
set of models include explicit references to the
70
literature providing evidence for specific pathway
reactions, we applied an alternative strategy where
reactions from a selection of PANTHER DB mod-
els were entered into the PathText system (Kem-
per et al, 2010),4 which is capable of suggest-
ing documents relevant to given reactions based
on an SBML model. We then selected a random
set of reactions to query the system, and manually
evaluated the highest-ranking documents to iden-
tify those whose abstracts explicitly discuss the se-
lected reaction. We refer to Miwa et al (2013a)
for a detailed description of this approach. Table 3
presents the pathway models on which the docu-
ment selection was based.
3.2 Annotation process
The base entity annotation for the PC corpus was
created automatically using state-of-the-art entity
mention taggers for each of the targeted entity
types. For SIMPLE CHEMICAL tagging, the OS-
CAR4 system (Jessop et al, 2011) trained on
the chemical named entity recognition corpus of
Corbett and Copestake (2008) was applied. For
GENE OR GENE PRODUCT mention detection, the
NERsuite5 system trained on the BioCreative 2
Gene Mention task (Wilbur et al, 2007) corpus
was used. NERsuite was also applied for CEL-
LULAR COMPONENT mention detection, for this
task trained on the Anatomical Entity Mention
(AnEM) corpus (Ohta et al, 2012). Finally, COM-
PLEX annotations were created using a combi-
nation of a dictionary and heuristics making use
of the GENE OR GENE PRODUCT annotation (for
mentions such as ?cyclin E/CDK2 complex?). To
support the curation process, these tools were in-
tegrated into the NaCTeM text-analysis workflow
system Argo (Rak et al, 2012).
Based on the evaluations of each of these tools
in the studies presenting them, we expected initial
automatic tagging performance to be in the range
80-90% in both precision and recall. Following
initial automatic annotation, the entity mention an-
notation was manually revised to improve quality
and consistency. As the entity annotation is not
itself a target of extraction in the shared task, we
did not separately evaluate the consistency of the
revised entity mention annotation.
To assure that the quality and consistency of
the event annotation are as high as possible, ini-
4http://nactem.ac.uk/pathtext/
5http://nersuite.nlplab.org/
Item Train Devel Test Total
Documents 260 90 175 525
Words 53811 18579 35966 108356
Entities 7855 2734 5312 15901
Events 5992 2129 4004 12125
Modifications 317 80 174 571
Table 4: PC corpus statistics
tial event annotation was created entirely man-
ually, without automatic support. This annota-
tion effort was carried out using the BRAT anno-
tation tool (Stenetorp et al, 2012) by a group of
biologists in collaboration between NaCTeM and
KISTI. Following initial annotator training and re-
finement of guidelines based on the event type def-
initions provided by the reference ontologies, the
primary event annotation was created by three bi-
ologists. To evaluate and maintain annotation con-
sistency, a random 20% of documents were an-
notated redundantly by all annotators, and these
overlapping annotations were periodically evalu-
ated and differences in annotation were discussed
between the annotators and annotation coordina-
tors. Following initial annotation, a round of semi-
automatic consistency checks were applied using
BRAT. Evaluation of the redundantly annotated
documents using the primary task evaluation cri-
teria gave an inter-annotator agreement of 61.0%
in F-score. For the final corpus, the redundantly
annotated documents were evaluated separately by
an annotation coordinator to select the best of each
set.6
The overall statistics of the corpus are summa-
rized in Table 4. We note that the among the
previous BioNLP ST corpora, only the GENIA
(GE) task corpus has a larger number of annotated
events than the PC corpus.
4 Results
4.1 Participation
Two groups submitted final results to the PC
task, one from the National Centre for Text Min-
ing (NaCTeM) and one from the University of
Turku BioNLP group (TEES-2.1) (Table 5). Both
participants applied their well-established, state-
of-the-art event extraction systems, EventMine7
(Miwa et al, 2012) (NaCTeM) and the Turku
6This selection implies that the consistency of the event
annotation of the final corpus is expected to exceed the 61%
F-score of the IAA experiment. Consistency after selection
was not separately evaluated.
7http://nactem.ac.uk/EventMine/
71
NLP Events Other resources
Rank Team Org Word Parse Trig. Arg. Group. Modif. Corpora Other
1 NaCTeM 1NLP Snowball Enju, GDep SVM SVM SVM SVM (see text) triggers
2 TEES-2.1 1BI Porter McCCJ + SD SVM SVM SVM SVM GE hedge words
Table 5: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician,
NLP=Natural Language Processing researcher, McCCJ=McClosky-Charniak-Johnson parser, Char-
niak=Charniak parser, SD=Stanford Dependency conversion, GE=GE task corpus.
Team recall prec. F-score
NaCTeM 52.23 53.48 52.84
TEES-2.1 47.15 55.78 51.10
Table 6: Primary evaluation results
Event Extraction System8 (Bjo?rne et al, 2011)
(TEES). The two systems share the same over-
all architecture, a one-best pipeline with SVM-
based stages for event trigger detection, trigger-
argument relation detection, argument grouping
into event structures, and modification prediction.
The feature representations of both systems draw
on substructures of dependency-like representa-
tions of sentence syntax, derived from full parses
of input sentences. TEES applies the Charniak
and Johnson (2005) parser with the McClosky
(2009) biomedical model, converting the phrase-
structure parses into dependencies using the Stan-
ford tools (de Marneffe et al, 2006). By contrast,
EventMine uses a combination of the predicate-
argument structure analyses created by the deep
parser Enju (Miyao and Tsujii, 2008) and the out-
put of the the GDep best-first shift-reduce depen-
dency parser (Sagae and Tsujii, 2007). All three
parsers have models trained in part on the biomed-
ical domain GENIA treebank (Tateisi et al, 2005).
Interestingly, both systems make use of the GE
task data, but the application of EventMine ex-
tends on this considerably by applying a stacked
model (Miwa et al, 2013b) with predictions also
from models trained on the BioNLP ST 2011 EPI
and ID tasks (Pyysalo et al, 2012) as well as from
four corpora introduced outside of the shared tasks
by Thompson et al (2011), Pyysalo et al (2011),
Ohta et al (2011b) and Ohta et al (2011c).
4.2 Evaluation results
Table 6 summarizes the primary evaluation results.
The two systems demonstrate broadly similar per-
formance in terms of F-scores, with NaCTeM
achieving an 1.7% point higher overall result.
8http://jbjorne.github.io/TEES/
However, the systems show quite different per-
formance in terms of the precision/recall balance:
while the NaCTeM system has little difference
between precision and recall, TEES-2.1 shows a
clear preference for precision, with 8.6% lower re-
call than precision.
Results are shown separately for each event type
in Table 7. The results largely mirror the over-
all performance, with the NaCTeM system show-
ing better performance for 13 out of the 21 event
types present in the test data and more balanced
precision and recall than TEES-2.1, which em-
phasizes precision over recall for almost all event
types. Although the results do not include evalu-
ation of EventMine with a reduced set of stacked
models in training, the modest difference in per-
formance suggests that comprehensive use of pre-
viously released event resources in EventMine did
not confer a decisive advantage, perhaps in part
due to differences in the event definitions between
the PC task and previous resources.
Overall, the two systems appear quite similar
not only in architecture but also performance, with
the clearest systematic difference observed being
the different emphases on precision vs. recall. As
both systems are based on machine learning meth-
ods with real-valued outputs, it would be relatively
straightforward to use prediction confidences to
analyse performance over the entire precision-
recall curve instead of a single fixed point. Such
analysis could provide further insight into the rel-
ative strengths and weaknesses of these two sys-
tems.
5 Discussion
Although participation in this initial run of the PC
task was somewhat limited, the two participating
systems have been applied to a large variety of
event extraction tasks over the last years and have
shown consistently competitive performance with
the state of the art (Bjo?rne and Salakoski, 2011;
Miwa et al, 2012). It is thus reasonable to as-
sume that the higher performance achieved by the
72
NaCTeM TEES-2.1
Event recall prec. F-score recall prec. F-score
CONVERSION 34.33 35.48 34.90 35.82 42.86 39.02
PHOSPHORYLATION 62.46 55.94 59.02 53.40 66.00 59.03
DEPHOSPHORYLATION 45.00 56.25 50.00 35.00 77.78 48.28
ACETYLATION 69.57 72.73 71.11 82.61 76.00 79.17
DEACETYLATION 33.33 33.33 33.33 0.00 0.00 0.00
METHYLATION 42.86 60.00 50.00 57.14 80.00 66.67
DEMETHYLATION 100.00 100.00 100.00 100.00 100.00 100.00
UBIQUITINATION 52.94 64.29 58.06 58.82 76.92 66.67
DEUBIQUITINATION 100.00 100.00 100.00 100.00 100.00 100.00
LOCALIZATION 42.25 61.22 50.00 43.66 54.39 48.44
TRANSPORT 65.52 61.29 63.33 56.55 59.85 58.16
GENE EXPRESSION 90.65 83.15 86.74 84.55 79.39 81.89
TRANSCRIPTION 71.15 82.22 76.29 57.69 73.17 64.52
TRANSLATION 0.00 0.00 0.00 50.00 100.00 66.67
Simple-total 66.42 64.80 65.60 60.40 67.87 63.92
DEGRADATION 78.57 89.19 83.54 78.57 78.57 78.57
ACTIVATION 78.54 70.96 74.56 72.06 72.06 72.06
INACTIVATION 44.62 55.77 49.57 38.46 45.45 41.67
BINDING 64.96 47.30 54.74 53.96 53.96 53.96
DISSOCIATION 38.46 46.88 42.25 35.90 45.16 40.00
PATHWAY 84.91 75.50 79.93 70.94 75.50 73.15
General-total 69.07 62.69 65.72 61.16 65.74 63.37
REGULATION 33.33 33.97 33.65 29.73 39.51 33.93
POSITIVE REGULATION 35.49 42.81 38.81 34.51 45.45 39.23
NEGATIVE REGULATION 45.75 50.64 48.07 41.02 47.37 43.97
Regulation-total 37.73 42.79 40.10 35.17 44.76 39.39
Sub-total 53.47 53.96 53.72 48.23 56.22 51.92
NEGATION 24.52 35.87 29.13 25.16 41.30 31.27
SPECULATION 15.79 22.22 18.46 0.00 0.00 0.00
Modification-total 23.56 34.65 28.05 22.41 40.00 28.73
Total 52.23 53.48 52.84 47.15 55.78 51.10
Table 7: Primary evaluation results by event type.
task participants, a balanced F-score of 52.8%, is
a good estimate of the performance level that can
be attained for this task by present event extraction
technology.
The results achieved by the two systems are
broadly comparable to the best results achieved by
any system in similar previously introduced event
extraction tasks (Kim et al, 2012; Pyysalo et al,
2012). Given the novelty of the task domain and
reference resource and the broad selection of doc-
uments, we find the results highly encouraging re-
garding the applicability of event extraction tech-
nology to supporting the development, evaluation,
and maintenance of pathway models.
6 Conclusions
This paper presented the Pathway Curation (PC)
task, a main event extraction task of the BioNLP
ST 2013. The task was organized in collaboration
between groups with an interest in pathway cura-
tion with the aim of evaluating and advancing the
state of the art in event extraction toward methods
for developing, evaluating and maintaining formal
pathway models in representations such as SBML
and BioPAX. We introduced an event extraction
task setting with reference to pathway model stan-
dards and the Systems Biology Ontology, selected
a set of 525 publication abstracts relevant to spe-
cific model reactions, and created fully manual
73
event annotation marking over 12,000 event struc-
tures in the corpus.
Two participants in the BioNLP ST 2013 sub-
mitted final predictions to the PC task, applying
established, state-of-the-art event extraction sys-
tems, EventMine and the Turku Event Extrac-
tion System. Both systems achieved F-scores
over 50%, with the EventMine system achiev-
ing the best overall result of 52.8%. This level
of performance is broadly comparable with re-
sults achieved in comparable previously proposed
tasks, indicating that current event extraction tech-
nology is applicable to the projected pathway cu-
ration support tasks.
To allow the further development and evalua-
tion of event extraction methods for the task, the
PC task continues as an open challenge to all inter-
ested participants, with the annotated corpus data,
supporting resources, and evaluation tools avail-
able under open licenses from the task homepage,
http://2013.bionlp-st.org/
Acknowledgments
We would like to thank Yonghwa Jo, Hyeyeon
Choi, Jeong-Ik Lee and Ssang-Goo Cho of
Konkuk University for their contribution to the de-
velopment of the relevance judgment annotation
criteria. We also wish to thank Hyun Uk Kim,
Jinki Kim and Kyusang Hwang of KAIST for
their efforts in producing the PC task annotation.
This work is a part of joint research of KISTI and
NaCTeM, and partially supported by the Biotech-
nology and Biological Sciences Research Council
(BBSRC) [BB/G53025X/1].
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and Dou-
glas B. Kell. 2010. Event extraction for systems biology
by text mining the literature. Trends in Biotechnology,
28(7):381?390.
Michael Ashburner, Catherine A. Ball, Judith A. Blake,
David Botstein, Heather Butler, J. Michael Cherry, Al-
lan P. Davis, Kara Dolinski, et al 2000. Gene ontology:
tool for the unification of biology. Nature genetics, 25:25?
29.
Jari Bjo?rne and Tapio Salakoski. 2011. Generalizing
biomedical event extraction. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 183?191.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola, Tapio
Pahikkala, and Tapio Salakoski. 2011. Extracting contex-
tualized complex biological events with rich graph-based
feature sets. Computational Intelligence, 27(4):541?557.
Laurence Calzone, Ame?lie Gelay, Andrei Zinovyev, Franc?ois
Radvanyl, and Emmanuel Barillot. 2008. A comprehen-
sive modular map of molecular interactions in rb/e2f path-
way. Molecular systems biology, 4(1).
Etienne Caron, Samik Ghosh, Yukiko Matsuoka, Dariel
Ashton-Beaucage, Marc Therrien, Se?bastien Lemieux,
Claude Perreault, Philippe P Roux, and Hiroaki Kitano.
2010. A comprehensive map of the mtor signaling net-
work. Molecular systems biology, 6(1).
Eugene Charniak and Mark Johnson. 2005. Coarse-to-Fine
n-Best Parsing and MaxEnt Discriminative Reranking. In
Proceedings of ACL?05, pages 173?180.
The UniProt Consortium. 2011. Ongoing and future devel-
opments at the universal protein resource. Nucleic Acids
Research, 39(suppl 1):D214?D219.
Peter Corbett and Ann Copestake. 2008. Cascaded classifiers
for confidence-based chemical named entity recognition.
BMC Bioinformatics, 9(Suppl 11):S4.
Me?lanie Courtot, Nick Juty, Christian Knu?pfer, Dagmar Wal-
temath, Anna Zhukova, Andreas Dra?ger, Michel Dumon-
tier, Andrew Finney, Martin Golebiewski, Janna Hastings,
et al 2011. Controlled vocabularies and semantics in sys-
tems biology. Molecular systems biology, 7(1).
Marie-Catherine de Marneffe, Bill MacCartney, and Christo-
pher D Manning. 2006. Generating typed dependency
parses from phrase structure parses. In Proceedings of
LREC, volume 6, pages 449?454.
Kirill Degtyarenko, Paula De Matos, Marcus Ennis, Janna
Hastings, Martin Zbinden, Alan Mcnaught, Rafael
Alca?ntara, Michael Darsow, Mickae?l Guedj, and Michael
Ashburner. 2008. Chebi: a database and ontology for
chemical entities of biological interest. Nucleic acids re-
search, 36(suppl 1):D344?D350.
Natalie C Duarte, Scott A Becker, Neema Jamshidi, Ines
Thiele, Monica L Mo, Thuy D Vo, Rohith Srivas, and
Bernhard ? Palsson. 2007. Global reconstruction of
the human metabolic network based on genomic and bib-
liomic data. Proceedings of the National Academy of Sci-
ences, 104(6):1777?1782.
Robert D. Finn, Jaina Mistry, John Tate, Penny Coggill, An-
dreas Heger, Joanne E. Pollington, O. Luke Gavin, Prasad
Gunasekaran, et al 2010. The Pfam protein families
database. Nucleic Acids Research, 38(suppl 1):D211?
D222.
Michael Hucka, Andrew Finney, Herbert M Sauro, Hamid
Bolouri, John C Doyle, Hiroaki Kitano, Adam P Arkin,
Benjamin J Bornstein, et al 2003. The systems biology
markup language (SBML): a medium for representation
and exchange of biochemical network models. Bioinfor-
matics, 19(4):524?531.
David M. Jessop, Sam Adams, Egon L. Willighagen, Lezan
Hawizy, and Peter Murray-Rust. 2011. Oscar4: a flexible
architecture for chemical text-mining. Journal of chemin-
formatics, 3(1):1?12.
Kazunari Kaizu, Samik Ghosh, Yukiko Matsuoka, Hisao
Moriya, Yuki Shimizu-Yoshida, and Hiroaki Kitano.
2010. A comprehensive molecular interaction map of the
budding yeast cell cycle. Molecular systems biology, 6(1).
Brian Kemper, Takuya Matsuzaki, Yukiko Matsuoka, Yoshi-
masa Tsuruoka, Hiroaki Kitano, Sophia Ananiadou, and
Jun?ichi Tsujii. 2010. Pathtext: a text mining integra-
tor for biological pathway visualizations. Bioinformatics,
26(12):i374?i381.
74
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu
Kano, and Jun?ichi Tsujii. 2009. Overview of BioNLP?09
Shared Task on Event Extraction. In Proceedings of
BioNLP?09.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu
Kano, and Junichi Tsujii. 2011. Extracting bio-molecular
events from literature ? the bionlp?09 shared task. Com-
putational Intelligence, 27(4):513?540.
Jin-Dong Kim, Ngan Nguyen, Yue Wang, Jun?ichi Tsujii,
Toshihisa Takagi, and Akinori Yonezawa. 2012. The
genia event and protein coreference tasks of the bionlp
shared task 2011. BMC bioinformatics, 13(Suppl 11):S1.
Hiroaki Kitano. 2002. Systems biology: a brief overview.
Science, 295(5560):1662?1664.
Martin Krallinger, Florian Leitner, and Alfonso Valencia.
2007. Assessment of the Second BioCreative PPI task:
Automatic Extraction of Protein-Protein Interactions. In
L. Hirschman, M. Krallinger, and A. Valencia, editors,
Proceedings of BioCreative II, pages 29?39.
Chen Li, Marco Donizelli, Nicolas Rodriguez, Harish
Dharuri, Lukas Endler, Vijayalakshmi Chelliah, Lu Li,
Enuo He, et al 2010. BioModels Database: An enhanced,
curated and annotated resource for published quantitative
kinetic models. BMC Systems Biology, 4:92.
Chen Li, Maria Liakata, and Dietrich Rebholz-Schuhmann.
2013. Biological network extraction from scientific litera-
ture: state of the art and challenges. Briefings in bioinfor-
matics.
Donna Maglott, Jim Ostell, Kim D. Pruitt, and Tatiana
Tatusova. 2005. Entrez gene: gene-centered information
at ncbi. Nucleic Acids Research, 33(suppl 1):D54.
David McClosky. 2009. Any Domain Parsing: Automatic
Domain Adaptation for Natural Language Parsing. Ph.D.
thesis, Brown University.
Huaiyu Mi and Paul Thomas. 2009. PANTHER pathway: an
ontology-based pathway database coupled with data anal-
ysis tools. In Protein Networks and Pathway Analysis,
pages 123?140. Springer.
Huaiyu Mi, Anushya Muruganujan, Emek Demir, Yukiko
Matsuoka, Akira Funahashi, Hiroaki Kitano, and Paul D
Thomas. 2011. Biopax support in celldesigner. Bioinfor-
matics, 27(24):3437?3438.
Makoto Miwa, Paul Thompson, and Sophia Ananiadou.
2012. Boosting automatic event extraction from the liter-
ature using domain adaptation and coreference resolution.
Bioinformatics, 28(13):1759?1765.
Makoto Miwa, Tomoko Ohta, Rafal Rak, Andrew Rowley,
Douglas B. Kell, Sampo Pyysalo, and Sophia Ananiadou.
2013a. A method for integrating and ranking the evidence
for biochemical pathways by mining reactions from text.
Bioinformatics. in press.
Makoto Miwa, Sampo Pyysalo, Tomoko Ohta, and Sophia
Ananiadou. 2013b. Wide coverage biomedical event
extraction using multiple partially overlapping corpora.
BMC bioinformatics, 14(1):175.
Yusuke Miyao and Jun?ichi Tsujii. 2008. Feature forest mod-
els for probabilistic HPSG parsing. Computational Lin-
guistics, 34(1):35?80.
Kanae Oda and Hiroaki Kitano. 2006. A comprehensive
map of the toll-like receptor signaling network. Molecular
Systems Biology, 2(1).
Kanae Oda, Yukiko Matsuoka, Akira Funahashi, and Hiroaki
Kitano. 2005. A comprehensive pathway map of epider-
mal growth factor receptor signaling. Molecular systems
biology, 1(1).
Kanae Oda, Jin-Dong Kim, Tomoko Ohta, Daisuke
Okanohara, Takuya Matsuzaki, Yuka Tateisi, and Jun?ichi
Tsujii. 2008. New challenges for text mining: mapping
between text and manually curated pathways. BMC bioin-
formatics, 9(Suppl 3):S5.
Tomoko Ohta, Sampo Pyysalo, Sophia Ananiadou, and Ju-
nichi Tsujii. 2011a. Pathway curation support as an infor-
mation extraction task. Proceedings of LBM?11.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, and Jun?ichi
Tsujii. 2011b. Event extraction for dna methylation.
Journal of Biomedical Semantics, 2(Suppl 5):S2.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011c.
From pathways to biomolecular events: opportunities and
challenges. In Proceedings of BioNLP?11, pages 105?
113.
Tomoko Ohta, Sampo Pyysalo, Jun?ichi Tsujii, and Sophia
Ananiadou. 2012. Open-domain anatomical entity men-
tion detection. In Proceedings of DSSD?12, pages 27?36.
Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari Bjo?rne,
Filip Ginter, and Tapio Salakoski. 2008. Comparative
analysis of five protein-protein interaction corpora. BMC
Bioinformatics, 9(Suppl 3):S6.
Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, and Jun?ichi
Tsujii. 2011. Towards exhaustive event extraction for pro-
tein modifications. In Proceedings of BioNLP?11, pages
114?123.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sullivan,
Chunhong Mao, Chunxia Wang, Bruno Sobral, Jun?ichi
Tsujii, and Sophia Ananiadou. 2012. Overview of the id,
epi and rel tasks of bionlp shared task 2011. BMC bioin-
formatics, 13(Suppl 11):S2.
Rafal Rak, Andrew Rowley, William Black, and Sophia Ana-
niadou. 2012. Argo: an integrative, interactive, text
mining-based workbench supporting curation. Database:
The Journal of Biological Databases and Curation, 2012.
Kenji Sagae and Jun?ichi Tsujii. 2007. Dependency parsing
and domain adaptation with lr models and parser ensem-
bles. In Proceedings of the CoNLL Shared Task Session of
EMNLP-CoNLL 2007, pages 1044?1050.
Pontus Stenetorp, Sampo Pyysalo, Goran Topic?, Tomoko
Ohta, Sophia Ananiadou, and Jun?ichi Tsujii. 2012. Brat:
a web-based tool for nlp-assisted text annotation. In Pro-
ceedings of EACL?12, pages 102?107.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and Junichi
Tsujii. 2005. Syntax annotation for the genia corpus. In
Proceedings of IJCNLP, volume 5, pages 222?227.
Paul Thompson, Raheel Nawaz, John McNaught, and Sophia
Ananiadou. 2011. Enriching a biomedical event corpus
with meta-knowledge annotation. BMC Bioinformatics,
12(1):393.
Domonkos Tikk, Philippe Thomas, Peter Palaga, Jo?rg Haken-
berg, and Ulf Leser. 2010. A comprehensive benchmark
of kernel methods to extract protein-protein interactions
from literature. PLoS Comput Biol, 6(7):e1000837, 07.
John Wilbur, Lawrence Smith, and Lorraine Tanabe. 2007.
BioCreative 2. Gene Mention Task. In L. Hirschman,
M. Krallinger, and A. Valencia, editors, Proceedings of
BioCreative II, pages 7?16.
75
Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 89?97,
Sofia, Bulgaria, August 8-9, 2013. c?2013 Association for Computational Linguistics
Making UIMA Truly Interoperable with SPARQL
Rafal Rak and Sophia Ananiadou
National Centre for Text Mining
School of Computer Science, University of Manchester
{rafal.rak,sophia.ananiadou}@manchester.ac.uk
Abstract
Unstructured Information Management
Architecture (UIMA) has been gaining
popularity in annotating text corpora. The
architecture defines common data struc-
tures and interfaces to support interoper-
ability of individual processing compo-
nents working together in a UIMA appli-
cation. The components exchange data by
sharing common type systems?schemata
of data type structures?which extend a
generic, top-level type system built into
UIMA. This flexibility in extending type
systems has resulted in the development of
repositories of components that share one
or several type systems; however, compo-
nents coming from different repositories,
and thus not sharing type systems, remain
incompatible. Commonly, this problem
has been solved programmatically by im-
plementing UIMA components that per-
form the alignment of two type systems,
an arduous task that is impractical with a
growing number of type systems. We al-
leviate this problem by introducing a con-
version mechanism based on SPARQL, a
query language for the data retrieval and
manipulation of RDF graphs. We pro-
vide a UIMA component that serialises
data coming from a source component
into RDF, executes a user-defined, type-
conversion query, and deserialises the up-
dated graph into a target component. The
proposed solution encourages ad hoc con-
versions, enables the usage of heteroge-
neous components, and facilitates highly
customised UIMA applications.
1 Introduction
Unstructured Information Management Architec-
ture (UIMA) (Ferrucci and Lally, 2004) is a frame-
work that supports the interoperability of media-
processing software components by defining com-
mon data structures and interfaces the compo-
nents exchange and implement. The architec-
ture has been gaining interest from academia and
industry alike for the past decade, which re-
sulted in a multitude of UIMA-supporting repos-
itories of analytics. Notable examples include
METANET4U components (Thompson et al,
2011) featured in U-Compare1, DKPro (Gurevych
et al, 2007), cTAKES (Savova et al, 2010),
BioNLP-UIMA Component Repository (Baum-
gartner et al, 2008), and JULIE Lab?s UIMA
Component Repository (JCoRe) (Hahn et al,
2008).
However, despite conforming to the UIMA
standard, each repository of analytics usually
comes with its own set of type systems, i.e., rep-
resentations of data models that are meant to be
shared between analytics and thus ensuring their
interoperability. At present, UIMA does not fa-
cilitate the alignment of (all or selected) types be-
tween type systems, which makes it impossible to
combine analytics coming from different reposito-
ries without an additional programming effort. For
instance, NLP developers may want to use a sen-
tence detector from one repository and a tokeniser
from another repository only to learn that the re-
quired input Sentence type for the tokeniser is
defined in a different type system and namespace
than the output Sentence type of the sentence
detector. Although both Sentence types repre-
sent the same concept and may even have the same
set of features (attributes), they are viewed as two
distinct types by UIMA.
Less trivial incompatibility arises from the same
concept being encoded as structurally different
types in different type systems. Figures 1 and 2
show fragments of some of existing type systems;
1http://nactem.ac.uk/ucompare/
89
(a) DKPro (b) JCoRe (c) ACE
Figure 1: UML diagrams representing fragments of type systems that show differences in encoding
coreferences.
specifically, they show the differences in encod-
ing coreferences and events, respectively. For in-
stance, in comparison to the JCoRe type system in
Figure 1(b), the DKPro type system in Figure 1(a)
has an additional type that points to the beginning
of the linked list of coreferences.
Conceptually similar types in two different type
systems may also be incompatible in terms of the
amount of information they convey. Compare, for
instance, type systems in Figure 2 that encode a
similar concept, event. Not only are they struc-
turally different, but the cTAKES type system in
Figure 2(a) also involves a larger number of fea-
tures than the other two type systems. Although,
in this case, the alignment of any two structures
cannot be carried out without a loss or deficiency
of information, it may still be beneficial to do so
for applications that consist of components that ei-
ther fulfill partially complete information or do not
require it altogether.
The available type systems vary greatly in size,
their modularity, and intended applicability. The
DKPro UIMA software collection, for instance,
includes multiple, small-size type systems organ-
ised around specific syntactic and semantic con-
cepts, such as part of speech, chunks, and named
entities. In contrast, the U-Compare project as
well as cTAKES are oriented towards having a sin-
gle type system. Respectively, the type systems
define nearly 300 and 100 syntactic and seman-
tic types, with U-Compare?s semantic types biased
towards biology and chemistry and cTAKES?s
covering clinical domain. Most of the U-Compare
types extend a fairly expressive higher-level type,
which makes them universally applicable, but at
the same time, breaks their semantic cohesion.
The lack of modularity and the all-embroiling
types suggest that the U-Compare type system is
developed primarily to work with the U-Compare
application.
The Center for Computational Pharmacology
(CCP) type system (Verspoor et al, 2009) is a
radically different approach to the previous sys-
tems. It defines a closed set of top-level types
that facilitate the use of external resources, such
as databases and ontologies. This gives the advan-
tage of having a nonvolatile type system, indiffer-
ent to changes in the external resources, as well as
greater flexibility in handling some semantic mod-
els that would otherwise be impossible to encode
in a UIMA type system. On the other hand, such
an approach shifts the handling of interoperability
from UIMA to applications that must resolve com-
patibility issues at runtime, which also results in
the weakly typed programming of analytics. Addi-
tionally, the UIMA?s native indexing of annotation
types will no longer work with such a type system,
which prompts an additional programming effort
from developers.
The aforementioned examples suggest that es-
tablishing a single type system that could be
shared among all providers is unlikely to ever take
place due to the variability in requirements and
applicability. Instead, we adopt an idea of us-
ing a conversion mechanism that enables align-
ing types across type systems. The conversion
has commonly been solved programmatically by
creating UIMA analytics that map all or (more
likely) selected types between two type systems.
For instance, U-Compare features a component
that translates some of the CPP types into the U-
Compare types. The major drawback of such a
solution is the necessity of having to implement
an analytic which requires programming skills and
becomes an arduous task with an increasing num-
ber of type systems. In contrast, we propose a
conversion based entirely on developers? writing a
query in the well established SPARQL language,
90
(a) cTAKES (b) ACE
(c) Events Type System
Figure 2: UML diagrams representing fragments of type systems that show differences in encoding event
structures.
an official W3C Recommendation2. Our approach
involves 1) the serialisation of UIMA?s internal
data structures to RDF3, 2) the execution of a user-
defined, type-conversion SPARQL query, and 3)
the deserialisation of the results back to the UIMA
structure.
The remainder of this paper is organised as fol-
lows. The next section presents related work. Sec-
tion 3 provides background information on UIMA,
RDF and SPARQL. Section 4 discusses the pro-
posed representation of UIMA structures in RDF,
whereas Section 5 examines the utility of our
method. Section 6 details the available implemen-
tation, and Section 7 concludes the paper.
2 Related Work
In practice, type alignment or conversion is the
creation of new UIMA feature structures based
on the existing ones. Current efforts in this
area mostly involve solutions that are essentially
2http://www.w3.org/TR/2013/REC-sparql11-overview-
20130321
3http://www.w3.org/RDF/
(cascaded) finite state transducers, i.e., an in-
put stream of existing feature structures is being
matched against developers? defined patterns, and
if a match is found, a series of actions follows and
results in one or more output structures.
TextMarker (Kluegl et al, 2009) is currently
one of the most comprehensive tools that de-
fines its own rule-based language. The language
capabilities include the definition of new types,
annotation-based regular expression matching and
a rich set of condition functions and actions. Com-
bined with a built-in lexer that produces basic to-
ken annotations, TextMarker is essentially a self-
contained, UIMA-based annotation tool.
Hernandez (2012) proposed and developed a
suite of tools for tackling the interoperability of
components in UIMA. The suite includes uima-
mapper, a conversion tool designed to work with
a rule-based language for mapping UIMA anno-
tations. The rules are encoded in XML, and?
contrary to the previous language that relies solely
on its own syntax?include XPath expressions for
patterns, constraints, and assigning values to new
91
feature structures. This implies that the input of
the conversion process must be encoded in XML.
PEARL (Pazienza et al, 2012) is a language for
projecting UIMA annotations onto RDF reposito-
ries. Similarly to the previous approaches, the lan-
guage defines a set of rules triggered upon encoun-
tering UIMA annotations. The language is de-
signed primarily to work in CODA, a platform that
facilitates population of ontologies with the output
of NLP analytics. Although it does not directly
facilitate the production or conversion of UIMA
types, the PEARL language shares similarities to
our approach in that it incorporates certain RDF
Turtle, SPARQL-like semantics.
Contrary to the aforementioned solutions, we
do not define any new language or syntax. Instead,
we rely completely on an existing data query and
manipulation language, SPARQL. By doing so,
we shift the problem of conversion from the def-
inition of a new language to representing UIMA
structures in an existing language, such that they
can be conveniently manipulated in that language.
A separate line of research pertains to the for-
malisation of textual annotations with knowledge
representations such as RDF and OWL4. Buyko et
al. (2008) link UIMA annotations to the reference
ontology OLiA (Chiarcos, 2012) that contains a
broad vocabulary of linguistic terminology. The
authors claim that two conceptually similar type
systems can be aligned with the reference ontol-
ogy. The linking involves the use of OLiA?s as-
sociated annotation and linking ontology model
pairs that have been created for a number of an-
notation schemata. Furthermore, a UIMA type
system has to define additional features for each
linked type that tie a given type to an annotation
model. In effect, in order to convert a type from an
arbitrary type system to another similar type sys-
tem, both systems must be modified and an anno-
tation and linking models must be created. Such
an approach generalises poorly and is unsuitable
for impromptu type system conversions.
3 Background
3.1 UIMA Overview
UIMA defines both structures and interfaces to
facilitate interoperability of individual processing
components that share type systems. Type systems
may be defined in or imported by a processing
component that produces or modifies annotations
4http://www.w3.org/TR/owl2-overview/
Figure 3: UML diagram representing relationships
between CASes, views, and feature structures in
UIMA. The shown type system is a fragment of
the built-in UIMA type system.
in a common annotation structure (CAS), i.e., a
CAS is the container of actual data bound by the
type system.
Types may define multiple primitive features as
well as references to feature structures (data in-
stances) of other types. The single-parent inheri-
tance of types is also possible. The resulting struc-
tures resemble those present in modern object-
oriented programming languages.
Feature structures stored in a CAS may be
grouped into several views, each of which hav-
ing its own subject of analysis (Sofa). For in-
stance, one view may store annotations about
a Sofa that stores an English text, whereas an-
other view may store annotations about a dif-
ferent Sofa that stores a French version of the
same text. UIMA defines built-in types including
primitive types (boolean, integer, string, etc.), ar-
rays, lists, as well as several complex types, e.g.,
uima.tcas.Annotation that holds a refer-
ence to a Sofa the annotation is asserted about, and
two features, begin and end, for marking bound-
aries of a span of text. The relationships be-
tween CASes, views, and several prominent built-
in types are shown in Figure 3.
The built-in complex types may further
be extended by developers. Custom types
that mark a fragment of text usually extend
uima.tcas.Annotation, and thus inherit
the reference to the subject of analysis, and the
begin and end features.
92
UIMA element/representation RDF resource
CAS <uima:aux:CAS>
Access to CAS?s views rdfs:member or rdf:_1, rdf:_2, ...
View <uima:aux:View>
View?s name <uima:aux:View:name>
View?s Sofa <uima:aux:View:sofa>
Access to view?s feature structures rdfs:member or rdf:_1, rdf:_2, ...
Access to feature structure?s sequential number <uima:aux:seq>
Type uima.tcas.Annotation <uima:ts:uima.tcas.Annotation>
Feature uima.tcas.Annotation:begin <uima:ts:uima.cas.Annotation:begin>
Access to uima.cas.ArrayBase elements rdfs:member or rdf:_1, rdf:_2, ...
Table 1: UIMA elements and their corresponding RDF resource representations
3.2 RDF and SPARQL
Resource Description Framework (RDF) is a
method for modeling concepts in form of making
statements about resources using triple subject-
predicate-object expressions. The triples are com-
posed of resources and/or literals with the latter
available only as objects. Resources are repre-
sented with valid URIs, whereas literals are val-
ues optionally followed by a datatype. Multiple
interlinked subject and objects ultimately consti-
tute RDF graphs.
SPARQL is a query language for fetching data
from RDF graphs. Search patterns are created
using RDF triples that are written in RDF Turtle
format, a human-readable and easy to manipulate
syntax. A SPARQL triple may contain variables
on any of the three positions, which may (and usu-
ally does) result in returning multiple triples from
a graph for the same pattern. If the same variable
is used more than once in patterns, its values are
bound, which is one of the mechanisms of con-
straining results.
Triple-like patterns with variables are simple,
yet expressive ways of retrieving data from an
RDF graph and constitute the most prominent fea-
ture of SPARQL. In this work, we additionally
utilise features of SPARQL 1.1 Update sublan-
guage that facilitates graph manipulation.
4 Representing UIMA in RDF
We use RDF Schema5 as the primary RDF vocab-
ulary to encode type systems and feature struc-
tures in CASes. The schema defines resources
such as rdfs:Class, rdf:type (to denote a
membership of an instance to a particular class)
5http://www.w3.org/TR/rdf-schema/
and rdfs:subClassOf (as a class inheritance
property)6. It is a popular description language for
expressing a hierarchy of concepts, their instances
and relationships, and forms a base for such se-
mantic languages as OWL.
The UIMA type system structure falls nat-
urally into this schema. Each type is ex-
pressed as rdfs:Class and each feature as
rdfs:Property accompanied by appropriate
rdfs:domain and rdfs:range statements.
Feature structures (instances) are then assigned
memberships of their respective types (classes)
through rdf:type properties.
A special consideration is given to the type
ArrayBase (and its extensions). Since the or-
der of elements in an array may be of impor-
tance, feature structures of the type ArrayBase
are also instances of the class rdf:Seq, a se-
quence container, and the elements of an ar-
ray are accessed through the properties rdf:_1,
rdf:_2, etc., which, in turn, are the subprop-
erties of rdfs:member. This enables query-
ing array structures with preserving the order of
its members. Similar, enumeration-property ap-
proach is used for views that are members of
CASes and feature structures that are members of
views. The order for the latter two is defined in the
internal indices of a CAS and follows the order in
which the views and feature structures were added
to those indices.
We also define several auxiliary RDF resources
to represent relationships between CASes, views
and feature structures (cf. Figure 3). We intro-
duced the scheme name ?uima? for the URIs of
6Following RDF Turtle notation we denote prefixed forms
of RDF resources as prefix:suffix and their full forms
as <fullform>
93
Figure 4: Complete SPARQL query that converts
the sentence type in one type system to a struc-
turally identical type in another type system.
the UIMA-related resources. The fully qualified
names of UIMA types and their features are part
of the URI paths. The paths are additionally pre-
fixed by ?ts:? to avoid a name clash against
the aforementioned auxiliary CAS and view URIs
that, in turn, are prefixed with ?aux:?. Table 1
summarises most of the UIMA elements and their
corresponding representations in RDF.
5 Conversion Capabilities
In this section we examine the utility of the
proposed approach and the expressiveness of
SPARQL by demonstrating several conversion ex-
amples. We focus on technical aspects of conver-
sions and neglect issues related to a loss or defi-
ciency of information that is a result of differences
in type system conceptualisation (as discussed in
Introduction).
5.1 One-to-one Conversion
We begin with a trivial case where two types
from two different type systems have exactly the
same names and features; the only difference
lies in the namespace of the two types. Fig-
ure 4 shows a complete SPARQL query that con-
verts (copies) their.Sentence feature struc-
tures to our.Sentence structures. Both types
extend the uima.tcas.Annotation type and
inherit its begin and end features. The WHERE
clause of the query consists of patterns that match
CASes? views and their feature structures of the
type their.Sentence together with the type?s
begin and end features.
For each solution of the WHERE clause (each
retrieved tuple), the INSERT clause then creates a
new sentence of the target type our.Sentence
(the a property is the shortcut of rdf:type)
Figure 5: SPARQL query that aligns different con-
ceptualisations of event structures between two
type systems. Prefix definitions are not shown.
and rewrites the begin and end values to its fea-
tures. The blank node _:sentence is going to
be automatically re-instantiated with a unique re-
source for each matching tuple making each sen-
tence node distinct. The last line of the INSERT
clause ties the newly created sentence to the view,
which is UIMA?s equivalent of indexing a feature
structure in a CAS.
5.2 One-to-many Conversion
In this use case we examine the conversion of
a container of multiple elements to a set of dis-
connected elements. Let us consider event types
from the ACE and Events type systems as shown
in Figures 2(b) and 2(c), respectively. A single
Event structure in the ACE type system aggre-
gates multiple EventMention structures in an
effort to combine multiple text evidence support-
ing the same event. The NamedEvent type in
the Events type system, on the other hand, makes
no such provision and is agnostic to the fact that
multiple mentions may refer to the same event.
94
To avoid confusion, we will refer to the types
using their RDF prefixed notations, ?ace:? and
?gen:?, to denote the ACE and ?generic? Events
type systems, respectively.
The task is to convert all ace:Events
and their ace:EventMentions into
gen:NamedEvents. There is a cou-
ple of nuances that need to be taken
into consideration. Firstly, although both
ace:EventMention and gen:NamedEvent
extend uima.tcas.Annotation, the be-
gin and end features have different mean-
ings for the two event representations. The
gen:NamedEvent?s begin and end features
represent an anchor/trigger, a word in the text that
initiates the event. The same type of informa-
tion is accessible from ace:EventMention
via its anchor feature instead. Secondly,
although it may be tempting to disregard the
ace:Event structures altogether, they contain
the type feature whose value will be copied to
gen:NamedEvent?s name feature.
The SPARQL query that performs that
conversion is shown in Figure 5. In the
WHERE clause, for each ace:Event,
patterns select ace:EventMentions
and for each ace:EventMention,
ace:EventMentionArguments are
also selected. This behaviour resembles
triply nested for loop in programming lan-
guages. Additionally, ace:Event?s type,
ace:EventMention?s anchor begin and end
values, and ace:EventMentionArgument?s
role and target are selected. In contrast to the
previous example, we cannot use blank nodes for
creating event resources in the INSERT clause,
since the retrieved tuples share event URIs for
each ace:EventMentionArgument. Hence
the last two BIND functions create URIs for
each ace:EventMention and its array of
arguments, both of which are used in the INSERT
clause.
Note that in the INSERT clause, if several
gen:NamedEventParticipants share the
same gen:NamedEvent, the definition of the
latter will be repeated for each such participant.
We take advantage of the fact that adding a triple
to an RDF graph that already exists in the graph
has no effect, i.e., an insertion is simply ignored
and no error is raised. Alternatively, the query
could be rewritten as two queries, one that creates
Figure 6: SPARQL query that converts corefer-
ences expressed as linked lists to an array repre-
sentation. Prefix definitions are not shown.
gen:NamedEvent definitions and another that
creates gen:NamedEventParticipant def-
initions.
To recapitulate, RDF and SPARQL support one-
to-many (and many-to-one) conversions by stor-
ing only unique triple statements and by providing
functions that enable creating arbitrary resource
identifiers (URIs) that can be shared between re-
trieved tuples.
5.3 Linked-list-to-Array Conversion
For this example, let us consider two types
of structures for storing coreferences from the
DKPro and ACE type systems, as depicted in Fig-
ures 1(a) and 1(c), respectively.
The idea is to convert DKPro?s chains of links
into ACE?s entities that aggregate entity mentions,
or?using software developers? vocabulary?to
convert a linked list into an array. The SPARQL
query for this conversion is shown in Figure 6.
The WHERE clause first selects all
dkpro:CoreferenceChain instances from
views. Access to dkpro:CoreferenceLink
instances for each chain is provided by a property
95
path. Property paths are convenient shortcuts
for navigating through nodes of an RDF graph.
In this case, the property path expands to the
chain?s first feature/property followed by any
number (signified by the asterisk) of links? next
feature/property. The pattern with this path will
result in returning all links that are accessible
from the originating chain; however, according
to the SPARQL specification, the order of links
is not guaranteed to be preserved, which in
coreference-supporting applications is usually of
interest. A solution is to make use of the property
<uima:aux:seq> that points to the sequential
number of a feature structure and is unique in the
scope of a single CAS. Since feature structures
are serialised into RDF using deep-first traversal,
the consecutive link structures for each chain will
have their sequence numbers monotonically in-
creasing. These sequence numbers are translated
to form rdf:_nn properties (nn standing for the
number), which facilitates the order of elements in
the ace:Entity array of mentions7. It should
be noted, however, that using the sequence num-
ber property will work only if the links of a chain
are not referred to from another structure. There is
another, robust solution (not shown due to space
limitation and complexity) that involves multiple
INSERT queries and temporary, supporting RDF
nodes. RDF nodes that are not directly relevant
to a CAS and its feature structures are ignored
during the deserialisation process, and thus it is
safe to create any number of such nodes.
6 Tool Support
We have developed a UIMA analysis engine,
SPARQL Annotation Editor, that incorporates the
serialisation of a CAS into RDF (following the
protocol presented in Section 4), the execution of
a user-defined SPARQL query, and the deseriali-
sation of the updated RDF graph back to the CAS.
The RDF graph (de)serialisation and SPARQL
query execution is implemented using Apache
Jena8, an open-source framework for building Se-
mantic Web applications.
To further assist in the development of type-
conversion SPARQL queries, we have provided
two additional UIMA components, RDF Writer
and RDF Reader. RDF Writer serialises CASes to
7The rdf:_nn properties are not required to be consec-
utive in an RDF container
8http://jena.apache.org/
files that can then be used with SPARQL query en-
gines, such as Jena Fuseki (part of the Apache Jena
project), to develop and test conversion queries.
The modified RDF graphs can be imported back
to a UIMA application using RDF Reader, an RDF
deserialisation component.
The three components are featured in Argo (Rak
et al, 2012), a web-based workbench for building
and executing UIMA workflows.
7 Conclusions
The alignment of types between different type sys-
tems using SPARQL is an attractive alternative to
existing solutions. Compared to other solutions,
our approach does not introduce a new language
or syntax; to the contrary, it relies entirely on a
well-defined, standardised language, a character-
istic that immediately broadens the target audi-
ence. Likewise, developers who are unfamiliar
with SPARQL should be more likely to learn this
well-maintained and widely used language than
any other specialised and not standardised syntax.
The expressiveness of SPARQL makes the
method superior to the rule-based techniques,
mainly due to SPARQL?s inherent capability
of random data access and simple, triple-based
querying. At the same time, the semantic cohesion
of data is maintained by a graph representation.
The proposed solution facilitates the rapid
alignment of type systems and increases the flexi-
bility in which developers choose processing com-
ponents to build their UIMA applications. As well
as benefiting the design of applications, the con-
version mechanism may also prove helpful in the
development of components themselves. To en-
sure interoperability, developers usually adopt an
existing type system for a new component. This
essential UIMA-development practice undeniably
increases the applicability of such a component;
however, at times it may also result in having the
ill-defined representation of the data produced by
the component. The availability of an easy-to-
apply conversion tool promotes constructing fine-
tuned type systems that best represent such data.
Acknowledgments
This work was partially funded by the MRC Text
Mining and Screening grant (MR/J005037/1).
96
References
W A Baumgartner, K B Cohen, and L Hunter. 2008.
An open-source framework for large-scale, flexible
evaluation of biomedical text mining systems. Jour-
nal of biomedical discovery and collaboration, 3:1+.
E Buyko, C Chiarcos, and A Pareja-Lora. 2008.
Ontology-based interface specifications for a nlp
pipeline architecture. In Proceedings of the Sixth In-
ternational Conference on Language Resources and
Evaluation (LREC?08), Marrakech, Morocco.
C Chiarcos. 2012. Ontologies of linguistic annota-
tion: Survey and perspectives. In Proceedings of the
Eighth International Conference on Language Re-
sources and Evaluation (LREC?12), pages 303?310.
D Ferrucci and A Lally. 2004. UIMA: An Ar-
chitectural Approach to Unstructured Information
Processing in the Corporate Research Environment.
Natural Language Engineering, 10(3-4):327?348.
Iryna Gurevych, Max Mu?hlha?user, Christof Mu?ller,
Ju?rgen Steimle, Markus Weimer, and Torsten Zesch.
2007. Darmstadt Knowledge Processing Repository
Based on UIMA. In Proceedings of the First Work-
shop on Unstructured Information Management Ar-
chitecture at Biannual Conference of the Society for
Computational Linguistics and Language Technol-
ogy, Tu?bingen, Germany.
U Hahn, E Buyko, R Landefeld, M Mu?hlhausen,
M Poprat, K Tomanek, and J Wermter. 2008. An
Overview of JCORE, the JULIE Lab UIMA Com-
ponent Repository. In Proceedings of the Language
Resources and Evaluation Workshop, Towards En-
hanc. Interoperability Large HLT Syst.: UIMA NLP,
pages 1?8.
N Hernandez. 2012. Tackling interoperability is-
sues within UIMA workflows. In Proceedings of
the Eight International Conference on Language
Resources and Evaluation (LREC?12), Istanbul,
Turkey. European Language Resources Association
(ELRA).
P Kluegl, M Atzmueller, and F Puppe. 2009.
TextMarker: A Tool for Rule-Based Information Ex-
traction. In Proceedings of the Biennial GSCL Con-
ference 2009, 2nd UIMA@GSCL Workshop, pages
233?240. Gunter Narr Verlag.
M T Pazienza, A Stellato, and A Turbati. 2012.
PEARL: ProjEction of Annotations Rule Language,
a Language for Projecting (UIMA) Annotations over
RDF Knowledge Bases. In Proceedings of the Eight
International Conference on Language Resources
and Evaluation (LREC?12), Istanbul, Turkey. Euro-
pean Language Resources Association (ELRA).
R Rak, A Rowley, W Black, and S Ananiadou. 2012.
Argo: an integrative, interactive, text mining-based
workbench supporting curation. Database : The
Journal of Biological Databases and Curation, page
bas010.
G K Savova, J J Masanz, P V Ogren, J Zheng, S Sohn,
K C Kipper-Schuler, and C G Chute. 2010. Mayo
clinical Text Analysis and Knowledge Extraction
System (cTAKES): architecture, component evalua-
tion and applications. Journal of the American Med-
ical Informatics Association : JAMIA, 17(5):507?
513.
P Thompson, Y Kano, J McNaught, S Pettifer, T K
Attwood, J Keane, and S Ananiadou. 2011. Promot-
ing Interoperability of Resources in META-SHARE.
In Proceedings of the IJCNLP Workshop on Lan-
guage Resources, Technology and Services in the
Sharing Paradigm (LRTS), pages 50?58.
K Verspoor, W Baumgartner Jr, C Roeder, and
L Hunter. 2009. Abstracting the Types away from a
UIMA Type System. From Form to Meaning: Pro-
cessing Texts Automatically., pages 249?256.
97
