Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 936?943,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Much ado about nothing:                                         
A social network model of Russian paradigmatic gaps 
Robert Daland Andrea D. Sims Janet Pierrehumbert 
Department of Linguistics 
Northwestern University 
2016 Sheridan Road 
Evanston, IL 60208 USA 
r-daland, andrea-sims, jbp@northwestern.edu 
 
 
 
 
 
Abstract 
A number of Russian verbs lack 1sg non-
past forms. These paradigmatic gaps are 
puzzling because they seemingly contradict 
the highly productive nature of inflectional 
systems. We model the persistence and 
spread of Russian gaps via a multi-agent 
model with Bayesian learning. We ran 
three simulations: no grammar learning, 
learning with arbitrary analogical pressure, 
and morphophonologically conditioned 
learning. We compare the results to the 
attested historical development of the gaps. 
Contradicting previous accounts, we 
propose that the persistence of gaps can be 
explained in the absence of synchronic 
competition between forms. 
1 Introduction 
Paradigmatic gaps present an interesting challenge 
for theories of inflectional structure and language 
learning. Wug tests, analogical change and 
children?s overextensions of regular patterns 
demonstrate that inflectional morphology is highly 
productive. Yet lemmas sometimes have ?missing? 
inflected forms. For example, in Russian the 
majority of verbs have first person singular (1sg) 
non-past forms (e.g., posadit? ?to plant?, posa?u ?I 
will plant?), but no 1sg form for a number of 
similar verbs (e.g., pobedit? ?to win?, *pobe?u ?I 
will win?). The challenge lies in explaining this 
apparent contradiction. Given the highly produc-
tive nature of inflection, why do paradigmatic gaps 
arise? Why do they persist?     
One approach explains paradigmatic gaps as a 
problem in generating an acceptable form.  Under 
this hypothesis, gaps result from irreconcilable 
conflict between two or more inflectional patterns.  
For example, Albright (2003) presents an analysis 
of Spanish verbal gaps based on the Minimal 
Generalization Learner (Albright and Hayes 2002). 
In his account, competition between mid-vowel 
diphthongization (e.g., s[e]ntir ?to feel?, s[je]nto ?I 
feel?) and non-diphthongization (e.g., p[e]dir ?to 
ask?, p[i]do ?I ask?) leads to paradigmatic gaps in 
lexemes for which the applicability of diphthon-
gization has low reliability (e.g., abolir ?to abolish, 
*ab[we]lo, *ab[o]lo ?I abolish?).   
However, this approach both overpredicts and 
underpredicts the existence of gaps cross-
linguistically.  First, it predicts that gaps should 
occur whenever the analogical forces determining 
word forms are contradictory and evenly weighted. 
However, variation between two inflectional 
patterns seems to more commonly result from such 
a scenario.  Second, the model predicts that if the 
form-based conflict disappears, the gaps should 
also disappear. However, in Russian and probably 
in other languages, gaps persist even after the loss 
of competing inflectional patterns or other 
synchronic form-based motivation (Sims 2006).   
By contrast, our approach operates at the level 
of inflectional property sets (IPS), or more 
properly, at the level of inflectional paradigms.  
We propose that once gaps are established in a 
language for whatever reason, they persist because 
learners infer the relative non-use of a given 
 1
936
combination of stem and IPS.1  Put differently, we 
hypothesize that speakers possess at least two 
kinds of knowledge about inflectional structure: (1) 
knowledge of how to generate the appropriate form 
for a given lemma and IPS, and (2) knowledge of 
the probability with which that combination of 
lemma and property set is expressed, regardless of 
the form. Our approach differs from previous 
accounts in that persistence of gaps is attributed to 
the latter kind of knowledge, and does not depend 
on synchronic morphological competition. 
We present a case study of the Russian verbal 
gaps, which are notable for their persistence.  They 
arose between the mid 19th and early 20th century 
(Baerman 2007), and are still strongly attested in 
the modern language, but have no apparent 
synchronic morphological cause.   
We model the persistence and spread of the 
Russian verbal gaps with a multi-agent model with 
Bayesian learning.  Our model has two kinds of 
agents, adults and children. A model cycle consists 
of two phases: a production-perception phase, and 
a learning-maturation phase. In the production-
perception phase, adults produce a batch of 
linguistic data (verb forms), and children listen to 
the productions from the adults they know. In the 
learning-maturation phase, children build a 
grammar based on the input they have received, 
then mature into adults.  The existing adults die off, 
and the next generation of children is born. 
Our model exhibits similar behavior to what is 
known about the development of Russian gaps. 
2 The historical and distributional facts 
of Russian verbal gaps 
2.1 Traditional descriptions 
Grammars and dictionaries of Russian frequently 
cite paradigmatic gaps in the 1sg non-past.  Nine 
major dictionaries and grammars, including 
?vedova (1982) and Zaliznjak (1977), yielded a 
combined list of 96 gaps representing 68 distinct 
stems.  These verbal gaps fall almost entirely into 
the second conjugation class, and they 
overwhelmingly affect the subgroup of dental 
stems.  Commonly cited gaps include: *gal?u ?I 
make a hubbub?; *o?u?us? ?I come to be (REFL)?; 
1SG *o??u??u ?I feel?; *pobe?u ?I will win?; and 
*ube?u ?I will convince?.2 
                                                 
                                                
1 Paradigmatic gaps also probably serve a sociolinguistic 
purpose, for example as markers of education, but socio-
linguistic issues are beyond the scope of this paper. 
There is no satisfactory synchronic reason for 
the existence of the gaps.  The grouping of gaps 
among 2nd conjugation dental stems is seemingly 
non-arbitrary because these are exactly the forms 
that would be subject to a palatalizing morphopho-
nological alternation (tj ? tS or Sj, dj ? Z, sj ? S, zj 
? Z). Yet the Russian gaps do not meet the criteria 
for morphophonological competition as intended 
by Albright?s (2003) model, because the 
alternations apply automatically in Contemporary 
Standard Russian. Analogical forces should thus 
heavily favor a single form, for example, pobe?u. 
Traditional explanations for the gaps, such as 
homophony avoidance (?vedova 1982) are also 
unsatisfactory since they can, at best, explain only 
a small percentage of the gaps. 
Thus, the data suggest that gaps persist in 
Russian primarily because they are not uttered, and 
this non-use is learned by succeeding generations 
of Russian speakers.3  The clustering of the gaps 
among 2nd conjugation dental stems most likely is 
partially a remnant of their original causes, and 
partially represents analogic extension of gaps 
along morphophonological lines (see 2.3 below). 
2.2 Empirical evidence for and operational 
definition of gaps 
When dealing with descriptions in semi- 
prescriptive sources such as dictionaries, we must 
always ask whether they accurately represent 
language use. In other words, is there empirical 
evidence that speakers fail to use these words? 
We sought evidence of gaps from the Russian 
National Corpus (RNC). 4  The RNC is a balanced 
textual corpus with 77.6 million words consisting 
primarily of the contemporary Russian literary 
language.  The content is prose, plays, memoirs 
and biographies, literary criticism, newspaper and 
magazine articles, school texts, religious and 
 
2  We use here the standard Cyrillic transliteration used by 
linguists.  It should not be considered an accurate 
phonological representation.  Elsewhere, when phonological 
issues are relevant, we use IPA. 
3 See Manning (2003) and Zuraw (2003) on learning from 
implicit negative evidence. 
4 Documentation: http://ruscorpora.ru/corpora-structure.html 
Mirror site used for searching: 
http://corpus.leeds.ac.uk/ruscorpora.html.    
 
 2
937
philosophical materials, technical and scientific 
texts, judicial and governmental publications, etc. 
We gathered token frequencies for the six non-
past forms of 3,265 randomly selected second 
conjugation verb lemmas.  This produced 11,729 
inflected forms with non-zero frequency. 5   As 
described in Section 3 below, these 11,729 form 
frequencies became our model?s seed data. 
To test the claim that Russian has verbal gaps, 
we examined a subsample of 557 2nd conjugation 
lemmas meeting the following criteria: (a) total 
non-past frequency greater than 36 raw tokens, and 
(b) 3sg and 3pl constituting less than 85% of total 
non-past frequency. 6   These constraints were 
designed to select verbs for which all six person-
number combinations should be robustly attested, 
and to minimize sampling errors by removing 
lemmas with low attestation. 
We calculated the probability of the 1sg 
inflection by dividing the number of 1sg forms by 
the total number of non-past forms. The subset was 
bimodally distributed with one peak near 0%, a 
trough at around 2%, and the other peak at 13.3%.  
The first peak represents lemmas in which the 1sg 
form is basically not used ? gaps. Accordingly, we 
define gaps as second conjugation verbs which 
meet criteria (a) and (b) above, and for which the 
1sg non-past form constitutes less than 2% of total 
non-past frequency for that lemma (N=56). 
In accordance with the grammatical descrip-
tions, our criteria are disproportionately likely to 
identify dental stems as gaps. Still, only 43 of 412 
dental stems (10.4%) have gaps, compared with 13 
gaps among 397 examples of other stems (3.3%).   
Second, not all dental stems are equally affected.  
There seems to be a weak prototypicality effect 
centered around stems ending in /dj/, from which 
/tj/ and /zj/ each differ by one phonological feature.  
There may also be some weak semantic factors that 
we do not consider here. 
 
/dj/ /tj/ /zj/ /sj/ /stj/ 
13.3% 
(19/143) 
12.4% 
(14/118) 
11.9% 
(5/42) 
4.8% 
(3/62) 
4.3% 
(2/47) 
Table 1. Distribution of Russian verbal gaps 
among dental stems 
                                                 
5  We excluded 29 high-frequency lemmas for which the 
corpus did not provide accurate counts. 
6 Russian has a number of verbs for which only the 3sg and 
3pl are regularly used. 
2.3 Some relevant historical facts 
A significant difference between the morpho-
logical competition approach and our statistical 
learning approach is that the former attempts to 
provide a single account for both the rise and the 
perpetuation of paradigmatic gaps.  By contrast, 
our statistical learning model does not require that 
the morphological system provide synchronic 
motivation. The following question thus arises: 
Were the Russian gaps originally caused by forces 
which are no longer in play in the language? 
Baerman and Corbett (2006) find evidence that 
the gaps began with a single root, -bed- (e.g., 
pobedit? ?to win?), and subsequently spread 
analogically within dental stems.  Baerman (2007) 
expands on the historical evidence, finding that a 
conspiracy of several factors provided the initial 
push towards defective 1sg forms. Most important 
among these, many of the verbs with 1sg gaps in 
modern Russian are historically associated with 
aberrant morphophonological alternations. He 
argues that when these unusual alternations were 
eliminated in the language, some of the words 
failed to be integrated into the new morphological 
patterns, which resulted in lexically specified gaps. 
Important to the point here is that the 
elimination of marginal alternations removed an 
earlier synchronic motivation for the gaps.  Yet 
gaps have persisted and new gaps have arisen (e.g., 
pylesosit? ?to vacuum?). This persistence is the 
behavior that we seek to model. 
3 Formal aspects of the model 
We take up two questions: How much machinery 
do we need for gaps to persist? How much 
machinery do we need for gaps to spread to phono-
logically similar words?  We model three scenarios.  
In the first scenario there is no grammar learning.   
Adult agents produce forms by random sampling 
from the forms that heard as children, and child 
agents hear those forms. In the subsequent 
generation children become adults. In this scenario 
there is thus no analogical pressure. Any perse-
verance of gaps results from word-specific learning. 
The second scenario is similar to the first, except 
that the learning process includes analogical 
pressure from a random set of words.  Specifically, 
for a target concept, the estimated distribution of 
its IPS is influenced by the distribution of known 
words. This enables the learner to express a known 
 3
938
concept with a novel IPS. For example, imagine 
that a learner hears the present tense verb form 
googles, but not the past tense googled. By analogy 
with other verbs, learners can expect the past tense 
to occur with a certain frequency, even if they have 
not encountered it.   
The third scenario builds upon the second.  In 
this version, the analogical pressure is not 
completely random.  Instead, it is weighted by 
morphophonological similarity ? similar word 
forms contribute more to the analogical force on a 
target concept than do dissimilar forms.  This 
addition to the model is motivated by the pervasive 
importance of stem shape in the Russian 
morphological system generally, and potentially 
provides an account for the phonological 
prototypicality effect among Russian gaps. 
The three scenarios thus represent increasing 
machinery for the model, and we use them to 
explore the conditions necessary for gaps to persist 
and spread.  We created a multi-agent network 
model with Bayesian learning component.  In the 
following sections we describe the model?s 
structure, and outline the criteria by which we 
evaluate its output under the various conditions. 
3.1 Social structure 
Our model includes two generations of agents.  
Adult agents output linguistic forms, which 
provide linguistic input for child agents.  
Output/input occurs in batches.7  After each batch 
all adults die, all children mature into adults, and a 
new generation of children is born. Each run of the 
model included 10 generations of agents.   
We model the social structure with a random 
network.  Each adult produces 100,000 verb forms, 
and each child is exposed to every production from 
every adult to whom they are connected. Each 
generation consisted of 50 adult agents, and child 
agents are connected to adults with some 
probability p.  On average, each child agent is 
connected to 10 adult agents, meaning that each 
child hears, on average, 1,000,000 tokens. 
3.2 Linguistic events 
Russian gaps are localized to second conjugation 
non-past verb forms, so productions of these forms 
are the focus of interest.  Formally, we define a 
linguistic event as a concept-inflection-form (C,I,F) 
triple. The concept serves to connect the different 
forms and inflections of the same lemma. 
                                                 
7  See Niyogi (2006) for why batch learning is a 
reasonable approximation in this context. 
3.3 Definition of grammar  
A grammar is defined as a probability distribution 
over linguistic events. This gives rise to natural 
formulations of learning and production as 
statistical processes: learning is estimating a 
probability distribution from existing data, and 
production is sampling from a probability 
distribution.  The grammar can be factored into 
modular components: 
 
p(C, I, F) = p(C) ? p(I | C) ? p(F | C, I) 
 
In this paper we focus on the probability 
distribution of concept-inflection pairs.  In other 
words, we focus on the relative frequency of 
inflectional property sets (IPS) on a lemma-by-
lemma basis, represented by the middle term above. 
Accordingly, we made the simplest possible 
assumptions for the first and last terms. To 
calculate the probability of a concept, children use 
the sample frequency (e.g., if they hear 10 tokens 
of the concept ?eat?, and 1,000 tokens total, then 
p(?eat?) = 10/1000 = .01). Learning of forms is 
perfect. That is, learners always produce the 
correct form for every concept-inflection pair. 
3.4 Learning model 
Although production in the real world is governed 
by semantics, we treat it here as a statistical 
process, much like rolling a six-sided die which 
may or may not be fair. When producing a Russian 
non-past verb, there are six possible combinations 
of inflectional properties (3 persons * 2 numbers).  
In our model, word learning involves estimating 
the probability distribution over the frequencies of 
the six forms on a lemma-by-lemma basis. A 
hypothetical example that introduces our variables: 
 
 
jest? 1sg 2sg 3sg 1pl 2pl 3pl SUM 
D 15 5 45 5 5 25 100 
d 0.15 0.05 0.45 0.05 0.05 0.25 1 
Table 2. Hypothetical probability distribution 
 
The first row indicates the concept and the 
inflections. The second row (D) indicates the 
 4
939
hypothetical number of tokens of jest? ?eat? that the 
learner heard for each inflection (bolding indicates 
a six-vector).  We use |D| to indicate the sum of 
this row (=100), which is the concept frequency.  
The third row (d) indicates the sample probability 
of that inflection, which is simply the second row 
divided by |D|.   
The learner?s goal is to estimate the distribution 
that generated this data. We assume the 
multinomial distribution, whose parameter is 
simply the vector of probabilities of each IPS. For 
each concept, the learner?s task is to estimate the 
probability of each IPS, represented by h in the 
equations below.  We begin with Bayes? rule: 
 
p(h | D) ? p(h) ? multinom(D | h) 
 
The prior distribution constitutes the analogical 
pressure on the lemma. It is generated from the 
?expected? behavior, h0, which is an average of the 
known behavior from a random sample of other 
lemmas. The parameter ? determines the number 
of lemmas that are sampled for this purpose ? it 
represents how many existing words affect a new 
word. To model the effect of morphophonological 
similarity (mpSim), in one variant of the model we 
weight this average by the similarity of the stem-
final consonant.8  For example, this has the effect 
that existing dental stems have more of an effect 
on dental stems.  In this case, we define 
 
h0 = ?c? in sample d c? ? mpSim(c, c?)/? mpSim(c, c?) 
 
We use a featural definition of similarity, so that if 
the stem-final consonants differ by 0, 1, 2, or 3 or 
more phonological features, the resulting similarity 
is 1, 2/3, 1/3, or 0, respectively. 
The prior distribution should assign higher 
probability to hypotheses that are ?closer? to this 
expected behavior h0. Since the hypothesis is itself 
a probability distribution, the natural measure to 
use is the KL divergence. We used an 
exponentially distributed prior with parameter ?: 
 
p(h) ? exp(-?? h0 || h) 
 
                                                 
8  In Russian, the stem-final consonant is important for 
morphological behavior generally. Any successful Russian 
learner would have to extract the generalization, completely 
apart from the issues posed by gaps. 
As will be shown shortly, ? has a natural 
interpretation as the relative strength of the prior 
with respect to the observed data. 
The learner calculates their final grammar by 
taking the mode of the posterior distribution 
(MAP). It can be shown that this value is given by 
 
arg max p(h | D) = (?? h0 + |D|? d)/(?+|D|) 
 
Thus, the output of this learning rule is a 
probability vector h that represents the estimated 
probability of each of the six possible IPS?s for 
that concept. As can be seen from the equation 
above, this probability vector is an average of the 
expected behavior h0 and the observed data d, 
weighted by ? and the amount of observed data |D|, 
respectively. 
Our approach entails that from the perspective 
of a language learner, gaps are not qualitatively 
distinct from productive forms.  Instead, 1sg non-
past gaps represent one extreme of a range of 
probabilities that the first person singular will be 
produced.  In this sense, ?gaps? represent an 
artificial boundary which we place on a gradient 
structure for the purpose of evaluating our model.  
The contrast between our learning model and the 
account of gaps presented in Albright (2003) 
merits emphasis at this point.  Generally speaking, 
learning a word involves at least two tasks:  
learning how to generate the appropriate 
phonological form for a given concept and 
inflectional property set, and learning the 
probability that a concept and inflectional property 
set will be produced at all.  Albright?s model 
focuses on the former aspect; our model focuses on 
the latter. In short, our account of gaps lies in the 
likelihood of a concept-IPS pair being expressed, 
not in the likelihood of a form being expressed. 
3.5 Production model 
We model language production as sampling from 
the probability distribution that is the output of the 
learning rule. 
3.6 Seeding the model 
The input to the first generation was sampled from 
the verbs identified in the corpus search (see 2.2). 
Each input set contained 1,000,000 tokens, which 
was the average amount of input for agents in all 
succeeding generations.  This made the first 
 5
940
generation?s input as similar as possible to the 
input of all succeeding generations. 
3.7 Parameter space in the three scenarios 
In our model we manipulate two parameters ? the 
strength of the analogical force on a target concept 
during the learning process (?), and the number of 
concepts which create the analogical force (?), 
taken randomly from known concepts.   
As discussed above, we model three scenarios.  
In the first scenario, there is no grammar learning, 
so there is only one condition (? = 0).  For the 
second and third scenarios, we run the model with 
four values for ?, ranging from weak to strong 
analogical force (0.05, 0.25, 1.25, 6.25), and two 
values for ?, representing influence from a small or 
large set of other words (30, 300). 
4 Evaluating the output of the model 
We evaluate the output of our model against the 
following question: How well do gaps persist?   
We count as gaps any forms meeting the criteria 
outlined in 2.2 above, tabulating the number of 
gaps which exist for only one generation, for two 
total generations, etc.  We define ? as the expected 
number of generations (out of 10) that a given 
concept meets the gap criteria.  Thus, ? represents a 
gap?s ?life expectancy? (see Figure 1). 
We found that this distribution is exponential ? 
there are few gaps that exist for all ten generations, 
and lots of gaps that exist for only one, so we 
calculated ? with a log linear regression.  Each 
value reported is an average over 10 runs.   
As discussed above, our goal was to discover 
whether the model can exhibit the same qualitative 
behavior as the historical development of Russian 
gaps.  Persistence across a handful of generations 
(so far) and spread to a limited number of similar 
forms should be reflected by a non-negligible ?.  
5 Results 
In this section we present the results of our model 
under the scenarios and parameter settings above. 
Remember that in the first scenario there is no 
grammar learning. This run of the model represents 
the baseline condition ? completely word-specific 
knowledge.  Sampling results in random walks on 
form frequencies, so once a word form disappears 
it never returns to the sample.  Word-specific 
learning is thus sufficient for the perseverance of 
existing paradigmatic gaps and the creation of new 
ones.  With no analogical pressure, gaps are 
robustly attested (? = 6.32).  However, the new 
gaps are not restricted to the 1sg, and under this 
scenario, learners are unable to generalize to a 
novel pairing of lexeme + IPS.   
The second scenario presents a more 
complicated picture.  As shown in Table 3, as 
analogical pressure (?) increases, gap life 
expectancy (?) decreases.  In other words, high 
analogical pressure quickly eliminates atypical 
frequency distributions, such as those exhibited by 
gaps. The runs with low values of ? are particularly 
interesting because they represent an approximate 
balance between elimination of gaps as a general 
behavior, and the short-term persistence and even 
spread of gaps due to sampling artifacts and the 
influence of existing gaps. Thus, although the limit 
behavior is for gaps to disappear, this scenario 
retains the ability to explain persistence of gaps 
due to word-specific learning when there is weak 
analogical force. 
At the same time, the facts of Russian differ 
from the behavior of the model in that the Russian 
gaps spread to morphophonologically similar 
forms, not random ones.  The third version of our 
model weights the analogical strength of different 
concepts based upon morphophonological 
similarity to the target.   
 
? ? ? (random) 
?  
(phono.) 
-- 0 6.32 
 
30 0.05 4.95 5.77 
30 0.25 3.46 5.28 
30 1.25 1.91 3.07 
30 6.25 2.59 1.87 
 
300 0.05 4.97 5.99 
300 0.25 3.72 5.14 
300 1.25 1.90 3.10 
300 6.25 2.62 1.84 
Table 3. Life expectancy of gaps, as a function of 
the strength of random analogical forces 
 
Under these conditions we get two interesting 
results, presented in Table 3 above.  First, gaps 
persist slightly better overall in scenario 3 than in 
 6
941
scenario 2 for all levels of ? and ?. 9  Compare the 
? values for random analogical force (scenario 2) 
with the ? values for morphophonologically 
weighted analogical force (scenario 3). 
Second, strength of analogical force matters. 
When there is weak analogical pressure, weighting 
for morphophonological similarity has little effect 
on the persistence and spread of gaps.  However, 
when there is relatively strong analogical pressure, 
morphophonological similarity helps atypical 
frequency distributions to persist, as shown in 
Figure 1.  This results from the fact that there is a 
prototypicality effect for gaps.  Since dental stems 
are more likely to be gaps, incorporating sensitivity 
to stem shape causes the analogical pressure on 
target dental stems to be relatively stronger from 
words that are gaps. Correspondingly, the 
analogical pressure on non-dental stems is 
relatively stronger from words that are not gaps.  
The prototypical stem shape for a gap is thereby 
perpetuated and gaps spread to new dental stems. 
 
0
1
2
3
4
5
6
1 2 3 4 5 6 7 8 9 10
# of generations
log
(# 
of
 ga
ps
)
random, ? = 0.05 random, ? = 1.25
phonological, ? = 0.05 phonological, ? = 1.25
Figure 1. Gap life expectancy (?=0.05, ?=30) 
  
                                                 
9 The apparent increase in gap half-life when ?=6.25 is 
an artifact of the regression model. There were a few 
well-entrenched gaps whose high lemma frequency 
enables them to resist even high levels of analogical 
pressure over 10 generations.  These data points skewed 
the regression, as shown by a much lower R2 (0.5 vs. 
0.85 or higher for all the other conditions).  
6 Discussion 
In conclusion, our model has in many respects 
succeeded in getting gaps to perpetuate and spread.  
With word-specific learning alone, well-
entrenched gaps can be maintained across multiple 
generations.  More significantly, weak analogical 
pressure, especially if weighted for morpho-
phonological similarity, results in the perseverance 
and short-term growth of gaps.   This is essentially 
the historical pattern of the Russian verbal gaps.  
These results highlight several issues regarding 
both the nature of paradigmatic gaps and the 
structure of inflectional systems generally. 
We claim that it is not necessary to posit an 
irreconcilable conflict in the generation of inflected 
forms in order to account for gaps.  Remember that 
in our model, agents face no conflict in terms of 
which form to produce ? there is only one 
possibility.  Yet the gaps persist in part because of 
analogical pressure from existing gaps.  Albright 
(2003) himself is agnostic on the issue of whether 
form-based competition is necessary for the 
existence and persistence of gaps, but Hudson 
(2000), among others, claims that gaps could not 
exist in the absence of it.  We have presented 
evidence that this claim is unfounded. 
But why would someone assume that grammar 
competition is necessary?  Hudson?s claim arises 
from a confusion of two issues.  Discussing the 
English paradigmatic gap amn?t, Hudson states 
that ?a simple application of [the usage-based 
learning] principle would be to say that the gap 
exists simply because nobody says amn?t...  But 
this explanation is too simple... There are many 
inflected words that may never have been uttered, 
but which we can nevertheless imagine ourselves 
using, given the need; we generate them by 
generalization? (Hudson 2000:300).  By his logic, 
there must therefore be some source of grammar 
conflict which prevents speakers from generalizing.   
However, there is a substantial difference 
between having no information about a word, and 
having information about the non-usage of a word.  
We do not dispute learners? ability to generalize.  
We only claim that information of non-usage is 
sufficient to block such generalizations.  When 
confronted with a new word, speakers will happily 
generalize a word form, but this is not the same 
task that they perform when faced with gaps. 
 7
942
The perseverance of gaps in the absence of 
form-based competition shows that a different, 
non-form level of representation is at issue.  
Generating inflectional morphology involves at 
least two different types of knowledge: knowledge 
about the appropriate word form to express a given 
concept and IPS on the one hand, and knowledge 
of how often that concept and IPS is expressed on 
the other. The emergence of paradigmatic gaps 
may be closely tied to the first type of knowledge, 
but the Russian gaps, at least, persist because of 
the second type of knowledge.  We therefore 
propose that morphology may be defective at the 
morphosyntactic level. 
This returns us to the question that we began this 
paper with ?  how paradigmatic gaps can persist in 
light of the overwhelming productivity of 
inflectional morphology.  Our model suggests that 
the apparent contradiction is, at least in some cases, 
illusory.  Productivity refers to the likelihood of a 
given inflectional pattern applying to a given 
combination of stem and IPS.  Our account is 
based in the likelihood of the stem and inflectional 
property set being expressed at all, regardless of 
the form.  In short, the Russian paradigmatic gaps 
represent an issue which is orthogonal to 
productivity.  The two issues are easily confused, 
however.  An unusual frequency distribution can 
make it appear that there is in fact a problem at the 
level of form, even when there may not be. 
Finally, our simulations raise the question of 
whether the 1sg non-past gaps in Russian will 
persist in the language in the long term. In our 
model, analogical forces delay convergence to the 
mean, but the limit behavior is that all gaps 
disappear.  Although there is evidence in Russian 
that words can develop new gaps, we do not know 
with any great accuracy whether the set of gaps is 
currently expanding, contracting, or approximately 
stable.  Our model predicts that in the long run, the 
gaps will disappear under general analogical 
pressure.  However, another possibility is that our 
model includes only enough factors (e.g., 
morphophonological similarity) to approximate the 
short-term influences on the Russian gaps and that 
we would need more factors, such as semantics, to 
successfully model their long-term development.  
This remains an open question. 
 
References 
Albright, Adam. 2003. A quantitative study of Spanish 
paradigm gaps. In West Coast Conference on Formal 
Linguistics 22 proceedings, eds. Gina Garding and 
Mimu Tsujimura. Somerville, MA: Cascadilla Press, 
1-14. 
Albright, Adam, and Bruce Hayes. 2002. Modeling 
English past tense intuitions with minimal 
generalization. In Proceedings of the Sixth Meeting of 
the Association for Computational Linguistics 
Special Interest Group in Computational Phonology 
in Philadelphia, July 2002, ed. Michael Maxwell. 
Cambridge, MA: Association for Computational 
Linguistics, 58-69. 
Baerman, Matthew. 2007. The diachrony of 
defectiveness. Paper presented at 43rd Annual 
Meeting of the Chicago Linguistic Society in 
Chicago, IL, May 3-5, 2007. 
Baerman, Matthew, and Greville Corbett. 2006. Three 
types of defective paradigms. Paper presented at The 
Annual Meeting of the Linguistic Society of America 
in Albuquerque, NM, January 5-8, 2006. 
Hudson, Richard. 2000. *I amn?t. Language 76 (2):297-
323. 
Manning, Christopher. 2003. Probabilistic syntax. In 
Probabilistic linguistics, eds. Rens Bod, Jennifer Hay 
and Stephanie Jannedy. Cambridge, MA: MIT Press, 
289-341. 
Niyogi, Partha. 2006. The computational nature of 
language learning and evolution. Cambridge, MA: 
MIT Press. 
Sims, Andrea. 2006. Minding the gaps: Inflectional 
defectiveness in paradigmatic morphology. Ph.D. 
thesis: Linguistics Department, The Ohio State 
University. 
?vedova, Julja. 1982. Grammatika sovremennogo 
russkogo literaturnogo jayzka. Moscow: Nauka. 
Zaliznjak, A.A., ed. 1977. Grammati?eskij slovar' 
russkogo jazyka: Slovoizmenenie. Moskva: Russkij 
jazyk. 
Zuraw, Kie. 2003. Probability in language change. In 
Probabilistic linguistics, eds. Rens Bod, Jennifer Hay 
and Stephanie Jannedy. Cambridge, MA: MIT Press, 
139-176. 
 
 8
943
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 873?877,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Does Korean defeat phonotactic word segmentation? 
Robert Daland 
Department of Linguistics 
University of California, Los Angeles 
3125 Campbell Hall, Box 951543 
Los Angeles, CA 90095-1543, USA 
r.daland@gmail.com 
Kie Zuraw 
Department of Linguistics 
University of California, Los Angeles 
3125 Campbell Hall, Box 951543 
Los Angeles, CA 90095-1543, USA 
kie@ucla.edu 
 
  
Abstract 
Computational models of infant word 
segmentation have not been tested on a 
wide range of languages. This paper ap-
plies a phonotactic segmentation model 
to Korean. In contrast to the underseg-
mentation pattern previously found in 
English and Russian, the model exhibited 
more oversegmentation errors and more 
errors overall. Despite the high error rate, 
analysis suggested that lexical acquisition 
might not be problematic, provided that 
infants attend only to frequently seg-
mented items. 
1 Introduction 
The process by which infants learn to parse the 
acoustic signal into word-sized units?word 
segmentation?is an active area of research in 
developmental psychology (Polka and Sundara 
2012; Saffran et al 1996) and cognitive model-
ing (Daland and Pierrehumbert 2011 [DP11], 
Goldwater et al 2009 [GGJ09]). Word segmen-
tation is a classic bootstrapping problem: to learn 
words, infants must segment the input, because 
around 90% of the novel word types they hear 
are never uttered in isolation (Aslin et al 1996; 
van de Weijer 1998). However, in order to seg-
ment infants must know some words, or gener-
alizations about the properties of words. How 
can infants form generalizations about words 
before learning words themselves? 
1.1 DiBS 
Two approaches in the literature might be termed 
lexical and phonotactic. Under the lexical ap-
proach, exemplified by GGJ09, infants are as-
sumed to exploit the Zipfian distribution of lan-
guage, identifying frequently recurring and mu-
tually predictive sequences as words. In the pho-
notactic approach, infants are assumed to lever-
age universal and/or language-specific knowl-
edge about the phonological content of se-
quences to infer the optimal segmentation. The 
present study focuses on the phonotactic ap-
proach outlined in DP11, termed DiBS. For other 
examples of approaches that use phonotactics, 
see Fleck 2008, Blanchard et al 2010.  
A (Di)phone-(B)ased (S)egmentation model 
consists of an inventory of segment-segment se-
quences, with an estimated probability that a 
word boundary falls between the two segments. 
For example, when [pd] occurs in English, the 
probability of an intervening word boundary is 
very high: Pr(# | [pd]) ? 1. These probabilities 
are the parameters of the model to be learned. In 
the supervised setting (baseline model), these 
parameters may be estimated directly from data 
in which the word boundaries are labeled: Pr(# | 
pd) = Fr(# ^ pd) / (Fr(# ^ pd) + Fr(?# ^ pd)) 
where Fr(# ^ pd) is the number of [pd] sequences 
separated by a word boundary, and Fr(?# ^ pd) 
the number of [pd]?s not separated by a word 
boundary. For assessment purposes, these prob-
abilities are converted to hard decisions. 
DP11 describe an unsupervised learning algo-
rithm for DiBS that exploits a positional inde-
pendence assumption, treating phrase edges as a 
proxy for word edges (phrasal model). This 
learning model?s performance on English is on 
par with state-of-the-art lexical models (GGJ09), 
reflecting the high positional informativeness of 
diphones in English. We apply the baseline and 
phrasal models to Korean. 
1.2 Linguistic properties of Korean 
Korean is unrelated to languages previously 
modeled (English, Dutch, French, Spanish, Ara-
873
bic, Greek, Russian), and it is an interesting test 
case for both phonotactic and lexical approaches. 
Korean syntax and morphology (Sohn 1999) 
present a particular challenge for unsupervised 
learning. Most noun phrases are marked with a 
limited set of case suffixes, and clauses generally 
end in a verb, inflected with suffixes ending in a 
limited set of sounds ([a,?,i,jo]). Thus, the 
phrase-final distribution may not reflect the 
overall word-final distribution?problematic for 
some phonotactic approaches. Similarly, the high 
frequency and positional predictability of affixes 
could lead a lexical model to treat them as words. 
A range of phonological processes apply in Ko-
rean, even across word boundaries (Sohn 1999), 
yielding extensive allomorphy. Phonotactic 
models may be robust to this kind of variation, 
but it is challenging for current lexical models 
(see DP11).  
Korean consonantal phonology gives diphones 
several informative properties, including: 
? Various consonant clusters (obstruent-
lenis, lenis-nasal, et al) are possible only 
if they span a word boundary 
? Various consonants cannot precede a 
word boundary 
? [?] cannot follow a word boundary  
Conversely, unlike in previously studied lan-
guages, vowel-vowel sequences are common 
word-internally. This is likely to be problematic 
for phonotactic models, but not for lexical ones. 
2 Methods 
We obtained a phonetic corpus representing Ko-
rean speech by applying a grapheme-to-phonetic 
converter to a text corpus. First, we conducted an 
analysis of this phonetic corpus, with results in 
Table 1. Next, for comparability with previous 
studies, two 750,000-word samples (representing 
approximately one month of child input each) 
were randomly drawn from the phonetic cor-
pus?the training and test corpora. The phrasal 
and baseline DiBS models described above were 
trained and tested on these corpora; results are 
reported in Table 2. Finally, we inspected one 
?day? worth of segmentations, and offer a quali-
tative assessment of errors. 
2.1 Corpus and phonetic conversion 
The Korean Advanced Institute of Science and 
Technology Raw Corpus, available from the Se-
mantic Web Research Center, semantic-
web.kaist.ac.kr/home/index.php/KAIST_Corpus 
contains approximately 70,000,000 words from 
speeches, novels, newspapers, and more. The 
corpus was preprocessed to supply phrase breaks 
at punctuation marks and strip XML.  
The grapheme-to-phonetic conversion system 
of Kim et al (2002) was generously shared by its 
creators. It includes morphosyntactic processing, 
phrase-break detection, and a dictionary of pho-
netic exceptions. It applies regular and lexically-
conditioned phonological rules, but not optional 
rules. Kim et al reported per-grapheme accuracy 
of 99.7% in one corpus and 99.98% in another. 
An example of original text and the phonetic 
conversion is given below, with phonological 
changes in bold: 
 
orthographic: ??? 1 ???? 2 ?? 3. 
??? 4 ??????? 5 ???? 6. 
phonetic: ???????1 ?????? 2 
?????? 3 # ??????? 4 
????????????????? 5 
????????? 6 
IPA: k j? ? k i t o1  j? t? u e s ?2   t?? u l s* ? 
?3   #   t? u ? a ? t ?4   m u n e t?? a ? t? a k? a k 
k* wa l ? l5   t? o l ? p? ? t t* a6 
(the * diacritic indicates tense consonants) 
gloss: Born3 in Yeoju2, Gyeonggi-do1. 
Graduated6 from Jungang University4 
Department of Creative Writing5. 
We relied on spaces in the corpus to indicate 
word boundaries, although, as in all languages, 
there can be inconsistencies in written Korean.  
2.2 Error analysis 
An under-researched issue is the nature of the 
errors that segmentation algorithms make. For a 
given input word in the test corpus, we defined 
the output projection as the minimal sequence of 
segmented words containing the entire input 
word. For example, if the#kitty were segmented 
as thekitty, then thekitty would be the output pro-
jection for both the and kitty. Similarly, for a 
posited word in the segmentation/output of the 
test corpus, we defined the input projection. For 
example, if the#kitty were segmented as 
theki#tty, then the the#kitty would be the input 
projection of both theki and tty. For each word, 
we examined the input-output relationship. Sev-
eral questions were of interest. Are highly fre-
quent items segmented frequently enough that 
the child is likely to be able to learn them? Is it 
874
the case that all or most items which are seg-
mented frequently are themselves words? Are 
there predicted errors which seem especially se-
rious or difficult to overcome? 
3 Results and discussion 
The 1350 distinct diphones found in the phonetic 
corpus were grouped into phonological classes. 
Table 1 indicates the probabilities (percentage) 
that a word boundary falls inside the diphone; 
when the class contains 3 or more diphones, the 
median and range are shown. Because of various 
phonological processes, some sequences cannot 
exist (blank cells), some can occur only word-
internally (marked int), and some can occur only 
across word boundaries (marked span). For ex-
ample, the velar nasal [?] cannot begin a word, 
so diphones of the form X? must be word-
internal. Conversely, a lenis-/h/ sequence indi-
cates a word boundary, because within a word a 
lenis stop merges with following /h/ to become 
an aspirated stop. If all diphones in a cell have a 
spanning rate above 90%, the cell says span*, 
and if below 10%, int*. This means that all the 
diphones in that class are highly informative; 
other classes contain a mix of more and less in-
formative diphones. 
The performance of the DiBS models is 
shown in Table 2. An undersegmentation error is 
a true word boundary which the segmentation 
algorithm fails to find (miss), while an overseg-
mentation error is a falsely posited boundary 
(false alarm). The under- and over-segmentation 
error rates are defined as the number of such er-
rors per word (percent). We also report the preci-
sion, recall, and F scores for boundary detection, 
word token segmentation, and type segmentation 
(for details see DP11, GGJ09). 
 
model baseline phrasal 
under (errs per wd) 43.4 72.5 
over (errs per wd) 17.7 22.0 
prec (bdry/tok/type) 68/36/34 28/11/12 
recall (bdry/tok/type) 46/27/29 11/6/8 
F (bdry/tok/type) 55/31/31 15/8/9 
Table 2: Results of DiBS models 
 
On the basis of the fact that the oversegmenta-
tion error rate in English and Russian was con-
sistently below 10% (<1 error/10 wds), DP11 
conjectured that phonotactic segmenters will, 
cross-linguistically, avoid significant overseg-
mentation. The results in Table 2 provide a coun-
terexample: oversegmentation is distinctly higher 
than in English and Russian. Indeed, Korean is a 
more challenging language for purely phonotac-
tic segmentation.  
3.1 Phonotactic cues to word segmentation 
Because phonological processes are more likely 
to apply word-internally, word-internal se-
quences are more predictable (Aslin et al 1996; 
DP11; GGJ09; Saffran et al 1996; van de Weijer 
1998). The phonology of Korean is a potentially 
        seg. 2 
seg. 1   
lenis 
stop 
lenis 
non-stop 
tense asp. h n m ? liquid vowel diphth. 
lenis stop span 100 
4-100 
int* 27 
5-53 
span 100 
98-100 
span  100 
10-100 
int* 7 
0-100 
lenis  
  non-stop 
         int int 
tense          int int 
aspirated          int int 
h          int int 
n 65 
29-66 
46, 57 38 
18-82 
45 
32-67 
35 32 61  span* 12 
1-37 
53 
20-99 
m 19 
14-21 
18, 18 14 
4-57 
14 
12-26 
14 int* 21  span int* 12 
1-92 
? 12 
11-13 
10, 12 9 
6-55 
11 
10-15 
int* int* 10  span 6 
0-64 
18 
4-86 
liquid 55 
43-63 
84, 88 71 
6-90 
53 
17-68 
42 90 53  int* 3 
0-14 
39 
7-95 
vowel 16 
6-87 
32 
12-82 
36 
4-97 
18 
3-88 
38 
9-84 
5 
1-31 
13 
2-70 
int int* 44 
1-90 
51 
3-100 
diphthong 10 
0-79 
12 
0-55 
21 
0-100 
11 
0-87 
16 
0-88 
3 
0-15 
19 
0-74 
int int* 26 
0-100 
31 
0-100 
Table 1: Diphone behavior 
875
rich source of information for word segmenta-
tion: obstruent-initial diphones are generally in-
formative as to the presence/absence of word 
boundaries. However, as we suspected, vowel-
vowel sequences are problematic, since they oc-
cur freely both within words and across word 
boundaries. Korean differs from English in that 
most English diphones occur nearly exclusively 
within words, or nearly exclusively across word 
boundaries (DP11), while in Korean most sono-
rant-obstruent sequences occur both within and 
across words. 
3.2 Errors and word-learning 
It seems reasonable to assume that word-learning 
is best facilitated by seeing multiple occurrences 
of a word. A segmentation that is produced only 
once might be ignored; thus we defined an input 
or output projection as frequent if it occurred 
more than once in the test sample. 
A word learner relying on a phonotactic model 
could expect to successfully identify many fre-
quent words. For 73 of the 100 most frequent 
input words, the only frequent output projection 
in the baseline model was the input word itself, 
meaning that the word was segmented correctly 
in most contexts. For 20 there was no frequent 
output projection, meaning that the word was not 
segmented consistently across contexts, which 
we assume is noise to the learner. In the phrasal 
model, for 16 items the most frequent output pro-
jection was the input word itself and for 64 there 
was no frequent output projection. 
Conversely, of the 100 most frequent potential 
words identified by the baseline model, in 26 
cases the most frequent input projection was the 
output word itself: a real word was correctly 
identified. In 26 cases there was no frequent in-
put projection, and in 48 another input projection 
was at least as frequent as the output word. One 
such example is [mj?n] ?cotton?, frequently seg-
mented out when it was a bound morpheme (?if? 
or ?how many?). The most frequently segmented 
item was [ke], which can be a freestanding word 
(?there/thing?), but was often segmented out from 
words suffixed with [-ke] ?-ly/to? and [-eke] ?to?. 
What do these results mean for a child using a 
phonotactic strategy? First, many of the types 
segmented in a day would be experienced only 
once (and presumably ignored). Second, infants 
would not go far astray if they learned fre-
quently-segmented items as words. 
3.3 Phrase edges and independence 
We suspected the reason that the phrasal DiBS 
model performed so much worse than baseline 
was its assumption that phrase-edge distributions 
approximate word-edge distributions. Phrase be-
ginnings were a good proxy for word beginnings, 
but there were mismatches phrase-finally. For 
example, [a] is much more frequent phrase-
finally than word-finally (because of common 
verb suffixes ending in [a]), while [n] is much 
more frequent word-finally (because of non-
sentence-final suffixes ending in [n]). The posi-
tional independence assumption is too strong. 
4 Conclusion 
This paper extends previous studies by applying 
a computational learning model of phonotactic 
word segmentation to Korean. Various properties 
of Korean led us to believe it would challenge 
both unsupervised phonotactic and lexical ap-
proaches. 
Phonological and morphological analysis of 
errors yielded novel insights. For example, the 
generally greater error rate in Korean is partly 
caused by a high tolerance for vowel-vowel se-
quences within words. Interactions between 
morphology and word order result in violations 
of a key positional independence assumption.  
Phonotactic segmentation was distinctly worse 
than in previous languages (English, Russian), 
particularly for oversegmentation errors. This 
implies the segmentation of simplistic diphone 
models is not cross-linguistically stable, a find-
ing that aligns with other cross-linguistic com-
parisons of segmentation algorithms. In general, 
distinctly worse performance is found for lan-
guages other than English (Sesotho: Blanchard et 
al. 2010; Arabic and Spanish: Fleck 2008). These 
facts suggest that the successful segmentation 
model must incorporate richer phonotactics, or 
integrate some lexical processing. On the bright 
side, we found that frequently segmented items 
were mostly words, so a high segmentation error 
rate does not necessarily translate to a high error 
rate for word-learning. 
References 
Aslin, R. N., Woodward, J. Z., LaMendola, N. P., & 
Bever, T. G. (1996). Models of word segmentation 
in fluent maternal speech to infants. In J. L. Mor-
gan & K. Demuth (Eds.). Signal to syntax. Mah-
wah, NJ: LEA, pp. 117?134. 
Blanchard, D., Heinz, J., & Golinkoff, R. (2010). 
Modeling the contribution of phonotactic cues to 
876
the problem of word segmentation. Journal of 
Child Language 37(3), 487-511. 
Daland, R. & Pierrehumbert, J.B. (2011). Learnability 
of diphone-based segmentation. Cognitive Science 
35(1), 119-155. 
Fleck, M. (2008). Lexicalized phonotactic word seg-
mentation. Proceedings of ACL-08: HLT, 130-138. 
Goldwater, S., Griffiths, T. L., & Johnson, M. (2009). 
A Bayesian framework for word segmentation: 
Exploring the effects of context. Cognition 112(1), 
21-54. 
Kim, B., Lee, G., & Lee, J.-H. (2002). Morpheme-
based grapheme to phoneme conversion using 
phonetic patterns and morphophonemic connec-
tivity information. ACM Trans. Asian Lang. Inf. 
Process. 1(1), 65-82. 
Polka, L. & Sundara, M. (2012). Word segmentation 
in monolingual infants acquiring Canadian-English 
and Canadian-French: Native language, cross-
language and cross-dialect comparisons. Infancy 
17(2), 198-232. 
Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996). 
Statistical learning by 8-month-old infants. Science 
275(5294), 1926-1928. 
Sohn, H.-M. (1999). The Korean Language. Cam-
bridge: Cambridge University Press. 
van de Weijer, J. (1998). Language input for word 
discovery. MPI series in psycholinguistics (No. 9). 
877
