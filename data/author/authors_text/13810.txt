Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 598?602,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Hierarchical Text Classification with Latent Concepts
Xipeng Qiu, Xuanjing Huang, Zhao Liu and Jinlong Zhou
School of Computer Science, Fudan University
{xpqiu,xjhuang}@fudan.edu.cn, {zliu.fd,abc9703}@gmail.com
Abstract
Recently, hierarchical text classification has
become an active research topic. The essential
idea is that the descendant classes can share
the information of the ancestor classes in a
predefined taxonomy. In this paper, we claim
that each class has several latent concepts and
its subclasses share information with these d-
ifferent concepts respectively. Then, we pro-
pose a variant Passive-Aggressive (PA) algo-
rithm for hierarchical text classification with
latent concepts. Experimental results show
that the performance of our algorithm is com-
petitive with the recently proposed hierarchi-
cal classification algorithms.
1 Introduction
Text classification is a crucial and well-proven
method for organizing the collection of large scale
documents. The predefined categories are formed
by different criterions, e.g. ?Entertainment?, ?Sport-
s? and ?Education? in news classification, ?Junk E-
mail? and ?Ordinary Email? in email classification.
In the literature, many algorithms (Sebastiani, 2002;
Yang and Liu, 1999; Yang and Pedersen, 1997) have
been proposed, such as Support Vector Machines
(SVM), k-Nearest Neighbor (kNN), Na??ve Bayes
(NB) and so on. Empirical evaluations have shown
that most of these methods are quite effective in tra-
ditional text classification applications.
In past serval years, hierarchical text classification
has become an active research topic in database area
(Koller and Sahami, 1997; Weigend et al, 1999)
and machine learning area (Rousu et al, 2006; Cai
and Hofmann, 2007). Different with traditional clas-
sification, the document collections are organized
as hierarchical class structure in many application
fields: web taxonomies (i.e. the Yahoo! Directory
http://dir.yahoo.com/ and the Open Direc-
tory Project (ODP) http://dmoz.org/), email
folders and product catalogs.
The approaches of hierarchical text classification
can be divided in three ways: flat, local and global
approaches.
The flat approach is traditional multi-class classi-
fication in flat fashion without hierarchical class in-
formation, which only uses the classes in leaf nodes
in taxonomy(Yang and Liu, 1999; Yang and Peder-
sen, 1997; Qiu et al, 2011).
The local approach proceeds in a top-down fash-
ion, which firstly picks the most relevant categories
of the top level and then recursively making the
choice among the low-level categories(Sun and Lim,
2001; Liu et al, 2005).
The global approach builds only one classifier to
discriminate all categories in a hierarchy(Cai and
Hofmann, 2004; Rousu et al, 2006; Miao and Qiu,
2009; Qiu et al, 2009). The essential idea of global
approach is that the close classes have some com-
mon underlying factors. Especially, the descendan-
t classes can share the characteristics of the ances-
tor classes, which is similar with multi-task learn-
ing(Caruana, 1997; Xue et al, 2007).
Because the global hierarchical categorization can
avoid the drawbacks about those high-level irrecov-
erable error, it is more popular in the machine learn-
ing domain.
However, the taxonomy is defined artificially and
is usually very difficult to organize for large scale
taxonomy. The subclasses of the same parent class
may be dissimilar and can be grouped in differen-
t concepts, so it bring great challenge to hierarchi-
598
Sports
Football
Basketball
Swimming
Surfing
Sports
Water
Football
Basketball
Swimming
Surfing
Ball
(a) (b)
College
High 
School
College
High 
SchoolAcade
my
Figure 1: Example of latent nodes in taxonomy
cal classification. For example, the ?Sports? node
in a taxonomy have six subclasses (Fig. 1a), but
these subclass can be grouped into three unobserv-
able concepts (Fig. 1b). These concepts can show
the underlying factors more clearly.
In this paper, we claim that each class may have
several latent concepts and its subclasses share in-
formation with these different concepts respectively.
Then we propose a variant Passive-Aggressive (PA)
algorithm to maximizes the margins between latent
paths.
The rest of the paper is organized as follows. Sec-
tion 2 describes the basic model of hierarchical clas-
sification. Then we propose our algorithm in section
3. Section 4 gives experimental analysis. Section 5
concludes the paper.
2 Hierarchical Text Classification
In text classification, the documents are often rep-
resented with vector space model (VSM) (Salton et
al., 1975). Following (Cai and Hofmann, 2007),
we incorporate the hierarchical information in fea-
ture representation. The basic idea is that the notion
of class attributes will allow generalization to take
place across (similar) categories and not just across
training examples belonging to the same category.
Assuming that the categories is ? =
[?1, ? ? ? , ?m], where m is the number of the
categories, which are organized in hierarchical
structure, such as tree or DAG.
Give a sample x with its class path in the taxono-
my y, we define the feature is
?(x,y) = ?(y)? x, (1)
where ?(y) = (?1(y), ? ? ? , ?m(y))T ? Rm and ?
is the Kronecker product.
We can define
?i(y) =
{
ti if ?i ? y
0 otherwise , (2)
where ti >= 0 is the attribute value for node v. In
the simplest case, ti can be set to a constant, like 1.
Thus, we can classify x with a score function,
y? = argmax
y
F (w,?(x,y)), (3)
where w is the parameter of F (?).
3 Hierarchical Text Classification with
Latent Concepts
In this section, we first extent the Passive-
Aggressive (PA) algorithm to the hierarchical clas-
sification (HPA), then we modify it to incorporate
latent concepts (LHPA).
3.1 Hierarchical Passive-Aggressive Algorithm
The PA algorithm is an online learning algorithm,
which aims to find the new weight vectorwt+1 to be
the solution to the following constrained optimiza-
tion problem in round t.
wt+1 = arg min
w?Rn
1
2
||w ?wt||2 + C?
s.t. ?(w; (xt, yt)) <= ? and ? >= 0. (4)
where ?(w; (xt, yt)) is the hinge-loss function and ?
is slack variable.
Since the hierarchical text classification is loss-
sensitive based on the hierarchical structure. We
need discriminate the misclassification from ?near-
ly correct? to ?clearly incorrect?. Here we use tree
induced error ?(y,y?), which is the shortest path
connecting the nodes yleaf and y?leaf . yleaf repre-
sents the leaf node in path y.
Given a example (x,y), we look for the w to
maximize the separation margin ?(w; (x,y)) be-
tween the score of the correct path y and the closest
error path y?.
?(w; (x,y)) = wT?(x,y)?wT?(x, y?), (5)
599
where y? = argmaxz ?=y wT?(x, z) and ? is a fea-
ture function.
Unlike the standard PA algorithm, which achieve
a margin of at least 1 as often as possible, we wish
the margin is related to tree induced error ?(y, y?).
This loss is defined by the following function,
?(w; (x,y)) =
{
0, ?(w; (x,y)) > ?(y, y?)
?(y, y?)? ?(w; (x,y)), otherwise (6)
We abbreviate ?(w; (x,y)) to ?. If ? = 0 then wt
itself satisfies the constraint in Eq. (4) and is clearly
the optimal solution. We therefore concentrate on
the case where ? > 0.
First, we define the Lagrangian of the optimiza-
tion problem in Eq. (4) to be,
L(w, ?, ?, ?) = 1
2
||w?wt||2+C?+?(???)???
s.t. ?, ? >= 0. (7)
where ?, ? is a Lagrange multiplier.
We set the gradient of Eq. (7) respect to ? to zero.
? + ? = C. (8)
The gradient of w should be zero.
w ?wt ? ?(?(x,y)? ?(x, y?)) = 0 (9)
Then we get,
w = wt + ?(?(x,y)? ?(x, y?)). (10)
Substitute Eq. (8) and Eq. (10) to objective func-
tion Eq. (7), we get
L(?) = ?1
2
?2||?(x,y)? ?(x, y?)||2
+ ?wt(?(x,y)? ?(x, y?)))? ??(y, y?) (11)
Differentiate Eq. (11 with ?, and set it to zero, we
get
?? = ?(y, y?)?wt(?(x,y)? ?(x, y?)))
||?(x,y)? ?(x, y?)||2 (12)
From ? + ? = C, we know that ? < C, so
?? = min(C, ?(y, y?)?wt(?(x,y)? ?(x, y?)))
||?(x,y)? ?(x, y?)||2
).
(13)
3.2 Hierarchical Passive-Aggressive Algorithm
with Latent Concepts
For the hierarchical taxonomy ? = (?1, ? ? ? , ?c),
we define that each class ?i has a set H?i =
h1?i , ? ? ? , h
m
?i with m latent concepts, which are un-
observable.
Given a label path y, it has a set of several latent
paths Hy. For a latent path z ? Hy, a function
Proj(z) .= y is the projection from a latent path z
to its corresponding path y.
Then we can define the predict latent path h? and
the most correct latent path h?:
h? = arg max
proj(z)?=y
wT?(x, z), (14)
h? = arg max
proj(z)=y
wT?(x, z). (15)
Similar to the above analysis of HPA, we re-define
the margin
?(w; (x,y) = wT?(x,h?)? wT?(x, h?), (16)
then we get the optimal update step
??L = min(C,
?(wt; (x,y))
||?(x,h?)? ?(x, h?)||2
). (17)
Finally, we get update strategy,
w = wt + ??L(?(x,h?)? ?(x, h?)). (18)
Our hierarchical passive-aggressive algorithm
with latent concepts (LHPA) is shown in Algorith-
m 1. In this paper, we use two latent concepts for
each class.
4 Experiment
4.1 Datasets
We evaluate our proposed algorithm on two datasets
with hierarchical category structure.
WIPO-alpha dataset The dataset1 consisted of the
1372 training and 358 testing document com-
prising the D section of the hierarchy. The
number of nodes in the hierarchy was 188, with
maximum depth 3. The dataset was processed
into bag-of-words representation with TF?IDF
1World Intellectual Property Organization, http://www.
wipo.int/classifications/en
600
input : training data set: (xn,yn), n = 1, ? ? ? , N ,
and parameters: C,K
output: w
Initialize: cw? 0,;
for k = 0 ? ? ?K ? 1 do
w0 ? 0 ;
for t = 0 ? ? ?T ? 1 do
get (xt,yt) from data set;
predict h?,h?;
calculate ?(w; (x,y)) and?(yt, y?t);
if ?(w; (x,y)) ? ?(yt, y?t) then
calculate ??L by Eq. (17);
update wt+1 by Eq. (18). ;
end
end
cw = cw +wT ;
end
w = cw/K ;
Algorithm 1:Hierarchical PA algorithmwith la-
tent concepts
weighting. No word stemming or stop-word
removal was performed. This dataset is used
in (Rousu et al, 2006).
LSHTC dataset The dataset2 has been constructed
by crawling web pages that are found in the
Open Directory Project (ODP) and translating
them into feature vectors (content vectors) and
splitting the set of Web pages into a training,
a validation and a test set, per ODP category.
Here, we use the dry-run dataset(task 1).
4.2 Performance Measurement
Macro Precision, Macro Recall and Macro F1 are
the most widely used performance measurements
for text classification problems nowadays. The
macro strategy computes macro precision and re-
call scores by averaging the precision/recall of each
category, which is preferred because the categories
are usually unbalanced and give more challenges to
classifiers. The Macro F1 score is computed using
the standard formula applied to the macro-level pre-
cision and recall scores.
MacroF1 = P ?R
P +R
, (19)
2Large Scale Hierarchical Text classification Pascal Chal-
lenge, http://lshtc.iit.demokritos.gr
Table 1: Results on WIPO-alpha Dataset.?-? means that
the result is not available in the author?s paper.
Accuracy F1 Precision Recall TIE
PA 49.16 40.71 43.27 38.44 2.06
HPA 50.84 40.26 43.23 37.67 1.92
LHPA 51.96 41.84 45.56 38.69 1.87
HSVM 23.8 - - - -
HM3 35.0 - - - -
Table 2: Results on LSHTC dry-run Dataset
Accuracy F1 Precision Recall TIE
PA 47.36 44.63 52.64 38.73 3.68
HPA 46.88 43.78 51.26 38.2 3.73
LHPA 48.39 46.26 53.82 40.56 3.43
where P is the Macro Precision and R is the Macro
Recall. We also use tree induced error (TIE) in the
experiments.
4.3 Results
We implement three algorithms3: PA(Flat PA), H-
PA(Hierarchical PA) and LHPA(Hierarchical PA
with latent concepts). The results are shown in Table
1 and 2. For WIPO-alpha dataset, we also compared
LHPA with two algorithms used in (Rousu et al,
2006): HSVM and HM3.
We can see that LHPA has better performances
than the other methods. From Table 2, we can see
that it is not always useful to incorporate the hierar-
chical information. Though the subclasses can share
information with their parent class, the shared infor-
mation may be different for each subclass. So we
should decompose the underlying factors into dif-
ferent latent concepts.
5 Conclusion
In this paper, we propose a variant Passive-
Aggressive algorithm for hierarchical text classifi-
cation with latent concepts. In the future, we will
investigate our method in the larger and more noisy
data.
Acknowledgments
This work was (partially) funded by NSFC (No.
61003091 and No. 61073069), 973 Program (No.
3Source codes are available in FudanNLP toolkit, http:
//code.google.com/p/fudannlp/
601
2010CB327906) and Shanghai Committee of Sci-
ence and Technology(No. 10511500703).
References
L. Cai and T. Hofmann. 2004. Hierarchical document
categorization with support vector machines. In Pro-
ceedings of CIKM.
L. Cai and T. Hofmann. 2007. Exploiting known tax-
onomies in learning overlapping concepts. In Pro-
ceedings of International Joint Conferences on Arti-
ficial Intelligence.
R. Caruana. 1997. Multi-task learning. Machine Learn-
ing, 28(1):41?75.
D. Koller and M Sahami. 1997. Hierarchically classify-
ing documents using very few words. In Proceedings
of the International Conference on Machine Learning
(ICML).
T.Y. Liu, Y. Yang, H. Wan, H.J. Zeng, Z. Chen, and W.Y.
Ma. 2005. Support vector machines classification
with a very large-scale taxonomy. ACM SIGKDD Ex-
plorations Newsletter, 7(1):43.
Youdong Miao and Xipeng Qiu. 2009. Hierarchical
centroid-based classifier for large scale text classifica-
tion. In Large Scale Hierarchical Text classification
(LSHTC) Pascal Challenge.
Xipeng Qiu, Wenjun Gao, and Xuanjing Huang. 2009.
Hierarchical multi-class text categorization with glob-
al margin maximization. In Proceedings of the ACL-
IJCNLP 2009 Conference, pages 165?168, Suntec,
Singapore, August. Association for Computational
Linguistics.
Xipeng Qiu, Jinlong Zhou, and Xuanjing Huang. 2011.
An effective feature selection method for text catego-
rization. In Proceedings of the 15th Pacific-Asia Con-
ference on Knowledge Discovery and Data Mining.
Juho Rousu, Craig Saunders, Sandor Szedmak, and John
Shawe-Taylor. 2006. Kernel-based learning of hierar-
chical multilabel classification models. In Journal of
Machine Learning Research.
G. Salton, A. Wong, and CS Yang. 1975. A vector space
model for automatic indexing. Communications of the
ACM, 18(11):613?620.
F. Sebastiani. 2002. Machine learning in automated text
categorization. ACM computing surveys, 34(1):1?47.
A. Sun and E.-P Lim. 2001. Hierarchical text classi-
fication and evaluation. In Proceedings of the IEEE
International Conference on Data Mining.
A. Weigend, E. Wiener, and J Pedersen. 1999. Exploit-
ing hierarchy in text categorization. In Information
Retrieval.
Y. Xue, X. Liao, L. Carin, and B. Krishnapuram. 2007.
Multi-task learning for classification with dirichlet
process priors. The Journal of Machine Learning Re-
search, 8:63.
Y. Yang and X. Liu. 1999. A re-examination of text
categorization methods. In Proc. of SIGIR. ACMPress
New York, NY, USA.
Y. Yang and J.O. Pedersen. 1997. A comparative study
on feature selection in text categorization. In Proc. of
Int. Conf. on Mach. Learn. (ICML), volume 97.
602
Triplet-Based Chinese Word Sense Induction
Zhao Liu
School of Computer Science
Fudan University
Shanghai, China
ZLiu.fd@gmail.com
Xipeng Qiu
School of Computer Science
Fudan University
Shanghai, China
xpqiu@fudan.edu.cn
Xuanjing Huang
School of Computer Science
Fudan University
Shanghai, China
xjhuang@fudan.edu.cn
Abstract
This paper describes the implementa-
tion of our system at CLP 2010 bake-
off of Chinese word sense induction.
We first extract the triplets for the tar-
get word in each sentence, then use
the intersection of all related words of
these triplets from the Internet. We
use the related word to construct fea-
ture vectors for the sentence. At last
we discriminate the word senses by
clustering the sentences. Our system
achieved 77.88% F-score under the of-
ficial evaluation.
1 Introduction
The goal of the CLP 2010 bake-off of Chi-
nese word sense induction is to automati-
cally discriminate the senses of Chinese target
words by the use of only un-annotated data.
The use of word senses instead of word
forms has been shown to improve perfor-
mance in information retrieval, information
extraction and machine translation. Word
Sense Disambiguation generally requires the
use of large-scale manually annotated lexical
resources. Word Sense Induction can over-
come this limitation, and it has become one
of the most important topics in current com-
putational linguistics research.
In this paper we introduce a method to
solve the problem of Chinese word sense in-
duction.For this task, Firstly we constructed
triplets containing the target word in every
instance, then searched the intersection of all
the three words from the Internet with web
searching engine and constructed feature vec-
tors.Then we clustered the vectors with the
sIB clustering algorithm and at last discrimi-
nated the word senses.
This paper is organized as following: firstly
we introduce the related works. Then we talk
about the methods in features selection and
clustering. The method of evaluation and the
result of our system is following. At last we
discuss the improvement and the weakness of
our system.
2 Related Works
Sense induction is typically treated as a
clustering problem, by considering their co-
occurring contexts, the instances of a target
word are partitioned into classes. Previous
methods have used the first or second or-
der co-occurrence (Pedersen and Bruce, 1997;
Sch?tze, 1998), parts of speech, and local col-
locations (Niu et al, 2007). The size of con-
text window is also various, it can be as small
as only two words before and after the target
words. It may be the sentence where the tar-
get word is in. Or it will be 20 surrounding
words on either side of the target words and
even more words.
After every instance of the target word is
represented as a feature vector, it will be the
input of the clustering methods. Many clus-
tering methods have been used in the task
of word sense induction. For example, k-
means and agglomerative clustering (Sch?tze,
1998). sIB (Sequential Information Bottle-
neck) a variation of Information Bottleneck is
applied in (Niu et al, 2007). In (Dorow and
Widdows, 2003) Graph-based clustering algo-
rithm is employed that in a graph a node rep-
resents a noun and two nodes have an edge be-
tween them if they co-occur in list more than
a given number of times. A generative model
based on LDA is proposed in (Brody and La-
pata, 2009).
In our method, we use the triplets (Bordag,
2006) and their intersections from the Internet
to construct the feature vectors then sIB is
used as the clustering method.
3 Feature Selection
Our method select the features of the words
similar to (Bordag, 2006) is also using the
triplets. In Chinese there are no natural sep-
arators between the words as English, so the
first step in Chinese language processing is of-
ten the Chinese word segmentation. In our
system we use the FudanNLP toolkit1 to split
the words.
At the first stage, we split the instance of
the target word and filter out the numbers,
English words and stop words from it. So we
get a sequence of the words. Then we select
two words before the target and another two
words after it. If there are no words before or
after then leave it empty. After that we enu-
merate two words from the selected four words
to construct a triplets together with the target
words. So we can get several triplets for every
instance of the target. Because the faulty of
Chinese word segmentation and some special
target word for example a single Chinese char-
acter as a word, there are some errors finding
the position of the target words. If the word
is a single Chinese character and the toolkit
combine it with other Chinese characters to
be a word, we will use that word as the tar-
get instead of the character to construct the
triplets.
The second stage is obtaining corpus from
the Internet. For every triplet we search the
three words sequence in it with a pair of dou-
ble quotation marks in Baidu web searching
engine2. It gives the snippets of the webs
1http://code.google.com/p/fudannlp/
2http://www.baidu.com
which have all the three words in it. We se-
lect the first 50 snippets of each triplets. If
the number of the snippets is less than 50,
we will ignore that triplet. For some rare
words the snippets searched from the Internet
for all the triplets of the instance is less than
50. In that situation we will search the target
word and another one co-occurring word in
the searching engine to achieve enough snip-
pets as features. After searching the triplets
we select the first three triplets (or doublets)
with largest amount of the webs searched by
the searching engine. For every instance there
are three or less triplets (or doublets) and we
have obtained many snippets for them. After
segmenting and filtering these snippets we use
the bag of words from them as the feature for
this instance.
The last stage of feature selection is to con-
struct the feature vector for every instances
containing the target word. In the previous
stage we get a bag of words for each instance.
For all the instances of one target word we
make a statistic of the frequence of each word
in the bags. In our system we select the words
whose frequence is more than 50 as the dimen-
sions for the feature vectors. From the tests
we find that when this thread varies from 50 to
120 the result of our system is nearly the same,
but outside that bound the result will become
rather bad. So we use 50 as the thread. Af-
ter constructing the dimension of that target
word, we can get a feature vector for each in-
stance that at each dimension the number is
the frequence of that word occurs in that po-
sition.
We obtain the feature vectors for the target
words by employing these three stage. The
following work is clustering these vector to get
the classes of the word senses.
4 The Clustering Algorithm
There are many classical clustering methods
such as k-means, EM and so on. In (Niu et
al., 2007) they applied the sIB (Slonim et al,
2002) clustering algorithm at SemEval-2007
for task 2 and it achieved a quite good result.
And at first this algorithm is also introduced
for the unsupervised document classification
problem. So we use the sIB algorithm for clus-
tering the feature vectors in our system.
Unlike the situation in (Niu et al, 2007),
the number of the sense classes is provided in
CLP2010 task 4. So we can apply the sIB
algorithm directly without the sense number
estimation procedure in that paper. sIB algo-
rithm is a variant of the information bottle-
neck method.
Let d represent a document, and w repre-
sent a feature word, d ? D,w ? F . Given
the joint distribution p(d,w), the document
clustering problem is formulated as looking for
a compact representation T for D, which re-
serves as much information as possible about
F . T is the document clustering solution. For
solving this optimization problem, sIB algo-
rithm was proposed in (Slonim et al, 2002),
which found a local maximum of I(T, F ) by:
given a initial partition T, iteratively draw-
ing a d ? D out of its cluster t(d), t ? T ,
and merging it into tnew such that tnew =
argmaxt?Td(d, t). d(d, t) is the change of
I(T, F ) due to merging d into cluster tnew,
which is given by
d(d, t) = (p(d)+p(t))JS(p(w|d), p(w|t)). (1)
JS(p, q) is the Jensen-Shannon divergence,
which is defined as
JS(p, q) = pipDKL(p||p) + piqDKL(q||p), (2)
DKL(p||p) =
?
y
p log p
p
, (3)
DKL(q||p) =
?
y
q log q
p
, (4)
{p, q} ? {p(w|d), p(w|t)}, (5)
{pip, piq} ? {
p(d)
p(d) + p(t)
, p(t)
p(d) + p(t)
}, (6)
p = pipp(w|d) + piqp(w|t). (7)
In our system we use the sIB algorithm in
the Weka 3.5.8 cluster package to cluster the
feature vectors obtained in the previous sec-
tion. The detailed description of the sIB algo-
rithm in weka can refer to the website 3. And
the parameters for this Weka class is that: the
number of clusters is the number of senses pro-
vided by the task, the random number seed is
zero and the other parameters like maximum
number of iteration and so on is set as default.
5 CLP 2010 Bake-Off of Chinese
Word Sense Induction
5.1 Evaluation Measure
The evaluation measure is described as fol-
lowing:
We consider the gold standard as a solu-
tion to the clustering problem. All examples
tagged with a given sense in the gold standard
form a class. For the system output, the clus-
ters are formed by instances assigned to the
same sense tag (the sense tag with the highest
weight for that instance). We will compare
clusters output by the system with the classes
in the gold standard and compute F-score as
usual. F-score is computed with the formula
below.
Suppose Cr is a class of the gold standard,
and Si is a cluster of the system generated,
then
1. F ? score(Cr, Si) = 2?P?RP+R
2. P =the number of correctly labeled ex-
amples for a cluster/total cluster size
3. R =the number of correctly labeled ex-
amples for a cluster/total class size
Then for a given class Cr,
FScore(Cr) = max
Si
(F ? score(Cr, Si)) (8)
Then
FScore =
c
?
r=1
nr
n
FScore(Cr) (9)
3http://pacific.mpi-cbg.de/javadoc/Weka/
clusterers/sIB.html
Where c is total number of classes, nr is the
size of class Cr , and n is the total size.
5.2 DataSet
The data set includes 100 ambiguous Chi-
nese words and for every word it provided 50
instances. Besides that they also provided a
sample test set of 2500 examples of 50 target
words with the answers to illustrate the data
format.
Besides the sIB algorithm we also apply the
k-means and EM algorithm to cluster the fea-
ture vectors. These algorithms are separately
using the simpleKMeans class and the EM
class in the Weka 3.5.8 cluster package. Ex-
cept the number of clusters set as the given
number of senses and number of seeds set as
zero, all other parameters are set as default.
For the given sample test set with answers the
result is illustrated in the Table 1 below.
algorithm F-score
k-means 0.7025
EM 0.7286
sIB 0.8132
Table 1: Results of three clustering algorithms
From Table 1 we can see the sIB clustering
algorithm improves the result of the Chinese
word sense induction evidently.
In the real test data test containing 100 am-
biguous Chinese words, our system achieves a
F-score 0.7788 ranking 6th among the 18 sys-
tems submitted. The best F-score of these 18
systems is 0.7933 and the average of them is
0.7128.
5.3 Discussion
In our system we only use the local collo-
cations and the co-occurrences of the target
words. But the words distance for the target
word in the same sentence and the parts of
speech of the neighboring word together with
the target word is also important in this task.
In our experiment we used the parts of
speech for the target word and each word be-
fore and after it achieved by the Chinese word
segmentation system as part of the features
vectors for clustering. With a proper weight
on each POS dimension in the feature vectors,
the F score for some word in the given sample
test set with answers improved evidently. For
example the Chinese word ????, the F score
of it was developed from 0.5983 to 0.7573. But
because of the fault of the segmentation sys-
tem and other reasons F score of other words
fell and the speed of the system was rather
slower than before, we gave up this improve-
ment finally.
Without the words distance for the target
word in the same sentence the feature vectors
maybe lack some information useful. So if we
can calculate the correlation between the tar-
get word and other words, we will use these
word sufficiently. However because of quan-
tity of the Internet corpus is unknown, we
didn?t find the proper method to weigh the
correlation.
From the previous section we find that the
F score for the real test data test is lower than
that for the sample test set. It is mainly be-
cause there are more single Chinese charac-
ters (as words) in the real test data set. Our
system does not process these characters spe-
cially. For most of the Chinese characters we
can?t judge their correct senses only from the
context where they appear. Their meaning
always depends on the collocations with the
other Chinese characters with which they be-
come a Chinese word. However our system
discriminates the senses of them only refer-
ring to the context of them, it can?t judge the
meaning of these Chinese characters properly.
Maybe the best way is to search them in the
dictionary.
However our system does not always have a
very poor performance for any single Chinese
character (as a word). The result is quite good
for some Chinese characters. For example the
Chinese character ??? which has three mean-
ing: valley, millet and a family name, the pre-
cision (P) of our system is 0.760. But for most
of single Chinese characters such as ??? and
???, it is so bad that the result in the sample
test worked rather better than the real test.
In Chinese the former character ??? tends
to express a complete meaning and the other
characters in the word which they combine of-
ten modify it such as the characters ??? and
??? in the word ???? and ????. So this
character can have a relatively high correla-
tion with the words around and our system
can deal with such characters like it. Unfor-
tunately most characters need other charac-
ters to represent a complete meaning as the
the latter ??? and ??? so they almost have
no correlation with the words around but with
those characters in the word in which they oc-
cur. But our system only uses the context fea-
tures and even doesn?t do any special process
about these single Chinese characters. There-
fore our system can not address those char-
acters appropriately and we need to find a
proper method to solve it, using a dictionary
may be a choice.
This method works better for nouns and ad-
jectives (in the sample test data set there are
only 4 adjectives), but for verbs F score falls
a little, illustrated in the Table 2 below.
POS F-score
nouns 0.8473
adjectives 0.8543
verbs 0.7921
Table 2: Results of each POS in the sample
test data set
Only using the local collocations in our sys-
tem the F score is achieve above 80% (in the
sample test), it demonstrates to some extent
the information of collocations is so important
that we should pay more attention to it.
6 Conclusion
The triplet-based Chinese word sense induc-
tion method is fitted to the task of Chinese
word sense induction and obtain rather good
result. But for some single characters word
and some verbs, this method is not appropri-
ate enough. In the future work, we will im-
prove the method with more reasonable triplet
selection strategies.
Acknowledgments
This work was (partially) funded by 863
Program (No. 2009AA01A346), 973 Pro-
gram (No. 2010CB327906), and Shanghai Sci-
ence and Technology Development Funds (No.
08511500302).
References
Bordag, S. 2006. Word sense induction: Triplet-
based clustering and automatic evaluation. Pro-
ceedings of EACL-06. Trento.
Brody, S. and M. Lapata. 2009. Bayesian word
sense induction. In Proceedings of the 12th Con-
ference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 103?
111. Association for Computational Linguistics.
Dorow, B. and D. Widdows. 2003. Discovering
corpus-specific word senses. In Proceedings of
the tenth conference on European chapter of
the Association for Computational Linguistics-
Volume 2, pages 79?82. Association for Compu-
tational Linguistics.
Niu, Z.Y., D.H. Ji, and C.L. Tan. 2007. I2r: Three
systems for word sense discrimination, chinese
word sense disambiguation, and english word
sense disambiguation. In Proceedings of the 4th
International Workshop on Semantic Evalua-
tions, pages 177?182. Association for Compu-
tational Linguistics.
Pedersen, T. and R. Bruce. 1997. Distinguishing
word senses in untagged text. In Proceedings of
the Second Conference on Empirical Methods in
Natural Language Processing, volume 2, pages
197?207.
Sch?tze, H. 1998. Automatic word sense discrim-
ination. Computational Linguistics, 24(1):97?
123.
Slonim, N., N. Friedman, and N. Tishby. 2002.
Unsupervised document classification using se-
quential information maximization. In Proceed-
ings of the 25th annual international ACM SI-
GIR conference on Research and development
in information retrieval, pages 129?136. ACM.
