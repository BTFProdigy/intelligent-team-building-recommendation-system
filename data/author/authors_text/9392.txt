Learn to speak and to write, learn to use your mind
The relevance of automatic text generation research for people
Michael Zock
LIMSI-CNRS, B.P.133,
91403 Orsay, France
zock@limsi.fr
Abstract
The aim of this talk is to show to what
extent the work on text generation by
computer (TGBC) does not address
some of the fundamental problems
people struggle with when generating
language (TGBP). We will substantiate
this claim by taking two tasks on
which a lot of research has been
carried out during the last 15 years:
discourse planning and lexicalisation.
1 Discourse planning
While a tremendous amount of work has been
done on the generation of coherent discourse,
little if any has been devoted to writing. As a
result, many fundamental problems have been
overlooked or have been dealt with on the basis
of wrong assumptions. Also, little, if any of the
results achieved in the TGBC framework can be
reused in the classroom or in the context of an
intelligent writing-aid (tools for assisting the
writer to structure her/his thoughts: outline
planning). Let us consider some of the reasons
why this is so.
? Top-down processing: in the TGBC-
community texts are generally processed top to
bottom. Given some goal one looks for data
(messages) and structures which integrate them.
While this is a clever way to handle the
problem, it does not give a precise reflection of
the writers? situation. First of all, it is not true
that content and structure are always determined
simultaneously, an assumption accepted since
Moore & Paris (1993). Secondly, writers gene-
rally switch between data-driven (brain-
storming) and structure-driven processing (out-
lining). Thirdly, there is a triangular relationship
between messages, structures and goals (or
effects), changing any of them can affect the
others. Yet, at present we do not have the fain-
test idea what effect(s) a specific propositional
or conceptual configuration (order of messages)
might produce.
? Lack of a Conceptual Structure Theory
(CST): messages tend come to our mind in any
order and without exhibiting their potential
links. We have to discover these later, and to
reorganize the former in order to reveal the
structure to the reader. Writing is thinking.
These last three points are crucial, yet none of
the existing theories (schema, RST) is really
able to take them into account. Just imagine
how complex it is to recognize the fact that
there is a causal link between two events. We
don?t have a solid theory of causality, leave
alone a method of operationalizing it (i.e. infer
this kind of link solely on the basis of the
intrinsic features of the events involved).
? Interaction: As we all know, texts have
structure. This latter is generally the result of
discourse planning (schemata or RST-based) or
reasoning (chain of inferencing), in which case
the structure emerges as a side effect. The major
shortcoming of all these techniques is that they
do not model the interaction between the
conceptual data (ideas, messages), the text
structure and the rhetorical effects: (all) the data
to be communicated and the global discourse
goal are generally given with the input.1 The
problem of reconciling mismatches between
data and structure,2 and the problem of variable
rhetorical effects/goals as a function of various
linearization strategies is not addressed at all.3
2 Lexicalisation
Lexicalisation amounts mainly to searching and
choosing: one has to find lemmata, matching a
given conceptual chunk, and then one has to
choose among them. While much emphasis has
been given to the notion of choice, far less
attention has been paid to the search mecha-
nisms (or access strategies). I will present
during my talk some preliminary results
concerning a system that is meant to help people
to overcome the tip-of-the tongue problem, a
well known stumbling block in real-time
processing: we know what we want to say, we
know that we do know the word, yet we cannot
access it (Brown and Mc Neill, 1966).
If the fundamental role of a dictionary in
NLG is obvious, it is less evident as to the
principles governing its compilation. A good
dictionary is a place with a lot of information,
structured in such a way that the relevant
information is easily accessible when needed. In
other words, what counts is 'what is in the
dictionary' (content) and 'how the information is
organized (meaning, form, sound). These two
factors are not sufficient though: access depends
not only on the structure of the lexicon
(organisation), but also on the efficiency of
                                                 
1 While in Moore & Paris (1993), the messages are
not given, the goal is?: it cannot emerge as a side
effect.
2 What shall we do if not all the data can be
integrated, or if we lack data for filling all the
slots of a chosen structure? Shall we keep the
structure and look for more data, or use a dif-
ferent structure as it integrates more of the data?
3 One of the reasons for this is that we do not have
a clear understanding concerning the mapping
between different conceptual configurations and
their corresponding rhetorical effect(s). If we did,
we could use them bidirectionally (for analysis
and generation).
search strategies, an issue not addressed at all
by the generation community. As a matter of
fact, from a strict computational linguistic point
of view, the whole matter may be a non-issue.
However, the problem does become relevant
when we look at generation as a machine-me-
diated process (people using a word processor
for writing) or from a psycholinguistic point of
view: word access in writing or spontaneous
discourse.
? The speaker?s problem?: choosing words,
finding them or both? ? Obviously, there is more
to lexicalisation than just choosing words: one
has to find them to begin with. No matter how
rich a lexical database may be, it is of little use
if one cannot access the relevant information in
time. Access is probably THE major problem that
we have to cope with when trying to produce
language in real-time (in spoken or written
form). As I will show during my talk, this is
precisely a point where computers can be of
considerable help.
Work on memory has shown that access
depends crucially on the way information is
organized, yet the latter can vary to a great
extent. From speech error literature we learn,
that ease of access depends not only on meaning
relations,?, i.e. the way words are organized in
our mind),? but also on linguistic form (letters,
phonemes). Researchers collecting speech errors
have offered countless examples of phono-
logical errors in which segments (phonemes,
syllables or words) are added, deleted, anti-
cipated or exchanged (Fromkin, 1993). The data
clearly show that knowing the meaning of
words does not guarantee their access.
The work on speech errors also reveals that
words are stored in at least two modes, by
meaning and by form (written, spoken), and it is
often this latter which inhibits finding the right
token: having inadvertently recombined the
components of a given word (syllable scramb-
ling), one may end up producing a word, which
either does not exist or is simply different from
the one in mind. This kind of recombination,
resulting from bookkeeping problems (due to
time pressure), parallel processing and infor-
mation overload, may disturb or prevent the
access of the right word. Hence the usefulness
of a tool which allows the process to be
reversed. In order to allow this to be done, it is
necessary to represent words not only in terms
of their meaning, but also in terms of their
written and spoken form. The fact that words are
indexed both by meaning and by sound could
now be used to our advantage. The phonetic co-
ding of words allows the recombination of their
segments (syllables), hence the presentation of
new candidates, among which the user should
find the one s/he is looking for.4 The fact that
words are coded semantically keeps the number
of candidates to be presented small.
Conclusion
I have tried to illustrate briefly to what extent
we have neglected the human factor in our
work. I have also attempted to show how a
simple computational method (combinatorics
and filtering) can be used to bridge (one of) the
gap(s) between TGBC and TGBP: text generation
by people.
References
Roger Brown and David Mc Neill. 1966. The tip
of the tongue ? phenomenon. Journal of Verbal
Learning and Verbal Behavior?, 5, 325-337
Viktoria Fromkin. 1993. Speech Production. In
Psycholinguistics edited by Jean Berko-Gleason
& Nan Bernstein Ratner. Fort Worth, TX:
Harcourt, Brace, Jovanovich
Johanna Moore and Cecile Paris. 1993.
Planning text for advisory dialogues: capturing
intentional and rhetorical information.
Computational Linguistics, 19(4).
                                                 
4
 The assumption is that speakers produce words
that formwise are reasonably close to the target
word. A fact that is supported by psycholinguistic
evidence.
Sorry, what was your name again, or how to overcome
the tip-of-the tongue problem with the help of a computer?
Michael Zock
LIMSI-CNRS, B.P.133
91403 Orsay-Cedex, France
zock@limsi.fr
Abstract
A speaker or writer has to find words for
expressing his thoughts. Yet, knowing a
word does not guarantee its access. Who
hasn?t experienced the problem of looking
for a word he knows, yet is unable to ac-
cess (in time) ? Work done by psy-
chologists reveals that people being in this
so called tip-of-the-tongue state (TOT)
know a lot about the word : meaning,
number of syllables, origine, etc. Speakers
are generally able to recognize the word,
and if they produce an erroneous word,
that token shares many things with the tar-
get word (initial/final letter/phoneme, part
of speech, semantic field, etc.). This being
so, one might want to take advantage of
the situation and build a program that as-
sists the speaker/writer by revealing the
word that?s on his/her mind (tongue/pen).
Three methods will be presented, the first
one being implemented.
1 The context or starting point
I?m currently involved in a project (PA-
PILLON)1 whose goal is to build a huge mul-
tilingual lexical data-base (English-French-
Japanese, Thai) from which one can extract
digital bilingual dictionaries. The latter can
be customized to fit different needs: dictiona-
ries to be used by people vs. dictionaries to
be used by machines (e.g. automatic transla-
tion).
One of the ideas is to enhance this dic-
tionary by adding certain functions, in order
to capitalize on the data. Rather than being a
                                                      
1
 http://www.papillon-dictionary.org
component supporting a single task, the dic-
tionary is at the centre, supporting the user in
a variety of tasks like reading, writing, me-
morization of words or automation of syn-
tactic structures. Particular emphasis will be
given to word access, the topic of this paper,
because, what is a dictionary good for, if one
cannot access the data it contains? The ap-
proach taken is generic, hence, it applies not
only within this particular context.
Word access being a fundamental task in
language production, one might wonder what
could be learned by gleaning at work done in
the context of automatic text generation.
2 Word access in Natural-Language 
Generation
A lot of (natural language generation) resear-
chers have been interested in lexical issues
during the last fifteen years or so.2 Yet des-
pite this enormous body of work, the issue of
word access has not been addressed at all
within this community, not even in Ward?s
extensive problem catalog (Ward 1988).
While from a strict computational linguistic
point of view, the whole matter may be a non-
issue,3 however, if we address the problem of
lexicalization from a psycholinguistic or
man-machine interaction point of view
                                                      
2
 For excellent surveys see (Robin, 1990; Wanner
1996).
3
 Most programs running serially, there is no such
thing as competition. Hence, problems like inter-
ference , confusion or forgetting do not occur.
Furthermore, computers having a perfect memory,
stored information can generally be easily acces-
sed. The situation is quite different for people.
(spontaneous discourse or writing on a com-
puter), things are quite different. Just as
?knowing a word? does not imply ?being
able to access it?, ?choosing a word? does not
imply ?being able to find the set of candidates
from which to choose?. The situation is so-
mehow different in psycholinguistics. Again,
there is an enormous body of research (Mar-
slen-Wilson, 1989; Aitchinson, 1987; Levelt,
1992, to name just those). While all these
authors take up the issue of word access, they
do not consider the use of computers for hel-
ping people in their task. Yet this is precisely
what I do here.
3 What prevents us from finding a
word?
In order to answer this question, let us take a
look at the time course of lexicalization. Ac-
cording to psychologists (Butterworth,
1989:110; Levelt 1989), lexical access takes
place in two temporally distinct stages. In the
first stage the speaker checks the semantic
lexicon for a lemma expressing the concep-
tual input.4 If he can find one, he will take it
and consult then the phonological lexicon in
order to find the appropriate phonological
form.5
Errors can occur at both ends. Yet, since
the two stages are independent, errors belong
to either category, but never to both. Errors at
the semantic level will yield a wrong lemma
(e.g. hate instead of love), while errors at the
phonological level may result in the wrong
phonological form. For example, the intented
relegate may surface as renegate or delegate
(/l/ and /n/ as well /r/ and /d/ being phonolo-
gically relatively close), turn on the heater
switch may result in turn on the sweeter hitch
(Clark & Clark, 1977), etc. As one can see,
these words are all phonologically reasonably
close to the target word, yet, it is precisely
                                                      
4
 Suppose you wanted to refer to a castor, then
there could be a competition between the lemmata
?otter, beaver?.
5
 If the chosen lemma were ?beaver? then  all
words starting with ?b-e-a? or ?b-e-e?  could be
considered as candidates.
this proximity that prevents the speaker to
access the ?right? word.
4 The speaker?s problem: choosing
words, finding them, or both?
Obviously, there is more to lexicalisation than
just choosing words: one has to find them to
begin with. No matter how rich a lexical data-
base may be, it is of little use if one cannot ac-
cess the relevant information in time.
Work on memory has shown that access de-
pends crucially on the way information is orga-
nized (Baddeley, 1982). From speech error lit-
erature (Fromkin 1973) we learn that ease of
access depends not only on meaning relations
(word bridges, i.e. associations) or the structure
of the lexicon (i.e. the way words are organized
in our mind),? but also on linguistic form.
Researchers collecting speech errors have of-
fered countless examples of phonological errors
in which segments (phonemes, syllables or
words) are added, deleted, anticipated or ex-
changed. Reversals like /aminal/ instead of
/animal/, or /karpsihord/ instead of /harpsikord/
are not random at all, they are highly systematic
and can be explained. Examples such as grastly,
a blend of grizzly + ghastly, or Fatz and Kodor
(instead of Katz and Fodor) clearly show that
knowing the meaning of a word does not guar-
antee its access.
The work on speech errors also reveals that
words are stored in two modes, by meaning and
by form (sound), and it is often this latter which
inhibits finding the right token: having recom-
bined inadvertently the components of a given
word (syllable scrambling), one may end up
producing a word, which either does not exist or
is simply different from the one in mind. This
kind of recombination, resulting from bookkee-
ping problems due to time pressure, parallel
processing and information overload, may dis-
turb or prevent the access of words. Hence the
usefulness of a tool that allows to revert the
process.
5 Three methods for enabling the
computer to guess the right word
I shall present here three methods (one based on
form, another based on meaning, the last one
based on a combination of both) for helping the
writer to find the word he is looking for. So far,
only the first method is implemented.
5.1 Access by form
The component described below is part of a
larger system PIC (Fournier & Letellier, 1990).
For its adaptation to the problem of lexical ac-
cess see Zock & Fournier (2001).
The system has two basic mechanisms for
finding the right word: anacodes and phoneti-
codes. The former deals with errors due to per-
mutations, while the latter deals with homo-
phones. Since an anacode is equivalent to the set
of letters composing the word, scrambled letters
(unwanted permutations) are not a problem at
all. The system would still find the right word,
provided that there is such a candidate in the
dictionary, and provided that the user didn't
omit, add or replace one character(s) by another.
For example, if the input were aclibrer instead
of calibrer, the system would have no difficulty
to find the target word (calibrer), since both
words are composed of the same set of letters
(a/b/c/e/i/l/r). If the user added letters outside of
the anacode, the system would need several runs
to check alternative spellings by making local
variations (delete or add a character by making
systematic permutations).
The second technique (phoneticodes) con-
sists in converting graphemes into phonemes,
which allows the system to deal with spelling
errors due to homophony, a very frequent phe-
nomenon in French (see figure 1).
FRENCH ENGLISH SYNT. CAT. DOMAIN
vingt twenty Adjective NUMBER
vin wine Noun-singular BEVERAGE
vins wines Noun-plural BEVERAGE
je vins I came Verb-past
tense
MOUVEMENT
tu vins you came Verb-past tense MOUVEMENT
il vint he came Verb-past
tense
MOUVEMENT
?qu?il
v?nt
...that he
came
Verb-
subjonctif
MOUVEMENT
je vaincs I win V-pres. tense COMPETITION
tu vaincs you win V-pres. tense COMPETITION
il vainc he wins V-pres. tense COMPETITION
vaincs win V-Imperative COMPETITION
en vein in vain Adverb UTILITY
Figure 1 : The many ways of writing /vR/
For example, the system would be able to
deal with errors like vin, vins, vein, vint,
vaincs, etc. instead of vingt. If the system can-
not find directly a candidate, it will perform lo-
cal changes by performing permutations of pho-
nemes or syllables. Hence it would have no
problem to find the word poteau (pole) instead
of topos (topic), both words being composed of
the same syllables (/po-to/), the only difference
being their order.
The situation is more complex and may even
become intractable if extraneous material is
added, or if the correction yields an existing, yet
semantically different word from what was in-
tended. Suppose that the target word were "mai-
son" (house), while the user typed ?masson?.
Relying on the phoneticode, the system might
suggest "ma?on" (bricklayer), a word that exists,
but which is not at all what was intended. Rely-
ing on the anacode, it would fail, because none
of the permutations would result in the target
word.
5.2 Access by meaning: navigation in a 
huge associative network
As mentionned before, words are stored by
meaning and by form (sound). Therefore we
need a method to access words in both modali-
ties. This is all the more necessary, as the spea-
ker starts from a meaning representation
(concept, message). We plan to experiment with
the following two methods. In the first case
search is done by propagation in a dynamically
built network. In the second case search is done
by filtering (5.3).
The fact that the dictionary is organized as a
web rather than a taxonomy, has obvious advan-
tages : there is more than one way to reach the
goal. Hence, if ever one has gone in the
? wrong ? direction, one may still recover later
on. To illustrate this last point, let?s take an
example. Suppose you played chess and you
wanted to find the French equivalent for the
word ? knight ? (cavalier). If the dictionary
were structured along the lines suggested, than
one could access the word via any of the follo-
wing links or associations : horseman (cavalier-
noun), to be nonchalant (?tre cavalier), to be a
loner (faire cavalier seul), but also to bolt (ca-
valer), King Arthur (chevalier), famous French
singer (Maurice Chevalier). Note, that while in
the first three cases we get homonymes of the
target word (cavalier), to bolt produces a simi-
larly sounding word (cavaler instead of cava-
lIer). The last association (Maurice Chevalier)
results in a perfect match, except for the first
syllable and the first name, which would have to
be dropped, of course.
5.2.1 Search by progagation in the net-
work
I start from the assumption that the mental dic-
tionary is a huge semantic network composed of
words (nodes) and associations (links), either
being able to activate the other.6 Finding a word
amounts thus to entering the network and to
follow the links leading to the target word.
Being unable to access the desired word, a spea-
ker being in the TOT-state may still be able to
recognize it in a list. If the list doesn?t contain
the exact word, he is generally able to decide
which word leads in the right direction, i.e.
which word is most closely connected to the
target word.
Suppose you wanted to find the word nurse
(target word), yet the only token coming to your
mind were hospital. In this case the system
would build (internally) a small semantic net-
                                                      
6
 The idea according to which the mental dictionary
(or encyclopedia) is basically an associative network,
composed of nodes (words or concepts) and links
(associations) is not new. Actually the very notion of
association goes back at least to Aristotle (350 before
our time), but it is also inherent in work done by
philosophers (Locke, Hume) physiologists (James &
Stuart Mills), psychologists (Galton, 1880 ; Freud,
1901 ; Jung & Riklin, 1906) and psycholinguists
(Deese, 1965 ; Jenkins, 1970, Schvaneveldt, 1989 ).
For surveys in psycholinguistics see (H?rmann,
1972 ; chapters 6-10), or more recent work (Spitzer,
1999). The notion of association is also implicit in
work on semantic networks (Sowa, 1992), hypertext
(Bush, 1945), the web (Nelson, 1967), connectionism
(Stemberger, 1985 ; Dell, 1986) and of course Word-
Net (Miller, 1990, Fellbaum, 1998).
work with hospital in the center (Figure 2a)
and as immediate satellites all the words having
a direct link with it (Figure 2b).7 This process is
recursive: satellites can become the center, thus
triggering a new search, and since the speaker
knows the concept/word he is looking for, he is
likely to encounter it sooner or later.
Figure 2b shows the candidates from which
the user is supposed to choose. If he finds in any
of these groups the word he is looking for, the
process halts, otherwise it goes on. As you can
see words are presented in clusters. Each cluster
corresponds to a specific link. The assumption is
that the user will use this information in order to
jump quickly from one group to the next.
This approach might work fine provided : 1)
the speaker is able to come up with a word rea-
sonably close to the target; 2) The dictionary
contains (or allows to infer) all the relations/
associations a speaker typically uses. This se-
cond condition hardly ever holds. Hence, we
need to find out what these assocations are.
Also, while a single piece of information (a
word, a relationship or part of the definition) can
be useful, it is obviously better to provide more
information (number of syllables, sound, ori-
gine, etc.) as it will reduce the search space.
dentist
assistant ako
near-synonym
nurse
gynecologist
physician
health
institution
clinic
patient
sick person
hospital doctor
sanatorium
psychiatric hospital
military hospital
asylum synonym
ako
treat
ako
akoako
isa
isa
isa
isa
isa
isa
take care of
treatactor
actor
actor
Figure 2a : Search based on propagation in a network
(internal representation)
                                                      
7
 Of course, in case of ambiguity the user would have
to signal the specific meaning he has in mind.
clinic
sanatorium
military hospital
psychiatric hospital
doctor
patient
nurse
Figure 2b: proposed candidates grouped according
to the nature of the link
5.3 Search through a combination of 
conceptual and linguistic constraints
As mentionned already, a speaker finding him-
self in the TOT state knows generally many
things about the object he is looking for: parts of
the definition, ethymology, beginning/ending of
the word, number of syllables, part of speech
(noun, verb, adjectif, etc.), and sometimes even
the gender (Brown et McNeill,1966 ; Burke et
al. 1991 ; Vigliocco et al,1997). We could use
all this information as constraints. The interface
for communicating this knowledge is somehow
akin to what MEDLINE offers to researchers
helping them to specify the kind of book they
are looking for.
6 Conclusion
I have drawn the readers? attention to the im-
portance of word access in the context of NLG:
information must not only be available, it must
also be accessible. While this problem may not
be relevant for NLG in general, or in the strict
computational linguistic?s framework, it cer-
tainly is relevant when we look at generation as
a machine mediated process (people using a
word processors for writing), or from a psycho-
linguistic point of view: word access in writing
or (spontaneous) discourse. Looking at some of
the psycholinguistic findings, and looking at the
work done on spell checking, it seemed that
some of the techniques developed in the context
of the latter could profitably be used in the do-
main of the former. While the use of certain spell
checking techniques can certainly enhance word
access in speaking and writing (hence the poten-
tial of electronic dictionaries associated with
word processors), more work is needed in order
to adjust the method to be in line with psycho-
linguistic data and in order to keep the search
space small.
I have also tried to show that in order to sup-
port a speaker being in the TOT-state, we need
to create an associative memory. That is, I've
raised and partially answered the question what
kind of information semantic networks need to
have in order to be able to help a speaker being
in this state. Actually, my basic proposal is to
build a system akin to WordNet, but containing
many more links ? in particular on the hori-
zontal plane. These links are basically associa-
tions, whose role consists in helping the speaker
to find either related ideas to a given stimulus,
(concept/idea/word - brainstorming), or to find
the word he is thinking of (word access). Hence,
future work will consist in identifying the most
useful assocations, by considering relevant work
in linguistics8 and in collecting data by running
psycholinguistic expermiments. For example,
one could ask people to label the links for the
words (associations) they have given in response
to a stimulus (word) ; or one could also ask them
to lable couples of words (eg. apple-fruit, lemon-
yellow, etc.). A complementary approach would
be to look for lexical-data-base mining-strate-
gies, as the desired information may be distri-
buted or burried deep down in the base. Finally,
one can also look at texts and try to extract au-
tomatically co-occurences (see Rapp & Wettler,
1991 ; Wettler & Rapp 1992).
References
Aitchinson, J. (1987) Words in the Mind: an Intro-
duction to the Mental Lexicon, Oxford, Blackwell.
Aitchison, J., A. Gilchrist & D. Bawden (2000) The-
saurus construction and use : a practical ma-nual,
Fitzroy Deaborn Pbs, Chicago
Aristotle (350 before JC) De memoria et reminiscen-
tia. In Parva Naturalia, Vrin
Baddeley, A. (1982) Your memory: A user's guide.
Penguin
Brown, R and Mc Neill, D. (1966). The tip of the
tongue  phenomenon. Journal of Verbal Learning
and Verbal Behavior, 5, 325-337
Burke, D.M., D.G. MacKay, J.S. Worthley & E.
Wade (1991) ?On the Tip of the Tongue:What
Causes Word Finding Failures in Young and Older
Adults??, Journal of Memory and Language 30,
542-579.
                                                      
8
 For example, have a look at Mel?cuk?s lexical func-
tion, (Mel?cuk et al (1992)  and Fillmore?s FRAME-
NET approach (Johnson et al 2001)
Bush, V. (1945) "As we may think". The Atlantic
Monthly; Volume 176, No. 1; pp. 101-108
Butterworth, B. (1989) Lexical Acces in Speech
Production. In, W. Marslen-Tayler  (Ed.).
Clark, H & Eve V. Clark, (1977) Psychology and
Language.Harcourt, Brace, Jovanovich, New York
Crouch, C. (1990). An approach to the automatic
construction of global thesauri. Information Pro-
cessing and Management, vol. 26, no. 5, pp. 624-
640
Deese, J.(1965) The structure of associations in lan-
guage and thought. Baltimore
Dell, G. S., Chang, F., and Griffin, Z. M. (1999),
"Connectionist Models of Language Production:
Lexical Access and Grammatical Encoding," Cog-
nitive Science, 23/4, pp. 517-542.
Fellbaum, C. ( Ed.) 1998, WordNet : an electronic
lexical database, Cambridge (Massachusetts), The
MIT Press.
Fournier, J.P & S. Letellier. (1990) PIC: a Parallel
Intelligent Corrector. Artificial Intelligence Appli-
cation & Neural Networks AINN'90, pp 38-41,
Z?rich
Freud, S. (1901) Psychopathology of everyday life.
Paris : Payot, 1997.
Fromkin, V. (1973) (Ed.) Speech errors as linguistic
evidence. The Hague: Mouton Publishers
Galton, F. (1880). Psychometric experiments. Brain,
2, 149-162.
H?rmann H. (1972). Introduction ? la psycholin-
guistique. Paris: Larousse
Jenkins, J.J. (1970). The 1952 Minnesota word asso-
ciation norms. In: L. Postman, G. Keppel (eds.):
Norms of Word Association. New York: Academic
Press, 1-38.
Johnson, R, C. Fillmore, E. Wood, J. Ruppenhofer,
M. Urban, M. Petruck, C. Baker (2001) The Fra-
meNet Project: Tools for Lexicon Building,
http://www.icsi.berkeley.edu/~framenet/
Jung, C.G., Riklin, F. (1906). Experimentelle Unter-
suchungen ?ber Assoziationen Gesunder. In: C.G.
Jung (ed.): Diagnostische Assoziationsstudien.
Leipzig: Barth, 7-145.
Levelt, W. (1992). Accessing Words in Speech Pro-
duction: Stages, Processes and Representations.
Cognition 42: 1-22.
Marslen-Taylor, W. (Ed.) (1979) Lexical Repre-
sentation and Process, Bradford book, MIT Press,
Cambridge, Mass.
Mel'cuk, I. et al (1992) Dictionnaire Explicatif et
Combinatoire du fran?ais contemporain. Recherche
lexico-s?mantique III. Les presses de l?universit?
de Montr?al.
Miller, G.A., ed. (1990). WordNet: An On-Line Lexi-
cal Database. International Journal of Lexico-
graphy, 3(4).
Nelson, T. (1967) Xanadu Projet hypertextuel,
http://xanadu.com/
Palermo, D., Jenkins, J. (1964). Word Association
Norms. Minneapolis, MN: University of Minnesota
Press.
Perreault, J. (1965). Categories and relators: a new
schema. In Rev.Int. Doc., vol. 32, no.4, pp.136-144
Rapp, R. & M. Wettler (1991) A connectionist simu-
lation of word associations. Int. Joint Conf. on
Neural Network, Seattle
Robin, J. (1990) A Survey of Lexical Choice in Natu-
ral Language Generation, Technical Report CUCS
040-90, Dept. of Computer Science, University of
Columbia
Schvaneveldt, R. (Ed.) (1989) Pathfinder Associative
Networks : studies in knowledge organization.
Ablex, Norwood, New Jersay
Sowa, J. (1992) "Semantic networks," Encyclopedia
of Artificial Intelligence, edited by S. C. Shapiro,
Wiley, New York
Spitzer, M. (1999). The mind within the net : models
of learning, thinking and acting. A Bradford book.
MIT Press, Cambridge
Stemberger, J. P. (1985) "An interactive activation
model of language production." In A. W. Ellis [ed]
Progress in the Psychology of Language, Vol. 1,
143-186.  Erlbaum.
Vigliocco, G., Antonini, T., & Garrett, M. F. (1997).
Grammatical gender is on the tip of Italian tongues.
Psychological Science, 8, 314-317.
Wanner, L. (1996). Lexical Choice in Text Gene-
ration and Machine Translation: Special Issue on
Lexical Choice, Machine Translation. L. W. (ed.).
Dordrecht, Kluwer Academic Publishers. 11: 3-35.
Ward, N. (1988). Issues in Word Choice. COLING-
88, Budapest.
Wettler, M. & R. Rapp (1992) Computation of Word
associations based on the co-occurences of words
in large corpora
Wettler, M. (1980) Sprache, Ged?chtnis, Verstehen.
Berlin, de Gruyter
Zock, M. & J.-P. Fournier (2001). How can compu-
ters help the writer/speaker experiencing the Tip-
of-the-Tongue Problem ?, Proc. of RANLP, Tzigov
Chark, pp. 300-302
Word lookup on the basis of associations:
from an idea to a roadmap
Michael ZOCK
LIMSI-CNRS
B.P. 133, 91403 Orsay,
France
zock@limsi.fr
Slaven BILAC
Tokyo Institute of Technology
Ookayama 2-12-1, Meguro 152-8552,
Japan
sbilac@cl.cs.titech.ac.jp
Abstract
Word access is an obligatory step in language
production. In order to achieve his communica-
tive goal, a speaker/writer needs not only to
have something to say, he must also find the
corresponding word(s). Yet, knowing a word,
i.e. having it stored in a data-base or memory
(human mind or electronic device) does not im-
ply that one is able to access it in time. This
is a clearly a case where computers (electronic
dictionaries) can be of great help.
In this paper we present our ideas of how
an enhanced electronic dictionary can help peo-
ple to find the word they are looking for. The
yet-to-be-built resource is based on the age-old
notion of association: every idea, concept or
word is connected. In other words, we assume
that people have a highly connected conceptual-
lexical network in their mind. Finding a word
amounts thus to entering the network at any
point by giving the word or concept coming to
their mind (source word) and then following the
links (associations) leading to the word they are
looking for(target word).
Obviously, in order to allow for this kind
of access, the resource has to be built accord-
ingly. This requires at least two things: (a) in-
dexing words by the associations they evoke,
(b) identification and labeling of the most fre-
quent/useful associations. This is precisely our
goal. Actually, we propose to build an associa-
tive network by enriching an existing electronic
dictionary (essentially) with (syntagmatic) as-
sociations coming from a corpus, representing
the average citizen?s shared, basic knowledge of
the world (encyclopedia). Such an enhanced
electronic database resembles in many respects
our mental dictionary. Combining the power of
computers and the flexibility of the human mind
(omnidirectional navigation and quick jumps),
it emulates to some extent the latter in its ca-
pacity to navigate quickly and efficiently in a
large data base.
While the notions of association and spread-
ing activation are fairly old, their use to support
word access via computer is new. The resource
still needs to be built, and this is not a trivial
task. We discuss here some of the strategies and
problems involved in accomplishing it with the
help of people and computers (automation).
1 Introduction
We all experience now and then the problem
of being unable to find the word expressing the
idea we have in our mind. It we care and have
time we may reach for a dictionary. Yet, this
kind of resource may be of little help, if it ex-
pects from us precisely what we are looking for :
a perfectly spelled word, expressing the idea we
try to convey. While perfect input may be rea-
sonable in the case of analysis (comprehension),
it certainly is not in the case of synthesis (gener-
ation) where the starting point is conceptual in
nature: a message, the (partial) definition of a
word, a concept or a word related to the target
word. The language producer needs a dictio-
nary allowing for reverse access. A thesaurus
does that, but only in a very limited way: the
entry points are basically topical.
People use various methods to initiate search
in their mind : words, concepts, partial descrip-
tions, etc. If we want to mimic these functional-
ities by a computer, we must build the resource
accordingly. Let us assume that the text pro-
ducer is looking for a word that he cannot ac-
cess. Instead he comes up with another word
(or concept)1 somehow related to the former.
He may not know precisely how the two relate,
but he knows that they are related. He may also
know to some extent how close their relation-
ship is, whether a given link is relevant or not,
that is, whether it can lead directly (synonym,
1We will comment below on the difference between
concepts and words.
antonym, hyperonym) or indirectly to the tar-
get word. Since the relationship between the
source- and the target word is often indirect,
several lookups may be necessary: each one of
them having the potential to contain either the
target word (direct lookup), or a word leading
towards it (indirect lookup).
2 How reasonable is it to expect
perfect input?
The expectation of perfect input is unrealistic
even in analysis,2 but clearly more so in gener-
ation. The user may well be unable to provide
the required information: be it because he can-
not access in time the word he is looking for,
even though he knows it,3 or because he does
not know the word yet expressing the idea he
wants to convey. This latter case typically oc-
curs when using a foreign language or when try-
ing to use a very technical term. Yet, not being
able to find a word, does not imply that one
does not know anything concerning the word.
Actually, quite often the contrary is the case.
Suppose, you were looking for a word ex-
pressing the following ideas: domesticated ani-
mal, producing milk suitable for making cheese.
Suppose further that you knew that the target
word was neither cow nor sheep. While none
of this information is sufficient to guarantee the
access of the intended word goat, the informa-
tion at hand (part of the definition) could cer-
tainly be used. For some concrete proposals go-
ing in this direction, see (Bilac et al, 2004), or
the OneLook reverse dictionary.4 Besides the
definition information, people often have other
kind of knowledge concerning the target word.
In particular, they know how the latter relates
to other words. For example, they know that
goats and sheep are somehow connected, that
both of them are animals, that sheep are appre-
ciated for their wool and meet, that sheep tend
to follow each other blindly, while goats man-
age to survive, while hardly eating anything,
etc. In sum, people have in their mind lexi-
cal networks: all words, concepts or ideas they
express are highly interconnected. As a result,
any one of the words or concepts has the po-
tential to evoke each other. The likelihood for
2Obviously, looking for ?pseudonym? under the letter
?S? in a dictionary won?t be of great help.
3Temporary amnesia, known as the TOT, or tip-of-
the-tongue problem (Brown and McNeill, 1996; Zock and
Fournier, 2001; Zock, 2002)
4http://www.onelook.com/reverse-dictionary.
shtml
this to happen depends, among other things, on
such factors as frequency (associative strength),
saliency and distance (direct vs. indirect ac-
cess). As one can see, associations are a very
general and powerful mechanism. No matter
what we hear, read or say, any idea is likely to
remind us of something else.5 This being so, we
should make use of it.6
3 Search based on the relations
between concepts and words
If one agrees with what we have just said, one
could view the mental dictionary as a huge se-
mantic network composed of nodes (words and
concepts) and links (associations), with either
being able to activate the other.7 Finding a
5The idea according to which the mental dictionary
(or encyclopedia) is basically an associative network,
composed of nodes (words or concepts) and links (as-
sociations) is not new, neither is the idea of spreading
activation. Actually the very notion of association goes
back at least to Aristotle (350BC), but it is also inher-
ent in work done by philosophers (Locke, Hume), phys-
iologists (James & Stuart Mills), psychologists (Galton,
1880; Freud, 1901; Jung and Riklin, 1906) and psycholin-
guists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989).
For surveys in psycholinguistics see (Ho?rmann, 1972), or
more recent work (Spitzer, 1999). The notion of associa-
tion is also implicit in work on semantic networks (Quil-
lian, 1968), hypertext (Bush, 1945), the web (Nelson,
1967), connectionism (Dell et al, 1999) and, of course,
in WordNet (Miller et al, 1993; Fellbaum, 1998).
6In the preceding sections we used several times the
terms words and concepts interchangeably, as if they were
the same. Of course, they are very different. Yet, not
knowing what a concept looks like (a single node, or
every node, i.e. headword of the word?s definition?), we
think it is safer to assume that the user can communicate
with the computer (dictionary) only via words. Hence,
concepts are represented by words, yet, since the two
are connected, one can be accessed via the other, which
addresses the interface problem with the computer. An-
other point worth mentionning is the fact that associa-
tions may depend on the nature of the arguments (words
vs. concepts). While in theory anything can be associ-
ated with anything (words with words, words with con-
cepts, concepts with concepts, etc.), in practice words
tend to trigger a different set of associations than con-
cepts. Also, the connectivity between words and con-
cepts explains to some extent the power and the flexi-
bility of the human mind. Words are shorthand labels
for concepts, and given the fact that the two are linked,
one can make big leaps in no time and easily move from
one plane (let?s say the conceptual level) to the other
(the linguistic counterpart). Words can be reached via
concepts, but the latter can also serve as starting point
to find a word. Compared to the links between concepts
which are a superhighway, associations between words
are more like countryroads.
7Actually, one could question the very notion of men-
tal dictionary which is convenient, but misleading in as
it supposes a dedicated part for this task in our brain. A
Figure 1: Search based on propagation in a network (internal representation)
word amounts thus to entering the network and
following the links leading from the source node
(the first word that comes to your mind) to the
target word (the one you are looking for). Sup-
pose you wanted to find the word ?nurse? (target
word), yet the only token coming to your mind
were ?hospital?. In this case the system would
generate internally a graph with the source word
at the center and all the associated words at
the periphery. Put differently, the system would
build internally a semantic network with ?hos-
pital? in the center and all its associated words
as satellites (figure 1).8
Obviously, the greater the number of associ-
ations, the more complex the graph. Given the
diversity of situations in which a given object
may occur we are likely to build many associa-
tions. In other words, lexical graphs tend to be-
multiply indexed mental encyclopedia, composed of poly-
morph information (concepts, words, meta-linguistic in-
formation) seems much more plausible to us.
8AKO: a kind of; ISA: subtype; TIORA: typically
involved object, relation or actor.
come complex, too complex to be a good repre-
sentation to support navigation. Readability is
hampered by at least two factors: high connec-
tivity (the great number of links or associations
emanating from each word), and distribution:
conceptually related nodes, that is, nodes acti-
vated by the same kind of assocation are scat-
tered around, that is, they do not necessarily
occur next to each other, which is quite confus-
ing for the user. In order to solve this problem
we suggest to display by category (chunks) all
the words linked by the same kind of association
to the source word (see figure 2). Hence, rather
than displaying all the connected words as a flat
list, we suggest to present them in chunks to al-
low for categorial search. Having chosen a cat-
egory, the user will be presented a list of words
or categories from which he must choose. If the
target word is in the category chosen by the user
(suppose he looked for a hyperonyme, hence he
checked the ISA-bag), search stops, otherwise it
goes on. The user could choose either another
category (eg. AKO or TIORA), or a word in
Figure 2: Proposed candidates, grouped accord-
ing to the nature of the link
the current list, which would then become the
new starting point.
4 A resource still to be built
The fact that the links are labeled has some very
important consequences. (a) While maintaining
the power of a highly connected graph (possible
cyclic navigation), it has at the interface level
the simplicity of a tree: each node points only
to data of the same type, i.e. same kind of asso-
ciation. (b) Words being presented in clusters,
navigation can be accomplished by clicking on
the appropriate category. The assumption be-
ing that the user generally knows to which cate-
gory the target word belongs (or at least, he can
recognize within which of the listed categories it
falls), and that categorical search is in principle
faster than search in a huge list of unordered
(or, alphabetically ordered) words.
Word access, as described here, amounts to
navigating in a huge associative network. Of
course, such a network has to be built. The
question is how. Our proposal is to build
it automatically by parsing an existing corpus
containing sufficient amount of information on
world knowledge (for example, an encyclope-
dia). This would yield a set of associations
(see below),9 which still need to be labeled. A
rich ontology should be helpful in determining
the adequate label for many, if not most of the
links. Unlike private information,10 which by
9The assumption being that every word co-occurring
with another word in the same sentence is a candidate of
an association. The more frequently two words co-occur
in a given corpus, the greater their associative strength.
10For example, the word elephant may remind you of a
definition cannot and should not be put into a
public dictionary,11 encyclopedic knowledge can
be added in terms of associations, as this infor-
mation expresses commonly shared knowledge,
that is, the kind of associations most people
have when encountering a given word. Take for
example the word elephant. An electronic dic-
tionary like Word Net associates the following
gloss with the headword: large, gray, four-legged
mammal, while Webster gives the following in-
formation:
A mammal of the order Proboscidia,
of which two living species, Elephas
Indicus and E. Africanus, and several
fossil species, are known. They have
a proboscis or trunk, and two large
ivory tusks proceeding from the ex-
tremity of the upper jaw, and curving
upwards. The molar teeth are large
and have transverse folds. Elephants
are the largest land animals now ex-
isting.
While this latter entry is already quite rich
(trunk, ivory tusk, size), an encyclopedia con-
tains even more information.12 If all this in-
formation were added to an electronic resource,
it would enable us to access the same word
(e.g. elephant) via many more associations than
ever before. By looking at the definition here
above, one will notice that many associations
are quite straightforward (color, size, origin,
etc.), and since most of them appear frequently
in a pattern-like manner it should be possible
to extract them automatically (see footnote 18
below). If one agrees with these views, the re-
maining question is how to extract this encyclo-
pedic information and to add it to an existing
electronic resource. Below we will outline some
methods for extracting associated words and
discuss the feasibility of using current method-
ology to achieve this goal.
5 Automatic extraction of word
associations
Above we outlined the need for obtaining asso-
ciations between words and using them to im-
prove dictionary accessibility. While the associ-
ations can be obtained through association ex-
periments with human subjects, this strategy is
specific animal, trip or location (zoo, country in Africa).
11This does not (and should not) preclude the possi-
bility to add it to one?s personal dictionary.
12You may consider taking a look at Wikipedia (http:
//en.wikipedia.org/wiki/) which is free.
not very satisfying due to the high cost of run-
ning the experiments (time and money), and
due to its static nature. Indeed, given the costs,
it is impossible to repeat these experiments to
take into account the evolution of a society.
Hence, the goal is to automatically extract asso-
ciations from large corpora. This problem was
addressed by a large number of researchers, but
in most cases it was reduced to extraction of col-
locations which are a proper subset of the set of
associated words. While hard to define, colloca-
tions appear often enough in corpora to be ex-
tractable by statistical and information-theory
based methods.
There are several basic methods for evalu-
ating associations between words: based on
frequency counts (Choueka, 1988; Wettler and
Rapp, 1993), information theoretic (Church
and Hanks, 1990) and statistical significance
(Smadja, 1993). The statistical significance
often evaluate whether two words are inde-
pendant using hypothesis tests such as t-score
(Church et al, 1991), the X2, the log-likelihood
(Dunning, 1993) and Fisher?s exact test (Peder-
sen, 1996). Extracted sets for associated words
are further pruned using numerical methods, or
linguistic knowledge to obtain a subset of collo-
cations.
The various extraction measures have been
discussed in great detail in the literature (Man-
ning and Schu?tze, 1999; McKeown and Radev,
2000), their performance has been compared
(Dunning, 1993; Pedersen, 1996; Evert and
Krenn, 2001), and the methods have been com-
bined to improve overall performance (Inkpen
and Hirst, 2002). Most of these methods were
originally applied in large text corpora, but
more recently the web has been used as a cor-
pus (Pearce, 2001; Inkpen and Hirst, 2002).
Collocation extraction methods have been used
not only for English, but for many other lan-
guages: French (Ferret, 2002), German (Ev-
ert and Krenn, 2001) and Japanese (Nagao and
Mori, 1994), to cite but those.
The most obvious question in this context
is to clarify to what extent available colloca-
tion extraction techniques fulfill our needs of ex-
tracting and labeling word associations. Since
collocations are a subset of association, it is pos-
sible to apply collocation extraction techniques
to obtain related words, ordered in terms of the
relative strength of association.
The result of this kind of numerical extraction
would be a large set of numerically weighted
word pairs. The problem with this approach is
that the links are only labeled in terms of their
relative associative strength, but not categori-
cally, which makes it impossible to group and
present them in a meaningful way for the dic-
tionary user. Clusters based only on the notion
of association strength are inadequate for the
kind of navigation described here above. Hence
another step is necessary: qualification of the
links according to their types. Only once this
is done, a human being could use it to navi-
gate through a large conceptual-lexical network
(the dictionary) as described above. Unfortu-
nately, research on automatic link identification
has been rather sparse. Most attempts have
been devoted to the extraction of certain types
of links (usually syntactic type (Lin, 1998) or
on extensions of WordNet with topical informa-
tion contained in a thesaurus (Stevenson, 2002)
or on the WWW (Agirre et al, 2000). Addi-
tional methods need to be considered in order
to reveal (automatically) the kind of associa-
tions holding between words and/or concepts.
Earlier in this paper we have suggested the use
of an encyclopedia as a source of general world
knowledge. It should be noted, though, that
there are important differences between large
corpora and encyclopedias. Large corpora usu-
ally contain a lot of repetitive texts on a lim-
ited number of topics (e.g. newspaper articles)
which makes them very suitable for statistical
methods. On the other hand, while being max-
imally informative and comprehensive, encyclo-
pedias are written in a highly controlled lan-
guage, and their content is continually updated
and re-edited, with the goal to avoid unneces-
sary repetition. While most of the information
contained in an entry is important, there is a
lack of redundancy. Hence, measures capable of
handling word pairs with low appearance counts
(e.g. log-likelihood or Fisher?s exact test) should
be favored. Also, rather than looking at indi-
vidual words, one might want to look at word
patterns instead.
6 Discussion and Conclusion
We have raised and partially answered the ques-
tion of how a dictionary should be indexed in
order to support word access. We were partic-
ularly concerned with the language producer,
as his needs (and knowledge at the onset) are
quite different from the ones of the language re-
ceiver (listener/reader). It seems that, in order
to achieve our goal, we need to do two things:
add to an existing electronic dictionary informa-
tion that people tend to associate with a word,
that is, build and enrich a semantic network,
and provide a tool to navigate in it. To this
end we have suggested to label the links, as this
would reduce the graph complexity and allow
for type-based navigation. Actually our basic
proposal is to extend a resource like WordNet
by adding certain links, in particular on the hor-
izontal axis (syntagmatic relations). These links
are associations, and their role consists in help-
ing the encoder to find ideas (concepts/words)
related to a given stimulus (brainstorming), or
to find the word he is thinking of (word access).
One problem that we are confronted with is to
identify possible associations. Ideally we would
need a complete list, but unfortunately, this
does not exist. Yet, there is a lot of highly
relevant information out there. For exam-
ple, Mel?cuk?s lexical functions (Mel?cuk, 1992),
Fillmore?s FRAMENET13, work on ontolo-
gies (CYC), thesaurus (Roget), WordNets (the
original version from Princeton, divers Euro-
WordNets, BalkaNet), HowNet14, the work
done by MICRA, the FACTOTUM project15
or the Wordsmyth dictionary/thesaurus combi-
nation16. Of course, one would need to make
choices here and probably add links. Another
problem is to identify useful associations. Not
every possible association is necessarily plausi-
ble. Hence, the idea to take as corpus some-
thing that expresses shared knowledge, for ex-
ample, an encyclopedia. The associations it
contains can be considered as being plausible.
We could also collect data by watching peo-
ple using a dictionary and identify search pat-
terns.17 Next, we could run psycholinguistic ex-
periments.18 While the typical paradigm has
been to ask people to produce a response (red)
to some stimulus (rose), we could ask them to
identify or label the links between words (e.g.
apple-fruit, lemon-yellow, etc.). The ease of la-
13http://www.icsi.berkeley.edu/~framenet/
14http://www.keenage.com/html/e_index.html
15http://humanities.uchicago.edu/homes/MICRA/
16http://www.wordsmyth.com/
17One such pattern could be: give me the word for a
bird with yellow feet and a long beak, that can swim.
Actually, word access problems frequently come under
the form of questions like: What is the word for X that
Y?, where X is usually a hypernym and Y a stereotypical,
possibly partial functional/relational/case description of
the target word.
18Actually, this has been done for decades, but with
a different goal in mind (Nelson, 1967), http://cyber.
acomp.usf.edu/FreeAssociation/.
beling will probably depend upon the origin of
the words (the person asked to label the link or
somebody else).
Another approach would be to extract col-
locations from a corpus and label them auto-
matically. There are tools for extracting co-
occurrences (see section 5.5), and ontologies
could be used to qualify some of the links be-
tween collocational elements. While this ap-
proach might work fine for couples like coffee-
strong, or wine-red (since an ontology would re-
veal that red is a kind of color, which is precisely
the link type: i.e. association), one may doubt
that it could reveal the nature of the link be-
tween smoke and fire. Yet, most humans would
immediately recognize this as a causal link. As
one can see, there are still quite a few serious
problems to be solved. Nevertheless, we do be-
lieve that these obstacles can be removed, and
that the approach presented here has the poten-
tial to improve word access, making the whole
process more powerful, natural and intuitive,
hence efficient.
References
E. Agirre, E. Hovy O. Ansa, and D. Mar-
tinez. 2000. Enriching very large ontologies
using the WWW. In Proc. of ECAI Ontology
Learning Workshop.
S. Bilac, W. Watanabe, T. Hashimoto, T. Toku-
naga, and H. Tanaka. 2004. Dictionary
search based on the target word description.
In Proc. of the Tenth Annual Meeting of The
Association for Natural Language Processing
(NLP2004), pages 556?559.
R. Brown and D. McNeill. 1996. The tip of
the tonuge phenomenon. Journal of Verbal
Learning and Verbal Behaviour, 5:325?337.
V. Bush. 1945. As we may think. The Atlantic
Monthly, 176:101?108.
Y. Choueka. 1988. Looking for needles in a
haystack. In Proc. of the RIAO Conference
on User-Oriented Context Based Text and
Image Handling, pages 609?623.
K. Church and P. Hanks. 1990. Word associa-
tion norms, mutual information and lexicog-
raphy. Computational Linguistics, 16:22?29.
K. Church, W. Gale, P. Hanks, and D. Hin-
dle. 1991. Using statistics in lexical analysis.
In U. Zernik, editor, Lexical Acquisition: Ex-
ploiting On-Line Resources to Build a Lexi-
con. Lawrance Erlbaum Associates.
J. Deese. 1965. The structure of associations in
language and thought. Johns Hopkins Press.
G. S. Dell, F. Chang, and Z. M. Griffin. 1999.
Connectionist models of language produc-
tion: Lexical access and grammatical encod-
ing. Cognitive Science, 23:517?542.
T. Dunning. 1993. Accurate methods for statis-
tics of surprise and coincidence. Computa-
tional Linguistics, 19:61?74.
S. Evert and B. Krenn. 2001. Methods for the
qualitative evaluation of lexical association
measures. In Proc. of the 39th Annual meet-
ing of Association of Computational Linguis-
tics (ACL 2001), pages 188?195.
C. Fellbaum. 1998. WordNet: An Electronic
Lexical Database and some of its Applica-
tions. MIT Press.
O. Ferret. 2002. Using collocations for topic
segmentation and link detection. In Proc. of
the 19th International Conference on Compu-
tational Linguistics, pages 261?266.
S. Freud. 1901. Psychopathology of everyday
life. Payot, 1997 edition.
F. Galton. 1880. Psychometric experiments.
Brain, 2:149?162.
H. Ho?rmann. 1972. Introduction a` la psycholin-
quistique. Larousse.
D. Z. Inkpen and G. Hirst. 2002. Acquiring
collocations for lexical choice between near-
synonyms. In Proc. of Unsupervised Lexical
Acquisition Workshop of the ACL SIGLEX,
pages 67?76.
J. J. Jenkins. 1970. The 1952 minnesota
word association norms. In L. Postman and
G. Kepper, editors, Norms of Word Associa-
tion, pages 1?38. Academic Press.
C. G. Jung and F. Riklin. 1906. Experimentelle
unter-suchungen u?ber assoziationene gesun-
der. In C. G. Jung, editor, Diagnostische As-
soziationsstudien, pages 7?145. Barth.
D. Lin. 1998. Extracting collocations from text
corpor. In First Workshop on Computational
Terminology.
C. D. Manning and H. Schu?tze. 1999. Foun-
dations of Statistical Natural Language Pro-
cessing. The MIT Press, Cambridge, Mas-
sachusetts.
K. R. McKeown and Dragomir R. Radev.
2000. Collocations. In H. Moisl R. Dale
and H. Somers, editors, Handbook of Natural
Language Processing, pages 507?523. Marcel
Dekker.
I. Mel?cuk. 1992. Dictionnaire Explicatif
et Combinatoire du franc?ais contemporain:
recherche lexicose?mantique III. Les presses de
l?universite? de Montre?al.
G. A. Miller, R. Beckwith, C. Fellbaum,
D. Gross, and Katherine Miller, editors.
1993. Introduction to WordNet: An On-line
Lexical Database. Cognitive Science Labora-
tory, Princeton University.
M. Nagao and S. Mori. 1994. A new method of
n-gram statistics for large number of n and
automatic extraction of words and phrases
from large text data of Japanese. In Proc. of
the 15th International Conference on Compu-
tational Linguistics (COLING 1994), pages
611?615.
T. Nelson. 1967. Xanadu projet hypertextuel.
D. Pearce. 2001. Synonymy in collocation
extraction. In Proc. of NAACL?01 Work-
shop on WordNet and Other Lexical Re-
sources: Applications, Extensions and Cus-
tomizations.
Ted Pedersen. 1996. Fishing for exactness. In
Proc. of the South-Central SAS Users Group
Conference, pages 188?195.
R. Quillian. 1968. Semantic memory. In M.
Minsky, editor, Semantic Information Pro-
cessing, pages 216?270.The MIT Press. Cam-
bridge, MA.
R. Schvaneveldt, editor. 1989. Pathfinder As-
sociative Networks: studies in knowledge or-
ganization. Norwood.
F. Smadja. 1993. Retrieving collocations from
text: Xtract. Computational Linguistics,
19:143?177.
M. Spitzer. 1999. The mind within the net:
models of learning, thinking and acting. MIT
Press.
M. Stevenson. 2002. Augmenting noun tax-
onomies by combining lexical similarity met-
rics. In Proc. of the 19th International Con-
ference on Computational Linguistics (COL-
ING 2002), pages 953?959.
M. Wettler and R. Rapp. 1993. Computation of
word associations based on the co-occurrences
of words in large corpora. In Proc. of the 1st
Workshop on Very Large Corpora: Academic
and Industrial Perspectives.
M. Zock and J.-P. Fournier. 2001. How can
computers help the writer/speaker experienc-
ing the tip-of-the-tongue problem ? In Proc.
of RANLP, pages 300?302.
M. Zock. 2002. Sorry, what was your name
again, or how to overcome the tip-of-the
tongue problem with the help of a com-
puter? In Proc. of the SemaNet workshop
COLING2002.
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 281?288,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Enhancing electronic dictionaries with an index based on associations 
 
Olivier Ferret 
CEA ?LIST/LIC2M 
18 Route du Panorama 
F-92265 Fontenay-aux-Roses 
ferreto@zoe.cea.fr 
Michael Zock1
LIF-CNRS 
163 Avenue de Luminy 
F-13288 Marseille Cedex 9 
michael.zock@lif.univ-mrs.fr
Abstract 
A good dictionary contains not only 
many entries and a lot of information 
concerning each one of them, but also 
adequate means to reveal the stored in-
formation. Information access depends 
crucially on the quality of the index. We 
will present here some ideas of how a 
dictionary could be enhanced to support a 
speaker/writer to find the word s/he is 
looking for. To this end we suggest to 
add to an existing electronic resource an 
index based on the notion of association. 
We will also present preliminary work of 
how a subset of such associations, for ex-
ample, topical associations, can be ac-
quired by filtering a network of lexical 
co-occurrences extracted from a corpus. 
1 Introduction 
A dictionary user typically pursues one of two 
goals (Humble, 2001): as a decoder (reading, 
listening), he may look for the definition or the 
translation of a specific target word, while as an 
encoder (speaker, writer) he may want to find a 
word that expresses well not only a given con-
cept, but is also appropriate in a given context.  
Obviously, readers and writers come to the 
dictionary with different mindsets, information 
and expectations concerning input and output. 
While the decoder can provide the word he wants 
additional information for, the encoder (language 
producer) provides the meaning of a word for 
which he lacks the corresponding form. In sum, 
users with different goals need access to different 
indexes, one that is based on form (decoding), 
 
1 In alphabetical order 
the other being based on meaning or meaning 
relations (encoding). 
Our concern here is more with the encoder, i.e. 
lexical access in language production, a feature 
largely neglected in lexicographical work. Yet, a 
good dictionary contains not only many entries 
and a lot of information concerning each one of 
them, but also efficient means to reveal the 
stored information. Because, what is a huge dic-
tionary good for, if one cannot access the infor-
mation it contains? 
2 Lexical access on the basis of what: 
concepts (i.e. meanings) or words?
Broadly speaking, there are two views concern-
ing lexicalization: the process is conceptually-
driven (meaning, or parts of it are the starting 
point) or lexically-driven2 : the target word is 
accessed via a source word. This is typically the 
case when we are looking for a synonym, anto-
nym, hypernym (paradigmatic associations), or 
any of its syntagmatic associates (red-rose, cof-
fee-black), the kind of association we will be 
concerned with here. 
Yet, besides conceptual knowledge, people 
seem also to know a lot of things concerning the 
lexical form (Brown and Mc Neill, 1966): num-
ber of syllables, beginning/ending of the target 
word, part of speech (noun, verb, adjective, etc.), 
origin (Greek or Latin), gender (Vigliocco et al, 
 
2 Of course, the input can also be hybrid, that is, it can be 
composed of a conceptual and a linguistic component. For 
example, in order to express the notion of intensity, MAGN in 
Mel?Auk?s theory (Mel?Auk et al, 1995), a speaker or writer 
has to use different words (very, seriously, high) depending 
on the form of the argument (ill, wounded, price), as he says 
very ill, seriously wounded, high price. In each case he ex-
presses the very same notion, but by using a different word. 
While he could use the adverb very for qualifying the state 
of somebody?s health (he is ill), he cannot do so when quali-
fying the words injury or price. Likewise, he cannot use this 
specific adverb to qualify the noun illness.
281
1997). While in principle, all this information 
could be used to constrain the search space, we 
will deal here only with one aspect, the words? 
relations to other concepts or words (associative 
knowledge). 
Suppose, you were looking for a word expressing 
the following ideas: domesticated animal, pro-
ducing milk suitable for making cheese. Suppose 
further that you knew that the target word was 
neither cow, buffalo nor sheep. While none of 
this information is sufficient to guarantee the 
access of the intended word goat, the information 
at hand (part of the definition) could certainly be 
used3. Besides this type of information, people 
often have other kinds of knowledge concerning 
the target word. In particular, they know how the 
latter relates to other words. For example, they 
know that goats and sheep are somehow con-
nected, sharing a great number of features, that 
both are animals (hypernym), that sheep are ap-
preciated for their wool and meat, that they tend 
to follow each other blindly, etc., while goats 
manage to survive, while hardly eating anything, 
etc. In sum, people have in their mind a huge 
lexico-conceptual network, with words 4 , con-
cepts or ideas being highly interconnected. 
Hence, any one of them can evoke the other. The 
likelihood for this to happen depends on such 
factors as frequency (associative strength), sali-
ency and distance (direct vs. indirect access). As 
one can see, associations are a very general and 
powerful mechanism. No matter what we hear, 
read or say, anything is likely to remind us of 
something else. This being so, we should make 
use of it. 
 
3 For some concrete proposals going in this direction, see 
dictionaries offering reverse lookup: http://www.ultralingua. 
net/ ,http://www.onelook.com/reverse-dictionary.shtml.
4 Of course, one can question the very fact that people store 
words in their mind. Rather than considering the human 
mind as a wordstore one might consider it as a wordfactory.
Indeed, by looking at some of the work done by psycholo-
gists who try to emulate the mental lexicon (Levelt et al, 
1999) one gets the impression that words are synthesized 
rather than located and call up. In this case one might con-
clude that rather than having words in our mind we have a 
set of highly distributed, more or less abstract information. 
By propagating energy rather than data ?(as there is no 
message passing, transformation or cumulation of informa-
tion, there is only activation spreading, that is, changes of 
energy levels, call it weights, electronic impulses, or what-
ever),? that we propagate signals, activating ultimately 
certain peripherical organs (larynx, tongue, mouth, lips, 
hands) in such a way as to produce movements or sounds, 
that, not knowing better, we call words. 
3 Accessing the target word by navigat-
ing in a huge associative network 
If one agrees with what we have just said, one 
could view the mental lexicon as a huge semantic 
network composed of nodes (words and con-
cepts) and links (associations), with either being 
able to activate the other5. Finding a word in-
volves entering the network and following the 
links leading from the source node (the first 
word that comes to your mind) to the target word 
(the one you are looking for). Suppose you 
wanted to find the word nurse (target word), yet 
the only token coming to your mind is hospital.
In this case the system would generate internally 
a graph with the source word at the center and all 
the associated words at the periphery. Put differ-
ently, the system would build internally a seman-
tic network with hospital in the center and all its 
associated words as satellites (see Figure 1, next 
page). 
Obviously, the greater the number of associa-
tions, the more complex the graph. Given the 
diversity of situations in which a given object 
may occur we are likely to build many associa-
tions. In other words, lexical graphs tend to be-
come complex, too complex to be a good repre-
sentation to support navigation. Readability is 
hampered by at least two factors: high connec-
tivity (the great number of links or associations 
emanating from each word), and distribution:
conceptually related nodes, that is, nodes acti-
vated by the same kind of association are scat-
tered around, that is, they do not necessarily oc-
cur next to each other, which is quite confusing 
for the user. In order to solve this problem, we 
suggest to display by category (chunks) all the 
words linked by the same kind of association to 
the source word (see Figure 2). Hence, rather 
than displaying all the connected words as a flat 
list, we suggest to present them in chunks to al-
low for categorial search. Having chosen a cate-
gory, the user will be presented a list of words or 
categories from which he must choose. If the 
target word is in the category chosen by the user 
(suppose he looked for a hypernym, hence he 
checked the ISA-bag), search stops, otherwise it 
continues. The user could choose either another 
category (e.g. AKO or TIORA), or a word in the 
current list, which would then become the new 
starting point. 
 
5 While the links in our brain may only be weighted, they 
need to be labelled to become interpretable for human be-
ings using them for navigational purposes in a lexicon. 
282
DENTIST
assistant
near-synonym
GYNECOLOGIST
PHYSICIAN
HEALTH
INSTITUTION
CLINIC
DOCTOR
SANATORIUM
PSYCHIATRIC HOSPITAL
MILITARY HOSPITAL
ASYLUM
treat
A OK
take care of
treat
HOSPITAL
PATIENT
INMATE
TIORA
synonym
ISA A OK A OK
A OK
A OK
ISA
ISA ISA
ISA
ISA
TIORA
TIORA
nurse
Internal Representation
 
Figure 1: Search based on navigating in a network (internal representation) 
AKO: a kind of; ISA: subtype; TIORA: Typically Involved Object, Relation or Actor.
list of potential target words (LOPTW)
source word
link
link
link
link
link
LOPTW
LOPTW
list of potential target words (LOPTW)
...
Abstract representation of the search graph
hospital
TIORA
ISA
AKO clinic, sanatorium, ...
military hospital, psychiatric hospital
inmateSYNONYM
nurse
doctor, ...
patient
...
A concrete example
 
Figure 2: Proposed candidates, grouped by fam-
ily, i.e. according to the nature of the link 
As one can see, the fact that the links are labeled 
has some very important consequences:  
(a) While maintaining the power of a highly 
connected graph (possible cyclic navigation), 
it has at the interface level the simplicity of a 
tree: each node points only to data of the 
same type, i.e. to the same kind of associa-
tion.  
(b) With words being presented in clusters, 
navigation can be accomplished by clicking 
on the appropriate category.  
The assumption being that the user generally 
knows to which category the target word belongs 
(or at least, he can recognize within which of the 
listed categories it falls), and that categorical 
search is in principle faster than search in a huge 
list of unordered (or, alphabetically ordered) 
words6.
Obviously, in order to allow for this kind of 
access, the resource has to be built accordingly. 
This requires at least two things: (a) indexing 
words by the associations they evoke, (b) identi-
 
6 Even though very important, at this stage we shall not 
worry too much for the names given to the links. Indeed, 
one might question nearly all of them. What is important is 
the underlying rational: help users to navigate on the basis 
of symbolically qualified links. In reality a whole set of 
words (synonyms, of course, but not only) could amount to 
a link, i.e. be its conceptual equivalent. 
283
fying and labelling the most frequent/useful as-
sociations. This is precisely our goal. Actually, 
we propose to build an associative network by 
enriching an existing electronic dictionary (es-
sentially) with (syntagmatic) associations coming 
from a corpus, representing the average citizen?s 
shared, basic knowledge of the world (encyclo-
paedia). While some associations are too com-
plex to be extracted automatically by machine, 
others are clearly within reach. We will illustrate 
in the next section how this can be achieved. 
4 Automatic extraction of topical rela-
tions 
4.1 Definition of the problem 
We have argued in the previous sections that dic-
tionaries must contain many kinds of relations on 
the syntagmatic and paradigmatic axis to allow 
for natural and flexible access of words. Synon-
ymy, hypernymy or meronymy fall clearly in this 
latter category, and well known resources like 
WordNet (Miller, 1995), EuroWordNet (Vossen, 
1998) or MindNet (Richardson et al, 1998) con-
tain them. However, as various researchers have 
pointed out (Harabagiu et al, 1999), these net-
works lack information, in particular with regard 
to syntagmatic associations, which are generally 
unsystematic. These latter, called TIORA (Zock 
and Bilac, 2004) or topical relations (Ferret, 
2002) account for the fact that two words refer to 
the same topic, or take part in the same situation 
or scenario. Word-pairs like doctor?hospital,
burglar?policeman or plane?airport, are exam-
ples in case. The lack of such topical relations in 
resources like WordNet has been dubbed as the 
tennis problem (Roger Chaffin, cited in Fell-
baum, 1998). Some of these links have been in-
troduced more recently in WordNet via the do-
main relation. Yet their number remains still very 
small. For instance, WordNet 2.1 does not con-
tain any of the three associations mentioned here 
above, despite their high frequency. 
The lack of systematicity of these topical rela-
tions makes their extraction and typing very dif-
ficult on a large scale. This is why some re-
searchers have proposed to use automatic learn-
ing techniques to extend lexical networks like 
WordNet. In (Harabagiu & Moldovan, 1998), 
this was done by extracting topical relations from 
the glosses associated to the synsets. Other re-
searchers used external sources: Mandala et al 
(1999) integrated co-occurrences and a thesaurus 
to WordNet for query expansion; Agirre et al 
(2001) built topic signatures from texts in rela-
tion to synsets; Magnini and Cavagli? (2000) 
annotated the synsets with Subject Field Codes. 
This last idea has been taken up and extended by 
(Avancini et al, 2003) who expanded the do-
mains built from this annotation. 
Despite the improvements, all these ap-
proaches are limited by the fact that they rely too 
heavily on WordNet and some of its more so-
phisticated features (such as the definitions asso-
ciated with the synsets). While often being ex-
ploited by acquisition methods, these features are 
generally lacking in similar lexico-semantic net-
works. Moreover, these methods attempt to learn 
topical knowledge from a lexical network rather 
than topical relations. Since our goal is different, 
we have chosen not to rely on any significant 
resource, all the more as we would like our 
method to be applicable to a wide array of lan-
guages. In consequence, we took an incremental 
approach (Ferret, 2006): starting from a network 
of lexical co-occurrences7 collected from a large 
corpus, we used these latter to select potential 
topical relations by using a topical analyzer. 
4.2 From a network of co-occurrences to a 
set of Topical Units 
We start by extracting lexical co-occurrences 
from a corpus to build a network. To this end we 
follow the method introduced by (Church and 
Hanks, 1990), i.e. by sliding a window of a given 
size over some texts. The parameters of this ex-
traction were set in such a way as to catch the 
most obvious topical relations: the window was 
fairly large (20-words wide), and while it took 
text boundaries into account, it ignored the order 
of the co-occurrences. Like (Church and Hanks, 
1990), we used mutual information to measure 
the cohesion between two words. The finite size 
of the corpus allows us to normalize this measure 
in line with the maximal mutual information 
relative to the corpus.  
This network is used by TOPICOLL (Ferret, 
2002), a topic analyzer, which performs simulta-
neously three tasks, relevant for this goal: 
 it segments texts into topically homogene-
ous segments;  
 it selects in each segment the most repre-
sentative words of its topic; 
 
7 Such a network is only another view of a set of co-
occurrences: its nodes are the co-occurrent words and its 
edges are the co-occurrence relations. 
284
 it proposes a restricted set of words from 
the co-occurrence network to expand the 
selected words of the segment. 
These three tasks rely on a common mecha-
nism: a window is moved over the text to be ana-
lyzed in order to limit the focus space of the 
analysis. This latter contains a lemmatized ver-
sion of the text?s plain words. For each position 
of this window, we select only words of the co-
occurrence network that are linked to at least 
three other words of the window (see Figure 3). 
This leads to select both words that are in the 
window (first order co-occurrents) and words 
coming from the network (second order co-
occurrents). The number of links between the 
selected words of the network, called expansion 
words, and those of the window is a good indica-
tor of the topical coherence of the window?s con-
tent. Hence, when their number is small, a seg-
ment boundary can be assumed. This is the basic 
principle underlying our topic analyzer. 
 
0.14
0.21 0.10
0.18 0.13
0.17
w5w4w3w2w1
0.48 = pw3x0.18+pw4x0.13
+pw5x0.17
selected word from the co-occurrence network (with its weight)
1.0
word from text (with p its weight in the window, equal to 
0.21 link in the co-occurrence network (with its cohesion value)
1.0 1.0 1.0 1.0 1.0
wi,
n1 n2
1.0 for all words of the window in this example)
0.48
Figure 3: Selection and weighting of words 
from the co-occurrence network 
The words selected for each position of the 
window are summed, to keep only those occur-
ring in 75% of the positions of the segment. This 
allows reducing the number of words selected 
from non-topical co-occurrences. Once a corpus 
has been processed by TOPICOLL, we obtain a 
set of segments and a set of expansion words for 
each one of them. The association of the selected 
words of a segment and its expansion words is 
called a Topical Unit. Since both sets of words 
are selected for reasons of topical homogeneity, 
their co-occurrence is more likely to be a topical 
relation than in our initial network. 
4.3 Filtering of Topical Units 
Before recording the co-occurrences in the Topi-
cal Units built in this way, the units are filtered 
twice. The first filter aims at discarding hetero-
geneous Topical Units, which can arise as a side 
effect of a document whose topics are so inter-
mingled that it is impossible to get a reliable lin-
ear segmentation of the text. We consider that 
this occurs when for a given text segment, no 
word can be selected as a representative of the 
topic of the segment. Moreover, we only keep 
the Topical Units that contain at least two words 
from their original segment. A topic is defined 
here as a configuration of words. Note that the 
identification of such a configuration cannot be 
based solely on a single word. 
 
Text words Expansion words 
surveillance 
(watch)
police_judiciaire 
(judiciary police)
t?l?phonique 
(telephone)
?crouer 
(to imprison)
juge 
(judge)
garde_?_vue 
(police custody)
policier 
(policeman)
?coute_t?l?phonique 
(phone tapping)
brigade 
(squad)
juge_d?instruction 
(examining judge)
enqu?te 
(investigation)
contr?le_judiciaire 
(judicial review)
placer 
(to put)
Table 1: Content of a filtered Topical Unit 
The second filter is applied to the expansion 
words of each Topical Unit to increase their topi-
cal homogeneity. The principle of the filtering of 
these words is the same as the principle of their 
selection described in Section 4.2: an expansion 
word is kept if it is linked in the co-occurrence 
network to at least three text words of the Topi-
cal Unit. Moreover, a selective threshold is ap-
plied to the frequency and the cohesion of the co-
occurrences supporting these links: only co-
occurrences whose frequency and cohesion are 
respectively higher or equal to 15 and 0.15 are 
used. For instance in Table 1, which shows an 
example of a Topical Unit after its filtering, 
?crouer (to imprison) is selected, because it is 
linked in the co-occurrence network to the fol-
lowing words of the text: 
juge (judge): 52 (frequency) ? 0.17 (cohesion) 
policier (policeman): 56 ? 0.17
enqu?te (investigation): 42 ? 0.16
285
word freq. word freq. word freq. word freq.
sc?ne 
(stage) 884 
th??tral 
(dramatic) 62 
cynique
(cynical) 26 
sc?nique 
(theatrical) 14
th??tre 
(theater) 679 
sc?nariste 
(scriptwriter) 51 
miss
(miss) 20 
Chabol 
(Chabol) 13
r?alisateur 
(director) 220 
comique 
(comic) 51 
parti_pris
(bias) 16 
Tchekov 
(Tchekov) 13
cin?aste 
(film-marker) 135 
oscar 
(oscar) 40 
monologue 
(monolog) 15 
allocataire
(beneficiary) 13
com?die 
(comedy) 104 
film_am?ricain 
(american film) 38 
revisiter
(to revisit) 14 
satirique
(satirical) 13
costumer 
(to dress up) 63 
hollywoodien 
(Hollywood) 30 
gros_plan 
(close-up) 14  
Table 2: Co-occurrents of the word acteur (actor) with a cohesion of 0.16  
(the co-occurrents removed by our filtering method are underlined) 
4.4 From Topical Units to a network of 
topical relations 
After the filtering, a Topical Unit gathers a set of 
words supposed to be strongly coherent from the 
topical point of view. Next, we record the co-
occurrences between these words for all the 
Topical Units remaining after filtering. Hence, 
we get a large set of topical co-occurrences, de-
spite the fact that a significant number of non-
topical co-occurrences remains, the filtering of 
Topical Units being an unsupervised process. 
The frequency of a co-occurrence in this case is 
given by the number of Topical Units containing 
both words simultaneously. No distinction con-
cerning the origin of the words of the Topical 
Units is made. 
The network of topical co-occurrences built 
from Topical Units is a subset of the initial net-
work. However, it also contains co-occurrences 
that are not part of it, i.e. co-occurrences that 
were not extracted from the corpus used for set-
ting the initial network or co-occurrences whose 
frequency in this corpus was too low. Only some 
of these ?new? co-occurrences are topical. Since 
it is difficult to estimate globally which ones are 
interesting, we have decided to focus our atten-
tion only on the co-occurrences of the topical 
network already present in the initial network. 
Thus, we only use the network of topical co-
occurrences as a filter for the initial co-
occurrence network. Before doing so, we filter 
the topical network in order to discard co-
occurrences whose frequency is too low, that is, 
co-occurrences that are unstable and not repre-
sentative. From the use of the final network by 
TOPICOLL (see Section 4.5), we set the thresh-
old experimentally to 5. Finally, the initial net-
work is filtered by keeping only co-occurrences 
present in the topical network. Their frequency 
and cohesion are taken from the initial network. 
While the frequencies given by the topical net-
work are potentially interesting for their topical 
significance, we do not use them because the 
results of the filtering of Topical Units are too 
hard to evaluate. 
4.5 Results and evaluation 
We applied the method described here to an ini-
tial co-occurrence network extracted from a cor-
pus of 24 months of Le Monde, a major French 
newspaper. The size of the corpus was around 39 
million words. The initial network contained 
18,958 words and 341,549 relations. The first run 
produced 382,208 Topical Units. After filtering, 
we kept 59% of them. The network built from 
these Topical Units was made of 11,674 words 
and 2,864,473 co-occurrences. 70% of these co-
occurrences were new with regard to the initial 
network and were discarded. Finally, we got a 
filtered network of 7,160 words and 183,074 re-
lations, which represents a cut of 46% of the ini-
tial network. A qualitative study showed that 
most of the discarded relations are non-topical. 
This is illustrated by Table 2, which gives the co-
occurrents of the word acteur (actor) that are 
filtered by our method among its co-occurrents 
with a high cohesion (equal to 0.16). For in-
stance, the words cynique (cynical) or allocataire 
(beneficiary) are cohesive co-occurrents of the 
286
word actor, even though they are not topically 
linked to it. These words are filtered out, while 
we keep words like gros_plan (close-up) or sc?-
nique (theatrical), which topically cohere with 
acteur (actor) despite their lower frequency than 
the discarded words. 
 
Recall8 Precision F1-measure
Error 
(Pk)9
initial (I) 0.85 0.79 0.82 0.20 
topical 
filtering 
(T) 
0.85 0.79 0.82 0.21 
frequency 
filtering 
(F) 
0.83 0.71 0.77 0.25 
Table 3: TOPICOLL?s results  
with different networks 
 
In order to evaluate more objectively our 
work, we compared the quantitative results of 
TOPICOLL with the initial network and its fil-
tered version. The evaluation showed that the 
performance of the segmenter remains stable, 
even if we use a topically filtered network (see 
Table 3). Moreover, it became obvious that a 
network filtered only by frequency and cohesion 
performs significantly less well, even with a 
comparable size. For testing the statistical sig-
nificance of these results, we applied to the Pk
values a one-side t-test with a null hypothesis of 
equal means. Levels lower or equal to 0.05 are 
considered as statistically significant: 
pval (I-T): 0.08 
pval (I-F): 0.02 
pval (T-F): 0.05 
These values confirm that the difference be-
tween the initial network (I) and the topically 
filtered one (T) is actually not significant, 
whereas the filtering based on co-occurrence fre-
quencies leads to significantly lower results, both 
compared to the initial network and the topically 
filtered one. Hence, one may conclude that our 
 
8 Precision is given by Nt / Nb and recall by Nt / D, with D
being the number of document breaks, Nb the number of 
boundaries found by TOPICOLL and Nt the number of 
boundaries that are document breaks (the boundary should 
not be farther than 9 plain words from the document break). 
9 Pk (Beeferman et al, 1999) evaluates the probability that a 
randomly chosen pair of words, separated by k words, is 
wrongly classified, i.e. they are found in the same segment 
by TOPICOLL, while they are actually in different ones (miss 
of a document break), or they are found in different seg-
ments, while they are actually in the same one (false alarm). 
method is an effective way of selecting topical 
relations by preference. 
5 Discussion and conclusion 
We have raised and partially answered the ques-
tion of how a dictionary should be indexed in 
order to support word access, a question initially 
addressed in (Zock, 2002) and (Zock and Bilac, 
2004). We were particularly concerned with the 
language producer, as his needs (and knowledge 
at the onset) are quite different from the ones of 
the language receiver (listener/reader). It seems 
that, in order to achieve our goal, we need to do 
two things: add to an existing electronic diction-
ary information that people tend to associate with 
a word, that is, build and enrich a semantic net-
work, and provide a tool to navigate in it. To this 
end we have suggested to label the links, as this 
would reduce the graph complexity and allow for 
type-based navigation. Actually our basic pro-
posal is to extend a resource like WordNet by 
adding certain links, in particular on the syntag-
matic axis. These links are associations, and their 
role consists in helping the encoder to find ideas 
(concepts/words) related to a given stimulus 
(brainstorming), or to find the word he is think-
ing of (word access). 
One problem that we are confronted with is to 
identify possible associations. Ideally we would 
need a complete list, but unfortunately, this does 
not exist. Yet, there is a lot of highly relevant 
information out there. For example, Mel?cuk?s 
lexical functions (Mel?cuk, 1995), Fillmore?s 
FRAMENET10, work on ontologies (CYC), thesau-
rus (Roget), WordNets (the original version from 
Princeton, various Euro-WordNets, BalkaNet), 
HowNet11, the work done by MICRA, the FACTO-
TUM project 12 , or the Wordsmyth diction-
ary/thesaurus13.
Since words are linked via associations, it is 
important to reveal these links. Once this is done, 
words can be accessed by following these links. 
We have presented here some preliminary work 
for extracting an important subset of such links 
from texts, topical associations, which are gener-
ally absent from dictionaries or resources like 
WordNet. An evaluation of the topic segmenta-
tion has shown that the relations extracted are 
sound from the topical point of view, and that 
they can be extracted automatically. However, 
 
10 http://www.icsi.berkeley.edu/~framenet/
11 http://www.keenage.com/html/e_index.html
12 http://humanities.uchicago.edu/homes/MICRA/
13 http://www.wordsmyth.com/
287
they still contain too much noise to be directly 
exploitable by an end user for accessing a word 
in a dictionary. One way of reducing the noise of 
the extracted relations would be to build from 
each text a representation of its topics and to re-
cord the co-occurrences in these representations 
rather than in the segments delimited by a topic 
segmenter. This is a hypothesis we are currently 
exploring. While we have focused here only on 
word access on the basis of (other) words, one 
should not forget that most of the time speakers 
or writers start from meanings. Hence, we shall 
consider this point more carefully in our future 
work, by taking a serious look at the proposals 
made by Bilac et al (2004); Durgar and Oflazer 
(2004), or Dutoit and Nugues (2002). 
References 
Eneko Agirre, Olatz Ansa, David Martinez and Edu-
ard Hovy. 2001. Enriching WordNet concepts with 
topic signatures. In NAACL?01 Workshop on 
WordNet and Other Lexical Resources: Applica-
tions, Extensions and Customizations.
Henri Avancini, Alberto Lavelli, Bernardo Magnini, 
Fabrizio Sebastiani and Roberto Zanoli. 2003. Ex-
panding Domain-Specific Lexicons by Term Cate-
gorization. In 18th ACM Symposium on Applied 
Computing (SAC-03).
Doug Beeferman, Adam Berger and Lafferty. 1999. 
Statistical Models for Text Segmentation. Machine 
Learning, 34(1): 177-210. 
Slaven Bilac, Wataru Watanabe, Taiichi Hashimoto, 
Takenobu Tokunaga and Hozumi Tanaka. 2004. 
Dictionary search based on the target word descrip-
tion. In Tenth Annual Meeting of The Association 
for Natural Language Processing (NLP2004),
pages 556-559. 
Roger Brown and David McNeill. 1996. The tip of the 
tongue phenomenon. Journal of Verbal Learning 
and Verbal Behaviour, 5: 325-337. 
Kenneth Church and Patrick Hanks. 1990. Word As-
sociation Norms, Mutual Information, And Lexi-
cography. Computational Linguistics, 16(1): 177-
210. 
Ilknur Durgar El-Kahlout and Kemal Oflazer. 2004. 
Use of Wordnet for Retrieving Words from Their 
Meanings, In 2nd Global WordNet Conference,
Brno 
Dominique Dutoit and Pierre Nugues. 2002. A lexical 
network and an algorithm to find words from defi-
nitions. In 15th European Conference on Artificial 
Intelligence (ECAI 2002), Lyon, pages 450-454, 
IOS Press. 
Christiane Fellbaum. 1998. WordNet - An Electronic 
Lexical Database, MIT Press. 
Olivier Ferret. 2006. Building a network of topical 
relations from a corpus. In LREC 2006.
Olivier Ferret. 2002. Using collocations for topic 
segmentation and link detection. In COLING 2002,
pages 260-266. 
Sanda M. Harabagiu, George A. Miller and Dan I. 
Moldovan. 1999. WordNet 2 - A Morphologically 
and Semantically Enhanced Resource. In ACL-
SIGLEX99: Standardizing Lexical Resources,
pages 1-8. 
Sanda M. Harabagiu and Dan I. Moldovan. 1998. 
Knowledge Processing on an Extended WordNet. 
In WordNet - An Electronic Lexical Database,
pages 379-405. 
Philip Humble. 2001. Dictionaries and Language 
Learners, Haag and Herchen. 
William Levelt, Ardi Roelofs and Antje Meyer. 1999. 
A theory of lexical access in speech production, 
Behavioral and Brain Sciences, 22: 1-75. 
Bernardo Magnini and Gabriela Cavagli?. 2000. Inte-
grating Subject Field Codes into WordNet. In 
LREC 2000.
Rila Mandala, Takenobu Tokunaga and Hozumi 
Tanaka. 1999. Complementing WordNet with Ro-
get?s and Corpus-based Thesauri for Information 
Retrieval. In EACL 99.
Igor Mel?Auk, Arno Clas and Alain Polgu?re. 1995. 
Introduction ? la lexicologie explicative et combi-
natoire, Louvain, Duculot. 
George A. Miller. 1995. WordNet: A lexical Data-
base, Communications of the ACM. 38(11): 39-41. 
Stephen D. Richardson, William B. Dolan and Lucy 
Vanderwende. 1998. MindNet: Acquiring and 
Structuring Semantic Information from Text. In 
ACL-COLING?98, pages 1098-1102. 
Piek Vossen. 1998. EuroWordNet: A Multilingual 
Database with Lexical Semantic Networks. Kluwer 
Academic Publisher. 
Gabriella Vigliocco, Antonini, T., and Merryl Garrett. 
1997. Grammatical gender is on the tip of Italian 
tongues. Psychological Science, 8: 314-317. 
Michael Zock. 2002. Sorry, what was your name 
again, or how to overcome the tip-of-the tongue 
problem with the help of a computer? In SemaNet 
workshop, COLING 2002, Taipei. 
http://acl.ldc.upenn.edu /W/W02/W02-1118.pdf
Michael Zock and Slaven Bilac. 2004. Word lookup 
on the basis of associations: from an idea to a 
roadmap. In COLING 2004 workshop: Enhancing 
and using dictionaries, Geneva. 
http://acl.ldc.upenn.edu/ coling2004/W10/pdf/5.pdf
288
Coling 2008: Proceedings of the workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), pages 9?17
Manchester, August 2008
Lexical Access Based on Underspecified Input
Michael ZOCK
LIF-CNRS
?
Equipe TALEP
163, Avenue de Luminy
F-13288 Marseille Cedex 9
michael.zock@lif.univ-mrs.fr
Didier SCHWAB
Groupe GETALP
Laboratoire d?Informatique de Grenoble
385 avenue de la Bibliothque - BP 53
F-38041 Grenoble Cedex 9
didier.schwab@imag.fr
Abstract
Words play a major role in language pro-
duction, hence finding them is of vital im-
portance, be it for speaking or writing.
Words are stored in a dictionary, and the
general belief holds, the bigger the bet-
ter. Yet, to be truly useful the resource
should contain not only many entries and a
lot of information concerning each one of
them, but also adequate means to reveal the
stored information. Information access de-
pends crucially on the organization of the
data (words) and on the navigational tools.
It also depends on the grouping, ranking
and indexing of the data, a factor too often
overlooked.
We will present here some preliminary re-
sults, showing how an existing electronic
dictionary could be enhanced to support
language producers to find the word they
are looking for. To this end we have started
to build a corpus-based association ma-
trix, composed of target words and ac-
cess keys (meaning elements, related con-
cepts/words), the two being connected at
their intersection in terms of weight and
type of link, information used subsequently
for grouping, ranking and navigation.
1 Context and problem
When speaking or writing we encounter basi-
cally either of the following two situations: one
where everything works automatically, somehow
like magic, words popping up one after another
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
like spring water, and another where we look de-
liberately and often painstakingly for a specific,
possibly known word. We will be concerned here
with this latter situation: a speaker/ writer using
an electronic dictionary to look for such a word.
Unfortunately, alphabetically organized dictionar-
ies are not well suited for this kind of reverse
lookup where the inputs are meanings (elements of
the word?s definition) or conceptually related ele-
ments (collocations, associations), and the outputs
the target words.
Without any doubt, lexicographers have made
considerable efforts to assist language users, build-
ing huge resources, composed of many words and
lots of information associated with each one of
them. Still, it is not unfair to say most dictionar-
ies have been conceived from the reader?s point of
view. The lexicographers have hardly taken into
account the language producer?s perspective,
1
con-
sidering conceptual input, incomplete as it may be,
as starting point. While readers start with words,
looking generally for their corresponding mean-
ings, speakers or writers usually start with the op-
posite, meanings or concepts,
2
which should be the
entry points of a dictionary, which ideally is neu-
tral in terms of access direction.
3
The problem is that we still don?t know very
well what concepts are, whether they are compo-
sitional and if so, how many primitives there are
(Wilks, 1977; Wierzbicka, 1996; Goddard, 1998).
1
Roget?s thesaurus (Roget, 1852), Miller and Fellbaum?s
WordNet (Fellbaum, 1998) and Longman?s Language Activa-
tor (Summers, 1993), being notable exceptions (For more de-
tails, see next section).
2
Of course, this does not preclude, that we may have to
use words to refer to them in a concept-based query.
3
While we agree with Polgu`ere theoretically when he
pleads for dictionary neutrality with regard to lexical access
(Polgu`ere, 2006), from a practical point of view the situation
is obviously quite different for the speaker and listener, even
if both of them draw on the same resource.
9
Neither do we know how to represent them. Yet,
there are ways around this problem as we will
show. Whether concepts and words are organized
and accessed differently is a question we cannot
answer here. We can agree though on the fact
that getting information concerning words is fairly
unproblematic when reading, at least in the case
of most western languages. Words can gener-
ally be found easily in a dictionary, provided the
user knows the spelling, the alphabet and how to
build lemma starting from an inflected form. Un-
like words, which are organized alphabetically (in
western languages) or by form (stroke counts in
Chinese), concepts are organized topically: they
are clustered into functional groups according to
their role in real world, or our perception of it.
Psychologist have studied the difficulties peo-
ple have when trying to produce or access words
(Aitchinson, 2003). In particular, they have stud-
ied the tip-of-the-tongue phenomenon (Brown and
McNeill, 1996) and the effects an input can have
on the quality of an output (error analysis (Cutler,
1982)) and on the ease of its production: positive
or negative priming effect (activation/inhibition).
Obviously, these findings allow certain conclu-
sions, and they might guide us when developing
tools to help people find the needed word. In par-
ticular, they reveal two facts highly relevant for our
goal:
1. even if people fail to access a given word, they
might know a lot about it: origin, meaning
(word definition, role played in a given sit-
uation), part of speech, number of syllables,
similar sounding words, etc. Yet, despite all
this knowledge, they seem to lack some cru-
cial information to be able to produce the pho-
netic form. The word gets blocked at the very
last moment, even though it has reached the
tip-of-the-tongue. This kind of nuisance is all
the more likely as the target word is rare and
primed by a similar sounding word.
2. unlike words in printed or electronic dictio-
naries, words in our mind may be inexis-
tent as tokens. What we seem to have in
our minds are decomposed, abstract entities
which need to be synthesized over time.
4
Ac-
4
This may be very surprising, yet, this need not be the case
if we consider the fact that speech errors are nearly always
due to competing elements from the same level or an adja-
cent one, unless they are the result of a surrounding concept
which has been activated, or which is about to be translated
cording to Levelt (Levelt, 1996) the genera-
tion of words (synthesis) involves the follow-
ing stages: conceptual preparation, lexical se-
lection, phonological- and phonetic encoding,
articulation. Bear in mind that having per-
formed ?lexical selection? does not imply ac-
cess to the phonetic form (see the experiments
on the tip-of-the-tongue phenomenon).
What can be concluded from these observa-
tions? It seems that underspecified input is suffi-
ciently frequent to be considered as normal. Hence
we should accept it, and make the best out of it by
using whatever information is available (accessi-
ble), no matter how incomplete, since it may still
contribute to find the wanted information, be it by
reducing the search space. Obviously, the more in-
formation we have the better, as this reduces the
number of words among which to choose.
2 Related work and goal
While more dictionaries have been built for the
reader than for the writer, there have been some
onomasiological attempts as early as in the mid-
dle of the 19th century. For example, Roget?s
Thesaurus (Roget, 1852), T?ong?s Chinese and
English instructor (T?ong, 1862), or Boissiere?s
analogical dictionary (Boissi`ere, 1862).
5
Newer
work includes Mel??cuk?s ECD (Mel??cuk et al,
1999), Miller and Fellbaum?s WordNet (Fellbaum,
1998), Richardson and Dolan?s MindNet (Richard-
son et al, 1998), Dong?s HowNet (Dong and
Dong, 2006) and Longman?s Language Activa-
tor (Summers, 1993). There is also the work of
into words. Put differently, we do not store words at all in
our mind, at least not in the layman?s or lexicographer?s sense
who consider word-forms and their meanings as one. If we
are right, than rather continue to consider the human mind as
a word store we could consider it as a word factory. Indeed,
by looking at some of the work done by psychologists who try
to emulate the mental lexicon (for a good survey see (Harley,
2004), pages 359-374) one gets the impression that words are
synthesized rather than located and read out. Taking a look at
all this work, generally connectionist models, one may con-
clude that, rather than having words in our mind we have a
set of more or less abstract features (concepts, syntactic infor-
mation, phonemes), distributed across various layers, which
need to be synthesized over time. To do so we proceed from
abstract meanings to concrete sounds, which at some point
were also just abstract features. By propagating energy rather
than data (as there is no message passing, transformation or
cumulation of information, there is only activation spreading,
that is, changes of energy levels, call it weights, electronic
impulses, or whatever), that we propagate signals, activating
ultimately certain peripheral organs (larynx, tongue, mouth,
lips, hands) in such a way as to produce movements or sounds,
that, not knowing better, we call words.
5
For a more recent proposal see (Robert et al, 1993).
10
(Fontenelle, 1997; Sierra, 2000; Moerdijk, 2008),
various collocation dictionaries (BBI, OECD) and
Bernstein?s Reverse Dictionary.
6
Finally, there is
M. Rundell?s MEDAL, a thesaurus produced with
the help of Kilgariff?s Sketch Engine (Kilgarriff et
al., 2004).
As one can see, a lot of progress has been ac-
complished over the last few years, yet more can be
done, especially with regard to unifying linguistic
and encyclopedic knowledge. Let?s take an exam-
ple to illustrate our point.
Suppose, you were looking for a word express-
ing the following ideas: ?superior dark coffee made
from beans from Arabia?, and that you knew that
the target word was neither espresso nor cappuc-
cino. While none of this would lead you directly
to the intended word, mocha, the information at
hand, i.e. the word?s definition or some of its ele-
ments, could certainly be used. In addition, people
draw on knowledge concerning the role a concept
(or word) plays in language and in real world, i.e.
the associations it evokes. For example, they may
know that they are looking for a noun standing for
a beverage that people take under certain circum-
stances, that the liquid has certain properties, etc.
In sum, people have in their mind an encyclope-
dia: all words, concepts or ideas being highly con-
nected. Hence, any one of them has the potential to
evoke the others. The likelihood for this to happen
depends, of course, on factors such as frequency
(associative strength), distance (direct vs. indirect
access), prominence (saliency), etc.
How is this supposed to work for a dictionary
user? Suppose you were looking for the word
mocha (target word: t
w
), yet the only token com-
ing to your mind were computer (source word:
s
w
). Taking this latter as starting point, the system
would show all the connected words, for example,
Java, Perl, Prolog (programing languages), mouse,
printer (hardware), Mac, PC (type of machines),
etc. querying the user to decide on the direction of
search by choosing one of these words. After all,
s/he knows best which of them comes closest to the
t
w
. Having started from the s
w
?computer?, and
knowing that the t
w
is neither some kind of soft-
ware nor a type of computer, s/he would probably
choose Java, which is not only a programming lan-
guage but also an island. Taking this latter as the
6
There is also at least one electronic incarnation
of a dictionary with reverse access, combining a dic-
tionary (WordNet) and an encyclopedia (Wikipedia)
(http://www.onelook.com/reverse-dictionary.shtml).
new starting point s/he might choose coffee (since
s/he is looking for some kind of beverage, possibly
made from an ingredient produced in Java, coffee),
and finally mocha, a type of beverage made from
these beans. Of course, the word Java might just
as well trigger Kawa which not only rhymes with
the s
w
, but also evokes Kawa Igen, a javanese vol-
cano, or familiar word of coffee in French.
As one can see, this approach allows word ac-
cess via multiple routes: there are many ways lead-
ing to Rome. Also, while the distance covered
in our example is quite unusual, it is possible to
reach the goal quickly. It took us actually very
few moves, four, to find an indirect link, between
two, fairly remotely related terms: computer and
mocha. Of course, cyber-coffee fans might be even
quicker in reaching their goal.
3 The lexical matrix revisited
The main question that we are interested in here
is how, or in what terms, to index the dictionary
in order to allow for quick and intuitive access to
words. Access should be possible on the basis
of meaning (or meaning elements), various kinds
of associations (most prominently ?syntagmatic?
ones) and, more generally speaking, underspeci-
fied input. To this end we have started to build an
association matrix (henceforth AM), akin to, yet
different from G. Miller?s initial proposal of WN
(Miller et al, 1990). He suggested to build a lex-
ical matrix by putting on one axis all the forms,
i.e. words of the language, and on the other, their
corresponding meanings. The latter being defined
in terms of synsets. The corresponding meaning-
form relations are signaled via a boolean (pres-
ence/absence). Hence, looking at the intersection
of meanings and forms, one can see which mean-
ings are expressed by, or converge toward what
forms, or conversely, what form expresses which
meanings. Whether this is the way WN is actually
implemented is not clear to us, though we believe
that it is not. Anyhow, our approach is different,
and we hope the reader will understand in a mo-
ment the reasons why.
We will also put on one axis all the form ele-
ments, i.e. the lemmata or expressions of a given
language (we refer to them as target words, hence-
forth t
w
). On the other axis we will place the trig-
gers or access-words (henceforth a
w
), that is, the
words or concepts capable and likely to evoke the
t
w
. These are typically the kind of words psy-
11
chologists have gathered in their association ex-
periments (Jung and Riklin, 1906; Deese, 1965;
Schvaneveldt, 1989). Note, that instead of putting
a boolean value at the intersection of the t
w
and the
a
w
, we will put weights and the type of link hold-
ing between the co-occurring terms. This gives us
quadruplets. For example, an utterance like ?this
is the key of the door? might yield the a
w
(key),
the t
w
(door), the link type l
t
(part of), and a weight
(let?s say 15).
The fact that we have these two kinds of in-
formation is very important later on, as it allows
the search engine to cluster by type the possible
answers to be given in response to a user query
(word(s) provided as input) and to rank them.
Since the number of hits, i.e. words from which
the user must choose, may be substantial (depend-
ing on the degree of specification of the input), it is
important to group and rank them to ease naviga-
tion, allowing the user to find directly and quickly
the desired word, or at least the word with which
to continue search.
Obviously, different word senses (homographs),
require different entries (bank-money vs bank-
river), but so will synonyms, as every word-form,
synonym or not, is likely to be evoked by a differ-
ent key- or access-word (similarity of sound).
7
Also, we will need a new line for every different
relation between a a
w
and a t
w
. Whether more than
one line is needed in the case of identical links be-
ing expressed by different linguistic resources (the
lock of the door vs. the door?s lock vs. the door
has a lock) remains an open empirical question.
Let us see quickly how our AM is supposed
to work. Imagine you wanted to find the word
for the following concept: hat of a bishop. In
such a case, any of the following concepts or
words might come to your mind: church, Vati-
can, abbot, monk, monastery, ceremony, ribbon,
and of course rhyming words like: brighter, fighter,
lighter, righter, tighter, writer,
8
as, indeed, any of
them could remind us of the t
w
: mitre. Hence, all
of them are possible a
w
.
Once this resource is built, access is quite
straightforward. The user gives as input all the
words coming to his mind when thinking of a given
7
Take, for example, the nouns rubbish and garbage which
can be considered as synonyms. Yet, while the former may
remind you of a rabbit or (horse)-radish, the latter may evoke
the word cabbage.
8
The question, whether rhyming words should be com-
puted is not crucial at this stage.
idea or concept,
9
and the system will display all
connected words. If the user can find the item he
is looking for in this list, search stops, otherwise
it will continue, the user giving other words of the
list, or words evoked by them.
Of course, remains the question of how to build
this resource, in particular, how to populate the
axis devoted to the trigger words, i.e. access-
keys. At present we consider three approaches:
one, where we use the words occurring in word
definitions (see also, (Dutoit and Nugues, 2002;
Bilac et al, 2004)), the other is to mine a well-
balanced corpus, to find co-occurrences within a
given window (Ferret and Zock, 2006), the size
depending a bit on the text type (encyclopedia) or
type of corpus. Still another solution would be
to draw on the association lists produced by psy-
chologists, see for example http://www.usf.edu/, or
http://www.eat.rl.ac.uk.
Of course, the idea of using matrices in linguis-
tics is not new. There are at least two authors who
have proposed its use: M. Gross (Gross, 1984)
used it for coding the syntactic behavior of lex-
ical items, hence the term lexicon-grammar, and
G. Miller, the father of WN (Miller et al, 1990)
suggested it to support lexical access. While the
former work is not relevant for us here, Miller?s
proposal is. What are the differences between his
proposal and ours? There are basically four main
differences:
1. we use, collocations or access-words, i.e a
ws
rather than synsets; Hence, any of the follow-
ing a
ws
(cat, grey, computer device, cheese,
Speedy Gonzales) could point toward the t
w
?mouse?, none of them are part of the mean-
ing, leave alone synonyms.
2. we mark explicitly the weight and the type of
link between the t
w
and the a
w
(isa, part of,
etc.),
10
whereas WN uses only a binary value.
Both the weight and link are necessary infor-
mation for ranking and grouping, i.e. naviga-
tion.
3. our AM is corpus-sensitive (see below),
hence, we can, at least in principle, accommo-
9
The quantifier all shouldn?t be taken too literally. What
we have in mind are ?salient? words available in the speaker?s
mind at a given moment
10
Hence, if several links are possible between the t
w
and
the a
w
, several cells will be used. Think of the many possible
relations between a city and a country, example: Paris and
France (part of, biggest city of, located in, etc.)
12
date the fact that a speaker is changing topics,
adapting the weight of a given word or find a
more adequate a
w
in this new context. Think
of ?piano? in the contexts of a concert or mov-
ing your household. Only the latter would
evoke the notion of weight.
4. relying on a corpus, we can take advantage of
syntagmatic associations (often encyclopedic
knowledge), something which is difficult to
obtain for WN.
4 Keep the set of lexical candidates small
Here and in the next section we describe how the
idea of the AM has been computationally dealt
with. The goal is to reduce the number of hits,
i.e. possible t
ws
(output), as a function of the in-
put, i.e, the number of relevant a
ws
given by the
speaker/writer. To achieve this goal we apply lex-
ical functions to the a
ws
, considering the intersec-
tion of the obtained sets to be the relevant t
ws
.
4.1 Lexical Functions
The usefulness of lexical functions for linguistics
in general and for language production in particu-
lar has been shown by Mel??cuk (Mel??cuk, 1996).
We will use them here, as they seem to fit also our
needs of information extraction or lexical access.
Mel??cuk has coined the term lexical functions to
refer to the fact that two terms are systematically
related. For example, the lexical function Gener
refers to the fact that some term (let?s say ?cat?)
can be replaced by a more general term (let?s say
?animal?).
Lexical functions encode the combinability of
words. While ?big? and ?strong? express the same
idea (intensity, magnitude), they cannot be com-
bined freely with any noun: strong can be as-
sociated with fever, whereas big cannot. Of
course, this kind of combinability between lexical
terms is language specific, because unlike in En-
glish, in French one can say grosse fi`evre or forte
fi`evre, both being correct (Schwab and Lafourcade,
2007). Our AM handles, of course these kind of
functions. Here is a list of some of them:
- paradigmatic associations: hypernymy
(?cat? - ?animal?), hyponymy, synonymy, or
antonymy,. . . ;
- syntagmatic associations: collocations (?fear?
being associated with ?strong? or ?little?);
- morphological relations ie. terms being de-
rived from another part of speech: applying
the change-part-of-speech lexical function
f
cpos
to ?garden? will yield: f
cpos
(?garden?) =
{?to garden?, ?gardener?, . . .}
- sound-related items: homophones, rhymes.
4.2 Assumptions concerning search
The purpose of using lexical functions is to reduce
the number of possible outcomes from which the
user must choose. The list contains either the t
w
or another promising a
w
the user may want use to
continue search. Hence, lexical functions are use-
ful for search provided that:
1. the speaker/writer is able to specify the kind
of relations s/he wants to use. The problem
here lies in the nature and number of the func-
tions, some of them being very well specified,
while others are not.
2. the larger the number of trigger words the
smaller the list of words from which to
choose: the speaker/writer can add or delete
words to broaden or narrow the scope of
his/her query.
These hypotheses are being modeled by using
set properties of lexical functions. The idea is to
apply all functions, or a selection of them, to the
a
ws
and to give the speaker/writer the intersection
as result (see section 5.3.5 for an example)
5 Experiment
We have started with a simple, preliminary exper-
iment. Only one lexical function was used: neigh-
borhood (henceforth f
neig
). Let f
neig
be the func-
tion producing the set of co-occurring terms within
a given window (sentence or a paragraph).
11
The
result produced by the system and returned to the
user is the intersection of the application of f
neig
to the a
ws
. In the next section we explain how this
function is applied to two corpora (Wordnet and
Wikipedia), to show their respective qualities and
shortcomings for this specific task.
5.1 WordNet
5.1.1 Description
WordNet (henceforth WN) is a lexical database
for English developed under the guidance of G.
11
The scope or window size will vary with the text type
(normal text vs. encyclopedia). The optimal size is at this
point still an empirical question.
13
Miller (Miller et al, 1990). One of his goals was
to support lexical access akin to the human mind,
association-based. Knowledge is stored in a net-
work composed of nodes and links (nodes being
words or concepts and the links are the means of
connecting them) and access to knowledge, i.e.
search, takes place by entering the network at some
point and follow the links until one has reached the
goal (unless one has given up before). This kind
of navigation in a huge conceptual/lexical network
can be considered equivalent to spreading activa-
tion taking place in our brain.
Of course, such a network has to be built, and
navigational support must be provided to find the
location where knowledge or words are stored.
This is what Miller and his coworkers did by build-
ing WN. The resource has been built manually, and
it contains at present about 150.000 entries.
The structure of the dictionary is different from
conventional, alphabetical resources. Words are
organized in WN in two ways. Semantically sim-
ilar words, i.e. synonyms, are grouped as clus-
ters. These sets of synonyms, called synsets, are
then linked in various ways, depending on the
kind of relationship they entertain with the ad-
jacent synset. For example, their neighbors can
be more general or specific (hyperonymy vs. hy-
ponymy), they can be part of some reference ob-
ject (meronymy: car-motor), they can be the op-
posite (antonymy: hot-cold), etc. While WN is a
resource it can also be seen as a corpus.
5.1.2 Using WN as a corpus
There are many good reasons to use WN for
learning f
n
. For one, there are many extensions,
and second, the one we are using, eXtended WN
(Mihalcea and Moldovan, 2001) spares us the trou-
ble of having to address issues like: (a) seg-
mentation: we do not need to identify sentence
boundaries ; (b) semantic ambiguity: words being
tagged, we get good precision; (c) lemmatization:
since only verbs, nouns, adjectives and adverbs are
tagged, we need neither a stoplist nor a lemmatizer.
Despite all these qualities, two important prob-
lems remain nevertheless for this kind of corpus:
(a) size: though, all words are tagged, the cor-
pus remains small as it contains only 63.941 dif-
ferent words; (b) in consequence, the corpus lacks
many syntagmatic associations encoding encyclo-
pedic knowledge.
5.2 Using Wikipedia as corpus
Wikipedia is a free, multilingual encyclopedia, ac-
cessible on the Web.
12
For our experiment we have
chosen the English version which of this day (12th
of may 2008) contains 2,369,180 entries.
Wikipedia has exactly the opposite properties of
WN. While it covers well encyclopedic relations, it
is only raw text. Hence problems like text segmen-
tation, lemmatisation and stoplist definition need
to be addressed.
Our experiments with Wikipedia were very rudi-
mentary, given that we considered only 1000 doc-
uments. These latter were obtained in response to
the term ?wine?, by following the links obtained for
about 72.000 words.
5.3 Prototype
5.3.1 Building the resource and using it.
Building the resource requires processing a cor-
pus and building the database. Given a corpus
we apply our neighborhood function to a prede-
termined window (a paragraph in the case of ency-
clopedias).
13
The result, i.e. the co-occurrences,
will be stored in the database, together with their
weight, i.e. number of times two terms appear to-
gether, and the type of link. As mentionned above,
both kinds of information are needed later on for
ranking and navigation.
14
At present, cooccurences are stored as triplets
(t
w
, a
w
, times), where times represents the number
of times the two terms cooccur in the corpus, the
scope of coccurence being here the paragraph.
5.3.2 Processing of the Wikipedia page
For each Wikipedia page, a preprocessor
converts HTML pages into plain text. Next,
a part-of-speech tagger (http://www.ims.uni-
stuttgart.de/projekte/corplex/TreeTagger/) is used
to annotate all the words of the paragraph under
consideration. This allows the filtering of all
irrelevant words, to keep but a bag of words,
that is, the nouns, adjectives, verbs and adverbs
occuring in the paragraph. These words will be
used to fill the triplets of our database.
12
http://www.wikipedia.org
13
The optimal window-size depends probably on the text
type (encyclopedia vs. unformatted text). Yet, in the absence
of clear criteria, we consider the optimal window-size as an
open, empirical question.
14
This latter aspect is not implemented yet, but will be
added in the future, as it is a necessary component for easy
navigation (Zock and Bilac, 2004; Zock, 2006; Zock, 2007).
14
5.3.3 Corpus Building
We start arbitrarily from some page (for our ex-
periment, we have chosen ?wine? as input), apply
the algorithm outlined here above and pick then
randomly a noun within this page to fetch with this
input a new page on Wikipedia. This process is re-
peated until a given sample size is obtained (in our
case 1000 pages). Of course, instead of picking
randomly a noun, we could have decided to pro-
cess all the nouns of a given page, and to add then
incrementally the nouns of the next pages. Yet,
doing this would have led us to privilege a specific
topic (in our case ?wine?) instead of a more general
one.
5.3.4 Usage
We have developed a website in Java as a
servlet. Interactions with humans are simple: peo-
ple can add or delete a word from the current list
(see Input in the figure on top of the next page).
The example presented shows that with very few
words, hence very quickly, we can obtain the de-
sired word.
Given some input, the system provides the user
with a list of words cooccuring with the a
ws
. The
output is an ordered list of words, the order de-
pending on the overall score, i.e. number of cooc-
currences between the a
w
and the t
w
. For exam-
ple, if the a
ws
?wine? and ?harvest? co-occur with
the t
w
?bunch? respectively 5 and 8 times, then
the overall score of cooccurence of ?bunch? is 13:
((wine, harvest), bunch, 13). Hence, all words with
a higher score will precede it, while those with a
lower score will follow it.
5.3.5 Examples and Comparison of the
results of the two corpora
Here below are the examples extracted from the
WN corpus (see figure-1). Our goal was to find
the word ?vintage?. Trigger words are ?wine? and
?harvest?, yielding respectively 488 and 30 hits, i.e.
words. As one can see ?harvest? is a better ac-
cess term than ?wine?. Combining the two will re-
duce the list to 6 items. Please note that the t
w
?vintage? is not among them, eventhough it exists
in WordNet, which illustrates nicely the fact that
storage does not guarantee accessibility (Sinopal-
nikova and Smrz, 2006).
Looking at figure-1 you will see that the results
have improved considerably with Wikipedia. The
same input, ?wine? evokes many more words (1845
as opposed to 488). For ?harvest? we get 983 hits in-
Input WordNet Wikipedia
488 words 1845
words
grape sweet aloholic country
serve france god characteristics
wine small fruit regulation grape
dry bottle appellation system
produce red bottled like
bread hold christian track
. . . . . . . . . . . .
30 words 983 words
month fish produce grain
grape revolutionary autumn farms
calendar festival energy cut
harvest butterfish dollar combine ground
person make balance rain
wine first amount rich
. . . . . . . . . . . .
6 words 45 words
make grape grape vintage
wine fish someone bottle produce
+harvest commemorate person fermentation juice
. . . . . . Beaujolais taste
viticulture France
Bordeaux vineyard
. . . . . .
Figure 1: Comparing two corpora (eXtended
WordNet and Wikipedia) with various inputs
stead of 30 (the intersection containing 62 words).
Combining the two reduces the set to 45 items
among which we will find, of course, the target
word.
We hope that this example is clear enough to
convince the reader that it makes sense to use real
text as corpus to extract from it the kind of in-
formation (associations) people are likely to give
when looking for a word.
6 Conclusion and perspectives
We have addressed in this paper the problem of
word finding for speakers or writers. Conclud-
ing that most dictionaries are not well suited to al-
low for this kind of reverse access based on mean-
ings (or meaning related elements, associations),
we looked at work done by psychologists to get
some inspiration. Next we tried to clarify which
of these findings could help us build the dictionary
of tomorrow, that is, a tool integrating linguistic
and encyclopedic knowledge, allowing navigation
by taking either or as starting point. While lin-
guistic knowledge is more prominent for analysis
(reading), encyclopedic facts are more relevant for
production. We?ve presented then our ideas of how
to build a resource, allowing lexical access based
15
on underspecified, i.e. imperfect input. To achieve
this goal we?ve started building an AM composed
of form elements (the words and expressions of
a given language) and a
ws
. The role of the lat-
ter being to lead to or to evoke the t
w
. In the last
part we?ve described briefly the results obtained by
comparing two resources (WN and Wikipedia) and
various inputs. Given the fact that the project is
still quite young, only preliminary results can be
shown at this point.
Our next steps will be to take a closer look at the
following work: clustering of similar words (Lin,
1998), topic signatures (Lin and Hovy, 2000) and
Kilgariff?s sketch engine (Kilgarriff et al, 2004).
We plan also to add other lexical functions to en-
rich our database with a
ws
. We plan to experiment
with corpora, trying to find out which ones are best
for our purpose
15
and we will certainly experiment
with the window size
16
to see which size is best
for which text type. Finally, we plan to insert in
our AM the relations holding between the a
w
and
the t
w
. As these links are contained in our corpus,
we should be able to identify and type them. The
question is, to what extent this can be done auto-
matically.
Obviously, the success of our resource will de-
pend on the quality of the corpus, the quality of
the a
ws
, weights and links, and the representativ-
ity of all this for a given population. While we do
believe in the justification of our intuitions, more
work is needed to reveal the true potential of the
approach. The ultimate judge being, of course, the
future user.
15
For example, we could consider a resource like Con-
ceptNet of the Open Mind Common-Sense project (Liuh and
Singh, 2004).
16
For example, it would have been interesting to consider
coocurrences beyond the scope of the paragraph, by consider-
ing the logical structure of the Wikipedia document. Anyhow,
our experiment needs to be redone with more data than just
1000 pages, the size chosen here for lack of time. Indeed one
could consider using the entire corpus of Wikipedia or mixed
corpora
References
Aitchinson, Jean. 2003. Words in the Mind: an Intro-
duction to the Mental Lexicon (3d edition). Black-
well, Oxford.
Bilac, S., W. Watanabe, T. Hashimoto, T. Tokunaga,
and H. Tanaka. 2004. Dictionary search based
on the target word description. In Proc. of the
Tenth Annual Meeting of The Association for NLP
(NLP2004), pages 556?559, Tokyo, Japan.
Boissi`ere, P. 1862. Dictionnaire analogique de la
langue franc?aise : r?epertoire complet des mots par
les id?ees et des id?ees par les mots. Larousse et A.
Boyer, Paris.
Brown, R. and D. McNeill. 1996. The tip of the tounge
phenomenon. Journal of Verbal Learning and Ver-
bal Behaviour, 5:325?337.
Cutler, A, editor, 1982. Slips of the Tongue and Lan-
guage Production. Mouton, Amsterdam.
Deese, James. 1965. The structure of associations in
language and thought. Johns Hopkins Press.
Dong, Zhendong and Qiang Dong. 2006. HOWNET
and the computation of meaning. World Scientific,
London.
Dutoit, Dominique and P. Nugues. 2002. A lexical
network and an algorithm to find words from defini-
tions. In van Harmelen, F., editor, ECAI2002, Proc.
of the 15th European Conference on Artificial Intel-
ligence, pages 450?454, Lyon. IOS Press, Amster-
dam.
Fellbaum, Christiane, editor, 1998. WordNet: An Elec-
tronic Lexical Database and some of its Applica-
tions. MIT Press.
Ferret, Olivier and Michael Zock. 2006. Enhancing
electronic dictionaries with an index based on associ-
ations. In ACL ?06: Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
the 44th annual meeting of the ACL, pages 281?288.
Fontenelle, Thierry. 1997. Using a bilingual dictionary
to create semantic networks. International Journal
of Lexicography, 10(4):275?303.
Goddard, Cliff. 1998. Bad arguments against seman-
tic primitives. Theoretical Linguistics, 24(2-3):129?
156.
16
Gross, Maurice. 1984. Lexicon-grammar and the anal-
ysis of french. In Proc. of the 11th COLING, pages
275?282, Stanford, CA.
Harley, Trevor. 2004. The psychology of language.
Psychology Press, Taylor and Francis, Hove and
New York.
Jung, Carl and F. Riklin. 1906. Experimentelle
Untersuchungen ?uber Assoziationen Gesunder. In
Jung, C. G., editor, Diagnostische Assoziationsstu-
dien, pages 7?145. Barth, Leipzig, Germany.
Kilgarriff, Adam, Pavel Rychl?y, Pavel Smr?z, and David
Tugwell. 2004. The Sketch Engine. In Proceedings
of the Eleventh EURALEX International Congress,
pages 105?116, Lorient, France.
Levelt, Willem. 1996. A theory of lexical access
in speech production. In Proc. of the 16th Con-
ference on Computational Linguistics, Copenhagen,
Denmark.
Lin, Chin-Yew and Eduard H. Hovy. 2000. The auto-
mated acquisition of topic signatures for text summa-
rization. In COLING, pages 495?501. Morgan Kauf-
mann.
Lin, Dekang. 1998. Automatic retrieval and clustering
of similar words. In COLING-ACL, pages 768?774,
Montreal.
Liuh, H. and P. Singh. 2004. ConceptNet: a practi-
cal commonsense reasoning toolkit. BT Technology
Journal.
Mel??cuk, I., N. Arbatchewsky-Jumarie, L. Iordanskaja,
S. Mantha, and A. Polgu`ere. 1999. Dictionnaire
explicatif et combinatoire du franc?ais contemporain
Recherches lexico-s?emantiques IV. Les Presses de
l?Universit?e de Montr?eal, Montr?eal.
Mel??cuk, Igor. 1996. Lexical functions: A tool for
the description of lexical relations in the lexicon. In
Wanner, L., editor, Lexical Functions in Lexicogra-
phy and Natural Language Processing, pages 37?
102. Benjamins, Amsterdam/Philadelphia.
Mihalcea, Rada and Dan Moldovan. 2001. Extended
WordNet: progress report. In NAACL 2001 - Work-
shop on WordNet and Other Lexical Resources, Pitts-
burgh, USA.
Miller, G. A., R. Beckwith, C. Fellbaum, D. Gross, and
K. Miller. 1990. Introduction to WordNet: An on-
line lexical database. International Journal of Lexi-
cography, 3(4), pages 235?244.
Moerdijk, Fons. 2008. Frames and semagrams; Mean-
ing description in the general dutch dictionary. In
Proceedings of the Thirteenth Euralex International
Congress, EURALEX, Barcelona.
Polgu`ere, Alain. 2006. Structural properties of lexi-
cal systems: Monolingual and multilingual perspec-
tives. Sidney. Coling workshop ?Multilingual Lan-
guage Resources and Interoperability?.
Richardson, S., W. Dolan, and L. Vanderwende. 1998.
Mindnet: Acquiring and structuring semantic infor-
mation from text. In ACL-COLING?98, pages 1098?
1102.
Robert, Paul, Alain Rey, and J. Rey-Debove. 1993.
Dictionnaire alphabetique et analogique de la
Langue Franc?aise. Le Robert, Paris.
Roget, P. 1852. Thesaurus of English Words and
Phrases. Longman, London.
Schvaneveldt, R., editor, 1989. Pathfinder Associa-
tive Networks: studies in knowledge organization.
Ablex, Norwood, New Jersey, US.
Schwab, Didier and Mathieu Lafourcade. 2007. Mod-
elling, detection and exploitation of lexical functions
for analysis. ECTI Transactions Journal on Com-
puter and Information Technology, 2(2):97?108.
Sierra, Gerardo. 2000. The onomasiological dictio-
nary: a gap in lexicography. In Proceedings of the
Ninth Euralex International Congress, pages 223?
235, IMS, Universit?at Stuttgart.
Sinopalnikova, Anna and Pavel Smrz. 2006. Knowing
a word vs. accessing a word: Wordnet and word as-
sociation norms as interfaces to electronic dictionar-
ies. In Proceedings of the Third International Word-
Net Conference, pages 265?272, Korea.
Summers, Della. 1993. Language Activator: the
world?s first production dictionary. Longman, Lon-
don.
T?ong, Ting-K?u. 1862. Ying ?u tsap ts??un (The Chinese
and English Instructor). Canton.
Wierzbicka, Anna. 1996. Semantics: Primes and Uni-
versals. Oxford University Press, Oxford.
Wilks, Yorick. 1977. Good and bad arguments about
semantic primitives. Communication and Cognition,
10(3?4):181?221.
Zock, Michael and Slaven Bilac. 2004. Word lookup
on the basis of associations : from an idea to a
roadmap. In Workshop on ?Enhancing and using
electronic dictionaries?, pages 29?35, Geneva. COL-
ING.
Zock, Michael. 2006. Navigational aids, a critical
factor for the success of electronic dictionaries. In
Rapp, Reinhard, P. Sedlmeier, and G. Zunker-Rapp,
editors, Perspectives on Cognition: A Festschrift for
Manfred Wettler, pages 397?414. Pabst Science Pub-
lishers, Lengerich.
Zock, Michael. 2007. If you care to find what you
are looking for, make an index: the case of lexical
access. ECTI, Transaction on Computer and Infor-
mation Technology, 2(2):71?80.
17
Coling 2008: Proceedings of the workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), pages 77?85
Manchester, August 2008
Looking up phrase rephrasings via a pivot language
Aure?lien Max
LIMSI-CNRS & Universite? Paris-Sud 11
Orsay, France
aurelien.max@limsi.fr
Michael Zock
LIF-CNRS
Marseilles, France
michael.zock@lif.univ-mrs.fr
Abstract
Rephrasing text spans is a common task
when revising a text. However, traditional
dictionaries often cannot provide direct as-
sistance to writers in performing this task.
In this article, we describe an approach
to obtain a monolingual phrase lexicon
using techniques used in Statistical Ma-
chine Translation. A part to be rephrased
is first translated into a pivot language,
and then translated back into the origi-
nal language. Models for assessing flu-
ency, meaning preservation and lexical di-
vergence are used to rank possible rephras-
ings, and their relative weight can be tuned
by the user so as to better address her
needs. An evaluation shows that these
models can be used successfully to select
rephrasings that are likely to be useful to a
writer.
1 Introduction
Once an initial draft of a text is ready, writers face
the difficult phase of text revision. Changes may
be made for various reasons: correcting spelling or
grammatical errors, making the text locally more
fluent (for example, in case it contains wordings
that are literal translations from another language),
avoiding close repetitions or enforcing terminolog-
ical consistency, or better conveying the writer?s
ideas. All these changes can affect text spans of
various sizes, and can globally be seen as cases
of rephrasing. Paraphrasing involves rephrasings
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
that are semantically equivalent, but targets termi-
nology and style that are more suited to the con-
text of use of a text. In a broad sense, rephrasing
may involve wordings that convey different mean-
ings in an attempt to correct or make the writer?s
thoughts more precise. Research concerned with
the study of changes between writers? drafts (tex-
tual genetic criticism) can help in understanding
writers? rewriting processes, and can be supported
by automatic tools (e.g. (Bourdaillet et al, 2007)).
In this work, we address the issue of how writ-
ers can be assisted in finding wordings that corre-
spond to multi-word phrases of any nature. Given
an original text span, the writer is presented with
a list of rephrasings that are organized by taking
into account the context of the rephrasing and user-
specified preferences. Our proposal can therefore
be used as a lexicon operating at the phrasal level,
which can be used either when writers are faced
with a tip-of-the-tongue lexical access problem, or
when they are not completely satisfied with some
initial wording. In the former case, they may be
able to come up with some words or phrases that
would be different in meaning from what they are
looking for, and in the latter they may be looking
for a near-synonymous wording that is more ap-
propriate to a given context, for example to avoid
close repetitions. To define such a phrase lexi-
con and its possible mode of use, the following
questions should be considered: (a) how the lex-
icon entries are obtained, (b) what can be the entry
points and how can one navigate in the results, and
(c) how the results are displayed.
Rephrasing can be more or less complex and
problematic depending on the consequences at the
various levels:
? In the simplest case, replacing one element
77
by another does not have any consequences
overall. This is often the case when a word is
replaced by its synonym or a similar word.
? An entire expression or sentence is replaced
by its equivalent. In this case the problem is
generally to obtain a good fit with regard to
the surrounding text, the replacing unit being
well-formed by definition.
? The replacing element may require syntactic
changes of the matrix, i.e. the text in which it
is embedded. This occurs if the source word
and the target word have different syntactic
requirements, and this can be seen as a good
reason to replace entire sentences, or at least
sentence fragments. This assumes a pattern
dictionary, where patterns achieving the same
conceptual goal are grouped together.
In the next section, we discuss limitations of tra-
ditional dictionaries with respect to the targeted
task, and describe an approach to obtain phrase
rephrasings through a pivot translation into another
language. In section 3, we discuss the issue of the
organization of the results along various axis: flu-
ency of rephrasings, preservation of meaning, and
lexical divergence between original text spans and
rephrasings. We then present an initial evaluation
of our approach on French rephrasing in section 4.
Related work is presented in section 5, and we fi-
nally discuss our approach and our future work in
section 6.
2 Lexicon of phrase rephrasings
Dictionaries and semantic resources such as the-
sauri can be used to find words by following links
of different kinds from a given entry point. Word-
Net (Fellbaum, 1998) is one such resource. For a
proposal of other kinds of links and navigational
aids see also (Zock and Bilac, 2004; Zock, 2006;
Zock, 2007).
Words are the traditional units that people ex-
pect to find in dictionaries. Whereas some types
of dictionaries can contain multiword expressions,
such as compound nouns and terms, those corre-
spond to linguistically-motivated units. In order
to rephrase phrases of any type with a dictionary, a
writer may have to look up several words, combine
various information and validate the result using
her experience of the language or throught the use
of a concordancer. Moreover, dictionary lookups
are in most cases insensitive to the actual context
of words in an existing text. It is therefore the re-
sponsibility of its users to ensure that a choice is
appropriate for a given context, which can be quite
difficult, for example when writing in a second lan-
guage.
One way of obtaining phrase rephrasings is by
looking at phrases that occur in similar contexts
in a monolingual corpus (e.g. (Munteanu and
Marcu, 2006)). In order to extract a comprehensive
phrase lexicon, a very large number of sentences
should be compared to extract potential rephras-
ings, which furthermore may often correspond to
phrases that are too remotely connected. Parallel
corpora provide the interesting advantage that it is
reasonable to assume that elements from one side
of the corpus should be aligned to elements on the
other side, and that associations of elements can be
reinforced by the number of times they occur in the
corpus. Various approaches for word alignment
from parallel corpora have been proposed (see e.g.
(Och and Ney, 2003)), and the phrase-based ap-
proach to Statistical Machine Translation (Koehn
et al, 2003) has led to the development of heuris-
tics for obtaining alignments between phrases of
any number of words.
Unfortunately, monolingual parallel corpora
aligned at the sentence level, such as various trans-
lations of a novel in a foreign language, are re-
sources that are extremely scarce. Using bilingual
parallel corpora, a much more common resource,
one can obtain various possible phrase translations
for a given source phrase, as well as some estimate
of the distribution of probabilities for the various
translations of that phrase. Such N ? M aligne-
ments can capture lexical translations (e.g. exi-
geons ? ask for, call for, demand, expect, request,
etc.) and phrasal literal or idiomatic translations
(e.g. un bon de?but ? a good approach, a good
first move, a good starting point, a positive initia-
tive, an encouraging start, the right road, etc.), but
can also capture noise depending on the alignment
heuristics used (e.g. les e?tats candidats (candi-
date countries) ? Member States, the candidate
countries were to, the accession countries have
called for, candidate, the, etc.) Different target
phrases associated with a given source phrase can
either represent paraphrases or phrases with differ-
ent meanings. Among the limitations of this type
of phrasal alignments are their inability to model
non-consecutive words and to generalize the con-
78
tents of phrases, and the fact that their translations
are not conditioned on their context.
If phrase extraction is performed in two oppo-
site directions, then it is possible to find the pos-
sible translations of a given phrase (and their con-
ditional probabilities), and then to translate back
those phrases into the original language. In this ap-
proach proposed by (Bannard and Callison-Burch,
2005), the second language acts as a pivot, as il-
lustrated on figure 1. Because of the nature of the
possible alignments, this pivot can represent vari-
ous senses, which in context can be equivalent or
comparable to that of the original phrase. In turn,
the same phenomena can take place when translat-
ing back from the pivot phrases to the original lan-
guage, and the resulting rephrasings can be equiv-
alent or comparable in meaning to that of the orig-
inal phrase in some context, may also be incom-
plete and/or require other changes in the rephrased
sentence.
Bannard and Callison-Burch have defined a
paraphrase probability between two phrases p
1
and p
2
(with p
1
6= p
2
) that uses conditional proba-
bilities between phrases and sums over all possible
pivot phrases:
P (p
2
|p
1
) = argmax
p
2
6=p
1
?
pivot
P (pivot|p
1
)P (p
2
|pivot)
(1)
(Callison-Burch, 2007) measured the impor-
tance of various factors impacting the quality of
the paraphrases obtained. Using manually built
alignments yields a significant improvement in
paraphrase quality, showing that if better align-
ments are available the proposed approach can
produce better paraphrases. Alignments between
several languages can be used for finding pivot
phrases, and using several simulateously tend to
improve alignment quality and therefore para-
phrases themselves. Using a language model to
find paraphrases that maximize its score in the
original sentencial context leads to improved flu-
ency, but has a negative impact on meaning preser-
vation. Lastly, restricting pivot phrases to those
actually aligned in a test aligned bilingual corpus
improves paraphrase quality, which illustrates the
importance of disambiguating source phrases rela-
tively to the pivot language.
The rephrasings obtained can be classified into
several categories when used in context:
? A rephrasing can be a paraphrase that is valid
in all contexts (e.g. je vous donne raison ?
je suis d?accord avec vous), in specific gram-
matical contexts (e.g. pouvoir accueillir dans
de bonnes conditions les pays ? comme il se
doit) and/or pragmatic contexts (e.g. c?est un
bon de?but ? nous partons du bon pied).
? A rephrasing can contain shifts in meaning
with the original phrase which might be ac-
ceptable or not (e.g. nous voulons apporter
notre contribution a` ce de?bat ? donner de
la valeur). Some such rephrasings reveal a
natural bias towards the bilingual corpus used
(e.g. le prochain e?largissement constitue la
principale ta?che ? l? objectif principal).
? A rephrasing can be ill-formed but still con-
tain elements of interest to a writer (e.g. ceux
qui disent que . . . se trompent ? devrions
a` nouveau re?fle?chir; here a rephrasing such
as devraient a` nouveau re?fle?chir could be
deemed acceptable in some contexts).
? A rephrasing may introduce a contradiction
in a specific context (e.g. ce n?est pas le mo-
ment de se montrer he?sitant ? il est trop to?t
pour)
? A rephrasing may be inexploitable because it
is syntactically ill-formed in context and does
not contain any element of interest, or is too
close to the original phrase.
The most natural entry point to such a resource
is by entering a phrase or selecting it in a text under
revision. Approximate search can also be of use,
as done in some concordancer software, for exam-
ple by allowing the user to enter word-based reg-
ular expressions mixing literal words, word lem-
mas, word part-of-speech or even word classes
(e.g. types of named entities). Boolean queries
on indexes of word lemmas can also be used to of-
fer yet more flexibility to search the lexicon, but at
the cost of more candidate results. Once results are
returned, they can recursively be reused as source
phrases, so as to offer a means to navigate by iter-
ative refining.
3 Evaluation of rephrasings in context
for ranking results
Each candidate phrase rephrasing for a given
phrase must be evaluated in order to define a rank-
ing order for presentation to the user, and possibly
79
Figure 1: Example of rephrasing for the French phrase ce n?est pas le moment de using English as pivot.
to discard some of them. The proposed ranking
should reflect as best as possible the preferences of
the user for the task at hand in order to minimize
reading time and maintain the user?s interest in us-
ing the phrase lexicon. It is essential to give the
user some control over how the results are returned
depending on what is more important to her. For
example, (Ferret and Zock, 2006) have proposed
to present results from a dictionary enriched with
topical associations in chunks to allow for catego-
rial search. There will be cases where the user may
find acceptable only grammatical results, while in
other cases the user might accept agrammatical re-
sults provided they contain interesting suggestions.
Moreover, it seems extremely important that result
ranking can take into account the phrase substitu-
tion into the original context.
Considering how the proposed phrase lexicon is
built, the pivot paraphrasing probability of equa-
tion 1 (PIV) can be used as a baseline ordering.
Such a model reflects some strength of association
between a rephrased phrase and the original phrase
using the extracted phrases and conditional prob-
abilities derived from a bilingual training corpus.
It is therefore expected that results will be biased
towards that corpus if the latter belongs to a partic-
ular genre or theme. Nonetheless, one can expect
that some associations will be general enough to
be of general interest.
In addition, several models that users can in-
terpret as ranking criterion can be used simulate-
neously using the log-linear framework tradition-
ally used in SMT systems. However, contrary to
what is done in SMT, the weight of the models
cannot be automatically optimized if we do not use
an automatic evaluation of rephrasing quality, the
definition of which depending heavily on the sub-
jective appreciation of a user. Equation 2 shows
how the score of a rephrasing p
2
of p
1
can be com-
puted, where M is the set of models used, h
m
is
the logarithm of the normalized score of a model
and ?
m
its weight (with?
m?M
?
m
= 1), and C
is the original sentence and the placeholder for the
rephrased phrase.
s(p
2
, p
1
, C) =
?
m?M
?
m
h
m
(p
1
, p
2
, C) (2)
3.1 Control over fluency
As noted by (Mutton et al, 2007), the notion of
sentence-level fluency is not uniformely agreed
upon, and its evaluation by human judges is some-
times found subjective, but in practice judges can
obtain high levels of agreement about what can
be considered fluent or not. Like (Callison-Burch,
2007), we can use a language model (LM) to as-
sess the local fluency of a sentence after a phrase
has been substituted with a rephrasing. A degra-
dation in score (with a fluent original sentence)
can indicate that the rephrasing segment should be
adapted to the sentence, and/or that the sentence
itself should be modified in order to integrate the
new phrase as is.
Syntax parsers can produce various information
that can be relevant for assessing the fluency of
sentences, which can be used as features from dif-
ferent parsers for classification that can correlate
well with human judgment (Mutton et al, 2007).
When substituting a part of a sentence with an-
other phrase and if this substitution does not re-
quire other changes in the sentence, then at least
the dependency relationships between words out-
side that phrase should be preserved. This seems
coherent with our objective of focussing on the
task of phrase rephrasing when it is possible to
modify only a given phrase and obtain an accept-
able result.
80
3.2 Control over meaning preservation
The preservation of dependency relationships out-
side of the rephrased phrase can also play a role
in terms of meaning preservation. Dependency
relationships connecting words in the phrase and
words outside the phrase (i.e., whose governor is
outside the phrase and dependant inside it, or the
opposite) should still exist after such a substitution,
but possibly with a modified dependency target in
the phrase. Indeed, those relationships denote the
grammatical role of the words of the phrase rela-
tive to their context, and if those are preserved then
it is more likely that meaning is preserved.
We use a model based on dependency preser-
vation (DEP) which involves relationships outside
the rephrased phrase and relationships crossing
a boundary of that phrase. The score is based
on some proportion of the number of such de-
pendencies found after substitution over the num-
ber of original dependencies (see (Max, 2008) for
details). Another way of controlling for mean-
ing preservation is to ensure that only the pivot
phrases with the same meaning as the original
phrase are kept (and then their back translations).
(Callison-Burch, 2007) has shown the positive im-
pact on paraphrase quality of using a controlled
pivot present in an aligned sentence in a test bilin-
gual corpora. Phrase disambiguation techniques
have been proposed for SMT and could be applied
to the problem at hand (e.g. (Stroppa et al, 2007)).
In an interactive context, it makes sense to let the
user the opportunity to control for phrase sense by
rejecting bad pivot phrases if she wants to, which
is then similar to Callison-Burch?s experiment set-
tings. This manual selection must of course be op-
tional, but can be used when a user prefers a stricter
control on meaning. Another possibly interesting
use is to disambiguate in a pivot language corre-
sponding to one?s native language when writing in
a foreign language.
3.3 Control over lexical divergence
There will be cases when possible rephrasings will
be very close to their original phrase, differing
for example by only punctuation marks or verbal
forms1. Writers may sometimes prefer rephras-
ings that differ by just one word, or on the con-
trary rephrasings that use a set of completely dif-
ferent words. To account for differents words be-
1This is particularly the case when aligning between low
and highly inflected languages.
Figure 2: Bilingual phrase lexicon statistics
tween an original phrase and its rephrasing, we use
a model (LEM) that returns a proportion of lem-
mas for full words that only belong to a rephrasing
over all such lemmas for an initial phrase and its
rephrasing (see (Max, 2008)).
4 Experiments and evaluation
We carried out an evaluation on the local rephras-
ing of French sentences, using English as the
pivot language.2 We extracted phrase align-
ments of up to 7 word forms using the Giza++
alignment tool (Och and Ney, 2003) and the
grow-diag-final-and heuristics described
in (Koehn et al, 2003) on 948,507 sentences
of the French-English part of the Europarl cor-
pus (Koehn, 2005) and obtained some 42 million
phrase pairs for which probabilities were estimated
using maximum likelihood estimation. Statistics
for the extracted lexicons are reported on figure 2.
Entries of the monolingual phrase lexicon are built
dynamically from the entries of the monolingual
lexicons.
For the LM model, we used a 5-gram language
model trained on the French part of the corpus us-
ing Kneser-Ney smoothing. The robust parser for
French SYNTEX (Bourigault et al, 2005) was used
to obtain lemmas for word and labeled dependency
relationships between words, used respectively for
the LEM and DEP models. Robust parsers provide
the advantage that they can provide partial analysis
for correct chunks in agrammatical sentences, but
they can also recover information from agrammat-
ical chunks which can be undesirable in this case.3
A test corpus of 82 sentences that were not used
for extracting phrase alignments and learning the
2The main motivation for this choice was that we could
easily have access to French native speakers for manual eval-
uation. We plan however to start new experiments using En-
glish, as well as experiments using another highly inflected
language as pivot such as Spanish.
3We intend to use several parsers for English implement-
ing different approaches as in (Mutton et al, 2007), but we
had access to only one parser for French.
81
language model was built. A human judge selected
one phrase of length 3 words or more per sen-
tence that would be a good candidate for rephras-
ing, and which was accepted if it belonged to the
French-English lexicon4. We kept at most the 20
first rephrasings obtained using the baseline PIV
model, and asked two French native speakers to
evaluate on a 5-level scale each the 1648 refor-
mulated sentences obtained on fluency, meaning
preservation, and authoring value, where the lat-
ter was described in the following way: (5) the
rephrasing can be directly reused for revising a
text, (4) the rephrasing can be used with a mi-
nor change, (3) the rephrasing contains elements
that could be used for a good rephrasing, (2) the
rephrasing contains elements that could suggest a
rephrasing, and (1) the rephrasing is useless.
After the judges had completed manual annota-
tion, smoothing of the scores was done by keep-
ing mean scores for each sentence. We measured
a value of 0.59 standard deviation for score differ-
ences between judges for grammaticality, 0.7 for
meaning preservation and 0.8 for authoring value.
Those values can indicate a growing difficulty in
judging those characteristics, and in particular that
judging authoring value on the proposed scale is
more dependant on personal judgment. Results of
mean scores for the first rank solutions with vari-
ous model combinations with uniform weights are
reported on figure 3, and results for mean author-
ing value scores depending on the number of top
results presented to the user are reported on fig-
ure 4.
Authoring value scores are lower, which can be
explained by the fact that rephrasings with bad
fluency and/or meaning preservation scores will
penalize authoring value scores according to our
scale. The best results are obtained when combin-
ing all models, which remains true when consider-
ing mean results up to at least 8 rephrasings.
The baseline PIV model seems to have the most
impact, but all other models also contribute in
different ways. This suggests that which model
should be used (or its weight in our framework)
could be chosen by a user. In the following ex-
ample, the LEM model helped select a rephrasing
which obtained good scores:
Original sentence: ce que je vous propose donc,
4This is a limitation of our evaluation, as our annotator
was not strictly speaking revising a text that she wrote. We
hope to be able to conduct task-based experiments in the fu-
ture.
fluency meaning authoring
PIV (baseline) 4.46 4.18 3.62
LM 4.28 3.62 3.45
DEP 4.35 3.68 3.43
LEM 4.05 3.21 3.28
PIV+LM 4.65 4.06 3.82
PIV+DEP 4.58 4.27 3.66
PIV+LEM 4.37 4.00 3.76
LM+DEP 4.49 3.81 3.68
LM+LEM 4.28 3.59 3.56
PIV+LM+DEP 4.65 4.05 3.92
PIV+LM+LEM 4.61 4.02 3.97
PIV+DEP+LEM 4.57 4.17 4.02
LM+DEP+LEM 4.37 3.69 3.64
PIV+LM+DEP+LEM 4.68 4.09 4.05
Figure 3: Mean results at first rank for various
model combinations (uniform weighting)
Figure 4: Mean authoring value scores depending
on the number of results presented to the user
c?est de travailler dans cette direction ... (what I
therefore propose is to work towards this . . .)
Rephrased sentence: ce que je vous pro-
pose donc, c?est de coope?rer dans ce sens ...
(work towards this goal . . .)
Figures 5 and 6 show two examples of rephras-
ings in French, whereby for each rephrasing the
ranks given by PIV, LM and the combination of
all mentioned models are shown.
5 Related work
While the traditional view of lexicons is word-
based, we may as well consider larger units, in-
cluding sentences. Corpus Pattern Analysis (CPA)
(Hanks and Pustejovsky, 2005) is concerned with
the prototypical syntagmatic patterns with which
words in use are associated. For example, the
meaning of take place is different from the mean-
82
Rephrasings Ranks given by model(s)
PIV LM PIV+LM+DEP+LEM
quelques points essentiels 1 3 1
les points essentiels 19 1 2
plusieurs questions importantes 17 4 3
des points essentiels 8 6 4
deux ou trois questions importantes 5 9 5
plusieurs points importants 11 2 5
un certain nombre de questions importantes 17 7 7
certains points importants 2 5 8
un certain nombre de points importants 3 8 9
certains e?le?ments tre`s importants 13 11 10
une se?rie de points importants 4 12 11
quelques accents importants 5 15 11
des choses extre?mement importantes 13 14 11
quelques remarques importantes , 8 16 14
des points importants 12 10 15
quelques choses tre`s importantes 13 17 16
certains points importants , 8 13 17
quelques points essentiels sur 20 18 17
de certains e?le?ments tre`s importants 13 19 19
placer quelques accents importants 5 20 20
Figure 5: Examples of rephrasings for the phrase quelques points importants in je voudrais mentionner
quelques points importants de la directive
Rephrasings Ranks given by model(s)
PIV LM PIV+LM+DEP+LEM
vous avez raison 1 1 1
je suis d? accord avec vous 2 2 2
je suis d? accord 3 6 3
je conviens avec vous 6 5 4
je partage votre avis 7 4 5
vous avez raison de dire 10 3 5
je pense comme vous 7 8 7
je suis parfaitement d? accord avec vous 12 7 8
je partage votre point de vue 12 9 9
je vous rejoins 7 10 10
, je vous donne raison 3 12 11
la` , je vous donne raison 3 13 12
tu as raison 16 11 12
vous avez raison de 10 14 14
je partage votre point 12 15 15
je partage votre point de 12 16 16
Figure 6: Examples of rephrasings for the phrase je vous donne raison in a` cet e?gard bien pre?cis , je vous
donne raison , monsieur le commissaire
83
ing of take his place, due to the possessive deter-
miner. The actual meaning of words depends on
the context in which they are used. The work done
by the team of Gross on lexicon-grammar (e.g.
(Gross, 1984)) showed that a relatively small set of
clause patterns and syntactic constraints suffices to
cover most of common French.
Comparable monolingual corpora have been
used for automatic paraphrasing. Barzilay and
Lee (Barzilay and Lee, 2003) learned paraphras-
ing patterns as pairs of word lattices, which are
then used to produce sentence level paraphrases.
Their corpus contained news agency articles on the
same events, which allows precise sentence para-
phrasing, but on a small sets of phenomena and
for a limited domain. As sentential paraphras-
ing is more likely to alter meaning, Quirk et al
(Quirk et al, 2004) approached paraphrasing as
a monotonous decoding by a phrase-based SMT
system. Their corpus consisted of monolingual
sentences extracted from a comparable corpus that
were automatically aligned so as to allow aligned
phrase extraction. Pang et al (Pang et al, 2003)
used parallel monolingual corpora built from news
stories that had been independantly translated sev-
eral times to learn lattices from a syntax-based
alignment process.
Bannard and Callison-Burch (Bannard and
Callison-Burch, 2005) proposed to use pivot trans-
lation for paraphrasing phrases. Fujita (Fujita,
2005) proposed a transfer-and-revision framework
using linguistic knowledge for generating para-
phrases in Japanese and a model for error detec-
tion. At the lexical level, a recent evaluation on En-
glish lexical substitution was held (McCarthy and
Navigli, 2007) in which systems had to find lexical
synonyms and disambiguate the context.
6 Discussion and future work
In this article, we have presented an approach for
obtaining rephrasings for short text spans from par-
allel bilingual corpora. These rephrasings can be
ranked according to user-defined preferences, and
the weights of the models used can be dynamically
adjusted by a user depending on what features are
more important to her, for instance after an initial
list of candidates has been proposed by the sys-
tem. Indeed, good candidates include paraphrases,
but also more generally phrases that could help a
writer revise a text with some shifts in meaning,
even if at the cost of some corrections to make the
resulting text grammatical. Furthermore, search
for rephrasings can be iteratively performed using
candidate rephrasings as source phrases, and the
user can have some fine-grained control if select-
ing or rejecting possible pivot phrases manually.
Possible user interfaces to this proposed bilingual
phrase lexicon could include rephrasing memory
features to learn from interaction with the user, and
concordancing features to display the context of
use in the bilingual corpus of the segments used to
build the relevant lexicon entries. In the latter case,
the similarity used to select examples could take
the context of the phrases into account in terms of
dependency relationships.
There are several open issues to the presented
work. Important issues are where the phrases
can come from and the bias introduced by the re-
source used. Using a bilingual corpora such as
the Europarl corpus with this pivot approach yields
both generic and domain/genre-specific rephras-
ings, and it is important to be able to determine
their appropriate context of use. It would also
be interesting to investigate enriching this frame-
work with phrases learnt from monolingual cor-
pora from a given domain or genre, and to use fea-
tures from the current text under revision. More
generally, we would need to get some idea of the
degree of possible reuse of a given rephrasing.
Another important group of issues concerns lim-
itations due to the nature of phrases for the task
at hand. As we have said, phrases as units of
rephrasing are limited because they cannot model
non-consecutive words and because of the rigidity
of their content. Various types of entry points to
the rephrasing lexicon such as using word-based
regular expressions can in some way alleviate this
problem, but work could be done on the lexicon
itself. As shown by Callison-Burch (Callison-
Burch, 2007), much can be gained by using bet-
ter alignments. Alignments techniques using syn-
tactic information could eliminate weak rephras-
ing candidates (i.e. increase in overall precision),
but interesting phrasal alignments could be lost as
well (decrease in overall recall). Furthermore, in-
formation from the context of alignments could
also be used to disambiguate the source phrase and
get only pivot phrases that are compatible with the
context of a given rephrasing, in similar ways as
recently done for SMT (Stroppa et al, 2007).
84
References
Bannard, Colin and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Proceed-
ings of ACL, Ann Arbor, USA.
Barzilay, Regina and Lillian Lee. 2003. Learn-
ing to paraphrase: an unsupervised approach us-
ing multiple-sequence alignment. In Proceedings of
NAACL/HLT, Edmonton, Canada.
Bourdaillet, Julien, Jean-Gabriel Ganascia, and Ire`ne
Fenoglio. 2007. Machine assisted study of writ-
ers? rewriting processes. In Proceedings of NLPCS,
poster session, Madeire, Portugal.
Bourigault, Didier, Ce?cile Fabre, Ce?cile Frrot, Marie-
Paule Jacques, and Sylvia Ozdowska. 2005. Syntex,
analyseur syntaxique de corpus. In Proceedings of
TALN, Dourdan, France.
Callison-Burch, Chris. 2007. Paraphrasing and Trans-
lation. Ph.D. thesis, University of Edinburgh.
Fellbaum, Christiane, editor, 1998. WordNet: An Elec-
tronic Lexical Database and some of its Applica-
tions. MIT Press.
Ferret, Olivier and Michael Zock. 2006. Enhancing
electronic dictionaries with an index based on asso-
ciations. In Proceedings of COLING/ACL, Sydney,
Australia.
Fujita, Atsushi. 2005. Automatic Generation of Syn-
tactically Well-formed and Semantically Appropriate
Paraphrases. Ph.D. thesis, Nara Institute of Science
and Technology.
Gross, Maurice. 1984. Lexicon-grammar and the anal-
ysis of french. In Proc. of the 11th COLING, pages
275?282, Stanford, CA.
Hanks, Patrick and James Pustejovsky. 2005. A pattern
dictionary for natural language processing. Revue
Franc?aise de linguistique applique?e, 10(2):63?82.
Koehn, Philipp, Franz Josef Och, , and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of NAACL/HLT, Edmonton, Canada.
Koehn, Philipp. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of MT
Summit, Phuket, Thailand.
Max, Aure?lien. 2008. Local rephrasing suggestions for
supporting the work of writers. In Proceedings of
GoTAL, Gothenburg, Sweden.
McCarthy, Diana and Roberto Navigli. 2007. Semeval-
2007 task 10: English lexical substitution task. In
Proceedings of the Semeval-2007 Workshop at ACL,
Prague, Czech Republic.
Munteanu, Dragos S. and Daniel Marcu. 2006. Ex-
tracting parallel sub-sentential fragments from non-
parallel corpora. In Proceedings of COLING/ACL
2006, Sydney, Australia.
Mutton, Andrew, Mark Dras, Stephen Wan, and Robert
Dale. 2007. GLEU : Automatic evaluation of
sentence-level fluency. In Proceedings of ACL,
Prague, Czech Republic.
Och, Franz Josef and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Pang, Bo, Kevin Knight, and Daniel Marcu. 2003.
Syntax-based alignment of multiple translations: Ex-
tracting paraphrases and generating new sentences.
In Proceedings of NAACL/HLT, Edmonton, Canada.
Quirk, Chris, Chris Brockett, and William B. Dolan.
2004. Monolingual machine translation for para-
phrase generation. In Proceedings of EMNLP,
Barcelona, Spain.
Stroppa, Nicolas, Antal van den Bosch, and Andy Way.
2007. Exploiting source similarity for smt using
context-informed features. In Proceedings of TMI,
Skvde, Sweden.
Zock, Michael and Slaven Bilac. 2004. Word lookup
on the basis of associations : from an idea to a
roadmap. In Workshop on ?Enhancing and using
electronic dictionaries?, pages 29?35, Geneva. COL-
ING.
Zock, Michael. 2006. Navigational aids, a critical
factor for the success of electronic dictionaries. In
Rapp, Reinhard, P. Sedlmeier, and G. Zunker-Rapp,
editors, Perspectives on Cognition: A Festschrift for
Manfred Wettler, pages 397?414. Pabst Science Pub-
lishers, Lengerich.
Zock, Michael. 2007. If you care to find what you
are looking for, make an index: the case of lexical
access. ECTI, Transaction on Computer and Infor-
mation Technology, 2(2):71?80.
85
Proceedings of the 2nd Workshop on Cognitive Aspects of the Lexicon (CogALex 2010), pages 75?84,
Beijing, August 2010
Lexical Access, a Search-Problem
Michael Zock (1), Didier Schwab (2) and Nirina Rakotonanahary (2)
(1) LIF-CNRS, TALEP, 163, Avenue de Luminy
(2) LIG-GETALP, University of Grenoble
zock@free.fr, didier.schwab@imag.fr, damanidaddy@msn.com
Abstract
Our work is confined to word access,
that is, we present here our ideas of how to
improve electronic dictionaries in order to
help language producers (speaker/writer)
to find the word they are looking for. Our
approach is based on psychological find-
ings (representation, storage and access of
information in the human mind), observed
search strategies and typical navigational
behavior.
If one agrees with the idea that lex-
ical access (word finding) is basically a
search problem, then one may still want
to find out where and how to search.
While the space, i.e. the semantic map
in which search takes place is a resource
problem,? any of the following could be
used: dictionary, corpus, thesauraus, etc.
or a mix of them,? its exploration is typ-
ically a search problem. Important as it
may be, the building of a high quality re-
source is not the focus of this work, we
rely on an existing one, and while we
are concerned with its quality, we will be
mostly concerned here with search meth-
ods, in order to determine the best.
1 Problem: find the needle in a haystack
One of the most vexing problems in speaking or
writing is that one knows a given word, yet one
fails to access it when needed. This kind of search
failure, often referred to as dysnomia or Tip of the
Tongue-problem, occurs not only in communica-
tion, but also in other activities of everyday life.
Being basically a search problem it is likely to oc-
cur whenever we look for something that exists
in real world (objects) or our mind: dates, phone
numbers, past events, peoples? names, or you just
name it.
As one can see, we are concerned here with the
problem of words, or rather, how to find them in
the place where they are stored: the human brain,
or an external resource, a dictionary. Our work
being confined to lexical access, we would like
to develp a semantic map and a compass to help
language producers to find the word they are look-
ing for. More precisely, we try to build an index
and a navigational tool allowing people to access
words no matter how incomplete their conceptual
input may be. Our approach is based on psy-
chological findings concerning the mental lexicon
(Aitchison, 2003; Levelt et al, 1999), i.e. storage
and access of information in the human mind, ob-
served search strategies and typical navigational
behavior.
2 Consider the following elements before
attempting an engineering solution
Before conceiving a roadmap leading to an en-
gineering solution it may be useful to consider
certain points. The list here below is by no
means complete, neither is the following discus-
sion. Nevertheless we believe that the following
points are worth consideration: features of the
mental lexicon, how to build and use the resource,
searching, ranking and weights, interface prob-
lems. For reasons of space constraints we will
touch briefly only upon some of these points.
Our main goal is the enhancement of electronic
dictionaries to help speakers or writers to find
75
quickly and intuitively the word they are looking.
To achieve this target we take inspiration in the
findings concerning the human brain (structure,
process) when it tries access words in the mental
lexicon.
2.1 The mental lexicon, a small-world
network?
While forms (lemma) and meanings (lexical con-
cepts, definitions) are stored side by side in pa-
per dictionaries (holistic presentation), the hu-
man brain stores them differently. The informa-
tion concerning meaning, forms and sound is dis-
tributed across various layers. Lexical fragmen-
tation or information distribution is supported by
many empirical findings,1 and while this fact is
arguably the reason accounting for word access
problems, it is probably also the explanation of
the power and the flexibility of the human mind
which generally manages to find in no time the
right term after having searched for it in a huge
store of words.
While it is still not entirely clear what is stored,
or whether anything is stored at all 2 coming close
to the kind of information generally found in dic-
tionaries, it does seem clear though that the struc-
ture of mental lexicon is a multidimensional net-
work in which the user navigates. ?Entries in the
lexicon are not islands; the lexicon has an inter-
nal structure. Items are connected or related in
various ways...There are item relations within and
between entries.? (Levelt, 1989). While the for-
mer relate meanings and forms: syntactic (part
of speech), morphological, phonological informa-
tion, the latter connect lexical entries.3 In sum,
1Speech errors (Fromkin, 1980), studies on aphasia (Dell
et al, 1997; Blanken et al, 2004) or response times i.e.
chronometric studies (Levelt et al, 1999), neuroimaging
(Shafto et al, 2007; Kikyo et al, 2001), eye movements,
(Roelofs, 2004), experiments on priming (Schvaneveldt et
al., 1976) or the tip of the tongue problem (TOT) (Brown
and McNeill, 1996).
2An important feature of the mental lexicon lies in the
fact that the entries are not accessed but activated (Marslen-
Wilson, 1990; Altmann, 1997). Of course, such a detail can
have far reaching consequences concerning knowledge rep-
resentation and use, i.e. structure and process.
3These are typically the kind of relations we can find in
WordNet (Fellbaum, 1998), which happens to be quite rich
in this respect, but relatively poor with regard to intrinsic, i.e.
intralexical information.
lexical networks store or encode the information
people typically have with regard to words, and
finding the needed information, amounts to enter
the graph at some point,? in the case of writing or
speaking, usually a node dedicated to meaning,?
and to follow the links until one has reached the
goal (target word). While computer scientists
call this kind of search ?navigation?, psychologists
prefer the term ?activation spreading. While not
being exactly the same, functionally speaking they
are equivalent though.
As every day language experience shows,
things may go wrong, we lack information, hence
we get blocked. Yet when trying to complete the
puzzle we do not start from scratch, we rely on
existing information, which, in terms of the net-
work metaphor means that we start from (infor-
mation underlying) a word being close to the tar-
get word.4
It is interesting to note, that our lexical graphs
seem to have similar characteristics as small-
world networks. These latter are a type of graph
in which most nodes, eventhough not being direct
neighbors, can be reached via a small number of
clicks, about 6, regardless of the starting point.
This property of networks, where objects, or the
nodes standing for them, are highly connected has
first been described by Frigyes Karinthy (1929)
a Hungarian writer, to be tested then many years
later by a social psychologist (Milgram, 1961).
Nodes can be anything, people, words, etc. If they
represent people, than edges specify their relation-
ship, i.e. the very fact that they know each other,
that they are friends, etc. Given this high connec-
tivity, anything seems to be at the distance of a few
mouse clicks. Hence, it is easy to connect peo-
ple or to find out who entertains with whom what
kind of relationship. Obviously, there is a strik-
ing similarity to our lexical graphs, and the small-
world feature has been tested by mathematicians,
who concluded that the distance for words is even
smaller than in the original Milgram experiments,
namely 4 rather than 6. Indeed, (Motter et al,
2002) and colleagues could show that more than
4As TOT experiments have shown (Brown and McNeill,
1996), people always know something concerning the target
word (meaning, form, relation to other words), hence finding
a word in such a situation amounts to puzzle-completion.
76
99 percent of the word pairs of their corpus could
be connected in 4 steps at the most.
2.2 Building the resource
There are two elements we need to get a clearer
picture of: the nature of the resource (semantic
map), and the search method i.e. the way to ex-
plore it. Concerning the resource, there are many
possible sources (dictionary, thesaurus, corpora,
or a mix of all this) and many ways of build-
ing it. Since our main goal is the building of
an index based on the notion of word relations
(triples composed of two terms and a link), the
two prime candidates are of course corpora and
association lists like the ones collected by psy-
chologists. While the former are raw data, con-
taining the information in a more or less hidden
form, the latter (often) contain the data explicitely,
but they are scarce, subject to change, and some of
the links are questionable.5
Corpora: Concerning the resource the follow-
ing points deserve consideration: size, representa-
tivity and topic sensitivity.
? Size or coverage: While size or coverage are
critical variables, they should not be overem-
phasized though, trading quantity against
quality. We need to define the meaning of
quality here, and whether, when or how lack
of quality can be (partially) compensated by
quantity. In other words, we need to define
thresholds. In the absence of clear guidelines
it is probably wise to strive for a good bal-
ance between the two, which again assumes
that we know what quality means.
? Representativity: Obviously, the system we
have in mind is only as good as the data we
use, i.e. the purity/accuracy and represen-
tativity of the word/feature-association lists.
5This flaw is due to the experimental protocol. Subjects
are asked to give the first word coming to their mind right
after a stimulas. Not having been asked to specify the link it
is the experimenter who does so. Yet, many word pairs,? say,
cat and dog,? allow for various links (love, tease, chase, etc.),
and it is not obvious at all which is the one intended by the
user. This problem could have been avoided to a large extent
if the instruction had been, ?build a sentence containing the
following word?. Another potential problem may be due to
the distance between the source and the target word: the link
may be mediated.
No single set of data (dictionary, corpus, the-
saurus) will ever suffice to capture the knowl-
edge people have. While it would be unreal-
istic to try to model the semantic map of ev-
eryone, it is not unreasonable to try to reach
an average user, say someone who has been
to school and is a computer literate. If we
want to capture the world-knowledge of this
kind of user (target), than we must beware
that it is contained in the material we use,
since our resource will be based on this data.
Hence, taking as corpus only the newspapers
read by an elite (say, Le Monde, in France),
will surely not suffice to capture the informa-
tion we need, as it will not relate information
ordinary citizens, say sport fans, are famil-
iar with or interested in. In sum, we need to
take a wide variety of sources to extract then
the needed information. While there is short-
age of some document types needed, there
are nevertheless quite a few sources one may
consider to begin with: Wikipedia, domain
taxonomies, topic signatures, (Lin and Hovy,
2000), a database like (http://openrdf.org),
etc.
? Topic sensitivity
Weights are important, but they tend to
change dynamically with time and the topic.
Think of the word ?piano? uttered in the con-
texts of a ?concert? or ?household moving?. It
is only in this latter case that this term evokes
ideas like size or weight. The dynamic re-
compution of weights as a function of topic
changes requires that the system be able to
recognize the topic changes, as otherwise it
might mislead the user by providing of in-
adequate weights. For some initial work see
(Ferret and Zock, 2006).
Association lists: Psychologists have built such
lists already decades ago (Deese, 1965; Schvan-
eveldt, 1989). Similar lists are nowadays freely
available on the web. For example, for English
there is the Edinburgh Associative Thesaurus 6
and the compilation done by Nelson and his col-
leagues in Florida 7. There are also some re-
6http://www.eat.rl.ac.uk/
7http://cyber.acomp.usf.edu/FreeAssociation/
77
sources for German (see 8 or 9), for Japanese,10
and probably many other languages.
While association lists are generally built man-
ually, one can also try to do so automatically or
with the help of people (see section 5 in (Zock
and Bilac, 2004)). JeuxdeMot (JdM), a collec-
tively built resource focusing on French being an
example in case.11
2.3 Searching
The goal of searching is more complex than one
might think. Of course, ultimately one should find
the object one is looking for,12 but the very pro-
cess should also be carried out quickly and natu-
rally. In addition we want to allow for recovery in
case of having taken the wrong turn, and we want
to avoid looping, that is, walking in circles, with-
out ever getting closer to the goal. Last, but not
least we want to make sure that stored informa-
tion can also be accessed.
That this is less obvious than it might seem at
first sight has been shown by (Zock and Schwab,
2008). Taking two resources (WN and Wikipedia)
that contain both a given target word, we wanted
to see whether we could access it or not. The
target word was ?vintage?. In order to find it we
provided two access keys, i.e. trigger words:
?wine? and ?harvest?. Combining the two produced
a list of 6 items in the case of WN and 45 in the
case of Wikipedia, yet, while the latter displayed
the target word, it was absent from the list pro-
duced by WN. This example illustrates the fact
that our claim concerning storage and acess is well
founded. Having stored something does by no
means guarantee its access.
In the next sections we will present a small ex-
periment concerning search.
3 System architecture
To allow for word access, we need at least two
components: an index, i.e. a resource, repre-
senting or encoding the way words are connected
8http://www.schulteimwalde.de/resource.html
9http://www.coli.uni-saarland.de/projects/nag/
10http://www.valdes.titech.ac.jp/ terry/jwad.html
11http://www.lirmm.fr/jeuxdemots/rezo.php
12This poses special requirements concerning the organi-
zation, indexing and ranking of the data, i.e. words. We will
not get into these issues here.
(database or semantic network encoding associa-
tive relations between words) and an efficient
search algorithm to find the needed information,
in our case, words.
In other words, since search requires a map or a
resource in which to search and a good algorithm
to perform the search, we are keen in finding out
how different resources (for example, Wikipedia,
WordNet or JeuxdeMots) and various search al-
gorithms might affect efficiency of word access.
While there is a link between (the quality of) the
resource and the searching, we will separate the
two, focusing here mainly on the search algo-
rithms and possible ways to evaluate them.

	








	






Proceedings of the Second Workshop on NLP Challenges in the Information Explosion Era (NLPIX 2010), pages 50?59,
Beijing, August 2010
Utilizing Citations of Foreign Words in Corpus-Based Dictionary Generation 
Reinhard Rapp University of Tarragona GRLMC 
reinhardrapp@gmx.de 
Michael Zock Laboratoire d?Informatique Fondamentale CNRS Marseille 
Michael.Zock@lif.univ-mrs.fr 
Abstract 
Previous work concerned with the identi-fication of word translations from text collections has been either based on par-allel or on comparable corpora of the re-spective languages. In the case of compa-rable corpora basic dictionaries have been necessary to form a bridge between the languages under consideration. We present here a novel approach to identify word translations from a single mono-lingual corpus without necessarily requir-ing dictionaries, although, as will be shown, a dictionary can still be useful for improving the results. Our approach is based on the observation that for various reasons monolingual corpora typically contain many foreign words (for example citations). Relying on standard news-ticker texts, we will show that their co-occurrence-based associations can be successfully used to identify word trans-lations. 
1 Introduction 
The web has popularized information access. As a consequence, the information put on the web evolved, expanding from mainly technical documents in one language (English) to topics concerning nearly any aspect of life in many lan-guages. For this reason it cannot be expected anymore that all web users speak English. Yet users speaking only one of the minority lan-guages will be penalized, finding only a small fraction of web content accessible. Hence they can make only very limited use of what is avail-able. In order to increase information access in-
dependently of the users? mother tongue, auto-matic translation is desirable. Recognizing this need, Google, among others, is providing free machine translation services for any pair of currently 50 languages. 1  However, with 6800 living languages, of which 600 also use a written form, offering comprehensive trans-lation services remains a challenge. The statistical approach to machine trans-lation (SMT), as adopted by Google, relies on parallel corpora, i.e. large collections of existing translations. But it is a daunting task trying to acquire parallel corpora for all possible language pairs. Therefore, it appears that for some lan-guages Google has combined SMT with an inter-lingua approach. This allows optimal exploita-tion of languages for which parallel corpora are easily obtained. These languages are then used as pivots. Note that in phrase-based SMT an inter-lingua approach may operate at the level of the phrase table, which facilitates matters while speeding up the process. At the downside it must be noted that a phrase table derived via a pivot language is generally of lower quality than a phrase table directly compiled from parallel texts (provided the corpus size is similar). Hence, just as for other interlingua approaches, translation quality is severely compromised.  An alternative approach that has been sug-gested is to try to generate the required dictionar-ies from other sources than parallel corpora. Bear in mind that statistical machine translation re-quires a language model and a translation model. To generate the language model only monolin-gual corpora of the target language are required which, for example, can be acquired from the web. If only few such documents exist, one may well conclude that there is probably no real need                                                  1 http://www.google.de/language_tools?hl=de as of April 22, 2010. 
50
for translation involving this particular language. So the main bottleneck are the parallel corpora required to generate a translation model. But the purpose of the translation model is in essence the creation of a bilingual dictionary, be it a diction-ary of individual words or a dictionary of phra-ses. For this reason, if we can find other ways to generate dictionaries for lesser used languages, this will be beneficial not only for the users of these languages but also for the solution of the overall problem of machine translation.  In other words, an important challenge is the generation of dictionaries. Since comparable cor-pora are a far more common resource than paral-lel corpora, attempts to exploit them for diction-ary construction have received considerable at-tention recently.2 One approach is to mine parallel sentences from comparable corpora. Roughly speaking, this can be done by automatically translating a corpus from one language (source language) to another (target language), and then searching in a large corpus of the target language for sentences simi-lar to the translations. The advantage of this pro-cedure is that the sentences retrieved this way are correct sentences as they were produced by hu-mans, whereas the sentences translated by a ma-chine tend to be garbled and of lower quality. However, the big problem with this approach is to ensure that the retrieved sentence pairs are indeed translations of each other. While there is no perfect solution to this problem, several stud-ies have shown that such data can be useful for building or supplementing translation models in SMT (see e. g. Munteanu & Marcu, 2005; Wu & Fung, 2005).  Another approach for exploiting comparable corpora in dictionary generation is based on the observation that word co-occurrence patterns between languages tend to be similar (Fung & McKeown, 1997; Rapp, 1995; Chiao et al, 2004). If, for example, two words X and Y co-occur more often than expected by chance in a corpus of language A, then their translated equi-
                                                 2 There is also the approach of identifying orthograph-ically similar words (Koehn & Knight, 2002) which does not even require a corpus as simple word lists will suffice. However, this approach is promising only for closely related languages but appears to have lim-ited scope otherwise. For this reason we will not fur-ther discuss it here. 
valents should also co-occur more frequently than expected in a corpus of language B. A great number of variants of this approach has been proposed, e.g. emphasizing aspects of corpus selection or expanding it to collocations or short phrases (Babych et al, 2007).  What is common to these studies is that they consider the source and the target language as two distinct semantic spaces, without any links at the beginning. Therefore, in order to connect the two, a base dictionary is required, and the pur-pose of the system is to expand this base diction-ary. Building a dictionary from scratch is not possible this way or at least computationally un-feasible (see Rapp, 1995). Whether the assumption of two completely distinct semantic spaces is realistic remains an open issue. Are separate lexical networks really a reasonable model for the processing of different languages by people?  One could say this is a plausible model, as-suming a person lived for some years in one country, and then for some more years in another country, assuming further that this person never looked at a dictionary or another multilingual document and never communicated with a per-son mixing both languages. It is known that this can work. The reason is probably the following: Many words of the basic dictionary assumed above correspond to items of the physical world. These items generally have names in natural languages which can serve as mediators. That the extrapolation to more ab-stract notions is possible has been claimed by Rapp (1999). Still, although persons proceeding this way can easily understand and, after some years, even think in each of the two languages, experience shows that they tend to have some difficulties when making translations, especially literal translations. So, although the above scenario is possible, we do not think that it is a typical one for our modern times. There are certainly good reasons why there are so many language courses, and why there is such an abundance of dictionaries. It is a matter of commonsense that the person try-ing to acquire a new language will look at a mul-tilingual dictionary. He or she will also commu-nicate with other persons who mix languages, for example, relatives, other people from the com-
51
munity of foreigners coming from the same country, teachers in language classes, etc. In many cases there will also be multilingual docu-ments around: leaflets, explanations in a mu-seum, or signs in a public area (e.g. airport). Hence the spoken and written ?corpus? (in-put) on which such a person?s language acquisi-tion process is based is not solely monolingual. While the corpus may be mainly monolingual, it surely will contain some multilingual elements. If we agree on this, our next step could be to acquire transcripts of language teaching classes with bilingual teachers and try to exploit these for dictionary generation. Since obtaining such transcripts in large enough quantities should be much more difficult than obtaining parallel cor-pora, this approach will probably not solve the data acquisition bottleneck which is the practical problem we were about to solve in the first place. The current study is therefore based on news-ticker texts which is a text type very similar to standard newspaper texts. At least for some lan-guages it is available in large quantities. How-ever, this type of text is probably not ideally suited for our purpose. Surprisingly, the reason is that newsticker and newspaper texts tend to be very well edited. This means that the author will typically avoid foreign words, and if ever some remain the respective passages are likely be re-phrased in order to make sure that the text uses familiar vocabulary, easily understandable by the readers. However, this is problematic for our ap-proach which is based on the occurrences of for-eign words in a monolingual text. So this is one of the rare cases where noisy corpora should yield better results than perfectly clean data. On the other hand, as this study suggests a (to our knowledge) novel approach, we consider it important to use a corpus that is generally known and available, and which has not been compiled with this particular purpose in mind. Only this way our results can convincingly give an idea concerning the baseline performance of the sug-gested algorithm. At this stage we consider this more important than optimizing results by com-piling corpora specifically suited for the purpose, even though this will be a logical next step. 
2 Approach and Language Resources 
Starting from the observation that monolingual dictionaries typically include a large number of 
foreign words, we consider the most significant co-occurrences of them as potential translation candidates. This implies that the underlying cor-pus corresponds to the target language, and that it can be utilized for any source language for which it contains a sufficient number of word citations. As this paper is written in English, we chose an English corpus as this should make judging our results convenient for most readers. However, being the world?s most widely spoken language, English tends to be rather self-contained in com-parison to other languages, which may use for-eign words more frequently. In particular, as a side effect of globalization, the use of English terminology is popular in many other languages. Therefore, in order to identify, for example, German?English word translations, it is better to look at occurrences of English words in a Ger-man corpus rather than at occurrences of German words in an English corpus.3 Nevertheless, the corpus we use here is the latest release of the English Gigaword Corpus (Fourth Edition) provided by the Linguistic Data Consortium (Parker et al, 2009). It consists of newswire texts of the time between 1995 and 2008 from the following news agencies:  
? Agence France-Presse, English Service  
? Associated Press Worldstream, English Ser-vice  
? Central News Agency of Taiwan, English Service 
? Los Angeles Times/Washington Post News-wire Service  
? New York Times Newswire Service 
? Xinhua News Agency, English Service  Altogether, the corpus comprises about 3 billion words. Since we are not interested in the transla-tion of function words, and in order to reduce the computational load, we removed all function words that were included in a stop word list for English comprising about 200 items. The stop words had been manually selected from a corpus-derived list of high frequency words. In the resulting corpus associations between words need to be identified, something that is usually done on the basis of co-occurrences. In 
                                                 3 Note that the results of both directions may be com-bined. This is something we leave for future work. 
52
order to count the co-occurrences between pairs of words, a text window comprising the ten words preceding and following a given foreign word is considered. On the resulting co-occur-rence counts a standard association metric like the log-likelihood ratio (Dunning, 1993) is ap-plied.   Note that the above mentioned window size of ?10 words from the given word relates to the preprocessed corpus from which function words have already been removed. Since in English roughly every second word tends to be a function word, the effective window size is about ?20 words. This window size is somewhat larger than what we typically find in other studies. However, the reason for this is quite obvious: As citations of foreign words are rare, we have a severe prob-lem of data sparseness, and by looking at a rela-tively large window we try to somewhat com-pensate for this.4  Despite its simplicity, this procedure of com-puting associations to foreign words already works well for identifying word translations. We simply assume that the strongest association is the best translation. We used this approach for words from three languages: French, German, and Spanish. The results are presented in the next section. In order to measure the quality of our results, for all source words of a language we counted the number of times where the expected English target word obtained the highest associa-tion score. As our gold standard for evaluation we used an existing list of translations as described in Rapp & Zock (2010), i.e. a resource that had not been compiled with the current application in mind. The data consists of 1079 word equations in three languages: English, French, and German. It has been extracted from the respective editions of the Collins GEM dictionaries, whereby when looking up a word only the first entry in the list of possible translations was taken into account. As in the current study we are also interested in Spanish, we manually looked up the main trans-
                                                 4  In preliminary experiments we also experimented with other window sizes. However, as we noticed that changes within a reasonable range of e.g. 5 to 20 words have only little effect, we do not consider them here. 
lations at the leo.dict.org website5 and added an-other column to this resource. Table 1 shows a few sample entries of the resulting list of word equations which were used for evaluating our approach. We should mention that the term word equa-tion is a bit problematic, as most words tend to be ambiguous, and ambiguities tend to vary with language. For this reason, we should, at least in principle, disambiguate all words in our corpus and map them to unambiguous concepts. Next we should use a gold standard using such con-cepts rather than words. Unfortunately, the cur-rent state of the art does not allow doing this with sufficient accuracy. Anyhow, addressing this problem is well beyond the scope of this paper.    
SOURCE LANGUAGES TARGET LANG. 
FRENCH GERMAN SPANISH ENGLISH 
britannique britisch brit?nico British 
P?ques Ostern Pascua Easter 
capable f?hig capaz able 
accent Akzent acento accent 
accident Unfall accidente accident 
accord?on Akkordeon acorde?n accordion 
acide S?ure ?cido acid 
gland Eichel bellota acorn 
action Handlung acci?n action 
avantage Vorteil ventaja advantage  Table 1. Some sample entries from the gold standard of word equations.  So far, for identifying the translations of the 1079 French words, we assumed the following ap-proach: We first computed their associations and then conducted an evaluation by checking for how many words the top association was identi-cal to the English translation found in the gold standard. The same approach was also used for the other languages, namely German and French. Hence, the three source languages were treated completely independently of each other. 
                                                 5 This is a manually edited high quality online diction-ary. Although it can be used for free, in our view for many purposes is as good as or even better than con-ventional printed dictionaries. 
53
However, there are several problems with this approach, in particular:  a) Several correct translations b) Data sparseness c) Homograph trap  Let us discuss these issues point by point.  a)  Several correct translations  Suppose we tried to identify the translation of the German word Stra?e and our gold standard listed street as the correct translation. If, however, our system produced road this would be considered just as much of an error as if it had produced a very remote word such as volcano. Hence, con-sidering only a single word as being correct, which is the consequence of using as gold stan-dard the resource exemplified in Table 1, implies that performance figures are artificially low, giv-ing us only the lower bound of the true perform-ance.  Despite this shortcoming, we will neverthe-less do so for the following reasons: 1) This is a pilot study presenting a new approach. For this reason, clarity has priority over performance. 2) The number of translations listed in a dictionary typically depends on the size of the resource. Hence, there is no absolute difference between correct and incorrect translations. Rather, we need to set a threshold somewhere, and truncat-ing after the first word listed is arguably the clearest and simplest way of doing so. 3) This is the main reason. We want to extend our approach to the multilingual case by (simultaneously) looking at several source languages. Given the fact that each language tends to have its own (i.e. idiosyncratic) ambiguities, we are already satis-fied if words from the various source languages have the same main translation. That all possible translations are identical is very unlikely.   b)  Data sparseness  What will happen if a source word does not oc-cur at all in the corpus, or only once or twice? We mentioned already that an appropriate choice of text genre, corpus size, and window size can somewhat reduce the problem of data sparseness. We also mentioned that by reversing source and target languages we can look at the problem from 
two perspectives, which may yield further im-provement. Nevertheless, these suggestions are limited in scope. Hence, given the nature of our approach, data sparseness will remain the core problem.  Fortunately, there is another possibility which is more promising than the ones mentioned above, provided that we manage to solve the am-biguity problem. The solution consists in consid-ering several source languages concurrently. Suppose that rather than starting from scratch we use existing dictionaries for various languages.6 In this case we can easily generate word equa-tions such as the ones shown in Table 1. We do this by considering as a single item all words appearing in a given row (excluding the target language word), and by computing the associa-tions to this aggregated artificial unit. (This is a simplified proposal. We shall see later how to improve it.) If, for example, we have 10 source languages, then it does not matter that 8 source words do not occur in the corpus, as long as the other two are well represented.   c)  The homograph trap  By this we mean that a word form from the source language also exists in the target lan-guage, but with a different meaning. For exam-ple, let us assume that we wanted to translate the word can (house) from Catalan to English. Sup-pose further that we are lucky and have ten Cata-lan citations with this word in our English cor-pus. But this will not help us because the word can happens to also belong to English, meaning something completely different. Moreover, can is a high frequency word, occurring millions of times in a large corpus. Of course, if we had a perfect word sense disambiguator, we could separate the Catalan and the English occurrences of can, thereby solving the problem.7 Unfortu-nately, existing tools are not powerful enough to do the job. What is worse, such collisions are not 
                                                 6 Which, for example, by using open source tools such as Moses and Giza++ (see www.statmt.org) can be easily generated from parallel corpora, e.g. from the Europarl corpus (Koehn, 2005) or the JRC Acquis corpus (Steinberger et al, 2006). 7 If we assume that foreign words typically occur in clusters, we could also use language identification software. 
54
uncommon between languages using the same script. So what can we do? Our suggestion is ex-actly the same as above for the problem of data sparseness, i.e. to look at several source lan-guages in parallel. But it is clear that collapsing all source words into a single item does not work. If only one of them happens to be also a common word in the target language, it is very likely that its co-occur-rences will override the co-occurrences of the foreign words we are interested in. So there is little chance to come up with a correct result. We propose a relatively simple solution to this problem, which possibly may well be novel in this context. Let us develop the idea.  In preliminary experiments we have tried sev-eral possibilities. Collapsing the source words would be equivalent to adding the respective co-occurrence vectors. This is apparently not ade-quate because, as mentioned above, the vector of a very frequent word would dominate all others. An alternative would be to sum up the associa-tion vectors. By the term association vector we mean the co-occurrence vectors after application of an association measure (in our case the log-likelihood ratio). It turns out that this somewhat reduces the problem without solving it entirely. Another possibility would be vector multiplica-tion. Multiplication is considerably better than addition as a property of multiplication is that moderate but coinciding support for a particular target word from several source words leads to a higher product than strong support by only a few. This is a highly desirable property as it helps us avoiding the homograph trap, and because all values are subject to considerable sampling er-rors. Unfortunately, there is yet another problem. Our association measure of choice, namely the log-likelihood ratio, as typical for ratios, has a skewed value characteristic. Since otherwise our previous experiences with the log-likelihood ra-tio are very good,8 and since it seems reasonably well suited for sparse data (Dunning, 1993), we suggest to multiply log-likelihood ranks rather than log-likelihood scores. This proposal is based on the observation (Dunning, 1993) that rankings of association strengths as produced by the log-                                                 8  To the best of our knowledge no other measure could consistently beat it over a wide range of NLP applications. 
likelihood ratio tend to be highly accurate even at higher ranks. Let us call this procedure the prod-uct-of-rank algorithm This algorithm works as follows: Starting from a vocabulary of target language words (which are the translation candidates), for each of these words an association vector is computed. Next, for each association vector the ranks of all words in the source language word tuple under consideration are determined. Hence, if we have three languages (e.g. English, French and Ger-man) we would get three values. These values are multiplied with each other, and finally all target language words are sorted according to the resulting products. As small ranks stand for strong associations, the word obtaining the smal-lest value is considered to be the translation of the source language tuple. This algorithm turned out to lead to highly plausible rankings and to be robust with regard to sampling errors.9 It is also quite effective in eliminating the homograph problem. 
3 Experimental Results and Evaluation 
Let us first try to see whether the basic assump-tion underlying our approach is sound, namely that we will find a sufficient number of foreign words in our corpus. To check this claim, we have listed in Table 2 for each of the four lan-guages the number of words from the gold stan-dard falling into particular frequency categories. For example, the value of 70 in the field belong-ing to the row 6-10 and the column Spanish means that out of the 1079 Spanish words in our gold standard 70 have a corpus frequency be-tween 6 and 10 in the 4th edition of the English Gigaword Corpus. Apparently, words with zero occurrences or with a very low corpus frequency are problematic because of data sparseness. Yet words with very high frequencies are not less problematic, as they may turn out to have homo-graphs in the target language. As there is no gen-erally accepted definition of what the vocabulary of a given language is, we cannot give precise figures concerning the number of homographs in our gold standard for each language pair. Never-
                                                 9 A further improvement is possible by giving words with identical association strengths not arbitrary rank-ing positions within this group, but an average rank which is to be assigned to all of them. 
55
theless, we believe that Table 2 gives a fair im-pression. By taking a look at the high frequency source language words one can see that the pair French?English has the greatest number of homographs, followed by German?English, and finally Spanish?English.  
Source languages Targ. lang. Corpus fre-quency Ger-man Fre-nch Spa-nish Eng-lish 0 449 329 317 0 1 64 85 43 0 2 26 52 25 0 3 24 39 23 0 4 17 34 27 0 5 7 26 15 0 6-10 32 71 70 0 11-20 50 59 86 0 21-50 63 52 129 0 51-100 50 37 95 1 101-200 52 10 75 3 201-500 50 25 74 6 501-1000 43 18 31 19 1001-10000 100 71 37 245 above 10000 52 171 32 805  Table 2: Corpus frequencies of the words occurring in the gold standard.  As to be expected, the corpus frequencies of the language of the corpus, namely English, are or-ders of magnitude higher than those of the other languages. But the table also gives a good idea concerning the presence of French, German, and Spanish word citations in written English. How-ever, we should not be misled by the overwhelm-ing presence of French words in the high fre-quency ranges, as this mainly reflects the amount of homography. Although pronunciation rules are very different between English and French, spelling tends to be similar, which is why there are lots of homographs. In contrast, Spanish and German usually use different spelling even for words having the same historical roots, which is why homography is far less common.10 
                                                 10 As an example for such spelling conversions, let?s mention that the grapheme c in English is almost con-sistently replaced by k in German, e.g. class ? Klasse and clear ? klar. 
From the figures of Table 2 one may conclude that identifying word translations from a mono-lingual corpus is not easy because of data sparse-ness. Nevertheless it seems possible, at least to some extent. Let us therefore take a look at some results. In our experimental work we first identified word translations for stimulus words from a sin-gle source language, then for stimulus words from two source languages, and finally for stimu-lus words from three source languages.  a)  One source language  We started by conducting separate runs for each of the three source languages (French, German, Spanish) and determined the number of times the algorithm was able to come up with the expected English translation as the top ranked association for the 3 * 1079 source words. Note, however, that hereby we did not consider the full range of possible target words present in the English Gi-gaword corpus as this would include many for-eign words. Instead, we restricted the number of target words to the 1079 English words present in the gold standard. The respective figures are 163 (15.1%) for French, 85 (7.9%) for German, and 97 (9.0%) for Spanish. As can be seen, French clearly per-formed best, which confirms previous studies that the lexical agreement between French and English is surprisingly high. Nevertheless, on average, only 10.7% of the translations were identified correctly, which does not look very good. However, remember that these figures can be considered as a lower bound as we do not take alternative translations into account and as the underlying corpus has not been prepared specifi-cally for this purpose. Note also that the product-of-ranks algorithm has no effect in the case when only a single source language is considered. (If there is only one value, no multiplication takes place.)   b)  Two source languages  Our next step was to combine pairs of source languages. There are three possible pairs, namely French?German, French?Spanish, and German?Spanish. Their respective performance figures are as follows: 217 (21.0%), 225 (20.9%), and 145 (13.4%). Computing the mean of these re-
56
sults yields an average of 18.4%, which is a nice improvement over the initial 10.7% which we had for single source languages. This lends sup-port to our hypothesis that the product-of-ranks algorithm works effectively in this context.  c)  Three source languages  Finally, all three source languages were com-bined, resulting in the correct translation of 248 of the altogether 1079 test items, which corre-sponds to a performance of 23.0%. This further improvement is consistent with our hypothesis that performance should increase when more source languages are considered.  Let us take a closer look at these performance gains. At the beginning we increased the number of source languages by 100% (from 1 to 2), yielding a relative performance increase of 72% (the absolute performance improved from 10.7% to 18.4%). Next we increased the number of source languages by 50% (from 2 to 3) which yielded a relative performance increase of 25% (absolute performance had improved from 18.4% to 23%). This means that the behavior is worse than linear, as in the linear case we should have obtained a further improvement of 72%/2 = 36%. But of course when combining statistics in NLP, hardly ever a linear behavior can be observed, and the above findings seem satisfactory. Never-theless they should be supported by looking at further languages, see Section 4.11 For the case of looking at three source lan-guages in parallel, let us provide data concerning the rank distribution of the expected translations (see the middle column of Table 3). Overall, in 357 of the 1079 cases (33.9%) the expected translation ranks among the top five, and in 392 cases (36.3%) it is among the top ten associa-tions. These results are based on a window size of ?10 words when counting the co-occurrence frequencies. To give an idea that the procedure is robust in this respect, we provide analogous val-                                                 11  Another important question, which we have not dealt with yet, is to what extend the observed gain in performance when increasing the number of source languages is a side effect of a higher likelihood that at least one of the source words happens to be identical to the target word (with the same or a similar mean-ing). In such cases (which might be common when considering related languages), predicting the correct translation is rather easy. 
ues for a window size of ?20 words in the third column of Table 3. As can be seen, apart from the usual statistical fluctuations the difference is hardly noticeable.    Number of items with the respective rank Rank window size ?10 window size ?20 rank could not be computed (all source words un-known) 
11 10 
1 248 247 
2 55 51 
3 32 36 
4 15 19 
5 7 8 
6 16 8 
7 7 6 
8 3 5 
9 3 5 
10 6 4 
above 10 676 680  Table 3: Ranks of the expected translations when all three source languages are combined.     
  EXAMPLE 1    Given word French:  tablier  [7]   Given word German:  Sch?rze  [0]   Given word Spanish:  delantal  [4]    Expected translation into English    according to the gold standard:  apron [3059]    Top 5 translations as computed:      1 apron     [3059]     2 sausage    [9954]     3 sauce   [49139]     4 appetite  [24682]     5 mustard  [13477]   Table 4: Sample results.  
57
  
  EXAMPLE 2    Given word French:  carton  [2671]   Given word German:  Karton     [22]   Given word Spanish:  cart?n       [0]    Expected translation into English    according to gold standard:  cardboard [13714]      Top 5 translations as computed:      1    cardboard  [13714]     2    cigarette  [54583]     3    fold   [43682]     4    milk   [85426]     5    egg   [42948]       Table 5: Sample results.  Having looked at the quantitative results, some sample output may also be of interest. For this purpose, Tables 4 and 5 show sample results for triplets of source language words. Hereby, the numbers in square brackets refer to the corpus frequencies of the respective words in the Eng-lish Gigaword Corpus.  
4 Summary and Future Work 
In this paper we made an attempt to solve the problem of identifying word translations on the basis of a single monolingual corpus where the same corpus is supposed to be used for several language pairs. The basic idea underlying our work is to look at citations of foreign words, to compute their co-occurrence-based associations, and to consider these as translations of the re-spective words. We pointed out some difficulties with this ap-proach, namely the problem of data sparseness and the homograph trap, but were able to suggest and implement at least partial solutions. Using the product-of-ranks algorithm, our main sugges-tion was to look at several source languages in parallel, which at least in theory has the potential to solve the experienced problems. We did not have very high expectations when starting this work and were positively surprised by the resulting performance of up to 25% cor-rectly predicted test items. As pointed out, in or-
der to avoid raising unjustified expectations, we presented somewhat conservative figures which should leave room for improvements.  Obvious extensions of the current work are to increase the number of considered languages and to also use other large monolingual corpora. For example, we could use the web corpora provided by the web-as-a-corpus (WaCky) initiative (Ba-roni et al, 2009). A few such corpora have al-ready been made available recently, and as they are based on a largely automatic acquisition pro-cedure there are probably more to come. This reflects a tendency towards extremely large cor-pora. Processing in the current framework turns out to be unproblematic if sparse matrices are used, as foreign word occurrences are implicitly of low frequency. Although web corpora should be very noisy in comparison to the carefully edited newsticker texts used here, the interesting thing is that ac-cording to the hypothesis formulated in the intro-duction the current approach seems to provide one of the rare occasions where noisy data is bet-ter than perfectly clean data, and we hope that future work will prove this prediction correct. Another possibility for future work is to look at second rather than first order associations, i.e. to consider those words as potential translations of a given foreign word which show similar con-text words. This might be promising in so far as the sparse data problem is less salient in this case. Finally, let us come back to our speculative question from the introduction whether or not people speaking different languages have sepa-rate lexico-semantic networks in their mind. Aparently our experiments did not provide evi-dence for either assumption. But the most straightforward assumption would probably be that our mind does not attach language labels to the words we perceive, and simply treats them all equally. At the lexical level, our mind?s unknown inner workings may be in effect analogous to clustering words according to their observed co-occurrence patterns. The likely result is that in some cases there will be many interconnections between clusters, and in other cases few. De-pending on the language environment experi-enced by a person, we cannot rule out that some of the larger clusters might exactly correspond to languages. But what the current research does 
58
tell us is that there can be a multitude of statisti-cally significant co-occurrences even at non-obvious places. So what we possibly should rule out is that, even across languages, there are sepa-rate clusters without any interconnections. 
Acknowledgments 
Part of this research was supported by a Marie Curie Intra European Fellowship within the 7th European Community Framework Programme. We thank the Linguistic Data Consortium for making available the English Gigaword Corpus, and Lourdes Callau, Maria Dolores Jimenez Lo-pez, and Lilica Voicu for their support in acquir-ing it. 
References 
Babych, Bogdan; Sharoff, Serge; Hartley, Anthony; Mudraya, Olga (2007). Assisting Translators in In-direct Lexical Transfer. Proceedings of the 45th In-ternational Conference of the Association for Com-putational Linguistics ACL 2007, Prague, 136?143.  
Baroni, Marco; Bernardini, Silvia; Ferraresi, Adriano,  Zanchetta, Eros (2009). The WaCky Wide Web: A collection of very large linguistically processed Web-crawled corpora. Journal of Language Re-sources and Evaluation 43 (3): 209?226. 
Chiao, Yun-Chuang; Sta, Jean-David; Zweigenbaum, Pierre (2004). A novel approach to improve word translations extraction from non-parallel, compara-ble corpora. In: Proceedings of the International Joint Conference on Natural Language Processing, Hainan, China. AFNLP. 
Dunning, Ted (1993). Accurate methods for the sta-tistics of surprise and coincidence. Computational Linguistics, 19(1), 61?74. 
Fung, P.; McKeown, K. (1997). Finding terminology translations from non-parallel corpora. Proceedings of the 5th Annual Workshop on Very Large Cor-pora, Hong Kong, 192?202.  
Fung, P.; Yee, L. Y. (1998). An IR approach for trans-lating new words from nonparallel, comparable texts. In: Proceedings of COLING-ACL 1998, Montreal, Vol. 1, 414?420. 
Koehn, Philipp; Knight, Kevin (2002). Learning a translation lexicon from monolingual corpora. In: Unsupervised Lexical Acquisition. Proceeding of the ACL SIGLEX Workshop, 9?16. 
Koehn, Philipp (2005). Europarl: A parallel corpus for statistical machine translation. Proceedings of MT Summit, Phuket, Thailand, 79?86.  
Munteanu, Dragos Stefan; Marcu, Daniel (2005). Im-proving machine translation performance by ex-ploiting non-parallel corpora. Computational Lin-guistics 31(4), 477?504. 
Rapp, Reinhard (1995). Identifying word translations in non-parallel texts. In: Proceedings of the 33rd Meeting of the Association for Computational Lin-guistics. Cambridge, Massachusetts, 320?322.  
Rapp, Reinhard. (1999). Automatic identification of word translations from unrelated English and Ger-man corpora. In: Proceedings of the 37th Annual Meeting of the Association for Computational Lin-guistics 1999, College Park, Maryland. 519?526. 
Rapp, Reinhard; Zock, Michael (2010). Automatic dictionary expansion using non-parallel corpora. In: Andreas Fink, Berthold Lausen, Wilfried Seidel Al-fred Ultsch (Eds.)  Advances in Data Analysis, Data Handling and Business Intelligence. Proceedings of the 32nd Annual Meeting of the GfKl, 2008. Hei-delberg: Springer. 
Steinberger, Ralf; Pouliquen, Bruno; Widiger, Anna; Ignat, Camelia; Erjavec, Toma?; Tufi?, Dan; VARGA, D?niel (2006). The JRC-Acquis: A multi-lingual aligned parallel corpus with 20+ languages. Proceedings of the 5thLREC, Genoa, Italy.  
Wu, Dekai; Fung, Pascale (2005). Inversion transduc-tion grammar constraints for mining parallel sen-tences from quasi-comparable corpora. Proceedings of the Second International Joint Conference on  Natural Language Processing (IJCNLP-2005). Jeju, Korea.  
Parker, Robert, Graff, David; Kong, Junbo; Chen, Ke; Maeda, Kazuaki (2009). English Gigaword. Fourth Edition. Linguistic Data Consortium, Philadelphia.  
59
Proceedings of the 4th International Workshop on Cross Lingual Information Access at COLING 2010, pages 16?25,
Beijing, August 2010
The Noisier the Better: Identifying Multilingual  Word Translations Using a Single Monolingual Corpus 
Reinhard Rapp University of Tarragona GRLMC 
reinhardrapp@gmx.de 
Michael Zock Laboratoire d?Informatique Fondamentale CNRS Marseille 
Michael.Zock@lif.univ-mrs.fr 
 
Abstract 
The automatic generation of dictionaries from raw text has previously been based on parallel or comparable corpora. Here we describe an approach requiring only a single monolingual corpus to generate bilingual dictionaries for several lan-guage pairs. A constraint is that all lan-guage pairs have their target language in common, which needs to be the lan-guage of the underlying corpus. Our ap-proach is based on the observation that monolingual corpora usually contain a considerable number of foreign words. As these are often explained via transla-tions typically occurring close by, we can identify these translations by look-ing at the contexts of a foreign word and by computing its strongest associations from these. In this work we focus on the question what results can be expected for 20 language pairs involving five ma-jor European languages. We also com-pare the results for two different types of corpora, namely newsticker texts and web corpora. Our findings show that re-sults are best if English is the source language, and that noisy web corpora are better suited for this task than well edited newsticker texts. 
1 Introduction 
Established methods for the identification of word translations are based on parallel (Brown et al, 1990) or comparable corpora (Fung & McKeown, 1997; Fung & Yee, 1998; Rapp, 1995; Rapp 1999; Chiao et al, 2004). The work using parallel corpora such as Europarl (Koehn, 
2005; Armstrong et al, 1998) or JRC Acquis (Steinberger et al, 2006) typically performs a length-based sentence alignment of the trans-lated texts, and then tries to conduct a word alignment within sentence pairs by determining word correspondences that get support from as many sentence pairs as possible. This approach works very well and can easily be put into prac-tice using a number of freely available open source tools such as Moses (Koehn et al, 2007) and Giza++ (Och & Ney, 2003).  However, parallel texts are a scarce resource for many language pairs (Rapp & Mart?n Vide, 2007), which is why methods based on compa-rable corpora have come into focus. One ap-proach is to extract parallel sentences from comparable corpora (Munteanu & Marcu, 2005; Wu & Fung, 2005). Another approach relates co-occurrence patterns between languages. Hereby the underlying assumption is that across languages there is a correlation between the co-occurrences of words which are translations of each other. If, for example, in a text of one lan-guage two words A and B co-occur more often than expected by chance, then in a text of an-other language those words which are the trans-lations of A and B should also co-occur more frequently than expected. However, to exploit this observation some bridge needs to be built between the two lan-guages. This can be done via a basic dictionary comprising some essential vocabulary. To put it simply, this kind of dictionary allows a (partial) word-by-word translation from the source to the target language,1 so that the result can be con-sidered as a pair of monolingual corpora. Deal-
                                                 1 Note that this translation can also be conducted at the level of co-occurrence vectors rather than at the text level. 
16
ing only with monolingual corpora means that the established methodology for computing similar words (see e.g. Pantel & Lin, 2002), which is based on Harris? (1954) distributional hypothesis, can be applied. It turns out that the most similar words between the two corpora effectively identify the translations of words. This approach based on comparable corpora considerably relieves the data acquisition bot-tleneck, but has the disadvantage that the results tend to lack accuracy in practice. As an alternative, there is also the approach of identifying orthographically similar words (Koehn & Knight, 2002) which has the advan-tage that it does not even require a corpus. A simple word list will suffice. However, this ap-proach works only for closely related languages, and has limited potential otherwise. We propose here to generate dictionaries on the basis of foreign word occurrences in texts. As far as we know, this is a method which has not been tried before. When doing so, a single monolingual corpus can be used for all source languages for which it contains a sufficient number of foreign words. A constraint is that the target language must always be the language of the monolingual corpus,2 which therefore all dictionaries have in common. 
2 Approach and Language Resources 
Starting from the observation that monolingual dictionaries typically include a considerable number of foreign words, the basic idea is to consider the most significant co-occurrences of a foreign word as potential translation candi-dates. This implies that the language of the un-derlying corpus must correspond to the target language, and that this corpus can be utilized for any source language for which word citations are well represented. As the use of foreign language words in texts depends on many parameters, including writer, text type, status of language and cultural back-ground, it is interesting to compare results when varying some of these parameters. However, due to the general scarceness of foreign word                                                  2 Although in principle it would also be possible to determine relations between foreign words from dif-ferent languages within a corpus, this seems not promising as the problem of data sparsity is likely to be prohibitive. 
citations our approach requires very large cor-pora. For this reason, we were only able to vary two parameters, namely language and text type. Some large enough corpora that we had at our disposal were the Gigaword Corpora from the Linguistic Data Consortium (Mendon?a et al, 2009a; Mendon?a et al, 2009b) and the WaCky Corpora described in Sharoff (2006), Baroni et al (2009), and Ferraresi et al (2010). From these, we selected the following for this study:  
? French WaCky Corpus (8.2 GB) 
? German WaCky Corpus (9.9 GB) 
? Italian WaCky Corpus (10.4 GB) 
? French Gigaword 2nd edition (5.0 GB) 
? Spanish Gigaword 2nd edition (6.8 GB)  The memory requirements shown for each cor-pus relate to ANSI coded text only versions. We derived these from the original corpora by re-moving linguistic annotation (for the WaCky corpora) and XML markup, and by converting the coding from UTF8 to ANSI. Both Gigaword corpora consist of news-ticker texts from several press agencies. News-ticker text is a text type closely related to news-paper text. It is usually carefully edited, and the vocabulary is geared towards easy understand-ing for the intended readership. This implies that foreign word citations are kept to a mini-mum. In contrast, the WaCky Corpora have been downloaded from the web and represent a great variety of text types and styles. Hence, not all texts can be expected to have been carefully edited, and mixes between languages are proba-bly more frequent than with newsticker text. As in this work English is the main source language, and as we have dealt with it as a tar-get language already in Rapp & Zock (2010), we do not use the respective English versions of these corpora here. We also do not use the Wikipedia XML Corpora (Denoyer et al, 2006) as these greatly vary in size for different lan-guages which makes comparisons across lan-guages somewhat problematic. In contrast, the sizes of the above corpora are within the same order of magnitude (1 billion words each), which is why we do not control for corpus size here. 
17
Concerning the number of foreign words within these corpora, we might expect that, given the status of English as the world?s pre-miere language, English foreign words should be the most frequent ones in our corpora. As French and Spanish are also prominent lan-guages, foreign words borrowed from them may be less frequent but should still be common, whereas borrowings from German and Italian are expected to be the least likely ones. From this point of view the quality of the results should vary accordingly. But of course there are many other aspects that are important, for ex-ample, relations between countries, cultural background, relatedness between languages, etc. As these are complex influences with intricate interactions, it is impossible to accurately an-ticipate the actual outcome. In other words, ex-perimental work is needed. Let us therefore de-scribe our approach. For identifying word translations within a corpus, we assume that the strongest association to a foreign word is likely to be its translation. This can be justified by typical usage patterns of foreign words often involving, for example, an explanation right after their first occurrence in a text. Associations between words can be com-puted in a straightforward manner by counting word co-occurrences followed by the applica-tion of an association measure on the co-occurrence counts. Co-occurrence counts are based on a text window comprising the 20 words on either side of a given foreign word. On the resulting counts we apply the log-likelihood ratio (Dunning, 1993). As explained by Dunning, this measure has the advantage to be applicable also on low counts, which is an important characteristic in our setting where the problem of data sparseness is particularly se-vere. This is also the reason why we chose a window size somewhat larger than the ones used in most other studies. Despite its simplicity this procedure of com-puting associations to foreign words is well suited for identifying word translations. As mentioned above, we assume that the strongest association to a foreign word is its best transla-tion. We did this for words from five languages (English, French, German, Italian, and Spanish). The results are shown in the next section. In 
order to be able to quantitatively evaluate the quality of our results, we counted for all source words of a language the number of times the expected target word obtained the strongest as-sociation score. Our expectations on what should count as a correct translation had been fixed before run-ning the experiments by creating a gold stan-dard for evaluation. We started from the list of 100 English words (nouns, adjectives and verbs) which had been introduced by Kent & Rosanoff (1910) in a psychological context. We translated these English words into each of the four target languages, namely French, German, Italian, and Spanish. As we are at least to some extent familiar with these languages, and as the Kent/Rosanoff vocabulary is fairly straightforward, we did this manually. In cases where we were aware of ambiguities, we tried to come up with a translation relating to what we assumed to be the most frequent of a word?s possible senses. In case of doubt we consulted a number of written bilingual dictionaries, the dict.leo.org dictionary website, and the transla-tion services provided by Google and Yahoo. For each word, we always produced only a sin-gle translation. In an attempt to provide a com-mon test set, the appendix shows the resulting list of word equations in full length for refer-ence by interested researchers. It should be noted that the concept of word equations is a simplification, as it does not take into account the fact that words tend to be am-biguous, and that ambiguities typically do not match across languages. Despite these short-comings we nevertheless use this concept. Let us give some justification.  Word ambiguities are omnipresent in any language. For example, the English word palm has two meanings (tree and hand) which are usually expressed by different words in other languages. However, for our gold standard we must make a choice. We can not include two or more translations in one word equation as this would contradict the principle that all words in a word equation should share their main sense.  Another problem is that, unless we work with dictionaries derived from parallel corpora, it is difficult to estimate how common a transla-tion is. But if we included less common transla-tions in our list, we would have to give their matches a smaller weight during evaluation. 
18
This, however, is difficult to accomplish accu-rately. This is why, despite their shortcomings, we use word equations in this work. Evaluation of our results involves comparing a predicted translation to the corresponding word in the gold standard. We consider the pre-dicted translation to be correct if there is a match, otherwise we consider it as false. While in principle possible, we do not make any finer distinctions concerning the quality of a match. A problem that we face in our approach is what we call the homograph trap. What we mean by this term is that a foreign word occur-ring in a corpus of a particular language may also be a valid word in this language, yet possi-bly with a different meaning. For example, if the German word rot (meaning red) occurs in an English corpus, its occurrences can not easily be distinguished from occurrences of the English word rot, which is a verb describing the process of decay. Having dealt with this problem in Rapp & Zock (2010) we will not elaborate on it here, rather we will suggest a workaround. The idea is to look only at a very restricted vocabulary, namely the words defined in our gold standard. There we have 100 words in each of the five languages, i.e. 500 words altogether. The ques-tion is how many of these words occur more often than once. Note, however, that apart from English (which was the starting point for the gold standard), repetitions can occur not only across languages but also within a language. For example, the Spanish word sue?o means both sleep and dream, which are distinct entries in the list. The following is a complete list of words showing either of these two types of repetitions, i.e. exact string matches (taking into account capitalization and accents): alto (4), bambino (2), Bible (2), bitter (2), casa (2), commando (2), corto (2), doux (2), duro (2), fruit (2), jus-tice (2), lento (2), lion (2), long (2), luna (2), mano (2), memoria (2), mouton (2), religion (2), sacerdote (2), sue?o (2), table (2), whisky (4). However, as is obvious from this list, these repetitions are due to common vocabulary of the languages, with whisky being a typical example. They are not due to incidental string identity of completely different words. So the latter is not a problem (i.e. causing the identification of wrong 
translations) as long as we do not go beyond the vocabulary defined in our gold standard. For this reason and because dealing with the full vocabulary of our (very large) corpora would be computationally expensive, we de-cided to replace in our corpora all words absent from the gold standard by a common designator for unknown words. Also, in our evaluations, for the target language vocabulary we only use the words occurring in the respective column of the gold standard. So far, we always computed translations to single source words. However, if we assume, for example, that we already have word equa-tions for four languages, and all we want is to compute the translations into a fifth language, then we can simply extend our approach to what we call the product-of-ranks algorithm. As sug-gested in Rapp & Zock (2010) this can be done by looking up the ranks of each of the four given words (i.e. the words occurring in a par-ticular word equation) within the association vector of a translation candidate, and by multi-plying these ranks. So for each candidate we obtain a product of ranks. We then assume that the candidate with the smallest product will be the best translation.3  Let us illustrate this by an example: If the given words are the variants of the word nerv-ous in English, French, German, and Spanish, i.e. nervous, nerveux, nerv?s, and nervioso, and if we want to find out their translation into Ital-ian, we would look at the association vectors of each word in our Italian target vocabulary. The association strengths in these vectors need to be inversely sorted, and in each of them we will look up the positions of our four given words. Then for each vector we compute the product of the four ranks, and finally sort the Italian vo-cabulary according to these products. We would then expect that the correct Italian translation, namely nervoso, ends up in the first position, i.e. has the smallest value for its product of ranks. 
                                                 3 Note that, especially in the frequent case of zero-co-occurrences, many words may have the same as-sociation strength, and rankings within such a group of words may be arbitrary within a wide range. To avoid such arbitrariness, it is advisable to assign all words within such a group the same rank, which is chosen to be the average rank within the group. 
19
In the next section, we will show the results for this algorithm in addition to those for single source language words. As a different matter, let us mention that for our above algorithm we do not need an explicit identification of what should count as a foreign word. We only need a list of words to be trans-lated, and a list of target language words con-taining the translation candidates from which to choose. Overlapping vocabulary is permitted. If the overlapping words have the same meaning in both languages, then there is no problem and the identification of the correct translation is rather trivial as co-occurrences of a word with itself tend to be frequent. However, if the over-lapping words have different meanings, then we have what we previously called a homogaph trap. In such (for small vocabularies very rare) cases, it would be helpful to be able to distin-guish the occurrences of the foreign words from those of the homograph. However, this problem essentially boils down to a word sense disam-biguation task (actually a hard case of it as the foreign word occurrences, and with them the respective senses, tend to be rare) which is be-yond the scope of this paper. 
3 Experimental Results and Evaluation 
We applied the following procedure on each of the five corpora: The language of the respective corpus was considered the target language, and the vocabulary of the respective column in the gold standard was taken to be the target lan-guage vocabulary.  
 Source Languages 
 DE EN FR ES IT all 
DE WaCky ? 54 22 18 20 48 
ES Giga 9 42 37 ? 29 56 
FR Giga 15 45 ? 20 14 49 
FR WaCky 27 59 ? 16 21 50 
IT WaCky 17 53 29 27 ? 56 
Average 17.0 50.6 29.3 20.3 21.0 51.8  Table 1: Number of correctly predicted translations for various corpora and source languages. Column all refers to the parallel use of all four source lan-guages using the product-of-ranks algorithm. 
The other languages are referred to as the source languages, and the corresponding columns of the gold standard contain the respective vocabu-laries. Using the algorithm described in the pre-vious section, for each source vocabulary the following procedure was conducted: For every source language word the target vocabulary was sorted according to the respective scores. The word obtaining the first rank was considered to be the predicted translation. This predicted translation was compared to the translation listed in the gold standard. If it matched, the prediction was counted as correct, otherwise as wrong. Table 1 lists the number of correct predic-tions for each corpus and for each source lan-guage. These results lead us to the following three conclusions:   1)  The noisier the better  We have only for one language (French) both a Gigaword and a WaCky corpus. The results based on the WaCky corpus are clearly better for all languages except Spanish. Alternatively, we can also look at the average performance for the five source languages among the three WaCky corpora, which is 30.3, and the analo-gous performance for the two Gigaword cor-pora, which is 26.4. These findings lend some support to our hypothesis that noisy web cor-pora are better suited for our purpose than care-fully edited newsticker corpora, which are probably more successful in avoiding foreign language citations  2)  English words are cited more often  In the bottom row, Table 1 shows for each of the five languages the scores averaged over all corpora. As hypothesized previously, we can take citation frequency as an indicator (among others) of the ?importance? of a language. And citation frequency can be expected to correlate with our scores. With 50.6, the average score for English is far better than for any other lan-guage, thereby underlining its special status among world languages. With an average score of 29.3 French comes next which confirms the hypothesis that it is another world language re-ceiving considerable attention elsewhere. Some-what surprising is the finding that Spanish can not keep up with French and obtains an average 
20
score of 20.3 which is even lower than the 21.0 for Italian. A possible explanation is the fact that we are only dealing with European lan-guages here, and that the cultural influence of the Roman Empire and Italy has been so con-siderable in Europe that it may well account for this. So the status of Spanish in the world may not be well reflected in our selection of corpora. Finally, the average score of 17.0 for German shows that it is the least cited language in our selection of languages. Bear in mind, though, that German is the only clearly Germanic lan-guage here, and that its vocabulary is very dif-ferent from that of the other languages. These are mostly Romanic in type, with English somewhere in between. Therefore, the little overlap in vocabulary might make it hard for French, Italian, and Spanish writers to under-stand and use German foreign words.   3)  Little improvement for several source words  The right column in Table 1 shows the scores if (using the product-of-ranks algorithm) four source languages are taken into account in par-allel. As can be seen, with an average score of 51.8 the improvement over the English only variant (50.6) is minimal. This contrasts with the findings described in Rapp & Zock (2010) where significant improvements could be achieved by increasing the number of source languages. So this casts some doubt on these. However, as English was not considered as a source language there, the performance levels were mostly between 10 and 20, leaving much room for improvement. This is not the case here, where we try to improve on a score of around 50 for English. Remember that this is a somewhat conservative score as we count cor-rect but alternative translations, as errors. As this is already a performance much closer to the optimum, making further performance gains is more difficult. Therefore, perhaps we should take it as a success that the product-of-ranks algorithm could achieve a minimal performance gain despite the fact that the influence of the non-English languages was probably mostly detrimental. Having analyzed the quantitative results, to give a better impression of the strengths and weaknesses of our algorithm, for the (according to Table 1) best performing combination of cor-
pus and language pair, namely the French WaCky corpus, English as the source language and French as the target language, Table 2 shows some actual source words and their com-puted translations. 
 
  ESW    CF   ET  RE  CT 
cabbage 9 chou 1 chou blossom 25 fleur 73 commande carpet 39 tapis 1 tapis bitter 59 amer 1 amer hammer 67 marteau 1 marteau bread 82 pain 1 pain citizen 115 citoyen 1 citoyen bath 178 bain 1 bain butterfly 201 papillon 1 papillon eat 208 manger 1 manger butter 220 beurre 59 terre eagle 282 aigle 1 aigle cheese 527 fromage 1 fromage cold 539 froid 1 froid deep 585 profond 1 profond cottage 624 cabanon 1 cabanon earth 702 terre 53 tabac child 735 enfant 1 enfant bed 806 lit 2 table beautiful 923 beau 1 beau care 1267 soin 1 soin hand 1810 main 2 main city 2610 ville 1 ville girl 2673 fille 1 fille green 2861 vert 1 vert blue 2914 bleu 1 bleu hard 3615 dur 1 dur black 9626 noir 1 noir Bible 17791 Bible 1 Bible foot 23548 pied 8 siffler chair 24027 chaise 1 chaise fruit 38544 fruit 1 fruit  Table 2: Results for the language pair English ? French. The meaning of the columns is as follows: ESW = English source word; CF = corpus frequency of English source word; ET = expected translation according to gold standard; RE = computed rank of expected translation; CT = computed translation. 
4 Summary and Future Work 
In this paper we made an attempt to solve the difficult problem of identifying word trans-lations on the basis of a single monolingual cor-
21
pus, whereby the same corpus is used for sev-eral language pairs. The basic idea underlying our work is to look at foreign words, to compute their co-occurrence-based associations, and to consider these as translations of the respective words. Whereas Rapp & Zock (2010) dealt only with an English corpus, the current work shows that this methodology is applicable to a wide range of languages and corpora. We were able to shed some light on criteria influencing per-formance, such as the selection of text type and the direction of a language pair. For example, it is more promising to look at occurrences of English words in a German corpus rather than the other way around. Because of the special status of English it is also advisable to use it as a pivot wherever possible. Perhaps surprisingly, the work may have im-plications regarding cognitive models of second language acquisition. The reason is that it de-scribes how to acquire the vocabulary of a new language from a mixed corpus. This is relevant as traditional foreign language teaching (involv-ing explanations in the native tongue and vo-cabulary learning using bilingual word lists) can be considered as providing such a mixed corpus. Regarding future work, let us outline a plan for the construction of a universal dictionary of all languages which are well enough represented on the web.4 There might be some chance for it, because the algorithm can be extended to work with standard search engines and is also suitable for a bootstrapping approach.  Let us start by assuming that we have a large matrix where the rows correspond to the union of the vocabularies of a considerable number of languages, and the columns correspond to these languages themselves. We presuppose no prior translation knowledge, so that the matrix is completely empty at the beginning (although prior knowledge could be useful for the iterative algorithm to converge). STEP 1: For each word in the vocabulary we perform a search via a search engine such as Google, preferably in an automated fashion via an application programming interface (API). Next, we retrieve as many documents as possi-
                                                 4 Note that this plan could also be adapted to other methodologies (such as Rapp, 1999), and may be more promising with these. 
ble, and separate them according to language.5 Then, for each language for which we have ob-tained the critical mass of documents, we apply our algorithm and compute the respective trans-lations. These are entered into the matrix. As we are interested in word equations, we assume that translations are symmetric. This means that each translation identified can be entered at two positions in the matrix. So at the end of step 1 we have for each word the translations into a number of other languages, but this number may still be small at this stage.  STEP 2: We now look at each row of the ma-trix and feed the words found within the same row into the product-of-ranks algorithm. We do not have to repeat the Google search, as step 1 already provided all documents needed. Be-cause when looking at several source words we have a better chance to find occurrences in our documents, this should give us translations for some more languages in the same row. But we also need to recompute the translations resulting from the previous step as some of them will be erroneous e.g.  for reasons of data sparseness or due to the homograph trap. STEP 3: Repeat step 2 until as many matrix cells as possible are filled with translations. We hope that with each iteration completeness and correctness improve, and that the process con-verges in such a way that the (multilingual) words in each row disambiguate each other, so that ultimately each row corresponds to an un-ambiguous concept. 
Acknowledgments 
Part of this research was supported by a Marie Curie Intra European Fellowship within the 7th European Community Framework Programme. We thank the WaCky group for making avail-able their excellent Web corpora, and the Lin-guistic Data Consortium for providing the Gi-gaword Corpora. We also wish to thank Lourdes Callau, Maria Dolores Jimenez Lopez, and Lilica Voicu for their support in acquiring the LDC corpora. 
                                                 5  If the language identification markup within the retrieved documents turns out to be unreliable (which is unfortunately often the case in practice), standard language identification software can be used. 
22
References 
Armstrong, Susan; Kempen, Masja; McKelvie, David; Petitpierre, Dominique; Rapp, Reinhard; Thompson, Henry (1998). Multilingual Corpora for Cooperation. Proceedings of the 1st Interna-tional Conference on Linguistic Resources and Evaluation (LREC), Granada, Vol. 2, 975?980.  
Baroni, Marco; Bernardini, Silvia; Ferraresi, Adri-ano,  Zanchetta, Eros (2009). The WaCky Wide Web: A collection of very large linguistically pro-cessed Web-crawled corpora. Journal of Language Resources and Evaluation 43 (3): 209-226. 
Brown, Peter; Cocke, John; Della Pietra, Stephen A.; Della Pietra, Vincent J.; Jelinek, Frederick; Laf-ferty, John D.; Mercer, Robert L.; Rossin, Paul S. (1990). A statistical approach to machine transla-tion. Computational Linguistics, 16(2), 79?85. 
Chiao, Yun-Chuang; Sta, Jean-David; Zwei-genbaum, Pierre (2004). A novel approach to im-prove word translations extraction from non-parallel, comparable corpora. In: Proceedings of the International Joint Conference on Natural Language Processing, Hainan, China. AFNLP. 
Denoyer, Ludovic; Gallinari, Pattrick (2006). The Wikipedia XML Corpus. SIGIR Forum, 40(1), 64?69. 
Dunning, T. (1993). Accurate methods for the sta-tistics of surprise and coincidence. Computational Linguistics, 19(1), 61?74.  
Ferraresi, Adriano; Bernardini, Silvia; Picci, Gio-vanni; Baroni, Marco (2010). Web corpora for bi-lingual lexicography: a pilot study of English/ French collocation extraction and translation. In Xiao, Richard (ed.): Using Corpora in Contrastive and Translation Studies. Newcastle: Cambridge Scholars Publishing. 
Fung, Pascale; McKeown, Kathy (1997). Finding terminology translations from non-parallel cor-pora. Proceedings of the 5th Annual Workshop on Very Large Corpora, Hong Kong, 192-202.  
Fung, Pascale; Yee, Lo Yuen (1998). An IR ap-proach for translating new words from nonparallel, comparable texts. In: Proceedings of COLING-ACL 1998, Montreal, Vol. 1, 414-420. 
Harris, Zelig S. (1954). Distributional structure. WORD, 10:146?162.  
Kent, Grace Helen; Rosanoff , A.J. (1910). A study of association in insanity. American Journal of In-sanity 67:317?390. Koehn, Philipp (2005). Europarl: A parallel corpus for statistical machine translation. Proceedings of MT Summit, Phuket, Thailand, 79?86.  
Koehn, Philipp; Hoang, Hieu; Birch, Alexandra; Callison-Burch, Chris; Federico, Marcello; Ber-toldi, Nicola; Cowan, Brooke; Shen, Wade; Moran, Christine; Zens, Richard; Dyer, Chris; Bo-jar, Ond?ej; Constantin, Alexandra; Herbst, Evan (2007). Moses: Open source toolkit for statistical machine translation. In: Proceedings of ACL, Pra-gue, demonstration session, 177?180.  
Koehn, Philipp; Knight, Kevin (2002). Learning a translation lexicon from monolingual corpora. In: Unsupervised Lexical Acquisition. Proceedings of the ACL SIGLEX Workshop, 9?16. 
Mendon?a, Angelo, Graff, David, DiPersio, Denise (2009a). French Gigaword Second Edition. Lingu-istic Data Consortium, Philadelphia. 
Mendon?a, Angelo, Graff, David, DiPersio, Denise (2009b). Spanish Gigaword Second Edition. Lin-guistic Data Consortium, Philadelphia. 
Munteanu, Dragos Stefan; Marcu, Daniel (2005). Improving machine translation performance by exploiting non-parallel corpora. Computational Linguistics 31(4), 477?504.  
Och, Franz Josef; Ney, Hermann (2003). A System-atic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1), 19?51. 
Pantel, Patrick; Lin, Dekang (2002). Discovering word senses from text. In: Proceedings of ACM SIGKDD, Edmonton, 613?619 
Rapp, Reinhard (1995). Identifying word translations in non-parallel texts. In: Proceedings of the 33rd Meeting of the Association for Computational Lin-guistics. Cambridge, Massachusetts, 320-322.  
Rapp, Reinhard. (1999). Automatic identification of word translations from unrelated English and German corpora. In: Proceedings of the 37th An-nual Meeting of the Association for Computational Linguistics 1999, College Park, Maryland. 519?526. 
Rapp, Reinhard; Mart?n Vide, Carlos (2007). Statis-tical machine translation without parallel corpora. In: Georg Rehm, Andreas Witt, Lothar Lemnitzer (eds.): Data Structures for Linguistic Resources and Applications. Proceedings of the Biennial GLDV Conference 2007. T?bingen: Gunter Narr Verlag. 231?240.  
Rapp, Reinhard; Zock, Michael (2010). Utilizing Citations of Foreign Words in Corpus-Based Dic-tionary Generation. Proceedings of NLPIX 2010. 
Sharoff, Serge (2006). Creating general-purpose cor-pora using automated search engine queries. In Marco Baroni and Silvia Bernardini (eds.): WaCky! Working papers on the Web as Corpus. Gedit, Bologna, http://wackybook.sslmit.unibo.it/ 
 
23
Steinberger, Ralf; Pouliquen, Bruno; Widiger, Anna; Ignat, Camelia; Erjavec, Toma?; Tufi?, Dan; Varga, D?niel (2006). The JRC-Acquis: A multi-lingual aligned parallel corpus with 20+ languages. Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC 2006). Genoa, Italy.   
Wu, Dekai; Fung, Pascale (2005). Inversion trans-duction grammar constraints for mining parallel sentences from quasi-comparable corpora. Pro-ceedings of the Second International Joint Confer-ence on  Natural Language Processing (IJCNLP-2005). Jeju, Korea.   
Appendix: Gold Standard of 100 Word Equations 
 
 ENGLISH GERMAN FRENCH SPANISH ITALIAN 
1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  
anger baby bath beautiful bed Bible bitter black blossom blue boy bread butter butterfly cabbage care carpet chair cheese child citizen city cold command convenience cottage dark deep doctor dream eagle earth eat foot fruit girl green hammer hand handle hard head health heavy 
Wut Baby Bad sch?n Bett Bibel bitter schwarz Bl?te blau Junge Brot Butter Schmetterling Kohl Pflege Teppich Stuhl K?se Kind B?rger Stadt kalt Kommando Bequemlichkeit H?uschen dunkel tief Arzt Traum Adler Erde essen Fu? Frucht M?dchen gr?n Hammer Hand Griff hart Kopf Gesundheit schwer 
col?re b?b? bain beau lit Bible amer noir fleur bleu gar?on pain beurre papillon chou soin tapis chaise fromage enfant citoyen ville froid commande commodit? cabanon fonc? profond m?decin r?ve aigle terre manger pied fruit fille vert marteau main poign?e dur t?te sant? lourd 
furia beb? ba?o hermoso cama Biblia amargo negro flor azul chico pan mantequilla mariposa col cuidado alfombra silla queso ni?o ciudadano ciudad fr?o comando conveniencia casita oscuro profundo m?dico sue?o ?guila tierra comer pie fruta chica verde martillo mano manejar duro cabeza salud pesado 
rabbia bambino bagno bello letto Bibbia amaro nero fiore blu ragazzo pane burro farfalla cavolo cura tappeto sedia formaggio bambino cittadino citt? freddo comando convenienza casetta buio profondo medico sogno aquila terra mangiare piede frutta ragazza verde martello mano maniglia duro testa salute pesante 
24
45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99  100  
high house hungry joy justice King lamp light lion long loud man memory moon mountain music mutton needle nervous ocean oven priest quick quiet red religion river rough salt scissors sheep short sickness sleep slow smooth soft soldier sour spider square stomach street sweet table thief thirsty tobacco whisky whistle white window wish woman work yellow 
hoch Haus hungrig Freude Gerechtigkeit K?nig Lampe Licht L?we lang laut Mann Ged?chtnis Mond Berg Musik Hammel Nadel nerv?s Ozean Backofen Priester schnell still rot Religion Fluss rau Salz Schere Schaf kurz Krankheit schlafen langsam glatt weich Soldat sauer Spinne Quadrat Magen Stra?e s?? Tisch Dieb durstig Tabak Whisky pfeifen wei? Fenster Wunsch Frau arbeiten gelb 
?lev? maison affam? joie justice roi lampe lumi?re lion long fort homme m?moire lune montagne musique mouton aiguille nerveux oc?an four pr?tre rapide tranquille rouge religion rivi?re rugueux sel ciseaux mouton courte maladie sommeil lent lisse doux soldat acide araign?e carr? estomac rue doux table voleur soif tabac whisky siffler blanc fen?tre d?sir femme travail jaune 
alto casa hambriento alegr?a justicia rey l?mpara luz le?n largo alto hombre memoria luna monta?a m?sica cordero aguja nervioso oc?ano horno sacerdote r?pido tranquilo rojo religi?n r?o ?spero sal tijeras oveja corto enfermedad sue?o lento liso suave soldado agrio ara?a cuadrado est?mago calle dulce mesa ladr?n sediento tabaco whisky silbar blanco ventana deseo mujer trabajo amarillo 
alto casa affamato gioia giustizia re lampada luce leone lungo alto uomo memoria luna montagna musica montone ago nervoso oceano forno sacerdote rapido tranquillo rosso religione fiume ruvido sale forbici pecora corto malattia dormire lento liscio morbido soldato acido ragno quadrato stomaco strada dolce tavolo ladro assetato tabacco whisky fischiare bianco finestra desiderio donna lavoro giallo 
25
Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 43?48,
Gothenburg, Sweden, April 26 2014. c?2014 Association for Computational Linguistics
How Well Can a Corpus-Derived Co-Occurrence Network  Simulate Human Associative Behavior? 
 Gemma Bel Enguix Reinhard Rapp Michael Zock  Aix-Marseille Universit?, Laboratoire d'Informatique Fondamentale UMR 7279, Case 901, 163 Avenue de Luminy, F-13288 Marseille  gemma.belenguix@gmail.com reinhardrapp@gmx.de zock@free.fr   Abstract 
Free word associations are the words people spontaneously come up with in re-sponse to a stimulus word. Such informa-tion has been collected from test persons and stored in databases.  A well known example is the Edinburgh Associative Thesaurus (EAT). We will show in this paper that this kind of knowledge can be acquired automatically from corpora, en-abling the computer to produce similar associative responses as people do. While in the past test sets typically consisted of approximately 100 words, we will use here a large part of the EAT which, in to-tal, comprises 8400 words. Apart from extending the test set, we consider differ-ent properties of words: saliency, fre-quency and part-of-speech. For each fea-ture categorize our test set, and we com-pare the simulation results to those based on the EAT. It turns out that there are surprising similarities which supports our claim that a corpus-derived co-occur-rence network can simulate human asso-ciative behavior, i.e. an important part of language acquisition and verbal behavior. 1 Introduction Word associations in general and free word asso-ciation in particular (Galton, 1879) have been used by psychologists of various schools1 to un-derstand the human mind (memory, cognition, language) and the hidden mechanisms driving peoples? thoughts, utterances, and actions. In the case of free word associations, a person typically hears or reads a word, and is asked to produce the first other word coming to mind. Kent & Ro-sanoff (1910) have used this method for compar-                                                1  For example, cognitive psychology (Collins and Loftus, 1975,), psycholinguistics (Clark, 1970) and psychoanalysis (Freud, 1901; Jung & Riklin, 1906). 
isons, introducing to this end 100 emotionally neutral test words. Having conducted the first large scale study of word associations (1000 test persons) they reached the conclusion that there was a great uniformity concerning people's asso-ciations, that is, speakers of a language share sta-ble, comparable associative networks (Istifci, 2010).  In this paper, we are mainly interested in the automatic acquisition of associations by com-puter. More precisely, we want to check whether a corpus-based method allows us to build auto-matically an associative network akin to the one in peoples? mind, that is, a network able to mim-ic human behavior. This means, given a stimulus word the system is supposed to produce the same responses as people do. We know since the old Greeks that thoughts and their expressions (words) are linked via associations. Yet, what we still do not know is the nature of these links. Al-so, links vary in terms of strength. Associationist learning theory (Schwartz & Reisberg, 1991) ex-plains how these strengths (or weights) are ac-quired. The strength between two perceived events increases by a constant fraction of a max-imally possible increment at each co-occurrence, and decreases in the opposite case.  Wettler et al. (2005) have shown that this mechanism can be replicated by looking at word co-occurrence frequencies in large text collec-tions. But there had been earlier corpus-linguistic work: For example, Wettler & Rapp (1989) com-pared several association measures in order to find search terms to be used for queries in infor-mation retrieval. Church & Hanks (1990) sug-gested to use mutual information, an information theoretic measure, for computing association strength. Prior to this, a lot of work had been done without reliance of corpora. For example, Collins & Loftus (1975) used associative seman-tic networks to show the distance between words. Others (Rosenzweig, 1961:358; Ekpo-Ufot, 1978) tried to show the universal status of a large subset of associations. While all these findings are important, we will not consider them further 
43
here. Rather we will focus on the claim that a -corpus-derived co-occurrence network is able to mimic human associative behavior. Such a network consists of nodes, which in our case correspond to words (or lemmas), and of weights connecting the nodes. The strengths of these weights are computed on the basis of word co-occurrence data, and by optionally ap-plying an association measure. But there are many association measures. Given their number and diversity some researchers (Evert & Krenn, 2001) felt that there was a need to define some criteria and methods in order to allow for quanti-tative comparisons via task-based evaluations. Pursuing a similar goal, Pecina & Schlesinger (2006) compared 82 different association measures for collocation extraction, while Hoang et al. (2009) classified them. Michelbacher et al. (2011) investigated the potential of asymmetric association measures, i.e. "associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)". Washtell & Markert (2009) tried to determine whether word associations should be computed via window-based co-occurrence counts or rather via a windowless approach measuring the dis-tances between words. Our work is related to previous studies com-paring human word associations with those de-rived from corpus statistics (e.g. Wettler et al., 2005; Tamir, 2005, Seidensticker, 2006). The main differences are that we categorize our stim-ulus words and present results for each class, and that we have a stronger focus on the graph aspect of our network. 2 Resources and processing In order to simulate human associative behavior via corpora, we need them to encode knowledge that people typically have, that is, encyclopedic or universally shared knowledge (e.g. Paris capi-tal of France) and episodic knowledge (i.e. knowledge momentarily true: Nadal winner of the French Open). To meet these goals we de-cided to use the British National Corpus (BNC, Burnard & Aston, 1998) as it is well balanced and relatively large (about 100 million words of contemporary British English). To lemmatize the corpus we used the NLTK (Bird et al., 2009) which for this purpose utilizes information from WordNet. Hence, inflected forms (e.g. wheels or bigger) were replaced by their base forms (e.g. wheel or big). This reduces 
noise and data sparsity while improving speed and accuracy during evaluation. Since this latter is based on exact string matching, our system would consider wheels, produced in response to car, as a mistake as the primary associative re-sponse of the test persons is wheel, the singular form. Lemmatization solves this problem. Since we were interested here only in content words (nouns, verbs, and adjectives) we removed all other words from the BNC. To evaluate the performance of our system we compared its results with the associations col-lected by Kiss et al. (1973), the Edinburgh Asso-ciative Thesaurus. The association norms of the EAT were produced by presenting each stimulus word to 100 subjects, and by collecting their re-sponses. The subjects were 17 to 22 year old British students. Table 1 shows the associations produced by at least five participants in response to the stimulus words bath and cold together with the number of participants producing them.  bath cold observed response number of subjects observed response number of subjects water tub clean hot 
20 8 5 5 
hot ice warm water 
34 10 7 5 Table 1: Extracts from the EAT for the stimulus words bath and cold. The EAT lists the associations to 8400 stimu-lus words. Since we were only interested in nouns, verbs, and adjectives, we eliminated all other words and also multiword units (e.g. a lot). After having lemmatized the data with the NLTK we obtained a list of 5910 test items which is considerably more than the usual 100 used in many previous studies (e.g. Wettler et al., 2005). 3 A graph-based approach for comput-ing word associations Unlike previous work (Wettler et al. 2005; Church & Hanks, 1990) which is described in the terminology of the well known vector space model, in the construction of the current system we had a graph-based approach in mind so we describe the system in such terms. We built up a graph on the basis of the nouns, verbs, and adjec-tives occurring in the corpus, these tokens being the nodes of the graph.2 The links (also called                                                 2  As preliminary experiments have shown, including func-tion words in the graph can create noise in the retrieval of 
44
weights, connections, or edges) between these nodes are zero at the beginning, and are incre-mented by one whenever the two connected words co-occur in the corpus as direct neigh-bors.3 Put differently, the weight of each link represents the number of times two words (nodes) co-occur in the corpus. The associations to a given stimulus word are calculated by searching the nodes which are di-rect neighbors of this stimulus word, and by ranking them according to the weights of the connections. Given a graph G=V,E with V={i,j,?,n} as its set of vertices and E as its set of edges linking pairs of nodes over V, we ex-press by N(i) the neighborhood of a node i ?V, where N(i) is defined as every j?V | ei,j ?E. 4 Results Given the way this network is built, one could expect the system to retrieve only syntagmati-cally related words, i.e. words often occurring in close proximity (e.g. blue ? sky). Yet, to our surprise, the system also retrieves many paradig-matic associations, that is, words which can sub-stitute each other (e.g. blue ? red). Table 2 shows some results. While not all computed primary responses are identical to the ones produced by humans (in the EAT), the re-sponses seem perfectly plausible. This raises the question whether the answers are within the bandwidth of variation of human associative be-havior. We measured the quality of our results by counting (for all 5910 items) the number of times the subjects participating in the creation of the EAT had given the same answer as our system. This number is 6.2 on average. In comparison, the number of other subjects giving the same an-swer as an average test person is 5.8. If the two numbers were identical, our system would be perfectly within the range of variation of the hu-man associative responses, i.e. our system's an-swers could hardly be distinguished from the ones given by a human. This is actually the case. The answers of our system are, on average, even slightly closer to the ones given by the test per-sons than the answers of a randomly selected test person.  
                                                                       associations. Hence we preferred to keep only these three categories. 3  Note that this refers to the pre-processed corpus where all stopwords have been removed. 
Stimulus Word Human Prima-ry Response Computed Pri-mary Response afraid fear person anger hate frustration baby boy mother bath water shower beautiful ugly woman bed sleep hospital bible book God bitter sweet taste black white white blossom flower white  Table 2: Comparison between human and computed associ-ations for the 10 alphabetically first words of the Kent/Ro-sanoff (1910) list.  In the following subsections we split our set of 5910 test items into three categories to check how well each one of them matches our intuition that a corpus-derived co-occurrence network can indeed simulate human associative behavior. 4.1 Word saliency Our goal is twofold: find out to what extend the saliency of a stimulus word has an effect on the homogeneity of human responses, and whether these findings can also be replicated in our com-puter simulation. To this end we divided our 5910 EAT stimu-lus words into six categories, i.e. saliency classes (SC). Saliency is defined here as the proportion of subjects producing the Primary Associative Response (PAR), this latter being the response produced by the largest number of subjects.    SC 1:  less than 10% producing the PAR (10.7%)  SC 2:  10 to 20% producing the PAR (36.0%) SC 3:  20 to 30% producing the PAR (24.3%) SC 4:  30 to 40% producing the PAR (13.3%) SC 5:  40 to 50% producing the PAR (8.0%) SC 6:  more than 50% producing the PAR (7.6%)  The percentages at the end of each line denote the proportion of words belonging to the respec-tive saliency class. All classes are reasonably well covered. Here are some representative words for each class:   SC 1:  leader, professor, yellow  SC 2:  horse, mountain, semaphore  SC 3:  chief, jungle, kiss  SC 4:  driver, monarchy, tornado  SC 5:  aid, cell, gasoline SC 6:  black, aunt, woman  
45
As can be seen from these examples, our intui-tions do not easily allow us to make predictions concerning the saliency classifications of words.  Figure 1 (blue curve) shows how well our sys-tem performs for each class. For the words in each class we counted the average number of times a human subject had come up with the same associative response as the system. It ap-pears that the system's performance is best for very salient words, performing less well in the opposite case. Note that this correlates perfectly well with the observed human associative behav-ior: Our system tends to produce the same an-swers as people for stimulus words yielding ho-mogeneous human responses. Likewise, the sys-tem?s answers tend to differ in cases where peo-ples? answers are heterogeneous. The red curve in Figure 1 shows for each sali-ency class the number of persons giving the same associative answer as an average test person. As can be seen this line is almost identical to the one representing the system's performance, which means that the system's behavior is very similar to human behavior with respect to saliency.   
   Fig. 1: Quality of our system's (blue curve) and an average test person's (red curve) performance (measured as the num-ber of matching responses found in the EAT) with respect to saliency. 4.2 Word frequency Encouraged by the findings for saliency, we con-ducted a similar experiment for word frequency. In this case the EAT stimulus words were split into frequency classes according to their corpus  frequencies in the BNC.  Since a logarithmic scale seems to be appro-priate for word frequencies (Rapp, 2005; van Heuven et al., in press), we used the following six frequency classes (FC):   FC1: 1 occurrence BNC (0.5%)  FC2: from 1 to 10 occurrences BNC (9.2%)  FC3: form 10 to 100 occurrences BNC (30.2%) FC4: from 100 to 1000 occurrences BNC (42.6%) 
FC5: from 1000 to 10000 occurrences BNC (17.3%) FC6: from 10000 to 100000 occurrences BNC (0.1%)  As can be seen from the percentages at the end of each line, extremes, i.e. very high and very low frequencies are covered only marginally.  In the first group we find words like cornuco-pia, jewelry4 and quaff, each appearing only once in the corpus, while the frequency class 6 con-tains only high frequency words such as the (auxiliary) verbs be, do, have, and make.  The results obtained for the frequency classes are shown in Figure 2.  As can be seen, the gen-eral tendency is that the results improve with de-creasing frequency. Our explanation for this is that frequent words tend to be more polysemous, and that increased ambiguity tends to yield more heterogeneous responses. For example, the am-biguous stimulus word palm is likely to evoke not only responses related to its tree sense, but also to its hand sense.  
  Fig. 2: Quality of our system's (blue curve) and an average test person's (red curve) performance with respect to fre-quency.  Whereas for mid frequency words the results for the test persons and in the simulation show a high agreement, this is not the case for high fre-quency and for low frequency words. For high frequency words (FC 6) a plausible explanation might be the sampling error due to the low sam-ple size of only 0.1% of the stimulus words in the EAT test set. However, for low frequency words the sample sizes are larger and the dis-crepancy is clearly systematic. Our explanation is that in this case we might have a systematic sampling error concerning the observed frequen-cies. The simulation has an advantage because the frequency classes were set up according to                                                 4  Note that this is the American spelling which is rare in the BNC. The British spelling is jewellery. 
46
the BNC frequencies rather than according to the subjective frequencies (= word familiarities) of the test persons. For example, the words of FC 1 are guaranteed to occur in the BNC, while it is not certain at all that the test persons ever en-countered them. This leads to a systematic bias in favor of the simulation results. 4.3 Part of speech In a last experiment we considered the results for the three parts of speech used in our system, namely nouns, verbs, and adjectives. We as-signed to each word in the EAT test set its part of speech. Syntactically ambiguous words (which can belong to several parts of speech) were as-signed to their most frequently occurring part of speech. Of the 5910 EAT items, 89.2% were classified as nouns, 2.4% as verbs, and 8.4% as adjectives.  
  Fig. 3: Quality of our system's (blue curve) and an average test person's (red curve) performance with respect to parts of the speech.  For the three categories we obtained the re-sults shown in Figure 3. The results are best for nouns and worst for verbs. Our explanation for this is once again average word ambiguity which is higher for verbs than it is for nouns. As with the saliency classes, we have again a high corre-lation between the results produced by humans and the ones produced by machine. 5 Discussion and conclusion We have presented a novel graph-based algo-rithm for the computation of word associations. The goal was to check whether and to what ex-tent an automatically built association network based on a large text corpus would yield similar results to the ones produced by humans. The re-sults were evaluated with a test set comprising all nouns, verbs, and adjectives of the EAT stimulus 
words. This test set is considerably larger than the ones used in most previous computational as-sociation studies. Contrary to what could be expected our sys-tem predicts not only syntagmatic but also para-digmatic relations. For instance, the pairs black ? white, bread ? butter and boy ? girl are cor-rectly computed. This shows that texts contain not only word pairs encoding syntagmatic rela-tions but also pairs encoding paradigmatic rela-tions. The results also show that statistical co-occurrence-based methods are suitable for tasks that traditionally were supposed to require more sophisticated symbolic approaches. In sum, our approach allows not only to cor-rectly predict thousands of associations, it also matches human performance in other respects: For the first time it was shown that the predic-tions for salient words are much better than for non-salient ones. Similarly, concerning word frequency and part of speech the simulated re-sults also closely mimic the behavior as found in the human data.  Altogether, our results provide evidence that human associative behavior as observed in the classical association experiments can be modeled by exploiting the co-occurrences of words in large text corpora. There seems to be a circulari-ty: (a) the word co-occurrences found in text and speech5 appear to be externalized forms of the associations stored in the human brain, and (b) the associations stored in the brain appear to be internalized forms of the co-occurrences as found in text and speech. This contradiction disappears as soon as we realize that time has elapsed be-tween these two events. Hence, one network may be fed by the other, and this may go on. Note that our corpus-based approach has fur-ther virtues: (a) it allows to generate associations from corpora covering particular time spans; (b) it can produce associations based on corpora covering specific topics; (c) it accounts for the fact that languages, hence associations, change over time. Think of the ideas associated with Dominique Strauss-Kahn, one of the top candi-dates before the last presidential campaign in France. While the associations prior to May 18, 2011 were probably IMF, politics or election, the ones after the Sofitel event were probably quite different, shifting towards a much more delicate topic.                                                   5  Note that the BNC also contains transcribed speech. 
47
Acknowledgments This research was supported by the Marie Curie Intra European Fellowships DynNetLAc and Au-toWordNet within the 7th European Community Framework Programme. References Bird, S.; Klein, E. and Loper, E. (2009). Natural Lan-guage Processing with Python. O'Reilley Media. Burnard, L. and Aston, G. (1998). The BNC Hand-book: Exploring the British National Corpus. Ed-inburgh: Edinburgh University Press.  Church, K.W. and Hanks, P. (1990). Word association norms, mutual information, and lexicography. Computational Linguistics 16 (1), 22?29.  Clark, H. H. (1970). Word associations and linguistic theory. In J. Lyons (Ed.), New horizons in linguis-tics (pp. 271-286). Baltimore: Penguin.  Collins, A. M. and Loftus, E. F. (1975). A spreading-activation theory of semantic processing. Psycho-logical Review 8. Vol. 82, No. 6, 407-428. Ekpo-Ufot, A. (1978). Word associations: a compara-tive study among college students in Nigeria and the United States. Journal of Cross-Cultural Psy-chology, Vol. 9(4), 455-468.  Evert, S. and Krenn, B. (2001). Methods for qualita-tive evaluation of lexical association measures. In Proceedings of the 39th Annual Meeting of the As-sociation of Computational Linguistics, Toulouse, France, 188-915.  Freud, S. (1901/1975). The psychopathology of eve-ryday life. Harmondsworth: Penguin. http://psych-classics.yorku.ca/Freud/Psycho/chap5.htm Galton, F. (1879). Psychometric experiments. Brain (2), 149-162.  Van Heuven, W.J.B., Mandera, P., Keuleers, E., & Brysbaert, M. (in press). Subtlex-UK: A new and improved word frequency database for British English. Quarterly Journal of Experimental Psychology. Hoang, H.H, Kim, S. N. and Kan, M.Y. (2009). A re-examination of lexical association measures. Pro-ceedings of the Workshop on Multiword Expres-sions, ACL-IJCNLP 2009, Suntec, Singapore, 31-39.  Istifci, I. (2010). Playing with words: a study on word association responses. The Journal of International Social Research, 3(10), 360?368 Jung, C. and F. Riklin. 1906. Experimentelle Untersu-chungen ?ber Assoziationen Gesunder. In Jung, C. G., editor, Diagnostische Assoziationsstudien, 7?145. Barth, Leipzig. 
Kent, G.H. and Rosanoff, A.J. (1910). A study of as-sociation in insanity. American Journal of Insanity, 67, 37?96, 317?390.  Kiss, G.R., Armstrong, C., Milroy, R., and Piper, J. (1973). An associative thesaurus of English and its computer analysis. In: A. Aitken, R. Beiley, N. Hamilton-Smith (eds.): The Computer and Literary Studies. Edinburgh University Press.  Michelbacher, L., Evert, S. and Sch?tze, H. (2011). Asymmetry in corpus-derived and human associa-tions. Corpus Linguistics and Linguistic Theory, Vo. 7, No. 2, 245?276.  Pecina, P., and Schlesinger, P. (2006). Combining as-sociation measures for collocation extraction. Pro-ceedings of the 21th International Conference on Computational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguis-tics (COLING/ACL 2006), Sydney, Australia, 651-658. Rapp, R. (2005). On the relationship between word frequency and word familiarity. In: B. Fisseni; H.-C. Schmitz; B. Schr?der; P. Wagner (Hg.): Sprach-technologie, mobile Kommunikation und linguisti-sche Ressourcen. Beitr?ge zur GLDV-Tagung 2005 in Bonn. Frankfurt: Peter Lang. 249?263. Rosenzweig, M. R. (1961). Comparisons among word-assocation responses in English, French, German, and Italian. The American Journal of Psy-chology, Vol. 74, No. 3, 347-360. Schwartz, B. and Reisberg, D. (1991). Learning and Memory. New York: Norton.  Seidensticker, P. (2006). Simulation von Wortassozia-tionen mit Hilfe von mathematischen Lernmodellen in der Psychologie. Dissertation an der Universit?t Paderborn.  Tamir, R. (2005). A Random Walk through Human Associations. Proceedings of ICDM 2005: 442-449.  Washtell, J.; Markert, K. (2009). A comparison of windowless and window-based computational as-sociation measures as predictors of syntagmatic human associations. Proceedings of the 2009 Con-ference on Empirical Methods in Natural Lan-guage Processing (EMNLP '09), Volume 2, 628-637 Wettler, M. and Rapp, R. (1989). A connectionist sys-tem to simulate lexical decisions in information re-trieval. In: R. Pfeifer, Z. Schreter, F. Fogelman, L. Steels (eds.): Connectionism in Perspective. Am-sterdam: Elsevier, 463?469.  Wettler, M., Rapp, R. and Sedlmeier, P. (2005). Free word associations correspond to contiguities be-tween words in texts. Journal of Quantitative Lin-guistics 12(2), 111?122.  
48
Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 1?14,
Dublin, Ireland, August 23, 2014.
The CogALex-IV Shared Task on the Lexical Access Problem 
 
 
Reinhard Rapp 
Aix-Marseille Universit? 
13288 Marseille 
France 
reinhardrapp@gmx.de 
 
Michael Zock 
Aix-Marseille Universit? 
13288 Marseille 
France 
michael.zock@lif.univ-mrs.fr 
 
 
Abstract 
The shared task of the 4th Workshop on Cognitive Aspects of the Lexicon (CogALex-
IV) was devoted to a subtask of the lexical access problem, namely multi-stimulus as-
sociation. In this task, participants were supposed to determine automatically an ex-
pected response based on a number of received stimulus words. We describe here the 
task definition, the theoretical background, the training and test data sets, and the 
evaluation procedure used for ranking the participating systems. We also summarize 
the approaches used and present the results of the evaluation. In conclusion, the out-
come of the competition are a number of systems which provide very good solutions to 
the problem. 
1 Introduction 
In the framework of CogALex-IV (co-located with COLING 2014 in Dublin) we invited colleagues to 
participate in a shared task devoted to the lexical access problem in language production. Our aim was 
to make a quantitative comparison between different systems based on a shared set of data and using 
the same evaluation metric. 
The lexical access problem is very relevant for this workshop series as the quality of a dictionary 
depends not only on its coverage, but also on the accessibility of the information. Put differently, a 
crucial point of dictionary development is word access by the language producer, an often neglected 
aspect. Access strategies vary with the task (text understanding versus text production) and the knowl-
edge available at the very moment of consultation (words, concepts, speech sounds). Unlike readers 
who look for meanings, writers start from them, searching for the corresponding words. While paper 
dictionaries are static, permitting only limited strategies for accessing information, their electronic 
counterparts promise dynamic, proactive search via multiple criteria (meaning, sound, related words) 
and via diverse access routes. Navigation takes place in a huge conceptual lexical space, and the re-
sults are displayable in a multitude of forms (e.g. as trees, as lists, as graphs, or sorted alphabetically, 
by topic, by frequency).  
Given a great number of possibilities of approaching the lexical access problem, we felt that for a 
competition it was necessary to narrow down the choices in order to be able to come up with a clear 
task definition. Therefore the CogALex shared task focused on a crucial subtask, namely multi-stimu-
lus association. What we mean by this is the following. Suppose we were looking for a word matching 
the following description: tasty nut with hard shell originally from Australia, but could not retrieve the 
corresponding and intended form macadamia. This is the well known tip-of-the-tongue problem where 
an author knows the word but fails to access its form, even though he is able to retrieve certain fea-
tures of it (meaning, sound, syllables, ...). People being in the tip-of-the-tongue state always remember 
something concerning the elusive word (Brown & Mc Neill, 1966). This being so, it would be nice to 
have a system accepting this kind of information as input, and which then proposes a number of can-
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer 
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/. 
1
didates which ideally should contain the target word. Given the above example, we might enter tasty, 
nut, hard, shell, and Australia, and the system would be supposed to come up with one or several as-
sociated words such as macadamia, walnut, cashew, or coconut. 
This paper is meant to provide an overview on the shared task and on its results. It is organized as 
follows: Section 2 gives some background concerning the theory of word finding. Section 3 describes 
the task definition and Section 4 the training and the test data sets and the evaluation procedure. Sec-
tion 5 lists the participating systems, tries to characterize the different approaches, and presents the 
results. For all systems but one, further details are given in the separate papers (in these proceedings) 
as provided by the members of the participating groups. Section 6 summarizes the conclusions. 
2 The problem of word finding 
One could imagine many kinds of shared tasks within the framework of the CogALex workshop. Yet, 
we have focused here on a very specific problem, namely word finding. To this end we have defined a 
task demanding participants to come up with a system able to compute reversed word associations. 
While in the standard association experiment people are asked to provide the associations coming to 
their mind given some stimulus (prime), we have reversed this situation. Given a set of associations, 
the system was supposed to predict its trigger. More concretely speaking, participants were given 2000 
sets of words, each set containing five words. The task was to determine automatically the sixth ele-
ment, i.e. the prime (or stimulus), evoking the five words. One could object that this task does not 
really address the word access problem or its solution, but this is not quite so as we will try to show.  
In particular, it seems quite reasonable to claim that an association network with bi-directional links 
(see Rapp, 2014) is a suitable resource to support word ?finding?. Since words are connected via bi-
directional links either of the connected items can be the source or the target during the search (or dur-
ing navigation). 
Although systems designed for the shared task can have many applications (see Section 6), a proto-
typical one is the tip-of-the-tongue problem, which is a special case (yet a quite frequent one) of word 
access. So let us briefly describe this problem and the steps needed to overcome it.  
One of the most vexing problems in speaking or writing is that one knows a given word, yet fails to 
access it when needed. Suppose, you were looking for a word expressing the following ideas: superior 
dark coffee made of beans from Arabia, but could not retrieve the intended word mocha. What will 
you do in a case like this? You know the meaning, you know how or when to use the corresponding 
word, and in principle you even seem to know its spoken or written form, since you have used it some 
time ago (for more details, see Zock et al., 2010). Yet for some unknown reason you simply cannot 
access it at the very moment of writing or speaking. The just described situation is called anomia or 
dysnomia, which in less technical terms means that a person has a word finding problem. This case is 
often assimilated with the tip-of-the-tongue phenomenon, which technically speaking is not quite cor-
rect, but this shall not concern us here.1 
To resolve the problem, one can think of many strategies. For example, one can ask somebody, by 
providing him some hints (cues) hoping that the person can guess the elusive word. Such hints could 
take various forms like a description (definition or circumlocution), an association or the role played 
by the target word, say, instrument used for eating Chinese food when searching for chopsticks. Of 
course, one can also search in an external resource (dictionary). Unfortunately, most dictionaries are 
primarily designed for the language recipient and not particularly well suited to assist the language 
producer. And even if there are quite a number of promising proposals,2 a lot more could be done 
these days with the help of corpora, computers, and language technology. 
                                                 
1
 The tip-of-the-tongue phenomenon (http://en.wikipedia.org/wiki/Tip_of_the_tongue) is a weak form of an ano-
mic aphasia (http://en.wikipedia.org/wiki/Anomic_aphasia). Yet, unlike the latter, it is only momentary. It is 
characterized by the fact that the person (speaker/writer) has only partial access to the word s/he is looking for. 
The typically lacking parts are phonological (syllables, phonemes). Since all information except this last one 
seems to be available, and since this is the one preceding articulation, we say: the word is stuck on the tip of the 
tongue. 
2
 Think of Roget?s Thesaurus (Roget, 1852), WordNet (Fellbaum, 1998; Miller et al., 1990), Longman?s Lang-
uage Activator (Summers, 1993), the Oxford Reverse Dictionary (Edmonds, 1999) or OneLook which combines 
a dictionary, WordNet, and an encyclopedia, Wikipedia (http://onelook.com/reverse-dictionary.shtml). 
2
This being said, to build a dictionary for the language producer, certain provisions must be made, 
and it is easy to understand why. When searching a word form (target), the dictionary user will cer-
tainly not search in the entire resource. He will rather navigate in a substantially smaller subset (Zock, 
2014; Zock & Cristea, 2014). The question is, how to build this reduced space and how to support then 
navigation. We will deal here mainly with this first step of search space reduction as it is crucial and 
this is where associations come into play (Deese, 1965; Cramer, 1968). 
The experiments concerning the tip-of-the-tongue problem have systematically shown (Aitchison, 
2003; Brown, 1991; Brown & McNeill, 1996) that users being in this state always know ?something? 
concerning the target word: fragments of the meaning, origin, number of syllables, etc. This being so, 
any of this could be used to guide the search. 
Suppose we focused only on the semantic aspects. In such a case it is reasonable to assume that the 
target form can be found on the basis of its defining elements (bag of the words contained in the defi-
nition). While not being perfect, this works quite well (Dutoit & Nugues, 2002; El-Kahlout & Oflazer, 
2004; Mandala et al., 1999; Michiels, 1982). Actually, even Google - although not designed for this - 
is able to recover in many cases the elusive word. Just try the following example, spring, typically 
found in Iceland or in the Yellowstone National Park, discharging hot water and steam, and chances 
are that you will find the target word geyser. Although not perfect, this is nevertheless quite useful. 
However, this represents only one kind of cognitive state (knowledge of the definition), and this is cer-
tainly neither the only one nor the most frequent one. Indeed, there are many situations where it is hard 
to come up with a precise definition, and in this case other types of information are used to initiate 
search, for example, co-occurrences, associations, etc. Hence, if our target is mocha it may be accessi-
ble not only via its definitional terms (coffee, beverage, ...) but also via any of its associates: black, 
hot, drink, Java, etc. This is the point where associations come to the centre stage. 
Some of the related recently published work has been cited in Rapp (2014), and some other is men-
tioned by the authors participating in the shared task. Therefore, let us focus here primarily on some of 
the earlier and nowadays often overlooked related work. 
Associative networks have been very popular in Artificial Intelligence at the end of the nineteen-
seventies (Findler, 1979). They were proposed to be used for many tasks such as word sense disam-
biguation, finding brand names, reading between the lines, subliminal communication, brainstorming, 
and supporting word finding. That is, the tip-of-the-tongue problem is but one of the many possible 
applications. 
The study of associative networks was motivated by the goal to understand the organization of the 
human memory and the mental lexicon. This led to the building of lexical graphs like WordNet (Fell-
baum, 1998), the study of the tip-of-the-tongue problem (Brown & Mc Neill, 1966), error analysis 
(Fromkin, 1980, 1973) and priming experiments. Priming is said to take place if exposure to one 
stimulus increases significantly the response to another. Meyer and Schvaneveldt (1971) showed in 
their seminal experiments that people were faster in deciding that a string of letters is a word when it 
was followed by an associatively or semantically related word. For example, nurse is recognized more 
quickly following doctor than following bread. These findings supported also the idea of activation 
spreading as a method of access or search (Collins & Loftus, 1975). 
Associative networks can be considered as a special type of semantic network which were intro-
duced by Richens (1956) and by Ceccato (1956) for quite a different purpose. They were meant to 
serve as an interlingua for machine translation. These knowledge representation structures were then 
further developed in the sixties by Simmons (1963) and Quillian (1963, 1966, 1967, 1968, 1969). 
They finally became famous due to the work done by Quillian and two psychologistst (Collins & Quil-
lian, 1969 & 1970 and Collins & Loftus, 1975). Note that semantic networks can represent language at 
various levels of granularity: word, sentence (Sowa, 1984) or discourse (Mann & Thomson, 1988). 
Also, and very relevant for us here is the fact that at the word level, they can represent its semantics, 
i.e. meaning (Nogier & Zock, 1992), or its place withing the global structure of the mental lexicon 
(Miller, 1995; Aitchison, 2003; Bonin, 2004). In this latter case words are connected by associations 
rather than by deep-case roles, and the resulting graphs show word neighborhood (Schvaneveldt, 
1989). The fact that the mental lexicon exhibits ?small world? characteristics (http://en.wikipedia.org/ 
wiki/Small-world_network) has been shown by Vitevitch (2008) and by Sporns and colleagues (2004). 
For the construction of associative networks knowledge about associations is required. Such knowl-
edge can be obtained in two different ways. One is to ask people what a given term (say cat) evokes in 
3
their mind (say dog, mouse, etc.). Another option is to look at word co-occurrences in corpora, and to 
derive the associations from them (which, strictly speaking, pre-supposes that the human brain is also 
doing this). For the purpose of having a gold standard for the shared task, by using the EAT, we have 
opted for the first possibility. In contrast, most systems constructed by the shared task participants rely 
on the second.  
3 Task definition 
The participants received lists of five given words (primes) such as circus, funny, nose, fool, and Coco 
and were supposed to compute the word most closely associated to all of them. In this case, the word 
clown would be the expected response. Table 1 shows some more examples. 
 
Given Words Target Word 
gin, drink, scotch, bottle, soda whisky 
wheel, driver, bus, drive, lorry car 
neck, animal, zoo, long, tall giraffe 
holiday, work, sun, summer, abroad vacation 
home, garden, door, boat, chimney house 
blue, cloud, stars, night, high sky 
 
Table 1. Lists of given words together with their targets. 
 
We provided a training set of 2000 sets of five input words (multiword stimuli), together with the ex-
pected target words (associative responses). The way how the datasets were produced will be de-
scribed in the next section. The participants had about five weeks to train their systems on this data. 
After the training phase, we released a test set containing another 2000 sets of five input words, but 
without providing the expected target words.  
The participants were given five days to run their systems on the test data,3 with the goal of predict-
ing the target words. For each system, we compared the results to the expected target words and com-
puted an accuracy based on the number of exact string matches (but without taking capitalization into 
account). The participants were invited to submit a paper describing their approach and their results.  
For the participating systems, we distinguished two categories:  
1) Unrestricted systems. They could use any kind of data to compute their results.  
2) Restricted systems based on ukWaC: These systems were only allowed to draw on the freely 
available ukWaC corpus (Ferraresi et al., 2008)4 in order to extract information on word asso-
ciations. The ukWaC corpus comprises about 2 billion words of web texts and provides also 
lemma and part-of-speech information. 
Participants could compete in either category or in both. They were encouraged to further improve on 
their results outside of the competition after the deadline, and to describe these advances in their pa-
pers (in these proceedings). 
4 Training and test data sets and evaluation procedure 
The training and the test data sets were both derived from the Edinburgh Associative Thesaurus (EAT; 
Kiss et al., 1973). The EAT lists for each of 8400 stimulus words up to 100 associative responses as 
obtained from test persons who were asked to produce the word coming spontaneously to their mind. 
As the EAT uses uppercase characters only, and as this might not suit everybody's needs, we de-
cided to modify its capitalization. For this purpose, for each word occurring in the EAT, we looked up 
which form of capitalization showed the highest occurrence frequency in the British National Corpus 
(Burnard & Aston, 1998). By this form we replaced the respective word. E.g. DOOR was replaced by 
                                                 
3
 The exact dates were: training data release:  March 27, 2014; test data release: May 5, 2014; final results due:  
May 9, 2014. 
4
 http://wacky.sslmit.unibo.it/doku.php?id=corpora. 
4
door, and GOD was replaced by God. This way we hoped to come close to what might have been pro-
duced during compilation of the EAT if case distinctions had been taken into account.5 Since this 
method is not perfect, e.g. words often occurring in sentence initial position might be falsely capital-
ized, we did some manual checking, but cannot claim to have achieved perfection. 
Next, for each stimulus word, only the top five associations (i.e. the associations produced by the 
largest number of test person) were retained, and all other associations were discarded. The decision to 
keep only a small number of associations was motivated by the results of Rapp (2013) which indicate 
that associations produced by very few test persons tend to be of arbitrary nature. We also wanted to 
avoid unnecessary complications, which is why we decided on a fixed number, although the exact 
choice of five is of course somewhat arbitrary. 
From the remaining dataset we removed all items which contained non-alphabetical characters. We 
also removed items which contained words that did not occur in the BNC. The reason for this is that 
quite a few of them are misspellings. By these measures, the number of items was reduced from ini-
tially 8400 to 7416.  
From these we randomly selected 4000 items. 2000 of these were used as our training data set. The 
remaining 2000 were used as our test data set, but of course for the test set we removed the stimulus 
words. Tables 2 and 3 show the alphabetically first 20 items in each data set.6 
The participating teams were asked to submit a list of 2000 words reflecting their predictions con-
cerning the 2000 items of the test data set. For evaluation, we simply compared these 2000 words to 
the expected results (as taken from the EAT) by counting the number of exact matches, with the only 
flexibility that word capitalization was not taken into account. 
There are a number of reasons why it was very difficult for the teams to get the target words exactly 
right: 
1) In many cases, the given words might almost quite as strongly point to other target words. For 
example, when given the words gin, drink, scotch, bottle, and soda, instead of the target word 
whisky the alternative spelling whiskey should also be fine, and possibly some other beverages 
might also be acceptable. 
2) The target vocabulary was not restricted in any way, so in principle hundred thousands of 
words had to be considered. 
3) Although most of the target words were base forms, the training and the test sets also contain a 
good number of cases where the target words were inflected forms. Of course it is almost im-
possible to get these inflected forms exactly right. 
Because of these difficulties we expected low performance figures (e.g. below 10%) in the competi-
tion7 and were positively surprised by some of the actual results (see Section 5). 
Concerning point 1 (other acceptable solutions) our data source did not provide any, so it was not 
practical for us to try to come up with alternative solutions in the chosen reverse association frame-
work. 
Concerning point 2 (restriction of target vocabulary), of course all teams had to make assumptions 
about the underlying vocabulary, as it is already difficult to fix boundaries for the English vocabulary, 
and occasionally even foreign words or names might occur as associations. In this respect all results 
have to be taken with caution, as some teams might have been more lucky than others in making good 
guesses concerning the target vocabulary.8 
 
                                                 
5
 Note that the participants of the shared task were nevertheless free to discard all case distinctions if their ap-
proach would not require them. During evaluation, case distinctions were not taken into account. 
6
 From http://pageperso.lif.univ-mrs.fr/~michael.zock/CogALex-IV/cogalex-webpage/pst.html the full data sets 
can be downloaded 
7
 Note that the results of up to 54% reported in Rapp (2014) were obtained using different data sets and severely 
restricted vocabularies, so these cannot be used for comparison. 
8
 For such reasons we had requested to include such information in the papers. We concede that a competition 
with a pre-defined target vocabulary might have been more fair by reducing the influence of chance. But we 
were also very interested in the approaches on how to limit this vocabulary, so this was an important part of the 
shared task. 
5
 Target Word Given Words 
a  B the alphabet an man 
abound  plenty many lots around leap 
about  around turn round now time 
above  below high over sky all 
abrasive  rough sandpaper rub cutting hard 
absence  away fonder illness leave presence 
absent  away minded gone present ill 
absurdity  stupid ridiculous mad stupidity clown 
accents  dialects language foreign speech French 
accordion  music piano play player instrument 
accountant  money chartered clerk office turf 
accrue  gather gain money acquire collect 
achieve  nothing attain gain success win 
acids  alkalis alkali bases burn science 
acknowledged  letter receipt accepted received replied 
acquaintance  friend know person friends casual 
acquired  got obtained gained taste bought 
acrid  smell bitter acid smoke dry 
actions  words deeds movement movements reactions 
actual  real fact happening truth exact 
 
Table 2: Extract from the training set. 
 
 
Given Words 
able incapable brown clever good 
able knowledge skill clever can 
about near nearly almost roughly 
above earth clouds God skies 
above meditation crosses passes rises 
abuse wrong bad destroy use 
accusative calling case Latin nominative 
ache courage blood stomach intestine 
ache nail dentist pick paste 
aches hurt agony stomach period 
action arc knee reaction jerk 
actor theatre door coach Act 
actress stage play man theatre 
addict pot store hash medicine 
Africa Bible priest abroad doctor 
again fresh afresh old morning 
against angry bad fight hostile 
age time epoch period years 
aid assistant kind mother good 
aid eyes aids see eye 
 
Table 3: Extract from the test set. The respective (undisclosed) target words are shown in Table 4. 
 
 
6
Concerning point 3 (matches of inflected forms) the ETS team had correctly pointed out that perform-
ance figures would significantly improve if matches with alternative inflected forms of the same word 
would also be counted as correct. For this purpose, the team kindly provided expanded versions of the 
target words for the training and for the test data set which were obtained using an in-house morpho-
logical tool. Table 4 shows the respective data for the alphabetically first 20 target words of the test 
data set. As we assumed that only the absolute but not the relative performance of the systems (rank-
ing in competition) would be affected by this measure, we decided not to include this in the standard 
procedure, but nevertheless forwarded the data to all teams and encouraged them to conduct such an 
evaluation by themselves outside of the competition (and some actually did so). Let us nevertheless 
point out our main concerns:  
1) Many target words are ambiguous, and in some cases the range of inflected forms depends on 
the way how the ambiguity is resolved. Assume, for example, that the target word form is can 
which might be an auxiliary verb or a noun. In this case, the inflected form cans in the ex-
panded list would only be correct if the target word can referred to the noun, but not if it re-
ferred to the auxiliary verb (see also Lezius et al., 1998). Of course one could try to disam-
biguate the target words based on the given words. But this is a non trivial task likely to be er-
ror prone and possibly controversial. 
2) In principle, such considerations might also apply to the given words, i.e. they could also be 
expanded. But in this case the disambiguation task is even more difficult as it is not clear what 
should be considered as context (i.e. as clues for disambiguation). 
Although point 2 could be left to the participants, our aim was to avoid any such complications, in or-
der to keep the focus on the core part of the shared task. So, as far as we as organizers were concerned, 
we decided not to consider inflectional variation. 
Let us now comment on the overall character of the shared task. It should be noted that this task is 
actually the reverse association task as described in Rapp (2013, 2014). That is, the shared task par-
ticipants were supposed to consider the associations from the EAT as their given words, and their task 
was to determine the original stimulus words.  
 
Word Morphological expansions 
capable  
ability abilities 
approximately 
 
heavens heaven 
transcends transcending, transcend, transcended 
misuse misusing, misused, misuses 
vocative vocatives 
guts gut, gutted, gutting 
tooth tooths 
pains pain, paining, pained 
reflex reflexes 
stage staging, staged, stages 
actor actors 
drug drugging, drugs, drugged 
missionary missionaries 
anew  
antagonistic  
era eras 
helper helpers 
visual visuals 
 
Table 4: Morphological expansions of the first 20 words in the test data set. 
 
7
However, we had not disclosed the nature of the data until after the competition mainly for the follow-
ing reasons: 
 
1) To avoid reverse engineering approaches based on the EAT or similar association norms. 
2) To avoid leading participants in a particular direction. For us it seemed most important to obtain 
approaches as diverse as possible. And as this was the first shared task devoted to multi-
stimulus associations, we thought that this would be a unique opportunity to obtain contribu-
tions as unbiased as possible. 
 
On the other hand we had concerns about the fairness of not disclosing the nature of the data. Firstly, 
some of the participants might discover its origin and thus possibly have an advantage. Secondly, it is 
not clear in how far the reverse association task is prototypical enough for the lexical access problem 
as to assume that in terms of relative system performance the two tasks are comparable. In any case, 
concerning the lexical access problem we saw no chance of acquiring large scale data sets within the 
given time frame, so it was clear that this was not feasible.  
When, after the competition, we disclosed the nature of the data, we invited the participants to com-
ment on these issues in their papers, and it was very interesting for us to learn about the different 
views.  
5 Participating systems and results 
Altogether 15 teams expressed their interest to participate in the shared task. Of these, ten teams actu-
ally submitted results, of which one (BRNO) participated in both tracks (ukWaC and unrestricted), and 
another (SAAR) provided two solutions for the unrestricted track. The teams who submitted results 
are listed in Table 5, where each team is assigned a short Team ID which is derived from the institu-
tion names. In Table 6 for each team we make an attempt to give short characterizations of the ap-
proaches and the resources used. 
Most approaches are variants of analyzing word co-occurrence statistics as derived from large text 
corpora. Several teams, among them the best performing ones, use for this purpose the open source 
tool Word2Vec which provides two neural network-based model architectures for computing continu-
ous vector representations of words from very large data sets (Mikolov, 2013a; Mikolov, 2013b). In 
contrast, the RACAI team uses WordNet relation chains, a method which makes absolutely sense, but 
seems to severely suffer from data sparseness issues (i.e. there are much fewer WordNet relations be-
tween words than there are non-random word co-occurrences within large corpora). This finding is 
confirmed by the BRNO and UBC teams who tried out both approaches (corpus-based and WordNet-
based) and came to the conclusion that the corpus-based approach performed considerably better. 
Let us emphasize that we consider this type of findings a valuable output of the shared task and 
therefore are very grateful to the teams who pursued the WordNet-based approach that they shared 
these results although they were all well aware that, despite excellent scientific work, the respective 
performance figures were not very competitive. 
Table 7 shows the results of the competition, ranked according to the accuracy of the results, and 
indicating the respective track (ukWAC or unrestricted). As some teams (AMU, QUT, SOEN, ranks 7 
to 9) could not quite make it for the deadline, they were granted an extension of three days. On the top 
four positions are submissions who all used the above mentioned Word2Vec tool, indicating that this 
software is well suited for this task. Note that the winning system (IIITH) opted for the CBOW (con-
tinuous bag-of-words) architecture, whereas the other three opted for the skip-gram architecture. This 
might be an explanation for the differences in the results. However, this must be further analyzed as 
there are also other differences, including the assumptions constraining the target vocabulary, which, 
as described in Section 4, is an important issue. For example, the IIITH team used a frequency thresh-
old of 25 while making word vectors using Word2Vec. In addition, when calculating PMI (pointwise 
mutual information) associations, a frequency threshold (for bigrams) of 3 was used (see sections 4.1 
and 4.2 of their paper).  
It should be mentioned that, like some others (see e.g. the papers by the ETS and by the RACAI 
teams), the IIITH team was able to improve on their results after the shared task deadline. Whereas for 
their submission they had used a re-ranking procedure based on point-wise mutual information (PMI), 
later on they used weighted PMI as their association measure. This improved their results from 
8
30.45% to 34.9%. Likewise, the ETS team could improve their results from 14.95% to 18.90%. And 
the RACAI team (who used a WordNet-based approach) was able to almost double their results from 
1.50% to 2.95%. 
 
Team ID Affiliation Team members / Authors of papers 
AMU Aix-Marseille University, France Gemma Bel-Enguix 
BRNO Brno University of Technology, Czech Republic Lubomir Otrusina, Pavel Smrz 
ETS Educational Testing Service, Princeton, USA Michael Flor, Beata Beigman Klebanov 
IIIT International Institute of Information Technology (IIIT), Hyderabad, India Urmi Gosh, Sambhav Jain, Soma Paul 
LEIPZIG University of Leipzig, Germany 
Rico Feist, Daniel Gerighausen, Manuel 
Konrad, Georg Richter, Thomas Eckart, 
Dirk Goldhahn, Uwe Quasthoff 
QUT Queensland University of Technology, Brisbane, Australia Laurianne Sitbon, Lance De Vine 
RACAI Romanian Academy Research Institute for Artificial Intelligence, Bukarest, Romania 
Catalin Mititelu, Verginica Barbu Mit-
itelu 
SAAR Saarland University, Germany Asad Sayeed (no paper) 
SOEN Universities of Stuttgart, Osnabr?ck, and Erlangen-N?rnberg, Germany Gabrielle Lapesa, Stefan Evert 
UBC University of the Basque Country, Spain Josu Goikoetxea, Eneko Agirre, Aitor Soroa 
 
Table 5: Participating teams. 
 
Team ID Approach Resources used 
AMU Co-occurrence-based lexical graph British National Corpus 
BRNO Word2Vec from Python package GenSim (skip-gram architecture) ukWaC, ClueWeb12, WordNet 
ETS 
Aggregating co-occurrence-based 
association strengths to individual 
cue words 
English Gigaword 2003, ETS in-
house corpus 
IIITH Word2Vec using CBOW architec-ture and re-ranking ukWaC 
LEIPZIG Sum of co-occurrence-based sig-
nificance values Leipzig corpora collection 
QUT 
Own implementation similar to the 
Word2Vec package (skip-gram 
architecture) 
ukWaC 
RACAI Shortest WordNet relations chain 
and maximum entropy modeling 
Princeton WordNet, Google n-
gram corpus 
SAAR Co-occurrence-based ukWaC and others 
SOEN 
Ranking according to average (co-
occurrence-based) association 
strength or according to distri-
butional similarity 
ukWaC 
UBC 
Word2Vec (skip-gram architec-
ture), random walks, personalized 
PageRank 
Google news corpus, Wikipedia, 
WordNet 
 
Table 6: Overview on approaches and resources. 
9
To give a rough idea on how much the results can be improved when inflectional variants are toler-
ated during evaluation (see Section 4), let us mention that the IIITH team did so. This way their results 
improved from 34.90% (as obtained after the deadline) to 39.55. Likewise, in the case of the ETS team 
the results improved from 14.95% to 20.25%. (For details see the respective contributions in these 
proceedings.) 
Concerning the two tracks of the competition, namely ukWaC and unrestricted, it appears that the 
ukWaC corpus contains already enough information to solve the task. Evidence for this is provided by 
the BRNO team which submitted results in both tracks and where the improvements were minimal 
(19.85% vs. 19.65%). Another indication is that, unexpectedly, the winning IIITH team was in the 
ukWaC track. 
For details on all other approaches (except SAAR) see the papers provided by the participating 
teams in these proceedings. Ideas that occurred when discussing the shared task with other colleagues 
were that Adam Kilgarriff's SketchEngine might be a useful tool for solving the lexical access problem 
(thanks to Eva Schaeffer-Lacroix for pointing this out), and that it may be useful to take syntax into 
account (thanks to Eric Wehrli and Luka Nerima). The latter would be in analogy to the generation of 
distributional thesauri where working with parsed rather than raw corpora has been shown to lead to 
very good quality (see e.g. Pantel & Lin, 2002). This way, rather than taking all word co-occurrences 
into account, the focus can be laid on selected relations between words, such as e.g. head-modifier or 
subject-object relations.  
 
Rank Team ID Accuracy (%) Track 
1 IIITH 30.45 ukWAC 
2 BRNO 19.85 unrestricted 
3 BRNO 19.65 ukWaC 
4 UBC 16.35 unrestricted 
5 ETS 14.95 unrestricted 
6 LEIPZIG 14.05 unrestricted 
7 SOEN 13.10 ukWaC 
8 AMU 9.10 unrestricted 
9 QUT 4.25 ukWaC 
10 SAAR 3.50 unrestricted 
11 SAAR 2.60 unrestricted 
12 RACAI 1.50 unrestricted 
 
Table 7: Results of the shared task. 
6 Discussion and conclusions 
For the shared task of finding associations to multiple stimuli, by the participants accuracies of up to 
30% (35% after the deadline) were reported. Given the very conservative evaluation procedure (see 
Section 4) which relies on exact matches and does not give any credit to alternative solutions, this is a 
very good result which considerably exceeded our expectations. Although we do not have comparative 
figures on human performance, our guess is that humans would not be able to do much better on this. 
So, in some sense, it seems that we have rather perfect results. 
But what does this mean? Is there any psycholinguistic relevance? And is the task which we ad-
dressed here of any relevance for practical work in computational linguistics? 
Let us first discuss the question of psycholinguistic relevance. In Rapp (2011) we have argued that 
human language intuitions are based on the detection, memorization, and reproduction of statistical 
regularities in perceived language. But we have only discussed this for single words. Now we can do 
so for multiword stimuli. And it seems that the same mechanisms that apply to single word stimuli are 
also valid in the case of multiwords. Apparently, from a relatively limited corpus such as ukWaC, in-
tuitively plausible associations to an almost unlimited number of multiword stimuli can be derived. 
This is in analogy to human language acquisition: Due to limitations of the input channel a person can 
only perceive a few hundred million words during lifetime. But this limited information seems to suf-
fice to have intuitions on almost anything that is language related. 
10
This is a contradiction only on first glance: Apparently, language is a highly compressed form of in-
formation where all co-occurrences of words or word-sequences count (and were literally counted by 
most algorithms!). Therefore its information content is far higher than it may appear, and this provides 
a solution to the often discussed argument concerning the poverty of the stimulus (Landauer & Du-
mais, 1997). With regard to language, it seems there simply is no poverty of the stimulus, but instead 
the human language is a highly condensed form of extremely rich information. As the capacities of the 
input and the output channels are very limited, evolution was probably forced to optimize on this. 
As the systems participating in the shared task can simulate human intuitions concerning zillions of 
possible multiword stimuli, it is likely that their algorithms grasp some of the essence that governs the 
respective inference processes taking place in human memory. In particular, they provide evidence 
that human association processing is also co-occurrence based, and that this not only applies to asso-
ciations to single stimulus words as shown by Wettler et al. (2005), but also to associations concerning 
multiple stimuli. 
Concerning the practical relevance of the work, our feeling is that such systems will be useful addi-
tions to many language-related tasks requiring human-like intuitions for the reason that human lan-
guage intuitions seem to be based on associative learning. Let us come up with some examples of pos-
sible applications: 
1) Augment associative resources such as the EAT. 
2) Tip-of-the-tongue problem: Recall elusive words.  
3) Lexical access: Rather than relying on alphabetical order, encyclopedias and dictionaries can be 
accessed associatively (e.g. president of Poland ? Bronislaw Komorowski). 
4) Generating thesauri of related words: Related words in the sense of Pantel & Lin (2002) are 
second order associations. The words related to a given word can be determined by computing 
its associations, and by then computing the multi-stimulus associations to these. 
5) Question answering: Questions can be considered as multiword stimuli, answers as their asso-
ciations (e.g. height of Eiffel Tower ? 324 m). 
6) Paraphrasing: The meaning of a phrase can be characterized by the associations resulting from 
its content words. Paraphrases are likely to lead to similar associations. 
7) Search word generation in information retrieval: Keywords used in search queries can be aug-
mented with relevant other keywords. 
8) Advertising: The effect of an advertisement can be described by the associations evoked by the 
words that are used in it. 
9) Word sense induction and disambiguation: Word contexts can be replaced by their multi-stimu-
lus associations. This way the effects of word choice will be reduced when clustering contexts. 
10) Machine translation: Translations can be seen as associations across languages (seed dictionary 
is required, see below). 
Of course, most of the above has already been dealt with using other approaches. But, when looking at 
the respective (statistical) algorithms more closely, it seems often the case that researchers have intui-
tively chosen statistics which show some analogy to multi-stimulus associations. So what we suggest 
here is not entirely new. We nevertheless hope that the current framework can be useful. Firstly, it 
draws a connection to psycholinguistic evidence. And secondly, as done in the shared task, it allows to 
optimize the core algorithm independently of particular applications.  
To be a bit more explicit, let us try to sketch a possible agenda of some future work which we 
would be happy to see: Let us start from the hypothesis that the meaning of a short sentence or phrase 
can be characterized by the vector resulting from taking its content words as multiword stimuli, and by 
computing their associations. For example, given the sentence John laughed in the circus, we would 
take John, laugh, and circus as our stimulus words, and the resulting association vector could be ex-
pected to have high values at its positions corresponding to clown, nose, and fun. For conciseness, let 
11
us call this type of vector meaning vector.9 Now let us look at the sentences Someone walks across the 
border and A person passes customs. The two sentences do not share a single word. But the associa-
tions derived from them should be nevertheless similar, because associations such as toll, officer, or 
country can be expected to come up in both cases. That is, their meaning vectors should be similar, 
and this similarity can be quantified e.g. by computing the cosine similarity between them. We thus 
have a method which allows us to measure the similarity between sentences in a way that to some ex-
tend takes their meanings into account.  
Finally, we can try to cross language barriers and make the step to association-based machine trans-
lation (ABMT). To translate a source language phrase, we compute its meaning vector. Presupposing 
that we have a basic dictionary, in analogy to Rapp (1999) we can translate this meaning vector into 
the target language.10 Further assuming that we already know the meaning vectors of a very large 
number of target language phrases, we next select the target language meaning vector which is most 
similar to the source language meaning vector. The respective target language phrase can be consid-
ered to be the translation of the source language phrase. Optionally, to improve translation quality, the 
target language phrase can be modified by adding, removing, substituting, or reordering words with 
the aim of improving the similarity between the meaning vectors of the source and target language 
phrases. 
Acknowledgments 
This work was supported by a Marie Curie Intra European Fellowship within the 7th European Com-
munity Framework Programme. We would like to thank George R. Kiss and colleagues for creating 
the Edinburgh Associative Thesaurus, and Michael Wilson for making it publicly available. Many 
thanks also to Adriano Ferraresi and colleagues for providing the ukWaC corpus, and to the partici-
pants of the shared task for their contributions and comments, as well as for the pleasant cooperation. 
References 
Aitchison, J. (2003). Words in the Mind: an Introduction to the Mental Lexicon. Oxford, Blackwell.  
Bonin, P. (2004). Mental Lexicon: Some Words to Talk about Words. Nova Science Publishers.  
Brown, A. (1991). A review of the tip of the tongue experience. Psychological Bulletin, 10, 204?223.  
Brown, R. & Mc Neill, D. (1966). The tip of the tongue phenomenon. Journal of Verbal Learning and Verbal 
Behavior, 5: 325?337.  
Burnard, L.; Aston, G. (1998): The BNC Handbook: Exploring the British National Corpus with Sara. Edin-
burgh: University Press. 
Ceccato, S. (1956). La grammatiea insegnata alle machine. Civilt? delle Machine, Nos. 1 & 2. 
Collins, A.M. & Quillian, M.R. (1969). Retrieval time from semantic memory. Journal of verbal learning and 
verbal behavior 8 (2): 240?247.  
Collins, A.M. & Quillian, M.R. (1970). Does category size affect categorization time? Journal of verbal learning 
and verbal behavior 9 (4): 432?438. 
Collins, A.M. & Loftus, E.F. (1975). A spreading-activation theory of semantic processing. Psychological Re-
view 8.  
Cramer, P. (1968). Word Association. Academic Press, New York. 
Deese, J. (1965). The structure of associations in language and thought. Johns Hopkins Press. Baltimore 
                                                 
9
 As this is a bag-of-words approach which does not take syntax into account, of course we do not claim that 
such a vector can grasp all of a sentence's meaning. 
10
 Note that gaps in dictionary coverage can be typically tolerated in such a setting as associations tend to be 
common words. That is, in principle the method allows to correctly translate words which are not in the diction-
ary. This is a property giving it some plausibility as a model for the cognitive processes underlying human trans-
lation. 
12
Dutoit, D. and P. Nugues (2002): A lexical network and an algorithm to find words from definitions. In Frank 
van Harmelen (ed.): ECAI2002, Proceedings of the 15th European Conference on Artificial Intelligence, Ly-
on, 450?454. 
Edmonds, D. (ed.), (1999). The Oxford Reverse Dictionary, Oxford University Press, Oxford, 1999. 
El-Kahlout, I. D. and K. Oflazer. (2004). Use of Wordnet for Retrieving Words from Their Meanings. Procee-
dings of the 2nd Global WordNet Conference, Brno, 118?123. 
Fellbaum, C. (1998). WordNet: An Electronic Lexical Database and some of its Applications. MIT Press. 
Ferraresi, A.; Zanchetta, E.; Baroni M.; Bernardini, S. (2008). Introducing and evaluating ukWaC, a very large 
web-derived corpus of English. In: S. Evert, A. Kilgarriff and S. Sharoff (eds.): Proceedings of the 4th Web as 
Corpus Workshop (WAC-4) ? Can we beat Google?, Marrakech. 
Findler, N. (editor). (1979). Associative Networks: The Representation and Use of Knowledge by Computers. 
Academic Press, Inc., Orlando, FL, USA. 
Fromkin V. (ed.). (1980). Errors in linguistic performance: Slips of the tongue, ear, pen and hand. New York: 
Academic Press. 
Fromkin, V. (ed.) (1973): Speech errors as linguistic evidence. The Hague: Mouton Publishers 
Kiss, G., Armstrong, C., Milroy, R. & Piper, J. (1973). An associative thesaurus of English and its computer 
analysis. In: A. Aitken, R. Beiley and N. Hamilton-Smith (eds.): The Computer and Literary Studies. Edin-
burgh: University Press. 
Landauer, T.K.; Dumais, S.T. (1997). A solution to Plato's problem: The latent semantic analysis theory of ac-
quisition, induction, and representation of knowledge. Psychological Review 104 (2), 211?240. 
Lezius, W.; Rapp, R.; Wettler, M. (1998). A freely available morphology system, part-of-speech tagger, and con-
text-sensitive lemmatizer for German. In: Proceedings of COLING-ACL 1998, Montreal, Vol. 2, 743?748. 
Mandala, R., Tokunaga, T. & Tanaka, H. (1999). Complementing WordNet with Roget?s and Corpus-based The-
sauri for Information Retrieval. Proceedings of EACL. 
Mann, W. C. Thompson, S. A. (1988). Rhetorical structure theory: Toward a functional theory of text organiza-
tion. Text 8(3), 243?281.  
Meyer, D.E. & Schvaneveldt, R.W. (1971). Facilitation in recognizing pairs of words: Evidence of a dependence 
between retrieval operations. Journal of Experimental Psychology 90: 227?234. 
Michiels, A. (1982). Exploiting a Large Dictionary Database. PhD Thesis, University of Li?ge, mimeographed.  
Mikolov, T.; Chen, K.; Corrado, G.; Dean, J. (2013a). Efficient estimation of word representations in vector 
space. CoRR, abs/1301.3781. 
Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G.S.; Dean, J. (2013b). Distributed representations of words and 
phrases and their compositionality. Advances in Neural Information Processing Systems, 3111?3119. 
Miller, G. A. (1995). WordNet : A lexical database for english. Communications of the ACM, 38 (11), 39?41. 
Miller, G.A. (ed.) (1990): WordNet: An On-Line Lexical Database. International Journal of Lexicography, 3(4), 
235?244.  
Nogier, J.F. & Zock, M. (1992) Lexical choice by pattern matching. Knowledge Based Systems, Vol. 5, No 3, 
Butterworth. 
Pantel, P.; Lin, D. (2002): Discovering Word Senses from Text. Proceedings of ACM Conference on Knowledge 
Discovery and Data Mining (KDD-02). Edmonton, Canada , 613?619. 
Quillian, M. R. (1967). Word concepts: A theory and simulation of some basic semantic capabilities. Behavioral 
Science, 12(5), 410?430.  
Quillian, M. R. (1968). Semantic memory. Semantic Information Processing, 227?270.  
Quillian, M. R. (1969). The teachable language comprehender: a simulation program and theory of language. 
Communications of the ACM, 12(8), 459-476.  
Quillian, R. (1963). A notation for representing conceptual information: An application to semantics and me-
chanical English paraphrasing. SP-1395, System Development Corporation, Santa Monica.  
13
Quillian, R. (1966). Semantic Memory. Unpublished doctoral dissertation, Carnegie Institute of Technology. 
Rapp, R. (1999). Automatic identification of word translations from unrelated English and German corpora. In: 
Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics 1999, College Park, 
Maryland. 519?526. 
Rapp, R. (2011). Language acquisition as the detection, memorization, and reproduction of statistical regularities 
in perceived language. Journal of Cognitive Science, Vol. 12, No. 3, 297?322. 
Rapp, R. (2013). From stimulus to associations and back. Proceedings of the 10th Workshop on Natural Langu-
age Processing and Cognitive Science, Marseille, France. 
Rapp, R. (2014). Corpus-based computation of reverse associations. Proceedings of the Ninth International Con-
ference on Language Resources and Evaluation (LREC 2014), Reykjavik, Island. 
Richens, R. H. (1956) Preprogramming for mechanical translation, Mechanical Translation 3 (1), 20?25. 
Roget, P. (1852). Thesaurus of English Words and Phrases. Longman, London. 
Schvaneveldt, R. (ed.) (1989). Pathfinder Associative Networks: studies in knowledge organization. Ablex. Nor-
wood, New Jersey, US. 
Simmons, R. (1963). Synthetic language behavior. Data Processing Management 5 (12): 11?18.  
Sowa, John F. (1984). Conceptual Structures: Information Processing in Mind and Machine, Addison-Wesley, 
Reading, MA. 
Sporns, O., Chialvo, D. R., Kaiser, M., & Hilgetag, C. C. (2004). Organization, development and function of 
complex brain networks. Trends in Cognitive Sciences, 8, 418?425. 
Summers, D. (1993). Language Activator: the world?s first production dictionary. Longman, London. 
Vitevitch, M. (2008). What can graph theory tell us about word learning and lexical retrieval? Journal of Speech, 
Language, and Hearing Research , 51:408?422. 
Wettler, M.; Rapp, R.; Sedlmeier, P. (2005). Free word associations correspond to contiguities between words in 
texts. Journal of Quantitative Linguistics 12(2), 111?122. 
Zock, M. (2014). How to overcome the tip-of-the-tongue problem with the help of a computer. Proceedings of 
CogALex-IV, COLING, Dublin, Ireland 
Zock, M.; Cristea, D. (2014). You shall find the target via its companion words: specification of tools and re-
sources to overcome the tip-of-the-tongue problem. Proceedings of the 11th International Workshop on Natu-
ral Language Processing and Cognitive Science (NLPCS), Venice. 
Zock, M.; Ferret, O.; Schwab, D. (2010). Deliberate word access : an intuition, a roadmap and some preliminary 
empirical results. International Journal of Speech Technology, 13(4), 107?117. 
 
14
Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 221?229,
Dublin, Ireland, August 23, 2014.
Wordfinding Problems and How to Overcome them Ultimately
With the Help of a Computer
Michael Zock
LIF-CNRS / TALEP
163, Avenue de Luminy
13288 Marseille / France
michael.zock@lif.univ-mrs.fr
Abstract
Our ultimate goal is to help authors to find an elusive word. Whenever we need a word, we look it
up in the place where it is stored, the dictionary or the mental lexicon. The question is how do we
manage to find the word, and how do we succeed to do this so quickly? While these are difficult
questions, I believe to have some practical answers for them. Since it is unreasonable to perform
search in the entire lexicon, I suggest to start by reducing this space (step-1) and to present then
the remaining candidates in a clustered and labeled form, i.e. categorial tree (step-2). The goal
of this second step is to support navigation.
Search space is determined by considering words directly related to the input, i.e. direct neigh-
bors (associations/co-occurrences). To this end many resources could be used. For example, one
may consider an associative network like the Edinburgh Association Thesaurus (E.A.T.). As this
will still yield too many hits, I suggest to cluster and label the outputs. This labeling is cru-
cial for navigation, as we want users to find the target quickly, rather than drown them under a
huge, unstructured list of words. Note, that in order to determine properly the initial search space
(step-1), we must have already well understood the input [mouse
1
/ mouse
2
(rodent/device)], as
otherwise our list will contain a lot of noise, presenting ?cat, cheese? together with ?computer,
mouse pad?, which is not quite what we want, since some of these candidates are irrelevant, i.e.
beyond the scope of the user?s goal.
1 Introduction
Whenever we read a book, write a letter, or launch a query on Google, we always use words, the short-
hand labels for more or less well specified thoughts. No doubt, words are important, a fact nicely ex-
pressed by Wilkins (1972) when he writes: without grammar very little can be conveyed, without vocab-
ulary, nothing can be conveyed. Still, ubiquitous as they may be, words have to be learned, that is, they
have to be stored, remembered, and retrieved. Given the role words play in our daily lives, it is surprising
to see how little we have to offer so far to help humans to memorize, find or retrieve them. Hoping to
contribute to a change for this, I have started to work on one of these tasks: word access, also called
retrieval or wordfinding.
Imagine the following situation: your goal is to express the following ideas: superior dark coffee
made of beans from Arabia? by a single word, but you cannot access the corresponding form mocha,
even though you know it, since you?ve used it not so long ago. This kind of problem, known as the
tip-of-the-tongue (TOT)-problem, has received a lot of attention from psychologists (Schwartz, 2002;
Brown, 1991). It has always been pointed out that people being in this state know quite a bit concerning
the elusive word (Brown and McNeill, 1996). Hence, using it should allow us to reduce the search space.
Put differently, it would be nice to have a system capable to use whatever you have, incomplete as it may
be, to help you find what you cannot recall. For example, for the case at hand, one might think of dark,
coffee, beans, and Arabia, to expect from system a set of reasonable candidates, like arabica, espresso,
or mocha. In the remainder of this paper I will try to show how this might be achieved, but before doing
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
221
so, I would like to clarify what I mean by computer-aided lexical access, what characterizes the problem
of word production, i.e. the process.
2 Computer-aided lexical access
Under normal circumstances, words are accessed on the fly, that is, the lexical access is immediate,
involontary and autonomous. Also, it takes place without any external help. As we all know, things do
not always work that smoothly, which is why we may ask for help. In this latter case, lexical access
is deliberate, incremental (i.e., distributed over time), and may be mediated via some external resource
(another person or a dictionary). This situation may well arise in writing, where we are much more
demanding and where we have much more time. Hence words are chosen with much more care than
during speaking, i.e., spontaneous discourse.
I view computer-aided lexical access as an interactive, cognitive process. It is interactive as it involves
two cooperative agents, the user and the computer, and it is cognitive as it is largely knowledge-driven.
The knowledge concerns words, i.e. meanings and forms, as well as their relations to other words. Since
the knowledge of both agents is incomplete, they cooperate: neither of them alone can point to the target
word (t
w
), but by working together they can. It is as if one had the (semantic) map and the other the
compass, i.e., the knowledge to decide where to go. Since both types of knowledge are necessary, they
complete each other, helping utlimately the user to find the elusive word, which is the goal.
To be more concrete, consider some user input (one or several words), the system reacts by providing
all directly associated words. Since all words are linked, they form a graph, which has two major conse-
quences : the system knows everyone, the immediate neighbors, the neighbors? neighbors, etc. and the
user can initiate search from anywhere, to continue it until he has reached the target word, t
w
. Everything
being connected, everything is reachable, at least in principle. Search may require several steps, but in
most cases the number of steps is surprisingly small.
As mentioned already, the user definitely has some knowledge concerning words, their components
and their organisation in the mental lexicon, but this knowledge is by no means complete. The user also
has some knowledge (or, more precisely, meta-knowledge) concerning the topology of the graph,
1
but he
certainly does not know as much as the system. The fact that an author does have this kind of knowledge
is revealed via word associations (Cramer, 1968; Deese, 1965; Nelson et al., 1998; Kiss et al., 1972) and
via the observed average path length (Vitevitch, 2008) needed in order to get from some starting point
(s
w
) to the goal (t
w
). This path is generally quite short. It hardly ever exceeds three steps, and in many
cases even less: search is launched via an item directly related to the t
w
(direct neighbor).
If the user does not know too much concerning the topology of the network, he does know quite a bit
concerning the t
w
,
2
information the system has no clue of at this point. Eventhough it knows ?everyone?
in the network, it cannot do mind-reading, i.e. guess the precise word a user has in mind (t
w
) when
providing a specific input (s
w
). Yet the user can. Even if he cannot access the word at a given moment,
he can recognize it when seeing it (alone or in a list). This fact is well established in the literature on the
?tip-of-the-tongue problem? (Aitchison, 2003).
3 From mind to mouth, or what characterizes the process of word production?
According to the father of modern linguistics (de Saussure, 1916), word forms (signifier) and their asso-
ciated meaning (signified) are but one, called the sign. They are said to be an inseparable unit. This is in
sharp contrast to what psychologists tell us about words synthesis. For example, one of the leading spe-
cialists of language production (Levelt, 1989; Levelt, 1999) has convincingly shown that, when speaking
1
For example, he knows that for a given word form there are similar forms in terms of sound or meaning. There are also
words that are more general/specific, or others meaning exactly the opposite than a given input. This kind of knowledge is so
obvious and so frequent that it is encoded in many resources like WordNet, Roget?s thesaurus or more traditional dictionaries
(incuding synonym and rhyming dictionaries).
2
For example, parts of the form (rhymes with x: health/wealth) or meaning, like the ?type? (animal), the ?function? (used for
eating) or the ?relationship? (synonym, antonym, ...) with respect the source word (s
w
). He may even be able to provide parts
of the definition (say, ?very small? for ?liliput?). His main problem problem resides in the fact that he cannot access at this very
moment the exact word form (he experiences the so called ?tip-of-the-tongue problem, TOT), which is why he tries to find it in
a lexical resource (dictionary).
222
we go, step by step, from meanings (concepts), to the lexical concept (also called lemma) to the sound
(written or spoken form). Depending on the theory, there may be retroaction or not, a lower level, say,
phonology, influencing a higher level, the lexical concept.
Note that the notion of lemma has completely different meanings in psychology and in lexicography.
While for linguists it is roughly speaking the word?s base-form or dictionary-form, for psycholinguists it
is a schema, i.e. an abstract form representing a specific meaning (a lexicalized concept) and a syntactic
category (part of speech), but it lacks entirely specific values concerning the form (sounds/graphemes).
This is being take care of at the next step (sound form encoding). In short, in contrast to Saussure?s view,
the information contributing to what we commonly call words (lemma or word forms) is distributed.
This is a well established empirical fact observed by psychologists working on the time course of word
production (Stemberger, 1985; Levelt and Schriefers, 1987; Dell et al., 1999), as by those who analyze
and interpret speech errors (Fromkin, 1973; Fromkin, 1980; Fromkin, 1993).
Yet, what concerns us here in particular is the following: as noted, speakers go from meanings to
sounds via lexical concepts (abstract word forms). More importantly, the conceptual input may lack in-
formation to determine a precise lexical form. Put differently, rather than starting from a full fledged def-
inition or complete meaning representation, authors may well start from an underspecified input (?small
bird? rather than ?sparrow?). Note that the specific requirements of a culture may help us to clarify our
thoughts, as well as induce biases or imprecisions because of lexical gaps. Hence we end up using an
existing words (eventhough it does not express excatly what we had in mind) rather than coining a new
one fitting better our purpose (expressibility problem). For a psycholinguistic explanation concerning
gradual refinement, see (Zock, 1996).
Let me briefly illustrate this here via an example, and comment then on the way how specific knowl-
edge states may ask for different kind of information from the lexicon. Suppose you wanted to talk about
a given reptile having certain features (dangerous, size, living space, ...). If you cannot come up immedi-
ately with the intended word, any of the following could be candidates: alligator, crocodile, cayman. At
some point you need to make up your mind though, as the form synthesizer needs to know what items to
activate so that it can produce the corresponding form (graphemes, sounds).
encyclopedic relations 
(syntagmatic associations)
crocodile:
voracious,.water,.tropics
semantic fields: 
(thesaurus- or domain relations)
aqua3c.rep3le
translation
equivalent word 
in another language
cocodril4crocodile
concepts (word definitions, 
conceptual primitives)
large voracious aquatic reptile 
having a long snout
scene
(visual input)
lexical relations
synonyms, antonyms
hypernyms, ...
meronym : snout
clang relations 
(sound related words)
crocodile4Nile
reptile 
A
form
crocodile
B C
A1
alligator
crocodile
cayman
11 2 3 4 5 6
specified meaning
(lexicalized concept)
Figure 1: Underspecified input and progressive refinement
As we can see in the figure above, there are two critical moments in word production: meaning speci-
fication (A-B) and sound-form encoding (B-C). It is generally this latter part that poses problems. How
to resolve it has been nicely illustrated in an experiment done by (James and Burke, 2000). They showed
that phonologically similar words of the target could resolve the TOT state. To show this they put partici-
pants into the TOT state by presenting them low-frequency words: abdicate, amnesty, anagram,.... Those
who failed were used for the experiment. Next the experimenters read a list of words containing parts
of the syllables of the TOT word. For example, if the definition ?to renounce a throne? put a participant
into a TOT state, he was asked to read aloud a list of ten words, like abstract, indigent, truncate, each of
which contains a syllable of the target. For the other half, participants were given a list of 10 phonologi-
cally unrelated words. After that participants were primed again to produce the elusive word (abdicate).
As the results clearly showed those who were asked to read phonologically related words resolved more
223
TOT states than those who were presented with unrelated words.
This is a nice example. Alas, we cannot make use of it, as, not knowing the target word we cannot
increase (directly) the activation level of the phonological form. Hence we have to resort to another
method, namely, association networks (see section 3). Let us see how search strategies may depend on
cognitive states.
4 Search strategies function of variable cognitive states
Search is always based on knowledge. Depending on the knowledge available at the onset one will
perform a specific kind of search. Put differently, there are different information needs as there are
different search strategies.
There are at least three things that authors typically know when looking for a specific word: its mean-
ing (definition) or at least part of it (this is the most frequent situation), its lexical relations (hyponymy,
synonymy, antonymy, etc.), and the collocational or encyclopedic relations it entertains with other words
(Paris-city, Paris-French capital, etc.). Hence there are several ways to access a word (see Figure 1): via
its meaning (concepts, meaning fragments), via syntagmatic links (thesaurus- or encyclopedic relations),
via its form (rhymes), via lexical relations, via syntactic patterns (search in a corpus), and, of course, via
another language (translation). Note that access by meaning is the golden route, i.e. the most normal
way. We tend to use other means only if we fail to access straight away the desired word.
I will consider here only one of them, word associations (mostly, encyclopaedic relations). Note
that, people being in the TOT-state clearly know more than that. Psychologists who have studied this
phenomenon (Brown and McNeill, 1996; Vigliocco et al., 1997) have found that their subjects had
access not only to meanings (the words definition), but also to information concerning grammar (gender)
and lexical form: sound, morphology and part of speech. While all this information could be used
to constrain the search space, the ideal dictionary being multiply indexed, I will deal here only with
semantically related words (associations, collocations in the large sense of the word). Before discussing
how such a dictionary could be built and used, let us consider a possible search scenario.
I start from the assumption that in our mind, all words are connected, the mental lexicon (brain) being a
network. This being so, anything can be reached from anywhere. The user enters the graph by providing
whatever comes to his mind (source-word), following the links until he has reached the target. As has
been shown (Motter et al., 2002), our mental lexicon has small-world properties: very few steps are
needed to get from the source-word to the target word. Another assumption I make is the following:
when looking for a word, people tend to start from a close neighbour, which implies that users have
some meta-knowledge containing the topology of the network (or the structure of their mental lexicon):
what are the nodes, how are they linked to their neighbours, and what are more or less direct neighbours
? For example, we know that black is related to white, and that both words are fairly close, at least a lot
closer than, say, black and flower.
Search can be viewed as a dialogue. The user provides as input the words that a concept he wishes
to express evokes, and the system displays then all (directly) connected words. If this list contains the
target search stops, otherwise it will continue. The user chooses a word of the list, or keys in an entirely
different word. The first part described is the simplest case: the target is a direct neighbour. The second
addresses the problem of indirect associations, the distance being bigger than 1.
Before presenting our method in section 3, let us say a few words about existing resources. Since
the conversion of meaning to sounds is mediated via a lexicon, one may wonder to what extent existing
resources can be of help.
5 Related work
While there are many kinds of dictionaries or lexical resources, very few of them can be said to meet
truly the authors? needs. To be fair though, one must admit that great efforts have been made to improve
the situation both with respect to lexical resources and electronic dictionaries. In fact, there are quite
a few onomasiological dictionaries (van Sterkenburg, 2003). For example, Roget?s Thesaurus (Roget,
1852), analogical dictionaries (Boissi`ere, 1862; Robert et al., 1993), Longman?s Language Activator
224
(Summers, 1993), various network-based dictionaries: WordNet (Fellbaum, 1998; Miller et al., 1990),
MindNet (Richardson et al., 1998), HowNet (Dong and Dong, 2006), Pathfinder (Schvaneveldt, 1989),
?The active vocabulary for French? (Mel??cuk and Polgu`ere, 2007) and Fontenelle (Fontenelle, 1997).
Other proposals have been made by Sierra (Sierra, 2000) and Moerdijk (2008). There are also various
collocation dictionaries (Benson et al., 2010), reverse dictionaries (Bernstein, 1975; Kahn, 1989; Ed-
monds, 1999) and OneLook,
3
which combines a dictionary (WordNet) and an encyclopedia (Wikipedia).
Finally, there is MEDAL (Rundell and Fox, 2002), a thesaurus produced with the help of Kilgariff?s
Sketch Engine (Kilgarriff et al., 2004). There has also been quite a lot of work on the time-course of
word production, i.e. the way how one gets progressively from a more or less precise idea to its expres-
sion, a word expressed in written or spoken form. See for example (Levelt et al., 1999; Dell et al., 1999).
Clearly, a lot of progress has been made during the last two decades, yet more can be done especially
with respect to indexing (the organization of the data) and navigation.
Two key idea underlying modern lexical resources are the notions of ?graphs? and ?association?. For a
useful introduction to graph-based natural language processing, see (Mihalcea and Radev, 2011). Associ-
ations have a long history. The idea according to which the mental lexicon (or encyclopedia) is basically
an associative network, composed of nodes (words or concepts) and links (associations) is not new at all.
Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in
work done by philosophers (Locke, Hume), physiologists (James & Stuart Mills), psychologists (Galton,
1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvan-
eveldt, 1989). For good introductions see (H?ormann, 1972; Cramer, 1968) and more recently (Spitzer,
1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hyper-
text (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet
(Miller, 1990; Fellbaum, 1998).
6 The framework for building and using our resource
To understand the problems at stake, I describe the communicative setting (system, user), the existing
and necessary components, as well as the information flow (see figure 2).
Imagine an author wishing to convey the name of a special beverage (?mocha?) commonly found in
coffee shops. Failing to do so, he tries to find it in a lexicon. Since dictionaries are too huge to be
scanned from beginning to the end, I suggest another solution : reduce the search space based on some
input (step-1) and presentation of the results (all directly related words) in a clustered form (step-2).
More concretely speaking, I suggest to have a system that accepts whatever comes to an author?s mind,
say ?coffee? in our ?mocha? case, to present then all directly associated words. Put differently, given
some cue, we want the system to guess the user?s goal (the elusive word). If this list contains the target,
search stops, otherwise the user will pick one of the associated terms or provide an entirely new word
and the whole process is repeated again, that is, the system will come up with a new set of proposals.
What I?ve just described here corresponds to step-1 in figure 2 (see next page). While there are a
number of resources that one could use to allow for this transition, I rely here on the E.A.T., i.e. the
?Edinburgh Association Thesaurus?. Note that the output produced by this resource is still too big to be
really useful. Suppose that each input word yielded 50 outputs (the EAT often presents 100, and one
could think of a lot more). Having provided three words the system will return 150 outputs. Actually, it
will take an intersection of the associated words to avoid redundancies. Since this list is still too big to
be scanned linearly (one by one), I suggest to structure it, by clustering words into categories (step-2).
This yields a tree whose leaves are words (our potential targets) and whose nodes are categories, that
is, also words, but with a completely different status, namely to group words. Category names function
like signposts, signalling the user the direction to go. Note that it is not the system that decides on the
direction, but the user. Seeing the names of the categories he can make reasonable guesses concerning
their content. Categories act somehow like signposts signaling the user the kind of words he is likely
to find if he goes one way or another. Indeed, knowing the name of a category (fruit, animal), the user
can guess the kind of words contained in each bag, a prediction which is all the more likely as each
3
http://onelook.com/reverse-dictionary.shtml
225
Hypothetical lexicon
 containing 60.000 words
Given some input the system displays
all directly associated words, 
i.e. direct neighbors (graph), 
ordered by some criterion or not
associated terms
to the input : ?coffee?
(beverage)
BISCUITS 1 0.01
BITTER 1 0.01
DARK 1 0.01
DESERT 1 0.01
DRINK 1 0.01
FRENCH 1 0.01
GROUND 1 0.01
INSTANT 1 0.01
MACHINE 1 0.01
MOCHA 1 0.01
MORNING 1 0.01
MUD 1 0.01
NEGRO 1 0.01
SMELL 1 0.01
TABLE 1 0.01
TEA 39 0.39
CUP 7 0.07
BLACK 5 0.05
BREAK 4 0.04
ESPRESSO 40.0.4
POT 3 0.03
CREAM 2 0.02
HOUSE 2 0.02
MILK 2 0.02
CAPPUCINO 20.02
STRONG 2 0.02
SUGAR 2 0.02
TIME 2 0.02
BAR 1 0.01
BEAN 1 0.01
BEVERAGE 1 0.01
Tree designed for navigational purposes (reduction of search-space). The 
leaves contain potential target words and the nodes the names of their 
categories, allowing the user to look only under the relevant part of the tree. 
Since words are grouped in named clusters, the user does not have to go 
through the whole list of words anymore. Rather he navigates in a tree (top-
to-botton, left to right), choosing first the category and then its members, to 
check whether any of them corresponds to the desired target word.
potential categories (nodes), 
for the words displayed 
in the search-space (B):
- beverage, food, color,
- used_for, used_with
- quality, origin, place
(E.A.T, collocations
derived from corpora)
Create +/or use
associative network
Clustering + labeling
1? via computation
2? via a resource
3? via a combination 
     of resources (WordNet, 
     Roget, Named Entities, ?)
1? navigate in the tree + determine 
whether  it contains the target or a 
more or less related word.
2? Decide on the next action : stop 
here, or continue.
Navigation + choice
Provide input
say, ?coffee?
C :  Categorial Tree
B: Reduced search-space
A: Entire lexicon D :  Chosen word
1? Ambiguity detection via WN
2? Interactive disambiguation:
coffee: ?beverage? or ?color? ?
1? Ambiguity detection via WN
2? Disambiguation: via clustering
set of 
words
espresso 
cappucino
mocha
COOKY
DRINK
set of 
words
TASTE FOOD
COLOR
Categorial tree
A
B
C
Target word
Step-2: system builder
Step-1: system builder
Step-1: user
Step-2: user
Pre-processing
Post-processing
A
.
.
.
.
.
L
.
.
.
N
.
.
.
.
.
.
.
.
.
.
Z
able
zero
target 
word
mocha
evoked 
term
coffee
Figure 2: Architecture of the components and information flow
226
category contains only terms directly associated with the source word. Assuming that the user knows
the category of the searched word,
4
he should be able to look in the right bag and take the best turn.
Navigating in a categorial tree, the user can search at a fairly high level (class) rather than at the level of
words (instances). This reduces not only the cognitive load, but it increases also chances of finding the
target, while speeding up search, i.e. the time needed to find a word.
Remains the question of how to build this resource and how to accomplish these two steps. I have
explained already the first transition going from A-B. The system enriches the input by taking all associ-
ated words, words he will find in the EAT. Obviously, other strategies are possible, and this is precisely
one of the points I would like to experiment with in the future : check which knowledge source (corpus,
association thesaurus, lexical resource) produces the best set of candidates, i.e. the best search space and
the best structure in order to navigate. The solution of the second step is quite a bit more complicated,
as putting words into clusters is one thing, naming them is another. Yet, arguably this is a crucial step,
as it allows the user to navigate on this basis. Of course, one could question the very need of labels, and
perhaps this is not too much of an issue if we have only say, 3-4 categories. I am nevertheless strongly
convinced that the problem is real, as soon as the number of categories (hence the words to be classified)
grows. To conclude, I think it is fair to say that the first stage is clearly within reach, while the automatic
construction of the categorical tree remains a true challenge despite the vast literature devoted to this
topic or to strongly related problems (Zhang et al., 2012; Biemann, 2012; Everitt et al., 2011).
7 Outlook and conclusion
I have started from the observation that words are important and that their accessibility can be a problem.
In order to help a dictionary user to overcome it I have presented a method showing promise. In particular,
I have shown how to reduce the search space, how to present a set of plausible candidates and what needs
to be done next (clustering and naming them) to reduce the search space and to support navigation. In
particular, I have proposed the creation of a categorial tree whose leaves contain the (potential target)
words and the nodes the names of their categories. The role of the latter is to avoid the user to search
in non relevant parts of the tree. Since words are grouped in named clusters, the user does not have to
go through the whole list of words anymore. Rather he navigates in a tree (top-to-botton, left to right),
choosing first the category and then its members, to check whether any of them corresponds to the desired
target word.
Even if the details of this work turn out to be wrong (this is just preliminary work), I believe and hope
that the overall framework is of the right sort, allowing for a rich set of experimentation in particular
with respect to determining the search space and the clustering. Concerning evaluation, the ultimate
judge will be, of course, the user, as only s/he can tell us whether our resource fits his/her needs or goals.
References
Jean Aitchison. 2003. Words in the Mind: an Introduction to the Mental Lexicon (3d edition). Blackwell, Oxford.
Morton Benson, Evelyn Benson, and Robert A Ilson. 2010. The BBI Combinatory Dictionary of English. John
Benjamins, Philadelphia.
Theodore Bernstein. 1975. Bernstein?s Reverse Dictionary. Crown, New York.
Chris Biemann. 2012. Structure Discovery in Natural Language. Springer.
Jean Baptiste Prudence Boissi`ere. 1862. Dictionnaire analogique de la langue franc?aise : r?epertoire complet des
mots par les id?ees et des id?ees par les mots. Larousse et A. Boyer, Paris.
Roger Brown and David McNeill. 1996. The tip of the tounge phenomenon. Journal of Verbal Learning and
Verbal Behaviour, 5:325?337.
Allan S. Brown. 1991. The tip of the tongue experience a review and evaluation. Psychological Bulletin, 10:204?
223.
4
A fact which has been systematically observed for people being in the ?tip of the tongue state? who may tell the listener
that they are looking for the name of ?a fruit typically found in PLACE?, in order to get ?kiwi?.
227
Vannevar Bush. 1945. As we may think. The Atlantic Monthly, 176:101?108.
Phebe Cramer. 1968. Word association. Academic Press, New York.
Ferdinand de Saussure. 1916. Cours de linguistique g?en?erale. Payot, Paris.
James Deese. 1965. The structure of associations in language and thought. Johns Hopkins Press.
Gary Dell, Franklin Chang, and Zenzi M. Griffin. 1999. Connectionist models of language production: Lexical
access and grammatical encoding. Cognitive Science, 23:517?542.
Zhendong Dong and Qiang Dong. 2006. HOWNET and the computation of meaning. World Scientific, London.
David Edmonds, editor. 1999. The Oxford Reverse Dictionary. Oxford University Press, Oxford, Oxford.
Brian S. Everitt, Sabine Landau, Morven Leese, and Daniel Stahl. 2011. Cluster Analysis. John Wiley and Sons.
Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database and some of its Applications. MIT
Press.
Thierry Fontenelle. 1997. Turning a Bilingual Dictionary into a Lexical-Semantic Database. Max Niemeyer,
T?ubingen.
Siegmund Freud. 1901. Psychopathology of everyday life. Payot, Paris, 1997 edition.
Victoria Fromkin, editor. 1973. Speech errors as linguistic evidence. Mouton, The Hague.
Victoria Fromkin. 1980. Errors in linguistic performance: Slips of the tongue, ear, pen and hand.
Victoria Fromkin. 1993. Speech production. In J. Berko-Gleason and N. Bernstein Ratner, editors, Psycholinguis-
tics. Harcourt, Brace, Jovanovich, Fort Worth, TX.
Francis Galton. 1880. Psychometric experiments. Brain, 2:149?162.
Hans H?ormann. 1972. Introduction `a la psycholinquistique. Larousse, Paris, France.
Lori James and Deborah Burke. 2000. Phonological priming effects on word retrieval and tip-of-the-tongue
experiences in young and older adults. Journal of Experimental Psychology: Learning, Memory, and Cognition,
6(26):1378?1391.
James Jenkins. 1970. The 1952 Minnesota word association norms. In L. Postman and G. Kepper, editors, Norms
of Word Association, pages 1?38. Academic Press, New York, NY.
Carl Jung and Franz Riklin. 1906. Experimentelle Untersuchungen ?uber Assoziationen Gesunder. In C. G. Jung,
editor, Diagnostische Assoziationsstudien, pages 7?145. Barth, Leipzig, Germany.
John Kahn. 1989. Reader?s Digest Reverse Dictionary. Reader?s Digest, London.
Adam Kilgarriff, Pavel Rychl?y, Pavel Smr?z, and David Tugwell. 2004. The Sketch Engine. In Proceedings of the
Eleventh EURALEX International Congress, pages 105?116, Lorient, France.
George Kiss, Christine Amstrong, and Robert Milroy. 1972. The associative thesaurus of English. Ediburgh
University Press, Edinburgh.
William Levelt and Herbert Schriefers. 1987. Stages of lexical access. In G. Kempen, editor, Natural Lan-
guage Generation: New Results in Artificial Intelligence, Psychology, and Linguistics, pages 395?404. Nijhoff,
Dordrecht.
William Levelt, A. Roelofs, and A. Meyer. 1999. A theory of lexical access in speech production. Behavioral and
Brain Sciences, 22(1):1?75.
William Levelt. 1989. Speaking : From Intention to Articulation. MIT Press, Cambridge, MA.
William Levelt. 1999. Language production: a blueprint of the speaker. In C. Brown and P. Hagoort, editors,
Neurocognition of Language, pages 83?122. Oxford University Press.
Igor Aleksandrovi?c Mel??cuk and Alain Polgu`ere. 2007. Lexique actif du franc?ais : l?apprentissage du vocabu-
laire fond?e sur 20 000 d?erivations s?emantiques et collocations du franc?ais. Champs linguistiques. De Boeck,
Bruxelles.
228
Rada Mihalcea and Dragomir Radev. 2011. Graph-Based Natural Language Processing and Information Re-
trieval. Cambridge University Press, Cambridge, UK.
George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine Miller. 1990. Introduction
to WordNet: An on-line lexical database. International Journal of Lexicography, 3(4), pages 235?244.
George Armitage Miller. 1990. Wordnet: An on-line lexical database. International Journal of Lexicography,
3(4).
Adilson E. Motter, Alessandro P. S. de Moura, Ying-Cheng Lai, and Partha Dasgupta. 2002. Topology of the
conceptual network of language. Physical Review E, 65(6).
Douglas Nelson, Cathy McEvoy, and Thomas Schreiber. 1998. The university of South Florida word association,
rhyme, and word fragment norms.
Ted Nelson. 1967. Xanadu projet hypertextuel.
Ross Quillian. 1968. Semantic memory. In M. Minsky, editor, Semantic Information Processing, pages 216?270.
MIT Press, Cambridge, MA.
Stephen Richardson, William Dolan, and Lucy Vanderwende. 1998. Mindnet: Acquiring and structuring semantic
information from text. In ACL-COLING?98, pages 1098?1102.
Paul Robert, Alain Rey, and J. Rey-Debove. 1993. Dictionnaire alphabetique et analogique de la Langue
Franc?aise. Le Robert, Paris.
Peter Roget. 1852. Thesaurus of English Words and Phrases. Longman, London.
Michael Rundell and G. (Eds.) Fox. 2002. Macmillan English Dictionary for Advanced Learners. Macmillan,
Oxford.
Roger Schvaneveldt, editor. 1989. Pathfinder Associative Networks: studies in knowledge organization. Ablex,
Norwood, New Jersey, US.
Bennett Schwartz. 2002. Tip-of-the-tongue states: Phenomenology, mechanism, and lexical retrieval. Lawrence
Erlbaum Associates, Mahwah, NJ.
Gerardo Sierra. 2000. The onomasiological dictionary: a gap in lexicography. In Proceedings of the Ninth Euralex
International Congress, pages 223?235, IMS, Universit?at Stuttgart.
Manfred Spitzer. 1999. The mind within the net: models of learning, thinking and acting. MIT Press, Cambridge,
MA.
Joseph Paul Stemberger. 1985. An interactive activation model of language production. In A. W. Ellis, editor,
Progress in the Psychology of Language, volume 1, pages 143?186. Erlbaum.
Della Summers. 1993. Language Activator: the world?s first production dictionary. Longman, London.
Piet van Sterkenburg. 2003. Onomasiological specifications and a concise history of onomasiological dictionar-
ies. In A Practical Guide to Lexicography, volume A Practical Guide to Lexicography, pages 127?143. John
Benjamins, Amsterdam.
Gabriella Vigliocco, Tiziana Antonini, and Garrett Merrill. 1997. Grammatical gender is on the tip of italian
tongues. Psychological Science, 4(8):314?317.
Michael Vitevitch. 2008. What can graph theory tell us about word learning and lexical retrieval? Journal of
Speech, Language, and Hearing Research, 51:408?422.
David Wilkins. 1972. Linguistics and Language Teaching. Edward Arnold, London.
Ziqi Zhang, Anna Lisa Gentile, and Fabio Ciravegna. 2012. Recent advances in methods of lexical semantic
relatedness ? a survey. Journal of Natural Language Engineering, Cambridge Universtiy Press, 19(4):411?479.
Michael Zock. 1996. The power of words in message planning. In Proceedings of the 16th conference on
Computational linguistics, pages 990?995, Morristown, NJ, USA. Association for Computational Linguistics.
229
