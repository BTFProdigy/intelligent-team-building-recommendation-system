Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume, pages 284?287,
New York City, June 2006. c?2006 Association for Computational Linguistics
SconeEdit: A Text-guided Domain Knowledge Editor 
 
 Alicia Tribble Benjamin Lambert Scott E. Fahlman 
Language Technologies  
Institute 
Language Technologies 
Institute 
Language Technologies  
Institute 
Carnegie Mellon University Carnegie Mellon University Carnegie Mellon University 
Pittsburgh, PA 15213 Pittsburgh, PA 15213 Pittsburgh, PA 15213 
atribble@cs.cmu.edu benlambert@cmu.edu sef@cs.cmu.edu 
 
 
 
 
Abstract 
We will demonstrate SconeEdit, a new tool 
for exploring and editing knowledge bases 
(KBs) that leverages interaction with do-
main texts.  The tool provides an annotated 
view of user-selected text, allowing a user 
to see which concepts from the text are in 
the KB and to edit the KB directly from 
this Text View.  Alongside the Text View, 
SconeEdit provides a navigable KB View 
of the knowledge base, centered on con-
cepts that appear in the text.  This unified 
tool gives the user a text-driven way to ex-
plore a KB and add new knowledge. 
1 Introduction 
We will demonstrate SconeEdit, a new tool for 
exploring and editing knowledge bases that inte-
grates domain text.  SconeEdit expands on the 
function of traditional ontology editors by showing 
the user an interactive text window (Text View) 
where the user can view and edit concepts from the 
knowledge base as highlighted terms in their origi-
nal context.  The Text View augments a traditional 
KB View, allowing the user to leverage existing 
knowledge as well as domain-focused text exam-
ples to perform a variety of knowledge-based 
tasks.   
Consider the task of assessing the quality of a 
knowledge base as a resource for a new AI or natu-
ral language system.  In SconeEdit, a user can view 
the knowledge base alongside a text document 
from the target domain.  SconeEdit searches for 
instances of KB concepts in the text and highlights 
them in the Text View.  Already the user can see a 
concise visual sample of the coverage of the KB 
for this domain. 
Now the user can work with the KB View and 
Text View together to navigate the ontology.  
Double-clicking on a highlighted concept like 
?keyboard? opens a detailed view of that concept 
in the KB View.  Inside the KB View, the user can 
click on the superclass of the keyboard concept to 
see the concept computer input device and all of its 
children.  Next, SconeEdit selectively highlights all 
instances of computer input device in the text.  The 
system uses type inference from the KB to high-
light ?mouse?, ?touchpad?, and ?wireless key-
board.?  If ?scanner? appears in the text but isn?t 
included in the knowledge base, the user can spot 
the omission quickly.   
 
 
Figure 1.  The SconeEdit Interface  
 
284
In this way, domain text is used as a measuring 
tool for coverage of domain knowledge.  Our dem-
onstration allows the user to try SconeEdit and to 
explore the interaction of text and knowledge. 
2 The Knowledge Base 
SconeEdit is a software client to the Scone Knowl-
edge Base System, or simply ?Scone? (Fahlman, 
2005).  Scone is an efficient, open-source knowl-
edge base (KB) system being developed in the 
Language Technologies Institute of Carnegie Mel-
lon University.  Scone is intended to be a practical 
KB system that can be used as a component in a 
wide range of AI and natural language software 
applications.  One of the goals in developing Scone 
is to make it easy to use, especially when adding 
new knowledge. 
The SconeEdit interface makes Scone more us-
able in several ways: the Text View display gives 
the user a convenient and intuitive starting point 
for exploring the knowledge base.  SconeEdit also 
provides an easy way of adding knowledge to the 
KB without learning the formal input language for 
Scone.  This demonstration focuses on the effec-
tiveness of SconeEdit and Scone together, but the 
design principles of SconeEdit are applicable to 
knowledge bases written in other formalisms. 
Figure 1 shows the SconeEdit window with a 
document and KB loaded.  The left side of the in-
terface contains the Text View, and the KB View 
is on the right.  Each of these views is described in 
detail below. 
3 Architecture 
3.1 Text View 
In a traditional ontology browser, the user starts 
looking for concepts of interest by typing words 
and phrases into a search field.  This is the model 
for several existing tools, including the VisDic 
viewer for WordNet (Hor?k and Smr?, 2004), the 
INOH ontology viewer (INOH, 2004), and the 
Gene Ontology viewer presented by Koike and 
Takagi (2004), among others. 
SconeEdit improves on this browsing paradigm 
by giving a user who is unfamiliar with the knowl-
edge base an easy way to start exploring.  Rather 
than generating a series of guesses at what may be 
 
Figure 2.  Excerpt from Text View, with Search 
and Text Tabs 
 
covered by the KB, the user can load natural lan-
guage text into SconeEdit from a file or the system 
clipboard.  We take an article from Xinhuanet 
News Service (Xinhuanet, 2006) as an example.  
Figure 2 shows an excerpt of this text after it has 
been loaded. 
When the text file is loaded, it appears in the 
Text Tab of the Text View pane.  SconeEdit high-
lights all strings that it can identify as concepts 
from the knowledge base. In this example, ?Wash-
ington? is correctly identified as the city, not the 
state.  In many cases the concept may be ambigu-
ous from the string alone.  SconeEdit currently 
uses dynamic programming to highlight the long-
est-matching concept names it can find (see Sec-
tion 5).  More sophisticated disambiguation is a 
priority for our future work.   
The result of highlighting is a concise visual 
representation of what is ?known? about that text.  
The Text View helps a user find relevant knowl-
edge quickly, even in a large general-domain KB.  
Clicking on any highlighted term in the Text View 
brings up a hierarchical representation of that con-
cept in the KB View.  
3.2 KB View 
The KB View contains two tabs: a Graph Tab and 
a List Tab. The Graph Tab displays an excerpt 
from the knowledge base as a network of linked 
concepts with one focus concept in the center.  
When the user clicks on a highlighted concept in 
the Text View, a graph focused on that concept 
appears in the Graph Tab.  Continuing with our 
Xinhuanet example, Figure 3 shows the Graph Tab 
after a user has clicked on ?Washington? in the 
text.  The Graph View now displays concepts that 
are closely related to Washington-Dc in the knowl-
edge base.   
285
  
 
 
 
 
 
 
 
 
 
 
Figure 3.  KB View, Graph Tab of Washington-Dc 
 
 
Figure 4.  KB View, List Tab of City 
 
Clicking on any of these related concepts in the 
Graph Tab moves the focus of the graph to that 
concept. 
The List Tab shows an alternative view of the 
same focus concept.  It displays KB information as 
a set of property lists.  As in the Graph Tab, the 
user can double-click on any concept in the List 
Tab to bring that concept into focus.  When the 
focus concept is densely connected to other con-
cepts in the KB, the List Tab can be easier to inter-
pret than the Graph Tab.  In general, research has 
shown that preference for the list style or graph 
style is personal and varies from user to user 
(Tribble and Ros?, 2006). Figure 4 shows the List 
Tab, focused on the concept City.  
4 Adding Knowledge 
Browsing the knowledge base in this way gives the 
user a detailed, domain-targeted view of its con-
tents.  A natural extension of this paradigm is to 
allow the user to edit the KB while browsing.  For 
example, a user may encounter a concept in the  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 5.  Adding a concept synonym 
 
text that is not present in the knowledge base. 
SconeEdit allows the user to simply click on a 
word in the text to create a new concept in the KB 
(see Figure 5).  To specify where the new concept 
belongs, the user navigates to the appropriate loca-
tion in the KB View (List Tab or Graph Tab). 
The user can also modify an existing KB con-
cept by adding English synonyms.  For example, 
the word ?United States? may be highlighted in a 
text example, while ?U.S.? is not.  To add a syno-
nym for the ?United States? concept, the user 
navigates to this concept in the KB View, and then 
clicks on the text ?U.S.?.  A menu offers the choice 
of adding a synonym to the existing focus concept.  
Figure 5 illustrates this process.   
5 Identifying KB Concepts in Text 
Elements in a Scone knowledge base represent 
specific concepts, rather than words or word 
senses.  Each concept is linked with a list of Eng-
lish names (words or phrases). This association 
between Scone elements and English names is 
many-to-many.  
To map a sentence to the set of concepts that 
appear there, a dynamic-programming alignment is 
performed using the English names in the KB as a 
dictionary.  SconeEdit searches for an alignment 
that covers as much of the input text as possible.  
The result of aligning an input string with concepts 
is a set of triples, each consisting of a concept, an 
offset, and a length.  These triples are used directly 
by the Text Tab to highlight substrings and associ-
ate them with KB concepts. 
Consider the sentence ?Washington, D.C. is a 
city.?  Table 1 shows some example Scone con-
cepts and their English names.  Given a knowledge  
286
Concept Name English Names 
Washington-State ?Washington?, ?Washing-ton State?,  
Washington-Dc ?Washington?, ?Washing-ton, D.C.? 
City ?city? 
Table 1.  Example concepts and their English 
Name lists 
 
base with these concepts, SconeEdit returns the 
alignment: (concept: Washington-DC, offset: 1, 
length: 16) (concept: City, offset: 23, length: 4). 
6 Planned Features 
A single node in the KB could have hundreds or 
thousands of outgoing links.  For readability, the 
browser must select a subset of these links to dis-
play to the user.  We plan to leverage Scone?s rea-
soning ability, along with SconeEdit?s document-
driven design, to select which nodes are likely to 
be relevant to the user in the context of the loaded 
document(s).  For example, a user who views sub-
classes of disease in a medical ontology may be 
presented with thousands of disease types.  If the 
current document loaded into SconeEdit is a 
document about food, Scone may be able to prune 
the subclasses it lists to only food-borne illnesses.  
Another feature we hope to add is better integra-
tion with an entire corpus. The current system al-
lows the user to work with individual documents.  
This could be extended to allow a user to navigate 
to a particular concept in the knowledge base and 
retrieve all documents in a corpus containing that 
concept (in its various forms).  These documents 
could then be used to generate more KB concepts 
of interest. 
7 Related Work 
To the best of our knowledge, existing ontology 
and KB editors and viewers do not specifically 
focus on editing and viewing an ontology or KB in 
the context of natural language text.  Other ontol-
ogy editors such as Prot?g? (Gennari, 2002) and 
OntoEdit (Sure, 2002) offer many features for gen-
erating complex ontologies, but do not provide the 
rich interaction with domain text that is the focus 
of SconeEdit.  The CNet Big Picture (CNet News 
Online, 2000) is one example of a system that does 
link ontology knowledge to text, but the concepts 
in the ontology are limited to a small fixed set. 
Acknowledgements 
This material is based upon work supported by the 
Defense Advanced Research Projects Agency 
(DARPA) under Contract No. NBCHD030010.  
The authors would like to thank Vasco Pedro, Eric 
Nyberg, and Tim Isganitis for their contributions to 
SconeEdit.  
References 
CNet News Online. 2000. The Big Picture, 
http://news.com.com/The+Big+Picture/2030-12_3-
5843390.html. 
Scott E. Fahlman. 2006. Scone User's Manual,  
http://www.cs.cmu.edu/~sef/scone/. 
J. Gennari, M. A. Musen, R. W. Fergerson, W. E. 
Grosso, M. Crubezy, H. Eriksson, N. F. Noy, S. W. 
Tu. 2002. The Evolution of Prot?g?: An Environment 
for Knowledge-Based Systems Development. Inter-
national Journal of Human-Computer Interaction, 
58(1), pp. 89?123. 
Ale? Hor?k and Pavel Smr?. 2004. VisDic -- WordNet 
Browsing and Editing Tool. Proceedings of GWC 
2004, pp. 136?141. 
INOH, 2004. INOH Ontology Viewer Website.  
http://www.inoh.org:8083/ontology-viewer/. 
Asako Koike and Toshishisa Takagi, 2004. 
Gene/protein/family name recognition in biomedical 
literature.  In Proceedings of  BioLINK 2004: Linking 
Biological Literature, Ontologies, and Databases, 
pp. 9-16. 
Alicia Tribble and Carolyn Ros?.  2006. Usable Brows-
ers for Ontological Knowledge Acquisition.  To ap-
pear in Proceedings of CHI-2006.  Montr?al, Canada. 
April 22-27, 2006. 
Xinhuanet. 2006. US accused of blocking approval of 
new UN human rights body. 
http://news.xinhuanet.com/english/2006-
03/02/content_4247159.htm. 
 Y. Sure, M. Erdmann, J. Angele, S. Staab, R. Studer 
and D. Wenke. OntoEdit: Collaborative Ontology 
Engineering for the Semantic Web. In Proceedings of 
the first International Semantic Web Conference 
2002 (ISWC 2002). 
287
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 121?124,
Prague, June 2007. c?2007 Association for Computational Linguistics
CMU-AT: Semantic Distance and Background Knowledge for Identify-
ing Semantic Relations 
Alicia Tribble 
Language Technologies Institute 
Carnegie Mellon University 
Pittsburgh, PA, USA 
atribble@cs.cmu.edu 
Scott E. Fahlman 
Language Technologies Institute 
Carnegie Mellon University 
Pittsburgh, PA, USA 
sef@cs.cmu.edu 
 
 
Abstract 
This system uses a background knowledge 
base to identify semantic relations between 
base noun phrases in English text, as eva-
luated in SemEval 2007, Task 4.  Training 
data for each relation is converted to state-
ments in the Scone Knowledge Representa-
tion Language.  At testing time a new 
Scone statement is created for the sentence 
under scrutiny, and presence or absence of 
a relation is calculated by comparing the 
total semantic distance between the new 
statement and all positive examples to the 
total distance between the new statement 
and all negative examples. 
   
1 Introduction 
This paper introduces a knowledge-based approach 
to the task of semantic relation classification, as 
evaluated in SemEval 2007, Task 4: ?Classifying 
Relations Between Nominals?.  In Task 4, a full 
sentence is presented to the system, along with the 
WordNet sense keys for two noun phrases which 
appear there and the name of a semantic relation 
(e.g. ?cause-effect?).  The system should return 
?true? if a person reading the sentence would con-
clude that the relation holds between the two la-
beled noun phrases. 
Our system represents a test sentence with a se-
mantic graph, including the relation being tested 
and both of its proposed arguments.  Semantic dis-
tance is calculated between this graph and a set of 
graphs representing the training examples relevant 
to the test sentence.  A near-match between a test 
sentence and a positive training example is evi-
dence that the same relation which holds in the 
example also holds in the test.  We compute se-
mantic distances to negative training examples as 
well, comparing the total positive and negative 
scores in order to decide whether a relation is true 
or false in the test sentence. 
2 Motivation 
Many systems which perform well on related tasks 
use syntactic features of the input sentence, 
coupled with classification by machine learning.  
This approach has been applied to problems like 
compound noun interpretation (Rosario and Hearst 
2001) and semantic role labeling (Gildea and Ju-
rafsky 2002). 
In preparing our system for Task 4, we started 
by applying a similar syntax-based feature analysis 
to the trial data: 140 labeled examples of the rela-
tion ?content-container?.  In 10-fold cross-
validation  with this data we achieved an average f-
score of 70.6, based on features similar to the sub-
set trees used for semantic role labeling in (Mo-
schitti 2004). For classification we applied the up-
dated tree-kernel package (Moschitti 2006), distri-
buted with the svm-light tool (Joachims 1999) for 
learning Support Vector Machines (SVMs). 
Training data for Task 4 is small, compared to 
other tasks where machine learning is commonly 
applied.  We had difficulty finding a combination 
of features which gave good performance in cross-
validation, but which did not result in a separate 
support vector being stored for every training sen-
tence ? a possible indicator of overfitting.  As an 
example, the ratio of support vectors to training 
121
examples for the experiment described above was 
.97, nearly 1-to-1.  
  As a result of this analysis we started work on 
our knowledge-based system, with the goal of us-
ing the two approaches together.  We were also 
motivated by an interest in using relation defini-
tions and background knowledge from WordNet to 
greater advantage.  The algorithm we used in our 
final submission is similar to recent systems which 
discover textual entailment relationships (Haghig-
hi, Ng et al 2005; Zanzotto and Moschitti 2006).  
It gives us a way to encode information from the 
relation definitions directly, in the form of state-
ments in a knowledge representation language.  
The inference rules that are learned by this system 
from training examples are also easier to interpret 
than the models generated by an SVM.  In small-
data applications this can be an advantage.  
3 System Description: A Walk-Through 
The example sentence below is taken (in abbre-
viated form) from the training data for Task 4, Re-
lation 7 ?Content-Container? (Girju, Hearst et al 
2007): 
 
The kitchen holds a cooker. 
 
We convert this positive example into a semantic 
graph by creating a new instance of the relation 
Contains and linking that instance to the WordNet 
term for each labeled argument ("kitch-
en%1:06:00::", "cooker%1:06:00::").  The result is 
shown in Figure 1.  WordNet sense keys (Fellbaum 
1998) have been mapped to a term, a part of 
speech (pos), and a sense number. 
Contains
{relation}
kitchen_n_1
cont iner content
cooker_n_1
 
Figure 1.  Semantic graph for the training example 
"The kitchen holds a cooker".   Arguments are 
represented by a WordNet term, part of speech, 
and sense number. 
 
This graph is instantiated as a statement using 
the Scone Knowledge Representation System, or  
(new-statement {kitchen_n_1} {contains} {cooker_n_1}) 
(new-statement {artifact_n_1} {contains} {artifact_n_1}) 
(new-statement  {whole_n_1}   {contains}  {whole_n_1}) 
Figure 2.  Statements in Scone KR syntax, based 
on generalizing the training example "The kitchen 
holds a cooker". 
 
?Scone? (Fahlman 2005).  Scone gives us a way to 
store, search, and perform inference on graphs like 
the one shown above.  After instantiating the graph 
we generalize it using hypernym information from 
WordNet.  This generates additional Scone state-
ments which are stored in a knowledge base (KB), 
shown in Figure 2.  The first statement in the fig-
ure was generated verbatim from our training sen-
tence.  The remaining statements contain hyper-
nyms of the original arguments. 
For each argument seen in training, we also ex-
tract hypernyms and siblings from WordNet.  For 
the argument kitchen, we extract 101 ancestors 
(artifact, whole, object, etc.) and siblings (struc-
ture, excavation, facility, etc.).  A similar set of 
WordNet entities is extracted for the argument 
cooker.  These entities, with repetitions removed, 
are encoded in a second Scone knowledge base, 
preserving the hierarchical (IS-A) links that come 
from WordNet.  The hierarchy is manually linked 
at the top level into an existing background Scone 
KB where entities like animate, inanimate, person, 
location, and quantity are already defined.   
After using the training data to create these two 
KBs, the system is  ready for a test sentence.  The 
following example is also adapted from SemEval 
Task 4 training data: 
 
     Equipment was carried in a box. 
 
First we convert the sentence to a semantic 
graph, using the same technique as the one de-
scribed above.  The graph is implemented as a new 
Scone statement which includes the WordNet pos 
and sense number for each of the arguments: 
?box_n_1 contains equipment_n_1?. 
Next, using inference operations in Scone, the 
system verifies that the statement conforms to 
high-level constraints imposed by the relation defi-
nition.  If it does, we calculate semantic distances 
between the argument nodes of our test statement 
and the analogous nodes in relevant training state-
ments.  A training statement is relevant if both of 
its arguments are ancestors of the appropriate ar-
122
guments of the test sentence.  In our example, only 
two of the three KB statements from Figure 2 are 
relevant to the test statement ?box contains equip-
ment?: ?whole contains whole? and ?artifact con-
tains artifact?.  The first statement, ?kitchen con-
tains cooker? fails to apply because kitchen is not 
an ancestor of box, and also because cooker is not 
an ancestor of equipment.   
Figure 3 illustrates the distance from ?box con-
tains equipment? to ?whole contains whole?, calcu-
lated as the sum of the distances between box-
whole and equipment-whole.  
Contains
{relation}
box equipment
container content
rtifact artifact
Contains
{relation}
whole whole
container content
Distance = 2
Support = 1/2
Distance = 2
Support = 1/2
 
Figure 3.  Calculating the distance through the 
knowledge base between "equipment contains box" 
and ?whole contains whole?.  Dashed lines indicate 
IS-A links in the knowledge base.   
 
The total number of these relevant, positive 
training statements is an indicator of ?support? for 
the test sentence throughout the training data.  The 
distance between one such statement and the test 
sentence is a measure of the strength of support.  
To reach a verdict, we sum over the inverse dis-
tances to all arguments from positive relevant ex-
amples: in Figure 3, the test statement ?box con-
tains equipment? receives a support score of  (?  + 
? + 1 + 1), or 3.      
Counter-evidence for a test sentence can be cal-
culated in the same way, using relevant negative 
statements.  In our example there are no negative 
training statements, so the total positive support 
score (3) is greater than the counter-evidence score 
(0), and the system verdict is ?true?. 
4 System Components in Detail 
As the detailed example above shows, this system 
is designed around its knowledge bases. The KBs 
provide a consistent framework for representing 
knowledge from a variety of sources as well as for 
calculating semantic distance. 
4.1 Background knowledge 
WordNet-extracted knowledge bases of the type 
described in Section 3 are generated separately for 
each relation.  Average depth of these hierarchies 
is 4; we store only hypernyms of WordNet depth 7 
and above, based on experiments in the literature 
by Nastase, et al (2003; 2006).  
Relation-specific and task-specific knowledge is 
encoded by hand.  For each relation, we examine 
the relation definition and create a set of con-
straints in Scone formalism.  For example, the de-
finition of ?container-contains? includes the fol-
lowing restriction (taken from training data for 
Task 4): There is strong preference against treat-
ing legal entities (people and institutions) as con-
tent. 
In Scone, we encode this preference as a type 
restriction on the container role of any Contains 
relation: (new-is-not-a {container} {potential 
agent}) 
During testing, before calculating semantic dis-
tances, the system checks whether the test state-
ment conforms to all such constraints. 
4.2 Calculating semantic distance 
Semantic distances are calculated between con-
cepts in the knowledge base, rather than through 
WordNet directly.  Distance between two KB en-
tites is calculated by counting the edges along the 
shortest path between them, as illustrated in Figure 
3.  In the current implementation, only ancestors in 
the IS-A hierarchy are considered relevant, so this 
calculation amounts to counting the number of an-
cestors between an argument from the test sentence 
and an argument from a training example.  Quick 
type-checking features which are built into Scone 
allow us to skip the distance calculation for non-
relevant training examples. 
5 Results & Conclusions 
This system performed reasonably well for relation 
3, Product-Producer, outperforming the baseline 
(baseline guesses ?true? for every test sentence).  
Performance for this relation was also higher than 
the average F-score for all comparable groups in 
Task 4 (all groups in class ?B4?).  Average recall 
for this system over all relations was mid-range, 
123
compared to other participating groups.  Average 
precision and average f-score fell below the base-
line and below the average for all comparable 
groups.  These scores are given in Table 1. 
 
Relation  R P F 
1.  Cause-Effect 73.2 54.5 62.5 
2.  Instrument-Agency 76.3 50.9 61.1 
3.  Product-Producer 79.0 71.0 74.8 
4.  Origin-Entity 63.9 54.8 59.0 
5.  Theme-Tool 48.3 53.8 50.9 
6.  Part-Whole 57.7 45.5 50.8 
7.  Content-Container 68.4 59.1 63.4 
Whole test set, not 
divided by relation 
57.1 68.9 62.4 
Average for CMU-AT 66.7 55.7 60.4 
Average for all B4 
systems 
64.4 65.3 63.6   
Baseline: ?alltrue? 100.0   48.5 64.8   
Table 1.  Recall, Precision, and F-scores, separated 
by relation type.  Baseline score is calculated by 
guessing "true" for all test setences. 
 
Analysis of the training data reveals that relation 
3 is the class where target nouns occur most often 
together in nominal compounds and base NPs, with 
little additional syntax to connect them.  While 
other relations included sentences where the targets 
were covered by a single VP, Product-Producer did 
not.  It seems that background knowledge plays a 
larger role in identifying the Producer-Produces 
relationship than it does for other relations.  How-
ever this conclusion is softened by the fact that we 
also spent more time in development and cross-
evaluation for relations 3 and 7, our two best per-
forming relations. 
This system demonstrates a knowledge-based 
framework  that performs very well for certain re-
lations.  Importantly, the system we submitted for 
evaluation did not make use of syntactic features, 
which are almost certainly relevant to this task.  
We are already exploring methods for combining 
the knowledge-based decision process with one 
that uses syntactic evidence as well as corpus sta-
tistics, described in Section 2. 
Acknowledgement 
This work was supported by a generous research 
grant from Cisco Systems, and by the Defense Ad-
vanced Research Projects Agency (DARPA) under 
contract number NBCHD030010.  
References 
Fahlman, S. E. (2005). Scone User's Manual. 
Fellbaum, C. (1998). WordNet An Electronic Lexical 
Database, Bradford Books. 
Gildea, D. and D. Jurafsky (2002). "Automatic labeling 
of semantic roles." Computational Linguistics 28(3): 
245-288. 
Girju, R., M. Hearst, et al (2007). Classification of Se-
mantic Relations between Nominals: Dataset for 
Task 4. SemEval 2007, 4th International Workshop 
on Semantic Evaluations, Prague, Czech Republic. 
Haghighi, A., A. Ng, et al (2005). Robust Textual Infe-
rence via Graph Matching. Human Language Tech-
nology Conference and Conference on Empirical 
Methods in Natural Language Processing, Vancou-
ver, British Columbia, Canada. 
Joachims, T. (1999). Making large-scale SVM learning 
practical. Advances in Kernel Methods - Support 
Vector Learning. B. Sch?lkopf, C. Burges and A. 
Smola. 
Moschitti, A. (2004). A study on Convolution Kernel 
for Shallow Semantic Parsing. proceedings of the 
42nd Conference of the Association for Computa-
tional   Linguistics (ACL-2004). Barcelona, Spain. 
Moschitti, A. (2006). Making tree kernels practical for 
natural language learning. Eleventh International 
Conference on European Association for Computa-
tional Linguistics, Trento, Italy. 
Nastase, V., J. S. Shirabad, et al (2006). Learning noun-
modifier semantic relations with corpus-based and 
Wordnet-based features. 21st National Conference on 
Artificial Intelligence (AAAI-06), Boston, Massa-
chusetts. 
Nastase, V. and S. Szpakowicz (2003). Exploring noun-
modifier semantic relations. IWCS 2003. 
Rosario, B. and M. Hearst (2001). Classifying the se-
mantic relations in Noun Compounds. 2001 Confe-
rence on Empirical Methods in Natural Language 
Processing. 
Zanzotto, F. M. and A. Moschitti (2006). Automatic 
Learning of Textual Entailments with Cross-Pair Si-
milarities. the 21st International Conference on 
Computational Linguistics and 44th Annual Meeting 
of the Association for Computational Linguistics 
(ACL), Sydney, Austrailia. 
124
