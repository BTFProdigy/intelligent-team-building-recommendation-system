BioNLP 2007: Biological, translational, and clinical language processing, pages 105?112,
Prague, June 2007. c?2007 Association for Computational Linguistics
From Indexing the Biomedical Literature to Coding Clinical Text: 
Experience with MTI and Machine Learning Approaches 
Alan R. Aronson1, Olivier Bodenreider1, Dina Demner-Fushman1, Kin Wah Fung1,  
Vivian K. Lee1,2, James G. Mork1, Aur?lie N?v?ol1, Lee Peters1, Willie J. Rogers1
1Lister Hill Center 
National Library of Medicine 
Bethesda, MD 20894 
{alan, olivier, demnerd, 
kwfung, mork, neveola,  
peters, wrogers} 
@nlm.nih.gov 
 
2Vanderbilt University 
Nashville, TN 37235 
vivian.lee@vanderbilt.edu 
 
 
Abstract 
This paper describes the application of an 
ensemble of indexing and classification 
systems, which have been shown to be suc-
cessful in information retrieval and classi-
fication of medical literature, to a new task 
of assigning ICD-9-CM codes to the clini-
cal history and impression sections of radi-
ology reports. The basic methods used are: 
a modification of the NLM Medical Text 
Indexer system, SVM, k-NN and a simple 
pattern-matching method. The basic meth-
ods are combined using a variant of stack-
ing. Evaluated in the context of a Medical 
NLP Challenge, fusion produced an F-
score of 0.85 on the Challenge test set, 
which is considerably above the mean 
Challenge F-score of 0.77 for 44 participat-
ing groups. 
1 Introduction 
Researchers at the National Library of Medicine 
(NLM) have developed the Medical Text Indexer 
(MTI) for the automatic indexing of the biomedical 
literature (Aronson et al, 2004). The unsupervised 
methods within MTI were later successfully com-
bined with machine learning techniques and ap-
plied to the classification tasks in the Genomics 
Track evaluations at the Text Retrieval Conference 
(TREC) (Aronson et al, 2005 and Demner-
Fushman et al, 2006). This fusion approach con-
sists of using several basic classification methods 
with complementary strengths, combining the re-
sults using a modified ensemble method based on 
stacking (Ting and Witten, 1997). 
While these methods have shown reasonable 
performance on indexing and retrieval tasks of 
biomedical articles, it remains to be determined 
how they would perform on a different biomedical 
corpus (e.g., clinical text) and on a different task 
(e.g., coding to a different controlled vocabulary). 
However, except for competitive evaluations such 
as TREC or BioCreAtIvE, corpora and gold stan-
dards for such tasks are generally not available, 
which is a limiting factor for such studies. For a 
survey of currently available corpora and devel-
opments in biomedical language processing, see 
Hunter and Cohen, 2006. 
The Medical NLP Challenge 1  sponsored by a 
number of groups including the Computational 
Medicine Center (CMC) at the Cincinnati Chil-
dren?s Hospital Medical Center gave us the oppor-
tunity to apply our fusion approach to a clinical 
corpus. The Challenge was to assign ICD-9-CM 
codes (International Classification of Diseases, 9th 
Revision, Clinical Modification) 2  to clinical text 
consisting of anonymized clinical history and im-
pression sections of radiology reports. 
The Medical NLP Challenge organizers distrib-
uted a training corpus of almost 1,000 of the ano-
nymized, abbreviated radiology reports along with 
                                                 
1 See www.computationalmedicine.org/challenge/.
2 See www.cdc.gov/nchs/icd9.htm.
105
gold standard ICD-9-CM assignments for each 
report obtained via a consensus of three independ-
ent sets of assignments. The primary measure for 
the Challenge was defined as the balanced F-score, 
with a secondary measure being cost-sensitive ac-
curacy. These measures were computed for sub-
missions to the Challenge based on a test corpus 
similar in size to the training corpus but distributed 
without gold standard code assignments. 
The main objective of this study is to determine 
what adaptation of the original methods is required 
to code clinical text with ICD-9-CM, in contrast to 
indexing and retrieving MEDLINE?. Note that an 
earlier study (Gay et al, 2005) showed that only 
minor adaptations were required in extending the 
original model to full-text biomedical articles. A 
secondary objective is to evaluate the performance 
of our methods in this new setting. 
 
2 Methods 
In early experimentation with the training corpus 
provided by the Challenge organizers, we discov-
ered that several of the training cases involved ne-
gated assertions in the text and that deleting these 
improved the performance of all basic methods 
being tested. For example, ?no pneumonia? occurs 
many times in the impression section of a report, 
sometimes with additional context. Section 2.1 
describes the process we used to remove these ne-
gated expressions; section 2.2 consists of descrip-
tions of the four basic methods used in this study; 
and section 2.3 defines the fusion of the basic 
methods to form a final result. 
2.1 Document Preparation 
The NegEx program (Chapman et al, 2001a and 
2001b, and Goldin and Chapman, 2003), which 
discovers negated expressions in text, was used to 
find negated expressions in the training and test 
corpora using a dictionary generated from concepts 
from the 2006AD version of the UMLS? Metathe-
saurus? (excluding the AMA vocabularies). A ta-
ble containing the concept unique identifier (CUI) 
and English string (STR with LAT=?ENG?) was 
extracted from the main concept table, MRCON, 
and was used as input to NegEx to generate a dic-
tionary that was later used as the universe of ex-
pressions which NegEx could find to be negated in 
the target corpora. (See the Appendix for examples 
of the input and output to this process.) 
The XML text of the training and test corpora 
was converted to a tree representation and then 
traversed, operating on one radiology report at a 
time. The clinical history and impression sections 
of each report were tokenized to allow whitespace 
to be separated from the punctuation, numbers and 
alphabetic text. The concepts from the UMLS were 
tokenized in the same way, to allow the concepts 
found by NegEx to be aligned with the text. The 
negation phrases discovered by NegEx were also 
tokenized to find the appropriate negation phrase 
preceding or trailing the target concept. Using the 
location information obtained by matching the set 
of one or more target concepts and the associated 
negation phrase, the overlapping concept spans 
were merged and the span for the negation phrase 
and the outermost negated concept was removed. 
Any intervening concepts associated with the same 
negation phrase were removed, too. The abbrevi-
ated tree representation was then re-serialized back 
into XML. 
As an example of our use of NegEx, consider 
the report with clinical history ?13-year 2-month - 
old female evaluate for cough.? and impression 
?No focal pneumonia.? After removal of negated 
text, the clinical history becomes ?13-year 2-month 
- old female?, and the discussion is empty. 
2.2 Basic Methods 
The four basic methods used for the Medical NLP 
Challenge are MTI (a modification of NLM?s 
Medical Text Indexer system), SVM (Support 
Vector Machines), k-NN (k Nearest Neighbors) 
and Pattern Matching (a simple, pattern-based clas-
sifier). Each of these methods is described here. 
Note that the MTI method uses a ?Restrict to ICD-
9-CM? algorithm that is described in the next sec-
tion. 
 
MTI. The original Medical Text Indexer (MTI) 
system, shown in Figure 1, consists of an infra-
structure for applying alternative methods of dis-
covering MeSH? headings for citation titles and 
abstracts and then combining them into an ordered 
list of recommended indexing terms. The top por-
tion of the diagram consists of two paths, or meth-
ods, for creating a list of recommended indexing 
terms: MetaMap Indexing and PubMed? Related 
Citations. The MetaMap Indexing path actually 
106
computes UMLS Metathesaurus concepts, which 
are passed to the Restrict to MeSH process 
(Bodenreider et al, 1998). The results from each 
path are weighted and combined using Post-
Processing, which also refines the results to con-
form to NLM indexing policy. The system is 
highly parameterized not only by path weights but 
also by several parameters specific to the Restrict 
to MeSH and Post-Processing processes. 
 
 
 
Figure 1: Medical Text Indexer (MTI) System 
 
For use in the Challenge, the Medical Text In-
dexer (MTI) program itself required few adapta-
tions.  Most of the changes involved the environ-
ment from which MTI obtains the data it uses 
without changing the normal parameter settings. 
We also added a further post-processing compo-
nent to filter our results. 
For the environment, we replaced MTI?s normal 
?Restrict to MeSH? algorithm with a ?Restrict to 
ICD-9-CM? algorithm, described below, in order 
to map UMLS concepts to ICD-9-CM codes in-
stead of MeSH headings. We also trained the Pub-
Med Related Citations component, TexTool (Ta-
nabe and Wilbur, 2002), on the Medical NLP Chal-
lenge training data instead of the entire MED-
LINE/PubMed database as is the case for normal 
MTI use at NLM.  For both of these methods, we 
used the actual ICD-9-CM codes to mimic UMLS 
CUIs used internally by MTI. 
To create the new training data for the TexTool 
(Related Citations), we reformatted the Medical 
NLP Challenge training data into a pseudo-
MEDLINE format using the ?doc id? component 
as the PMID, the ?CLINICAL_HISTORY? text 
component for the Title, the ?IMPRESSION? text 
component for the Abstract, and all of the 
?CMC_MAJORITY? codes as MeSH Headings 
(see Figure 2).  This provided us with direct ICD-
9-CM codes to work with instead of MeSH Head-
ings. 
 
<doc id="97663756" type="RADIOLOGY_REPORT"> 
  <codes> 
    <code origin="CMC_MAJORITY" type="ICD-9-
CM">780.6</code> 
    <code origin="CMC_MAJORITY" type="ICD-9-
CM">786.2</code> 
    <code origin="COMPANY3" type="ICD-9-
CM">786.2</code> 
    <code origin="COMPANY1" type="ICD-9-
CM">780.6</code> 
    <code origin="COMPANY1" type="ICD-9-
CM">786.2</code> 
    <code origin="COMPANY2" type="ICD-9-
CM">780.6</code> 
    <code origin="COMPANY2" type="ICD-9-
CM">786.2</code> 
  </codes> 
  <texts> 
    <text origin="CCHMC_RADIOLOGY" 
type="CLINICAL_HISTORY">Cough and fever.</text> 
    <text origin="CCHMC_RADIOLOGY" 
type="IMPRESSION">Normal radiographic appear-
ance of the chest, no pneumonia.</text> 
  </texts> 
</doc> 
PMID- 97663756 
TI  - Cough and fever. 
AB  - Normal radiographic appearance of the 
chest, no pneumonia. 
MH  - Fever (780.6) 
MH  - Cough (786.2) 
 
Figure 2: XML Medical NLP Training Data modi-
fied to pseudo-ASCII MEDLINE format 
 
Within MTI we also utilized an experimental 
option for MetaMap (Composite Phrases), which 
provides a longer UMLS concept match than usual. 
We did not use the following: (1) UMLS concept-
specific checking and exclusion sections; and (2) 
the MeSH Subheading generation, checking, and 
removal elements, since they were not needed for 
this Challenge. We then had MTI use the new Re-
107
strict to ICD-9-CM file and the new TexTool to 
generate its results. 
 
Restrict to ICD-9-CM. The mapping of every 
UMLS concept to ICD-9-CM developed for the 
Medical NLP Challenge is an adaptation of the 
original mapping to MeSH, later generalized to any 
target vocabulary (Fung and Bodenreider, 2005). 
Based on the UMLS Metathesaurus, the mapping 
utilizes four increasingly aggressive techniques: 
synonymy, built-in mappings, hierarchical map-
pings and associative mappings. In order to comply 
with coding rules in ICD-9-CM, mappings to non-
leaf codes are later resolved into leaf codes. 
Mappings to ICD-9-CM are identified through 
synonymy when names from ICD-9-CM are in-
cluded in the UMLS concept identified by 
MetaMap. For example, the ICD-9-CM code 592.0 
Calculus of kidney is associated with the UMLS 
concept C0392525 Nephrolithiasis through synon-
ymy. 
Built-in mappings are mapping relations be-
tween UMLS concepts implied from mappings 
provided by source vocabularies in the UMLS. For 
example, the UMLS concept C0239937 Micro-
scopic hematuria is mapped to the concept 
C0018965 (which contains the ICD-9-CM code 
599.7 Hematuria) through a mapping provided by 
SNOMED CT. 
In the absence of a mapping through synonymy 
or built-in mapping, a hierarchical mapping is 
attempted. Starting from the concept identified by 
MetaMap, a graph of ancestors is built by first us-
ing its parent concepts and broader concepts, then 
adding the parent concepts and broader concepts of 
each concept, recursively. Semantic constraints 
(based on semantic types) are applied in order to 
prevent semantic drift. Ancestor concepts closest 
to the MetaMap source concept are selected from 
the graph. Only concepts that can be resolved into 
ICD-9-CM codes (through synonymy or built-in 
mapping) are selected. For example, starting from 
C0239574 Low grade pyrexia, a mapping is found 
to ICD-9-CM code 780.6 Fever, which is con-
tained in the concept C0015967, one of the ances-
tors of C0239574. 
The last attempt to find a mapping involves not 
only hierarchical, but also associative relations. 
Instead of starting from the concept identified by 
MetaMap, associative mappings explore the con-
cepts in associative relation to this concept. For 
example, the concept C1458136 Renal stone sub-
stance is mapped to ICD-9-CM code 592.0 Calcu-
lus of kidney. 
Finally, when the identified ICD-9-CM code 
was not a leaf code (e.g., 786.5 Chest pain), we 
remapped it to one of the corresponding leaf codes 
in the training set where possible (e.g., 786.50 Un-
specified chest pain). 
Of the 2,331 UMLS concepts identified by 
MetaMap in the test set after freezing the method, 
620 (27%) were mapped to ICD-9-CM. More spe-
cifically, 101 concepts were mapped to one of the 
45 target ICD-9-CM codes present in the training 
set. Of the 101 concepts, 40 were mapped through 
synonymy, 11 through built-in mappings, 40 
through hierarchical mapping and 10 through asso-
ciative mapping. 
 
After the main MTI processing was completed, 
we applied a post-processing filter, restricting our 
results to the list of 94 valid combinations of ICD-
9-CM codes provided in the training set (hence-
forth referred to as allowed combinations) and 
slightly emphasizing MetaMap results. Examples 
of the post-processing rules are: 
? If MTI recommended 079.99 (Unspecified 
viral infection in conditions?) via either 
MetaMap or Related Citations, use 079.99, 
493.90 (Asthma, unspecified type?), and 
780.6 (Fever) for indexing. This is the only 
valid combination for this code based on the 
training corpus. 
? Similarly, if MTI recommended ?Enlarge-
ment of lymph nodes? (785.6) via the 
MetaMap path with a score greater then 
zero, use 785.6 and 786.2 (Cough) for in-
dexing. 
The best F-score (F = 0.83) for the MTI method 
was obtained on the training set using the negation-
removed text.  This was a slight improvement over 
using the original text (F = 0.82). 
 
SVM. We utilized Yet Another Learning Envi-
ronment3 (YALE), an open source application de-
veloped for machine learning and data mining, to 
determine the data classification performance of 
support vector machine (SVM) learning on the 
                                                 
3 See http://rapid-i.com. 
108
training data. To prepare the Challenge data for 
analysis, we removed all stop words and created 
feature vectors for the free text extracted from the 
?CLINICAL_HISTORY? and ?IMPRESSION? 
fields of the records.  Since both the training and 
test Challenge data had a known finite number of 
individual ICD-9-CM labels (45) and distinct com-
binations of ICD-9-CM labels (94), the data was 
prepared both as feature vectors for 45 individual 
labels as well as a model with 94 combination la-
bels.  In addition, the feature vectors were created 
using both simple term frequency as well as in-
verse document frequency (IDF) weighting, where 
the weight is (1+log(term frequency))*(total 
documents/document frequency).  There were thus 
a total of four feature vector datasets: 1) 45 indi-
vidual ICD-9-CM labels and simple term fre-
quency, 2) 45 ICD-9-CM labels and IDF weight-
ing, 3) 94 ICD-9-CM combinations and simple 
term frequency, and 4) 94 ICD-9-CM combina-
tions and IDF weighting. 
The YALE tool encompasses a number of SVM 
learners and kernel types.  For the classification 
problem at hand, we chose the C-SVM learner and 
the radial basis function (rbf) kernel.  The C-SVM 
learner attempts to minimize the error function 
?
=
+
N
i
i
T Cww
1
,
2
1 ?  
Niandbxw iii
T
i ,,1,01))(( K=???+ ????
 
where w is the vector of coefficients, b is a con-
stant, ?  is the kernel function, x are the independ-
ent variables, and ?i are parameters for handling 
the inputs.  C > 0 is the penalty parameter of the 
error function.  The rbf kernel is defined as K(x, 
x?) = exp(?? |x ? x?|2), ? > 0 where ? is a kernel 
parameter that determines the rbf width. We ran 
cross-validation experiments using YALE on all 
training datasets and varying C (10, 100, 1000, 
10000) and ? (0.01, 0.001, 0.0001, 0.00001) to de-
termine the optimal C and ? combination.  The 
cross-validation experiments generated classifica-
tion models that were then applied to the complete 
training datasets to analyze the performance of the 
learner. The 94 ICD-9-CM combination and sim-
ple term frequency dataset with C = 10000 and ? = 
0.01 had the best F-score at 0.86.  The best F-score 
for the 94 ICD-9-CM combination and IDF weight 
dataset was 0.79, where C = 0.001 and ? = 10000.   
Further preprocessing the training dataset by 
removing negated expressions was found to im-
prove the best F-score from 0.86 to 0.87.  The C = 
10000 and ? = 0.01 combination was then applied 
to the test dataset, which was preprocessed to re-
move negation and stop words and transformed to 
a feature vector using 94 ICD-9-CM combinations 
and simple term weighting.  The predicted ICD-9-
CM classifications and confidence of the predic-
tions for each clinical free text report were output 
and later combined with other methods to optimize 
the accuracy and precision of our ICD-9-CM clas-
sifications. 
 
k-NN. The Challenge training set was used to 
build a k-NN classifier. The k-NN classification 
method works by identifying, within a labelled set, 
documents similar to the document being classi-
fied, and inferring a classification for it from the 
labels of the retrieved neighbors. 
The free text in the training data set was proc-
essed to obtain a vector-space representation of the 
patient reports.  
Several methods of obtaining this representation 
were tested: after stop words were removed, simple 
term frequency and inverse document frequency 
(IDF) weighting were applied alternatively. A 
higher weight was also given to words appearing in 
the history portion of the text (vs. impression). 
Eventually, the most efficient representation was 
obtained by using controlled vocabulary terms ex-
tracted from the free text with MetaMap.4 Further 
processing on this representation of the training 
data showed that removing negated portions of the 
free text improved the results, raising the F-score 
from 0.76 to 0.79.   
Other parameters were also assessed on the 
training data, such as the number of neighbors to 
use (2 was found to be the best vs. 5, 10 or 15) and 
the restriction of the ICD-9-CM predictions to the 
set of 94 allowed combinations. When the predic-
tion for a given document was not within the set of 
allowed 94 combinations, an allowed subset of the 
ICD-9-CM codes predicted was selected based on 
the individual scores obtained for each ICD-9-CM 
code.  
The best F-score (F = 0.79) obtained on the 
training set used the MetaMap-based representa-
                                                 
4 Note that this use of MetaMap is independent of its 
inclusion as a component of MTI. 
109
tion with simple frequency counts on the text with 
negated expressions removed. ICD-9-CM predic-
tions were obtained from the nearest neighbors and 
restricted to one of the 94 allowed combinations.   
 
Pattern Matching. We developed a pattern-
matching classifier as a baseline for our more so-
phisticated classification methods. A list of all 
UMLS string representations for each of 45 codes 
(including synonyms from source vocabularies 
other than ICD-9-CM) was created as described in 
the MTI section above. The strings were then con-
verted to lower case, punctuation was removed, 
and strings containing terms unlikely to be found 
in a clinical report were pruned. For example, Ab-
domen NOS pain and Abdominal pain (finding) 
were reduced to abdominal pain. For the same rea-
sons, some of the strings were relaxed into pat-
terns. For example, it is unlikely to see PAIN 
CHEST in a chart, but very likely to find pain in 
chest. The string, therefore, was relaxed to the fol-
lowing pattern: pain.*chest. The text of the clinical 
history and the impression fields of the radiology 
reports with negated expressions removed (see 
Section 2.2) was broken up into sentences. Each 
sentence was then searched for all available pat-
terns. A corresponding code was assigned to the 
document for each matched pattern. This pattern 
matching achieved F-score = 0.79 on the training 
set. To reduce the number of codes assigned to a 
document, a check for allowed combinations was 
added as a post-processing step. The combination 
of assigned codes was looked up in the table of 
allowed codes. If not present, the codes were re-
duced to the combination of assigned codes most 
frequently occurring in the training set. This 
brought the F-score up to 0.84 on the training data. 
As the performance of this classifier was compara-
ble to other methods, we decided to include these 
results when combining the predictions of the other 
classifiers.  
2.3 Fusion of  Basic Methods: Stacking 
Experience with ad hoc retrieval tasks in the TREC 
Genomics Track has shown that combining predic-
tions of several classifiers either significantly im-
proves classification results, or at least provides 
more consistent and stable results when the train-
ing data set is small (Aronson et al, 2005). We 
therefore experimented with stacking (Ting and 
Witten, 1997), using a simple majority vote and a 
union of all assigned codes as baselines. The pre-
dictions of base classifiers described in the previ-
ous section were combined using our re-
implementation of the stacked generalization pro-
posed by Ting and Witten.  
3 Results 
Table 1 shows the results obtained for the training 
set. The best stacking results were obtained using 
predictions of all four base classifiers on the text 
with deleted negated expressions and with check-
ing for allowed combinations. We retained all final 
predictions with probability of being a valid code 
greater than 0.3. Checking for the allowed combi-
nations for the ensemble classifiers degraded the F-
score significantly. 
 
Classifier F-score 
MTI 0.83 
SVM 0.87 (x-validation) 
k-NN 0.79 (x-validation) 
Pattern Matching 0.84 
Majority 0.82 
Stacking 0.89 
 
Table 1: Training results for each classifier, the ma-
jority and stacking 
 
Since stacking produced the best F-score on the 
training corpus and is known to be more robust 
than the individual classifiers, the corresponding 
results for the test corpus were submitted to the 
Challenge submission website. The stacking results 
for the test corpus achieved an F-score of 0.85 and 
a secondary, cost-sensitive accuracy score of 0.83. 
For comparison purposes, 44 Challenge submis-
sions had a mean F-score of 0.77 with a maximum 
of 0.89. Our F-score of 0.85 falls between the 70th 
and 75th percentiles. 
4 Discussion 
It is significant that it was fairly straightforward to 
port various methods developed for ad hoc MED-
LINE citation retrieval, indexing and classification 
to the assignment of codes to clinical text. The 
modifications to MTI consisted of replacing Re-
strict to MeSH with Restrict to ICD-9-CM, training 
the Related Citations method on clinical text and 
replacing MTI?s normal post-processing with a 
much simpler version. Preprocessing the text using 
110
NegEx to remove negated expressions was a fur-
ther modification of the overall approach. 
It is noteworthy that a simple pattern-matching 
method performed as well as much more sophisti-
cated methods in the effort to fuse results from 
several methods into a final outcome. This unex-
pected success might be explained by the follow-
ing limitations of the Challenge. 
Possible limitations on the extensibility of the 
current research arise from two observations: (1) 
the Challenge cases were limited to two relatively 
narrow topics, cough/fever/pneumonia and uri-
nary/kidney problems; and (2) the clinical text was 
almost error-free, a situation that would not be ex-
pected in the majority of clinical text. It is possible 
that these conditions contributed to the success of 
the pattern-matching method but also caused 
anomalous behavior, such as the fact that simple 
frequency counts provided a better representation 
than IDF for the SVM and k-NN methods. 
Finally, as a result of low confidence in the 
ICD-9-CM code assignment, no codes were as-
signed to 29 records in the test set. It is worthwhile 
to explore the causes for such null assignments. 
One of the reasons for low confidence could be the 
aggressive pruning of the text by the negation algo-
rithm. For example, after removal of negated text 
in the sample report given in section 2.1, the only 
remaining text is ?13-year 2-month - old female? 
from the clinical history field; this provided no 
evidence for code assignment. Secondly, in some 
cases the original text was not sufficient for confi-
dent code assignment. For example, for the docu-
ment with clinical history ?Bilateral grade 3.? and 
impression ?Interval growth of normal appearing 
Kidneys?, no code was assigned by the SVM, k-
NN, or pattern-matching classifiers. Code 593.70 
corresponding to the UMLS concept Vesicouret-
eral reflux with reflux nephropathy, unspecified or 
without reflux nephropathy was assigned by MTI 
with a very low confidence, which was not suffi-
cient for the final assignment of the code. The third 
reason for assigning no code to a document was 
the wide range of assignments provided by the 
base classifiers. For example, for the following 
document: ?CLINICAL_HISTORY: 3-year - old 
male with history of left ureteropelvic and uret-
erovesical obstruction. Status post left pyeloplasty 
and left ureteral reimplantation. IMPRESSION: 1. 
Stable appearance and degree of hydronephrosis 
involving the left kidney. Stable urothelial thicken-
ing. 2. Interval growth of kidneys, left greater than 
right. 3. Normal appearance of the right kidney 
with interval resolution of right urothelial thicken-
ing.? MTI assigned codes 593.89 Other specified 
disorders of kidney and ureter and 591 Hy-
dronephrosis. Codes 593.70 Vesicoureteral reflux 
with reflux nephropathy, unspecified or without 
reflux nephropathy and 753.3 Double kidney with 
double pelvis were assigned by the k-NN classifier. 
Pattern matching resulted in assignment of code 
591 with fairly low confidence. No code was as-
signed to this document by the SVM classifier. 
Despite failing to assign codes to these 29 records, 
the conservative approach (using threshold) re-
sulted in better performance, achieving F-score 
0.85 compared to F-score 0.80 when all 1,634 
codes assigned by the base classifiers were used. 
5 Conclusion 
We are left with two conclusions. First, this re-
search confirms that combining several comple-
mentary methods for accomplishing tasks, ranging 
from ad hoc retrieval to categorization, produces 
results that are better and more stable than the re-
sults for the contributing methods. Furthermore, 
we have shown that the basic methods employing 
domain knowledge and advanced statistical algo-
rithms are applicable to clinical text without sig-
nificant modification. Second, although there are 
some limitations of the current Challenge test col-
lection of clinical text, we appreciate the efforts of 
the Challenge organizers in the creation of a test 
collection of clinical text. This collection provides 
a unique opportunity to apply existing methods to a 
new and important domain. 
Acknowledgements 
This work was supported in part by the Intramural 
Research Program of the NIH, National Library of 
Medicine and by appointments of Aur?lie N?v?ol 
and Vivian Lee to the NLM Research Participation 
Program sponsored by the National Library of 
Medicine and administered by the Oak Ridge Insti-
tute for Science and Education. 
The authors gratefully acknowledge the many 
essential contributions to MTI, especially W. John 
Wilbur for the PubMed Related Citations indexing 
method, and Natalie Xie for adapting TexTool (an 
interface to Related Citations) for this paper. 
111
References 
Aronson AR, Demner-Fushman D, Humphrey SM, Lin 
J, Liu H, Ruch P, Ruiz ME, Smith LH, Tanabe LK, 
Wilbur WJ. Fusion of knowledge-intensive and sta-
tistical approaches for retrieving and annotating tex-
tual genomics documents. Proc TREC 2005, 36-45. 
Aronson AR, Mork JG, Gay CW, Humphrey SM and 
Rogers WJ. The NLM Indexing Initiative's Medical 
Text Indexer. Medinfo. 2004: 268-72. 
Bodenreider O, Nelson SJ, Hole WT and Chang HF. 
Beyond synonymy: exploiting the UMLS semantics 
in mapping vocabularies. Proc AMIA Symp 1998: 
815-9. 
Chapman WW, Bridewell W, Hanbury P, Cooper GF, 
Buchanan B. Evaluation of negation phrases in narra-
tive clinical reports. Proc AMIA Symp. 2001a:105-9.  
Chapman WW, Bridewell W, Hanbury P, Cooper GF 
and Buchanan BG. A simple algorithm for identify-
ing negated findings and diseases in discharge sum-
maries. J Biomed Inform. 2001b;34:301-10.  
Demner-Fushman D, Humphrey SM, Ide NC, Loane RF, 
Ruch P, Ruiz ME, Smith LH, Tanabe LK, Wilbur WJ 
and Aronson AR. Finding relevant passages in scien-
tific articles: fusion of automatic approaches vs. an 
interactive team effort. Proc TREC 2006, 569-76. 
Fung KW and Bodenreider O. Utilizing the UMLS for 
semantic mapping between terminologies. AMIA 
Annu Symp Proc 2005: 266-70. 
Gay CW, Kayaalp M and Aronson AR. Semi-automatic 
indexing of full text biomedical articles. AMIA Annu 
Symp Proc. 2005:271-5. 
Goldin I and Chapman WW. Learning to detect nega-
tion with ?not? in medical texts. Proc Workshop on 
Text Analysis and Search for Bioinformatics, ACM 
SIGIR, 2003. 
Hunter L and Cohen KB. Biomedical language process-
ing: what?s beyond PubMed? Mol Cell. 2006 Mar 
3;21(5):589-94. 
Tanabe L and Wilbur WJ. (2002) Tagging gene and 
protein names in biomedical text. Bioinformatics, 
Aug 2002; 18: 1124 ?32. 
Ting WK and Witten I. 1997. Stacking bagged and dag-
ged models. 367-375. Proc. of ICML'97. Morgan 
Kaufmann, San Francisco, CA.
Appendix  
A sample of the input to NegEx for dictionary generation:  
 
C0002390 pneumonitis, allergic interstitial 
C0002390 allergic interstitial pneumonitis, nos 
C0002390 extrinsic allergic bronchiolo alveolitis 
C0002390 extrinsic allergic bronchiolo alveolitis, nos 
C0002390 hypersensitivity pneumonia 
C0002390 hypersensitivity pneumonia, nos 
C0002390 eaa  extrinsic allergic alveolitis 
C0002390 allergic extrinsic alveolitis nos (disorder) 
C0002390 extrinsic allergic alveolitis (disorder) 
C0002390 hypersensitivity pneumonitis nos (disorder) 
 
A sample of the dictionary generated by NegEx for later use in detecting negated expressions:  
 
C0002098 hypersensitivity granuloma (morphologic abnormality 
C0151726 hypersensitivity injection site 
C0020517 hypersensitivity nos 
C0429891 hypersensitivity observations 
C0002390 hypersensitivity pneumonia 
C0002390 hypersensitivity pneumonia, nos 
C0002390 hypersensitivity pneumonitides 
C0005592 hypersensitivity pneumonitides, avian 
C0002390 hypersensitivity pneumonitis 
C0182792 hypersensitivity pneumonitis antibody determination re-
agents 
112
Proceedings of the BioNLP Shared Task 2013 Workshop, pages 50?57,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
GRO Task: Populating the Gene Regulation Ontology with events and 
relations 
 
 
Jung-jae Kim, 
Xu Han 
School of Computer Engineering 
Nanyang Technological University 
Nanyang Avenue, Singapore 
jungjae.kim@ntu.edu.sg, 
HANX0017@e.ntu.edu.sg 
Vivian Lee 
European Bioinfor-
matics Institute 
Wellcome Trust Ge-
nome Campus 
Hinxton, Cambridge, 
UK 
vivian_clee@ 
yahoo.com 
Dietrich Rebholz-
Schuhmann 
Institute of Computational 
Linguistics 
University of Zurich  
Binzm?hlestrasse 14  
Zurich, Switzerland  
rebholz@cl.uzh.ch 
 
  
 
Abstract 
Semantic querying over the biomedical litera-
ture has gained popularity, where a semantic 
representation of biomedical documents is re-
quired. Previous BioNLP Shared Tasks exer-
cised semantic event extraction with a small 
number of pre-defined event concepts. The 
GRO task of the BioNLP?13-ST imposes the 
challenge of dealing with over 100 GRO con-
cepts. Its annotated corpus consists of 300 
MEDLINE abstracts, and an analysis of inter-
annotator agreement on the annotations by two 
experts shows Kappa values between 43% and 
56%. The results from the only participant are 
promising with F-scores 22% (events) and 
63% (relations), and also lead us to open is-
sues such as the need to consider the ontology 
structure. 
1 Background 
As semantic resources in the biomedical domain, 
including ontologies and linked data, increase, 
there is a demand for semantic querying over the 
biomedical literature, instead of the keyword 
searching supported by conventional search en-
gines (e.g. PubMed). The semantic search re-
quires adapting Semantic Web technologies to 
the literature, to analyze the complex semantics 
described in biomedical documents and to repre-
sent them with ontology concepts and relations. 
The ontology-based formal semantics will then 
form a Semantic Web. The GRO task of the 
BioNLP Shared Tasks 2013 is to provide a plat-
form to develop and evaluate systems for identi-
fying complex semantic representation of bio-
medical documents in the domain of gene regula-
tion. 
   There are solutions for servicing the ontology 
concepts recognized in the biomedical literature, 
including TextPresso (M?ller et al, 2004) and 
GoPubMed (Doms and Schroeder, 2005). They 
utilize term recognition methods to locate the 
occurrences of ontology terms, together with 
terminological variations. Systems like EBIMed 
(Rebholz-Schuhmann et al, 2007) and FACTA 
(Tsuruoka et al, 2008) go further to collect and 
display co-occurrences of ontology terms. How-
ever, they do not extract events and relations of 
the semantic types defined in ontologies. 
The annotation of those ontology event and re-
lation instances described in text was initiated in 
the biomedical domain by the GENIA corpus 
(Kim et al, 2003), and the tasks of the BioNLP 
Shared Tasks 2009 and 2011 aimed at automati-
cally identifying such ontological annotations. 
However, the tasks dealt only with a small num-
ber of ontology concepts (less than 20 unique 
concepts in total), considering the thousands of 
concepts defined in standard biomedical ontolo-
gies (e.g. Gene Ontology, anatomy ontologies). 
The goal of the Gene Regulation Ontology 
(GRO) task is to confirm if text mining tech-
niques can be scaled up to cover hundreds of 
(and eventually thousands of) concepts, and 
thereby to address the complex semantic repre-
sentation of biomedical documents. 
The GRO task is to automatically annotate bi-
omedical documents with the Gene Regulation 
Ontology (Beisswanger et al, 2008). GRO is a 
50
conceptual model of gene regulation and in-
cludes 507 concepts, which are cross-linked to 
such standard ontologies as Gene Ontology and 
Sequence Ontology and are integrated into a 
deep hierarchical structure via is-a and part-of 
relations. Note that many of the GRO concepts 
are more specific than those used in the previous 
BioNLP Shared Tasks. The GRO is one of the 
first ontological resources that bring together 
different types of ontology concepts and relations 
in a coherent structure. It has two top-level cate-
gories of concepts, Continuant and Occurrent, 
where the Occurrent branch has concepts for 
processes that are related to the regulation of 
gene expression (e.g. Transcription, 
RegulatoryProcess), and the Continuant branch 
has concepts mainly for physical entities that are 
involved in those processes (e.g. Gene, Protein, 
Cell). It also defines semantic relations (e.g. 
hasAgent, locatedIn) that link the instances of the 
concepts. The GRO task in the BioNLP Shared 
Task (ST) 2013 assumes that the instances of 
Continuant concepts are provided and focuses on 
extracting the instances of the events and rela-
tions defined in the GRO. 
This paper is organized as follows: We de-
scribe the manual construction of the training 
and test datasets for the task in Section 2 and ex-
plain the evaluation criteria and the results in 
Section 3. 
2 Corpus annotation 
2.1 Annotation elements 
The BioNLP?13-ST GRO task follows the repre-
sentation and task setting of the ST?09 and ST?11 
main tasks. The representation involves three 
primary categories of annotation elements: enti-
ties (i.e. the instances of Continuant concepts), 
events (i.e. those of Occurrent concepts) and re-
lations. Mentions of entities in text can be either 
contiguous or discontinuous spans that are as-
signed the most specific and appropriate Contin-
uant concepts (e.g. TranscriptionFactor, 
CellularComponent). The event annotation is 
associated with the mention of a contiguous span 
in text (called event trigger) that explicitly sug-
gests the annotated event type (e.g. ?controls? - 
RegulatoryProcess). If a participant of an event, 
either an entity or another event, can be explicit-
ly identified with a specific mention in text, the 
participant is annotated with its role in the event. 
In this task, we consider only two types of roles 
(i.e. hasAgent, hasPatient), where an agent of an 
event is the entity that causes or initiates the 
event (e.g. a protein that causes a regulation 
event), and a patient of an event is the entity up-
on which the event is carried out (e.g. the gene 
that is expressed in a gene expression event) 
(Dowty, 1991). The semantic relation annotation 
is to annotate other semantic relations (e.g. 
locatedIn, fromSpecies) between entities and/or 
events, without event triggers. Figure 1 illustrates 
some of the annotations.  
2.2 Document selection  
The corpus texts are selected based on the rele-
vance to the topic of gene regulation in humans. 
Specifically, we first obtained a list of human 
transcription factors (TFs) and then used Pub-
Med to collect a set of candidate documents. A 
random subset of 300 documents was then se-
lected for the GRO task from the collection. We 
annotated entities, events, and relations in them, 
and divided them into three subsets of 150 (train-
ing), 50 (development), and 100 (test) docu-
ments. In fact, 100 out of the 200 documents for 
training and development are from Kim et al 
(2011a), though we revised and updated their 
annotations based on new annotation guidelines, 
some of which are explained below.  
2.3 Annotation guidelines 
The first step of annotating ontology concepts in 
the text is the recognition of a word or a phrase 
that refers to a concept of the GRO. Such a word 
or phrase, called mention, is one of the names of 
the concept, its synonyms, or expressions that are 
semantically equivalent to or subsumed by the 
concept. For each mention, we annotate it with 
the single, most specific and appropriate concept, 
but not with any general concept. For example, if 
Figure 1. Example annotations of the GRO corpus 
51
a protein is clearly mentioned as a transcription 
factor in the text, we annotate it with the GRO 
concept TranscriptionFactor, not with Protein. 
There are many issues in the annotation, and 
we here introduce our guidelines on two of them 
about complex noun phrases and overlapping 
concepts.  
1) If a noun phrase refers to an event that cor-
responds to an Occurrent concept and includes 
mentions of other concepts, we consider sepa-
rately annotating the multiple mentions in the 
phrase with concepts and relations. For example 
in the phrase ?nephric duct formation?, we anno-
tate it as follows:  
? ?formation?:CellularProcess hasPatient 
?nephric duct?:Cell 
This means that the phrase indicates an individu-
al of CellularProcess, which is an event of form-
ing an entity of Cell, which is nephric duct. An-
other example noun phrase that involves multiple 
mentions is ?Sim-2 mRNA expression?, which is 
annotated as follows: 
? ?expression?:GeneExpression hasPatient 
(?mRNA?:MessangerRNA encodes 
?Sim-2?:Gene) 
However, we do not allow such multi-mention 
annotation on e.g.  
? ?mRNA expression?, because this phrase 
is too generic and frequent so that a mul-
ti-mention annotation for it, ?expres-
sion?:GeneExpression hasPatient 
?mRNA?:MessangerRNA, does not en-
code any ?useful? information 
?  ?nuclear factor?, because this factor is 
not always located in nucleus. 
Therefore, we decided that, in general, we avoid 
annotation of generic information, but consider a 
thread of information specific only if it involves 
specific entities like individual gene/protein and 
cell (e.g. Sim-2, nephric duct). Also, we did not 
divide a noun phrase to multiple mentions if the 
relation between the mentions is not always true 
(cf. ?nuclear factor? ? ?factor?:Protein locatedIn 
?nuclear?:Nucleus). 
2) As some GRO concepts are overlapping, we 
made the following guidelines: 
(a) When there is ambiguity between Increase 
(Decrease), Activation (Inhibition), and 
PositiveRegulation (NegativeRegulation), we 
annotate 
o binary relations with PositiveRegulation, 
ignoring Activation 
(e.g., ?augment?:PositiveRegulation hasAgent 
?Nmi?:Protein hasPatient (?recruit-
ment?:Transport hasPatient ?coactivator pro-
tein?: TranscriptionCoactivator)) 
o unary relations with Increase 
(e.g., ?enhance?:Increase hasPatient ?transcrip-
tion?:Transcription) 
   Note that we cannot exchange the two concepts 
of PositiveRegulation and Increase in the two 
examples due to the arity restriction. 
(b) Binding concepts are ambiguous. We anno-
tate as follows: 
o For such a GRO concept as "Binding of 
A to B", A should be the agent and B the 
patient. 
(For example, when we annotate 
BindingOfProteinToDNA and 
BindingOfTFToTFBindingSiteOfProtein, Protein 
and TF will be agents, and DNA and 
BindingSiteOfProtein will be patients, respec-
tively.) 
o For such a GRO concept as "Binding to 
A" for binary relation between two enti-
ties of the same type, both entities should 
be patients. 
(For example, in the events of binding between 
proteins with BindingToProtein and of binding 
between RNAs with BindingToRNA, the pro-
teins and the RNAs, respectively, will all be pa-
tients.) 
Other annotation guidelines can be found at the 
task homepage1. 
2.4 Annotation 
Two annotators with biology background anno-
tated the documents with GRO entities, events 
and relations. They used the Web-based annota-
tion tool brat (Stenetorp et al, 2012) for the an-
notation. Annotator A is the one who annotated 
the earlier version of the corpus (Kim et al, 
2011a). He first revised the earlier version of 100 
abstracts (named Set 1) and drafted the new an-
notation guidelines. Annotator B studied the 
drafted annotations and guidelines and then fur-
ther revised them, and the two annotators togeth-
er updated and made agreements on final ver-
sions of the annotations and guidelines. They 
selected two more sets of 100 abstracts each 
(named Sets 2 and 3), where Set 2 was combined 
with Set 1 to become the training and develop-
ment datasets, and Set 3 became the test dataset. 
They updated the guidelines after annotating Sets 
2 and 3 independently and together combining 
their annotations. 
                                                 
1 http://nlp.sce.ntu.edu.sg/wiki/projects/bionlpst13grotask/ 
52
We estimated the inter-annotator agreement 
(IAA) between the two annotators for Sets 2 and 
3 with Kappa measures as shown in Table 1. The 
Kappa values between 43% and 56% are moder-
ately acceptable, though not substantial, which is 
expected with the high degree of the ontology?s 
complexity and also with the high number of 
mentions (56 per abstract; see Table 2). Note that 
the agreement is met, only when the two annota-
tors annotate the same concept on the same men-
tion with the same boundaries and, if any, the 
same roles/arguments, not considering the gener-
alization criteria used for evaluation (see Section 
3 for details). If we relax the boundary restriction 
(i.e. approximate span matching of (Kim et al, 
2009)), the Kappa values for events slightly in-
crease to 47% (Set 2) and 45% (Set 3). Also note 
that the agreement on relations is higher than 
those on entities and events.  
We analyzed the different annotations by the 
two annotators as follows: As for the entity anno-
tations, 84% of the differences are boundary 
mismatches, while the rest are due to mismatch 
of entity types and to missing by either of the 
annotators. As for the event annotations, 56% of 
the differences are also boundary mismatches, 
and 31% are missed by either of the annotators. 
The majority (71%) of the differences in relation 
annotations are due to missing by either annota-
tor, while the rest are mostly due to the differ-
ences in the entity annotations. 
One negative finding is that the agreement did 
not always increase from Set 2 to Set 3, which 
means the two annotators did not improve the 
alignment of their understanding about the anno-
tation even after making agreements on Set 2 
annotations. It may be too early to conclude, and 
the Kappa value might increase as the annotators 
examine more examples, since the annotation 
corpus size in total (Sets 1,2,3 together) is still 
small compared to the total number of GRO con-
cepts. After examining the IAA, we integrated 
the independently annotated sets and released the 
final versions of the three datasets at the task 
homepage. 
 
Table 1. Inter-annotator agreement re-
sults 
 Set 2 Set 3 
Entities  44.6% 43.8% 
Events  45.8% 43.2% 
Relations  54.7% 55.9% 
All 46.2% 45.3% 
 
2.5 Statistics 
Table 2 shows the number of MEDLINE ab-
stracts in each of the three datasets: training, de-
velopment, and test datasets. It also shows the 
number of instances for each of the following 
annotation types: entities (i.e. instances of Con-
tinuant concepts), event mentions (i.e. event trig-
gers), event instances (i.e. instances of Occurrent 
concepts), and relation instances. Note that rela-
tion instances are not associated with mentions 
like event instances. It also shows the number of 
unique entity/event types (i.e. unique GRO con-
cepts) used in the annotation of each dataset. The 
total number of unique entity types in the three 
datasets is 174, and that of unique event types is 
126. 
 
Table 2. Number of annotation elements 
 Train Dev. Test 
No. of documents 150 50 100
No. of entity mentions 5902 1910 4007
No. of event mentions 2005 668 2164
No. of event instances 2175 747 2319
No. of event instances 
with agents 
693 251 625
No. of event instances 
with patients 
1214 451 1467
No. of relation instances 1964 581 1287
No. of unique entity types 128 94 147
No. of unique event types 98 72 100
 
  Note that the frequency of event instances in the 
test dataset (23.2 per document) is much higher 
than those in the training and development da-
tasets (14.5 and 14.9 per document, respective-
ly). We compared the three datasets and ob-
served that several event types (e.g. 
GeneticModification), which are popular in the 
test dataset (e.g. GeneticModification is the 12th 
frequent type (2.3%)), seldom appear in the other 
two datasets. It may indicate that the annotators 
were getting aware of (or familiar with) more 
GRO concepts as they annotate more documents, 
where the test dataset is the last annotated. This 
sudden increase of frequency did not happen for 
the entity annotations, possibly because the two 
annotators were provided with candidate entity 
annotations, though of low quality, from a pre-
liminary dictionary-based entity recognition 
method and modified them. 
  Table 3 shows the number of mentions for the 
most frequent top-level Continuant concepts 
such as InformationBiopolymer, whose sub-
concepts include Gene and Protein, Cell, and 
53
ExperimentalMethod. Please note that these fre-
quent concepts are closely related to the topic of 
gene regulation, and that this distribution may 
reflect to some degree the distribution of terms in 
the sub-domain of gene regulation, but not that in 
the whole MEDLINE. If you like to see the de-
scendant concepts of those top-level concepts, 
please refer to the latest version of the GRO2.  
 
Table 3. Number of mentions for frequent 
top-level Continuant concepts 
Level 2 Level 3 Level 4 Count 
Continuant/PhysicalContinuant 3647 
 MolecularEntity 2805 
 InformationBiopo
lymer 
2508 
 ComplexMolecula
rEntity 
140 
 Chemical 127 
 Ligand 27 
 LivingEntity 584 
 Cell 306 
 Organism 268 
 Tissue 170 
 CellComponent 77 
Continuant/NonPhysicalContinuant 359 
 ExperimentalMethod 123 
 Function 111 
 MolecularStructure 66 
 Locus 25 
 Phenotype 11 
 
  Table 4 shows the number of event instances 
for the most frequent top-level Occurrent con-
cepts. Table 5 shows the number of instances for 
each relation. 
 
Table 4. Number of event instances for 
frequent top-level Occurrent concepts 
Level 3 Level 4 Count 
Occurrent/Process/RegulatoryProcess 782 
 PositiveRegulation 217 
 NegativeRegulation 186 
Occurrent/Process/MolecularProcess 422 
 IntraCellularProcess 189 
Occurrent/Process/PhysiologicalProcess 418 
 OrganismalProcess 143 
Occurrent/Process/PhysicalInteraction 312 
 Binding 296 
Occurrent/Process/Mutation 82 
Occurrent/Process/Localization 77 
                                                 
2 http://www.ebi.ac.uk/Rebholz-srv/GRO/GRO.html 
 Transport 16 
Occurrent/Process/Decrease 73 
Occurrent/Process/Affecting 64 
 Maintenance 20 
Occurrent/Process/ExperimentalInterve
ntion 
54 
 GeneticModification 54 
Occurrent/Process/Increase 49 
Occurrent/Process/ResponseProcess 38 
 ResponseToChemicalStimul
us 
13 
 
Table 5. Number of relation instances 
Relation Count Relation Count 
locatedIn 405 hasPart 403 
fromSpecies 274 hasFunction 82 
resultsIn 56 encodes 49 
precedes 17 hasQuality 1 
 
3 Evaluation 
There was one submission for the GRO task of 
the BioNLP?13-ST, designated as ?TEES-2.1? 
(Bj?rne and Salakoski, 2013). For comparison 
purposes, the GRO task organizers produced re-
sults with a preliminary system by adapting our 
existing system, designated as OSEE (Kim and 
Rebholz-Schuhmann, 2011b), for event extrac-
tion and developing a simple machine learning 
model for relation identification. We describe 
these two systems briefly and compare their re-
sults with several criteria. 
3.1 System descriptions 
TEES-2.1 is based on multi-step SVM classifica-
tion, which automatically learns event annotation 
rules to train SVM classifiers and applies the 
classifiers for 1) locating triggers, 2) identifying 
event arguments, and 3) selecting candidate 
events.  
OSEE is a pattern matching system that learns 
language patterns for event extraction from the 
training dataset and applies them to the test da-
taset. It performs the three steps of TEES-2.1 in a 
single step of pattern matching, thus requiring a 
huge amount of patterns (eventually, a pattern for 
each combination of the features from the three 
steps) and failing to consider that many features 
of a step are independent from other steeps and 
also from event types and can thus be general-
ized.  
We added a simple Na?ve Bayes model to the 
system for identifying (binary) semantic relations 
between entities, which utilizes such features as 
54
entity strings, the distance between them, and the 
shortest path between the two entities in the de-
pendency structure of the source sentence, which 
is identified by Enju parser (Sagae et al, 2007). 
3.2 Evaluation criteria 
The GRO task follows some of the evaluation 
criteria of the Genia Event Extraction (GE) task 
of BioNLP-ST 2009 (Kim et al, 2009), includ-
ing strict and approximate matching, and also 
introduce new criteria that consider 1) the hierar-
chical structure of the GRO and 2) parent and/or 
grandparent of answer concept. We here explain 
these new criteria in detail. 
1) In this scheme of evaluation, the event re-
sults of a participant are classified into the GRO 
concepts at the third level (see Table 4 for exam-
ples), which are ancestors of their labeled clas-
ses, and the evaluation results are accumulated 
for each of those concepts at the third level. This 
scheme may give us insights on which categories 
the participant system shows strength or weak-
ness. 
2) This scheme is to deal with such a case that 
the answer class is "GeneExpression", but a par-
ticipant gives "IntraCellularProcess" or 
"MolecularProcess", which are the parent and 
grandparent of the answer class, thus not entirely 
wrong nor too generic. For example, the scheme 
"Allowing parents" allows "IntraCellularProcess" 
to be a correct match to the answer class 
"GeneExpression", as well as the answer class 
itself. "Allowing grandparents" accepts the 
grandparents of answer classes as well as the 
parents. 
3.3 Evaluation results 
Table 6 shows the evaluation results of the two 
systems. Note that all the evaluation results in 
terms of precision, recall, and F-score in all the 
tables are percentages. The performance of the 
TEES-2.1 systems, which is clearly better than 
the OSEE system, is lower than its performance 
for other tasks of the BioNLP?13-ST, which is 
understandable, considering 1) the higher num-
ber of GRO concepts than those for the other 
tasks and 2) the low Kappa value of the inter-
annotator agreement. 
It also shows that the evaluation scheme that al-
lows the parents/grandparents of answer con-
cepts for acceptance does not greatly help in-
creasing the performance, which may mean that 
the systems are designed to aim individual con-
cepts, not considering the ontology structure. 
This issue of considering the structure of the on-
tology in event extraction can be an interesting 
future work. 
 
Table 6. Evaluation results (percentage) 
Evaluation 
scheme 
TEES-2.1 OSEE 
R P F R P F 
Strict match-
ing 
15 37 22 10 18 13 
Approximate 
boundary 
matching 
16 39 23 10 20 14 
Approximate 
recursive 
matching 
16 39 23 12 20 15 
Allowing par-
ents 
16 38 23 10 19 13 
Allowing 
grandparents 
16 38 23 10 19 13 
 
Table 7 shows the performance of the systems 
for different event categories in the third level of 
the GRO. It shows that the systems are good at 
extracting events of the categories of 
MolecularProcess (e.g. GeneExpression) and 
Localization (e.g. Transport), but are, expectedly, 
poor at extracting events of the categories with 
small number of training data (e.g. Decrease, 
ResponseProcess). 
 
Table 7. Evaluation results grouped into 
3rd-level GRO concepts (%) 
3rd-level con-
cept 
TEES-2.1 OSEE 
R P F R P F 
RegulatoryPr
ocess 
12 24 16 10 11 11
MolecularPro
cess 
30 60 40 23 51 31
Physiological
Process 
9 78 17 6 25 9
PhysicalIntera
ction 
18 33 24 3 6 4
Mutation 16 39 23 1 8 2
Localization 21 62 31 16 55 24
Decrease 3 12 4 0 0 0
Affecting 2 50 3 0 0 0
Increase 8 8 8 0 0 0
ResponseProc
ess 
3 8 4 5 50 10
 
  Table 8 shows the performance of the systems 
for the most frequent concepts and also for some 
selected infrequent concepts. From the results, 
we observe that the system performance for an 
event class does not reflect the number of train-
55
ing data of the class, and that the performance of 
the syntactic pattern matching system OSEE is 
high for the event classes, for which the machine 
learning system TEES-2.1 also performs well. 
These observations may indicate that the current 
approaches to event extraction deal with event 
types independently, not considering the hierar-
chical (or semantic) relations between the event 
types nor relations between entity types. 
 
Table 8. Evaluation results for frequent 
and infrequent individual concepts (%) 
Event class 
(Count) 
TEES-2.1 OSEE 
R P F R P F 
RegulatoryPr
ocess (224) 
18 23 20 13 13 13
PositiveRegul
ation (217) 
11 22 15 11 9 9
NegativeRegu
lation (186) 
12 23 16 14 10 12
GeneExpressi
on (160) 
59 72 65 46 67 55
Disease (143) 0 0 0 1 100 3
Decrease (73) 3 12 4 0 0 0
Localization 
(61) 
16 71 27 20 60 30
Development
alProcess (61) 
23 82 36 23 78 35
BindingOfPro
teinToDNA 
(55) 
13 15 14 0 0 0
GeneticModif
ication (54) 
0 0 0 0 0 0
 
  Table 9 shows the performance of the systems 
for the GRO relations. These results of TEES in 
the relation identification of the GRO task (F-
scores between 50% and 87%) are much higher 
than the best results of relation identification 
(40% F-score) in the Bacteria Biotopes (BB) task 
(N?dellec et al, 2013), which is to extract rela-
tions of localization and part-of. Though the two 
relation identification tasks of GRO and BB can-
not be directly compared due to many differ-
ences (e.g. entity types, relation types, corpus 
sources), it may indicate that the GRO task cor-
pus has been annotated consistently enough to 
train a model with such high performance and 
that the low performance of event extraction 
compared to relation identification may be due to 
the big number of event types and would be re-
solved as the corpus size increases. 
 
Table 9. Evaluation results for relations 
(%) 
Relation TEES-2.1 OSEE 
R P F R P F 
locatedIn 45 83 58 66 38 48
hasPart 45 81 58 76 22 34
fromSpecies 80 96 87 89 41 56
hasFunction 38 73 50 62 20 30
encodes 49 89 63 45 2 5
Total 49 86 63 72 23 35
 
4 Conclusion 
The main challenge in this task is the increased 
size of the underlying ontology (i.e. GRO) and 
the more complex semantic representation in 
GRO compared to those in other ontologies used 
for ontology-based event extraction. The com-
plex structure of the GRO enables us to evaluate 
participant systems at different abstrac-
tion/generalization levels. The evaluation results 
of the participant are quite promising, leading us 
to open issues in this direction, including the in-
corporation of ontology structure in event extrac-
tion. We plan to extend the corpus semi-
automatically by incrementally updating the 
event extraction system with more training data. 
References  
E. Beisswanger, V. Lee, J.-J. Kim, D. Rebholz-
Schuhmann, A. Splendiani, O. Dameron, S. 
Schulz, and U. Hahn, ?Gene Regulation Ontology 
(GRO): design principles and use cases,? Stud 
Health Technol Inform, vol. 136, pp. 9?14, 2008. 
Jari Bj?rne, Tapio Salakoski. TEES 2.1: Automated 
annotation scheme learning in the BioNLP 2013 
Shared Task. In proceedings of the workshop of 
BioNLP 2013 Shared Task, 2013. (submitted) 
A. Doms, M. Schroeder. GoPubMed: exploring Pub-
Med with the gene ontology. Nucleic Acids Res 
2005; 33:W783?6. 
D. Dowty. Thematic Proto-Roles and Argument Se-
lection. Language 67(3):547-619, 1991. 
J.D. Kim, T. Ohta, Y. Tateisi et al GENIA corpus - a 
semantically annotated corpus for bio-text mining. 
Bioinformatics 19:i180-i182, 2003. 
J.D. Kim, T. Ohta, S. Pyysalo et al Overview of 
BioNLP'09 shared task on event extraction. In Pro-
ceedings of the Workshop on Current Trends in Bi-
omedical Natural Language Processing: Shared 
Task, Association for Computational Linguistics, 
pp. 1-9, 2009. 
56
Jung-Jae Kim, Xu Han and WatsonWei Khong Chua. 
Annotation of biomedical text with Gene Regula-
tion Ontology:Towards Semantic Web for biomed-
ical literature. In Proceedings of LBM 2011, 
pp.63?70, 2011a. 
Jung-jae Kim, Dietrich Rebholz-Schuhmann. Improv-
ing the extraction of complex regulatory events 
from scientific text by using ontology-based infer-
ence. Journal of Biomedical Semantics 2(Suppl 
5):S3, 2011b. 
H.M. M?ller, E.E. Kenny, P.W. Sternberg. 
Textpresso: an ontology-based information retriev-
al and extraction system for biological literature. 
PLoS Biol 2:e309, 2004. 
Claire N?dellec, Robert Bossy, Jin-Dong Kim, Jung-
jae Kim, Tomoko Ohta, Sampo Pyysalo, Pierre 
Zweigenbaum. Overview of BioNLP Shared Task 
2013. Proc Workshop BioNLP Shared Task 2013, 
ACL 2013, 2013. (to appear) 
D. Rebholz-Schuhmann, H. Kirsch, M. Arregui, et al 
EBIMed: text crunching to gather facts for proteins 
from Medline. Bioinformatics 23:e237?44, 2007. 
Kenji Sagae, Yusuke Miyao, and Jun'ichi Tsujii. 
2007. HPSG Parsing with Shallow Dependency 
Constraints. In Proceedings of ACL 2007, 2007. 
P. Stenetorp, S. Pyysalo, G. Topic, T. Ohta, S. 
Ananiadou, and J. ichi Tsujii, ?brat: a Web-based 
Tool for NLP-Assisted Text Annotation,? EACL. 
The Association for Computer Linguistics, pp. 
102?107, 2012.  
Yoshimasa Tsuruoka, Jun'ichi Tsujii, and Sophia 
Ananiadou. FACTA: a text search engine for find-
ing associated biomedical concepts. Bioinformatics 
24(21):2559-2560, 2008.  
 
57
