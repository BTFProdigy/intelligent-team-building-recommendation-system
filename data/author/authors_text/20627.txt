Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 65?68,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Event Extraction for Balkan Languages
Vanni Zavarella, Dilek K?uc? ?uk, Hristo Tanev
European Commission
Joint Research Centre
Via E. Fermi 2749
21027 Ispra (VA), Italy
first.last@jrc.ec.europa.eu
Ali H?urriyeto
?
glu
Center for Language Studies
Radboud University Nijmegen
P.O. Box 9103
NL-6500 HD Nijmegen
a.hurriyetoglu@let.ru.nl
Abstract
We describe a system for real-time detec-
tion of security and crisis events from on-
line news in three Balkan languages: Turk-
ish, Romanian and Bulgarian. The system
classifies the events according to a fine-
grained event type set. It extracts struc-
tured information from news reports, by
using a blend of keyword matching and
finite-state grammars for entity recogni-
tion. We apply a multilingual methodol-
ogy for the development of the system?s
language resources, based on adaptation
of language-independent grammars and on
weakly-supervised learning of lexical re-
sources. Detailed performance evaluation
proves that the approach is effective in de-
veloping real-world semantic processing
applications for relatively less-resourced
languages.
1 Introduction
We describe a real-time event extraction system
for three less-resourced languages: Bulgarian, Ro-
manian and Turkish
1
. The goal of event extraction
is to identify instances of a specified set of event
types in natural language texts, and to retrieve
database-like, structured information about event
participants and attributes: these are the entities
that are involved in the event and fill type-specific
event roles (Ashish et al., 2006). For example,
in the fragment ?Three workers were injured in
a building collapse?, the phrase ?three workers?
will be assigned a semantic role Injured of the
event type ManMadeDisaster template.
Gathering and tracking such information over
time from electronic news media plays a crucial
1
While belonging to three distant language families,
namely Slavic, Romance and Turkic, respectively, they are
spoken in the same geopolitical area, the Balkans.
role for the development of open-source intelli-
gence systems, particularly in the context of global
news monitoring of security threats, mass emer-
gencies and disease outbreaks (Yangarber et al.,
2005). In this view, it has been proved that be-
ing able to rely on highly multilingual text mining
tools and language resources is of paramount im-
portance, in order to achieve an unbiased coverage
of global news content (Steinberger, 2012).
The system language components include fi-
nite state-based entity extraction grammars and
domain-specific semantic lexica. These are
adapted to the target language from existing
language-independent resources or built by using
semi-supervised machine learning algorithms, re-
spectively. Most importantly, the lexical acquisi-
tion methods we put into place neither make use
of any language knowledge nor require to have an-
notated corpora available.
Section 2 outlines the main processing stages of
the application. In Section 3 we describe the meth-
ods applied to acquire and adapt the system?s lan-
guage knowledge bases. Finally, in Section 4 we
report on an evaluation on event type classification
and on the extraction of slot fillers for event tem-
plates, and we briefly discuss system performance
and prospective improvements.
2 System Architecture
As depicted in Figure 1 (Tanev et al., 2009), first
news feeds are clustered, upstream of the event
extraction engine, by applying similarity metrics
over meta data (named entities, locations, cate-
gories) extracted from single articles by dedicated,
multilingual software.
Event extraction begins by preprocessing the ti-
tle and first three sentences of each article within
a cluster. This encompasses: fine-grained tok-
enization, sentence splitting, domain-specific dic-
tionary look-up (i.e. matching of key terms in-
dicating numbers, quantifiers, person titles, per-
65
Meta-Data Creation
Real Time Clusterer
Geo-Locating
Core Linguistic Analysis
Cascaded Event 
Extraction  Grammar 
Application
Entity Role 
Disambiguator
Victim 
Arithmetic
Event Type 
Classifier
Event Description
Assembly
News
News
News
News
News
Figure 1: Event extraction processing chain
son groups descriptors like civilians, policemen
and Shiite), and finally morphological analysis,
simply consisting of lexicon look-up on large
domain-independent morphological dictionaries
from the MULTEXT project (Erjavec, 2004). Sub-
sequently, a multi-layer cascade of finite-state ex-
traction grammars in the ExPRESS formalism
(Piskorski, 2007) is applied on such more ab-
stract representation of the article text, in order
to: a)identify entity referring phrases, such as
persons, person groups, organizations, weapons,
etc. b) assign them to event specific roles by lin-
ear combination with event triggering surface pat-
terns. For example, in the text ?Iraqi policemen
shot dead an alleged suicide bomber? the gram-
mar should extract the phrase ?Iraqi policemen?
and assign to it the semantic role Perpetrator,
while the phrase ?alleged suicide bomber? should
be extracted as Dead. We use a ?lexicon? of 1/2-
slot patterns of the form:
<DEAD[Per]> was shot by <PERP>
<KIDNAP[Per]> has been taken hostage
where each slot position is assigned an event-
specific semantic role and includes a type restric-
tion (e.g. Person) on the entity which may fill
the slot.
Finally, we aggregate and validate information
extracted locally from each single article in the
same cluster, such as entity role assignment, vic-
tim counts and event type.
We categorize the main event from each cluster
with respect to a fine-grained event type set, shown
in Table 1.
The event classification module consists of a
blend of keyword matching, event role detection
and a set of rules controlling their interaction.
First, for each event type, we deploy: a) a list
of weighted regular expression keyword patterns:
each pattern match is awarded the corresponding
weight, and an event type is triggered when the
weight sum exceeds a defined threshold; b) a set of
boolean pattern combinations: OR pattern lists are
combined by the AND operator, each pattern is a
restricted regular expression and conjunctions are
restricted by proximity constraints. For example
in order to detect TerroristAttack we use the fol-
lowing combination (translated here in English):
(?bomb? OR ?explosion? OR....) AND (?terrorist?
OR ?Al Qaida? OR..).
Besides the event TYPE, the other main
slots of an output event frame include:
TYPE, DEAD, DEAD-COUNT, ARRESTED,
ARRESTED-COUNT, PERPETRATOR, WEAPON,
etc.
The system will be demonstrated using a KML-
aware earth browser
2
. Figure 2 shows a sample
output event template.
3 Development of language resources
The system?s language components are:
Event grammar rules They consist of regular
expressions over flat feature structures whose el-
ements include, among the others, semantic types
from the domain lexica. We use them to locally
parse semantic entities such as person names, per-
son group descriptions, and their clausal combi-
nation with verbal event patterns (see Section 2).
Grammars in target languages are compiled by
adapting the existing rules from source languages,
such as English, while the bulk of grammar devel-
opment mostly consists of providing suitable lexi-
cal resources.
Semantic dictionaries Domain-specific lexica,
listing a number of (possibly multi-word) expres-
sions sub-categorized into semantic classes rel-
evant for the event domain, with limited or no
linguistic annotation, are used by entity recogni-
tion grammar rules. Such lexica were created us-
ing the weakly supervised terminology extraction
algorithm LexiClass (Ontopopulis), described in
(Tanev et al., 2009). In order to enforce syntactic
2
E.g. Google Earth. Notice that Geocoding is cur-
rently performed at the level of article text by a language-
independent algorithm which is not yet integrated within the
event detection process, while Document Creation Date is
currently used as the event Date slot filler.
66
Figure 2: A sample output template of the system
constraints (e.g. Case) into event clause rules for
Romanian language, we have enriched learnt lex-
ical entries for the semantic classes with morpho-
logical annotations, using MULTEXT resources.
For Turkish, as we do not currently perform mor-
phological analysis, we have rather included com-
mon inflected forms of the applicable lexical en-
tries, resulting in larger lexica.
Event triggering patterns They are also ac-
quired semi-automatically, starting with a set of
seed examples and an article clustering, by deploy-
ing the paraphrase learning algorithm described in
(Tanev et al., 2008). For Bulgarian, the grammar,
semantic dictionaries and event patterns were cre-
ated simultaneously, following a semi-automatic
approach, described in (Tanev and Steinberger,
2013). In particular, we learned a list of terms
referring to people, institutions and organizations
and the corresponding pre- and post-modifiers
(about 5000 terms). In the same manner, we
learned about 550 surface patterns for killing, in-
juring, kidnapping and arresting actions, together
with a 4 level grammar cascade.
Keyword terms The keyword sets used in the
event type definitions, namely the OR lists in
the boolean pattern combinations (see Section 2
above), can be viewed as instances of some more
abstract semantic classes, that a domain expert
uses to model a target event scenario. These
classes are semi-automatically acquired using the
LexiClass algorithm, and then manually com-
Table 1: Event type set
AirMissileAttack Landslide
ArmedConflict LightningStrike
Arrest ManMadeDisaster
Assassination MaritimeAccident
Avalanche PhysicalAttack
BioChemicalAttack Robbery
Bombing Shooting
Disorder/Protest/Mutiny Stabbing
Earthquake Storm
Execution TerroristAttack
Explosion TropicalStorm
Floods Tsunami
HeatWave Vandalism
HeavyWeaponsFire VolcanicEruption
HostageVideoRelease Wildfire
HumanitarianCrisis WinterStorm
Kidnapping NONE
bined. As Turkish is an agglutinative language,
we have frequently added wildcards at the ends of
keywords to cover possible inflected forms.
4 Experiments and Evaluation
System performance is evaluated on three differ-
ent extractive tasks, carried out on the titles and
first three sentences of single news articles: event
type classification, event role name/description ex-
traction and victim counting.
We collected test corpora of 52, 126 and 115
news articles for Bulgarian, Romanian and Turk-
ish, respectively, spanning over a time range of 2
months
3
. For each article in the gold standard, we
3
Articles were manually selected using news aggregators
such as Google News. Type distribution resulted in zeroes for
67
Table 2: System performance in single article extraction mode.
Lang
Type Dead Injured Arrested Kidnapped Perpetrator Weapon
MRR mF MF MSE mF MF MSE mF MF MSE mF MF MSE mF MF mF MF
BG 0.34 0.27 0.68 17.08 0.44 0.6 108.82 0.22 1.0 7.69 0.4 0.5 0.71 0.0 0.0 0.39 1.0
RO 0.22 0.48 0.73 36.53 0.46 0.97 18.57 0.39 0.82 80.5 0.2 1.0 2.14 0.07 0.67 0.1 0.2
TR 0.66 0.73 0.79 16.41 0.85 0.91 0.24 0.31 0.36 52.17 0.4 0.33 0.82 0.25 0.67 0.77 1.0
annotated: a list of applicable types, ordered by
relevance, for the main event reported in the arti-
cle; the set of all the names/descriptions occurring
in the text for each applicable event role, merging
morphological variants; the cumulative count for
the roles Dead, Injured, Kidnapped and Arrested.
Event type classification is evaluated by apply-
ing an adapted version of the mean reciprocal rank
(MRR) score, used in Information Retrieval to
evaluate processes producing a list of relevance or-
dered query responses. In our case, the MRR for a
set of N articles is:
MRR =
1
|N |
N
?
i=1
1
rank
i
where rank is the rank of the system type re-
sponse within the gold standard type list for each
article.
For each role name/description extraction sepa-
rately, we compute standard Precision, Recall and
F1-measure on system responses, based on partial,
n-gram match with gold standard responses, ignor-
ing morphological suffixes.
Finally, we record the root Mean Squared Er-
ror (MSE) of system output victim count values
against gold standard, over all applicable roles.
Table 2 summarizes the evaluation results. mF
and MF columns for each role description task
represent respectively the micro and macro aver-
age F1-measure over the test set.
Overall, the performance figures are in line with
previous evaluations on other languages (Tanev et
al., 2009). This proves the methodology is ef-
fective on adapting the system to new languages
even with little lexical and syntactical proximity.
Turkish system consistently outperforms the oth-
ers, and it also underwent the most resource devel-
opment cycles: this suggests that applying learn-
ing iterations, alternated with human filtering, to
the language resources, can increase system ac-
curacy, eventually making it usable for real-world
applications. System accuracy is still unreliable
for victim counting. One of the main reasons for
large errors in victim counting is that the system
some less frequent event types.
interprets historical victim statistics reported in ar-
ticles as event instances. We are currently imple-
menting temporal and discourse heuristics to mit-
igate this problem.
Acknowledgments
This study is supported in part by a postdoctoral
research grant from T
?
UB
?
ITAK and by the Dutch
national program COMMIT.
References
Naveen Ashish, Doug Appelt, Dayne Freitag, and
Dmitry Zelenko. 2006. Proceedings of the work-
shop on event extraction and synthesis. Technical
report, AAAI.
Tomaz Erjavec. 2004. MULTEXT-East morphosyn-
tactic specifications.
Jakub Piskorski. 2007. ExPRESS?extraction pattern
recognition engine and specification suite. In Pro-
ceedings of the International Workshop Finite-State
Methods and Natural language Processing.
Ralf Steinberger. 2012. A survey of methods to ease
the development of highly multilingual text mining
applications. Language Resources and Evaluation,
46(2):155?176.
Hristo Tanev and Josef Steinberger. 2013. Semi-
automatic acquisition of lexical resources and gram-
mars for event extraction in Bulgarian and Czech. In
Proceedings of the 4th Biennial International Work-
shop on Balto-Slavic Natural Language Processing,
pages 110?118.
Hristo Tanev, Jakub Piskorski, and Martin Atkinson.
2008. Real-time news event extraction for global
crisis monitoring. In E. Kapetanios, V. Sugumaran,
and M. Spiliopoulou, editors, Natural Language and
Information Systems, volume 5039 of Lecture Notes
in Computer Science, pages 207?218.
Hristo Tanev, Vanni Zavarella, Jens Linge, Mijail
Kabadjov, Jakub Piskorski, Martin Atkinson, and
Ralf Steinberger. 2009. Exploiting Machine Learn-
ing Techniques to Build an Event Extraction Sys-
tem for Portuguese and Spanish. Linguam?atica,
1(2):55?66.
Roman Yangarber, Lauri Jokipii, Antti Rauramo, and
Silja Huttunen. 2005. Extracting information about
outbreaks of infectious epidemics. In Proceedings
of the HLT/EMNLP.
68
Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 71?78,
Gothenburg, Sweden, April 26-30 2014.
c
?2014 Association for Computational Linguistics
Experiments to Improve Named Entity Recognition on Turkish Tweets
Dilek K?uc? ?uk and Ralf Steinberger
European Commission, Joint Research Centre
Via E. Fermi 2749
21027 Ispra (VA), Italy
firstname.lastname@jrc.ec.europa.eu
Abstract
Social media texts are significant informa-
tion sources for several application areas
including trend analysis, event monitor-
ing, and opinion mining. Unfortunately,
existing solutions for tasks such as named
entity recognition that perform well on
formal texts usually perform poorly when
applied to social media texts. In this pa-
per, we report on experiments that have the
purpose of improving named entity recog-
nition on Turkish tweets, using two dif-
ferent annotated data sets. In these ex-
periments, starting with a baseline named
entity recognition system, we adapt its
recognition rules and resources to better
fit Twitter language by relaxing its capital-
ization constraint and by diacritics-based
expansion of its lexical resources, and we
employ a simplistic normalization scheme
on tweets to observe the effects of these on
the overall named entity recognition per-
formance on Turkish tweets. The evalua-
tion results of the system with these differ-
ent settings are provided with discussions
of these results.
1 Introduction
Analysis of social media texts, particularly mi-
croblog texts like tweets, has attracted recent at-
tention due to significance of the contained in-
formation for diverse application areas like trend
analysis, event monitoring, and opinion mining.
Tools for well-studied problems like named entity
recognition (NER) are usually employed as com-
ponents within these social media analysis appli-
cations. For instance, in (Abel et al., 2011), named
entities extracted from tweets are used to deter-
mine trending topics for user modeling within the
context of personalized recommender systems and
in (Ritter et al., 2012), named entities in tweets
are used to complement the events extracted by an
open domain event extraction system for Twitter.
However, existing NER solutions for well-formed
text types like news articles are reported to suf-
fer from considerable performance degradations
when they are ported to social media texts, mainly
due to the peculiarities of this latter text type (Rit-
ter et al., 2011).
In this paper, we report on our NER experiments
on Turkish tweets in order to determine facilitating
and impeding factors during the development of a
NER system for Turkish tweets which can be used
in social media analysis applications. We carry
out these experiments on two tweet data sets an-
notated with named entities. After the initial eval-
uation results of a rule-based NER system (K?uc??uk
and Yaz?c?, 2009) on these data sets, we gradually
present the performance results achieved by the
extended versions of the system together with dis-
cussions of these results. For these experiments,
we first perform two system adaptations, i.e., re-
laxing the capitalization constraint of the system
and diacritics-based expansion of the system?s lex-
ical resources. Next, we incorporate a simplistic
tweet normalization scheme into the NER proce-
dure. After the evaluation of these extensions, we
provide discussions on the plausible features of a
NER system tailored to Turkish tweets.
The rest of the paper is organized as follows:
In Section 2, we review the literature on NER on
tweets and NER on Turkish texts. In Section 3, we
present our NER experiments on Turkish tweets.
Directions of future work are outlined in Section 4
and finally Section 5 concludes the paper.
2 Related Work
There are several recent studies presenting ap-
proaches for NER on microblog texts, especially
on tweets in English. Among these studies, in
(Ritter et al., 2011), a NER system tailored to
71
tweets, called T-NER, is presented which employs
Conditional Random Fields (CRF) for named en-
tity segmentation and labelled topic modelling for
subsequent classification, using Freebase dictio-
naries. A hybrid approach to NER on tweets is
presented in (Liu et al., 2011) where k-Nearest
Neighbor and CRF based classifiers are sequen-
tially applied. In (Liu et al., 2012), a factor graph
based approach is proposed that jointly performs
NER and named entity normalization on tweets.
An unsupervised approach that performs only
named entity extraction on tweets using resources
like Wikipedia is described in (Li et al., 2012). A
clustering-based approach for NER on microtexts
is presented in (Jung, 2012), a lightweight filter
based approach for NER on tweets is described
in (de Oliveira et al., 2013), and a series of NER
experiments on targeted tweets in Polish is pre-
sented in (Piskorski and Ehrmann, 2013). Finally,
an adaptation of the ANNIE component of GATE
framework to microblog texts, called TwitIE, is
described in (Bontcheva et al., 2013).
Considering NER research on Turkish texts,
various approaches have been employed so far
including those based on using Hidden Markov
Models (HMM) (T?ur et al., 2003), on manually
engineered recognition rules (K?uc??uk and Yaz?c?,
2009; K?uc??uk and Yaz?c?, 2012), on rule learning
(Tatar and C?icekli, 2011), and on CRFs (Yeniterzi,
2011; S?eker and Eryi?git, 2012). All of these ap-
proaches have been proposed for news texts and
the CRF-based approach (S?eker and Eryi?git, 2012)
is reported to outperform the previous proposals
with a balanced F-Measure of about 91%.
To the best of our knowledge, there are only
two studies on NER from Turkish tweets. In
(C?elikkaya et al., 2013), the CRF-based NER sys-
tem (S?eker and Eryi?git, 2012) is evaluated on in-
formal text types and is reported to achieve an
F-Measure of 19% on tweets. In (K?uc??uk et al.,
2014), a tweet data set in Turkish annotated with
named entities is presented. The adaptation of a
multilingual rule-based NER system (Pouliquen
and Steinberger, 2009) to Turkish, which achieves
an F-Measure of about 61% on a news article data
set, gets an F-Measure of 37% on this tweet data
set, and after extending the resources of the NER
system with frequently appearing person and orga-
nization names in Turkish news articles, the corre-
sponding scores increase to about 69% and 43%,
respectively (K?uc??uk et al., 2014).
Table 1: NE Statistics on the Data Sets.
Frequency in
NE Type Tweet Set-1 Tweet Set-2
Person 457 774
Location 282 191
Organization 241 409
All PLOs 980 1,374
Date 201 342
Time 5 25
Money 16 13
Percent 9 3
All NEs 1,211 1,757
3 Named Entity Recognition
Experiments
The NER experiments are performed using the
rule-based NER system (K?uc??uk and Yaz?c?, 2009)
which makes use of a set of lexical resources,
i.e., lists of person/location/organization names
(henceforth referred to as PLOs), and patterns for
the extraction of named entities (NEs) of type
PLOs and time/date/money/percent expressions
(K?uc??uk and Yaz?c?, 2009). The system is pro-
posed for news articles which is a considerably
well-formed text type usually with proper capital-
ization of the initial letters of PLOs and separa-
tion of these PLOs from their suffixes with apos-
trophes
1
. Yet, as even such well-formed texts may
be lacking these important indicators of PLOs, the
system can be configured to make use of the cap-
italization clue or not, and it includes a simplistic
morphological analyzer to check the suffixes at the
end of PLO candidates and thereby validate these
candidates (K?uc??uk and Yaz?c?, 2009).
This NER system achieves a balanced F-
Measure of 78.7% (without giving any credit to
partial extractions) on a news article data set of
about 20K tokens obtained from the METU Turk-
ish corpus (Say et al., 2002) where the annotated
form of this data set includes a total of 1,613 NEs.
Within the course of the current study, we have
evaluated this system on two tweet data sets in
Turkish where statistical information about these
data sets are provided in Table 1. The first one,
which is referred to as Tweet Set?1 in Table 1,
is presented in (K?uc??uk et al., 2014) and comprises
2,320 tweets with about 20K tokens. The sec-
ond data set (Tweet Set?2) includes about 5K
1
An example inflected named entity of location name type
(a city name) in Turkish which takes the dative case suffix
(?ya) is Ankara?ya (meaning to Ankara) where the ini-
tial letter of the named entity is properly capitalized and the
case suffix is accordingly separated from the entity with an
apostrophe.
72
tweets with about 50K tokens and is described in
(C?elikkaya et al., 2013).
3.1 Initial Experiments
We have first evaluated the system?s performance
on the data sets without any extensions to the exist-
ing NER system. Table 2 presents these evaluation
results using the commonly employed metrics of
precision, recall, and balanced F-Measure, with-
out giving any credit to partially extracted NEs.
Table 3 displays those results with the same met-
rics this time giving credit to partial extractions
with the constraint that the NE type within the sys-
tem output and the answer key must be the same,
where these metrics have been employed in stud-
ies like (Maynard et al., 2001).
The evaluation results in Table 2 and Table
3 are in line with the common finding reported
in the literature that the NER systems for com-
paratively well-formed text types face consider-
able performance decreases when they are eval-
uated on tweets. This observation is usually at-
tributed to the peculiarities of tweet texts such as
common grammatical/spelling errors and deliber-
ate contractions. With strict metrics, the system is
reported to achieve an F-Measure rate of 78.7%.
When it is ported to tweets, the best overall F-
Measure rates achieved are 53.23% and 44.25%
on Tweet Set?1 and Tweet Set?2, respectively,
while the corresponding best F-Measure rates for
only PLOs are 47.76% and 36.63%, respectively,
all with strict metrics. The difference between
the results for PLOs and the overall results also
confirms that the system recognizes temporal and
numerical expressions (within its scope) with de-
cent performance, compared to the recognition of
PLOs.
The F-Measure rates obtained when partial ex-
tractions are also given credit are about 5% higher
than those obtained without giving any credit to
partially extracted NEs. This increase is impor-
tant due to pragmatic reasons as these partially
extracted NEs can help conveniently filter tweet
streams and retrieve relevant subsets of tweets in
several application settings.
3.2 NER Experiments with Rule/Resource
Adaptations
Tweet texts possess the following peculiarities
usually as opposed to other formal text types:
? Grammatical/spelling errors are common,
like incorrectly writing proper names all in
lowercase letters. A Turkish example illus-
trating a spelling error is the use of geliyoooo
instead of geliyor (meaning is coming).
? Contracted word forms are commonly used
instead of full forms, like referring to the
football club called Fenerbahc?e as Fener
only, where the latter contracted form is also
homonymous to a common name in Turkish
(meaning lantern).
? For the particular case of Turkish tweets,
non-accentuated characters (c, g, i, o, s, and
u) are often utilized instead of the corre-
sponding Turkish characters with diacritics
(c?, ?g, ?, ?o, s?, and ?u). An example of this phe-
nomenon is writing cunku instead of the cor-
rect form, c??unk ?u (meaning because).
Considering the above features, in order to im-
prove the initial NER performance on Turkish
tweets, we have tested two adaptations of the rule-
based NER system. The details of these adapta-
tions and the corresponding evaluation results are
presented in the following subsections.
3.2.1 Relaxing the Capitalization Constraint
of the System
As proper capitalization of PLOs is usually lack-
ing in tweets, we have evaluated the NER sys-
tem with its capitalization feature turned off, so
that the system considers all tokens (no matter
whether their initial character is capitalized or not)
as valid NE candidates. The initial evaluation re-
sults of the system with this setting are provided
in Table 2 and Table 3 within the rows where
the Capitalization column has a corresponding
OFF value. The results for these two capitaliza-
tion settings are also similarly provided in Tables
4-6 which present the evaluation results described
in the upcoming sections.
The results in Table 2 and Table 3 demonstrate
that relaxing the capitalization constraint (i.e., not
using the capitalization clue) during the NER pro-
cedure on Turkish tweets consistently improves
performance for PLOs on both data sets. The im-
provement obtained with this relaxation is more
dramatic on Tweet Set?2 and for this data set
the overall results are accordingly better than those
obtained when the capitalization clue is used. It
should again be noted that the NER system uses a
73
Table 2: Initial NER Evaluation Results (Strict Metrics).
Data Set Capitalization Metric Person Location Organization Overall for PLOs Overall for 7 Types
Tweet Set-1
ON
P (%) 52.82 77.78 72.34 64.16 71.13
R (%) 32.82 49.65 28.22 36.53 42.53
F (%) 40.49 60.61 40.60 46.55 53.23
OFF
P (%) 36.73 71.72 58.70 49.29 56.21
R (%) 43.33 62.06 33.61 46.33 50.45
F (%) 39.76 66.54 42.74 47.76 53.18
Tweet Set-2
ON
P (%) 55.79 58.68 72.06 58.86 65.62
R (%) 20.54 37.17 11.98 20.31 30.85
F (%) 30.03 45.51 20.55 30.19 41.97
OFF
P (%) 35.61 45.53 40.72 38.31 46.27
R (%) 38.37 61.26 16.63 35.08 42.40
F (%) 36.94 52.23 23.61 36.63 44.25
Table 3: Initial NER Evaluation Results (Partial Metrics).
Data Set Capitalization Metric Person Location Organization Overall for PLOs Overall for 7 Types
Tweet Set-1
ON
P (%) 65.33 86.05 88.37 75.98 80.74
R (%) 39.38 54.01 32.34 41.87 47.13
F (%) 49.14 66.37 47.35 53.99 59.52
OFF
P (%) 42.83 78.68 69.11 56.25 62.49
R (%) 50.92 67.71 38.00 52.55 55.72
F (%) 46.53 72.78 49.04 54.34 58.91
Tweet Set-2
ON
P (%) 69.79 61.34 74.63 68.27 72.51
R (%) 24.28 38.62 12.25 22.65 33.31
F (%) 36.03 47.40 21.05 34.02 45.65
OFF
P (%) 41.82 48.41 41.99 43.21 50.91
R (%) 45.10 65.59 17.06 39.38 46.45
F (%) 43.40 55.71 24.26 41.21 48.58
simplistic morphological analyzer to validate suf-
fixes added at the ends of the NEs, thereby the sys-
tem does not overgenerate with this new setting,
although the precision rates decrease considerably
in return to corresponding increases in the recall
rates. To summarize, together with the fact that
about 25.1% of all PLOs within Tweet Set?1 are
lacking proper capitalization (K?uc??uk et al., 2014),
these findings suggest that the ability to relax this
capitalization constraint is a convenient feature of
a practical NER system for Turkish tweets. An
alternative feature would be to automatically cor-
rect the capitalization of NEs instead, as a pre-
processing step.
3.2.2 Diacritics-Based Expansion of the
Lexical Resources
In Turkish tweet texts, words including Turkish
characters with diacritics are often, usually ei-
ther erroneously or deliberately for pragmatic rea-
sons such as to type faster, spelled with their non-
diacritic equivalents, as pointed out above. There-
fore, we expand the entries in the lexical resources
of the NER system to include both diacritic and
non-diacritic variants of these entries. For in-
stance, the Turkish name of the island Cyprus,
K?br?s, may appear in tweets as K?bris, Kibr?s,
or Kibris, as well. As this example denotes, for
each existing entry with n such Turkish-specific
characters, 2
n
entries (including the original en-
try) are included in the ultimate expanded forms
of the lexical resources, since each such character
may be used as it is or may be replaced with its
equivalent.
During this expansion stage, we have applied
a filtering procedure over these newly considered
2
n
? 1 entries to check whether they are homony-
mous to common names in Turkish. This fil-
tering procedure basically checks whether an ex-
pansion candidate is within a list of unique, sup-
posedly well-formed, Turkish words comprising
about 1,140,208 items including inflected forms
(Zemberek, 2010), and if it is, then this candidate
is discarded to avoid overgeneration during the ac-
tual NER procedure.
We have tested this new version of the sys-
tem with expanded lexical resources and the corre-
sponding evaluation results are provided in Table
4 and Table 5, using the strict and partial evalua-
tion metrics, respectively. Both strict and partial
evaluation results denote that the performance of
the system is improved after this diacritics-based
expansion of the system resources. The best re-
sults are obtained when this expansion is com-
bined with the relaxation of the capitalization con-
straint, for PLOs on Tweet Set?1, and both for
PLOs and all 7 NE types on Tweet Set?2. Sim-
ilar to the points made in the previous section,
this diacritics-based expansion scheme stands as
a promising feature of an ultimate NER system
for Turkish tweets, also considering the fact that
74
Table 4: NER Evaluation Results After Diacritics-Based Expansion of Resources (Strict Metrics).
Data Set Capitalization Metric Person Location Organization Overall for PLOs Overall for 7 Types
Tweet Set-1
ON
P (%) 53.00 78.80 73.20 64.89 71.95
R (%) 32.82 51.42 29.46 37.35 44.26
F (%) 40.54 62.23 42.01 47.41 54.81
OFF
P (%) 36.17 71.31 59.03 48.95 56.16
R (%) 43.76 63.48 35.27 47.35 52.35
F (%) 39.60 67.17 44.16 48.13 54.19
Tweet Set-2
ON
P (%) 58.22 58.73 70.67 60.20 67.29
R (%) 22.87 38.74 12.96 22.13 34.89
F (%) 32.84 46.69 21.90 32.36 45.95
OFF
P (%) 36.80 44.61 32.43 37.61 46.24
R (%) 43.41 62.83 17.60 38.43 47.64
F (%) 39.83 52.17 22.82 38.01 46.93
Table 5: NER Evaluation Results After Diacritics-Based Expansion of Resources (Partial Metrics).
Data Set Capitalization Metric Person Location Organization Overall for PLOs Overall for 7 Types
Tweet Set-1
ON
P (%) 65.58 87.46 88.76 76.81 81.44
R (%) 39.38 56.12 33.62 42.80 48.98
F (%) 49.21 68.37 48.77 54.97 61.17
OFF
P (%) 42.21 79.17 69.00 56.02 62.49
R (%) 51.56 69.85 39.70 53.88 57.90
F (%) 46.42 74.22 50.40 54.93 60.11
Tweet Set-2
ON
P (%) 71.48 61.29 72.97 69.07 73.68
R (%) 26.68 40.21 13.24 24.51 37.47
F (%) 38.86 48.56 22.41 36.18 49.67
OFF
P (%) 42.26 47.07 33.33 41.75 50.23
R (%) 50.14 66.76 18.04 42.65 51.72
F (%) 45.86 55.21 23.41 42.20 50.96
about 6.3% of all NEs in Tweet Set?1 are writ-
ten in characters with missing diacritics. A plausi-
ble alternative to this feature would be to perform
diacritics-based correction (or, normalization) as
presented in studies like (Mihalcea, 2002) prior to
the actual NER procedure. Similar approaches can
be tested on tweets in other languages having com-
mon characters with diacritics.
3.3 Tweet Normalization
Tweet normalization has emerged as an important
research problem (Han and Baldwin, 2011), the
solutions to which can readily be used in systems
for sentiment analysis and NER (as considered in
studies such as (Liu et al., 2012)), among others.
In order to observe the effects of normalization
on NER performance on Turkish tweets, we have
first experimented with a simplistic tweet normal-
ization scheme which aims at decreasing repeated
characters in words, as repetition of characters in
tweets is a frequent means to express stress. The
scheme is outlined below:
1. In order to determine the list of valid Turk-
ish words with consecutively repeated char-
acters, we have employed the list of Turk-
ish unique words (Zemberek, 2010), that we
have previously utilized during the diacritics-
based resource expansion procedure in Sec-
tion 3.2.2. Within this list, 74,262 words
(about 6.5% of the list) turn out to have con-
secutively repeated characters.
2. Using this sublist as a reference resource, we
have implemented the actual simplistic nor-
malization scheme: if a word in a tweet has
consecutively repeated character sequences
and the word is not included within the afore-
mentioned sublist, then all of these character
sequences are contracted to single character
instances. For instance, with this procedure,
the token zamaanlaaa is correctly replaced
with zamanla (meaning with time) and
mirayyy is correctly replaced with miray (a
proper person name).
The employment of the above normalization
scheme prior to the actual NER procedure has
led to slightly poorer results as some NEs which
should not be normalized through this scheme are
normalized instead. For instance, the city name
C?anakkale is changed to C?anakale during the
normalization procedure and it is missed by the
subsequent NER procedure. Hence, we employ
a three-phase pipelined NER approach where we
first run the NER procedure on the input text, then
employ the normalization scheme on the NER out-
put, and finally run the NER procedure again on
the normalization output, in order to avoid that the
normalization step corrupts well-formed NEs that
can readily be extracted by the system.
The performance of this ultimate NER pipeline,
with the capitalization feature turned off during
75
both of the actual NER phases, is evaluated only
on Tweet Set?1. Therefore, the performance
evaluations of the first NER phase correspond to
the previously presented results in the rows 4-6 of
Table 2 and Table 3, with strict and partial versions
of the metrics, respectively.
Below we summarize our findings regarding the
intermediate normalization procedure employed,
based on its evaluation results. Although some of
these findings are not directly relevant for the pur-
poses of the NER procedure, we provide them for
the completeness of the discussion on the normal-
ization of Turkish tweets.
? Excluding the normalization cases which in-
volve non-alphabetical characters only (like
normalizing >>>>>> to >), those that result
in a normalized form with a single alphabet-
ical character (like normalizing oooooo to
o), and those that involve emotion expres-
sions (like normalizing :DDDDD to :D), the
number of resulting instances considered for
performance evaluation is 494.
? The number of normalization instances in
which an incorrect token is precisely con-
verted into its corresponding valid form is
253, so, the precision of the overall normal-
ization scheme is 51.21%.
? 117 of the incorrect cases are due to the fact
that the token that is considered for normal-
ization is a valid but foreign token (such as
normalizing Harry to Hary, jennifer to
jenifer, full to ful, and tweet to twet).
Hence, these cases account for a decrease of
23.68% in the precision of the normalization
scheme.
? 15 of the incorrect instances are due to the
fact that Turkish characters with diacritics
are not correctly used, hence they cannot be
found within the reference sublist of valid
Turkish words, and subsequently considered
by the normalization procedure, although
they could instead be subject to a diacritics-
based normalization, as pointed out at the end
of Section 3.2.2. For instance, s?iir (mean-
ing poem) is incorrectly written as siir in
a tweet and since it, in this incorrect form,
cannot be found on the reference sublist, it is
erroneously changed to sir. There are also
other incorrect instances in which superflu-
ous characters are correctly removed with the
normalization procedure, yet the resulting to-
ken is still not in its correct form as a subse-
quent diacritics-based correction is required.
Though they are not considerably frequent
(as we only consider here tokens with consec-
utively repeated characters), these instances
serve to confirm that the restoration of dia-
critics should be considered along with other
forms of normalization.
? Some other frequent errors made by the nor-
malization scheme are due to incorrect to-
kenization as whitespaces to separate to-
kens can be missing due to writing errors or
the tendency to write some phrases hashtag-
like. An example case is incorrectly writ-
ing the adverb, demek ki (meaning so or
that means), as demekki in a tweet, which
in turn is erroneously changed to demeki
during normalization. This token, demekki,
should not be considered within this type of
normalization at all, although it needs pro-
cessing to be transformed into its correct
form, demek ki.
To summarize, the normalization scheme can
be enhanced considering the above points, where
proper treatment of non-Turkish tokens and the
consideration of diacritics-based issues stand as
the most promising directions of improvement.
Other more elaborate ways of normalizing tweets,
as presented in studies such as (Han and Bald-
win, 2011), should also be tested together with
the NER procedure, to observe their ultimate con-
tribution. Along the way, a normalization dictio-
nary for Turkish can be compiled, following stud-
ies like (Han et al., 2012).
The evaluation results of the ultimate three-
phase NER pipeline are provided in Table 6, with
the systems?s capitalization feature turned off in
both NER phases. Within the first three rows, the
results with the strict evaluation metrics are dis-
played while the last three rows present those re-
sults obtained with the partial versions. When we
examine the individual NER results after the in-
corporation of normalization scheme in details, we
observe that there are cases where incorrectly nor-
malizing some common names or slang/contracted
words leads to them being extracted as NEs during
the second NER phase. In order to prevent such
76
Table 6: Evaluation Results of the NER Pipeline with Normalization, on Tweet Set?1.
Metric Type Metric Person Location Organization Overall for PLOs Overall for 7 Types
Strict
P (%) 36.45 71.72 58.99 48.94 55.91
R (%) 44.42 62.06 34.02 46.94 51.20
F (%) 40.04 66.54 43.16 47.92 53.45
Partial
P (%) 42.32 78.68 69.35 55.73 62.04
R (%) 52.07 67.71 38.43 53.18 56.48
F (%) 46.69 72.78 49.45 54.43 59.13
false positives, the ways of improving the normal-
ization procedure discussed above can be imple-
mented and thereby less errors will be propagated
into the second NER phase.
Though the overall results in Table 6 are slightly
better than their counterparts when normalization
is not employed, we cannot derive sound conclu-
sions about the contribution of this normalization
scheme to the overall NER procedure. The slight
improvement is also an expected result as the size
of the test data set is quite small and the number
of NEs to be recognized after this type of nor-
malization is already limited since only about 1%
of all PLOs in Tweet Set?1 have incorrectly re-
peated consecutive characters. Yet, the results are
still promising in that with a more elaborate nor-
malization procedure evaluated on larger corpora,
more dramatic increases in the NER performance
can be obtained on Turkish tweets.
4 Future Work
Directions of future work based on the current
study include the following:
? Following the points made throughout Sec-
tion 3, several normalization schemes also in-
volving case and diacritics restoration can be
implemented and incorporated into the NER
procedure on tweets.
? Since tweet texts are short and informal, they
often lack contextual clues needed to perform
an efficient NER procedure. Additionally,
there is a tendency to mention new and pop-
ular NEs in tweets which might be missed by
a NER system with static lexical resources.
Hence, extending the lexical resources of
the NER system with contemporary up-to-
date NEs automatically obtained from Turk-
ish news articles can be considered. For this
purpose, we can readily employ resources
like JRC-Names (Steinberger et al., 2011), a
publicly available continuously-updated NE
and name variant dictionary, as a source of
up-to-date NEs in Turkish.
5 Conclusion
In this study, we target the problem of named en-
tity recognition on Turkish tweets. We have car-
ried out experiments starting with a rule-based
recognition system and gradually extended it in
two directions: adapting the rules/resources of
the system and introducing a tweet normalization
scheme into the recognition procedure. Thereby,
we present our findings on named entity recogni-
tion on Turkish tweets in addition to those on the
normalization of Turkish tweets. Based on these
findings, we outline some desirable features of a
named entity recognition system tailored to Turk-
ish tweets. Future work includes the employment
and testing of more elaborate tweet normalization
procedures along the way, on larger tweet data
sets, in addition to evaluating the system after its
resources are automatically extended with dictio-
naries of up-to-date named entities.
Acknowledgments
This study is supported in part by a postdoctoral
research grant from T
?
UB
?
ITAK.
References
Fabian Abel, Qi Gao, Geert-Jan Houben, and Ke Tao.
2011. Analyzing Temporal Dynamics in Twitter
Profiles for Personalized Recommendations in the
Social Web. In Proceedings of the 3rd ACM Inter-
national Web Science Conference.
Kalina Bontcheva, Leon Derczynski, Adam Funk,
Mark Greenwood, Diana Maynard, and Niraj
Aswani. 2013. TwitIE: An Open-Source Informa-
tion Extraction Pipeline for Microblog Text. In Pro-
ceedings of the International Conference on Recent
Advances in Natural Language Processing.
G?okhan C?elikkaya, Dilara Toruno?glu, and G?uls?en
Eryi?git. 2013. Named Entity Recognition on Real
Data: A Preliminary Investigation for Turkish. In
Proceedings of the 7th International Conference
on Application of Information and Communication
Technologies.
G?okhan A. S?eker and G?uls?en Eryi?git. 2012. Ini-
tial Explorations on Using CRFs for Turkish Named
77
Entity Recognition. In Proceedings of the Inter-
national Conference on Computational Linguistics,
pages 2459?2474.
Diego Marinho de Oliveira, Alberto H.F. Laender,
Adriano Veloso, and Altigran S. da Silva. 2013.
FS-NER: A Lightweight Filter-Stream Approach to
Named Entity Recognition on Twitter Data. In Pro-
ceedings of the 22nd International Conference on
World Wide Web Companion, pages 597?604.
Bo Han and Timothy Baldwin. 2011. Lexical Nor-
malisation of Short Text Messages: Makn Sens a
#twitter. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 368?378.
Bo Han, Paul Cook, and Timothy Baldwin. 2012.
Automatically Constructing a Normalisation Dictio-
nary for Microblogs. In Proceedings of the Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning.
Jason J. Jung. 2012. Online Named Entity Recog-
nition Method for Microtexts in Social Networking
Services: A Case Study of Twitter. Expert Systems
with Applications, 39(9):8066?8070.
Dilek K?uc??uk and Adnan Yaz?c?. 2009. Named En-
tity Recognition Experiments on Turkish Texts. In
T. Andreasen et al., editor, Proceedings of the Inter-
national Conference on Flexible Query Answering
Systems, volume 5822 of Lecture Notes in Computer
Science, pages 524?535.
Dilek K?uc??uk and Adnan Yaz?c?. 2012. A Hybrid
Named Entity Recognizer for Turkish. Expert Sys-
tems with Applications, 39(3):2733?2742.
Dilek K?uc??uk, Guillaume Jacquet, and Ralf Stein-
berger. 2014. Named Entity Recognition on Turkish
Tweets. In Proceedings of the Language Resources
and Evaluation Conference.
Chenliang Li, Jianshu Weng, Qi He, Yuxia Yao, An-
witaman Datta, Aixin Sun, and Bu-Sung Lee. 2012.
TwiNER: Named Entity Recognition in Targeted
Twitter Stream. In Proceedings of the 35th Inter-
national ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 721?
730.
Xiaohua Liu, Shaodian Zhang, Furu Wei, and Ming
Zhou. 2011. Recognizing Named Entities in
Tweets. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics:
Human Language Technologies - Volume 1, pages
359?367.
Xiaohua Liu, Ming Zhou, Furu Wei, Zhongyang Fu,
and Xiangyang Zhou. 2012. Joint Inference of
Named Entity Recognition and Normalization for
Tweets. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics: Long Papers - Volume 1, pages 526?535.
Diana Maynard, Valentin Tablan, Cristan Ursu, Hamish
Cunningham, and Yorick Wilks. 2001. Named en-
tity recognition from diverse text types. In Proceed-
ings of the Conference on Recent Advances in Natu-
ral Language Processing.
Rada F. Mihalcea. 2002. Diacritics Restoration:
Learning from Letters versus Learning from Words.
In Proceedings of the 3rd International Conference
on Intelligent Text Processing and Computational
Linguistics, pages 339?348.
Jakub Piskorski and Maud Ehrmann. 2013. On Named
Entity Recognition in Targeted Twitter Streams in
Polish. In Proceedings of the ACL Workshop on
Balto-Slavic Natural Language Processing.
Bruno Pouliquen and Ralf Steinberger. 2009. Auto-
matic Construction of Multilingual Name Dictionar-
ies. In C. Goutte et al., editor, Learning Machine
Translation, Advances in Neural Information Pro-
cessing Systems Series, pages 59?78. MIT Press.
Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.
2011. Named Entity Recognition in Tweets: An
Experimental Study. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 1524?1534.
Alan Ritter, Mausam, Oren Etzioni, and Sam Clark.
2012. Open Domain Event Extraction from Twit-
ter. In Proceedings of the 18th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and
Data Mining, pages 1104?1112.
Bilge Say, Deniz Zeyrek, Kemal Oflazer, and Umut
?
Ozge. 2002. Development of a Corpus and a Tree-
bank for Present-Day Written Turkish. In Proceed-
ings of the 11th International Conference of Turkish
Linguistics.
Ralf Steinberger, Bruno Pouliquen, Mijail Alexandrov
Kabadjov, Jenya Belyaeva, and Erik Van der Goot.
2011. JRC-Names: A Freely Available, Highly
Multilingual Named Entity Resource. In Proceed-
ings of the Conference on Recent Advances in Natu-
ral Language Processing.
Serhan Tatar and
?
Ilyas C?icekli. 2011. Automatic
Rule Learning Exploiting Morphological Features
for Named Entity Recognition in Turkish. Journal
of Information Science, 37(2):137?151.
G?okhan T?ur, Dilek Hakkani-T?ur, and Kemal Oflazer.
2003. A Statistical Information Extraction Sys-
tem for Turkish. Natural Language Engineering,
9(2):181?210.
Reyyan Yeniterzi. 2011. Exploiting Morphology in
Turkish Named Entity Recognition System. In Pro-
ceedings of the ACL Student Session, pages 105?
110.
Zemberek. 2010. Turkish Unique Word List of Zem-
berek NLP Library for Turkic Languages. Available
at http://zemberek.googlecode.com/
files/full.txt.tr.tar.gz.
78
