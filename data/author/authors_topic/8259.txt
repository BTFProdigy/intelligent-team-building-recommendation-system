proceeding,international conference,computational linguistics,coling,manchester,august,bayesian semi-supervised chinese word segmentation,kristout microsoft,com abstract word,chinese text,delimiters,challenge,system,approach, a c hinese word seg menter,fixed lexicon,word segmentation,translation, a b ayesian semi-supervised chinese word segmenta tion model,bilingual information,seg mentation suitable,method,state-of the-art mt system,large data environment,1 i ntroduction chinese sentence,se quence,chinese character,white space,european language,pose difficulty,many natural language processing task,machine translation,various definition,segmentation, a c w method,translation performance,common solution,chinese-to-english translation,segment,chinese text,off-the-shelf  cws method,standard translation model,fixed seg mentation,method,unigram segmentation,segmenta tion,manual lexicon,chi nese word,frequency,lexicon,creative common attribution-noncommercial-share alike,li cense,creativecommons,frequency,method,manual lexicon,method,addition,unigram segmentation,method,adaptive  cws system,andrew,conditional ran dom field model,sequence segmentation,method,mt application,significant im provements,translation performance need,word segmentation,mt sys tems,model training,translation,method, a b ayesian semi, cws approach,goldwa,generative model,word model,alignment model,bilin gual information,method,segment chinese text,unigram seg menter,new word type,word distribution,experiment,chinese-to-english trans lation,method,per formance,state-of-the-art machine translation system,2 r eview,baseline system,statistical machine translation, ac hinese sentence,character,adequate mapping,chinese,english word,baseline system,commonly,unigram model,segmenta tion,lexicon contain ing word,segmentation  fj,joint probability,sentence,assumption,maximization,chinese word sequence,character sequence,chinese sentence,standard alignment model,direction,phrase-based decoder,log-linear model,log-linear model,clude translation model,direction,lan guage model,distortion model,sentence length penalty,feature weight,development,downhill simplex al gorithm,language model,statistical ngram model,kneser-ney smoothing,3 u nigram dirichlet process model,version,monolingual information,different,stan dard unigram model,new chinese word type,learn word distribution,unlabeled data,corpus,chinese word,distribution, ad irichlet process,base measure,estimate,possible value,bayesian inference,notational convention,general probability distribution,specific assumption,contrast,model-based probability distribution,probability, a c hinese word,chinese word generation,restaurant,infinite num ber,chi nese word type,infinite number,chinese word frequency,dirichlet process model,cache model,goldwater,corpus,wheren,number,chinese word,previous context,total number,chi nese word,base probability,probability,new word,lexicon,probability,instance,generation,new word,following dis tribution,number,character,character vocabulary size,number,chinese character, a p oisson distribution,word length,unigram distribution,character,length,experi ments,w model,solution,problem,conventional approach,section,generative model,section,deficient model,maximum entropy model,feature,submodels,generative model,generative model,generative model,corpus,par allel sentence,hidden sequence,chinese word,hid den word alignment 1i,sentence,alignment,aligned chinese word,spe cial null word, ibm model,special form,prob ability,sentence pair,hidden vari ables,monolingual chi nese sentence probability,bilingual transla tion probability,character,se quence,conditioning,character,joint probability,observation,possible value,hidden variable,section,modeling assumption,monolingual chinese sentence model,translation model,dirichlet process unigram word model,section,parameter,distribution,first drawn,probability,sequence,chinese word,sentence,dirichlet process inverse  ibm model,english word,alignment,chinese word,null word,distri bution,english word,first drawn,a d irichlet process,empirical distribution,en glish word,parallel data,parameter,probability,english sentence,alignment, a c hinese sentence,sequence,1j  1p,model form,inverse  ibm model,dirichlet process prior,chinese-word specific distribution,english word,chinese word,distribution,english word,english word,di rection,distribution,chinese word con,practice,word alignment model,direction,factor,cludes word alignment, ad irichlet process  ibm model,description,calculation,inverse  ibm model,null word,distribution,chinese word,first drawn, a d irichlet process,monolingual unigram dirichlet process,probability,sequence,chinese word,word alignment,sequence,english word,1i  1p,monolingual model,transla tion model,direction,sin gle model,component model,scaling factor,maximum entropy model,weight,sub-models,development,maximiz, ble score,final translation,normalization factor,practice,proba bilities,valid observation,model work,experiment,similar deficient model,example,ibm model,unsupervised grammar induction model,manning,likely segmentation,bayesian model,exact inference,hidden variable,exact computation,integral,stream,sample,posterior dis tribution,hidden variable,obser vations,gibbs sampler, mcm method,transition,figure,transition,boundary state,no-boundary state,markov chain result,compo nent,current value,variable,problem,observation,bilingual sentence pair,hidden variable,word segmentation,alignment,direction,initial word segmentation,initial word alignment,word segmentation,alignment,equation,efficiency,limited modification,initial word alignment,different word segmenta tions,segmen tation,re-linking alignment point,original word,process,possible word boundary,char acter,sentence,tive segmentation,segmentation,segmentation,boundary,single word,character,adjacent word,bound ary,introduction,new possible alignment,figure,boundary v no-boundary state,character position,alignment link,english word,chinese word,word alignment,sentence pair,general algorithm,initial segmentation,alignment output,sampled segmentation,alignment,candidate,word boundary,word boundary,kc ompute probability,relevant alignment update count,gibbs sampler,alternative,boundary,relevant alignment link,hidden variable,probability,alternative,fixed value,hidden variable,notation,presen tation,position,sentence pair,observation,den variable,sentence,sentence,observation,hidden variable,side sentence,character position,fixed variable,sentence,position,align ments,direction,process,alternative,segmentation,product space,relevant alignment,direc tions,relevant alignment,brevity,alternative,alterna tives,section,probability,section,iteration,whole training corpus,parallel sentence,number,parallel sentence,computing probability,alternative,algorithm,probability,alternative segmentation alignment,fixed value,data dh nk,probability,hidden variable,alternative,joint probability,hidden variable,observation,probability,probability,chinese restaurant process,scheme,dirichlet process,tegrating,possible value,dis tributions,alternative hypothesis,boundary,position,relevant alignment,direction,chinese word,segmentation,probability,configuration,monolingual word probability,cba dh,translation probability,direction,computation,component probability,equation,equation,hypothesis,probabili tie,proba bility,initial state,figure,total number,word token,number,instance,probability,equation,translation model probability,segmentation boundary,english word,relevant chinese word,first case,word boundary,english word,e-to-c direction,c-to-e direction,alignment,initial state,loaded notation,alignment,relevant chinese word,posi tion,english word,total number,english word,sentence,denote,number,chinese word,segmentation,total num ber,english word,e-to-c direction,translation model probability,e-to-c direction,signments,translation probability,direction,signments,second case,hypothesis,evalua tion,word boundary,position,total number,chinese word,equation,single set,english word,e-to-c direction,c-to-e direction,initial state,figure,probability,hypothesis,alternative hypothesis,alternative alignment,cur rent alignment,constraint, ibm model,direction,alternative,current character,position,boundary,previ ous state,figure,sin gle word,position,english word,e-to-c direction,en glish word,c-to-e direction,satisfies, ibm one-to-many constraint,en glish word,c-to-e direction,e-to-c direction,hypothesis cba,segmentation,alignment,pre vious state,overview,alternative hypothesis,different hypothesis,boundary,number,previous state,boundary,c-to-e direction,number,different hypothesis, 2p combination,alignment,example,possible alignment,figure,alignment,c-to-e direction,option,previous state,hypothesis,alternative,assignment,segmentation,alignment,previous state,position,previous state,english word,e-to-c direction,english word,c-to-e direction,hypothesis,position,e-to direction,c-to-e direction,alignment,alignment,probability,c-to-e word translation probability,complete algorithm,gibbs sampler,alignment model,tr un g,re-sample word segmentation,alignment,initial segmentation,alignment,algorithm,perfor mance,corpus,new segmentation,complete algorithm,cludes,word segmentation,iteration, giz corpus alignment,di rections,g re-segmentation step,algorithm,algorithm,new segmen tation,chinese data,translation model,segmentation,baseline mt system,segment,test data,transla tion,unigram model,maxi mum likelihood estimation,final segmen tation,training corpus  ft,ranslation experiment,experiment,small data track,performance,papineni,multiple ref erences,translation task,large track  nis twe first report,experiment,mono lingual unigram dirichlet process model,word segmentation,computational re quirements,monolingual word model,fea ture weight,alignment information need,bilingual training corpus,superset,corpus,news domain,differ ent source,baseline  cws method,training corpus,language,sentence,statistic,corpus,task  nis,data sent,g method,character,g word segmentation method,running word,scaling factor,translation model,section,sentence,system,convenience,statistic,first english reference,baseline  ldc output,ini tial word segmentation,gibbs sam,word segmentation,itera tions,chinese training corpus,official  nis measure,translation performance,translation result,development data mt-eval, ble score,absolute,ab solute  ble score,test set,monolingual semi,word segmentation method,training test corpus,many unknown word,different frequency,mt data, cws data,translation task,small track  iws lt,full model,monolin gual,bilingual information, iws lt data,chinese training corpus,unigram seg menter,section,g method,unigram segmenter performs,experiment,base line,method,initialization,later ex periments,vocabulary size,chinese training corpus,signif,baseline method,statistic,corpus,task  iws lt,test sent,word voc,translation performance,different cws method,dev3 unigram,eval character,unigram,similar number,run ning word,distribution,chinese word,parameter optimization,dev2 data,sentence,evaluation,evaluation corpus,weight,section,powell,algorithm,respect, ble score,optimal value,optimal number,iteration,re-alignment,fair comparison,various cws method,translation,character,uni gram,test set,tion criterion,baseline method,absolute  wer,eval data,baseline,translation,baseline method,eval data,sentence,sentence,sentence,similar translation qual ities,example,eval corpus,segmentation,baseline,g method,transla tions,segmentation,g method generates,translation result,baseline method,segmentation,translation output,baseline,please,please,total amount,7 c onclusion,future work,chinese word boundary,translation performance,chinese-to-english mt system, a b ayesian generative model,parallel chinese-english sentence,word segmentation,alignment,hidden vari ables,bilingual information,segmentation suitable,initial word segmentation,method,new chinese word,dis tributions,small data environment,method,standard chinese word segmentation approach,chinese,translation quality,future work,bilingual model,true distribution,8 a cknowledgments jia xu,research,intern ship,microsoft research,material,exchangeability,springer,berlin,andrew,hybrid markov semi-markov con ditional random field,sequence segmentation,proceeding, emn lp,sydney,della pietra,mathematics,statistical machine translation,parameter estimation,compu tational linguistics,nese word segmentation,entity recogni tion,pragmatic approach,computational lin guistics,griffith,johnson,contextual dependency,unsupervised word seg mentation,proceeding,sydney,international workshop,spoken language translation home page,generative constituent-context model,improved grammar,duction,proceeding,linguistic data consor tium chinese resource home page,machine translation home page,gov speech test,discriminative training,maximum entropy model,statistical machine translation,proceeding,method,automatic evaluation,machine translation,proceeding,philadelphia,vetterling,numerical recipe,university press,makhoul,translation edit rate,human annotation,proceeding,august,tillmann,statistical translation,proceed ings,chinese word segmentation,statistical machine translation,proceeding, sig han wo rk shop,chinese language learning,barcelona,chinese word segmentation,statistical ma chine translation,proceeding, iws lt,october,improvement,phrase,statistical machine translation,proceeding,proceeding,second  sig han wo rkshop,chinese language learning,proceeding,conference,empirical method,natural language processing,singapore,6-7 august, afn lp joint optimization,machine translation system combination  x,microsoft research   o,microsoft way,com kristina toutanova microsoft research   o,microsoft way,com  a bstract system combination,powerful method,joint optimization strategy,output,multiple  mt system,word alignment,lexical selection decision,feature function,single log-linear model,algorithm,detail,new feature,joint decoding approach,approach,comparison,confusion-network-based system combination method,equivalent feature,ntroduction system combination,powerful method,strength,multiple mt system,result,bangalore,matusov,state-of-the-art system combination method,several input translation hypothesis,output,function,matusov,word-level system combination,sentence re-ranking method,phrase-level combination,confusion-network-based system combination,example,figure,figure,translation hypothesis,chinese-to english mt system,general idea,hypothesis,representation,figure,word position,possible word,column,final output,column,real word,example,distinct sequence,choice,scoring function,feature,log-linear model,matusov,confusion network,ordered sequence,column,correspondence set,ach word,input hypothesis belongs,correspondence,correspondence,contains,input hypothesis,final output,final word,output,correspondence set,representation,arrange word,correspondence set,alignment problem,order correspondence set,problem,confusion network,decide,output,correspondence,lexical choice problem,current state-of-the-art approach,construction,confusion network,backbone hypothesis,backbone hypothesis,final system output,guide word-level alignment,construction,column,possible word,position,example,figure,second hypothesis,backbone,hypothesis,backbone,alignment,empty word,one-to-one 1 t,representation,acyclic graph representation,confusion network,alignment,hypothesis,position,backbone word,confusion network,quality,selection,backbone,alignment,large impact,performance,word order,backbone,possible word,position,alignment,possible alignment,heuristic technique,pair-wise alignment,hypothesis,backbone,separate processing,multiple alignment,several model,pair-wise alignment,sophisticated technique, hmm model,matusov,al2008,krakos,method,hypothesis,backbone,optimal behavior,example,state-of-the-art word alignment model,hypothesis,figure,show likely alignment link,hypothesis,hypothesis,similar chinese content,backbone,alignment,empty word,network,result,process,undesirable property,instance,separate column,independence assumption,pair-wise alignment,example,method,hypothesis,backbone,instance,hypothesis,backbone,desirable output,jeep  suv,confusion network,re reordering,column,cn-based approach,backbone,alignment,correspondence set,greedy step,lexical choice,final output,backbone,alignment,auxiliary scoring function,heuristic,respect,good translation,recent approach,assumption,input hypothesis,backbone,backbone,separate  cn,decision,later decoding stage,possible order,alignment,matusov,joint optimization method,system combination,method,alignment,lexical selection sub problem,single decoding framework,log-linear model,  f igure,mt system,pair wise alignment,pair-wise alignment,incremental alignment, f igure,correspondence set,confusion network,pair-wise,incremental alignment,second hypothesis,backbone,large body,mt system combination,confusion-network,state-of-the-art method,word alignment,correspondence set,method,selection,backbone hypothesis,introduction,relation,specific model,specific,function,confusion network algorithm,pair-wise,incremental,word-level alignment algorithm,correspondence,construction,problem,many-to-many alignment,multiple insertion,deletion,prior work,number,heuristic,problem,matusov,ome work,decision,principled fashion,model-based score,matusov,special purpose algorithm,heuristic,single alignment,approach,heuristic,alignment,concept,backbone,combination,alignment,lexical choice,confusion-network-based algorithm,method,mt system combination,jayaraman,method,approach,word-level system combination,word order,single backbone hypothesis,flexibility,selection,correspondence set,decoding,confusion network-based approach,algorithm,several important difference,pair wise alignment,different hypothesis,probability,hypothesis,hypothesis,uncertainty,correspondence set,aligned word,partial hypothesis,search,hypothesis,heuristic matching,unused word,  i contrast,algorithm,definition,joint scoring model,account alignment uncertainty,combine information,word-level alignment model,lexical selection model,sub-problems,word-level system combination,addition,language model,word-voting feature,feature,alignment confidence,word-level alignment model,feature,re-ordering,distortion model,respect,original hypothesis,number,special-purpose heuristic,phenomenon,unused word,last used word,heuristic,search,assignment,hidden variable,ordered correspondence set,output variable,final translation,comparison,confusion-network,method,impact,joint decoding,sub-problems,3 n otation,algorithm,notation,  w denote,hypothesis,multiple mt system,hypothesis,i-th system,word sequence,simplicity,system,1-best hypothesis,combination,i-th hypothesis,weight,i-th system,scenario,n-best list,individual system,combination,weight,hypothesis,n-best list,cn-based system combination,input hypothesis,final output,hypothesis,final output,valid complete set,non-empty word,hypothesis,algorithm,ordered correspondence set,joint decoding process,lexical selection,presentation,feature,notation,sequence,correspondence set,correspondence,position,respective input,hypothesis,input hypothesis,special empty word,position,li-th word,i-th hypothesis,position,original hypothesis,correspondingly,example,correspondence set,surface form,different hypothesis,single candidate,different original word position,decoding process,joint optimization framework,system combination,joint decoding framework,optimal output,following log-linear model,possible valid arrangement,possible order,possible word sequence,feature,feature weight,log-linear model,feature   a set,feature,alignment,lexical selection sub problem,feature, w ord posterior model,word posterior feature,posterior,single word,weighted voting score,number,length,output word sequence,empty word,i-gram voting model,second feature,bi-gram voting feature,weighted position-independent voting score,global bi-gram voting feature,conventional cn-based system combination,flexible order,joint decoding framework,distortion,different ordering,distortion model,distortion cost,single hypothesis,distortion penalty,conventional phrase,decoder,distortion cost,position,distance,distortion cost,position vector,original position,weighted sum,single-hypothesis-based distortion cost,k-th element,word position vector,purpose,distortion feature,position,empty word,position,last visited non-empty word,overall ordering feature,feature,re-ordering behavior,joint decoding framework,feature,language model,bi-gram voting,ordering,hypothesis,valid complete set,word alignment,different hypothesis,alignment score,alignment score,word pair,word pair,pair-wise hypothesis alignment,indirect  hmm,input hypothesis,bi-directional hypothesis alignment,alignment score,average,posterior probability,alignment link,direction,direction,posterior,held-out validation,j-th word,anchor word,probability,whole c,weighted sum,logarithm,alignment probability,global alignment score,different hypothesis,common  cs,purity,entropy,distinct word,global entropy score,ther feature,log-linear model,real word,n-gram language model,hese feature,sub-problems,feature,decision,alignment,lexical selection,5 j oint decoding,core algorithm decoding,beam search,translation hypothesis,final output,sentence,figure,decoding process,example input hypothesis,figure,partial sequence,correspondence set,input hypothesis,sequence,partial output hypothesis,initial decoding state,empty sequence,empty output sequence,complete output candidate,input word,state figure,illustration,decoding process, i practice,feature,hypothesis,information,decoding state,attribute,position,input hypothesis,non-empty word,tri-gram lm,position,figure,visited word,filled circle,dotted pattern,filled circle,figure,hypothesis,third word,hypothesis,last word,estimated future score,expansion,figure,expansion,intermediate state,seed state,seed state,choice,unvisited word,example,word jeep,first hypothesis,word  suv,second hypothesis,seed state,seed state,hypothesis,valid alignment link,seed word,c state,first seed state,first hypothesis,seed word,empty word,second hypothesis,word  suv,alignment,figure, cs state,complet,current c, epv vector,c state,expansion,translation,jeep  suv,confusion network,figure,full search space,joint decoding,product,alignment,lexical selection space,length,sentence,number,hypothesis,combination,therefore,technique,search space,alignment link,arbitrary word,hypothesis,threshold,viterbi alignment,direction,garbage collection problem,many word,rare word,alignment score,top link,alignment,real word,expansion,new state,preceding state, ep v,next state,adjacency,position,empty word,position,last visited non-empty word,hypothesis,number,possible c state,number,hypothesis,c state,alignment score,top  k c state,technique,path recombination,best-first pruning,  p ath recombination,risk-free pruning method,hypothesis,real word,search space,decoding process,number,empty word,certain number,promising path,overall score,estimated future score,future score computation,future score,future cost,unfinished path,unvisited word,input hypothesis,backbone,greedy search,alignment,backbone,likely word,alignment link score,hypothesis,hypothesis,word order,backbone,form  a c,process,search beam,approximate future path,future feature score,decoding process,leftover word,section,technique,computation,future score,method,future score,input hypothesis,final future score,hypothesis-dependent score,leftover input word,certain point,finished path,input word,example,situation,second state,word  suv,third input hypothesis,adjacent state,extra score,leftover word,ur approach,output translation,leftover word,pseudo c,hypothesis,extra distortion cost,example,second state,mt hypothesis,fifth word,third hypothesis,third hypothesis,original path,left-over word,pseudo c,new inserted pseudo  cs,word count feature,dependent feature score,bi-gram voting,empty word,distortion score,example,figure,distortion cost,position,distortion cost,difference,word position,  s core,feature,pseudo c,word posterior,c count,local score,future score,process,extra score,final state,complete score,complete score,final output sentence,  f igure,leftover word,pseudo correspondence,6 e valuation,experimental condition,joint decoding method,threshold,alignment-score-based pruning,maximum number,standard setting,joint decoding approach,test set, nis t op,case insensitive  ble score,percentage, c2e test set,sentence,newswire,web-data,test sentence,reference,human translator,individual system,experiment,official submission,mt08  c2e constraint-training track,submission,1-best translation,whole test set,feature weight,original test set,test set,dev set,first half,newswire,web-data,test set,second half,individual system, ble score result,dev set,system,system,subset,erformance,system,test set,pair-wise hypothesis alignment approach,incremental hypothesis alignment approach,incremental  hmm,inchmm,lexical translation model,semantic similarity,parallel sentence pair,training corpus, ihm m-based approach, a b leu-,loss function,various parameter,inchmm,dev set,alignment feature score,joint decoding approach,final combination output,feature,feature,baseline system,feature,joint decoding approach,feature,hypothesis,non-constant feature,word posterior,gram voting,language model score,word count,joint decoding approach,  s ystem weight,feature weight,powell,search, ih mm-based approach,system weight,inchmm,joint decoding,approach,feature weight,max-bleu training method,performance,individual system,test set system id,test system,system,system,system,system,comparison,baseline, ble score,baseline,baseline,individual system,incremental  hm,possible reason,discrepancy,hypothesis,combination,experiment,performance difference,method outperforms,inchmm baseline,comparison,joint decoding approach,baseline,dev test  ih mm,inchmm,joint decoding,joint decoding,inchmm,statistical significance level,paired bootstrap re,method,comparison,effect,alignment pruning,allowable link,bi-directional viterbi alignment,result,standard setting,bi-directional viterbi alignment,slight performance degradation, ihm baseline,fair margin,joint decoding approach,ambiguous 1-to-many alignment,proper place,empty word,comparison,different setting,test standard setting,comparison,constraint,effect,flexible word ordering,experiment,different constraint,ordering,decoding process,first case,word order,backbone,input hypothesis, mbr -ble,second case,word order,comparison,standard,backbone-free word ordering,constrained setting,significant performance degradation,joint decoding approach,joint optimization,alignment,word selection,c adjacency constraint,search,benefit,flexible word ordering,effect,constraint,standard setting,monotone,backbone,monotone,7 d iscussion,joint optimization approach,word-level combination,translation hypothesis,multiple machine translation system,conventional confusion-network-based method,alignment,different hypothesis,flexible word ordering,decision,word alignment,hypothesis,word ordering,lexical choice,final output,feature,decoding process,new set,feature,alignment,behavior,method,state-of-the-art baseline, nis t mt, c2e task,joint decoding approach,baseline,ecause,complexity,search,challenge,approach,large number,input hypothesis,n-best hypothesis,system,one-to-one word alignment,same-system hypothesis,pre-computation,observation,disagreement,hypothesis,different system,hypothesis,system,alignment search space,1-best case,setting,performance,approach,opportunity,estimate,future score,additional feature,beside potential performance improvement,effective pruning,overall decoding process,reference   s rinivas bangalore,german bordel,giuseppe riccardi,consensus translation,multiple machine translation system,proceeding, iee e asru,jianfeng gao,patrick nguyen,robert moore,indirect  hmm,hypothesis alignment,output,machine translation system,proceeding, emn lp,hyamsundar jayaraman,alon lavie,explicit word matching,proceeding,amianos karakos,jason eisner,sanjeev khudanpur,markus dreyer,machine translation system combination,hilipp koehn,statistical significance test,machine translation evaluation,proceeding, emn lp,hilipp koehn,pharaoh, a b eam search decoder,phrase,statistical machine translation model,proceeding,incremental  hmm alignment,mt system combination,proceeding,ercy liang,ben taskar,dan klein,nicola ueffing,hermann ney,consensus translation,multiple machine translation system,enhanced hypothesis alignment,proceeding, ea cl,vgeny matusov,gregor leusch,rafael,daniel,chelotte,marcello federico,muntsin kolss,young-suk lee,matthias paulik,salim roukos,holger schwenk,hermann ney,system combination,machine translation,audio speech,language processing,chris quirk,random restarts,minimum error rate training,statistical machine translation,proceeding, co ling  r obert, ibm word alignment model,proceeding, n ist , nis t op,machine translation evaluation,gov speech test,doc  f ranz,minimum error rate training,statistical machine translation,proceeding, k ishore papineni,salim roukos,todd ward,weijing zhu, a m ethod,automatic evaluation,machine translation,proceeding,bing xiang,necip fazil ayan,output,multiple machine translation system,proceeding,spyros matsoukas,richard schwartz,word-level system combination,machine translation,proceeding,bing zhang,spyros matsoukas,richard schwartz,incremental hypothesis alignment,building confusion network,application,machine translation system combination,proceeding, ac l wo rkshop,ong zhao,n-gram,feature,machine translation system combination,proceeding, naa cl-hlt,a g lobal joint model,semantic role labeling kristina toutanova,california berkeley christopher,stanford university,semantic role,linguistic intuition,semantic argument frame,joint structure,strong dependency,argument,strong dependency,statistical joint model,rich set,feature,multiple argument phrase,similar state-of-the-art local model,dependency,different argument,joint information,propbank corpus,correct syntactic parse tree,parse tree,gain amount,error reduction,argument,core argument,gold-standard parse tree,propbank,automatic parse tree,error reduction,core argument,present result, con ll,task data set,multiple syntactic analysis,parser noise,release,framenet,fillmore,propbank,palmer,gildea,kingsbury,corpus,large amount,statistical model,semantic role,local classifier,semantic role,phrase,phrase,linguistic theory tell,core argument frame,joint struc ture,strong dependency,argument,instance,e-mail,kristout microsoft,electrical engineering,computer science,soda hall,berkeley,e-mail,computer science,gate building,serra mall,stanford ca,e-mail,submission,submission,publication,association,accelerated,first argument,subject noun phrase final-hour trading,active verb,sentence, age nt argu ment,good candidate, a t heme argument,sharesmust,arget ,yesterday,previous work,correlation,parse tree node,key property,joint structure,finite markov horizon assumption,dependency,node label,multiple argument node,internal feature,statistical model,long-distance dependency,joint model,argument frame,novel feature,discriminative log-linear model,system,error reduction, all argument, cor argument,state-of-the-art independent classifier,gold-standard parse tree,propbank,linguistic basis,joint modeling,argument,modifier,information,occurrence,argument,instance,argument, arg m-tmp ,others, arg m-mnr ,information apply,argument,argument,propbank,linguistic theory,argument frame,argument,information,adjunct,arg argument,propbank,independent realizational choice,argument frame,many verb,number,different argument frame,previous work,word sense,roland,jurafsky,semantic role,phrase,semantic role,word sense,model condition,much joint informa tion,argument,verb lemma,example,compare,common,steroid use,church,factory,first case,noun phrase,whereas,second case,choice,verb pas,different pattern,argument realization lead,joint information,argument,propbank semantic role name,section,toutanova,haghighi,manning  a g,joint model,example,identical surface syntax,initial noun meal,second example,evidence,beneficiary,graphical model,variable,parse tree,dependency,variable,example,statistical tendency,semantic role,constituent, age nt,dependency link,variable,probability,role  age nt,rich graphical model structure,observation,parse tree, mcc allum,pereira,practice,restricted case,linear chain conditional markov random field, mcc allum,pereira,pereira,strong markov property,efficient dynamic programming al gorithms,blunsom, crf structure,markov property,approximate inference,n-best solution,simpler model,independence assumption,exact inference,rich graphical model,many dependency,danger,computational complexity,search ing,likely labeling,many dependency,training data,danger,achieves significant performance gain,similar local model,dependency arc,random variable,efficiency problem,dynamic programming,re-ranking algorithm,small set,dependency,feature,random variable,re-ranking approach,ap proach,re-ranking,collins,simpler model,local semantic role,first pas,likely complete assign ments,parse tree node,joint model,assign ments,large space,possible joint labelings,related work,substantial amount,automatic semantic role labeling,statistical model,gildea,jurafsky,new useful feature,different system,andmodels,method,joint information,robustness,conditional distribution,parse tree,computational linguistics volume,number,joint information gildea,jurafsky,method,global dependency,includ,probability distribution,multi-sets,semantic role label,predicate,assignment,parse tree,semantic role,necessary role,unusual set,argument,local model,additional factor,mistake,distribution,label multi-sets,interpolation,relative frequency,back-off distribution,back-off distribution,argument label,naive bayes model,likely assignment,joint model,re-scoring,assignment,local model,dependency,argument,performance,system,f-measure,global information,performance,system,global information,multi-sets,joint modeling,source,joint information,flexible statistical model,pradhan,hacioglu,state-of-the-art model,support vector machine,large set,lexical feature,local classifier,parse tree node,possible argument label,joint information,dynamic class context,feature,current node,freitag,pereira,non-none label,linear order,label  non,language model lattice re-scoring,re-scoring,n-best lattice,trigram language model,semantic role label sequence,target predicate,sequence,joint information,small gain,base line system,feature,gildea,jurafsky,performance gain,joint information,system,feature,joint information,n-gram markov assumption,language model,modeling,joint dependency,longer-distance context,feature,sequence,input feature,model parameter,system,longer-distance dependency,punyakanok,punyakanok,semantic role,system,local classifier,global component,global constraint,argument frame,constraint,example,global constraint,argument,overlap,non-none label,descendant,framework,likely assignment,parse tree subject,toutanova,haghighi,manning  a g,joint model,constraint, ilp problem,practice,punyakanok,substantial gain,performance,global consistency constraint,method,performance,system,syntactic chunk,parse tree node,work differs,constraint,statistical preference,feature,knowledge engineer,search estimation problem,re-ranking,n-best search,system,parse tree,many system,shallow syntactic information,hacioglu,punyakanok,full syntactic parse information, con ll,semantic role labeling,description,system,carreras,shallow syntactic information,input sentence,sequence,phrase, a b io,representation,outside argument label,joint information,sys tems,fixed size context,previous token,example,length,window,chunk-based system,pradhan,hacioglu,information,different way,blunsom,tree-structured  crf,statistical dependency structure,syntactic parse tree,depen dencies,chil dren,argument,predicate,syntactic parse tree,tree-crf model,ability,dependency,different argument,instance,dependency,sentence,phrase,local tree,penn treebank,robustness,parser error,multiple approach,sensitivity,semantic role,system,syntactic parser error,approach,multiple syntactic analysis,top par,multiple full parser,punyakanok,shallow parse,pradhan,several type,full syntactic par,pradhan,good performance,system, con ll,task competition,multiple syntactic analysis,carreras,special component,labeling deci sion,different syntactic annotation,method,punyakanok,consistent set,argument,different parse tree,pradhan,classifier,decision,different annotation,rquez et al,special-purpose filtering,inference stage,argument,system,full analysis,approach,robustness,top par,single parser,simple general method,factor,uncertainty,parser,bayesian inference,method,finkel,manning,approximation,method,system,detail,simpler local semantic role,section,joint model,sec tion,evaluation measure,section,reader,next section,section,detail,evaluation measure,experiment,february,release,propbank,result, con ll,task data,propbank,section,standard  con ll evaluation measure,reader,description,detail,evaluation,carreras,section,evaluation measure,february,measure,february,reason,measure,performance,system,core argument,adjunct,performance,versus,argument, con ll measure,february,format,argument,additional  r-a rgx  label,measure,comparison,early paper,research,argument,argument-based measure,detail,case researcher,result,february,february,standard split,training,development,test set,annotation,section,training set,section,development,section,test set,argument label,core argument label,figure,training set,proposition,test set,development,semantic role,gold-standard parse tree,parse tree,charniak,automatic parser,charniak,gold-standard parse tree,empty constituent,strip functional tag,trace information,empty constituent,performance,palmer,gildea,kingsbury,pradhan,information,result,previous work,automatic system,evaluation measure,precise,standard evaluation measure,semantic role la beling,organizer, con ll,carreras,script,original propbank annotation,ll format, con ll software distribution,toutanova,haghighi,manning  a g,joint model, srl figure  1l abel,argument,propbank,provided software,system,propbank,several detail,eval uation measure,semantic role,result,different researcher,researcher,implementation,evaluation measure,exact detail,first issue,existence,argument,multiple constituent,partial credit,con stituents,argument,second issue,bracketing,constituent,labelings,multiple labelings,parse tree,third issue,automatic parser,constituent,filler,semantic role,parser,various research group,system,headword match,argument,choice,different evaluationmeasures,detail,different choice,large difference,reported performance,detail,evaluation measure,result,february,article,measure, con ll evaluation measure,statistic,exact difference,section,automatic par,evaluation measure,argument-based evaluation,evaluation measure,example,correct,semantic role labelings,figure,labelings,parse tree node,form  arg,label  c-a rgx ,multi-constituent argument,con stituent, c-a rgx ,continuation,constituent,semantic role,system,labelings,gold standard propbank annotation,predicate,argument frame,sentence,several clause,several argument frame,representation,valid labelings,multi-constituent argument,new argument,label  arg,previous multi-constituent argument,label  arg,computational linguistics volume,number  2o ur argument-based measure,exact bracketing,argument,constituent,partial credit,several constituent,multi-constituent argument,figure,measure,semantic role labeling,sentence,labeling,several non-contiguous span,figure,representation,correct,guessed labelings,figure,second row,labeling,parse tree node,labeled set,multi-constituent argument,exact bracketing,partial credit,several constituent,multi-constituent argument,word set,compute,measure,guessed set,labeled span,correct set,labeled span,various measure,comparison,herein,example,correct figure  2a rgument-based scoring measure,guessed labeling,toutanova,haghighi,manning  a g,joint model, srl labelings,figure,scoring measure,figure,figure,whole frame accu racy,different condition,complete taskmeasures, all column,figure,several measure,performance,system,different type,performance,consider,core argument,argument,single  arg label,argument,arseargm,argument,defines,sub-tasks,whole frame accuracy,f-m easure,whole frame accuracy,percentage,proposition,exact match,correct labelings,example,whole frame accuracy,correct,guessed set,labeled span,figure,figure,abbreviation,whole frame accuracy,measure,previous work,potential application,role labeling,correct labeling,argument,sentence,correct labelings,joint model,semantic role,optimizes whole frame accuracy,local model,confusion, f-m easure,multi-class setting, f-m easure,harmonic mean,precision,recall,formula,number,false nega tive span,guessed labeling,number,correct label,argument label,guessed label,correct label,number,guessed label,correct label,number,correct label,guessed label,figure, f-m easure,whole frame accuracy,system,core argument,regard,argument,non-core argument label,correct labelings,knowledge,specific role label,addition,argument label,decision,disagreement,annotator,palmer,gildea,kingsbury,setting, arg m-x  argument,performance measure,palmer,measure,core argument,coarse version,argument, coa rseargm,true positive span,purpose,evaluation,non-none label,generic label  arg,example, cor e id,following set,labeled span,correct, f-m easure,whole frame accuracy,performance,argument span,argument span,exact label,thesemeasures,argument label,correct label,classification accuracy,previous work,accuracy,system,correct set,argument span, cls measure,scorrect,resulting set,example, all  cls measure,following set,labeled span,correct,labelings, f-m easure,whole frame accuracy,semantic frame,predicate,sentence,sentence,several proposition,annotation,predicate,sentence,example,sentence,spacecraft,six-year journey,jupiter,proposition,six-year journey,six-year journey,evaluation measure,correct set,labeled span,proposition,relation, con ll evaluation measure, con ll evaluation measure,carreras,argument-based measure,difference, con ll measure intro,additional label type,argument,toutanova,haghighi,manning  a g,joint model, srl pressions,propbank distribution,specification,whichmulti-constituent argument,coreference chain, con ll evaluation script considers,multi-constituent argument,several separate argument,different label,argument, arg label,others, r-a rgx  label,decision,constituent,regular expression,script,propbank annotation,ll format,task software,example,following sentence, con ll specification,argument,railroad,shipper,transportation,contrast,multi-constituent argument,coreferential versus non-coreferential split argument,argument-based evaluation,annotation,argument,deregulation,railroad,shipper,transportation,difference,argument,measure, con ll evaluation measure,measure,example,deregulation,railroad,shipper,transportation, con ll script,argument,report precision,recall,argument-based measure,argument correct,report precision,recall,guessed labeling,deregulation,railroad,shipper,transportation, con ll measure,precision,recall,argument-based measure,precision,recall,guessed labeling,deregulation,railroad,shipper,transportation,measure,precision,recall,argument-based measure, r-a rgx  label, c-a rgx  label,phrase,measure,similar result,local classifier classifier,probability,individual parse tree node,standard separation,semantic role,identification,classification phase,mapping,label set,semantic role,respect,predicate,mapping,non-none value,regular expression,phrase,pronoun,part-of-speech tag,personal communication,computational linguistics volume,number  2t hen,gildea,jurafsky,system,probability,labeling,probability,identification model  pid,decomposition,independence assumption,use ful way,problem,local model,semantic role labeling use,decomposition,feature,local identification,classi fication model,decomposition,efficiency,training,identifica tion model,parse tree,classification model,argument node,training,specific label,training set,classification model,hard pruning,identification stage,exact labeling,complete parse tree,maximizer,log-linear model,multi-class classification,local model,probability distribution,identification,classification model,principled way,baseline,local identification,classification model,figure,feature,subset,feature,previous work,standard feature,figure,gildea,jurafsky,structural feature,recent work,surdeanu,pradhan,palmer,several novel feature,figure  3b aseline feature,toutanova,haghighi,manning  a g,joint model, srl figure  4e xample,displaced argument,additional feature,displaced constituent,large source,figure,argument,predicate,subject,typical position,auxiliary,subject,current position,example,predicate,subject,feature,conjunction, pat feature,typical path,subject,absence,subject,particular case,figure,instance,argument,predicate,predicate widen share,phrase,trade gap,expect,argument,expect,subject,typical position,position,subject,path relative,argument,certain argument,predicate,infinitival vps,maximum,projection,predicate,predicate,maximal,projection,argument node,feature,argument,direct object,hese feature,non local dependency,performance gain,new feature,identification,performance,all argument,feature,figure,additional feature,figure,result,constraint,argument phrase,algorithm,section,non-overlapping constraint,direct way,trained local identification,classification model,labeling,parse tree,product,subject,immediate,sister,computational linguistics volume,number  2f igure  5p erformance,local classifier, all argument,feature,figure,additional local feature,using gold standard parse tree,product,probability,twomodels,label li,parse tree node ni,problem,approach,labeling,constraint,argument node,consistent set,argument,local classifier,non-overlapping constraint,parse tree node,previous work,greedy algorithm,non-overlapping assignment,general-purpose  ilp approach,punyakanok,exact algorithm,punyakanok,length,sentence,exact dynamic programming algorithm,labeling,parse tree,product,probability,local model,simplicity,dynamic program,generalization,algorithm,viterbi algorithm,context-free grammar,non-overlapping constraint, arg node, arg descendant,local proba bilities,product,local probability,dynamic program work,assignment,subtree,assignment,likely consistent assignment,subtree,child tree,likely consistent assignment,log-probability,all none assignment,assignment,likely assignment,log-probabilities,likely assignment,log-probability,log-probabilities, all none assignment,log-probability,toutanova,haghighi,manning  a g,joint model, srl figure  6p erformance,local model, all argument,non-overlapping constraint,log-probability, all none assignment,log-probability,root node,log-probabilities,all none assignment,child subtrees,procedure,likely non-overlapping assignment,procedure,likely assignment,product,local identification,classification model,local model,conjunction,search procedure,most-likely labeling,complexity,algorithm,number,parse tree,square,number,complexity,punyakanok,algorithm,example,binary branching parse tree,number,speedup,parse tree node,bracketing constraint,parse tree,path algorithm,punyakanok,computational complexity,non-overlapping constraint,large gain,performance,result,figure,frommodels,dynamic pro gram,non-overlapping argument,constraint,figure,performance,local model,feature,dynamic program,versus,assignment,local model,additional feature,first pas model,re-ranking,non-overlapping constraint,dynamic program,state-of-the-art model, f-m easure, all argument,argument-based scoring measure,reported result,gold-standard parse tree,null constituent,functional tag,f-m easure,pradhan,detailed analysis,result,local model,fig ure,confusion matrix,figure,number,first confusion matrix con centrates, cor argument,merges,argument label,single arg label,second concentrate,confusion,argument,confusion matrix,figure,number,confusion,argument label,number,confusion,core argument,number,confusion,core andmodifier label,column,figure,number,off-diagonal entry,high  f-m easures,result,pradhan,measure,argument-based scoring,sameer pradhan,personal communication,performance,measure,computational linguistics volume,number  2f igure  7p erformance measure,local model,local feature,non-overlapping constraint,result,section,gold standard parse tree, coa rseargm cls ,figure,number,confusion,argument label, non column,number,confusion,argument label,non row,precision,recall,precision,tradeoff,increase,f-m easure,confusion matrix,figure,number,confusion,modifier argument label,number,confusion,core argument label, all  cls  f-m easure,cor e cls f-me asure,per-label  f-m easures,last column show,performance,frequent modifier label,low sixty,seventy,confusion,performance, cor argument,recall,precision,several likely  cor label,additional source,evidence,confidence,performance,argument,confusion,argument,joint model,overall performance,performance,toutanova,haghighi,manning  a g,joint model, srl cor argument,recall,precision,sentence context,split constituent,section,multiple constituent,semantic argument,propbank,automatic system,information need,multiple constituent,semantic role,argument,researcher,pradhan,punyakanok,form  c-a rgx  distinct argument label,additional class,multi-class constituent classifier, c-a rgx ,argument,figure,additional label,training data,automatic classifier,constituent,semantic role label,simple post-processing rule,output,system,constituent,argument,post-processing rule,constituent,core argument label  arg,constituent,algorithm,constituent,core argument label,argument,constituent,samemodifier label,separate argument,core argument,argument,evaluation, con ll data set,evaluation measure,upper bound,performance, f-m easure, all argument,joint classifier,dependency,parse tree,briefly,dependency,factorized sequence model,finite markov horizon,chain  crf,lafferty, mcc allum,pereira,dependency, a c rf,dependency structure,joint classifier motivation,re-ranking,argument identification,number,signments,parse tree,number,hundred,billion,normal-sized tree,argument labeling,number,possible assignment,number,argument,approximate number,possible label,argument,huge number,strong independence assumption,long-range dependency,re-ranking approach,collins,signments,independence assumption,top assignment,local semantic role,likely assignment,figure,small value,computational linguistics volume,number,re-ranking approach,serious bottleneck,performance,training,figure,oracle,assignment,assignment,local model, f-m easure,argument,number,result,small gain,upper bound,performance,large increase,memory requirement,good compromise,generation,top  n m,likely joint assignment,likely non-overlapping joint assignment,parse tree,exact dynamic programming algorithm,direct generalization,algorithm,top non-overlapping assignment,section,parametric model,log-linear re-ranking model,joint semantic role label ing,feature map,parse tree,label sequence,vector space,feature map,target verb,joint assignment,top possible joint assignment,log-linear model,parameter vectorw,weight,dimension,feature vector,probability,assignment,re-ranking model,prs rl,assignment,log-likelihoods,assignment,quadratic regularization term,framework,arbitrary feature,labeled tree,capture general property,predicate,argument structure,joint model feature wewill,feature,joint re-rankingmodel,context,example parse,figure,dependency, af igure  8o racle upper bound,top non-overlapping assignment,local model, all argument,gold-standard parse tree,toutanova,haghighi,manning  a g,joint model, srl figure  9a example tree,propbank,semantic role annotation,sentence final-hour trading,share yesterday,dependency,input feature,argument node,feature,instantiation,template,feature,number,particular pattern,labeled tree,predicate,joint assignment,candidate argument sequence,sequence,non-none labeled node,reasonable candidate argument sequence,typical number,argument,feature,predicate node,sequence,sequence,labeled node,respect,left-to-right order,constituent,parse tree,non-none labeled node,strict left-to-right order,candidate argument sequence,correct assignment,figure,feature,local model,feature,local model,joint model,template,local feature,joint template,local template,node label,example,local feature  pat,joint feature template,candidate argument sequence,feature,specific argument label,feature,generic back-off  arg label,feature,identification,classification model,example candidate argument sequence,node np1,feature,joint model,local feature template,joint model,performance,performance,local model,parametric family,parameter,likelihood,assignment,joint model,local feature,likelihood,assignment,local model,denominator,partition function,joint model sum,computational linguistics volume,number,likely assignment,denominator,local model sum,assignment,joint model,decomposition,identification,classification model,local model,whole label sequence feature,previous work,gildea,jurafsky,pradhan,information,sequence,disambiguation,example,information,multiple node,labeling,obligatory argument,whole label sequence feature template,argument node,information,position,predicate,template,whole label sequence,predicate voice,predicate lemma,template,example candidate argument sequence,variant,template,generic  arg label,specific label,argument,feature template,effect,number,argument,predicate,useful global information,argument structure,local model,argument,feature,encode preference,required argument,number,argument,pradhan,argument,sequence feature,standard linguistic understand,prevalent constraint,position,presence,adjunct,argument frame,experiment,whole label sequence feature,argument,whole label sequence feature,first type,feature,independence assumption,local model,feature,sequence,argument,joint information,length,label sequence,n-gram markov order independence assumption,practice,candidate argument sequence,top complete assignment,candidate argument sequence,local tree,syntactic analysis,tree-crf model,blunsom,dependency,joint syntactic,semantic feature,feature,whole label sequence feature,addition,argument node,syntactic feature,feature,joint mapping,syntactic realization,predicate,argument,semantic frame,feature,knowledge,constituent,syntactic realization,argument,syntactic alternation,dative alternation,example,toutanova,haghighi,manning  a g,joint model,object position,following argument,feature template,information extract,candidate argument node,phrase type,example,instantiation,template,predicate voice,predicate lemma,several kind,feature,argument node,phrase type,exists,local model,feature,phrase,addition,feature,predicate,account,feature,argument node,parse tree,identity,argument node,local model,feature,number,parameter,feature,semantic feature,encode important dependency,small number,parameter,section,palmer,similar feature template,syntactic frame,similar information,important difference,template,contextual information,noun phrase,predicate,sequence,argument node,joint model,information,argument node,repetition feature,feature,repetition,candidate argument sequence,phrase type,common pattern,variant,feature template,argument,sister,parse tree,argument,word span,feature,robustness,adjacent phrase,parser,section,result,joint model,ablation study,contribution,joint feature,applying joint model,application,joint model,semantic role labeling,joint re-ranking model rs rl,non-overlapping joint assignment,option,rs rl,local model,experiment,performance,re-ranking model  prs rl,test time,local classifier,poor argument frame,bottom,re-ranking model,computational linguistics volume,number,good argument frame,bad frame,local model,final score,final score,tunable parameter,amount,influence,local score,final score,first-pass model,parse re-ranking,collins,test time,top local assignment,performance,joint re-ranking model,local model,joint assignment,re-ranking model,weight,local model,different number,joint assignment,training,testing,memory requirement,training,figure,summary performance,figure,joint model,local feature,intlocal,joint model,local whole label sequence feature,belseq,joint model,described type,feature,evaluation,gold-standard parse tree,addition,performance measure,figure,number,binary feature,number,feature,measure,complexity,hypothesis space,parametric model,joint model,local feature,local model, f-m easure,joint model,local feature,feature,top consistent assignment,different node,estimation procedure,improved performance,factor,model  joi ntlocal ,combination,combination,sequence feature,model  lab elseq  result,point jump, f-m easure,argument,gain result,inclusion,repetition feature,error reduction,model  all jointfi gure,performance,joint model,gold-standard parse tree,number,feature,thousand,toutanova,haghighi,manning  a g,joint model,local model, cor argument  f-m easure, cor argument whole frame accuracy, all argument  f-m easure, all argument whole frame accuracy,difference, all argument  f-m easure,paired wilcoxon, all joint ,wilcoxon,rank test,per-proposition  all argument  f-m easure,joint model,feature,local model,local model,negative example,unique feature,joint feature,local feature,joint model, all joint  model,feature, joi ntlocal  model,experiment,label sequence feature, cor argument, f-m easure,argument, joi ntlocal  model,local model,large set,feature,state-of-the-art performance,joint information,sequence,predicate,argument frame,semantic feature,performance,argument,condition,feature,argument,addition,detailed analysis,result,joint model  all joint,figure,confusion matrix,number,first confusion matrix concentrate, cor argument,merges,argument label,single  arg label,second confusion matrix concentrate,confusion,argument,figure,figure,result,local model,difference,performance, cor argument,confusion matrix,figure, f-m easure,core argument label, f-m easure, f-m easure,confusion,core argument label,large decrease,confusion,slight increase, f-m easure,performance,modifier label,joint feature,dependency,core argument,useful regularity,argument,different joint feature template,figure,frequency,top assignment,loc al model,example,proposition,re-ranking model,assignment,loc al model,assignment, loc al model,figure,statistic,top ten,assignment,re-ranking model,proposition,labeling,figure,specific example,joint model,local classifier,first argument,subject position,computational linguistics volume,number,semantic role labeling,automatic par,automatic par,charniak,parser,propbank training,section,training set,parser,performance,parser,training set,constituent,argument,constituent,parse tree,semantic role,correct,system,pradhan,correct set,constituent,figure,performance measure,joint model,feature,section,gold-standard parse tree,figure,percentage,proposition,top ten assignment,local model,joint model alljoint,toutanova,haghighi,manning  a g,joint model, srl figure,percentage,argument constituent,automatic par,charniak,parser,constituent,percentage,constituent,proposition,percentage,proposition,constituent,argument word,practice,figure,percentage,argument constituent,automatic parse tree,charniak,parser,percentage,constituent,joint model result,gold-standard par,argument,constituent,parser,samemeasures,section,confusion matrix,joint model,confusion,modifier argument label,arseargm,figure,error reduction,local model, cor argument  f-m easure, all argument  f-m easure,multiple automatic parse guess semantic role labeling,correctness,parse tree,result,argument,constituent,parse tree,constituent exists,hard time,correct labeling,syntactic parser,seman tic role,system,correct way,uncertainty,syntactic parser,multiple possible parse tree,likelihood,finkel,manning,figure,comparison,joint model result,section,chaniak,automatic parser,computational linguistics volume,number  2f igure,coa rseargm  argument confusion matrix,joint model,charniak,automatic par,parse tree,argmax approximation,top parse tree,parser,charniak,alternative par,sentence swith probability,parser,fixed predicate,joint labeling,score scoresrl,final joint model,labeling lwhich,scoresrl,method,multiple parse tree,factor,uncertainty,parser,extent,method,argmax operation,single parse,complete semantic frame,method,different argument,semantic frame,different syntactic annotation,pradhan,punyakanok,show summary result,test set,top ten par,joint model,weighting parameter,parser probability,different value,evaluation, con ll,shared task, con ll,propbank version,first official release,result,previous section,pre-final february, con ll,evaluation standard,result,different group,toutanova,haghighi,manning  a g,joint model, srl figure,performance,joint model,top ten par,charniak,parser,result,several change,annotation convention,error fix,addition,new proposition,change,way pp argument,february,pp argument,head np child,propbank,pp argument,pp node,maximal performance,respect,annotation,feature definition,change,adaptation,feature,training set,annotation,section,development set,devset,section,brown corpus,ll annotation,argument,section,approach,argument,constituent,argument,label constituent,argument label,continuation label, a r -arg,constituent,continuation label,system,february,section,constituent label,core argument label,constituent,core argument label,therefore, con ll,semantic role,system,different post-processing rule,ll-style labelings,upper bound,performance,conversion scheme,following way,gold-standard  con ll annotation,development set,argument label,form  arg,labeling,referring,annotation, f-m easure,figure,performance,joint model, con ll test set,test  wsj,gold-standard parse tree,performance,gold-standard parse tree, con ll,comparison,result,researcher,figure,result, con ll  wsj test set,gold-standard parse tree,computational linguistics volume,number  2f igure,result, con ll data set,charniak automatic parse tree,con ll,task data,figure,result, con ll data set,automatic parse tree,version,charniak parser,correct treatment,forward quote,present result,charniak,automatic par,development,test set,present result,joint model,charniak parse tree,result,joint model,charniak parse tree,algorithm,section,performance measure,result,submission, con ll,haghighi,toutanova,manning,change,argument,continuation label,argument label,previous version,continuation label,sentence,charniak,parser,analysis,forward quote,first present result,joint model, con ll,result,joint model,joint model,charniak par,correct representation,forward,result,version,charniak parser,4 m ay,result,result,version, 18m arch,new re-ranking model,charniak,johnson,charniak,comparison,system, f-m easure, wsj test set,winning system,punyakanok, f-m easure,current system, f-m easure,brown test set,version, f-m easure,winning system,current system,figure,per-label performance,joint model,charniak parse tree,test  wsj test set,column,precision,recall,f-m easure,total number,argument,charniak, con ll,task data,distinction,forward,backward quote,parser,analysis,correct treatment,toutanova,haghighi,manning  a g,joint model,conclusion,accord,standard linguistic assumption,sub stantial gain,argument frame,dependency,discriminative model,non-local feature,joint information,feature,feature,complete sequence,argument label,feature,dependency,argument,syntactic feature,argument,feature,significant performance gain,state-of-the-art local model,performance,presence,perfect syntactic par,avenue,improvement,identification,argument node,handling,long-distance dependency,example,incorporatingmodels,null element information,penn treebank parse tree,levy andmanning,accuracy,knowledge,semantic characteristic,specific word,phrase,lexical statistic,instance,performance, arg m-tmp  role,alternative handling,multi constituent argument,current model,simple rule,post-processing step figure,per-label performance,joint model,charniak automatic parse tree,test  wsj test set,computational linguistics volume,number,constituent,argument,machine,perfect syntactic parser,major bottleneck,performance,current semantic role,system,syntactic parser performance,important question,performance,presence,parser error,simple approach,top par,charniak,parser,improvement,method,pradhan,punyakanok,palmer,finkel,manning,promising line,research,research,author,stanford university,journal reviewer,reviewer,audience,con ll,helpful comment,dan jurafsky,insightful comment,useful discussion,question answering,reference baker,collin,charles fillmore,john lowe,berkeley framenet project,proceeding,carreras,xavier,introduction, con ll-2004,semantic role labeling,proceeding, con ll,carreras,xavier,introduction, con ll-2005,semantic role labeling,proceeding, con ll,charniak,eugene,maximum-entropy-inspired parser,proceeding, naa cl,charniak,eugene,mark johnson,coarse-to-fine n-best parsing,maxent discriminative reranking,proceeding,trevor,philip blunsom,semantic role,tree conditional random field,proceeding,con ll,collins,michael,discriminative reranking,natural language parsing,proceeding,finkel,christopher manning,problem,approximate bayesian inference,linguistic annotation pipeline,proceeding, emn lp,sydney,australia,gildea,daniel,daniel jurafsky,automatic labeling,semantic role,computational linguistics,hacioglu,proceeding, hlt -naa cl,short paper,haghighi,kristina toutanova,christopher,manning,joint model,semantic role labeling,proceeding, con ll,lafferty,andrew  mcc allum,fernando pereira,conditional random field,probabilistic model,sequence data,proceeding,chris manning,deep dependency,context-free statistical parser,surface dependency approximation,proceeding,barcelona,mihai surdeanu,pere coma,jordi turmo,robust combination strategy,semantic role labeling,proceeding, emn lp,vancouver,canada,mcc allum,andrew,dayne freitag,fernando pereira,maximum entropy markov model,information extraction,segmentation,proceeding,palmer,martha,dan gildea,paul kingsbury,proposition bank,annotated corpus,semantic role,computational linguistics,pradhan,sameer,kadri hacioglu,valerie krugler,wayne ward,james martin,dan jurafsky,support vector,semantic argument,toutanova,haghighi,manning  a g,joint model, srl classification,machine learning journal,pradhan,sameer,wayne ward,kadri hacioglu,james martin,dan jurafsky,shallow semantic parsing,support vector machine,proceeding, hlt -naa cl,pradhan,sameer,wayne ward,kadri hacioglu,james martin,daniel jurafsky,semantic role,different syntactic view,proceeding,punyakanok,dan roth,classifier,sequential inference,proceeding,vancouver,canada,punyakanok,dan roth,wen-tau yih,necessity,syntactic parsing,semantic role labeling,proceeding, ijc ai,acapulco,mexico,punyakanok,dan roth,wen-tau yih,dav zimak,semantic role,inference,classifier,proceeding, con ll,roland,douglas,daniel jurafsky,verb sense,verb subcategorization probability,paola merlo,suzanne stevenson,editor,lexical basis,sentence processing,formal,computational,experimental issue,john benjamin,amsterdam,fernando pereira,conditional random field,proceeding,hlt -naa cl,edmonton,canada,surdeanu,sanda harabagiu,john williams,paul aarseth,predicate-argument structure,information extraction,proceeding,nianwen,martha palmer,feature,semantic role labeling,proceeding, emn lp,barcelona,martha palmer,integration,syntactic parsing,semantic role labeling,proceeding,con ll,proceeding,human language technology conference, naa cl,companion volume,new york city,association,computational linguistics,automatic semantic role labeling scott wen-tau yih,kristina toutanova,microsoft research,semantic role labeling,sentence,domain-independent semantic representation,syntactic structure,deep  nlp task,question,textual entailment,complex information extraction,semantic role labeling,significant interest,natural language processing community,problem,history,semantic role labeling,corpus,related task,detailed survey,state-of-the-art machine,approach,semantic role,system,direction,semantic role,system,application,natural language problem,tutorial outline,semantic role,corpus,survey,development,achine learning technology, con ll-05,several  con ll-05 system,verall comparison, con ll-05 system,analysis,system,parser error,main target audience, nlp student,researcher,semantic role labeling,development,researcher,semantic role labeling,global view,summary,relevant work,tutorial,researcher,related area,information extraction,spoken language understanding,scott wen-tau yih,computer science,university,illinois,urbana-champaign, a p ost-doc researcher,machine learning,applied statistic group,mi crosoft research,research,different problem,natural language processing,machine learning,information extraction,semantic parsing,several paper,seman tic role labeling, ijc ai-05, srl system,system, con ll-05,kristina toutanova,computer science,stanford university,microsoft research, a r esearcher,natural language processing group,expertise,semantic role labeling,syntactic parsing,machine learning,machine translation,kristina,semantic role labeling, con ll-05, srl system,stanford,runner-up system, con ll-05,proceeding, naa cl  hlt,association,computational linguistics generating case marker,machine translation kristina toutanova hisami suzuki microsoft research one microsoft way,redmond wa, usa hisamis,kristout microsoft,com  a bstract,rich syntax-based statistical model,gram matical case,purpose,machine translation,language,english,language,rich system,surface case marker,extension,n-best re-ranking,method,statistical mt system,method,stan dard n-best re-ranking,perform,signifi cant improvement,baseline mt system,re sults,1 i ntroduction generation,grammatical element,flectional ending,case marker,impor tant component technology,system,corporated component,grammati cal element,target language,state of-the-art  smt system treat grammatical ele ments,content word,general-purpose phrasal translation,target language model,ele ments,chiang,galley,grammatical element,target language,long-range dependency,word corresponding,source,output, smt system,example,figure,output,baseline english-to-japanese  smt system,sentence,computer domain, smt system,domain,natu ral lexical translation,english word patch,correction program,passive voice,problem,case marker assignment,output, smt system,main verb,mistake,case marker,signment, smt system,manual analysis,translation,mistake,signment,case marker,case assignment,quality, smt system,dll file,example,statisti cal model,case marker generation,english to-japanese  smt,gen eration,case marker,many surface grammatical phenomenon,similar way, smt system,morpho-syntactically diver gent language pair,similar approach,grammatical element,rich set,syntactic feature,source,english,target,sentence,context, smt system,feature result,high case assignment quality,nota ble improvement,mt quality,revious work,building,special-purpose classifier,gram matical element,preposition,determiner,knight,chander,case marker,suzuki,toutanova,mt output,strong tendency,transitive sentence,inanimate subject,japanese,component,mt system,knowledge,first work,grammatical element production model, smt system,impact,context,new mod el,statistical mt system,new feature function,decod ing,re-rank n-best list,mt system,extension,n-best re-ranking approach,n-best candidate list,multiple case assignment variation,new feature function,expanded candidate,n-best list,standard n-best re ranking,case prediction model,quality,transla tion,papineni,human evaluation,2 b ackground,section,necessary background,current work,case marker prediction,definition,case marker prediction task,suzuki,toutanova,source english sentence,translation,case marker,case marker,japanese sentence,location,case marker,sertion,notion,bunsetsu,content,number,function word,segment,sentence,sequence,bun setsu,sentence,bunsetsu,location,case mark er,sentence,bunsetsu,case marker,position,case maker,phrase,rightmost position,punctuation mark,sentence,figure,following bunsetsu analysis,square bracket,location,potential case marker inser tion,correction,program,position,case marker,phrase,prediction task,suzuki,toutatnova,addition,case marker,strict sense,topic marker wa,combination,case marker,topic marker,case marker,column wa,case marker,simple case marker,case wa combi nation,case prediction task,19-fold classification task,phrase,case marker,treelet translation system,case predic tion model,context,treelet-based trans lation system,approach,translation,treelet translation pair,treelet,connected subgraph,dependency tree,  a sentence,treelet system,input sentence,dependency structure,treelet,uniform probability dis tribution,partition,source treelet,treelet translation pair,col lection,target translation,language treelet,single tree,ordering,method,  t ranslations,linear combination,feature function,result,context,treelet system,phrase-based  smt system,case marker grammatical function,ga subject,genitive,location,instrument,case marker,model parameter,feature function,ten feature function,treelet sys tem,log-probabilities,direct channel model,relative frequency,lexical weighting channel model,trigram target language model,order model,word count,phrase count,average phrase size func tions,whole-sentence  ibm model,log probability,direction,max-bleu method,section,case prediction model,system,additional feature function,translation model,parallel corpus,corpus,source sentence,de pendency structure,dependency,target side,heuris tic,example,aligned sentence pair,source,english,word dependency structure,solid arc,english,japa nese word,dotted line,target,pendencies,solid arc,additional annotation,figure, pos tag,bunsetsu dependency structure,bold arc,target side,treelet sys tem,case prediction model,section,data experiment,parallel data,computer,domain,main data set,train-500k,sentence pair,baseline treelet system,case prediction model,disjoint set,data set,test-2k,case prediction model,characteristic,data set,experiment,later section,sent pair,lambda-1k,dev-1k,test-2k,characteristic 3 s tatistical model,case prediction,case prediction model   o ur model,case marker prediction,fol low,previous work,case prediction,non-mt context,suzuki,toutanova,maximum entropy,classifier,case marker,probability dis tribution,case marker assignment,source english sentence,non-case marker word,candidate japanese translation,additional annotation information,japanese translation,corresponding source sentence,additional annotation informa tion,alignment,dependency structure, pos tag,sequence,exclud,case marker,assignment,phrase,probability,signment,information,probability,complete case assignment,product,phrase,probability,case marker,phrase,context feature,case marker,sentence,independ ent,independence assumption,result,previous work,su zuki,toutanova,joint model,large improvement,case marker,non -mt context, f igure,english-japanese sentence pair,feature selection,suzuki,toutanova,main difference,current model,feature selection,induction,useful feature,feature combination,source,information,im portant,grammatical element, smt system,sentence pair,case prediction model,subset,10k sentence,case prediction model,ref erence translation,treelet translation system,figure,source,target word dependency structure,source language  pos,word align ment, a p o tagger,target sentence,sentence,bunsetsu,bracket,method,section,bunsetsu,pendency structure,target side,bold arc,figure,pendency structure,english,procedure,paired corpus,japanese sentence,refer ence translation,translation, smt system,large set,possible feature,annotation,feature,feature template,binary feature,different instantiation,template,automatic feature selection,induc tion algorithm,base set,template,selection algorithm,original template,trigram,conjunction,template,performs,feature selection,template,increase,model accuracy,algorithm,described, mcc allum,application,feature selection pro cedure,template,example instantia tions,phrase,saabisu,service,figure,conjunction,many feature,parent,information,target,source side,context,feature, smt system,treelet,phrase size,exam ple,word lemma, pos tag,previous word,next word,previous head word,parent word,context,treelet system,system,treelet size limit,case model,information,source,tar get,baseline mt system,context,contribution,multiple source,knowledge,maximum entropy model,relative frequency estimate,limited amount,smoothing,state-of-the art  smt system,performance,reference translation,integration,case pre diction model,mt system,evaluation,case assignment,reference translation,performance,upper bound,performance,ref erence translation,word choice,word order,result,refer ence experiment,5k-test set,metric,accuracy,percentage,phrase,respective model,case marker, ble score,reference translation,com feature example word,position,moodo headword previous headword saabisu,parent word kaishi aligned word service parent,next word  pos  nou next word next word  pos seefu nn headword  pos  nou parent headword  pos vn,word  pos next word  po prev word  pos  ve rb nn,parent  pos, nou table,feature,case prediction model,parison,result,base line,frequency-based baseline,baseline,standard method,grammatical element,word-trigram lm, cmu toolkit,clarkson,rosenfeld,sentence,model performs,baseline,accuracy,frequency-based baseline,accuracy,error reduction,lm baseline,accuracy, ble score,  t hese result,predict case marker,correct word,correct order,impact,mt output,ntegrating case prediction model,end-to-end mt scenario,case assignment model, smt system,contribution,final mt output,method,integration,mt sys tem,n-best re-ranking approach,baseline mt system,additional model,feature function,re-ranking,n-best list,system,approach,sophis,syntax-informed model,phrase, smt system,approach,implementation,sec tion,feature,case model extend,long distance,tighter inte gration,process,future,approach,fast experimentation,n-best re-ranking,variation,standard,re-ranking method,extension,method,standard n-best re-ranking,method,straightforward application,n-best re-ranking approach,section,baseline  smt system,linear model,ten feature function,case prediction model,linear model,feature function,log-probability,case assignment,candidate hypothesis accord,weight,feature func tions,max-bleu training,n-best list,lambda-1k set,section,re-ranking method,good performance,method,re-ranking,expanded candidate,drawback,previous method,n-best list,many case assignment variation,hypothe s,hypothesis,good case assignment,simple experiment,hypothesis,mt system,case variation,signment model,variation,case marker,fraction,new hypothesis,1000-best list,mt system,dev-1k set,fraction,new case variation,first hypothesis,1000-best list,hypothesis,case variant,first hypothesis,1000-best list,indicat ing,n-best list,enough candi date,case marker assignment,candi date,following method,candidate translation list,translation,n-best list,base line  smt system,case assign ment variation,simplicity,top case assignment variation,hypothesis,case model,computational standpoint,model  acc  ble baseline,frequency,baseline,log-linear model,case prediction,context,reference translation,5k-test set,  a fter,translation candidate,feature function,candidate,linear model,feature,word count feature,new candi date,feature,treelet phrase transla tion probability,feature,baseline model,language model feature,word count feature,reverse whole-sentence  ibm model,feature,baseline model feature,casing variation,addition,feature function,extent,variation,original baseline system,binary feature,original baseline system candidate,candidate,non-none,case marker,respect,original translation candi date,case marker,case marker,feature,original baseline system candidate,effect,method,differ ence,method,integration,presence,absence,case-expanded candi date translation,5 e xperiments,result,setting,end-to-end mt experiment,datasets,disjoint,train-500k data set,source english sentence,candidate translation,baseline  smt sys sider,possible case assignment variation,hypothesis,case assignment score,sentence,global dependency,linear model,reverse whole-sentence  ibm model,feature func tion,result,additional case variation,datasets,lambda-1k set,weight,linear model,dev-1k set,model selection,test-2k set,final testing,human evaluation,result,result,end-to-end experiment,dev-1k set,section,first section, ble score,baseline  sm system,1-best re-ranking scenario,case expansion, bl eu score,baseline,oracle  ble score,translation,candidate list, ble score,second section,corresponds,result,method,stan dard n-best re-ranking,oracle,actual performance,result,strategy,new information,feature,standard n-best re-ranking scenario,improvement,baseline,contrast,method,obtains notable im provements,baseline,n-best  smt candidate,k-best case,variation,method,modified version,sen tence-level  ble,hypothesis,sentence,corpus-level  ble,result,hypothe s case,eu oracle  bl eu baseline,method,method,method,result,end-to-end experiment,dev-1k set,model parameter,small  bl eu gain,baseline,big improvement,improvement,standard n-best re,1000-best list,case marker variation,half  ble point,baseline,case varia tions,case assignment candidate,case model,approach,case prediction model,feature function,weight,linear model,case prediction model,post-processor,mt output,last section,combi nation, smt candidate,case varia tions, ble score,dev -1k set, ble point improvement,baseline,case variation, smt candidate,performance,case model,choice,content word,influence,baseline system candidate,result,dev-1k set,test-2k set,base line,pair-wise statistical test design,collins, ble im provement,wilcoxon signed-rank test,human evaluation,result,translation quality, ble score,sec tion,result,human evaluation,improvement, ble lead,translation,human evaluator,human evaluation,baseline,final test set,test-2k data,perform ance,full test-2k data,baseline,1best-40case model,human evaluation,annotator,random set,sentence,different translation,translation,baseline output,original  smt system,output,system,case marker generation component,separate evaluation,dif ferent evaluation criterion,evaluation,fluency,translation,reference translation,evaluation,adequacy,lation,meaning,reference translation,setting,source sentence,result,evalua tion,20best-10case model,result,evaluation criterion,fluency,adequacy,evaluation result,annotator,column,annotator,number,sentence,annotator,proposed system output,baseline system,translation,diagonal,bold face,judgment,annotator,annotator,output,system,translation,translation,system output,translation,adequate,translation,system output,criterion,sign test,improvement,fluency,adequacy,  o ne,reason,inconclusive result,human evaluation,dif ferent translation candidate,result,n-best candidate,20best-10case model, s  b e  s b,anno tator,result,human evaluation,system,equal quality,raw agreement rate,annotator,number,agreed judg ments,judgment,fluency,ade quacy,additional human evaluation,translation,differ,case marker,baseline,1best-40case model output,result,evaluation,agreement,fluency,adequacy,indicat ing,translation,case marker,improvement,fluency,adequacy,sign test,particu lar,sentence,system,flu ency,sentence,system,degradation,proposed system,candidate,case marker,quality,mt output,im provements,degradation,6 c onclusion,method,case marker generation model,quality,english-to-japanese mt output,mt output,human evaluation,extension,n-best re-ranking,standard n-best re-ranking,method,specific phenomenon,translation,vari ant,phenomenon,quality,generated case marker,result,many phenomenon,target language,special-purpose model,generation,article,aux iliaries,inflection,agreement,current approach,phenomenon,com plex language,rosenfeld,statistical language, cmu cambridge toolkit, esc a eu rospeech,ierarchical phrase-based model,statistical machine translation,thayer,scalable inference,training,context-rich syntactic translation model,statistical phrase-based translation,natural language generation,context,machine translation,technical report,center,language,speech process ing,john hopkins university,summer work,final report,chander,automatic postedit ing,document,feature,conditional random field,minimum error-rate training,statistical machine translation,statistical alignment model,discriminative training,maximum entropy model,statistical ma chine translation,smorgasbord,feature,statistical machine translation,automatic evaluation,machine translation,cherry,ency tree translation,informed phrasal  smt,toutanova,pre dict case marker,japanese,waibel, cm u st atistical machine translation system,proceeding,mt summit, s  b e  s b,anno tator,result,human evaluation,human language technology,annual conference,north american chapter,boulder,colorado,association,computational linguistics,morphological segmentation,log-linear model hoifung poon,computer sci,university,colin cherry microsoft research redmond,colinc microsoft,com kristina toutanova microsoft research redmond,kristout microsoft,com abstract morphological segmentation break word,morpheme,basic semantic unit,key component,natural language,system,morphologi cal segmentation,ev ery language,unlimited sup ply,labeled resource,model-based system,unsupervised morphological segmentation use,generative model,dif ficult,fea tures,first log-linear model,unsupervised morphological seg mentation,fea tures,morpheme,context,exponential prior,principle,present efficient algorithm,inference,con trastive estimation,sys tem,monolingual feature,performs,state-of-the-art system,large margin,latter us,formation,phrasal alignment,pho netic correspondence,arabic penn treebank,system,f1 error,morfessor,ntroduction,morphological segmentation,ment word,morpheme,basic syntac tic semantic unit,key subtask,research,author,intern ship,machine translation,speech recognition,question answering,past approach,alyzers,buckwalter,learn ing,habash,rambow,deep language expertise,laborious process,system building,labeling,approach,availability,large quantity,unlabeled text,unsupervised morphological segmentation,number,language,goldsmith,dasgupta,creutz,supervised label,rich feature,global dependency,system,generative model,creutz,snyder,dependency,segmentation,first log-linear model,unsupervised morphological segmentation,simple prior,principle,feature,morpheme,arabic,string al,morpheme,efficient learning,infer ence algorithm,novel combination,previous work,unsupervised learn,log-linear model,contrastive estimation,eisner,domingo,inflectional morphology,approach,datasets,arabic,hebrew,system,monolingual feature,large mar gin,system,bilingual informa tion,phrasal alignment,phonetic corre spondence,arabic penn treebank,sys tem reduces f1 error,mor fessor categories-map,creutz,semi-supervised learning,fraction,result,benefit,log-linear model,elated work,large body,unsupervised learning,morphology,addition,ical segmentation,morpheme analysis,mine feature,word form,kurimo,stem change,jurafsky,gold smith,review specif,morphological segmentation,absence,unsupervised learning,strong learning bias,morphological segmentation,often-used bias,principle,compact representation,lexicon,corpus,goldsmith,creutz,statistic,mor pheme context,conditional entropy,adjacent n-grams,morpheme candidate,harris,keshava,pitler,intuition,powerful model,contributes,performance,morphological segmentation sys tems,engineering perspective,pipeline approach,schone,ju rafsky,dasgupta,demberg,candidate affix,candidate,others,segmenta tion,joint probabilistic distribution,goldwa,creutz,snyder,barzilay,model parameter,unlabeled data,proba ble segmentation,final output,latter ap proach,standpoint,avoids,propagation,pipeline,system,generative model,goldwater,bayesian model,pitman-yor,dirichlet process,arbitrary overlap,feature,accuracy,contextual feature,prove performance,non-overlapping contextual feature,directed gen erative model,markov model,unsupervised morphological segmentation,creutz,word segmentation,goldwater,feature set,constituent-context model,manning,grammar induction,sarawagi,emi-markov  crf,supervised word segmentation,andrew,unsupervised morphological segmentation,log-linear model,little attention,notable ex ceptions, pos tagging,coreference re olution,log-linear model,partition function,supervised learning,unsupervised learning,difficulty,absence,supervised label,contrastive estimation,small neighbor hood,neighborhood,computation ea,sufficient contrastive information,aid unsupervised learning,tech niques,contrastive estimation,language modeling,morpheme,context,parenthesis,feature,segmented word w-vlav-wn,powerful global feature,og-linear model,unsupervised morphological segmentation central,approach,log-linear model,joint probability distribution,segmentation,cor pu,morpheme-context model,feature,morpheme,feature,morpheme context,resent context,n-grams,morpheme,constant,segmented arabic corpus,feature,bi gram context,segmentation,hyphen,word boundary,corpus  hna,w-vlav-wn bn-w al-ywm al-jmaep morpheme feature,value  hna, jma ep,wvlavwn,corresponding feature,word w-vlav-wn,figure,feature,weight,likelihood,correspond,morpheme,context mark,valid morpholog ical segment,overlapping feature,rich segmentation regularity,example,arabic word alywm,correct segmentation al-ywm,likely morpheme,morpheme,likely morpheme context whereas,ablation test,importance,feature,section,morpheme-context model,manning,grammar induction,morphological segmentation,flat tree,root node corre,morpheme,figure, ccm us uni gram,context feature,bigram,trigram,accuracy,trigram,full model,corpus,collection,word type,unique word,use token frequency,parameter estimation,system,performs,word type,mor phological learner,goldwater,learning,inference,constraint,segmentation,evaluation,performance,real application,addition,feature,morpheme context model,ture additional intuition,morphological seg mentation,number,distinct morpheme,segment,corpus,mor phemes,many different word,intuition,lexicon prior,exponential prior,nega tive weight,length,morpheme lexi con,lexicon,unique morpheme,complete segmentation,corpus,lexicon length,tal number,character,lexicon,lexi con,unique morpheme,morpheme,lex icon,trivial seg mentation,character,result,lexicon,sin gle character,corpus,exponential prior,number,phemes,segment,corpus,over-segmentation,morpheme,contribution,length,character,segmented word w-vlav-wn,log-linear model,directed gen erative model,length princi ple,lexicon prior favor,morpheme type,corpus prior favor,morpheme,success,initial inductive bias,prefix,suffix,language,inflectional morphology,arabic,hebrew,english,separate lexicon,prefix,suffix,result,non-negligible accuracy gain,exper iments,stem contain,character,character,mor pheme,mor pheme,prefix,follow ing morpheme,suffix,sample,corpus,following lex icon,prefix  w a stem  hna  vla bn ywm  jma ep suffix,formal model,notation,segmentation,prefix,suffix,string,adjacent character n-grams,context,occurrence,segmentation,morpheme string,context,number,character,segmentation,several morpheme,max imum length,distinct segmentation,number,morpheme,segmentation,lexicon,prefix,suffix,joint proba bility distribution,restricted set,occur rence count,morpheme,context,feature weight,weight,malization constant,cor pora,segmentation,next section,learning,inference,learning,probabilistic model,probability mass,question,log-linear mod el,answer amount,contrastive estimation,neighborhood,observed data,instance,neighborhood,pseudo-negative example,observed instance,observed corpus,function,string,string,corpus,unsupervised learning,log-likelihood,gradient descent,optimization,partial derivative,feature weight,string,context,possible segmenta tions,second expected count,neighborhood,various neigh borhoods,unsupervised  pos tagging,neighborhood, tra ns1,adjacent word,ortrans1,adjacent word,counterpart,morphological segmentation,character,instance,neighbor hood serve,pseudo-negative example,probability mass,regard,lortrans,result,ungrammatical sentence,morphology,character,legitimate word,exam ple,hebrew word lyhwh,result,probability mass,misguided ob jective, tra ns1,adjacent character,result,learning, ag aussian prior,l2 regularization,weight,learning,algorithm,semi-supervised learning,gold segmentation,contains gold segmentation,learn ing,partial deriva,difference,comparison,learning,segmenta tion,section,directed graphical model,6 i nference,object,sentence,exact inference,lexicon prior render,object,interdependent,segmentation decision,simple cor pu,penalty,lexi con,single mor pheme,segment alrb,new morpheme,lexicon,lexicon,result,segment,whole corpus,exact inference,inference,gibbs sampling,sample,procedure,next segmentation,segmentation,sam ples,expected count,segment,char acters,new segmentation,partic ular word,conditional proba bility,segmentation,dynamic programming framework,semi markov  crf,sarawagi,setting,future work,maximum number,morpheme,small constant,many lan guages,arabic penn treebank,character,maximum num ber,morpheme,constraint,morpheme,language-specific constant,prior knowledge,development set,constraint,number,segmentation candidate,number,segmentation,character,next word,neighborhood,addition,next segmentation,probable segmentation,deterministic annealing,weight,temperature,large value,burn-in faster,expected count,sampler,probable seg mentation output,7 e xperiments,system,datasets,main evaluation,multi-lingual dataset,short parallel phrase,hebrew,arabic,ara maic,dialect,arabic,english,paral lel phrase,hebrew bible,translation,word alignment,post processing,arabic,gold segmentation,accurate arabic morpholog ical analyzer,habash,rambow, a b ible edition,westmin ster hebrew institute,lowery,gold segmentation,english,ara maic,arabic,hebrew portion,ap proach,system,formation,dataset,result,gold segmentation,arabic corpus,arabic word,previous work,precision,segmentation point,phrase,feature develop ment,model hyperparameters,weight,lexicon,corpus pri or,feature weight, a g aussian prior,experiment,full arabic penn treebank,iteration,iteration,sample,sampler,sample,temperature,decrement,probable segmentation,sample,temperature schedule,segmentation candidate,segment,experiment,unsupervised segmentation,experimental set-up,direct comparison,dataset,training,phrase,test set,unsupervised learning,training data,probable segmentation,learned weight,seg mentation,training,prob able segmentation,test set,sev eral version,system,much bilingual information,monolingual information,system,state-of-the-art system morfessor,formation,phrasal alignment,pho netic correspondence,arabic,hebrew,morfessor,state-of the-art result,dataset,magnitude,unsupervised learning,entire dataset,system,bilingual information,training,test time,ara bic pr ec,heb rew pr ec,comparison,segmentation result,system,sys tem,large margin,example,arabic,sys tem reduces f1 error,-be st,monolingual morpheme con text,log-linear model,bilingual cue,ablation test,contribution,major compo nents,ablation test,full model,aspect,effect,effect,context feature,impact,separate lexicon,corpus,lexicon,distinct one,ablation result,compari son,result,full model,f1 score drop,corpus,no-prior,no-cor-pr,result,segmentation,high recall,low precision,corpus,lexicon prior,precision ara bic pr ec,big ram ,heb rew pr ec,big ram ,ablation test result,recall,system,under-segmentation,string,morpheme,large accuracy drop,f1 score,context feature,importance,feature,no-context model,feature type,different prior,accuracy,system,accuracy,restrictive dirichlet process,exponential prior,priori,context,unigrams,data sparsity,problem,context,trigram,arabic,accuracy,trigram,f1 error,unigrams,hebrew,bigram,f1 error,separate lexicon,difference,ara bic  lbl,heb rew  lbl,comparison,segmentation result,semi-supervised learning,semi-supervised learning,system,learning setting,perfor mance,various amount,learning,result,result,mono lingual feature,bilingual learning,lan guages,language,sys tem,arabic,system re duce f1 error,one-fourth,system,log-linear model,advantage,supervised label,arabic penn treebank,system,unsupervised learning,entire set,system,morfessor,creutz,addition,mor fessor categories-map,morfessor,additional greedy search specifi,segmentation,-7w compare,system,result,bilingual data,f1 mor fessor,mor fessor -map,atb prec,f1 mor fessor,mor fessor -map,comparison,segmentation result,ara bic penn treebank,morfessor,arabic,hebrew,system,low data setting,experiment,set con,character,re sults,morfessor,morfessor categories-map,performance,system,f1 error,full  atb dataset,morfessor,whereas morfessor categories-map benefit,dataset,system,f1 er ror,8 c onclusion,first log-linear model,unsupervised morphological segmentation,feature,morpheme,context,easy extension,porate additional feature,linguistic knowledge,arabic,hebrew,state of-the-art system,large margin,semi-supervised learning,future di rections,agglutinative language,ternal variation,morpheme,parallel data,multiple language,morpho logical segmentation, nlp task,experiment,mea sure accuracy,entire training set,difference,condition,full  atb result,reference galen andrew,hybrid markov semi-markov conditional random field,sequence segmentation,conference,empirical method,michael,sreerama,murthy,andrew lundberg,morphemic suffix,case study,minimum description length induction,proceeding,15th annual conference,cognitive science society,tim buckwalter,buckwalter arabic morphologi cal analyzer version,mathias creutz,krista lagus,morpheme segmentation,morphology,speech,language processing,high performance,language-independent morphological segmentation,proceeding,vera demberg,language-independent unsuper,morphological segmentation,pro ceedings,45th annual meeting,association,computational linguistics,prague,czech repub lic,john goldsmith,learning,morphology,natural language,computational linguistics,sharon goldwater,thomas,griffith,mark john son,power-law generator,advance,thomas,griffith,mark john son,distributional cue,word segmenta tion,context,proceeding,boston university conference,language develop ment,alan grove,kirk lowery,editor,west minster hebrew bible morphology database,west minster hebrew institute,nizar habash,owen rambow,arabic tok enization,part-of-speech tagging,morphological disambiguation,proceeding,annual meeting,association,com putational linguistics,zellig,harris,phoneme,language,samarth keshava,emily pitler,intu itive approach,induction,proceeding,pascal challenge workshop,venice,dan klein,christopher,manning,natu ral language grammar induction,constituent context model,advance,mathias creutz,ville turunen,overview,morpho challenge,workshop,hoifung poon,pedro domingo,joint un,coreference resolution,markov logic,proceeding,conference,empirical method,natural language processing,ronald rosenfeld,whole sentence maximum entropy language model, iee workshop,auto matic speech recognition,understanding,sunita sarawagi,william cohen,semimarkov conditional random field,information extraction,proceeding,twenty first international con ference,machine learning,patrick schone,daniel jurafsky,knowlege free induction,inflectional morphology,pro ceedings,jason eisner,contrastive esti mation,training log-linear model,unlabeled data,proceeding,annual meeting,sociation,computational linguistics,benjamin snyder,regina barzilay,cross lingual propagation,morphological analysis,proceeding,twenty third national conference,artificial intelligence,benjamin snyder,regina barzilay,unsuper,multilingual learning,morphological segmen tation,proceeding,annual meeting,association,computational linguistics,proceeding,international conference,computational linguistics,annual meeting,sydney,association,computational linguistics learning,predict case marker,japanese    h isami suzuki    k ristina toutanova1 microsoft research one microsoft way,redmond wa, usa hisamis,kristout microsoft,com  a bstract japanese case marker,gram matical relation,complement np,predicate,pose challenge,generation,japanese text,foreign language learner,system,japanese case marker,propose machine,method,setting,information,japanese sentence,information,corresponding eng lish source sentence,mt context,well-studied task,english semantic role labelling,feature,syntactic dependency structure,monolingual task,kyoto corpus,ac curacy,correct case marker,phrase,bilingual task,ac curacy,phrase,bilingual dataset,technical domain,setting,feature,exploit dependency informa tion,gold-standard annota tions,contribute signifi,prediction,case marker,1 i ntroduction,grammatical element,inflec tional ending,case marker,impor tant component technology,context,english-to-japanese  mt system,example,japanese case marker,grammatical relation,location,complement noun phrase,predicate,case marker,source language,many grammatical relation,word order,english,case marker,author name,relation,reason,generation,case marker,foreign language learner,difficulty,generation,choice,case marker,generated sentence contains,grammatical element,vere unintelligibility,different semantic interpretation,intended one,reasonable prediction,case marker,content word,sentence,gen eration,source,native,target language,case marker,information,sentence,example,figure,sen tence contains,case marker,english,case marker,sentence,multiple valid answer,decision,correspond,different semantic relation,example,first case marker slot,figure,topic marker,case marker,reasonable choice,marker,marker,second slot,subject marker,reasonable choice,einstein,subject,idolize,meaning,sentence,example,choice,correct answer,speaker,intent,sen tence,content word,sentence structure,unlikely case,decision,external component,example, mt component,inten tional ambiguity,case prediction model,sentence generation,case marker,signment,distinct,related setting,section,mod el,section,monolingual task,section,case marker,japanese sentence,dependency struc ture,well-studied task,semantic role,jurafsky,carreras,semantic role label,phrase,sentence,respect,predicate,annotation,propbank,palmer,case marker prediction,uncertainty,semantic role,encouraging result,section,section,bilingual task,information,case assignment,corresponding source language sentence,process,mt introduces uncer tainties,feature,benefit,dependency structure,mod el,signed structure,case prediction,section,description,nominal particle,japanese traditionally,japanese nominal postposition,category,masuoka,takubo,  c ase particle,case marker,grammatical relation,complement np,predicate,predicate,case marker,simple mapping,language,generation,relationship,case marker,grammatical relation,case marker,multiple grammatical relation,ainshutain-ni akogareru,ein stein,object relation,kyo-ni sumu live,loca tion,grammatical relation,different case marker,tokyo-ni sumu,tokyo-de au meet,location relation,case marker,primary target,pre diction,particle,phrase,english,occurrence,sentence structure,current prediction task,  f ocus particle,particle,phrase,background,contextual knowledge,example shika,pasuta-shika tabenakatta ate,pasuta-mo tabeta,case marker,example,object marker,information,predi cate-argument structure,principle,sentence structure,target,exception,target,prediction,following reason,ome linguist,topic marker,focus particle,masuoka,takubo,main function,sentence,extent,structure,sentence,japanese text,ex ample,postposition,kyoto university text corpus,henceforth kyoto corpus,kurohashi,frequent postposition,readability,focus particle,english,formation,source language,herefore,addition,true case marker,case marker,combination,case particle,secondary target,case marker,check mark,secondary target,karawa,madewa,yoriwa,case particle,phrase,task definition,case prediction task,sentence,bunsetsu,nominal parti cles,focus particle,nominal particle,kyoto corpus, f igure,example,case marker,bun setsu,phrase,boundary,phrase,dependency relation,dependency structure,monolingual experiment,dependency structure annota tion,kyoto corpus,bilingual experiment,consisting,content word,n-content word,compound,n-components,number,function word,particle,auxiliary,ase marker,function word,case marker,case marker,phrase,phrase,case marker,phrase,case marker,related work,case marker prediction,similar task,semantic role,section,example,function tag assignment,charniak,case prediction task,function tag,parsed structure,major difference,current task,semantic role label,function tag,sentence,parse structure,decision,case marker,sentence structure,section,related task,concrete comparison,frequent semantic role label,account,labeled argument,propbank,exception,certain case marker,phrase,case marker,conjunctive particle,adnominal relation,subject,relative clause,carreras,frequent case marker,account,case-marked phrase,semantic role label,function tag,accordance,theoretical deci sion,annotation,natural language understanding task,contrast,case marker,surface sentence string,theoretical decision,case prediction,japanese,implicit case relation,noun phrase,kawahara,murata,isahara,differ ent form,surface form,case marker,deeper case relation,surface case marker,context,sentence generation,decision tree,sentence realization,semantic representation,high accuracy,account,uchimoto,generat,function word,case marker,keywords,headword,phrase,component,n-gram lan guage model,surface word string,bun setsu dependency information,result,test sentence,content word,next section,feature,3 c lassifiers,case prediction   w,case prediction,local model,case marker,phrase,case mark er,phrase,joint model,rate dependency,case marker,depend ents,head phrase,local classifier,standard practice,semantic role label ing,case prediction task,identification,classification,gildea,juraf sky,pradhan,identification task,phrase,-ca se,phrase,case marker, no ne,grammatical function,wa ga subject,object,genitive,dative object,location kara source,location,instrument,cause goal,direction,source,object,comparison wa topic   t,case marker,classification task,case mark er,phrase,binary classifier,identification,multi-class classifier,classifier,complete task,classifier,probability,bunsetsu accord,identification,classification model,probability distribution,complete model,case assignment,case marker,employ,decomposition,effi ciency,training,decomposition,classification model,subset,training example,phrase,case marker,toutanova,various machine,method,classifier,log-linear model,identification,classification task,probability distribution,chain ing,component model,easy integra tion,mt system,joint classifier toutanova,substantial improve ment,performance,semantic role,joint classifier,phrase,account,phrase,argument structure,joint structure,strong dependency,argument,case marker,argument structure,extent,joint classifier,case prediction task,joint classifier,framework,n-best reranking,collins,toutanova,experiment,case assignment sequence candidate,sister phrase,local model,joint classifier,candidate,sister,oracle accuracy,5-best candidate list,phrase,onolingual case prediction task,section,gold-standard dependency annota tions,kyoto corpus,annotation,rich set,feature,syntactic structure,feature,basic local model,identi fication,classification model,feature,phrase,parent phrase,relation,grandparent,phrase,feature,phrase,parent,sibling node,superset,dependency-based feature,hacioglu,semantic labeling task,addition,basic feature,combined feature,bottom,joint model,feature,sequence,non-none case marker,sister phrase,repetition,non-none case marker,feature,regularity,sequence,case marker,phrase,head phrase,  a ll,feature,binary fea tures,feature,combination,feature name,unique feature,count cut-off,feature,feature,identification basic,phrase,prevheadpos,nextheadpos   p revpos,prev2pos,nextpos,next2pos headnounsubpos,formal noun,adverbial headlemma headword,prevheadword,nextheadword prevword,prev2word,nextword,next2word lastwordlemma,case marker,astwordinfl,case marker,sfiniteclause isd ateexpression isn umberexpression haspredicatenominal hasnominalizer haspunctuation,period hasfiniteclausalmodifier relativeposition,last  ns iblings,number,absolute position,passcaus negation basic,phrase relation,linear distance,child indication,feature,combined feature,local classifier,feature,classification model,number,joint feature,joint model, a g aussian prior,baseline,kyoto corpus,version,section,contains news article,january,editorial article,january-august,sentence,phrase,contains news article,january,editorial article,sentence,phrase,contains news article,january,editorial article,sen tences,phrase,model pa rameters,error analysis,previous work exists,case marker,kyoto corpus,good baseline,baseline,accuracy,test set,non-none case marker,case-marked phrase,reasonable baseline,language model,lan guage model,first model,log-linear model,sen tences,second model,bigclm,domain,sentence,advantage,language model,dependency annotation,training,language model, cm language,toolkit,default parame ter setting,clarkson,rosenfeld,language model baseline,task set-up,classifier,phrase,possible case marker,position,insertion,case marker,phrase,phrase,punctuation,case assignment,sequence,phrase,sentence,language model probability,resulting sentence,likely case assignment sequence,dynamic programming algorithm,result,discussion,result,case marker pre diction,respond,component,local model,phrase,classifica tion task,case-marked phrase,complete task,phrase,complete task,local model,joint model,improvement,joint model,absolute percentage point,difference,proportion,joint classifier,improvement,local classifier,semantic role,several reason,limited set,feature,case sequence,repetition feature,extensive use,global feature,improvement,se mantic role labeling,phrase,respect,predicate,phrase,kyoto corpus,phrase,advantage,joint classifier,current model formulation,case marker,semantic role label,lin guistic analysis,variation,argument,pronoun,case marker,different semantic role,  f rom table,baseline model,language model,performance,system,training data,dependency,syntactic feature,inspection,weighted feature,phrase dependency-based feature,identification,language model,classifier,error reduction,difference,language model,log-linear model,difference,proportion,  f igure,recall,precision,good re sults,ambiguous decision,marker,multiple grammatical relation,performance,baseline,frequency,baseline,bigclm,accuracy,case prediction model,formance,secondary target,suffers,ambiguity,primary target,ilingual case prediction task,simulating case prediction,case prediction model,additional factor,consideration,monolingual task,source sentence,useful feature,gold-standard dependency annotation,mt context,imperfection,structural annotation,section,case prediction model,context,setting,dependency information,target language,projec tion,dependency structure,source lan guage,english,tree-to-string-based statistical mt system,experiment,english source sentence,reference translation,case marker,japanese reference translation,reference sen tence,information,source sentence,word alignment,japanese dependency struc ture,mt component,case marker assignment,candidate translation,case prediction model,experiment,section,reference translation,important preliminary step,final goal,section,syntactic information,case marker,target language,information,source language,dataset,collection,parallel eng lish-japanese sentence,computer,domain,sentence pair,training,development,parallel sentence,tree-to-string-based mt system,dependency structure,source language,project dependency structure,target language,figure,example,aligned sentence pair,source,english,word dependency structure,english,japanese word,dotted line,pendency structure,kyoto corpus monolingual task,additional information,japanese sentence,following manner, f igure,english-japanese sentence pair first,sentence,automatic tagger, pos tag, pos tag,phrase,bunsetsu,bunsetsu,content word,number,function word,content,function word,phrase-level dependency structure,breadth-first traversal,word dependency structure,english,phrase dependency,bold arc,figure,case marker,case marker prediction,section,case marker,section,phrase,baseline model,baseline model,section,domain,precision recall  f igure,precision,case marker,frequency,parenthesis,case assignment,test set,frequency,kyoto corpus,bunsetsu-parsing algorithm prefers,phrase,final goal,case marker,bunsetsu,case assigner,case marker,bunsetsu,bunsetsu,case marker,frequent case marker,case-marked phrase,monolingual task,trigram language model,training set,case prediction model,sentence,sentence,domain,result,baseline,section,log-linear model,log-linear model,section,impact,information,source language,case prediction task,monolingual model,information,source english sentence,bilingual mod el,information,source,mod el,local model,section,feature,bilingual model,example,feature,addition,feature combination,bilin gual model,monolingual feature,feature,impor tance,dependency information,context,quality,kyoto corpus,addition,feature, a d irection feature,parent,phrase,word-based dependency tree,constraint,case marker,alternative parent,feature,information,process,phrase dependency structure,word dependency information,target language,show bilingual feature,source sentence,word alignment,feature,source word,phrase,parent phrase,alterative parent,phrase,preposition,source language,information,addition, pos feature,source word,correspond,dependency,phrase,parent phrase,english source,japa nese phrase,parent phrase,single source word,relationship,define subcategorization,direction,distance,number,sibling feature,grammatical relation,source,projected target dependency structure,result,discussion table,result,complete case assignment task,mt context,language model,monolingual feature,eature example headword headpos,nn prevword prevpos,nn next2word net2pos moodo nn prevheadword prevheadpos,sister,distance,direction,nn bilingual,source word,source word,source word,head word,parent phrase,source word,parent word,parent,source word,phrase,aligned distance,aligned direction,bilingual feature model test data baseline,frequency,baseline,baseline,accuracy,monolingual model performs,error reduction,language model,error reduction,difference,difference,proportion,projected dependency information,case prediction task,  w hen,bilingual feature,error rate,bilingual model,error reduction,monolin gual model,result,information,source sentence,accuracy,case assignment,usefulness,source lan guage information,case marker,accuracy,information,translation,english preposition,marker,subject marker,marker,limited gain,onclusion,future direction,case mark er,result,bilingual setting,result,syntax-based feature,feature,source language,bilingual task,case marker,number,extension,next step,end-to-end mt system,improve ments,output,extensive analysis,feature,feature ablation experiment,language,inflectional morphology,prediction,gram matical element,  a cknowledgements,anonymous reviewer,comment,bob moore,arul menezes,chris quirk,lucy vanderwende,helpful discussion,japanese relative clause construction,proceeding,workshop,text meaning,interpretation,charniak,function tag,parsed text,proceeding, naa cl,introduction,con ll-2005 shared task,semantic role labeling,proceeding, con ll-2005,rosenfeld,statistical lan guage, esc a eu rospeech,discriminative reranking,natural language parsing,proceeding,machine-learned context,linguistic opera tions,german sentence realization,jurafsky,automatic labeling,semantic role,de pendency tree,proceeding, col ing ,kurohashi,japanese case structure analysis,unsupervised construction, a c ase frame dictionary,proceeding, col -in,kyoto university text corpus project,proceeding,takubo,isahara,japanese case analysis,machine learning method,proceeding, iee  nl p-ke,statistical align ment model,proceeding,kingsbury,proposition bank,annotated corpus,semantic role,shallow semantic parsing using support vector machine,proceeding,cherry,dependency tree translation,informed phrasal  smt,proceeding,nihongo-no shintakusu-to imi,japa nese syntax,kuroshio shuppan,semantic role labeling,isahara,text gen eration,keywords,proceeding, col ing ,proceeding,45th annual meeting,association,computational linguistics,czech republic,association,computational linguistics a d iscriminative syntactic word order model,machine translation pi-chuan chang,pichuan stanford,global discriminative statistical word order model,machine translation,model combine syntactic movement,surface movement information,possible word order,discriminative training,feature,different kind,move ment phenomenon,substantial im provements,word ordering performance,strong baseline,word order model,baseline mt system result,point improvement,english,japanese translation,ntroduction,machine translation task,con sisting,subtasks,collection,translation,predicted word,language pair,english,ordering problem,target word order differs,source word order,previous work,target language order,movement,syn tactic constituent,constituency tree,yamada,knight,galley,depen dency tree,parser,linguistic con stituency,movement,induced hierarchical structure,sentence,chiang,research,author,intern ship,microsoft research,advantage,target lan guage syntax tree move,respect,source lan guage syntax tree,constituent,phrasal cohesion constraint,phenomenon,subject-verb-object construc tions,subject-object-verb one,english,significant amount,information,surface string,source,target,alignment,many state-of-the-art smt system,ordering decision,surface phrase,al-onaizan,papineni,order model,machine translation,surface information,framework,statistical model,fol low,existence,dependency tree,source sentence,unordered dependency tree,target sentence,word alignment,target,source sentence,figure,example,source,target dependency tree,target,pendency tree,statistical model,unordered target dependency tree,im portant advantage,tar get sentence,series,local decision,order model,machine transi tion,al-onaizan,papineni,feature,complete target sentence order,independence assumption,constraint,restriction,ssive-pres,figure,sentence pair,source depen dency tree,target dependency tree,word alignment,target tree projectivity constraint,unordered target depen dency tree,possible order,possible order,un ordered dependency tree,n-best list,possible order,n-best list,approximate search,simpler model,re-ranking approach,collins,target sentence,correct,reference,target dependency tree,result,com bining feature,source,dependency tree,distortion surface order-based feature,distortion,pharaoh,language model-like feature result,information source,contribution,performance,mt system,order model,mt system,target translation sentence output,system,improve ment, ble point,english-to japanese translation,computer domain,ask setup,ordering problem,target bag,source sentence,word alignment,tar get,source word,source dependency tree,unordered target dependency tree,figure,ex ample,target dependency tree,target sentence word,dependency tree,possible order,target sentence,respect,sentence,respect,descendant,contiguous subsequence,ordered sen tence,figure,several order,sen tence,constraint,revious study,source,target dependency tree,lin guistic constituency,alignment,subtrees,language,wellington,mt system,translation,source dependency tree,parser,linguistic structure,target depen dency tree,projection,source dependency tree,word alignment,parallelism,source,target structure,obtaining target dependency tree,projection,algorithm,target dependency tree,projection,source tree,word align ment,mt system,algorithm schemat,example,figure,projection,dependency tree,alignment,straightforward,reason,difficulty,alignment,isomor phism,sentence,one-to-one,align ment,parent,word wt,target,target word,parent,source word si,additional difficulty,definition,non-projective target dependency tree,projection algorithm,heuristic,problem,one-to-many alignment,example,constraint,japanese word,re striction,condition,algorithm,example,first order,descendant,mapping,target side,source side,subtree,target,rightmost,non-projectivity,dependency tree,example sentence,translation,constraint,target,constituent,source,important characteristic,projection algo rithm,heuristic,target dependency tree,information,source dependency tree,task setup,reference sentence v mt output,reference sentence,machine translation,source sentence,de pendency tree,unordered target sentence,unordered target dependency tree,word alignment,reference sentence,setting,target dependency tree,correct bag,target word,reference translation,respect,cor rect word order,reference,construction,setting,eval uation,contribu tion,order model,mt system,new sentence,target dependency tree,projection algorithm,setting,target dependency tree,baseline mt system,detail,system,dependency tree,figure,translation hypothesis,target dependency tree,correct target word,respect,example,rightmost,one-to-many mapping,constructed tree,knowledge,correct word order,target,3 l anguage model,syntactic constraint, a p ilot study,section,result,pilot study,difficulty,target sentence,target dependency tree,figure,versus,unordered bag,target language word,difference,setting,target dependency tree,sentence,respect,projectivity constraint,target depen dency tree,respect,correct word order,possible order,one consistent,experiment,reference sentence,target dependency tree,con struction,target dependency tree,respect,word order,constraint,experiment,mt output sentence,section,use fulness,constraint,setting,reference sentence,projective dependency tree,mt output sentence,pendency tree,baseline,methodology,simple,effective order model,art  smt system,trigram language model,setting,unordered bag,target dependency tree,experimental design,unordered sentence,unordered target,pendency,tar get sentence order,unconstrained space,permutation,permutation,respect,target dependency tree,targetprojective,standard trigram target language model,likely order,operator,np-hard,reference sentence space  ble u av,targetprojective,mt output sentence space  ble u av,targetprojective,performance,tri-gram language model,reference,mt output sentence,tree projectivity con straints,bi-gram language model,eisner,tromble,left-to-right beam search,permutation space,tree-based bottom,beam search,tar getprojective space,estimate,search error,number,correct order,language model score,search error,per mutation,targetprojective,reference sentence,performance,perfor mance,reference sentence,mt output sentence,result,addition,median number,possible order,sentence,achievable  ble,reference sen tences,correct bag,achievable  ble,put sentence, ble score,mt output sentence,characteristic,main data-sets,experiment,present pilot study,reference test set,ref test,sentence,sentence,result,experiment show,tree projectivity constraint,reference sentence,target dependency tree,setting,information,true order,large performance gain,dependency tree,number,underestimate,search error,non-reference,constraint,mt output sentence,reduction,search space size,constraint,projective order,permutation,experiment,constraint,projective target dependency tree,constraint,target dependency tree,baseline mt system,respect,projectivity constraint,respect,good target dependency tree,search,modeling problem,global order model,target dependency tree,new word,der model,reference sentence,machine translation,previous work, nlp task,parsing,recent work,machine translation,discriminative,der model,advantage,different kind,feature,parameter,evaluation measure,interest,normalized model,independence assumption,conditional model,global log-linear model,rich set,surface feature,possible order,unordered dependency tree,simpler model,n-best order,global model,n-best order,simpler model,n-best order,unordered target dependency tree,standard trigram language model,section,statistical model,current decision,inde pendent,future observation,roku fun,pron posp noun noun noun posp noun posp vn auxv,period,dependency parse,source,english,sentence,alignment,target,sentence,notice,head-relative movement,syntactic information,source,dependency tree,local tree,target dependency tree,order model,probability,position,target node,relative,par ent,information,source,target tree,probability,complete target dependency,product,probability,position,position,closeness,dependency tree,pre-modifier,position,post-modifier,position,figure,example dependency,head-relative position,small set,feature,local information,dependency tree,source node,part of-speech,source node,parent,head-relative position,source node,target node,log-linear model,fea tures,training set,aligned sentence,source,target dependency tree,figure,non-sequence,clas sifier,decision,placement,local tree order model,order whole subtrees,target dependency tree,syntactic information,source,alternative view,trigram language model,example,figure,head word,eliminates,dependent,japanese side,head word,eliminates,dependent,correspond,trigram language model,position,respect,position,language model,local tree,n-best target dependency tree order,n-best list,simple log-linear combination,bottom-up beam search,n-best,performance,combination,acle performance,reference sentence,30-best oracle perfor mance,improvement,log-linear reranking model,fol low,sentence pair,training data,candidate target word order,simpler model,gen erality,ble score,respect,feature function,sen tence pair spl,log-linear model,correspond,weight vector,distribution,possible candidate order,devel opment,problem, a b leu score,correct word four-gram,sentence-level k-gram  ble,correct k-gram, n-b est order,parameter,neg ative log-likelihood,training data,objective function,performance,feature,feature,head-relative movement,surface sequence movement,sentence,different combination,feature,contribu tion,reference sentence,machine translation,notation,ta bles,section,word bigram,target sen tence,example,figure,target sentence,align ment,current word,previous word,possible pattern,figure,category,pharaoh  dis,displacement,pharaoh,position,sentence,feature,difference,absolute value,position,source word,source,target side, pos tag,conjunction,feature,information,explored model,log probability,language model,log-probability,lo cal tree order model,feature,baseline model,5 e valuation,reference sentence,experiment,reference sentence,english sentence,japanese translation,subset,widening figure,displacement feature,different alignment pattern,contiguous word,target sen tence,mt-train,sentence,alignment,syntactic dependency structure,source,target,section,japanese  pos tag,automatic pos tagger,local classifier,tag sequence information,sentence pair,complete set,first pas model,language model,sentence,local tree order model,n-best target tree order,re-ranking model,re-ranking model, 44k sentence pair,mod el,sentence pair set,set ref-test,top part,1-best ble score,actual performance,acle  ble score,first-pass model,log-linear combination,section,combination,language model,local tree order model,large margin,combin, lto model,surface,language model,information,n-best order,re-ranking,30-best oracle,formance,upper bound,performance,approach,bottom part,perfor mance,global log-linear model,feature,addition,first-pass mod el,word-bigram feature,performance,language-model,feature,formance,first-pass model model  ble,lang model,permutation,lang model,targetprojective,local tree order model,word bigram,pharaoh  dis,performance,first-pass order model,30-best oracle performance,perfor mance,re-ranking model,different feature set,result,reference sentence,pharaoh displacement feature,displace ment feature,figure,pharaoh displacement feature,performance,baseline,displacement feature,performance, 1 b leu  point, pos tag,source word,current word,performance,result,surface movement feature, dis feature,performance,syntactic-movement feature,part-of speech information,language,combi nation,displacement,displacement feature,per formance,formation source, ble point,improvement,fist-pass model,upper bound,6 e valuation,machine translation,machine translation,translation,baseline mt system,baseline mt system construct,target translation hypothesis,target depen dency tree,mt output,reference sen tences,source sen tence,dependency tree,word alignment,unordered target dependency tree,example,figure,difference,target dependency tree,correct data,num sent,english japanese avg,vocab avg, 79k mt-test,main data set,experiment,target word,re spect,possible order,baseline mt system,baseline  smt system,system,depen dency tree,source sentence,source dependency tree,target depen dency tree,probabilistic model,translation,treelet pair,treelet,connected subgraph,source,target depen dency tree,treelet translation pair,word-aligned source,target treelet,baseline  smt model combine,treelet translation model,feature function,target language model,tree order model,lexical weighting feature,translation prob ability,word count feature,treelet-pairs count feature,feature func tions,target sentence,source sentence,framework,system,order model,parallel source,target dependency tree,figure,particular interest,component,baseline  smt system,der decision, smt system,target language trigram model,local tree order model,n-best order,re ranking,baseline system,first-pass order model,additional information,re-ranking order model,experimental result,baseline mt system,mt-train dataset,test set,mt experiment,1k sentence,mt-test,linear model,baseline  smt system,separate development,performance,first-pass model,top part,performance,first-pass model model  ble,baseline mt system,permutation,lang model,targetcohesive,local tree order model,word bigram,pharaoh  dis,performance,first pas order model,30-best oracle performance,perfor mance,re-ranking model,different feature set,result,bottom part,first row,performance,baseline mt system, a b leu  score,first pas,re-ranking model,1-best output,mt system,ref erence sentence,combination,first pas model,individual model,1-best performance,combination,30-best oracle,re-ranking model,setting,ble point,re-ranking model,baseline mt system,point improvement,first pas model,reference ex periments,difference,target  pos tag,didates,displacement feature,re-ranking model,upper bound oracle performance,first-pass model,formance,7 c onclusions,future work,machine translation,-9n otice,combination,first-pass model,baseline mt system,ver sus,mt system,possible word transla tions,addition,word order,search error,respect,target dependency tree,com bination,feature,surface movement,syntactic movement phenomenon,information source,combination,result,mt output,reference sentence,substantial improvement,simple method,1-best mt output,translation,future,tighter integra tion,order model, smt system,accurate algorithm,projective target dependency tree,translation,reference,al-onaizan,papineni,distortion model,statistical machine translation,hierarchical phrase-based model,statis tical machine translation,discriminative reranking,natural language parsing,j e isner,local search,large-scale neighborhood,optimal permutation,ma chine translation,phrasal cohesion,statistical machine transla tion,thayer,scalable inference,train ing,context-rich syntactic translation model,pharaoh,beam search decoder,phrase,statistical machine translation model,johnson,segment choice model,feature-rich model,global distortion,statistical machine transla tion,discriminative training,max imum entropy model,statistical machine translation,alignment template approach,statistical machine translation,computational linguistics,method,automatic evaluation,machine translation,cherry,dependency treelet translation,phrasal  smt,dan melamed,empirical,complexity,translational equivalence,stochastic inversion transduction grammar,bilingual parsing,parallel corpus,computational lin guistics,maximum entropy,phrase,statistical machine translation,kevin knight,syntax-based statistical translation model,proceeding,45th annual meeting,association,computational linguistics,prague,czech republic,association,computational linguistics generating complex morphology,machine translation einat minkov,kristout microsoft,hisamis microsoft,com abstract,novel method,word form,morpho,rich language,machine trans lation,rich set,morphological knowledge source,source,target sentence,prob abilistic model,contribu tion,arabic,tences,result,baseline,trigram target lan guage model,syntactic feature,large gain,prediction accuracy,method,small amount,quality,recent year,data intensive statistical technique,state-of the-art approach,surface word,phrase,source sentence,corresponding translation,dependent entity,shortcoming,word-based approach,data sparsity,importance,corpus,ex pensive resource,many language pair,rich language,many different surface form,sparsity problem,research,author,intern ship,microsoft research,approach,collection,morpholog ical entity,information,rich language,generalization,morphology,data sparsity problem,morphology generation,syntactic coherence,morphological agreement,target language,generation,morphologi,rich language,problem,limited manner,target language model,framework,inflected form,se quence,target sentence,source sentence,word alignment information,lexi cal resource,morphological informa tion,source,target side,sentence pair,syntactic analysis information,source,sentence,inflected form,target sentence,available information,log-linear model,relevant mapping function,case study,english-arabic language pair,english,russian,arabic,rich system,mor phology,distinct characteristic,morphology rich language,morphological information need,language,formation,language pair,tative,respect,generality,approach,several contribution,general approach,promise,challenge,morpholog,rich language,morphological information,translation quality,utility,source language information,word form,target language,result,limited morphological resource,approach,resource-scarce language pair,arabic morphology table,morphological feature,russian,arabic,possible value,rightmost column,table refers,morphological feature,arabic,person,number,gender,feature,english,additional gender,neuter,ara bic,distinct number notion,russian morphology,suffixation,nom inal modifiers1,russian case feature,possible value,notion,sub ject,direct object,location,arabic,semitic language,word surface form,proclitics,enclitics,prefix,suffix,flected stem,prefix,conjunc tions,preposition,terminer,suffix,possessive pronoun,verbal,conjunction,negation,suffix,object pronoun,possessive pronoun,indica tor function,presence,absence,feature,person,number,gender,large number,surface,combination,feature,marking,arabic,stance,diacritic,standard orthography,experiment,arabic,orthography,morphological generation,language,non-trivial task,morphologically complex language,rich system,agreement,example,head noun,num ber,gender,sub ject noun,person,number,past tense verb,gender,rich system,agreement,unique characteris tic,example,addition,agreement involv,person,number,gender,terminer,definite noun phrase,adjectival modifier,noun compound,deter miner,last noun,non-human subject plural noun,singular feminine form,complex language,agreement phenomenon,morphological feature,language mod elling,morphology rich language,kirchhoff,factored language model,morphological feature,backoff policy,perplexity,large body,transla tion system,generated align ments,particular language pair,example,determiner seg mentation,deletion,arabic sentence,arabic-to-english translation system,sen tence alignment,translation quality,knight,improvement,compound,similar level,alignment qual ity,corpus,morpho-syntactic source restructuring,hierar chical lexicon model,german,inflectional lan,english, pos tag,suffix,source language,oldwater, mcc losky,improvement,feature russian arabic pos,category,category,person,tense gerund present,future,imperative mood subjunctive,jussive case dat,negation,determiner,pers numb gend,pronoun,none possessivepronoun,objectpronoun table,morphological feature,arabic set,possible source transformation,incorporat,morphology,work fo,rich lan,english,research,opposite direction,cludes,survey,statistical mt system,di rections,europarl corpus,challenge,recent work,oflazer,english-to turkish translation,limited success,inflection generation,morphological fea tures,positive result,current work,probabilistic framework,morphology generation,post-processing,technique,approach,particular language pair,modelling,agreement,target side,framework,suzuki,toutanova,proba bilistic model,japanese case marker,generalization,suzuki,toutanova,model generates,closed set,case marker,addition,morphology genus tion problem,complex agreement phenomenon,multiple morphological dimension,4 i nflection prediction framework,section,morphologi cal generation,inflection prediction,lexical operation,morphology analysis,generation morphological analysis,ap plying language specific rule,full-scale morphological analysis,contextual disambiguation,resource,simple heuristic rule,last character,morphogical suffix,lexicon l,source,translation lan guages,lexicon,lexi con,surface word,following operation,possible morphological stem,surface form word,possible morphological analysis,morphological analysis,vector,categorical value,dimension,possible value,dimension,vector representation space,aligned sentence pair,sentence pair,source,tar -2m ultiple stem,ambiguity,morpho logical analysis,nn sg nom,det allocation,resource,raspredelenie resursov zaversheno figure,english-russian sentence pair,morphological annotation get sentence,lexicon l,operation,section,output, a m system,target language,sentence,corresponding stem,op eration,output sentence,inflection yt,inflection,predicted inflection,meaning,source sen tence,comply,agreement rule,target language, 3f igure,example,aligned english russian sentence pair,source,english,word dependency structure,solid arc,alignment,en glish,russian word,dependency structure,russian side,solid arc,treelet mt system,section,word dependency structure,english,word alignment information,russian sen tence display agreement,number,gender,subject noun,raspredelenie,pred icate,zaversheno,resursov,gen itive case,5 m odels,inflection prediction,framework,overall probability,predicted inflection sequence,product,local proba bilities,individual word prediction,stem sequence,output,mt system,probability,previous pre diction,second order,decision point,prob ability distribution,prediction,addition,word context,source,tar get sentence,probability,predicted inflection sequence,context,position,inflection,feature,predicate,suggested framework,morphological property,addition,surface,example,particular inflected word form yt,con text,paired feature,surface word yt,first example,neighboring stem,context feature,target word,second feature,gen der agreement,previous word,second order,context feature,morpho logical property,previous prediction,simple multi-class clas,feature,mul tiple target label,example,gender fea ture,applies,structured prediction model,structure,morphological proper tie,target prediction,addition,word sequence decomposition,feature category,information,distri bution,several category,prediction task left-to right,alternative,top-down decompo sition,dependency tree,sentence,syntactic analysis,sufficient quality,source,first ma jor distinction,monolingual versus bilingual fea tures,monolingual feature,context,target language,bilingual feature,access,information,source sentence,word alignment link,target word,figure,bilingual feature,lexical feature,word form,second order,monolingual lexical fea tures,feature,standard word trigram language model,word form,monolingual lexical model,addition,rent position,right con text,morphological feature,feature,morphological infor mation,target label,context,morpho logical generalization,syntactic feature,syntactic analysis,source,target sentence,analysis,target language,pre-stemmed sen tence,generality,dependency,paradigm,syntactic analysis,syntactic feature,ex ample,parent word,agree ment phenomenon,feature,full set,suggested feature,arabic,monolin gual lexical feature,predicted word,adjacent word,addition,traditional word bigram,trigram feature,monolingual morphological feature,morphological attribute,current predic tion,monolingual syntactic feature,parent node,bilingual feature,focus word,position,word feature,instantiation monolingual lexical word stem,person,number,gender,objpron,posspron monolingual syntactic parent stem  she ad,bilingual lexical aligned word,al alt,person,number,gender,objpron,feature,english russian,english-arabic pair,separate feature,bilingual lexical fea tures,immediate neighbor,syntactic feature,feature,source language,morphol ogy,target language,example,bilin gual det,determiner,feature,source dependency tree,determiner,fea ture value,surface word form,bilingual prep feature,parent chain,existence,preposi tion,feature,predict,arabic,prepositional pre fix,ru sian,bilingual objpron,posspron feature,object pronoun,possessive pronoun,feature,object,possessive pronoun feature,arabic,bilingual compound feature,noun compound,english source,feature,feature,rel evant,genitive case,russian,definiteness,arabic,6 e xperimental setting,effectiveness,approach,reference experi ments,aligned sentence pair,data eng-rus eng-ara avg,eng ru eng ara training,development,statistic,corpus size,average sentence length,reference translation,output,mt system,allows,method,reduced noise level,word order,reference translation,experiment,preliminary step,real task,corpus,aligned sentence pair,english-arabic,corpus,software manual,domain,morpho logical dimension,person,sentence pair,development,testing,language pair,detail,datasets,sentence pair,treelet-based mt system,word dependency structure,source language,project word dependency structure,target language,structure,figure,lexicon table,relevant statistic,lexicon,general-domain lexicon,consisting,inflected form,lexicon,word type,train ing,average,inflection,lexicon,experiment,task defi nition,word frequency,lexicon,lexicon statistic,arabic,full-size arabic lexicon,buckwalter morpholog ical analyzer,buckwalter,lexicon,stemming,inflection operator,training data,buckwal ter analyzer,arabic,high level,ambiguity,many po sible segmentation,morphological analysis,different stem,buckwalter analyzer,lexicon,manner,distinct stem,generation,word feature,dominant analysis,surface word,simplicity,ambiguity,analysis,russian,arabic,following heuristic,frequent analysis,gold stan dard label,arabic treebank,maamouri,treebank,first analysis,buckwal ter analyzer,word analysis,result,rambow,future work,baseline,baseline,morphological inflection yt,random,random baseline serf,indicator,difficulty,problem,competitive baseline, cmu language,toolkit,clarkson,rosenfeld,default setting,training data,experiment,experiment,primary goal,effectiveness,feature,contribution,informa tion source,bilin gual feature,performance,full feature schema,subset,feature,described,section,monolingual-word,stem n-gram feature,bilingual-word,bilingual lex ical feature,onolingual-all,access,information,target lan guage,syntactic fea tures,bilingual-all,feature type,language,feature selection,following manner,feature,feature template,binary feature,different instantiation,template,individual feature,con junction,feature,conjunction,feature template,contains,predicate,predicate,context,feature selection algorithm,greedy forward step wise feature selection,feature,development,accuracy,algo rithm,described,toutanova,process,man ual inspection,template,template,monolingual,bilingual-all setting,template,binary feature instantiation,fi nal model,corresponding num bers,arabic,feature template,mil lion binary instantiation,feature template,binary instantiation,monolingual,bilingual-all,7 r esults,discussion table,accuracy,word form,baseline,lexicon,punctuation,english word,target sentence,unknown lemma,evaluation,ac curacy measure therefore,-7o verall,feature,information,state-of-the-art statistical mt system,monolingual word,bilingual word,monolingual,bilingual,model sue,incomplete coverage,lexicon,true mt scenario,prediction,current experiment,word token,lexicon,arabic,word token,arabic character,result,suggested model,language model,language,contribution,non-lexical feature,notewor thy,non-lexical feature,absolute gain,bilingual setting,language pair,large gain,russian bilin gual case,absolute gain,error rate reduction,bilingual feature,similar effect,ac curacy,monolingual model,overall accu racy,arabic,inherent difficulty,effectiveness,data sparsity problem,morpho logical generation,inflection prediction model,various subset,training data,accuracy,result,figure,training sentence,model ob,accuracy,language model,magnitude,arabic,inflection ambiguity,inflected form,development corpus,evaluation,arabic,inflected form,inflected form,average,development data,data size,accuracy,data size,training data,learning generalization,repre sentative case,correct prediction,russian,ara bic,common pattern,mistake,gender,number,person,arabic,pronoun,correct choice,pronoun,coreference resolution,thorough analysis,result,improvement,8 c onclusions,future work,probabilistic framework,mor phological generation,aligned sentence pair,morpho-syntactic information,source,target sentence,re sults,reference translation,posed model,accuracy,language model,small amount,training data,morpho syntactic information,lexical information,wide margin,result,ultimate goal,mt output,special ized model,target language morphological gener ation,preliminary experi ment,english-to-russian mt system,stemmed version,stemmed word sequence,suggested framework,simple integration,mt system, ble score,obvious next step,research,integration,end-to-end mt scenario,multiple path,im provements,result,refinement,feature design,word analysis disambiguation,syntactic anal ysis,se mantic role tag,investigation,longer-distance agreement phenomenon,global statistical model,feature,dependency tree,reference tim buckwalter,buckwalter arabic morphological ana lyzer version,philip clarkson,roni rosenfeld,statistical language, cmu cambridge toolkit,eurospeech,kevin duh,kathrin kirchhoff,automatic learning,language model structure,kemal oflazer,initial ex plorations,english,statistical machine transla tion, naa cl workshop,statistical machine translation,sharon goldwater,david  mcc losky,sta tistical mt,morphological analysis, emn lp,nizar habash,owen rambow,arabic tokenization,part-of-speech tagging,morphological disambiguation,philipp koehn,kevin knight,empirical method,compound splitting,philipp koehn,europarl,parallel corpus,statistical machine translation,mt summit,young-suk lee,morphological analysis,statistical machine translation, hlt -naa cl,mohamed maamouri,ann bies,tim buckwalter,hubert jin,arabic treebank,linguistic data consortium,andrew  mcc allum,dayne freitag,maximum entropy markov model,information extraction,segmentation,sonja nie,hermann ney,statistical machine translation,scarce resource,formation,computational linguistics,franz josef och,hermann ney,statistical alignment model,maja popovic,hermann ney,suffix,statistical machine translation,chris quirk,arul menezes,colin cherry,depen dency tree translation,phrasal  smt,hisami suzuki,kristina toutanova,dict case marker,competitive generative model,structure, nlp classification task, emn lp,proceeding,45th annual meeting,association,computational linguistics,prague,czech republic,association,computational linguistics a c omparative study,parameter estimation method,redmond wa,galena,kristout microsoft,rown university, a bstract,comparative study,parameter estimation algorithm, nl task,algorithm,computational linguistics community,l2 regularization,vestigate estimation,l1 regularization,novel optimization algorithm, bl asso,version,estimator,re-ranking task,parse selection task,estimator,additional task,conditional sequence model,speech tagging,estimator,estimation,l2 regularization,near sta tistical tie,first place,ntroduction parameter estimation,many sta tistical approach,high-dimensional nature,natural language,large number,feature,challenge,parameter estimation,combination,re dundant feature,target output,avoids,small number,highly-effective feature,others,large number,weakly informative feature,intuition motivates,selection method,boosting,many feature,lasso regularization,linear model,tibshirani,feature selection,regularization,assessment,reliability,feature,decision,frame work,large amount,interest, nlp community,riezler,vasserman,feature,target,feature,estimator,l2 regularization,rosenfeld,charniak,johnson,johnson,addition,perceptron algorithm,perceptron,competitive performance,simplicity,implementation,low computational cost,advantage,l1 regularization,estimator,diverse set, nlp task,blasso,explicit use,l1 regularization,boosting,logistic regression,l1 regularization outperforms l2,larization,artificial datasets,irrelevant feature,oodman,esti mator,regularization,constraint,feature weight,comparable estimator,regulari zation,iezler,vasserman,l1-regularized estimator,l2-regularized estimator,stochastic unification-based grammar,individual estimator,literature,relative performance,method,result,example,parse re-ranking task,l2regularized approach,charniak,johnson,boosting method,collins,different feature set,n-best par,evaluation,method,much-needed comparative study,parameter estimation algorithm,l2 regularization,blasso,version,estimator,re-ranking task,parse selection task,estimator,additional task,conditional sequence model, a c mm, pos tagging, a c rf, me estimation,l2 regularization,performing estimator,training time,regularization,2 e stimators, nlp task,linear model,collins,mapping,candi date,feature,vector,feature value,real-valued weight,feature, cmm sequence model, po tagging,mapping, cmm sequence classifier,linear model,probability esti mate,entire tag sequence,different decision rule,inear model,complex dependency,feature,arbitrary function,input output pair,example,feature,log con ditional probability,output,complex interaction,feature,practice,appropriate feature,linear model,good empirical result,various  nlp task,feature definition,domain knowledge,varies,parameter estimation,fixed feature template,large number,feature,estimator,training sample,parameter vector,unseen example,estimator,estimation,l2 regularization,many linear model,estimator chooses,empirical loss,training set,loss term,negative con ditional log-likelihood,training data,l2 norm,parameter,parameter,amount,regu larization,held-out data,popular estimator,computational proper tie,gradient-based numerical algorithm,global minimum,experiment,limited memory quasi-newton algorithm,wright,optimal,method,method,generalized iterative scaling,malouf,sentence, f-s core,variant,estimator,riezler,likelihood,variant,experiment,parse re-ranking,lm adaptation,significant improvement,performance,l2-regularied estimator,l1-regularied estimator,estimation,l1 regularization,estimator,negative condi tional log-likelihood,penalty,solution,many feature weight,natural candidate,feature selection,contrast,l2 regularization,solution,weight,l1-regularized objective function,gradient,parameter equal,kazama,tsujii,estimation method,equivalent,optimization problem,number,variable,method,large-scale  nlp task,mod ification, l-b fgs ,discontinuity,gradient,andrew,scription, l-b fgs ,first order information,iterate,approximation,local curvature,function,search direction,quadratic approximation,current iterate,func tion gradient,positive definite,vector,change,recent iteration,estimate,full matrix,computation,number,operation,number,observation,single orthant,l1 regularizer,linear function,  t hus,coordinate,con secutive search point,curvature,function,segment, l-b fgs ,he sian,approxi mation,full regularized objective,orthant,next point,valid region,line search,iteration,orthant,current point,direction,local rate,function decrease point,algorithm,simple modifi cation,practice,convergence,itera tions,standard  l-b fgs ,analogous l2-regularized objective,training time,iteration,total time,function evaluation,describe  owl qn,andrew,kazama,tsujii,algorithm,l1 regularization,converge,parameter vector,l1-regularized objective,boosting algorithm,collins,function,logarithmic loss,projection,coordinate,change sign,iteration,negative value,next iteration,positive value,define,margin,respect,boosting algorithm,incremental feature selection proce dure,initialization,iteration,feature,weight,updated model,parameter value,exception,  t hen,figure,exploss,boosting,weight,small fixed step size, fsl algorithm,hastie,small step,boosting,implicit regularization,effect,l1 regularization,local sense,hastie,number,test error,boosted lasso,algorithm,language modeling,version,l1 regularization,incremental feature selec tion procedure,parameter vector,boosting,explicit use,major difference,iteration,forward step,backward step,boosting,forward step,feature,weight,important difference,boosting,feature,impact,contrast,blasso,feature,update,grid search,feature weight,experiment,mod ification,backward step,iteration,feature,absolute value,weight,decrease,lassoloss,lassoloss,blasso algorithm,initialization,iteration,feature,weight,fixed amount,reduction,exploss,forward step,decrease,exploss,effective feature,early stage,training,reduction,exploss,early stage,later stage,hese early step,boosting,effect,backward step,later stage,finite number,feature,blasso algorithm,figure,converges,lasso solution,implementation detail,theoretical justification,blasso,feature fk,impact,exploss,return,figure,algorithm,perceptron,perceptron algorithm,sto chastic approximation,loss function,mitchell,figure,initial pa rameter,update,training example,experiment,averaged perceptron algorithm,freund,schapire,variation,standard algorithm,collins,parameter vector,th training sample,training data,average parameter,number,number,training sample,3 e valuation,lan guage model adaptation,example,training,linear model,candidate list,additional feature,mapping,linear model,arbitrary global feature,output,linear model,global model,explicit enumeration,mapping,sequence model,decision,local linear model,local linear model, crf model,local model,model local model,output,local feature,e timators,global model,re-ranking framework,application,estimator,local model,boosting, bl asso,training,estimation method,probabilistic sequence model,log-loss,estimation,comparison,trained model,trained one,punyakanok,performance,different estimator,task-specific measure,wilcoxon,rank test,statistical significance,difference,estimator,result,number,non-zero feature,estima tion,number,iteration,computation time,minute,elapsed time, xeo ntm mp,machine,parse re-ranking,experimental paradigm,parse re-ranking,charniak,johnson,feature,pro gram,rerankers,linear model,esti mators,rerankers,sentence,50-best list,possible par,sentence,model combine,log probability,charniak,parser,feature,additional feature,fea 1 i,forward step,updated model,backward step,de crease,lassoloss,forward step,blasso algorithm 1 s,total number,iteration,candidate zi,current model,perceptron,ture weight,section,penn tree bank,regularizer, f-s core,section,tree bank,rerankers,result,baseline result,parser,charniak,estimation,l2 regularization,performs,estimator,magnitude,blasso,feature selection method,nature,sparsest model,perfor mance,training time,l1-regularized estimator,sparse solution,averaged per ceptron,l2-regularized estimator assign,feature,non-zero weight,language model adaptation,experiment,lm adaptation,trained language model,impact,japanese text input accuracy,input phonetic symbol,application,character error,result,andrew,variant,l2-regularized estimator,section,er feature time,  m ap, me l1,performance summary,estimator,statistical significance test result,number,character,number,character,linear rerankers,estimator,rerankers,conversion,input phonetic string,possible conver sion,baseline system,linear model,log probability,trigram language model,base feature,word uni bi-gram feature,hese uni bi-gram feature,trigram model,background domain corpus,linear model,feature weight,cross domain adaptation paradigm,portion,redundant feature,parse re-ranking task,background domain,adaptation domain,encarta corpus,training data,5k-sentence set,development data,5k-sentence set,result,baseline,word-based trigram model,background domain corpus,posteriori,traditional model adaptation method,parameter,background model,likelihood,adaptation data,  f score feature time,train iter baseline,  b lasso,performance summary,estimator,l1 regularization,statistical significance test result,result,parsing task,visible difference,l1 regularization,perfor mance,example,parsing task,l2 regularization,l1 regularization,formance difference,parsing task,performance differ ence,blasso,boosting,propor tion,feature,parsing task,result,observation,l1 regularization,presence,many redundant feature,chinese word segmentation,third task,boundary,section,hybrid mar kov semimarkov  crf,andrew,state-of-the-art accuracy,various estimation method,microsoft research asia corpus,second international chinese word segmentation,train test split,competition,experi mental setup,andrew,difference,feature,negative training example,andrew,feature,last 4k sentence,training data,weight,regularizers,performing e timation procedure,l1 regularization,refers,negative log-probability,correct segmentation,perceptron,iteration,exact maximum-scoring segmentation,current weight,pattern,algorithm,identical performance,feature,averaged perceptron,training iteration,several time,result,algorithm,andrew,l2 regularization,difference,feature,negative training example,finally,impact,regularization method,conditional probability,tag sequence,word sequence,probability distribution,context,pre vious work,ratnaparkhi,equation,local model,position,feature,current word,previous word,next word,feature,addition,lexical identity,feature,word suffix,capitalization,number special character signature,standard split,penn treebank,tagging literature,toutanova,training,development,test set,comprises section 0-18,development,regularization,regularization,grid search,accuracy,development,result,difference,wilcoxon,rank test,f1 feature,iter  me l2, me l1,performance summary,estimator,accuracy,regularization,difference,l1 regularization,estimation,competitive para meter estimation method, nlp task,variety,result,method,estimation,l1 regularization,perceptron,accuracy,estimation,l2 regularization,zation,performance,sparse model,averaged perceptron,excellent com promise,high performance,parameter estimation,similar  nlp task,popular method,choice,plement,consideration,model sparsity,estimation,l1 regularization,feature selection method,blasso,quick implementation,training,averaged perceptron,estimation,l2 regularization,ob tainable level,hybrid markov semi-markov condi tional random field,sequence segmentation, emn lp,scalable training,l1-regularized log-linear model,maximum-entropy-inspired parser,coarse-to-fine n-best parsing,maxent discriminative re-ranking,survey,technique,ee trans,speech,discriminative re-ranking,natural language parsing,discriminative training method,hid den markov model,theory,experiment,ceptron algorithm, emn lp,schapire,singer,efficient boosting algorithm,preference,margin classifica tion,perceptron algorithm,machine learning,friedman,element,statistical learning,springer-verlag,approximation,method,language modeling,exponential prior,maximum entropy model,estimator,grammar,evaluation,extension,maximum entropy model,inequality constraint,comparison,algorithm,maximum entropy parameter estimation,pereira,maximum entropy markov model,information extraction,segmentation,machine learning, mcg raw-hill company,feature selection,rotational invariance,inference,output,maximum entropy part-of-speech tagger,incremental feature selection,l1 regularization,relax maximum entro py modeling, emn lp,wall street journal,lexical-functional grammar,discriminative estima tion technique,regression shrinkage,selection,statist,feature-rich part-of-speech tagging,cyclic dependency network, hlt -naa cl,tech report,berkeley,iter  me mm l2, me mm l1,performance summary,estimator,proceeding,columbus,association,computational linguistics applying morphology generation model,kristout microsoft,hisamis microsoft,v-acruop microsoft,com abstract,quality,word form,syntactic infor mation,source,target lan guages,inflection generation model, smt system,different way,flection prediction component, smt system,base mt system,inflection generation model,english,complex language,arabic,quality,syntax-based  smt system,human judge ments,outstanding problem,improv,system,diffi culty,mt problem,sub-problems,sub-problem,isolation,overall quality,difficulty,little work,independent sub component,success ful case,literature,example,word align ment,fraser,target language cap italization,case marker gen eration,toutanova,suzuki,successful attempt,tegrate,subcomponent,word inflec tions,system,research,previous work,morpho-syntactic information,advantage,morphological analysis,motivated clustering,sparse,tures morphological constraint,target side,agreement phenomenon,sec ond problem,translation system,relevant mor phological information,target language,source language,aspect,example,morphological pre-processing,input data,common method, mcc losky,application,target language model,sec ond aspect,minkov,problem,rich feature,target word inflection,translation,english,complex language,ru sian,arabic,show improvement,mt output,several alternative method,tegration,un certainty,different component,translation problem,baseline mt system,advantage,reduction,sparsity,phrasal  smt system,active research,morphological knowledge,several ap proaches,pre-processing scheme,segmentation,clitics,habash,sa dat,compound splitting,goldwater, mcc losky,segmentation approach,dif ficult,target language,segmented morpheme,output,el-kahlout,oflazer,translation,english,recent work,general framework,morphological feature,phrase-based  smt system,repre sentation,vector,morphological feature,phrase-based mt system,factored representation,moses system,motivation,independent compo nent,inflection prediction,isolation,morphological information,main translation model,er rors,important ad vantage,decoupling,compo nents,approach,restric tions,allowable context size,phrasal seg mentation,current mt decoder,different type,mt system,problem,combinatorial expansion,search space,factored approach,inflection prediction model,minkov,inflected form,arabic,contrast,method,integration,inflection pre diction model,mt system,evaluation,impact,translation,toutanova,suzuki,trained case marker prediction model,english-japanese translation system,problem,small set,closed class word,inflected form,translation,different method,inte gration,component,3 i nflection prediction model,section,flection prediction,minkov,inflection prediction,correct inflection,tar get language,corresponding source sentence,stemming,inflection operation,lexicon,lexicon operation,target language,lexicon,following necessary operation,stemming,possible morpholog,word accord, 1i nflection,surface word,stem sw,morphological analysis,morphological analysis,vector,categorical value,dimension,possible value,morphological analysis operation,morphological feature,minkov,fea tures,person,number,gender,person,number,gender,negation,determiner,conjunction,preposition,object,uninflected form,subset,fea tures,feature,determiner,arabic,multiple value,fea tures,pronoun,adjective,russian,others,category,number,possi ble inflected form,section,av erage,word form,disambiguated stem analysis,set sw,operation,morphological analysis,arabic,dataset,generation,correct form,challenging problem,russian lexicon,general domain lexicon,training data,arabic lexicon,buckwalter morphological analyser,training data,contextual dis ambiguation,morphology,language,addition,lexicon,capitaliza tion,inflectional feature,russian,true-case word variant,possible inflection,capitalization,source sentence,sequence,translation,additional morpho-syntactic annotation,inflection yt,inflection,target sentence, a m aximum entropy markov model,flection prediction,minkov,probability,inflec tion sequence,product,local probability,prediction,local probability,previous prediction,arabic,ex periments,probability,predicted inflection sequence,inflection,refers,context,position,con text,extensive morpho,syntactic information,source,target sentence,figure,example,english-russian sentence pair,source,english,word dependency structure,solid arc,alignment,english,russian word,dotted line,de pendency structure,russian side,solid arc,treelet mt system,sec tion,word dependency struc -nn sg nom,det allocation,resource,raspredelenie resursov zaversheno figure,english-russian sentence pair,morphological annotation,english,word alignment information,feature,inflection prediction model,predicate,fea tures,certain position,source sentence,word stem,tar get language,morpho-syntactic information,source,independent component,main search,mt decoder,decoder,local ity constraint,global information,performance,reference translation,result,flection prediction model,reference translation,ideal case,translation,model contain,correct order,reference translation,inflection,accuracy,prediction,sentence,arabic,ur model performs,random,trigram language model baseline,accuracy,stem choice,realistic scenario,inflec tions,mt output sentence,accuracy,lexicon,mt scenario, oov item,russian arabic random,result,reference translation,achine translation system,inflection prediction model,machine translation system,system,syntax,surface phrase-based system,treelet translation system,syntactically-informed mt system,ap proach,translation,treelet translation pair,treelet,connected subgraph,syntactic dependency tree,translation,linear combination,feature func tions,feature,phrasal system,weight,max-bleu training,feature function,treelet system,log-probabilities,direct channel model,relative frequency,lex ical weighting channel model,trigram target language model,word count,phrase count,average phrase size function,treelet translation model,parallel corpus,corpus,implementation,source sentence,dependency structure,dependency,target side,heuristic,sen tence pair,training data,inflection model,example,figure,phrasal translation system,re-implementation,pharaoh trans lation system,lexicalized-hmm model,word alignment,treelet system,standard extraction heuristic,phrase pair,backward alignment,decoding,system,linear combination,feature function,weight,max-bleu training,feature,log-probabilities,direct channel model,rel ative frequency,lexical weighting channel model,trigram target language model,distortion,word count,phrase count,data set,english-arabic experi ments,computer,language pair,paral lel sentence,mt system sub model,phrase table,language model,parallel sentence,lambda,com bination weight,max-bleu training,parallel sentence,small number,combination parameter,integration meth od,parallel sentence,final evaluation,detail,training data,flection model,subset,training set,language pair,datasets,dataset,pair word token,avg sent,english-russian english russian train,lambda,english-arabic english arabic,lambda,data set size,5 i ntegration,inflection model,mt system,main method,integration,method,extent,factoring,problem,subprob lem,inflection,base mt system,first method,mt system,target word,inflection model,inflection,method,mt system,sequence,tar get language,inflection component,method,general framework,inflection model,mt system,method,output,base mt system,ranked list,translation hypothesis,source sentence,translation,sequence,target language,transla tions,base mt system,translation hypothesis si,source,annotation,figure,output,base mt system,subsection,candidate stem sequence,base mt model,inflection model,language model,translation,formula,dependency,brevity,expression,probability,joint probability,sequence,inflected word,integration,base mt system,word form,base mt system,sequence,inflected form,mt hypothesis si,flection model,inflected hypothesis,base mt score wi,method,standard n-best re ranking,base mt system,sequence,translation,chosen translation,provided,method,difference,1-best input,base mt system,interpolation weight,optimal number,translation,base mt system,maxi mum,hypothesis,sep arate dataset,grid search, ble score,final system,development set,sentence,method,integration differ,base mt engine,choice,specific inflected form,target,candidate translation,sequence,base mt system,flected translation,base mt system,sequence,target sen tences,word alignment,stemming operation,word alignment,goldwater, mcc losky,target sentence,sparsity,translation table,language model,performance,mt system,ability,correct se quences,target,machine learn,complex problem,inflection,vapnik,language pair,language,word alignment worse,violation,assumption,cur rent word alignment model,source,target,addition,trigram lm,violation,markov independence assumption,trigram lm,exact base mt system,stemmed form,alignment,translation,pri ori,result,system,inflected form,method,base mt system,usual way,source sen tences,target sentence,flection model,m-best translation,output trans lation,hypothesis,m-best output,base mt system,stemmed hypothesis,original one,needed form,sequence,target language,method,m-best list,treelet system,translation hypothesis,annotation,model need,system,alignment,parse tree,search space,anything,application,inflection model,phrase-based system,annotation,source,source,candidate transla tions,word-alignment model,train ing,dependency tree,target,algorithm,word alignment,translation,search,solution,situation,method,setting,integra tion,hypothesis,base mt system,second setting,translation,number,translation,arabic,method,method  2i,method,base mt system,sequence,target language,straightforward way,training parallel data,mt sys tem,stem sequence,log sum-exp,method,intermedi ate step,impact,alignment,translation stage,method,word alignment,target language sentence,alignment,target language,base mt system,sub-models,alignment,addition,word-aligned corpus,mt system,product,word alignment, ibm model,trans lation table,trained translation table, ibm model,target word,version,translation table,probability,method  3i,base mt system,se quences,target,baseline mt system,target sen tences,method,word alignment,addition,translation model,6 m performance result,result,method,evaluation measure,performance,4-gram  ble,single reference translation,oracle  ble,oracle knowledge,method,trans lation,base mt system,oracle  ble score, ble score,stemmed translation,stemmed reference,upper bound,inflected form,translation,input hypothe s,oracle,possible stem sequence,hypothesis list,addition,possible inflected form,parameter fitting,oracle,provided list,english-russian treelet system table,result,baseline,different method,treelet mt system,baseline,519 model  ble u or acle  ble uba,test set performance,result,treelet mt system,treelet system,section,method,result,good im provement,translation,baseline,oracle improvement,inflection,leu point,uncertainty,baseline system,input hypothesis,performance,different method,additional improvement,result,method,sparsity,translation modeling,oracle  ble,first hypothe si,achieved performance,model im,performance,method,performance,method,oracle performance,method,100-best list,target stem sequence,method,100-best list,inflected target word,disadvantage,method,100-best list,inflected translation,different sequence,distinction,inflection,oracle,method,100-best oracle,method,addition,hy pothesis list,method,hypothesis,word alignment stage,achieved result,performance, ble point,baseline,russian,property,english,word level,result,previous result,word alignment,result,base mt system,word alignment,transla tion model,sparse stem level,improvement,morphological property,russian word,feature-rich component model,large size,training data,mil lion sentence,method,problem,morphology-rich language,english-russian phrasal system,phrasal system,integration,method,translation,straightforward method,system,proof-of-concept experiment,model  ble u or acle  ble uba,test set performance,result,phrasal mt system,phrasal mt system,treelet system,phrase size,dis tortion limit,phrase size,distortion limit,system, ble score,treelet system,oracle  ble score,method,translation,improvement,phrasal system,improvement,transla tions,translation,improvement,large size,training data,direction,result,word alignment,mt system,alignment model,model  ble u or acle  ble uba,test set performance,result,treelet mt system,english-arabic treelet system,arabic system,system,method, ble score,baseline,method,result,method,oracle  ble score im,oracle improvement,1-best analysis,formance,method,absence,expertise,arabic,factor,performance,arabic,definition,stemming,effect,distinction,language,performance,arabic,latter situation,happen ing,grammatical property,definiteness,conjunction,pronominal clitics,arabic word,detrimental effect,mt system,stemmed input,investigation,hypothesis,human evaluation,section,result,human evaluation,output,inflection prediction system,correlation, ble score,human evaluation result,output,component,output,treelet system,com ponent,scenario,performing system,method,method,performing system,difference,output,change,word inflection,output,selection,scenario,human judge,native speak er,language,sentence,different translation,baseline system,reference translation,source sentence,sentence pair,cate gories,baseline system,output,quality,human evaluation result,result,averaged,evaluation sce nario, ble score improvement,human evaluation score,indi cating,translation,baseline system,russian,human evaluation score,method, ble score gain,differ ent,human evaluation,scenario,word inflection,toutanova,suzuki,7 c onclusion,future work,independent model,mor phology generation, smt system,improvement,phrasal,future,sophistication,lexicon,particular language pair,error analysis,pre-processing,operation,improvement,arabic,sig nificant,sentence,reference tim buckwalter,buckwalter arabic morphological analyzer version,ilknur durgar el-kahlout,kemal oflazer,ini tial exploration,english,statistical ma chine translation, naa cl workshop,statistical machine translation,jenny finkel,christopher manning,problem,ap proximate bayesian inference,linguistic annotation pipeline, emn lp,alexander fraser,daniel marcu,word alignment quality,statistical machine transla tion,computational linguistics,sharon goldwater,david  mcc losky,improv,statistical mt,morphological analysis,emn lp,nizar habash,fatiha sadat,arabic prepro cessing scheme,statistical machine translation,hlt -naa cl,xiaodong,word-dependent transition model,word alignment,statistical machine translation, acl workshop,statistical machine translation,philipp koehn,hieu hoang,transla tion model, emn lp-connl,philipp koehn,pharaoh,beam search decoder,phrase-based statistical machine translation model,young-suk lee,morphological analysis,statis tical machine translation, hlt -naa cl,einat minkov,kristina toutanova,hisami suzuki,complex morphology,machine translation,sonja nie,hermann ney,statistical ma chine translation,scarce resource,morpho syntactic information,computational linguistics,franz och,minimum error rate training,statis tical machine translation,chris quirk,arul menezes,colin cherry,dependency tree translation,phrasal  smt,kristina toutanova,hisami suzuki,case marker,machine translation, naa cl-hlt,vladimir vapnik,nature,statistical learn,theory,springer-verlag,wei wang,kevin knight,daniel marcu,machine translation, hlt -naa cl,proceeding,47th annual meeting, ijc nlp , afn lp,suntec,singapore,2-7 august, afn lp global model,joint lemmatization,part-of-speech prediction kristina toutanova microsoft research redmond,kristout microsoft,com colin cherry microsoft research redmond,colinc microsoft,com abstract,global joint model,lemmatization,part-of-speech predic tion,morphological lexicon,unlabeled data,part-of-speech tagger,lemmatizer,fea tures,dependency structure,english,bulgarian,slovene,substantial im provements,direct transduction approach,lemmatization,pipelined approach,part-of-speech tag,lemmatization,traditional problem,word form,possible morphological analysis,morpho logical analysis,morphological feature,basic form,feature combination,problem,setting,morphological dictionary,training,un-annotated text,language,new machine learn,addition,morphological analysis task,performance,subtasks,tag-set prediction,possible tag,lemmatization,sub task,application,result,example,sparsity,feature,text labeling task,lemmatization,information retrieval,machine translation,poor language,full analysis,subtasks,isolation,independent solution,subtask,pendencies,subtasks,performance,infor mation,joint model,subtasks,formation,reason,multi ple word,component tag-set,lemmatization model,combine,predic tions,joint feature,log linear model,pendency structure,section,section,result,english,bulgarian,slovene,joint modeling,lemmatization error,tag-prediction error,complete morphological analysis task,ask formalization,main task,lexicon,morphological analysis,morphological analysis,addition,lexicon,unannotated text,language,morphological analysis,word type,context,morphological analysis,several lemma,possible ba sic form,exam ple,morphological analy s,several word, cel ex,cal database,english,baayen,multext-east lexicon,bulgarian,erjavec,bulgarian word,word form morphological analysis tag lemma,person,izpravena adjective fem,izpravia  vmp s-sfp-n  izpravia izpraviha verb,izpravia  vmi a3p  izpravia table,example,morphological analysis,english,bulgarian,latin character,simple main pos-tags,grammatical fea tures,english,present tense third person singular verb,bulgarian,feminine singular adjective,indefinite form,main  pos tag,multext-east language,lemmatization,predicted element,precision,recall,performance,subtasks,tag-set prediction,lemmatization,correct tag-sets,example word,separate column,differs,lemma tization,complete rootlist,wicentowski,dreyer,unlabeled text,guarantee,coverage,target lemma,number,noise word,data statistic,ur setting,real application scenario,morphological analysis,machine learning,exception,daelemans,prediction,possible analysis,antal van den bosch,pre diction,seg mentation,arabic,setting,availability,word form,possible lemma,rootlist,word form,language,addition,training set,complete rootlist setting,word form,test set,approach,prediction,word type,isolation,machine learning work,lemmatization,inflective language,word form, a p o tag,califf,wicentowski,erjavec,dreyer,task setting,availability,gold-standard  pos tag,component model,lemmatiz,transducer,ap proaches,previous work,related string transduction area,transducer,detail,section,related line,dis ambiguation problem,correct analysis,word-forms,context,sentence,possible anal y,cor rect  pos tag,high accuracy,sentence,er javec,habash,rambow,unlabeled data,morphological analyzer,semi-supervised hmm model,disambiguation,context,analysis,unknown word,guesser,likely  pos tag,possible analysis,complex string transduction problem,lemma tization,segmentation,focus language,hebrew,related task,performance,success ful,joint inference,pipeline approach,problem,4 c omponent model,component model,partially-supervised pos tagger,transducer,input  pos tag,training,testing,lemma tization,tagger,section,transducer,section,pipeline approach,tagging,lemmatization component,tagger,lemmatizer,possible tag,direct transduction,proach,lemmatization subtask,lemmatizer,access,single lemma,joint model,section,re-ranking framework,k-best prediction,tag-sets,component tagger,lemma tizer model,morphological analyser,discriminative character transducer,component morphological analyzer,transducer,inflected word,source,part-of-speech,ji ampojamarn et al,letter-to-phoneme conversion,whole-word feature,output,engine,dynamic programming algo rithm,monotone phrasal,main feature,algorithm,capability,many consecutive char acters,single operation,algorithm,subsequence,semi-markov crf,sarawagi,main category,feature,context,transition,rootlist,fea tures,detail,ji ampojamarn et al,context feature,transduction operation,context,indicator,operation,indicator,n-grams,source context,fixed window,operation,copy feature,operation,source character,tran sition feature,markov,n-gram feature,transduction operation,vocabulary feature,complete target word,frequency,provided unla,frequency,experiment,development set,indicator,first fire,vocabulary,trie index,target context,dynamic programming chart,frequency,transduc tion,source part-of-speech tag,feature,context fea ture e,able communication,various parts-of speech,universal set,unannotated feature,part-of-speech,back-off model,general behave,linear weight,trans ducer,averaged perceptron,structure prediction,collins,feature,operation,transduction,ate gold-standard feature vector,output,derivation,output,deterministic heuristic,derivation,gold standard source-target pair,deriva tion,trivial copy operation,first character mismatch,remainder,transduction,single multi character replacement,example,deriva tion,living,language,morpholo gy,suffix,complex heuristic,derivation,separate aligner,ristad,yianilos,tag-set prediction model,tag-set model,training lexicon,unlabeled text,predict set,semi-supervised tag,toutanova,johnson,sub-models,ambiguity class,tag-set model,probabili tie,possible set,word  pts,word context model,probability  pcm,contextsw,context,occurrence,unlabeled text,word-context model,sparse dirichlet,distribution,addition,informa tion,word context,occurrence,unlabeled text,toutanova,johnson,tagger,occurrence,dict set,possible tag,word type,com ponent sub-model  pts,context model,account information,context,occurrence,compute probability,tag-sets,observed occurrence,prediction,tag-set,test word,unlabeled text,contextsw,direct re-implementation,word context model,variational inference follow ing,toutanova,johnson,tag set sub-model,sophisticated approach,log-linear classifier, a n aive bayes model,feature,related word,possible class,classifier,observed tag-sets,sparsity,feature,individ ual tag,tag-sets,feature,word suffix,capital ization,existence,hyphen,word prefix,feature,toutanova,johnson,latter feature,cucerzan,yarowsky,telling,indicator feature,combination,suf fix,prefix,exists,example,feature,suffix,suffix,character, dv bd    v bn jj   vb   vb  rj jr nn bounce bouncer bounce,bounc bouncer boucer fbounce bounce,small subset,graphical model,tag-sets,illustrated assignment,extent,joint feature,lemma bounce,factor,blue cir cle,assignment,global joint model,morphological analysis,possible tag,addi tion,dependency,single word,de pendencies,prediction,multiple word,dependency,tag-sets,example,imagine,tag-set,word bouncer,comparative form,suffix,occurrence,dicate,lemmatizer,bounce,tag-set model,bounce,joint model,bouncer,bounce,problem,assign ments,tagging,lemmatization error,bouncer,main source,information,joint model,information,assignment,tag-set model,information,lemmatized cor,others,test word,dependency,signments,example,figure,sample english word,possible tag-sets,lem ma,component model,dependency,variable,feature,incorrect,assignment,formal model description given,test word,additional word form,unlabeled data,extended set,original test word,additional re,useful information,test word,example,bouncer,test word,bounce,test word,classification,bouncer,algorithm,related word,top lemma,test set,joint model,tag-sets,lem ma,extended set,fea tures,structure,assigned analysis,re ranking model,tag-sets,possible lemma,top option,large set,variable,large set,example,test set,slovene,extended set,corresponding,tag-set,lemma assignment,possible assignment,combination,tag ging,lemmatizer component model,tag-sets,average,possible assignment,tag set,average,variable,feature,connectivity structure,com plex,possible tag-sets,tag-sets,training,top lemma,word wi,assignment,word wi,choice,tag-set,possible tag-sets,chosen tag-set,choice,possible lemma,brevity,joint assignment,concrete example,figure,current assignment,assigned tag-sets,bolded box,cho sen,lemma bounce,ther possible tag-sets,possible lemma,chosen tag,greyed box,joint model,distribution,signments,vector,feature,assignment,vector,parameter,feature,feature,word-local feature,feature,capture coarse-grained dependency,feature,joint dependency,lem ma,signment,single word,feature,number,distinct lemma,dif ferent tag,assigned tag-set,feature,identity,tag-set,example,tag-set,number,distinct lemma,feature,log-probabilities,tag-set,lemmatizer model,non-local feature,non-local feature,derive several predicate,joint assignment,example,word graph,figure,lemma bounce,tag  vbd,tag vb,tag  jjr,feature,combination,differ,ent form,feature,vb tag,neg ative weight,feature,tag  jjr,variant,feature,final character,variant,slavic lan guages,main  pos tag,granularity,feature,feature,number,distinct word,different word,ad ditional feature fire,distinct lemma,effect,number,assigned lemma,training,inference,re-rank candidate,component model,component model,joint model feature,accuracy,component model,joint model,com ponent model,training lexicon ltrain,hyperparameters,ldev lexicon,joint model,ldev lexicon,ltest lexicon,ltest set,component mod el,ltrain,amount,training data,unfair advantage,joint model,set-up,re-ranking model,collins,joint model,log-likelihood,correct assignment,assign ments,related word,graph ical model,gradient approx,expectation,feature,observed assignment,marginal ex pectations,feature,ex pectations,gibbs sampling,com plete assignment,gibbs sampler,assignment,pipeline method,annealing schedule,neighborhood,high-likelihood assignment,complete sample,expectation,gradient descent,small learning rate,accuracy,ldev set,likely assignment,test time,sampling procedure,schedule,single sample,output,guessed answer,gibbs sampler,assignment,current assignment,current assignment,conditional probability,assignment tli,word wi,summation,denominator,possible assignment,quantity,current word,nature,feature,component,share feature,assignment,possi ble assignment,separate compo nents,component,component,common case,component ap proximate inference,6 e xperiments,datasets,language,english,bul garian,slovene,lan guages,lexicon,morphological analysis,unlabeled text,english,lexicon, cel ex,baayen,multext-east resource,er javec,english,open-class word,adjective,language,unlabeled data,english,penn treebank, wsj data,marcus,language,george,morpho,disambiguated form,multext east,annotation, bll ip corpus, wsj data,cor pora,plain text,annotation,lang ltrain ldev ltest text w tl nf w tl nf w tl nf eng,data set,experiment,number,thousand,average number,cent target,detail statistic,data set size,differ ent language,different lexicon,lan guage,global model weight,develop ment,described,section,lex icon,frequent word,training lexicon,frequent word,test lexicon,natural process,lexicon construction,english lexicon,full  cel ex dictionary,penn treebank corpus,sentence, cel ex,training lexi con,corpus,velopment,test lexicon,second word,test set,first oc currence,procedure,full multext-east lexicon,lexicon,different form,different lexicon,training lexicon,realistic scenario,application,number,lexicon,unlabeled corpus,average number,tag-lemma com binations,percentage,word lemma,unlabeled text,english,large majority,target lem ma,multext-east language,target lemma,performance,language,main tag,multext-east language,detailed tag,english,unlab data,bulgarian none,unlab data,development,result,different tag-set model,prediction,evaluation,pipelined model,lemmatization,first experiment,joint modeling approach,comparison,lemmatization performance,setting,training,testing,transducer,correct tag,training,tagging model,section,formance,english,bulgarian,compa rable performance,multext-east lan guages,section,result,experi ments,ltrain,training,f-measure,lemma-set f-measure,performance,lemmatization,tag model,tag-set model,language lemmatization,latent tag-set variable,prediction,relative error reduction,lem f-measure,english,bulgarian,slavic,main  pos tag,lemmatization perfor mance,contribution,unlabeled data,performance,tag-set model,word-context sub-model,tagger,word feature,result,setting,english,bulgarian,tag-set f-measure,lemmatization f-measure,large por tion,positive impact tagging,lemma tization,ability,unlabeled data,result,experiment show,strong dependency,tagging,lemmatization subtasks,joint model,evaluation,joint model,joint model re-ranks candidate,component tagger,lemmatizer,upper bound,achievable perfor mance,upper bound,language,m-best oracle,oracle,five-best tag-set prediction,three-best lemma prediction,oracle,formance,tag f-measure,language,performance,lemmatization,complete task,percent,slavic language,second oracle,perfect tag oracle,transducer,correct part-of-speech tag,tagging model perfect,lemmatizer,slavic,m-best oracle,majority,pipelined approach,global model,potential,lemma assignment,correct tag,information,multiple word,performance,dif ferent model,comparison,lemmatization performance,direct trans duction approach,pipelined model,tag-set prediction,1-best lemma,mod el,section,model name lo cal f,joint log-linear model,word-internal feature,word-internal feature,performance,language,improvement,slovene,relative re duction,f-measure error,complete task,feature,joint assignment,multiple word,improvement,language,overall improvement,pipelined approach,slovene,reduc tion,full task,reduction,optimization,result,standard deviation,english m-best oracle,english,bulgarian tag oracle,bulgarian m-best oracle,bulgarian joint f,slovene tag oracle,slovene m-best oracle,slovene,czech tag oracle,czech m-best oracle,result,pipelined model,oracle,number,tag-set prediction f-measure,lemma-set prediction f-measure,f-measure,complete tag,lemma analysis set,upper bound,m-best oracle,overall improvement,english,error reduction,slavic language,single lemma,joint reasoning,information,7 c onclusion,mor phological analysis,lexicon,tag pre diction,lemmatization,state-of-the art model,subtasks,joint inference,performance,main contribution,joint model,subtasks,corporates dependency,prediction,multiple word type,fea tures,approximate inference procedure,global log-linear model,dependen cies,effectiveness,english,slavic language,acknowledgement,galen andrew,lucy vander wende,useful discussion,reference meni adler,yoav goldberg,michael elhadad,lexicon-based resolution,unknown word,full morpholological analysis,proceeding,galen andrew,trond grenager,christopher manning,verb sense,subcategorization,using joint,ference,performance,complementary task, emn lp,erwin marsi antal van den bosch,abdelhadi soudi,memory-based morphological analysis,part of-speech tagging,arabic,abdelhadi soudi,tal van den bosch,gunter neumann,editor,arabic computational morphology,em pirical method,gulikers,cel ex lexical database,antal van den bosch,walter daelemans,memory-based morphological analysis,proceeding,annual meeting,association,compu tational linguistics,alexander clark,memory-based learning,mor phology,stochastic transducer,proceeding,40th annual meeting,association,joint morpholog,syntactic disambiguation, emn lp,michael collins,discriminative reranking,natural language parsing,discriminative training method,hid den markov model,theory,experiment,percep tron algorithm,yarowsky,supervised induction,lexical probability,proceeding,markus dreyer,jason eisner,latent-variable modeling,transduction,finite-state method,proceeding,conference,empirical method,honolulu,october,erjavec,eroski,machine,morphosyntactic structure,unknown slovene word,applied artificial intelligence,erjavec,multext-east version,multilingual morphosyntactic specification,lexicon,corpus,proceeding, lre c-04,jenny rose finkel,christopher,manning,andrew,problem,approximate bayesian inference,linguistic annotation pipeline, emn lp,nizar habash,owen rambow,arabic tokeniza tion,part-of-speech tagging,morphological disam biguation,proceeding,annual meeting,association,computational lin guistics,sittichai jiampojamarn,colin cherry,grzegorz kon drak,joint processing,discriminative training,letter-to-phoneme conversion,proceeding,columbus,marcinkiewicz,large annotated coprus,penn treebank,computational linguistics,raymond,mooney,mary elaine califf,induc tion,first-order decision list,result,past tense,english verb,journal,artificial intelli gence research,yianilos,pattern analy si,machine intelligence,sunita sarawagi,william cohen,semimarkov conditional random field,information extraction,kristina toutanova,mark johnson,bayesian lda,semi-supervised part-of-speech tag ging,richard wicentowski,learning mul tilingual inflectional morphology,framework,thesis,improvement,phrase-based statistical machine translation, hlt -naa cl,boston,proceeding,conference,empirical method,sydney,association,computational linguistics competitive generative model,structure,com abstract,generative model,discriminative model,structure,dis crimination,bayesian network,conditional log linear model, nlp task,structure,gen erative model encodes,strong inde pendence assumption,la naive bayes,discriminative model,generative model,independence assumption,complex structure,perfor mance,corresponding discrimina tive model,addition,structure,generative model,ef ficient,1 i ntroduction discriminative model,choice, nlp task,ability,non-independent feature,classification accuracy,art model,many  nlp task,discrim inative reranking,collins,part-of-speech tagging,toutanova,semantic-role labeling,punyakanok,pradhan,penn tree bank parsing,charniak,johnson,superiority,discriminative model,many task,discrimina tive,generative model,model structure,manning,advantage,discriminative mod el,johnson,small training,size generative model,training sam ples,optimal parameter setting,jordan,criminative model,generative model,base model,discriminative feature,reranking,collins,charniak,johnson,small set,weight,feature,probability,generative model,component,discriminative model,generative model,strong independence assumption,joint distribution,feature,problem,generative model,nlp task,appropriate representation,joint distribution,parsing model,collins,charniak,generative model,good model structure,compar,discriminative model,question,input feature,generative model,optimal structure,joint distribution,discriminative model,op timal structure,dependence assumption,generative,criminative model,rep resentation,learning,genus tive model,directed graphical mod el,bayesian network,optimal parameter,closed form,structure,discriminative counterpart,conditional log linear model,structure learning,condi tional log-linear model,con ditional random field,lafferty,ex cept,structure,structure,feature,nlp classification task,prepositional phrase,tachment,semantic role labelling,re sults,generative model,discriminative mod el,small set,interpolation parame ters,conditional probability table,hybrid generative discriminative model,discriminative model,section,detail,discriminative model,structure search methodology,section,result,empirical study,odel class,methodology,classification task,training set,stance,input feature,i-th instance,classifier,la bel,new example,classifier,generative model,joint probability,depen dent,parameter vector,generative model,likely label,joint distribution,pa rameters,fitted distribution,maximum joint likelihood esti mate,generative model,bayesian network,parameter,maximizer,joint likelihood,closed form relative frequency estimate, a b ayesian net work,variable,parent,structure,bayesian network,following set,figure,naive bayes bayesian network dence assumption,variable,non-descendants,par ents,example,structure,bayesian network model,figure,indepen dence assumption,input feature,class label,vector,nominal feature,bayesian network,input variable,network,class variable,input feature,generative model,class-specific distribution,simple bayesian network,well-known naive bayes model,specific joint distribution,distribution,parent, a b ayesian network model,graph structure,conditional probability,joint likelihood,optimal pa rameters,relative frequency estimate,vector,parent,probability estimate,simple form,smooth ing,irichlet, nlp task,method,example,goodman,rate lower-order information,subset,conditioning information,structural form,conditional proba bility table,sophisti cated type,witten-bell,witten,smooth ing,generative parser,collins,good performance,language modeling,goodman,conditional proba bility table,notation,variable,parent,witten-bell smoothing,relative fre quency estimator,recursion,uniform distribution,vocabulary,prediction vari able,interpolation back-off order,number,following rule,number,training set,variable,number,class variable,witten-bell smoothing,terpolation coefficient,relative frequency estimate,con text increase,context,training data,decrease,con text,different value,variable,conditional proba bility table,major parame ters,training data,addition,interpolation parameter,interpolation weight,parameter,hyper-parameters,development set,sam ples,single parameter,multiple parameter,context,many parameter,back-off lev el,restriction,bayesian net work,correspondence,discriminative model,tractability,input variable node,label node,parent,parent,variable,structure search method differs,method,literature,heckerman,pernkopf,bilmes, a b ayesian network, cho sen ,vari ables,network, rem aining,unplaced variable,class variable, cho sen ,vari ables, rem aining,cur rent,next candidate structure,unplaced variable, rem aining,subset sub,variable,parent sub,number,candidate structure,current bn,number,variable,greedy search,variable,evaluation criterion,rem aining,search,variable, rem aining,evaluation criterion,evaluation criterion,clas sification accuracy,development set,sam ples,structure search method,terminology,grossman,domingo,pernkopf,bilmes,candidate bn,main parameter,relative frequency estimator,training set,previous section,hyper-parameters,structure search,parameter,final bn structure,struc ture search,fixed value,back-off,generative parameter estimation,discrimi native structure search,section,discus sion,method,previous work,notice,optimal parameter,con ditional probability table,variable,current bn,new variable,ef ficient,stopping criterion,hyper-parameters,development set,previ ous subsection,multiple hyper-parameters,fitting criterion,generative bayesian network,joint likelihood,development set,sample, a g aussian prior,hyper parameter,bayesian network,conditional likelihood,develop ment set,sample,resulting model hybrid bayesian network mod el,number,trained parameter,hybrid model,discriminative model discriminative model,discriminant function,conditional log-linear model,sim ple example,logistic regression,conditional likelihood,describe,notation,nominal variable,vector,following standard way,nominal variable,vector space,dimensionality,possible val ues,variable,single dimension,vector space,vector,corresponding dimension,mapping,logistic regression,probability,input feature,parameter,prob lem,unconstrained optimization,parameter,constraint,weight,representational power,parameter vector,feature weight,parameter,log-linear model,conditional likelihood,training,gaussian prior,parameter,variance,variance,hyper-parameter,development set,addition,simple logistic regression model,generative model,structure,complex mapping,conjunction,combination,input variable,number,variable,com binations,number,parent,bayesian network structure,polynomial kernel,example,bigram conjunction,variable,structure search,feature selec tion,log-linear model, mcc allum,structure search methodology,structure search,bayesian network,ex act hypothesis space,search procedure,optimal structure,initial empty feature,candidate feature,consisting,course,search,set  can didates ,feature conjunction,addition,ini tial input feature,feature,candidate,fea ture, can didates ,con junction,feature,input feature,example,fea ture conjunction,expansion,conjunction,greedy search,feature,evaluation criterion,can didates ,evaluation criterion,feature,curacy,development set,sample,bayesian network structure search,candidate fea tures,iterative re-estimation,addition,weight,new feature,old parameter,optimal value,search,hyper-parameter,development,accuracy af ter,feature,lection algorithm,input variable,vari able conjunction,possible value,single step,search,hundred,thousand,binary feature,della pietra,form complete re-estimation,parameter,3 e xperiments,classification problem,attachment,semantic role,literature,collins,vanschoen winkel,manderick,common configuration,guities, v n p pp,verb phrase,following noun phrase,prepo sitional phrase,ob ject noun phrase,example,sentence,painting np,peg pp,prepositional phrase,verb hang,object noun phrase,painting,verb hang,common practice,problem,head word,constituent,example sentence,following quadruple,pp attachment task,binary label att,input variable,standard dataset,researcher,ratna task training devset test pp,data size,pp attachment, srl task,collins,penn treebank wall street journal data,ratnaparkhi,show summary statistic,dataset,second task,semantic role labeling,context,propbank,palmer,propbank corpus,phrase,semantic role,penn treebank parse tree,annotated role,patient,direction,semantic role,core argument label,argument la bel,tradi tional distinction,argument,adjunct,plenty,machine learning model,semantic role labeling,gildea,jurafsky, con ll,carreras,successful formulation,syn tactic parse tree,possible label,corresponding phrase,se mantic role,la bel,subproblem,clas sification,core argument node,core argument label,correct label,researcher,subproblem,gildea,jurafsky,toutanova,pradhan,palmer,feature,build ing model,semantic role labeling,initially,feature,gildea,juraf sky,following research,feature,additional one,feature,feature,state-of-the-art model,subprob lem,classification,core argument addition,feature,individual node,palmer,pradhan,global feature,parse tree,feature,standard training,development,feature type,gildea,jurafsky,syntactic category,node pre dicate  lem ma,verb pat,passive relative,predicate,parent,feature,semantic role labeling,test set,february,version,prop bank,training set,section,development set,test set,section,number,sample,training,pp attachment training,result,previous work,jordan,manning,naive bayes,logistic regression, nlp task,generative model,strong independence assumption,structure,discriminative model,structure,naive bayes logistic re gression result,pp attachment,re sults,several condition,naive bayes classifier,hybrid model,multiple hyper-parameters,result,gen erative naive bayes,parameter,joint likelihood,velopment,hybrid naive bayes,hyper-parameters,conditional likelihood,column  h-p aram,hyper-parameters,multiple parameter,logistic regression,naive bayes,single hyper parameter,single hyper parameter,development set,generative model,multiple weight,likelihood,development set,respect,parameter,logistic regression,different variance,differ ent type,feature,search,pro model h-params test,naive bayes,naive bayes,logistic regression,hybrid naive bayes,hybrid naive bayes,naive bayes,logistic regression pp attachment result,multiple interpolation weight,gener ative model,result,logistic regression outperforms,naive bayes,hybrid naive bayes,performance,hybrid naive bayes,multiple interpolation weight,accuracy,performance,logis tic regression,dependence assumption,classifier,logistic regression,naive bayes model,hybrid naive bayes,single interpolation,hybrid naive bayes,multiple interpolation parameter,generative,dis criminative model,optimal structure,generative model,discriminative model,bayesian network,single interpolation weight,accuracy,discriminative model performs,single interpolation weight,accuracy,comparison,accuracy,test set,result,discriminative model,feature,polynomial kernel,multiple hyper-parameters,vanschoenwinkel,manderick,hybrid bayes net,log-linear model,bayes net,log-linear model,semantic role,classification,core argument,result,difference,performance,naive bayes,performance,lo gistic regression,independence assumption,model h-params test set acc bayes net,bayes net,log-linear model,hybrid bayes net,hybrid bayes net,bayesian network,conditional log linear model pp attachment result,model h-params test set acc naive bayes,naive bayes,logistic regression,hybrid naive bayes,hybrid naive bayes,naive bayes,logistic regression  srl classificaion result,feature,sparse lexical feature,naive bayes model,ad vantage,discriminative logistic regression model,hybrid naive bayes model,mul tiple interpolation weight,naive bayes,classifier,sig nificant,pp attach ment task,benefit,multiple hyper-parameters,di versity,feature,sparse lexical feature,non-sparse syntac tic one,feature,pp attachment,pare general bayesian network,eral log-linear model,performance gap,generative,discriminative model,bayesian network,single interpolation weight,accuracy,log-linear model,accuracy,hybrid model,multiple interpolation weight performs,statistical tie,log-linear model,bayes net model,generative model,structure,independence assumption,naive bayes model,performance,discriminative model,figure,bayesian net work,pp attachment,semantic role labeling,conjunction model h-params test,bayes net,bayes net,log-linear model,hybrid bayes net,hybrid bayes net,bayesian network,log-linear model,log-linear model,structure search,generative bayesian net work model,structure search,log-linear model,implementation,computation reuse,succes sive step,structure search,bayesian net work,log-linear model,structure search,bayesian network,log-linear model,result,context,previous work,result,core argument,input feature,degree,poly nomial kernel,pradhan,result,independent classifica tion,core argument,log-linear model,additional basic feature,toutanova,accuracy compare, svm model,polynomial ker nel,importance,structure learning,omparison,related work previous work,dis criminative model,structure,naive bayes,logistic regression model,jordan,man ning,manning,johnson,result,version,propbank,pp attachment,role sub,figure,bayesian network structure,pp attachment,bayesian network,special structure,decision tree,goldszmidt, nlp task,comparison,criminative model,discriminative model,structure,bilmes,grossman,domingo,non-nlp domain,several important algorithmic difference,pernkopf,bilmes,grossman,domingo,difference,empirical evalua tion,impact,difference,generative model,genus tive model,previous work,special form,conditional prob ability table,pernkopf,bilmes,simple smoothing method,probability,relative frequency estimate,account information,distribution,hyper-parameters,grossman,domingo,special form,generative model,discriminative model,pernkopf,bilmes,grossman,domingo,study bayesian network,parameter,conditional likelihood,represen tatives,discriminative model,general log-linear model,markov random field,parameter,probability,structure,bayes net structure,discriminative classifier,compo nent parameter,probability,restriction,generative model,major differ ence,smoothing algorithm,gaussian prior hyper parameter,feature,subset,clique,pernkopf,bilmes,zero-valued param eters,domin go,early stopping,held-out data,similar effect,gaussian prior,importance,difference,algorithm,importance,hyper-parameters,modified version,structure search,modification,bayes net structure learning,witten-bell smooth ing,backoffs,lower-order distribution,inter polation,uniform distribution,fixed weight,discriminative log-linear model structure learning,gaussian prior,weight,conjunction selection,ayes net structure,feature,sub set,feature conjunction,differ ence,modified discrimina tive log-linear model,pernkopf,bilmes,grossman,domingo,parameter,probability,result,re sults,modified algorithm,generative,discriminative learner,performance,log-linear model,pp attachment performs,gistic regression,smoothing,pp attachment result model h-params test,bayes net,log-linear model,srl classification result model h-params test,bayes net,log-linear model,bayesian network,minimal smoothing,backoff,order distribution,result,structure,generative model,discriminative model,importance,sophisti,technique,structure search al gorithms,natural language classification task,reference,carreras,introduction, con ll-2005,semantic role labeling,proceeding, con ll,eugene charniak,mark johnson,coarse-to-fine n-best parsing,maxent discriminative reranking,proceeding,eugene charniak,maximum-entropy-inspired parser,proceeding, naa cl,michael collins,james brook,prepositional,tachment,backed-off model,proceeding,third workshop,large corpus,michael collins,lexicalised model,statistical parsing,proceeding,discriminative reranking,natural language parsing,proceeding,stephen della pietra,vincent,della pietra,lafferty,feature,random field,ee transaction,pattern analysis,machine intelli gence,nir friedman,moises goldszmidt,bayesian network,local structure,daniel gildea,daniel jurafsky,automatic labeling,semantic role,computational linguistics,joshua,goodman,progress,language modeling, msr technical report,tr-2001-72,daniel grossman,pedro domingo,bayesian network classifier,conditional likelihood,proceeding,david heckerman,bayesian network,donald hindle,mat rooth,structural ambi guity,lexical relation,computational linguistics,mark johnson,conditional estimation,proceeding,dan klein,christopher manning,conditional structure,conditional estimation, nlp model,proceeding, emn lp,john lafferty,andrew  mcc allum,fernando pereira,conditional random field,probabilistic model,sequence data,ternational conf,machine learning,morgan kaufmann,andrew  mcc allum,feature,conditional random field,proceeding,andrew ng,michael jordan,comparison,logistic regression,naive bayes,hermann ney,discriminative training,maximum entropy model,statistical ma chine translation,proceeding,martha palmer,dan gildea,paul kingsbury,proposition bank,annotated corpus,semantic role,computational linguistics,judea pearl,probabilistic reasoning,intelligent system,network,plausible inference,morgan kauf mann,franz pernkopf,jeff bilmes,discriminative versus generative parameter,structure learning,bayesian network classifier,proceeding,sameer pradhan,kadri hacioglu,valerie krugler,wayne ward,james martin,dan jurafsky,support vector,semantic argument classification,ma chine learning journal,sameer pradhan,wayne ward,kadri hacioglu,james mar tin,daniel jurafsky,semantic role,different syntactic view,proceeding,vasin punyakanok,dan roth,wen tau yih,necessity,syntactic parsing,semantic role labeling,proceeding, ijc ai,rajat raina,yirong shen,andrew,andrew mcc allum,classification,hybrid genus tive discriminative model,sebastian thrun,lawrence saul,bernhard scho,editor,advance,adwait ratnaparkhi,jeff reynar,salim roukos,maximum entropy model,prepositional phrase attach ment,workshop,human language technology,brian roark,murat saraclar,michael collins,mark johnson,discriminative language,conditional random field,perceptron algorithm,proceeding,kristina toutanova,dan klein,christopher,manning,feature-rich part-of-speech tagging,cyclic dependency network,proceeding, hlt -naa cl,kristina toutanova,aria haghighi,christopher,improves semantic role label,proceeding,bram vanschoenwinkel,bernard manderick,weighted polynomial information gain kernel,resolv,prepositional phrase attachment ambiguity,sup port vector machine, ijc ai,witten,timothy,zero-frequency problem,probability,novel event,infor mation theory,nianwen xue,martha palmer,feature,semantic role labeling,proceeding, emn lp,proceeding,workshop,statistical machine translation,new york city,association,europarl evaluation arul menezes,kristina toutanova,kristout,chrisq microsoft,microsoft research translation system,phrasal   sm system,phrase translation model,dependency treelet,global reordering model,source dependency tree,hese model,several knowledge source,log-linear manner,individual component,log linear model,automatic parameter,brief overview,component,system,experience,europarl data,english,dependency treelet translation system,statistical mt system,advantage,linguistic tool,source language dependency,word alignment component,translation system,source side,dependency tree,corpus,source dependency,target sentence,aligned dependency corpus,treelet translation pair,order model,bi-lexical dependency model,input sentence,decoder,combination,ordering,treelet translation pair,source tree,now-common generalization,classic noisy-channel framework,log linear combination,translation,approach,translation scoring,practice,translation system,information,variety,non-probabilistic source,brief word,notation,represent source,lexical node,source,target tree,represent source,target treelet,subgraphs,dependency tree,expression,refers,lexical item,target language tree,refers,lexical item,subscript,th lexical item,in-order traversal,training,source language dependency tree,word alignment,regimen,parameter,held-out data,word alignment,dependency tree projection heuristic,target dependency tree,source treelet,maximum size,target treelet,tree-based decoder,dynamic programming,approximation,n-best translation,subtree,treelet translation pair,training corpus,process,detail,channel model,several channel model,direct maximum likelihood estimate,probability,target,source,estimate,source,target,source,word-based  ibm model,absolute discounting,probability,instance,training corpus,probability,possible alignment,treelet,length,calculation,source,target,source,bilingual n-gram channel model traditional phrasal   sm system,number,theoretical problem,ad hoc estimation,phrasal probability,failure,partition probability,tenuous connection,phrase,string-based   sm system,problem,key role,phrase,absence,good global ordering model,inexorable push towards,phrase,serious practical problem,detail,approach,problem,briefly,basic unit,source,target word pair,word alignment link,distinct  mtu,minimal non-compositional phrase,n-grams,source string,target string,combination,global ordering model,phrase,quality,quality,phrase size constant,example,aligned sentence pair,figure,cumplir m4,probability,context,previous  mtu,previous  mtu,target order,ancestor  mtu,traversal order,separate feature function,log linear combination,source,target traversal order,trigram model,bigram model,tree order,target language model,surface level trigram language model,bilexical dependency mode,english treebank parser,parent,ptrisurf,trigram language model,target side,training corpus,pbilex,kneser-ney,agenda,programa,dependency tree pair,head relative position,bigram language model,target language dependency,parallel dependency tree corpus,order model,probability,position,target,information,source,target tree,position,closeness,dependency tree,pre modifier,position,post-modifier,example dependency,head-relative position,small set,feature,local information,dependency tree,parent,parent,dependency tree,exical item,source node,source node,modifier,ead-relative position,source node,target feature,word-aligned parallel dependency tree corpus,previous version,system,current version,log-linear model,addition,different way,information,multiple feature,log-linear model,similarity,different class,position,method,automatic selection,feature,feature conjunction,log-linear model,method,feature conjunction template,accuracy,development,part-of-speech label,source node,modifier,head-relative position,source node,modifier,important feature,part-of-speech,source head,feature,effectively achieves,separate movement model,source head category,lexical information,dependent,source,target,similarity,different target class,pooling,similar class,multiple feature,target position,feature,example,position,like position,like position,feature,positive negative position,feature,displacement,position,target,corresponding position,source,feature,target position,hese feature,target position,feature,section,source sentence,target dependency,target tree,training instance,order model,log-linear order model,single feature,overall log linear combination,parameter,order model,decision tree-based model,decision tree model,log-linear model,position,modifier,reference parallel sentence,full mt system,decision tree,decision accuracy,log-linear model,decision accuracy,context,full   mt system,new order model,modest improvement,ble score,pseudo-models,help balance certain bias inherent,feature,treelet,translation,number,treelet,treelet,context,target sentence,feature,per-decision accuracy number,random,training,test data,target language model,english,supplied bilingual data,target side,bilingual corpus,target language model,target language order,noticeable impact,translation quality,target language corpus,impact,add bilingual  mtu model,replace dt order model,log-linear model,result,development,addition,bilingual n-gram,substantial impact,translation quality,ble score,anecdotal evidence,human-evaluated quality, ble score difference,corpus,great diversity,translation,source language word,phrase,human judgment,human evaluation,final test result,system,middle,ten system, ble score,n-gram channel model,robustness, ble score,out-of-domain data,average  ble score,system,maximum entropy model,assistance,natural language processing,marcel dekker,method,automatic evaluation,mathematics,three generative,asm orgasbord,feature, int erspeech,jeju island,sapporo,phrase,conventional wisdom,statistical machine translation,lingo redwood treebank motivation,preliminary application stephan oepen,kristina toutanova,stuart shieber,christopher manning,dan flickinger,thorsten brant,kristina,dan csli,stanford,harvard,lingo redwood initiative,seed activity,development,new type,treebank,sev eral mediumto large-scale treebanks,english,major language,available re source,following limitation,phrase structure,dependency,information,linguistic information,design,format,linguistic representation,tree bank hard-wires,predefined range,information,treebank,resentations,treebanks,evolution,large-scale treebank tend,development,lingo redwood,development,novel treebanking methodology,nature,way linguistic data,treebank,granularity,constant evolution,regular updating,treebank,october,project,foun dations,new type,treebank,basic set,treebank construction,maintenance,struct,initial set,open-source license,1 w hy,past decade,method,machine learning ap proaches,incompat ible,paradigm,probabilistic processing technique,use ful result,many class,application,full range,precise interpretation,variety,linguistic expression,amount,training data,deep approach,grammatical coverage,sufficient processing efficiency,precise linguistic grammar,certain type,real-world application,application,broad-coverage analyti cal grammar,generation,sophisticated statistical technique,ambigu ities,transfer,system,industry,example,general parse ranking,disambigua tion,robust recovery technique,general consensus,necessity,activity,stochastic approach,promising research,stochastic par,number,framework,dynamic language corpus,likewise,stochastic parsing,information-extraction-type application,semantic interpretation,redwood initia tive,next section,motivation,lingo redwood project,treebank,ment process,construction,treebank,early stage,section,prelim inary result,treebank data,concrete application,instance,statistical model,parse ranking,redwood corpus,accuracy,dynamic treebank,redwood treebank,open-source  hps resource,broad consortium,re search group,researcher,stanford,edinburgh,wide distribution,common acceptance, hps framework,resource,excellent anchor point,redwood treebanking initiative,key innovative aspect,redwood ap proach,treebanking,anchoring,linguis tic data,treebank, hps frame work,generally-available broad-coverage gram mar,english,lingo english resource grammar,flickinger, lkb gram mar development environment,copestake,treebanks,grammatical representation specific,tree bank,treebank record complete syntacto semantic analysis,lingo  erg,pro vide tool,different type,linguistic informa tion,granularity,treebanking environment,building,incr tsdb,environment,annotator,sentence,full set,analysis,grammar,pre-existing tree comparison tool, sri cambridge treebanker,carter,annotator,correct,preferred analysis,rare case,analysis,selection tool,little expert knowledge,underly ing grammar,basic property,analysis,disambiguating decision,annotator,incr tsdb,database,dynamic extraction,profile,re cent profile,version,grammar,corpus,important innovative research aspect,approach,treebank,information,available representation,ability,treebank,enhanced version,grammar,automated fashion,disambiguating decision,corpus,updated version,grammar,representation,transformation,formation internally,incr tsdb,database record analysis,different format,deriva tion tree,identifier,lexical item,con structions,analysis,traditional phrase structure tree,inventory,fifty atomic label,underspecified  mrs,copestake,lascarides,representation,many case,rep resentation,penn treebank,representation,functor,argument,structure,prague dependency tree bank,german  tig er corpus,information,full  hps analysis,orig inal grammar,open-source  hps process,latter ap proach,treebank,infor mation,representation,full analysis,exist ing mapping,inventory,node label,phrase structure tree,likewise,incr tsdb,facility,compe tence,performance profile,ate result,parse disambiguation system,preference,treebank,target,comparison,automating treebank construction,pre cise  hps grammar,lingo  erg,small number,analysis,sentence,dozen read ings,error-prone,project,approach,disambigua tion task,lexical selection,tagger,inter-annotator comparison,assisted resolution,conflict,treebank maintenance,evolution one,research aspect,redwood initiative,methodology,treebank,continuous evolution,underlying linguistic framework,lingo grammar,building,notion,elementary linguistic discriminator,semi automatic propagation,deci sion,version,parsed corpus,basic phrase structure inven tory,granularity,lexical distinction,certain degree,discriminator,re cent set,analysis,utterance,gram mar,new ambiguity,history,decision,correct,preferred analysis,sentence,understanding,nature,discriminator,relation,foundation,update procedure,minimal manual,spection,regular re gression test cycle,grammar,current state,seeding initiative,kick-off initiative,domain,english resource grammar,accurate coverage,face-to-face dia logues,appointment scheduling,follow-up phase,project,second domain,text genre,available on-line source,initiative,integrated treebanking environment,incr tsdb, lkb tree selection tool,first iteration,verbmobil utterance,approach,selection,minimal discriminator,second-year stanford,graduate,linguistics,completion,first iteration,ten week,utterance,verbmobil project,wahlster,data set,expert grammarian,degree,phrasal ambiguity,total active,active,active,redwood development status,transcribed,hand-segmented verbmobil dialogue,column,total number,sentence,fragment,lingo grammar,metric,following subset,sentence,annotator,analysis,active tree,annotation,preferred analysis,full disambiguation,first round,annotation,active tree,ambiguous sentence,experimental result development,treebank,nonethe,preliminary experiment,concrete application,utility,re source,section,ex periments,redwood treebank,system,parse disambiguation,component,tagger, hps lexical tag,treebank,report result,application,linguistic system,multiple par,string,problem,preferred one,variety,approach,statistical model,parse se lection,lexical type sequence,likelihood,sequence,lexical type,preterminals,derivation,part-of-speech tag,finer-grained information,well-understood statistical part-of-speech tag,technology,approach,information,entire derivation,string,probabilistic parsing research,ex ample,collins,charniak,process model,harris,derivation,treebank,branching process,stochastic model,important problem,soundness,approach,unification-based grammar,derivation,log-linear model,agresti,parse ranking,johnson,colleague,johnson,many interacting dependency,structural complexity,unification-based theory,syntax,nevertheless,naive  pcf approach,advan tage,simplicity,tagging ap proach,ranking,proof-of-concept exper iments,log-linear model, hps sign,possible par,unseen test sentence,probability,parse se lection performance,percentage,test sentence,correct parse,test corpus,sentence,grammar,parse selection task,simple  pcf, ap cfg ,grandparent annotation,hybrid model,prediction,tagger,detail,tagger,standard tri gram  hmm tagger,joint probability distribu tion,preterminal sequence,trigram probability,linear,terpolation,lower-order model,comparison,performance,unigram tagger,upper-bound oracle tagger,true tag se quence,correct preterminal sequence, pcf model,probability distribution,derivational type,hps analysis,sentence,cfg  model,application,nonterminals, pcf g ai, hps grammar, hea d-compl ,parameter,likelihood,derivation tree,preferred par,sen tences,training set,prob ability,local tree count,treebank,maximum likelihood estimate,observed data,grammar rule,possible derivation,assumption,context-freeness,rule application, hps grammar,introduction,grammar,example,researcher, a p cfg ,grandparent,notation,accuracy,extended  pcf,condition,expansion,parent,phrase structure tree,extended  pcf,henceforth  pcf g-gp,grammar, a p cfg ,nonterminals,nonterminals,original  pcf,combined model score possible par,probability, pcf g-gp model,probability,preterminal sequence,parse tree,trigram tag sequence model, ptr ig,probability,sequence,preterminals,appropriate treatment,boundary,trigram probability, hmm tagger,combined model,relative weight,component model,exact optimization,parameter,combined,combined model,sound probabilistic model,probability distribution,parse tree,crude way,ancestor,context information,second column,accuracy,parse selection,comparison,baseline,perfor mance,uni form distribution,first row,accu racy result,ten-fold cross-validation,data set,experiment,disambiguated sen tences,preferred parse,sentence,stochastic model,ent par,equal score,preferred parse,treebank,accuracy,sentence,approach,probability,anal y,derivation tree,tradi tional approach, pcf grammar,phrase structure tree,comparison,model  pcf g-gp,corresponding phrase structure tree,average ac curacy,accu racy,derivation tree,result,information,grammar construction,parse disambiguation,method task tag sel,parse sel,random,oracle,performance, pcf model,parse selection task,accuracy,result,indicate,high disambigua tion accuracy,simple statisti cal model,performance,perfect tagger,information,lexi cal type,information,method,combined,parse disambigua tion,availability,parser,accuracy,tag sequence,scoring parse,word sequence,problem,tag selection problem,analogy,relation,parsing problem,parse selection problem,first column,present,performance,tag selection problem,result,averaged accuracy,cross-validation split,corpus,previous experiment,parse disambigua tion,information,lexical type sequence,tag selection performance,experiment,tag sequence,possible par,probable tag sequence,accuracy re sults,latter case,corpus,short sentence,low ambiguity,perfor mance degrades,ambiguous sentence,purpose,accuracy,combined model,function,number,possible analysis,sen tences,sentence,number,possible analysis,first column,example,first row con,information,sentence,ambiguous sentence,column,total number,sentence,accu racy,random,accuracy,accuracy,powerful model,good accuracy,ambiguous sentence,several difference,corpus size,compo analysis sentence random combined,accuracy,number,possible par,sition,parse selection,unification,grammar,johnson,estimate  as tochastic unification,log-linear model,feature,production rule feature,ad junct,argument,motivated feature,dataset,sentence,total training,test set, a v erbmobil corpus,parse disambiguation accuracy,baseline accu racy,random,random base line,full data set,random baseline,sentence,analysis,accuracy,combined model,sentence,accuracy,knowledge,prior research,linguistic depth,flexibil ity,available information,dynamic nature,tree bank,corpus,hand-selected analysis,broad-coverage grammar,microsoft research,resource,proprietary grammar,analysis engine,treebanks,research result,successful lingo open-source repository,tree bank,associated processing scheme,stochastic model,public,on-going initiative,treebank,dependency structure,mullen,malouf, hps g-like grammar,general approach,redwood initiative,discriminator-based method,tree se lection, lkb tree comparison tool,malouf,sin gle stratum,representation,provision,analysis,tandem,grammar,dipper,application,broad-coverage  lfg grammar,tectogrammatical structure, tig er corpus,approach,groningen framework,limitation,computational linguistics,wide-coverage computational analysis,zavrel,netherlands,amsterdam,netherlands,rodopi,treebanker,supervised training,parsed corpus,proceeding,workshop,computational environment,grammar development,linguistic engineering,madrid,context-free grammar,word statistic,proceeding,four teenth national conference,artificial intelligence,ontext-sensitive statistic,improved grammatical language model,proceeding,twelth national conference,artificial intelligence,statistical parsing,proceeding,35th meeting,association,computational linguistics,conference,european chapter,madrid,typed feature structure grammar,algebra,semantic construction,constraint-based gram mar,proceeding,meeting,association,computational linguistics,toulouse,france,workshop,luxembourg,efficient grammar,natural language engineering,efficient,theory,process,berlin,germany,springer,gram mar,proceeding,37th meeting,associa tion,computational linguistics,statis tical natural language processing,maximum entropy model,fea ture,proceeding,natural language pro,pacific rim symposium,parser cross-fertilization,towards,compo nent comparability,exchange,proceeding,international workshop,parsing technology,rich  hps grammar,decision tree,proceed ings,sixth conference,natural language,foundation,speech to-speech translation,berlin,germany,springer, a c yclic dependency network kristina toutanova dan klein computer science dept,computer science dept,christopher,yoram singer computer science dept,school,computer science stanford university,jerusalem,israel,stanford,new part-of-speech tagger,following idea,tag con text,dependency network representa tion,lexical feature,multiple consecu tive word,effective use,con ditional loglinear model,unknown word feature,tagger,accuracy,penn treebank  wsj,error reduction,result,ntroduction almost,approach,problem,unidirectional approach,inference,sequence,regardless,maximum entropy condi tional sequence model,technique,decision tree,system,direction,sequence,excep tions,transformation-based learning,successful approach,recent year,sequence model,decision,successive local mod el,global model,entire sequence,identity,future tag,identity,causal,direction,influence,local point,example,left-to-right first-order  hmm,current tag t0,current word,ward interaction,next tag,unidirectional model,direction,influence,good reason,sus pecting,informa tion,direction,condi tioning,local point,smoothing,interaction,modeled feature,sharp estimate,right context,dependency network,series,local con ditional loglinear,aka maximum entropy,multiclass logistic regression,ef ficient bidirectional inference,tagger,lexical information,lexical probability,tag sequence probability,charniak,tagger,limited use,lexical probability,example,bilexical probability,current sta tistical parser,hile modern tagger,classic  cla w tagger,marshall,respect, idi omtag  module,correct taggings,frequent idiomatic word sequence,appropriate multiword feature,variable,position index,clearer relative notation,current position,right context tag,   e dmonton,   m ain paper,   p roceedings, hlt -naa cl,dependency network,left-to-right first-order  cmm,right-to-left  cmm,bidirectional dependency network,expressive template,large number,feature,suitable use,regularization,conditional loglinear model,something,previous maximum entropy tag gers,many feature,overall positive effect,ceptron,collins,performance gain,support threshold,feature,unknown word fea tures,part-of-speech tagger,per-position tag accuracy,whole-sentence correct rate,penn treebank  wsj data,part-of-speech tagging result,error reduction,collins,data split,error reduction,previous loglinear model,toutanova,manning,2 b idirectional dependency network,building probabilistic model,tag sequence,global probability,sequence,probability,tagged sequence,product,sequence,local portion,graphical model,time slice,example,left-to-right cmm,figure,replicated structure,local model,many con,quantity,local model,sophisticated way,tag ging,tropy model,example,maxent model,joint effect,joint feature,variable,feature,feature,previous tag feature,current word,carry useful information,influence,left-to-right  cmm,influence,ex plicit,influ ence,local model,next position,situation,right-to-left  cmm,figure,seat-of-the-pants machine,perspective,classifier,certain posi tion,obvious thing,local model,predictive feature,matter,target position,good formal reason,position,figure,effect,interaction,feature,left-to-right factor,termine,example,observation bias,manning,first-order left-to right  cmm, ptb tag set,sequence,modal verb,effect, a c mm,modal tagging,regardless,tag position,influence,problem ex ists,direction,symmetric right -2t hroughout,enough boundary symbol,difference,final position,espite use,observation bias,effect,unwanted explaining-away effect,cowell,causal competition,simple dependency net,bidi rectional net,a b ayes,to-left model,common noun tagging,symmetric reasoning,next section,direction,location,replicated model,example correct,dependency network,structure,figure,understood graphical model,well-known semantics,figure,standard bayes,pendency network,heckerman,random,local condi tional probability model,source variable,incoming arc,semantics,standard bayes,proper factorization,large joint prob ability estimate,local conditional factor,two-node case,figure,information,chain rule doesn,struct,quantity,un der appropriate condition,quantity,gibbs sampling,joint probability,local condi tional probability,local probability,acyclic model,observation,local environment,maximum likelihood estimation method,experiment,local maxent model,event space,relative count,effect,indirect influence,fluence,simple  hmm,prob abilistic model,right-to-left  hmm,emission,transition,end sym bols,equivalence,prac tice,addition,function,return bestscoresub,function,return cache,boundary case,recursive case,bestscoresub,pseudocode,polynomial inference,first order bidirectional  cmm,memoized version,inference,linear dependency network cyclic,product,local probabil ities,dependency network,acyclic model,joint prob ability,general case,tag sequence,dependency net work,figure,adaptation,viterbi algorithm,maximizing sequence,polynomial time,figure,pseudocode,concrete case,network,figure,general case,max-plus version,standard inference algorithm,cowell,essence,difference,inference,network,second-order left-to-right cmm,difference,markov window,position,foundational issue worth mention,maximum scoring se quence,sequence,maximum likeli hood,collusion,un likely sequence,two-node network,following distribution,ob servations,likely state,network,ad ditional,problem,training,negative logarithm,sequence score,training,sequence,data set sect,n sent,token unkn, 0d evelop,following training,network,entire data point,relative-frequency model assigns loss,training example,training data label,heckerman,suggests,practical use,dependency network,general immune,theoretical concern,dependency network,sequence model,problem,network,tagging problem,feature,observation,discriminator,tag sequence feature,framework,con ditional random field,lafferty,approach,similar local feature,local model,sin gle,normalized model,principal advan tage,dependency network approach,tageous bidirectional effect,expensive global training,dependency network,neighbor,influence,neighborhood,isolation,local model,lihood,training data,test time,sequence,product,local conditional score,exact maximizing sequence,acyclic net,maximum likelihood sequence,3 e xperiments,speech,experiment,wall street journal data,penn treebank  iii,tagged sentence,parse tree,training,development,test set,collins,sentence,po directory,hundred,rb rp set,parsed mrg version,istics,model  bes,result,development set,innovation,reporting,result,whole-sentence accuracy number,traditional per-tag accuracy measure,unambiguous one,quantity,sequence model,per-state optimization,subsequent linguistic processing,tag error,others,first cut,single tag,com mon way,subsequent processor,information extraction system,parser,result,entire sentence,measure,dynamic range,appeal,result,per-state model,log-linear mod el,ratnaparkhi,toutanova,manning,feature,template,different template,rare word,correct tag,unknown word,result,experi ments,experiment,directionality,experiment,lexicalization,experiment,experiment,directionality,section,experiment,log-linear cmm,various structure,relative value,discussed network,network,ver tical feature template,word signature feature,spelling,capitaliza tion feature,section,vertical conditioning,accuracy,baseline,condition -6t agger result,tag set,amount,training data,perfor mance increase,training,size grows,percentage,unknown word decrease,system perfor mance,increase,word class,count cutoff,common word feature,rare word feature,support,cutoff,simple model,unknown word model,prior distribution,baseline,sophisticated unknown word model,large number,unambiguous token,skewed distribution,base model feature template,feature sentence token unkn,word accuracy accuracy accuracy baseline,accuracy,development,different sequence feature,vertical word-tag feature,baseline,cutoff,feature,model feature,tagging accuracy,different lexical feature,development set,model feature,support feature sentence token unknown cutoff accuracy accuracy accuracy bes,final tagging accuracy,test set,previous tag,fea tures,next tag,individual-direction feature,accu racy,many tag-tag feature,uni directional model,evidence,bidirectional network,performs,second previous word feature,next word feature,2-tag feature,sym metric bidirectional model,high-performance tagger,joint three-tag count,tag trigram,tag-triple feature,ratnaparkhi,toutanova,manning,vertical feature,single set,tag-triple feature,equivalent feature set,left context,centered context,unidirectional context,substantial annotator noise,unknown upper bound,lexicalization lexicalization,key factor,advance,statistical parsing model,current word,tagger,ratnaparkhi,transformation,tagger, hmm model,lexicalization,tag ging model,dependence,speech tag,maximum entropy model,joint feature,joint fea tures,current word,surrounding word,principle straightforward addition,previous model,feature,lexicaliza tion,combination,tag history,development,accuracy,several model,various lexical feature,rare word,baseline model,current word,count cutoff,feature,first model,second row,tag sequence feature,ac curacy,cutoff,per tag accuracy,third row,accu racy,sequence model,standard tag fourgram  hmm feature,fifth row,bi directional tagging feature,tag sequence feature,last model,next word,last model,ad dition,feature,im provements,unknown word modeling,sec tion,accuracy,final test set,sen tence accuracy,confi dence interval,accuracy,binomial model,right con text tag,lexicalization,exam ple,enriched model,interesting example,simpler model,determinis tic fixup rule, idi omtag  module,marshall,expression,penn treebank,current word,expression,tag sequence probability,strong reason,common tagging,right tag,addition,model bes,unknown word,ratna parkhi,n-gram pre fix,suffix,detector,prominent feature,capitaliza tion,hyphen,number,error analysis,simple tagging model,several ad ditional specialized feature,harper,accuracy,opposite tiling,feature,accuracy,quadratic regularization,performance,crude com pany name detector,company name suffix,entity recognizer,prepro cessor,tagger,common order,processing,pipelined system,good example,something,condi tional model,minor gain,additional feature,allcaps feature,conjunction feature,common noun,prefix,suffix,length,template,feature,unknown word accuracy,tagger,many feature,dis tinct possibility,pure maximum likelihood e timation, a g aussian prior,aka quadratic regularization,quadratic penalization,high feature weight,great score gain, 2s ince,conjugate-gradient procedure,data likelihood,addition,penalty term,total size,penalty,partial derivative,repsect,log-likelihood,log-likelihood derivative,penalized optimization procedes,modification,different pa rameters,parameter class,result,paper use,denominator disap pear,expression,experiment,simple model,magnitude,performance,experiment,quadratic regularization,generalization perfor mance,num ber,feature,tagger support cutoff accuracy collins,effect,common word feature cutoff,fea tures,support,cutoff,number,feature,complex model,several hundred,thousand,com parison,number,feature,machine learning domain,experiment,regularization,simple model,small number,feature,large number,feature,usefulness,maximum entropy model,gaussian prior smoothing,rosenfeld,stochastic  lfg work,johnson,importance,example,perceived,success,logistic regres sion,text categorization,regular ization,conditional loglinear model,prob lem,high quality part-of-speech tagger,ratnaparkhi,manning,collins,present unregularized model,result,collins,low support feature,voted perceptron model,max imum entropy model,weight,maximum entropy model,show result,development,experiment,first pair,com mon word,rare word,second pair,feature,model bes,frequency cutoff,common word feature,first pair,error reduction,unknown word,second pair,error reduction,convergence,accuracy,unsmoothed model,training,iteration,large reduction,unknown word er ror,penalty,rare feature,frequent one,presence,penalty,degree,general cross-word signature feature,unknown word,word-specific sparse feature,unknown word,regularization,feature,low support,training iteration ac cu ra,smoothing figure,accuracy,iteration,quadratic regularization,performance,whereas ratnaparkhi,feature support cutoff,early stopping,overfitting,collins,low support feature,maximum entropy model,result,low support feature,regularized maximum entropy model,contrast,result,collins,exact number,difference,direction,regularized model,performance improves,inclu sion,low support feature,addition,accu rate,unsmoothed one,early stopping,ex ample,first smoothed model,conjugate gradient iteration,maximum difference,fea ture weight,iteration,unsmoothed model,iteration,training,second pair,iteration,unsmoothed model,gen eralization capacity,convergence,accu racy,unseen test,fur ther iteration,mod el,accuracy,training iteration,figure,iteration,accuracy,second pair,development set,4 c onclusion,broad feature use,appropriate model regularization,supe rior level,tagger performance,experience sug 10o,important difference,minute,iteration,practice,wiggling,chosen convergence point,final accuracy number,combination,tagger,previous single tagger,best-known combination tagger,accuracy, wsj data,training set,hile part-of-speech tagging,well-worn road,ability,performance increase,domain,er rors,inconsistency,penn treebank training data,implication,many  nlp problem,sequence mod el,sparse multinomial distribution,feature-rich model,extensive lexicalization,bidirec tional inference,effective regularization,key element,state-of-the-art result,acknowledgement,advanced re search,question answering,national science foundation, ibm faculty partnership award,reference steven abney,robert,schapire,yoram singer,pp attachment,statistical part-of-speech tagger,eric brill,classifier combination,improved lexical disambiguation,eric brill,transformation-based error-driven learning,natural language processing,case study,part-of speech tagging,computational linguistics,eugene charniak,curtis hendrickson,neil jacobson,mike perkowitz,equation,part-of-speech tagging,stanley,ronald rosenfeld,survey,technique,maximum entropy model,ee transaction,speech,kenneth,church,stochastic part program,noun phrase parser,unrestricted text,michael collins,discriminative training method,hidden markov model,theory,experiment,ceptron algorithm, emn lp,robert,steffen,lauritzen,spiegelhalter,probabilistic network,expert system,springer-verlag,new york,david heckerman,david maxwell chickering,christopher meek,robert rounthwaite,carl myers kadie,dependency network,inference,collaborative filtering,data visualization,journal,mark johnson,stuart geman,stephen canon,zhiyi chi,stefan riezler,estimator,unification,grammar,dan klein,christopher,manning,conditional structure,conditional estimation, nlp model,emn lp,andrew  mcc allum,fernando pereira,conditional random field,probabilistic model,seg menting,sequence data, icm l-2001,sang-zoo lee,jun ichi tsujii,hae-chang rim,of-speech tagging,hidden markov model,joint independence,mitchell,marcus,beatrice santorini,marcinkie wicz,large annotated corpus,english,penn treebank,computational linguistics,ian marshall,tag selection,probabilistic method,roger garside,geoffrey sampson,geoffrey leech,editor,computational analysis,english,corpus,approach,longman,london,adwait ratnaparkhi,maximum entropy model,part-of-speech tagging, emn lp,harper,second-order hidden markov model,part-of-speech tagging,kristina toutanova,christopher manning,knowledge source,maximum entropy part-of speech tagger,tong zhang,text categorization,regularized linear classification method,information re trieval, usa robert, usa abstract,method,incor porating word pronunciation information,noisy channel model,cor rection,method,explicit error model,word pronuncia tions,pronunciation simi larities,sub stantial performance improvement,performing model,correction,1 i ntroduction,kuckich,cogni tive,cognitive error,writer,misspelling,pronunciation,correct word,example,latecks,ypographic error,substitution,transposition,letter,keyboard,damerau,non-word error,result,sin gle insertion,deletion,substitution,transposition,letter,early algorithm,correction,assumption,cor rect word differs,misspelling,operation,kernigan,church,dam erau,probability,weight,different edit operation,right context,insertion,deletion,multiple edit operation,correction accuracy,new error model,generic string-to-string edits,error rate,previous model,substitution,5-letter sequence,model deal,phonetic error,previous model,context size,residual error,word pronunciation,example,triple,misspelling,correct word,incorrect,moore model,edelweiss advise bouncie bouncy bounce latecks,approach,phonetic error,separate er ror model,phonetic error,different error model,moore learning algorithm,letter-based model,moore model,similar dataset,phone-sequence-to-phone-sequence error model,first model,pronunciation,correct word,pronunciation,misspelling,phone-sequence-to-phone-sequence edits,probability,classification time,list prediction,log linear model,requirement,availability,   p roceedings,40th annual meeting,association,letter-to-phone model,pronunci ations,misspelling,letter-to-phone model,section,moore model,briefly,er ror model,section,present,letter-to-phone model,result,series,improve ments,n-gram letter-to phone model,fisher,training,test phase,algorithm,de tail,report,experiment,new model,moore model,section,con tains conclusion,future work,moore noisy channel,correction model many,correction method,instance,noisy channel model,misspelling,result,cor ruption,intended word,noisy communication channel,correction,finding,misspelling,correct word  2 d,dictionary,probable word,problem,denominator,terminology,noisy channel modeling,source model,channel model,correction model,misspelled word,propos ing correction,notice,noisy chan nel model,possibility,mi spelling,sufficient data,source model fac tor,example,correct,incor rect,improved er ror model,noisy channel,correction,single insertion,deletion,substitu tions,transposition,pa rameters,letter sequence,length,extension,pa rameters, jp sn,position,substitution,source word,misspelling,correct word,person,partition,correct word,partition,probability,generation,mi spelling,product,substitution probability,partition,example,person,word bouncy,partition boun,proba bility,boun cie,maximum,parti tions,probability,partition,method,error model,letter string,separate error model,phone sequence,model  ltr,letter,substitution prob ability,character string,model ph,substitution probability,phone sequence,data set,misspelling,correct word,training data,moore training algorithm,parameter,misspelling correct word,pronunciation,mi spelling,correct word,moore training algorithm,word pronunciation,cor rect word,misspelling,misspelling,dictionary,letter to-phone converter,possible pronun ciations,next section,training,conversion data,etter-to-phone model,research,machine learn,method,letter-to-phone conversion,high accuracy,example,neural network,sejnowski,rosenberg,deci sion tree,fisher,modified version,method pro,fisher,several extension,substantial gain,performance,section,phone level,fisher,extension,resulting letter to-phone conversion accuracy,machine learning algorithm,example,let ters,context,corresponding phone,clas sifications,ronunciation dictionary,ma jor source,training data,algorithm,information,correspondence,letter,respondences,sequence,letter,se quences,first step,machine,algorithm,alignment,individual letter,align ment algorithm,phone set,dictionary, net talk dataset,microsoft speech dictionary,statis tic,training,test set, net talk dataset,information,phone level align ment,algorithm,auto matic alignment,microsoft speech dictionary,phone level,big ger,final letter-to-phone model, net talk dictionary,letter correspond,length,pronunciation,alignment algorithm,letter,one correspond,example, net talk,information,phone level alignment, abl  b l,correct alignment,empty phone,microsoft speech dic tionary,letter,example,en try,dictionary, abl ey ax,correct alignment,letter,correct alignment,machine,algorithm,alignment algorithm,implementa tion,hard em,viterbi training,initial parameter,iteration,likely alignment,pa rameters,parameter,obtained alignment,sequence,microsoft speech dictionary, net talk,parameter,phonesjletter,method sim ilar,daelemans,den bosch,consideration,fre quency information,initial letter-to-phone model,method,n-gram model,fisher,pronunciation,letter,letter,letter,right context,sequence,letter,sequence,letter,number,letter,context,right varies,letter,example,letter,first context,letter,probability,probability,probability,context,window size,lected count,configuration,letter,probable translation,specific rule,context,occurrence,letter,example,second,empty phone,first rule,extension,extension,initial model,error rate,letter to-phone model,prediction,several ap plicable rule,pronunciation,middle,escoring,pronunciation,fourgram vowel sequence language,performance figure,fisher,figure,basic model,experiment,dif ferences,phoneset size,extension,letter-to-phone conversion,decision tree,last extension,vowel fourgams,algo rithms, net talk,microsoft speech dic tionaries,training,test set,proportion,training-set,test-set size,letter-to-phone model,training split,test split,interpolation,context,distinction,phonetic trigram,vowel fourgram,letter-to-phone accuracy,accuracy figure, net talk dataset,dataset,letter-to-phone model,phone accuracy,non phonetically-aligned microsoft speech dictionary,correction,letter to-phone model,microsoft speech dictionary,result,phone accuracy,word accuracy,initial model,extension,phone accuracy,percentage cor rect,word accuracy,percentage,pronunciation,specific rule,good predictor,probabili tie,word error rate,individual rule,prediction,several rule,choice,substring,example,right context,second,letter context,heuristic,latter,right context,fisher,choice,prediction,several rule,interpolation,context,refers,extension,basic model,symbol,interior,accuracy,feature,feature,explic,error rate,result,improvement,third row,prediction,top matching rule,probability distribu tion,letter,probability,sequence,trigram phone sequence model,prediction,basic model,sequence,sequence,letter,probability,distribution,let ter,combination,matching rule,weight,phone sequence model,held-out,linear search,performance,fourth row,final improvement,vowel fourgram language model,log probability,sequence,gram model,vowel sequence,final accuracy,fifth row,comparison,accuracy, net alk,similar proportion,training,test set size,source,information,left context,feature,decision tree,large performance gain,multiple decision tree,separate portion,training data,accuracy,letter-to phone model,art sys tems,improvement,component,correction accuracy,pronunciation,letter-based model,combined error model,probability pc mb,misspelling,dictionary,correction algo rithm selects,misspelling,dictionary,experiment,uniform source language model,dictio,correction, pc mb,source lan guage model,accuracy,addition,language model,good error model,improvement,error model lead,significant improvement,full noisy channel model,separate error model,letter,letter-based model,prob ability distribution  pl tr,phone-based model,distribution pp,pron wjpron,pronunciation,ph model,letter-to-phone model,distribution  pp hl,mate score,sc mb,logp ltr,logp phl,probability  pc mb,pp hl,pp hl,pron  rp,pron  rp,pron rjr,equation,expression, pp hl,figure,assumption,pron wjpron,equation,approximation, pp hl,possible pronunciation,dictionary,independence,misspelling,right word,pro nunciation,right word,inversion,conditional prob ability,pron rjw,marginal probability,latter factor,pron  wp,maximum term,following decomposition,pron rjw,pron rjpron,second part,final indepen dence assumption,expression,figure,letter-to-phone model,following subsection,individ ual error model,performance re sults,combined model,letter,error model,training individual error model,error model  ltr,training set,algorithm e,rewrite probability,probability pl tr,ph model pp,pron wjpron,phone-sequence-to-phone-sequence error model,training set,misspelling,correct word, ltr model,pronunciation,misspelling,pronunciation,correct word,following way,training sample,pronunciation,number,pronunciation,correct word,sample,probable pronunciation,letter-to-phone model,possible pronunciation,training set,algorithm,substitution probability,sequence,sequence,probability  pp,pron wjpron,product,substitution probability,probable alignment,result,system,moore model,dataset,misspelling,correct word,training,test set,ex act data size,word pair,training set,word pair,test set,dataset,experiment,original dataset,correct word,pronunciation dictio,training set,interpolation,combined model  cmb us,train ing,classification accuracy,test time,possible word,maximizing score cmb,combi nation,candidate word, pl tr,pron wjpron,pronunciation,pronunciation,letter-to-phone model,letter-to-phone model, 4-b est ltr,error reduction,correction accuracy result model,probable pro nunciations,performance,pronunciation,likely hypothesis,3-best accuracy,letter-to-phone model,1-best accuracy,correction accuracy,com bination,accuracy result,accuracy figure,percent test case,correct word,top word,con text size, ltr model,context size maximized test,accuracy,larger context,hurt accuracy,phone-based model,respectable accuracy result,word pronun ciations,error reduction,combined model,letters-only model, 1-b est,error reduction, 3-b est, 4-b est, 4-b est,example,influence,pronuncia tion modeling,misspelling correct word, ltr model,incorrect guess,combined model  cmb,5 c onclusions,future work,method,word pro nunciation information,correc tion accuracy,method,error rate,correction model,subject,future research,bet ter way,error model,correct  ltr guess bouncie bouncy bounce edelvise edelweiss advise grissel gristle grizzle latecks,newt nut rench wrench ranch,sang stail stale stall,example,corrected error,single model,typographic error,interest,potential,different setting,specialized model,non-native english speaker,particular origin,reference,improved error model,noisy channel,correction,annual meeting,probability,correction,statistic,computing,van den bosch,independent data-oriented grapheme-to-phoneme con version,progress,speech synthesis,damerau,technique,computer detection,correction,communication,volume,fisher,statistical text-to-phone function,ngrams, iee e in ter national conference,acoustic,speech,signal processing,improvement,trainable letter-to-sound converter,proceed ings,5th european conference,speech com munication,technique, acm computing survey,spelling correction program,noisy channel model, col ing-,damerau,conext,correction,information processing,management,sejnowski,parallel net work,english text,complex system,proceeding,annual meeting,ann arbor,association,computational linguistics joint learning improves semantic role labeling kristina toutanova dept,aria haghighi dept,aria42 stanford,christopher,abstract,much recent progress,accu rate semantic role labeling,previous work,independent classifier,separate label se quence model,viterbi,stark contrast,linguistic observation,core argument frame,joint structure,strong dependen cies,argument,joint model,argument frame,novel feature,interaction,discriminative log linear model,system,error reduction,argument,core argument,state of-the art independent classifier,gold standard parse tree,propbank,ntroduction,release,corpus,framenet,propbank,palmer,high-accuracy statistical model,automated se mantic role labeling,gildea,jurafsky,pradhan,palmer,tivated feature,argument,feature,aspect,individual argument,predicate,feature,ar guments,example,hard constraint,predicate,soft con straints,example,predicate, age nt argument,predicate,active voice, a t heme argument, age nt argument,several sys tems,dependency,jurafsky,pradhan,thompson,several system, con ll-2004,carreras,joint infor mation,argument structure,discriminative log-linear joint model,semantic role labeling,global feature,achieves superior performance,comparison,state-of-the-art mod el,computational complexity,dynamic programming,re ranking approach,present performance re sults,february,version,propbank,gold-standard parse tree,result,auto matic par,charniak,parser,emantic role labeling,task definition,architecture consider,sentence,much-needed boost,much-needed boost,different syntactic position,phrase,meaning,verb give,phrase filler,semantic role,sen tence,target verb,phrase,correct label,sub task,sentence,phrase,constituent,previous work,se mantic role labeling,existence,separate parsing model,parse tree,sentence,parse tree,semantic role,phrase,phrase,joint framework,feature,shallow parse,represen tation, con ll-2004,carreras,february,version,propbank cor pu,annotation,penn tree bank ii parse tree,marcus,ble label,argument,corpus,core argument label,argu ment label,core argument  arg 3-5,consistent global role,verb spe cific,arg m-loc ,location,tem poral modifier,ex ample parse tree,semantic role,bel node,parse tree,lo cal model,dependen cies,multiple node,joint model,joint model,se mantic role labeling,joint information,local model,joint model,3 l ocal classifier,context,role labeling,classifier,probability,individual parse tree node,standard separation,se mantic role,identification,classifi -1f,full listing,propbank argument label,palmer,cation phase,identification,sify node,argument,modifier,clas sification,argument,appropriate semantic role,mapping,label set,semantic role,mapping,non-none value,probability,labeling,probabili tie,identification model  pid,decomposition,indepen dence assumption,useful way,problem,local model,semantic role labeling use,decomposition,previous work,distinction,example,different feature,effec tive,good way,training,search,ef ficient,feature,local identifi cation,classification model,decom position,efficiency,training,identification model,parse tree,classification model,argument node,train ing,specific label,train ing,classification model,hard pruning,identifica tion stage,exact labeling,complete parse tree,maximizer,equation,accuracy loss,two-pass hard prune strategy,pradhan,previous work,various machine,meth od,local classifier,role labeling,example,rela tive frequency model,gildea,jurafsky,pradhan,decision tree,log-linear model,palmer,log-linear mod el,multi-class classification,advantage,log-linear model,probability distribution,identification,standard feature,gildea,jurafsky,syntactic category,node pre dicate  lem ma,verb pat,passive relative,predicate,parent additional feature,pradhan,appended length, pat feature nod e-lca partial path path,constituent,lowest common ancestor,predicate node pp  par ent head  wor d if parent, a p return parent,rightmost np selected pair,palmer,baseline feature,classification model,princi pled way,equation,feature,local identification,classification model,feature,subset,feature,previous work,standard feature,gildea,jurafsky,structural fea tures,recent work,pradhan,surdeanu,palmer,direct way,trained local identifi cation,classification model,labeling,parse tree,product,probability,equation,product,probability,label li,parse tree node ni,equation,problem,approach,labeling,con straint,argument node,consistent set,argument,local classifier,non-overlapping constraint,non-overlapping constraint,fast exact dynamic programming algorithm,labeling,parse tree,product,probability,local model,equation,simplicity,dynamic program,gen eralization,algorithm,viterbi al gorithm,context-free grammar,non-overlapping constraint, arg node, arg descen dants,local probability,prod uct,local probability,dynamic program work,assignment,assignment,likely consistent assignment,subtree,child tree,likely consistent assignment,log-probability,signment,likely assignment,log-probabilities,likely assignment,log-probability,log-probabilities,assign,log probability,procedure,likely non-overlapping assignment,procedure,likely assignment,product,local identification,classification model,local model,conjunction,search procedure,likely labeling,result,oint classifier,previous work,pendencies,semantic argu ment node,drawback,local model,parse tree node,use information,feature,dependency,instance,argument la bel,dependency,node label,factorized sequence model,finite markov horizon,chain conditional ran dom field,lafferty,dependency,re-ranking,argument identification,number,possi ble assignment,parse tree,number,hundred,bil lion,normal-sized tree,argument label ing,number,possible assignment,number,argument,approximate number,possible label,argument,huge number,strong independence assumption,corporate long-range dependency,re-ranking approach,collins,likely assignment,independence assumption,top assignment,local semantic role,likely assignment,small value,re-ranking approach,serious bottleneck,performance,train ing,oracle,assignment,assignment,local model, f-m easure,argument,number,result,small gain,upper bound,performance,large increase,memory requirement,good compromise,generation,likely joint assignment,likely non,joint assignment,parse tree,exact dynamic programming algorithm,generalization,algorithm,top non-overlapping assignment,section,parametric model,log-linear re-ranking model,joint se mantic role labeling,feature map,parse tree,label sequence,vector space,feature map,target verb,joint assignment,top possible joint assignment,log linear model,weight,dimension,feature vector,probability,assignment,re-ranking model,assignment,log-likelihoods,assignment,quadratic regularization term,framework,arbitrary fea tures,labeled tree,capture general property,predicate-argument structure,joint model feature,feature,joint re,context,example parse,figure,dependency,s1 np1-arg1 final-hour trading vp1 vbd,pp1  arg,share np3  arg m-tmp yesterday figure,example tree,propbank,semantic role annotation,dependency,la bel,input feature,argument node,feature,instantiation,template,feature,number,particular pattern,labeled tree,predicate,joint assignment,argument sequence,sequence,non -no ne,reasonable candidate ar gument sequence,typical number,argument,feature,predicate node,sequence,sequence,labeled node,re spect,left-to-right order,constituent,parse tree,strict left-to-right order,candidate argument sequence,correct assignment,figure,pp1-arg4,np3-argm-tmp feature,local model,feature,local model,joint model,template,local fea tures,joint template,local template,node label,exam ple,local feature  pat,joint fea ture template,candidate argument sequence,feature,specific argument label,feature,generic back-off  arg label,feature,identification,classifi cation model,example candidate argument sequence,node np1,feature,joint model,local feature template,whole label sequence,previous work,gildea,jurafsky,pradhan,information,se quence,disambiguation,example,information,multiple filler,labeling,obligatory argument,whole label se quence feature template,argument node,information,position,predicate,template,information,predi cate,example,template,example candidate argument se quence,active  arg,variant,feature,generic  arg label,specific label,feature template,effect,num ber,argument,predi cate,useful global information,argument structure,argument,sequence feature,experiment,whole label sequence feature,argument,important variation,feature,actual predicate lemma,addition,variation,feature,label sequence,feature,individual node,variation,phrase type,feature,repetition,candidate argument sequence,phrase type,common pattern,frame feature,effective class,fea tures,feature,single argument node,internal feature,argument node,feature,ture knowledge,constituent,syntactic realization,argument,syntactic alternation,dative alternation,example,object position,following argument,feature template,information extract,ar gument node,phrase type,con text,phrase type,argument,example,instantiation,template,reimbursement,template,identity,predicate,palmer,similar feature template,syntactic frame,similar information,im portant difference,template extract,textual information,noun phrase,predicate,sequence,ar gument node,information,argument node,final pipeline,application,joint model,semantic role labeling,joint re-ranking model  rsr,top non-overlapping joint assignment,equation,local model,experiment,performance,model  rsr,test time,local classifier,poor argument frame,bot tom,re-ranking model,good argument frame,bad frame,local model,final score,final score,tunable parameter,fluence,local score,final score,terpolation,first-pass model,parse re-ranking,collins,test time,top local assignment,result,experiment,february,re lease,propbank,annotation,section,training,development,previous work,semantic role labeling,infrequent discontinuous argu ments,training,test set,addi tion,standard result,individual argument  f-m easure,frame accu racy,fraction,sentence,reason,frame accuracy,measure,performance,individual-argument statistic,foremost,tential application,role labeling,cor rect labeling,argument,sentence,correct labelings,first official release,propbank,task  cor e argm f1 acc,f1 acc,identification,classification,id classification,performance,local classifier,identification,classification,identification classification,gold-standard parse tree,ore argm f1 acc,f1 acc,oracle upper bound,performance,complete identification classification task,number,top joint labelings,local classifier,model  cor e argm f1 acc,f1 acc,performance,joint model,identification classification,gold standard parse tree,result,variation,seman tic role,core argument,argument,result,joint model,argu ment identification,argument classification,complete identification,classification pipeline,local model,feature,technique,non-overlapping constraint,section,labeling,figure,specific example,joint mod el,local classifier,first argument,subject position,joint model,experiment,whole sequence,frame feature,joint model,error reduc tions,local model,measure,re spect,frame accuracy,joint error reduction, arg re,result,automatic par,automatic parse tree,charniak,parser,charniak,argument constituent,test set,exact match,automatic par,argument,constituent,automatic parse,head-word,gold-standard argument constituent,proposition,test set,charniak,parser,tokenization,put sentence,result,error reduction,joint model,respect,local model,setting,reason,upper bound,performance,identification model,automatic par,local identification model,f-m easure,frame accuracy,local clas sification model, f-m easure,frame accuracy,feature,argu ments,presence,parser error,feature,joint model,global coherence,argument frame,error reduction, cor argu ments, f-m easure,frame accuracy,model  cor e argm f1 acc,f1 acc,performance,joint model,identification classification,charniak,parse tree,work several semantic role,system,success,juraf sky,empirical probability,proposed argument,language model,label sequence,linear programming framework,ar gument frame,probability mass,respect global constraint,argument label,key difference,approach,previous work,following property,finite markov horizon,dependency,node la bel,feature,multiple argument node,internal feature,discriminative model,long-distance depen dencies,7 c onclusions,linguistic intuition,cur rent work,substantial gain,argument frame,dependency,discriminative model,long-distance feature,author,review er,helpful comment,dan juraf sky,insightful suggestion,useful dis cussions,advanced research,question answering,reference collin baker,charles fillmore,john lowe,berkeley framenet project,proceeding, col ing- acl,carreras,introduction,con ll-2004,semantic role labeling,pro ceedings, con ll-2004,eugene charniak,maximum-entropy-inspired parser,proceeding, naa cl,michael collins,discriminative reranking,natural language parsing,proceeding, icm l-2000,daniel gildea,daniel jurafsky,automatic labeling,semantic role,computational linguistics,john lafferty,andrew  mcc allum,fernando pereira,conditional random field,probabilistic model,seg menting,sequence data,proceeding,icm l-2001,mitchell,marcus,beatrice santorini,mary ann marcinkiewicz,large annotated corpus,english,penn treebank,computational linguistics,martha palmer,dan gildea,paul kingsbury,proposition bank,annotated corpus,semantic role,computational linguistics,sameer pradhan,wayne ward,kadri hacioglu,james martin,dan jurafsky,shallow semantic parsing,support vector machine,proceeding,sameer pradhan,kadri hacioglu,valerie krugler,wayne ward,james martin,dan jurafsky,support,tor learning,semantic argument classification,machine learning journal,vasin punyakanok,dan roth,wen tau yih,dav zimak,semantic role,inference,classifier,proceeding, con ll-2004,mihai surdeanu,sanda harabagiu,john williams,paul aarseth,predicate-argument structure,formation extraction,proceeding,thompson,roger levy,christopher,generative model,semantic role labeling,proceeding, ecm l-2003,nianwen xue,martha palmer,feature,semantic role labeling,proceeding, emn lp-2004,knowledge source, a m aximum entropy part-of-speech tagger kristina toutanova dept,computer science gate bldg,christopher,computer science,linguistics gate bldg,abstract,result,maximum entropy-based part,speech tagger,superior performance,information source,result,feature,extensive treatment,capitaliza tion,unknown word,disambiguation,tense form,particle,preposition,adverb,accuracy,tagger,penn treebank,numerous system,automatic assignment,speech,many different machine,method,recent op,method,hidden markov model,maximum entropy approach,ratnaparkhi,transformation-based learning,approach,manning,schiitze,method,information source,tagging,consequence,similar level,performance,contrast,engcg tagger,performance,contextual information source,generalization,statistical tagger,samuelsson,voutilainen,demonstrate,thank dan klein,michael saunders,useful discussion,anonymous reviewer,many helpful comment,notion,performance,knowledge source,tagger,special attention,unknown word,accuracy,unknown word tagging,significant performance gain,maximum entropy approach,inclusion,diverse source,information,frag mentation,independence,predictor,maxi mum entropy approach,part of-speech tagging,ratnaparkhi,approach,ability,non-hmm-tagger-type evidence,experiment,baseline maximum entropy model,maximum entropy,tagger,feature,ratnaparkhi,loglinear conditional probability model,probability,possible tag,context,sequence,several word,probability,tagging,process,maximum likelihood tag sequence,string,maximum entr,py modeling,probability distribution,entropy,distribution,certain set,constraint,constraint,accordance,statistic,training data,statistic,expected value,appropriate function,context,particu lar,constraint,expectation,feature,empirical expectation,feature,example,frequency,empirical model,training data,feature,makeandt vb,statistic,speech,certain word,certain way,sequence,sequence,statistic,arkov model,maximum entropy framework,complex statistic,n-gram sequence,expectation,feature,joint distribution,expectation,feature,constraint,constraint,conditional entropy,intu ition,nothing,constraint,berger,joint distribution,context,product,empirical distribution,history,conditional distribution,example,constraint,approximation,efficient computation,expectation,possible context,speech tag,context contain sequence,information,approximation,observed context,training sample,solution,optimization task,para metric form,denominator,normalizing term,partition function,correspond,weight,feature,detail,characteris tic,parameter estimation procedure,extensive discussion,maximum entropy method,berger,jelinek,pa rameter estimation,ratnaparkhi,approximation summing,training data,possible tag,ti lhi,passage,estimate,iterative scaling algorithm,expecta tions,ratnaparkhi,feature,baseline model,baseline model,context,speech tag,word wi,sentence,feature,constraint,instantiation,feature template,ratnaparkhi,rare word,training data,predictioff-capacity,unknown word,actual feature,next table,subset,feature,ratnaparkhi,arbitrary context,rare feature tem plate,history,current word wi,rare word,certain number,training data,feature,misleading statistic,different cutoff value,rare feature template,implementation,feature,conjunction,boolean function,history,boolean function,first conjuncts,corresponding threshold number,history,training data,template,ratnaparkhi,previous word,position,position,feature,template,different position,ur motivation,feature,result,experiment,feature template,general feature,rare feature,accuracy,development,addition,feature template,current ag,accuracy,testing,performance,part-of speech, wsj section,penn treebank,contiguous part,section,training,section,development test set,section,final test set,data set size,number,unknown word,set token unknown training,development,testing procedure,beam search,tag sequence,maximal probability,sentence,experiment,beam size,improved accuracy,beginning,sentence,information,first word,sentence,tagger,tag dictionary,training data,basic systematic tag ambiguity,english,regular verb,ed form, a v bn,stem form,training data,result,test set,baseline model,result,ratnaparkhi,convenience,accuracy figure,unknown word,difference,feature template,threshold,approxi mations,expected value,feature,beginning,section,difference,choice,training,test set,ratnaparkhi,difference,definite statement,different use,feature template,particularity,model estimation,conclusion,present,additional word feature,ratnaparkhi,position,overall performance,discussion,problematic case large number,common word,syntactic category,ambiguity,tagger,ambiguity,tagger,others,significant confusion,baseline model,test set,row label,correct ag,column label,assigned tag,example,num ber,position,number,jj category,particular confu sion,account,large percentage,total error,show part,baseline model,confusion matrix,unknown word,baseline model,overall assignment accuracy,different part,speech,example,accuracy,accuracy,adjective,accuracy,assignment,different part,speech,various type,result,inconsistency,training data,ratnaparkhi,linguistic clarity,determination,correct part,speech,context,instance,status,various noun premodifiers,maximum,reflect difficulty,unknown word,syste matic tag ambiguity pattern,english,fight answer,context,general good structural contextual clue,rp rb ambiguity,linguistic distinction,semantic intuition,good syntactic ues,correct ag,human tagger,classification,improvement appear,third class,classification,following section,additional knowledge source,assignment,unknown word,particle word,overall accuracy,speech assignment,unknown word model,accuracy,baseline model,unknown word,tagger,importance,lexical information,tagger,accuracy figure,corpus-based tagger,word accuracy,whereas unknown word accuracy,experiment,additional feature,accuracy,unknown word,mikbeev,accuracy,capitalized word,proper noun,first word,sentence, nn p,table  5 c onfusion matrix,baseline model,top confusion pair overall  jj nn  nnp  nns  nnp s vbn to, nn p,table  6 c onfusion matrix,baseline model,unknown word,top confusion pair accuracy test set unknown word accuracy test set accuracy development set unknown word accuracy development set baseline model  1 m,capitalization verb form particle,development set baseline model  1 m,sentence,letter,table  8 n umber,feature,different ypes,example,account,percent,total error,unknown word,known word,baseline model,unknown word error,category,category,percentage,incorporation,feature schema,feature,letter,feature,capitalization,uppercase character,notable distinction,example, wsj data,uppercase,distribution,overall distribution,feature,uppercase character,sentence,different ag distribution,distribution,prefix feature,rare word,net negative ffect,accuracy,good explanation,phenomenon,addition,removal,prefix,accuracy,unknown word,overall accuracy,result,test set,feature, 9 a ccuracy,capitalization feature,prefix feature,nknown word error,information,tagger,feature,conjunction,feature,baseline model,negation,feature,baseline model,beginning,sentence,pseudo-tag  na,feature,though-our maximum entropy model,independence,predictor,simple combination,feature weight,interaction term,non-additive interaction,log-space term,feature,3 f eatures,verb form,significant source,classifier error,total word error, vbp vb confusion,many case,people,tagger,correct form,example,several position,current position,feature,several word,threshold,modal verb,bare infinitive complement,separate feature look,position,feature,chosen number,position,available history,tagger,similar feature,auxiliary form,several position,implementation,feature template,structural rule,english,training data,predictor,certain part,speech,preceding word,example,association strength,addition,feature schema,performance,test set,feature,verb form,section,number,base line,number,accuracy,extended model 4 f eatures,particle disambiguation,section,rb rp tag,particular example,good local syntactic indicator,instance,exact sequence,speech,particle use,accuracy,rarer rp,particle,category,monster,tagger,capability,ambiguity,infor mation,preference,specific word,particle,adverb,preposition,particle,others,particular word,particle,context,different feature,information,predicate,history,condition,first predicate,current word,particle,position,good chance,current word,particle,verb-particle pair,system,analysis,training data,preprocessing stage,second feature template,last verb,current word,particle,current ag,last verb,pseudo-symbol na,position,hese feature,rb rp confusion,accuracy, rp category,overall confusion,example,number,considerable room,result,attainable accuracy,accuracy,distinction,penn treebank,quick informal study,accuracy,next table,final performance,accuracy,final model,comparison,accuracy,development set,accuracy,development set,corre sponds,charniak,observation,section,penn treebank,others,different number,feature template,different model,total number,feature,feature,verb form,capital ization,feature,particle,small number,feature,improvement,classification accuracy,parameter,maximum entropy model,accuracy figure,corpus-based part-of-speech tagger,performance level,information source,addition,ach new feature,limited range,improvement,accuracy,previous result,individual decision,maximum entropy method,assignment,speech,maximum entropy-based tagger,sophisticated feature,particular position,feature,interaction,predictor,change,modest increase,accuracy,initial experiment,tagger accuracy,additional information source,future,information source,english syntax,nd edition,nerger,della pietra,vincent,aximum entropy approach,natural language processing,thorsten, a s tatistical part-of speech tagger,proceeding,advance,transformation,speech tagging,proceeding,eugene,aximum-entropy inspired parser,proceeding,north american chapter,association,computational linguistics,frederick,statistical method,speech recognition,christopher,hinrich schiitze,statistical natural language processing,andrei,period,capitalized word,university,edinburgh,ukl-mikheevlpapers,html ratnaparkhi,adwait,maximum entropy model,part-of-speech tagging,proceeding,conference,empirical method,natural language processing,university,pennsylvania,adwait,maximum entropy model,natural language ambiguity resolu tion, phd thesis,university,christer,atro voutilainen, a s tochastic tagger,proceeding,th annual meeting,association,computational linguistics,heterogeneous classifier,word-sense disambiguation dan klein,sepandar,kamvar,christopher,ensemble,het erogeneous classifier,word-sense disambigua tion,stanford-cs224n system en, sen seval-,english lexical sample task,first-order classifier,second-order classifier,ma jority voting,voting,maximum en tropy model,individual first-order classifier,middle-scoring team,sys tems,combination,high performance,trade-off,empirical performance,analysis,combination,ensemble performance,error independence,task difficulty,problem,ent classification algorithm,decision tree,decision list,memory-based learner,certain al gorithms, wsd problem,others,comparison,mooney,similar input feature,various al gorithms exhibit,similar accuracy, sen seval-,result,na tional science foundation, nsf graduate fellowship,research collaboration, ntt communication science labora tory,nippon telegraph,telephone corporation,difference,imple mentation,single classifier type,dow size,accuracy,choice,classi fication algorithm,large fraction,system,narrow region,senseval-2,system,supervised wsd system,student,stanford university,spring,student, wsd method,implemented variant,naive-bayes,others,method,n-gram model,vector space model,memory-based learner,system,accuracy, sen seval-,english lexical sam ple task,others,perfor mance,clas sifiers,combination,section,first-order classifier,method,combination,sec tion,performance,ben efit,combination,aspect,component system,overall performance,procedure figure,high-level organization,system,individual first-order classifier,map list,context word,word-sense predic tions,self-contained  wsd system,first order classifier,variety,second-order classifier,second-order classi fiers,selector,first-order,computational linguistics,   d isambiguation,recent success,future direction,philadelphia,   p roceedings,word sense rankingorder2nd,entropy validation voting,voting majority classifiersorder1st,classifiersorder chosen classifierfinal classifier cross rankingorder1st,figure,high-level system organization,1 s plit data,multiple training,held-out part,2 r ank first-order classifier,3 r ank first-order classifier,global rank,size 6 c,top classifier,voting method 8 t,second-order classifier,second-order classifier instance,choose,top-ranked second-order classifier,retrain,per-word classifier,entire training data,classifier,test data,evaluate result,construction process,outline,construction process,training data,training,held-out set,random bootstrap split,example,training,subset,first-order classifier,combination method,training split,first order classifier,held-out data,first order classifier,formance,held-out data,accu rate classifier,ranking,classifier,average perfo mance,ootstrap split,standard n-fold cross-validation,reason,arbitrary number,held-out pair,substantial held-out data set size,second,ap proach,literature,ensemble,theoretical property,breiman,proper ad vantage,ability,numerous split,cross-validation,second-order classifier,second-order clas sifier type,ensemble size,combination method,instance,second-order type,ensemble size,second-order classifier,ensemble size,ensemble mem bers,top first-order classifier,local rank,first-order ensemble,method,sense output,first-order classifier,ensemble,sense frequency,frequent sens,eighted voting,first-order classifier,voting weight,maximum entropy classifier,output,first-order classifier,possible second-order clas sifiers,ensemble,performance,good first order classifier ranking,section,parameter,method,parameter,second-order classifier,bootstrap split,training data,manner,first-order classi fiers,second-order classifier,local ranking,second-order classifier,average,curacy,held-out data,ranking,average performance,classifier type,top second-order classi fier,tie-broken ranking,first-order ensemble member,second-order combination method,unsplit training data,final test data,target word,separate task,different firstand second-order choice,discussion,combination method,second-order classifier,training instance,correct sense,combination scheme,weighted voting,different way,weight,first-order voter,majority voting,attempt,statistical estimation,method,weighted vot ing,combination output,mixture model,first-order system,conditional probabilties,assign mass,sense si,mix ture weight,likelihood,second-order training instance,weighted vote,posterior likeli hood,selected sense,maximum entropy classifier,different model,chosen sense,exponential model,feature,function,subset,vector,original intent,feature,sense ex pertise,individual classifier,example,classifier,certain sense,mate parameter,number,feature,triple,feature,support,certain word,simple majority voting,maximum entropy model,complex feature,feature,first-order classifier,sin gle feature,classi fier,feature,maxi mum entropy approach,weighted vote,posterior probabil ity,indicator,correspond,simple,posterior probability,maximum entropy classifier,weight,likelihood,standard  iis algorithm,berger,weighted scheme,iterative procedure,conver gence,single round,method,weight,exact weight estimate,method,trigger broad qualitative change,weight,majority voting,classifier,positive weight,weighted vot ing,weight,maximum entropy weighting,non-negativity constraint,re laxed,classifier,classifier,negative weight,effect,poor classifier,error mask,com mon error,majority voting,voting,entropy,estimation,correct sense,overfitting problem,classifier,spectrum,sparsity,training corpus,different word,individual classifier,first-order classifier,va riety,classification algorithm,difference,individual accuracy,algorithm chosen,rather,implementation detail,difference,example,naive-bayes classifier,sensible win dow,window size,poor size,optimal window,strong local syntactic,collocational cue,large size,topical cue,rograms,hard-wired window size,middle-size window,student,extreme,design,implementation choice,performance,naive-bayes system,amount,heavy smoothing,conditional dis tributions,relevant marginal,good result,insufficient smoothing,uniform marginals,result,significant way,first order classifier,system,original class project,stu dent,ambiguous word,single orthographic form,system,guarantee, sen seval-,window size,system,long distance,feature,window size,defective behavior,smooth,chosen sense,context window,skewed-prior data,sen seval-,common sense,regard,context word,context word,citation form,information,system,overall perfor mance,considerable correlation,tween form,nev ertheless,attempt,student system,thoroughly inves,difference,3 r esults,discussion,result,show result,sen seval-,english lexical sample task,second-order classifier,opti mal second-order classifier choice,mistake,ensem ble size,method,wide range,second-order classifier type,overview,benefit,combination,single classifier,single classifier,test data,second order classifier,test data,dynamic selection method,examines combi nation,change,system,sen seval-,competition,overall accu racy,revised ranking,total sys,first-order classifier,black-boxes,combination,selection method,effectiveness,second-order classifier choice,system,second-order classifier,test data,overall accuracy,oracle method,various top-scoring team,system,test-set performance,second-order classifier,change,result, sen seval-,english lexi cal sample task,first-orders,baseline,single first-order classifier,held-out data,fixed com binations,second order classifier,test data,first-order classifier,correct answer,method,ensemble-size depen dent,system choice,accuracy,selection,system,2nd-order classifier,better-tuned method,combination model,significant improvement,method,next section,increase,final accu racy,system,current score,preliminary result,revised result,lb baseline combination ub system all  mfs  sng mj-7 wt-7 me-7  bes t some  acc,result,christopher,manning department,ilhan stanford,abstract,word level alignment model,statistical machine translation,method,speech tag information,alignment accu racy,approach,fertility,cor respondence,empty word, hmm align ment model,present accuracy result,viterbi alignment,human-judged alignment,canadian hansard corpus,bigram  hmm, ibm model,result,alignment error reduc tion,ntroduction,main task,statistical machine translation,string translation probability,string,language,language,source language string,target language string,accordance,noisy chan nel terminology, ibm model,pairwise mapping,source,target string,mapping,alignment model,present exten sion, hmm alignment model,extension,alignment model,language pair huge amount,parallel corpus,available whereas,gual resource,tagger,little research,national science foundation,author,various reviewer,helpful comment,version,tential,speech information,model translation probability,permutation probabili tie,melamed,broad classifica tion,content,function,several punctu ation class,class-specific parameter,translation model,english tag,chinese language,coerced markov model,english  pos class,markov model,chinese language word, pos tag information,prior knowledge,word translation,local word order vari ation,information,translation,many alignment model,many mapping,source language word,lan guage word, ibm model, hmm alignment model, ibm model,fertility model,number,alignment word fertility,alignment position,target word,alignment probability,word depend,alignment,pre vious word,first order  hmm,source word,target word,extension,alignment,model word fertility,assumption,alignment mod el,special null word,source sentence,target word,correspondence,source language, a n ull word,many model,   a ssociation,computational linguistics,philadelphia,   p roceedings,conference,empirical method,natural existence,special null word,source lan guage,target language,different model,constrains,condition generation,generation probability,null depends,target sentence,general equation,decom position,translation probability,speech tag,detail,extension,2 p art,speech tag, a t ranslation model augmenting, a r ich  hps g gr ammar using decision tree kristina toutanova,christopher,feature selection,log linear model,representation,decision tree,fea tures,probabilistic context free grammar,single decision tree,optimal use,formation,ensemble,decision tree,different feature subspace,signifi cant performance gain,performance,learned  pcf grammar,log linear model,feature,1 i ntroduction hand-built  nlp grammar,linguistic representation,constraint,current treebanks,tial importance,process,gram mar,disambiguation problem,problem,prob abilistic parse selection,al ternatives,hand-built grammar,context,redwood  hps treebank,head-driven phrase structure grammar,modern constraint,lexicalist,unification,grammar,pollard,redwood,semantic analysis,example,penn treebank,large number,feature,stochastic model,disambigua tion,researcher,feature,disambiguation,unification grammar analysis,log linear mod,stochastic unification,grammar,johnson,riezler,log linear model,condi tional probability,sentence analysis,fea ture selection,mod el,high computational cost,pcf model,feature,log linear mod el,method,fea tures, pcf g,decision tree,feature,conditional log linear model,performance,equivalent feature, pcf model,process model,penn treebank,next state,feature,recent parsing work,small number,feature,charniak,collins,conditioning information,various state,possible feature,predictor,situation,decision tree,feature selection,statistical parsing model,magerman,haruno,example,automatic feature selection,parsing,context,determin istic parsing model,parse action,decision,rich feature,hermjakob,mooney,feature selection,deci sion tree,single decision tree,optimal use,large number,rel evant feature,greedy search procedure,informa tion,different feature,partition ing,example,difficulty,evidence,different feature,common approach,problem,decision tree,variance,representational power,ensemble,decision tree,example,bagging,breiman,freund,schapire,deci sion tree,significant gain,approach,separate decision tree,disjoint,subset,feature space,estimate,aver age,prediction,similar method,random feature subspace,random feature,space method,bagging,datasets,large number,relevant feature,redundancy,feature,ex amples,ensemble combination,different feature subspace,combination,naive bayes classifier,zenobi,cunningham,ensemble,knn classifier,information, hps corpus,subset,ensemble,decision tree,parameter izations,process model,parse disambiguation result,conditional log linear model,2 c haracteristics,treebank,feature,redwood treebank,under-construction treebank,sentence,particular  hps grammar,lingo erg,flickinger,current preliminary version,sentence,spoken di alog material drawn,verbmobil project,redwood treebank,en tire  hps sign,sentence analysis,experiment,small subset,representation,identifier,lexical item,construc tions,analysis,semantic head-to head relation,redwood treebank,semantics,minimum recur sion semantics formalism,copestake,present experiment,derivation tree,com bining rule schema, hps grammar,er hco mp hco mp bse _verb_infl let _v1,_verb_infl see _v3,derivation tree,sentence,phrasal category,standard sort,whole hps,deriva tion tree,grammar,preterminals,derivation tree,lexical label,much finer,penn treebank pretermi nals tag,tree adjoining grammar model,bangalore,lexical la bel,treebank,supertagging approach,long way,parse disambiguation,per bound,approach,corpus,percent parse selection accuracy,accuracy,oracle tagger,random,correct tag se quence,semantic dependency tree,relation,correspond,sentence,abstraction,semantic label,example,number,example,derivation tree,analysis,short sentence,figure,semantic dependency tree,addition,information,main part,speech information,lexical head,derivation tree,preposition,information,cludes subcategorization information,lexical type,rich set,syntactic type,dividual feature,aspect,gender,resource,type hierarchy,equivalence class,statistical estimation,3 m odels,generative model,assign probability,derivation tree,dependency tree,final stage,probability,entire sentence analysis,possible analysis, hps grammar,accor dance,estimated score,generative model,derivation tree,single decision tree,available feature,available feature,history,probability,derivation tree,expansion,probability,derivation tree,product,probability,expansion,history,available feature,training corpus,derivation tree,preferred analysis,sentence,decision tree,standard decision tree,algorithm,gain ratio,quinlan,final expansion prob ability,linear interpolation,estimate,strategy,magerman,derivation tree,learner,node direction feature,left child,right child,single child,num ber,ancestor feature,history,grammar,lingo  erg,complement,ad juncts,multiple rule,extensive use,unary rule,various kind,type changing,operation,sim ple  pcf,extent,important dependency,local tree,much flatter representation,penn treebank,inclusion,ancestor node,history,necessary information,grandparent anno tation,charniak,carroll,johnson,name example 0 n,label  hco mp 1 p arent node label  hco mp 2 n,direction,3 p arent node direction none 4 g randparent node label  imp er 5 g reat grandparent top,sister node label  hco mp 7 l,preterminal u 8 p reterminal, 7 l et_v1 9 c ategory,node verb table,feature,derivation tree,name example 0 n,1 d irection,dependent,2 n umber,intervening dependent,3 p arent node label top 4 l abel,right pron_rel table,feature,semantic dependency tree,generative model,se mantic dependency tree,ex pansion,consisting,sepa rate trial,dependent,pendencies,history,feature,semantic dependency tree,feature,semantic tree,feature,selection method,obvious redundancy,method,single decision tree,generation,semantic dependent,left dependent,parent,right sister,num ber,dependent,right dependent,parent,sister,number,dependent,stop sym bols,rule model,collins,example,joint probability,dependent,let_rel,example,let_rel,pron_rel let_rel,see_understand_rel let_rel,let_rel,see_understand_rel,conditional log linear model conditional log linear model,probability, hps analysis,sentence,analysis,feature,derivation tree,syntactic tree,described,branching process model,sentence,possible analysis,conditional probability,analysis ti,johnson,conditional likelihood,preferred analysis, a g aussian prior,rosenfeld,conjugate gradient,optimization,ensemble,decision tree,fea tures,corresponding log linear model,fol low,decision tree,possible expansion,training set,feature,number,expansion,history,4 e xperiments,present experimental result,performance,different model,accuracy result,ten-fold cross validation,data set,sentence,data set,human annotator,early stage,treebank,annotation,single annotator,accuracy result,percentage,test sen tences,ranked analysis,correct one,measure,whole sentence ac curacy,labelled precision recall measure,parse ranking,equal score,preferred parse,treebank,accuracy,sentence,difficulty,corpus,baseline,expected accuracy,parse sentence,lex ambig struct ambig,corpus,experiment,column,total number,sen tences,average length,structural ambiguity model generative log linear test train test train random,pcf g-dtal,accuracy,syntactic mod el,single decision tree,mod el,random,accuracy result,simple  pcf model,node label,history, pcf g-gp,parent,feature, pcf grammar,grandparent annota tion,accuracy,parse selection,simple model,derivation tree,accuracy,fea tures,third column contains,result,log linear model,feature,genus tive model,addition,conditioning information,log lin,model performs,simple rule feature,accuracy,addition,complex feature,error reduction, pcf g-s ,g-dtal,corresponding error reduction,log linear model,reduction,log linear model, pcf g-gp,log lin ear model,feature,training data,test data,partial explanation,g-s  try,likelihood,correct par,strong independence assumption,log linear model,cor rect,incorrect one,result,single deci type,model feature feature subspace pcf g lo linear  pcf g lo linear derivation tree,dependency tree,combined feature subspace accuracy,accuracy,single decision tree,ensemble,ensemble,decision tree,different feature subspace,decision tree,ensemble,possible par,sentence,simple ma jority vote,feature,decision tree,feature,whole space,left preterminal feature,feature,number,participate,cision tree,participate,decision tree,po sible value,feature space,cision tree,left preterminal fea tures,feature,number,initial feature space,method,feature subspace,intuition,feature,number,possi ble value,accuracy result,mod el,derivation tree,semantic dependency tree,combined model,first row show,accuracy,derivation tree,log linear model,fea tures,result,feature,single decision tree,ensemble,decision tree model,different feature subspace,relative improvement,accu racy,log linear model,decision tree,second row show,semantic dependency tree,small number,feature,performance gain,feature subspace,experiment,ev ery combination,feature,whole space,fea tures,subspace,result,large number,feature subspace,performance,method,result,ensemble,decision tree,computational reason,upper bound,accuracy,semantic tree,many sentence,several analysis,semantic dependency structure,interestingly,semantic tree,difference,log lin ear,generative model,last row,combination,derivation tree,semantic tree,feature,space ensemble,decision tree model,derivation tree,ensemble,feature subspace model,semantic dependen cies,possible sentence analysis,weighted majority vote,weight,semantic model,improvement, pcf model,semantic model,error reduction,error rate,syntac tic,corresponding log linear model,feature,semantic decision tree,ensemble,error reduction,addition,semantics,log linear model,semantic information,research,result,decision tree,ensem bles,decision tree,performance,generative model,deriva tion tree,dependency tree,performance,generative model,formation,performance,log linear model,corresponding improvement,log linear mod el,complex feature,improvement,generative model,information,additional history,log linear model,5 e rror analysis,hard disambiguation decision,combined syntactic-semantic model,present get,log linear model,derivation tree,semantic dependency tree,analysis sentence,training test split,fold cross-validation,whole corpus,error analysis,breakdown,limitation,real error,inconsistency,annotation,perfor mance,training data,sentence,parameter,correct analysis,incorrect,incorrect annotation,tect inconsistency,training data,test data error,percentage,log linear model,suscepti ble,training,annotation,pcf model,pa rameters,large number,feature,log linear model,data set,addition,large number,feature,significant portion,real error,pp attachment error,parallel structure,long dis tance dependency,example,sentence,thirty,thursday,interpretation,thirty,thurs day,common meaning,thirty,thurs day,disambiguation decision,quire common world knowledge,addition,knowledge,paral lel structure,add feature,log linear model,derivation tree feature,combined model,large majority,combined model,syntactic model,example,semantic infor mation include,sentence,twenty fourth monday,punctuation,corpus,derivation tree,monday,monday,common interpretation,twenty fourth day,several error,dependency tree model,interesting error,seman tic model,sentence,syntactic model,interpreta tion,sentence,semantic model,6 c onclusions,future work,probabilistic model, hps parse disambiguation,number,available feature,relevant feature,decision tree,dif ferent feature subspace,ensem bles,correct parse,accu racy,individual model,future work,information, hps sign,fea tures,capture long distance dependency,future research, mrs semantic representation,conjunction,clustering,semantic type,7 a cknowledgements,stephan oepen,redwood treebanking project, hps development envi ronment,dan flickinger,explanation,lingo  erg,error analysis,thanks,stuart shieber,participant,redwood project meeting,many discus sion,thanks,dan klein,implementation,conjugate gradient,anonymous  con ll-2002 reviewer,help ful comment,work sup,national science foundation,reference srinivas bangalore,aravind,approach,computational linguistics,predictor,machine learning,eugene charniak,carroll,context sensitive statistic,improved grammatical lan guage model,proceeding,twelth national conference,artificial intelligence,eugene charniak,context-free grammar,word statistic,pro ceedings,fourteenth national conference,artificial intelligence,rosenfeld,gaussian prior,maximum entropy model,technical report  cmu c,michael john collins,statistical parsing,proceed ings,35th meeting,association,computational linguistics,confer ence,european chapter,ann copestake,alex lascarides,dan flickin ger,algebra,semantic construction,constraint-based grammar,proceeding,meeting,association,compu tational linguistics,toulouse,france,dan flickinger,effi cient grammar,natural lan guage engineering,effi cient,robert,schapire,new boosting algorithm,inter national conference,machine learning,masahiko haruno,satoshi shirai,yoshifumi ooyama,decision tree,struct,practical parser,proceeding,meeting,association,computa tional linguistics,ulf hermjakob,reymond,mooney,translation decision,ex amples,rich context,proceeding,35th meeting,association,computa tional linguistics,conference,european chapter,random subspace method,decision forest,ee transac tions,pattern analysis,machine intelli gence,mark johnson,stuart geman,stephen canon,zhiyi chi,stefan riezler,estimator,grammar,proceeding,37th meeting,associ ation,computational linguistics,mark johnson,linguistic tree representation,computational linguistics,magerman,statistical decision-tree model,proceeding,meeting,association,computational linguistics,stephan oepen,kristina toutanova,stuart shieber,christopher manning,dan flickinger,lingo redwood tree bank,motivation,preliminary application, col ing ,carl pollard,head driven phrase structure grammar,university,quinlan,program,machine learning,morgan kaufmann,stefan riezler,detlef prescher,jonas kuhn,mark johnson,stochastic modeling,constraint-based grammar,log-linear measure,em training,pro ceedings,meeting,association,computational linguistics,hong kong,gabriele zenobi,padraig cunningham,diversity,ensemble,classi fiers,different feature subset,generalization error,naive bayesian classifier commit tee,leaf projection path view,parse tree,string kernel,hps g pa rse selection kristina toutanova c dept,stanford university,serra mall stanford,penka markova ee dept,stanford university,serra mall stanford,christopher manning c dept,stanford university,serra mall stanford,edu abstract,novel representation,parse tree,leaf projection path,top level,representation,accuracy, hps parse selection,standard model,application,string kernel,tree kernel,string kernel,projec tion path,performance,con text,parse disambiguation, svm rank ing model,exact sentence accuracy,redwood corpus,1 i ntroduction,building sta tistical model,parse disambiguation,correct analysis,possible analysis,sentence,many machine,algorithm,classification,require data,real-valued vector,fixed dimension ality,natural language parse tree,choice,repre sentation,success,machine,algorithm,large class,machine,algorithm,explicit representation,kernel function,similarity,addition,efficient computation,high dimensional representation space,ker nels,alternative view,problem,similarity,relevant feature,previous work,discriminative natural lan guage parsing,approach,fea tures,lexicalized local rule,collins,simi lar,feature,performing,generative parsing model,charniak,collins,non-local feature,parallelism,complexity,phrase,discriminative log-linear parse ranking model,riezler,approach,tree kernel,example,collins,subtrees representation,parse tree,application,fast dynamic programming algorithm,number,common subtrees,tree kernel,hierarchi cal directed graph,suzuki,interesting kernel,sequence,application,quence classification,parsing,good overview,kernel,new representation,parse tree,localization,useful context,ker nels,superior disambiguation ac curacy,tree representa tions,context-free rule,usual notion,discriminative model,criminative  pcf,plain context free rule feature,fea tures,particular tree,reference,served input,standard way,problem,lexicalization,el ement,tree node,feature,alterna tive way,tree context,ker nels,performs,parse tree,jection path,top level,head-path,syntactic head,non-head path,example case,non-head dependency,large subtree fea tures,sister,adjective phrase,comparative clause,representation,projection imp er verb hco mpverb hco mpverb let v1,tha t deix,figure,derivation tree,sentence,string,string kernel,tree kernel,context,parse disambiguation,sentence analysis,grammar formalism,redwood corpus,modern constraint-based lexicalist,unification,discriminative mod el,support vector machine,joachim,rep resentation,previous approach,substantial improvement,accuracy,leaf projection path view,parse tree, hps g si gns,sentence analysis, hps sign,information,seman tic property,phrase,previous work,red wood corpus,toutanova,toutanova,manning,derivation tree,main representation,disambiguation,deriva tion tree,combining rule schema, hps grammar,initial lexical type,derivation tree,fundamental data,redwood treebank,full sign,reference,gram mar,internal node,example,head-adjunct schema,component part,derivation tree,introduction,pollard,figure,head node,leaf word,non-head node,sentence,figure,deriva tion tree,information, hps sign,annotation,feature path,feature structure,information,chil dren,parent,theory,enough annotation,derivation tree,whole  hps sign,node annotation,disambiguation,annotation,feature path synsem,basic part,speech,phrase structure category information asso,several feature path,red wood corpus,phrase-structure tree,annotation,lexical type,head word,preterminals,figure,lexical item identifier,identifier,lexical entry,le-types, hps type hier archy,direct super-types,lexical item identifier,le-types,figure,figure,example,lexical type, let v1,figure,figure,annotation,synsem,leaf projection path view,projection path,sequence,figure,leaf projection path,derivation tree par,sentence,possible analysis,attachment,ad junct,complement,ticipates,projection path,original local rule config urations,projection path,special anno tation,informa tion,figure,grammar,non-crossing lexical depen dencies,initial segment,projec tion path,leaf word,syntactic head,head path,final segment,syntactic head,non-head path, hps non-local dependency,final semantic representation,syntactic head annotation,traditional parsing model,likelihood,local rule expansion,tree node,lexical head,formation present,word projection path,information,projection path,fur ther experiment,non-head part,projection path,disambigua tion,representation,derivation tree,kernel,leaf projection path,kernel,application,kernel,performance,new model,standard rule feature,string kernel, svm ranking,machine,parse se lection problem,training example,natural language sentence,number,sentence,parse tree,conference,ann arbor,association,computational linguistics a j oint model,semantic role labeling aria haghighi dept,aria42 stanford,edu kristina toutanova dept,christopher,edu abstract,semantic role,sys tem,closed track,con ll-2005,system,toutanova,im plements,joint model,pendencies,argument,predi cate,log-linear model,discrimi native re-ranking framework,scribe experiment,robustness,system,presence,syntactic parse error,final system,f1-measures,development, wsj portion,test set,1 i ntroduction,strong statistical pattern,syntactic realization,ordering,argu ments,instance,active predicate,a0 argument,a1 argument,pendencies,syntactic parse tree,possible joint la belings,number,parse tree node,labelings,strong independence,sumptions,problem,discriminative re-ranking approach reminiscent,collins,local model,bel argument,number,likely joint labelings,candidate la belings,turn input,joint model,global feature,candidate,global re-ranking model,maximum entropy,following section,joint model,system architecture,feature,emphasis,new feature,performance,joint model, con ll,approach,robustness,semantic role la,system,parser error,consid,multiple parse tree,statistical parser,2 l ocal model,local model label node,parse tree inde,probability,argument label,product,probability,prob ability,argument label,identification,classification model,identification model,phrase,argument,non argument,classification model label,potential argument,specific argument label,feature,previous research,gildea,jurafsky,pradhan,carreras,many useful feature,local iden tification,classification,fea tures,hand-picked conjunction,feature,local model,toutanova,feature,previous work,feature,next section,knowledge,phrase type,predicate,head word,ub-cat  cfg expansion,predicate,length,path feature,ode-lca partial path path,common ancestor,predicate,parent,parent,head word head-pos,afternoon,predicate,subject,standard,path path,maximal,projection,predicate,additional local feature,large source,fig ure,argument,predicate,subject,typical position,empty np,auxiliary,subject,current position,example,binary fea ture,subject,pred icate,subject,feature,conjunction,path feature,typical path,subject,absence,subject,typical position,particular case,figure,instance,argument,trade gap vpp ppp,figure,example,displaced argument,predicate,predicate widen share,trade gap,argument,ex pect,subject,typical position,position,subject,path relative,argument,certain argument,predicate,infinitival vps,maximum ex,projection,predicate,predicate,new path feature,projected path,maximal,projec tion,argument node,feature,argument,maxi mal projection,direct object,hese feature,non local dependency,troller verb,local model,new feature,conjunction,f1-measure,development set,f1-measure,oint model,joint model,contrast,local model,labeling,parse tree,likely labelings,local model,exact top consistent1,likely local model la belings,simple dynamic program,toutanova,labeling,satisfies,constraint,ment phrase,snp 1-a1 crude oil price vp vbd,pp1-a3,example tree,semantic role annotation,feature,detail,toutanova,feature,several new joint feature,parse tree,candidate argu ment frame,sequence,non-none label,joint model feature,candidate argument frame,internal feature,candi date argument,context,example,figure,candidate argument frame,correct labeling,pp2-a4,sequence,core argument,predicate voice,example,back-off feature,specific argument label,consecutive equal label,argument,annotated phrase type sequence,sequence,core argument,annotated phrase type,phrase type,head word,pp node,head  pos tag,vp node,example,variant,pred icate stem,core argument label,phrase type,phrase type,core argument label,feature cap tures,example,tendency,phrase,second phrase,np phrase,core argument label,phrase type,previous feature,argument,sister,parse tree,argument,word span,feature,robustness,adjacent phrase,parser,joint model,joint model score,local model score,local model,negative example,joint model,likely argument frame,ur final score,mixture,joint model,log probability,scoresrl,scorej,local score,scorej,corresponding joint score,tunable parameter,top candidate labelings,local model,labeling,final score,robustness,parser error,role labeling,correctness,parse tree,argument,constituent,parse tree,correct phrase,problem,native par,recent release,charniak parser,charniak,option,top par,sentence,probability model,parser,alternative par,follow,sentence,probability,parser,fixed predicate,precision recall,development,test  wsj,test  wsj precision recall,overall result,detailed result, wsj test,bottom,closed track,con ll,joint labeling,score scoresrl,final joint model,labeling,arg max,scoresrl,parse tree,al gorithm,absolute increase,f-m easure,future work,information,mul tiple parse tree,6 e xperiments,result,final result,joint model,candidate labelings,local model,alternative par,whole training, con ll-2005 task,mod el,local identifi cation model,minute,local classifica tion model,final development,test result,percentage,proposition,development,improvement,joint model relative,local model, f-m easure,im provement,gold-standard syntactic par,toutanova,relative error re duction,automatic par,upper bound,performance,performance,brown test set,learned model,feature,related domain,reference,carreras,introduction, con ll-2004,semantic role label,proceeding, con ll-2004,eugene charniak,maximum-entropy-inspired parser,proceeding, naa cl,michael collins,discriminative reranking,nat ural language parsing,proceeding, icm l-2000,daniel gildea,daniel jurafsky,automatic la beling,semantic role,computational linguistics,sameer pradhan,wayne ward,kadri hacioglu,james martin,dan jurafsky,shallow semantic parsing,support vector machine,proceed ings,kristina toutanova,aria haghighi,christopher,manning,improves semantic role labeling,proceeding,proceeding,conference,empirical method,natural language processing,massachusetts,october,association,computational linguistics translingual document representation,discriminative projection john,jplatt,kristout,scottyih microsoft,wen-tau yih abstract,document,vector,language enhances machine translation,multilingual text categoriza tion,discriminative training,projection,document,multiple lan,single translingual vector space,variant,pro jections,variant,basic model,docu ments,discriminative,compa rable document pair,similar vector representation,algorithm,parallel document retrieval,wikipedia,europarl document,cross-lingual text classification,reuters,discriminative variant,cpl sa,baseline,difference,performance,re trieval,document, opc method,1 i ntroduction given,growth,multiple language,ternet,natural language processing,language,computer,high performance,text categorization,impor tant,growth,diekema,machine trans,system,sentence,paral lel,comparable document,munteanu,rable document,word-level translation lexicon,text categorization,sentiment classification,multiple language,catego rization,language,developer,language,broad approach,comparable document retrieval,cross-language text catego rization,approach,training,different language,single target language,standard monolingual retrieval,classification algorithm,target language,cross-language system,bag-of-words vector,dimensional vector space,ideally,vector,semantics,document,inde pendent,language,advantage,pre-translation,meaning,document,document,full mt,fast word-by word translation model,projection,low dimensional space,linear projection al gorithms,matrix-sparse vector multiplication,section,accuracy,previous projection,technique,machine translation,technique,coupled,technique,high speed,projection,quality level,word glossing,quality,projection,dis criminative training,difference,tween comparable document,projected vec tor space,difference,eigensystem,diamantaras,us poste rior regularization,ganchev,topic assignment,compara ble document,previous work,extensive work,mono lingual document,vector space,ini tial algorithm,document,bag-of word vector,low-rank gaussians,deerwester,generative model,individual term,document,la tent dirichlet allocation,cross-lingual projection,sim ilar pattern,gaussian model,term-wise generative model,comparable doc uments,multiple language,tuples,document,mul tiple language,experiment,section,use cl-lsi,algorithm,bench mark,previous work,projection,multiple language,result,vinokourov,cross-lingual model,par allel,comparable document,translation dictionary,sharing,language,haghighi,ja garlamudi,domain,par allel document,researcher,al gorithms,discriminative projection,algorithm,diamantaras,projection,signal-to noise ratio,discriminative feature,audio fin gerprinting,burges,structure,algorithm,translin gual document projection,coupled,cl-lsi,section,detail,section,section, cpl sa,cl -ls,section,detail,cpl sa,section,algorithm,dif ferent task,comparable document retrieval,sec tion,cross-language text categorization,section,finding,evalua tions,extension,algorithm,section,lgorithms,translingual document projection,ple language,mathematics,number,document,number,document-term matrix,low-rank gaussian,originally, a s ingular value decompo sition,deerwester,eigendecomposition,relationship,correlation matrix,tween term,rayleigh quotient,vector,matrix,variance,length,good projection,large amount,variance,rayleigh ratio,derivative,projection,eigenvectors,jth-largest eigenvalue,eigen value,variance,top eigenvectors,projection,principal component analysis,difference,cor relation matrix,covariance matrix,practice,document-term matrix,column mean,correlation matrix,covariance ma trix,number,method,document-term matrix,method,practice,dij log2,number,time term,document,total number,document,total number,document,tain term,logarthm,distribution,matrix entry,gaussian, lsa model,cross-language  lsi,application,parallel document,multiple lan guages,single term,multiple lan guages,concate nation,term count accumulates,lan guages,proper noun,element,number,time term,document,language,number,document term,total number,document,language,cl-lsi,catenated document,model term,document vector,language,oriented principal component analysis,limitation,cl-lsi,generalization,signal covariance matrix,variance,signal pro,variance,signal-to-noise ratio,derivative,rayleigh quotient,respect,projection,eigenproblem,local minimum,available parallel code,specialization,noise covariance matrix,signal-to-noise ratio,signal,empiri cal covariance,spherical white noise,projection,appropri ate,multilingual document projection,multilingual document projec tions,projected covariance,doc ument vector,language,distance,comparable document,framework,discriminative pro jections,covariance matrix,document,signal covariance,meaning,document,language,projection,covariance matrix,covariance matrix,differ ences,comparable document,covariance,lat ter covariance,projection language,weighted document term matrix dm,language,signal covariance matrix,language,column,noise covariance matrix,language,document-term matrix,number,language,matrix,top gener,eigenvectors,projection matrix,regularization term,empirical sample,comparable docu ments,entire space,translation,system,test set,safety,regularizer,vari ance,development set,section,vector,data set,dimensionality,final test,tech nique,cross-language document model,vinokourov,lin ear projection,language,projection,corpus,language,linear projection,top generalized eigenvectors,system,e maxim,com parab le pair sf igure,projection,variance,document,distance,matrix,cross-correlations,projection,matrix,autocorrelations,projec tion minimizes,covariance matrix,di mension,vocabulary size,document vector,language,regularization term,performance,validation,matrix,language,projection,cross-covariance,projected vector,minimiz,definition,advantage,information,comparable document,section,eigenvectors,length,vocabulary,language,projection,language,eigenvectors,section,vocabulary size,language,information,perform bet ter,addition,compa rable document,vector,vector,low euclidean distance,latter,algorithm,projection,cross-language topic model,baseline generative model,cl-lsi,baseline joint,poly-lingual lda model,graphical model, jpl sa,figure,language,lan guages,graphical model, jpl sa,bottom,document di,sequence,cross-language topic,dis tribution,mod el,language,vocabulary,word type,language,language,symmetric dirichlet,topic specific word distribution,generative process,corpus,paired document d1i,lan guages l1,next paragraph,document,distribution,symmetric dirichlet,doc uments d1i,document,first pick,multinomial distribution,word token,topic-specific word distribution,probability,word w11,topic assignment,com mon topic vector,difference, jpl sa model,poly-lingual topic model,vocabulary,lan guages,topic-specific word distribution,vocabulary,topic-specific word distribution,language,cl-lsi model,document,language,document,document,difference,poly-lingual  lda model,bayesian inference,inference,ference method,asuncion,hyper-parameters,inference method,initial experiment,bayesian versus  map inference,parallel docu ment retrieval, jpl sa,result,practice,baseline model,poly lingual  lda,experiment,coupled probabilistic latent semantic analysis, jpl sa model,comparable document,parameter,probability,assumption,comparable document retrieval,topic model,similar topic distri butions,document, jpl sa model,common topic vector,english,foreign document,topic assignment,english document,topic assignment,foreign doc ument,difference,appar ent,document,different length,topic vector,document,document,shorter document,little weight,document,graphi cal model, cpl sa,bottom,fig ure,figure,topic vector,document,language,log-likelihood,regularization term,topic assignment,correspond ing document,poste rior regularization,ganchev,linear constraint,expec tations,topic assignment,document,linked document d1,expected fraction,expected fraction,document,z2 denote vector,topic assignment,document d1,dimensionality,length,document,posterior distribution,hidden topic assign ments,property,expected fraction,constrained space,objective function,log-likelihood,simulta,kl-divergence,desired distribution,posterior distri bution,objective function,single document pair,final corpus-wide objective,document-pairs,probability,parameter,dirichlet prior,expected proportion,doc uments,ganchev,pa rameters,em-like algorithm,document pair,posterior distri bution,hidden variable,kl projection,constraint set,respect,projec tion,m-step,projection,baseline  jpl sa, cpl sa model,projection step,iteration,task performance,velopment, jpl sa model,peak accuracy,iteration,iteration,iteration,number,frequency,similar frequency,initialization,performed random initialization,concentration parameter,performance,region,hyper-parameter val ues,convergence,formance,different value,3 e xperimental validation,discriminative projection,established cross-language model,introduction,retrieving comparable document,corpus,classifier,language,test set,sensitivity,dimensionality,projection,development set,training,evaluation,various algorithm dis,full machine translation system,document projec tions, cpl sa,matrix multiplica tion,number,distinct word,document,dimensionality,indexed document,memory,logarithm,second,2000-dimensional space,41k word,second,word-by-word operates,second,contrast,chine translation,second,magnitude slower,total training time,comparable document,minute,8-core  cpu,dimension,minute,iteration,cpl sa,minute,factor,iteration,retrieval,comparable document,comparable document retrieval,doc ument,language,cor -3f, cpl sa,perform,single em iteration,test time,document,language,document,vector space,com parison,vector comparison,experiment,cosine sim ilarity,vector,document, jpl sa, cpl sa model,document,topic vector,compute distance,probability vector,mapping,vector,em iteration,folding-in,hofmann,single em iteration,formance,distance,l1-norm,differ ence,jensen shannon divergence,topic vector,europarl data set,document,english,spanish,wikipedia article,english,spanish,con tain interlanguage link,wikipedia community,language,europarl data set,doc uments,training,document,devel opment,document,final test set,document,speech,sin gle speaker,wikipedia set,training document,development document,final test set document,corpus,document,frequent term,fre quent term,stemming,folding,ass performance,document,english,possible document,span ish,vice versa,true comparable,clos est,test set,mean reciprocal rank,average per formance,retrieval direction,dimensionality,projection,development set,figure,section,document,dev section,document,test section,document,dimension,development set,algorithm,final test set,regularization,europarl,wikipedia,figure,mean reciprocal rank versus dimension,eu roparl figure,mean reciprocal rank versus dimension,wikipedia,figure,projec tion method,word-by-word transla tion method,word-by-word,refers,cosine distance,word-by-word translation model,spanish document,word-by-word translation model,europarl training set,probability matrix,english word,spanish word,document,translated document vector,probability matrix,development set,tf vector,vector,english training set,corpus,figure,dimensionality, wbw translation refers,dimensionality,monolingual  lsa,overall ordering,dif ferent,europarl,wikipedia development datasets,discriminative model,corresponding generative one,ca v cl -ls,lsa  v  jpl sa,datasets,fast-translation,projection method, cpl sa outperform cl -ls,dimension, jpl sa,setting,word-by-word translation model,whereas,wikipedia,result,final test set,dimensionality setting,development set,fi nal result,experiment,unpaired t-test,bon ferroni correction,algorithm,accuracy,p-value threshold,sig nificance,accuracy,superior algorithm,boldface,wikipedia,europarl,ad ditional baseline model,refers,cosine distance,english document,vocabulary term,wikipedia,comparable doc uments,share many common term,co sine distance,untranslated document,reasonable benchmark,final europarl result,parallel document,narrow europarl domain,dimensionality reduction method,parallel data,discriminative training,additional error reduction,parallel document retrieval,europarl speech,english,spanish,training,test set,accuracy,document,length,accuracy,document,length,final wikipedia result,development,result,problem,wikipedia,doc uments,wikipedia,degree,parallelism,doc uments share,main topic,different number,sub-topics,training data,linked document,projection method,word-by-word translation model,setting,out-of-domain parallel data,europarl,disadvantage,good coverage,vocabulary,wikipedia train,sentence-aligned transla tions,projection method,outperformed word-by-word trans lation,topic correspondence,comparable docu ment pair,noisy setting, pls a-based model, jpl sa,cl-lsi,untranslated baseline,diverse vocabulary,het erogenous wikipedia collection,sign importance weight,topic model,word count,weighting,use ful,wikipedia,example,untranslated matching,raw word count,test set,hierar chical topic model,topic-specific word,overall conclusion,outper algorithm dimension accuracy  mrr,cpl sa,jpl sa,test result,comparable document retrieval,europarl,boldface,significant superior result,algorithm dimension accuracy  mrr,cpl sa,jpl sa,test result,comparable document retrieval,wikipedia,boldface,result,document retrieval method,fast machine translation,docu ments,discriminative projection method,generative counterpart,cross-language text classification,second task,text categorization sys tem,language,document,mul tilingual reuters collection,english spanish language pair,collection,news article,english,spanish,portage translation sys tem,english news corpus,document,training,document,develop ment,document,en glish training document,comparable training data,entire spanish news corpus,document,cross-lingual projection,portage,data set,already-processed document vector,related method, cpl sa re quire,performance,clas sification accuracy,disjoint category la bel,minimal bias,neighbor,cosine distance,tween vector,classifier,tech niques,language,language,algorithm,english,english news,op timal dimension,devel opment set,accuracy,english classification,english-to spanish classification,algorithm dim,english spanish accuracy accuracy full mt,full mt,test result,cross-language text categoriza tion,test classification accuracy,superior al gorithms,bonferroni-corrected test,boldface,result,word-by-word translation,document,english,vector,document,section,word-by-word translation,idf vector,translation probability matrix,europarl,word-by-word translation,full translation,spanish document,full translation, lsi model,english training set,full translation,full translation,method,word-by-word translation fol,iscussion,extension,language,memory,computation time,number,language,large vocabulary,researcher,problem,distortion discriminant analysis,large generalized eigensystem,future work,document,many language,spherical admixture model,reisinger,hierarchical generative model,tf-idf representation,similar model, cpl sa,future work,5 c onclusions,different method,discriminative projection, cpl sa,method,artificial concatenated document,docu ments,multiple language,constraint,comparable document,similar loca tions,projected space,technique,accuracy,run-time,large data set,pre-processing step,large-scale comparable document retrieval,cross-language text categorization,reference massih-reza amini,nicolas usunier,cyril goutte,application,multilingual text categoriza tion,advance,neural information processing system,arthur asuncion,max welling,padhraic smyth,yee whye teh,inference,topic model,proceeding,uncertainty,ar tificial intelligence,lisa ballesteros,bruce croft,dictionary method,cross-lingual information retrieval,proceeding,international  dex a co,database,expert system application,andrew,jordan,john lafferty,latent dirichlet alocation,journal,machine learning research,burges,soumya jana,distortion discriminant analysis,audio fin,speech,audio processing,scott deerwester,dumais,george,furnas,thomas,landauer,richard harshman,latent semantic analysis,journal,american society,information science,diamantaras,cipal component neural network,theory,appli cation,wiley-interscience,dumais,letsche,michael,littman,thomas,landauer,automatic cross language retrieval,latent semantic indexing,aaa i-97 spring symposium series,cross-language text,speech retrieval,dumais,performance,retrieval,technical re port tm-arh-017527,bellcore,pascale fung,lo yuen yee,ir approach,new word,compa rable text,proceeding,kuzman ganchev,joao graca,jennifer gillenwater,ben taskar,posterior regularization,latent variable model,technical report m -ci s-09-16,university,pennsylvania,joao graca,kuzman ganchev,ben taskar,expectation maximization,posterior constraint,roweis,edi tor,advance,neural information processing sys,aria haghighi,percy liang,taylor berg-kirkpatrick,dan klein,bilingual lexicon,monolingual corpus,word-dependent transition model,word alignment,statistical machine translation,statistical mt work shop,thomas hofmann,probabilistic latent semantic analysis,proceeding,uncertainty,artificial intelligence,jagadeesh jagarlamudi,multilingual topic,unaligned compara ble corpus,david mimno,wallach,jason naradowsky,andrew  mcc allum,polylingual topic model,proceeding,empir ical method,natural language processing,dragos stefan munteanu,daniel marcu,machine translation performance,non-parallel corpus,computational linguistics,douglas,diekema,cross language information retrieval,martha williams,editor,annual review,bo pang,lillian lee,shivakumar vaithyanathan,sentiment classification,ma chine,technique,reinhard rapp,automatic identification,word translation,unrelated english,german cor pora,proceeding,joseph reisinger,austin water,bryan silverthorn,raymond,mooney,spherical topic model,nicola ueffing,michel simard,samuel larkin,howard johnson,workshop,alexei vinokourov,john shawe-taylor,nello cris tianini,semantic representation,cross-language correlation analysis,becker,obermayer,editor,ad vances,fridolin wild,christina stahl,gerald stermsek,gustaf neumann,parameter,effective ness,automated essay,pro ceedings,internaional computer-assisted ass ment conference,duo zhang,qiaozhu mei,chengxiang zhai,cross-lingual latent topic extraction,uppsala,sweden,association,computational linguistics,proceeding,conference,empirical method,natural language processing,seattle,washington,18-21 october,association,computational linguistics regularized minimum error rate training michel galley microsoft research mgalley microsoft,com chris quirk microsoft research chrisq microsoft,com colin cherry national research council colin,kristina toutanova microsoft research kristout microsoft,preferred method,linear parameter,machine translation system,significant issue,unregularized learner,second,non-convex loss func tion,number,parameter increase,ad dress,addition,regularization term, mer objective function,standard regularizers,scale invariance,objective function,regularizers,modification,present method,search,search,large parameter space,new direc tion,algorithm,gradient,exact line search,experiment,feature,extension, mer yield re sults,learner,large feature set,ntroduction minimum error rate training,decade,superior training method,small number,linear model parameter,machine translation system,prior work,maximum likelihood criterion,technique,many research,commercial mt system,variant,lattice,macherey,hypergraphs,benefit,approximation error,n-best list,primary advantage,evaluation,surrogate loss,optimal line search,several potential difficulty,number,feature,non-convex loss function,reg ularization,challenge,researcher,lin early decomposable approximation,evaluation,chiang,hopkins,cherry,foster,correspond,optimization problem,rate regularization,recent work,chiang,thousand,thousand,feature,mt quality,weight,margin-based approximation,simulated datasets,hopkins,conventional  mer,reasonable parameter vector,smooth loss function,real data, pro method,small feature set,number,feature increase,advantage,shortcoming,regularization,search,regularization term, mer objective function,common regularizers,regularizers, mer objective function,weight vector,predic tions,linear model,error count,regularization penalty,linear model weight,first contribution,iou form,regularization,scaling problem,regularization,scale insen sitive,new parameterizations,regularization,regularization,scale-senstive linear transforms,original linear model,addition,efficient method,regularization,exact line search,regularizers,meth od,true optimum,regularized objective function,high-dimensional space,gradient,eisner,search direction,line search,direction finder,serious concern,hopkins,optimum,synthetic linear objective function,hopkins,experi ments,search algorithm,coordinate ascent,powell,algo rithm,powell,random direction set,experimental condition,problem,1000-dimensional space,result,combination,reg ularized objective function,gradient-informed line search algorithm,large number,feature,experiment,feature,extension,mer yield result,hopkins,parameter,method,large feature set,nregularized  mer tpr ior,standard unregularized  mer,tences,tuning set,translation,linear model,model parameter,feature function,hidden state,derivation,phrase segmenta tion,alignment,feature vector,loss function,translation hypothesis,reference translation,error surface,equation,approximation,true error surface,mt decoder,quality,approximation,hypothesis space,hypothesis list,initial parameter vector,parameter estimation,alternate,cumula tive,change,hypothesis space,subse quent work,macherey,lattice,crucial observation,unsmoothed error count,equation,piecewise con stant function,enabled och,line search,optimum point,search,dimension,sequence,line optimization,variable set,search direction,convergence criterion,point wt,direction dt,iteration,probable translation hypothesis,candi date translation c,function,equation,efficient exhaustive computation,function,upper envelope,model score function,error count,piecewise constant function,crease,change,optimum,equation,whole corpus,sentence-level piecewise constant function,sentence,piecewise con stant interval,corpus-level error function,optimum,interval,pa rameters,method,global dimensional search,algorithm,aforementioned exact line search algo rithm,powell,method,powell,coordinate ascent,recent work,random search direction,macherey,novel direction finder,maximum-bleu optimization,gradient,direction, ble score,3 r egularization, mer tbe cause  mer,large number,parameter,addition,regularization term,objective function,conventional approach,objective function,penalty,regularization,following objective function,assumes,sufficient statistic,consideration,sentence,popular evaluation metric,papineni,regularizer,conjunction,log likelihood objective,regularization term,equation,objective,distinc tion doesn,impact,practice,step size,current direction mer,figure,example  mer,coordi nate,piecewise constant function,function,piecewise constant,point discontinuity,regularization term,free param eter,strength,regularization penalty,similar regularizers,conjunction,constant force,vec tor,non-zero component,number,non-zero component,weight vector,preference,sparse vector,geometrically,parabola,absolute value function,impulse function,original formulation,equation,piecewise con stant representation,function,step size,direction,ularization term,function,piecewise linear,piecewise,potential impulse jump,dis tinct choice,regularizer,figure,effect,keshet,problem,equation,output,underlying linear classifier,error count,regularization,reg ularization,op timizer,function,regularization term,special treatment,linear transforms,weight vector,vector,regu larization term,vector,free parameter,renormalization,regularization,towards,weight vector,feature,core feature,chiang,system,requirement,feature,overfitting,regularization,overfit parameter vector,purpose,regularization term,transformation,observation,d-parameter linear model,equation,degree,freedom,component,non-zero constant,others,new linear model re,modeling power,free parameter,dimensional vector,effect,linear model prediction,weight vector,contrast,problem,exact line search,regularization,regularized error surface,change,line search algorithm,briefly mention,regularizer,ramp loss objective function,section,aspect,global search algorithm,coordinate ascent,powell,di rections,unregularized mer,line search,regularization term,guar anteed,optimum,objective function,point wt,direction dt,line search iteration,optimum,opt corresponds,regularization,optimum,intersection,upper enve lope,discontinuity,error surface,difference,error count,segment,final step,line search,optimum,equation,con stant,segment,segment point,optimum,left edge,right edge,middle,vertex,parabola,segment,optimum,derivative,regularization term,easy closed-form solution,closed-form solution,time pro portional,com -4w,optimum,left edge,right edge,segment,small relative distance,segment,former case,objective value,putation,equation,segment,con struction,segment,upper envelope,regularization,minimiza tion,0-norm,np-hard,mahata,optimization,line search,segment,equation,coordinate,method,equation,intersection point,coordinate hyperplanes,optimal point,segment,segment,hyperplanes,objective function,segment,entire segment,4 d irection,obstacle,many dimension,good search direc tions,problem,dimension,coordinate,global maximum,perfect line search,number,dimension increase,mag nitude,coordinate direction approach,quality,search,suffers,hopkins,direction,steepest ascent,gradient,unfortu,objective function,subgradi ent,direction,smoothed variation,original approximation,variant,flanigan,expected  ble approximation,assum ing hypothesis,log-linear distri bution,parameter value,eisner,proba bility,parameter,vector,feature,scaling parameter,approach infinity,distribution,weight,scoring candidate, ble score,reference length,corpus,candidate length,number,matched n-grams,number,n-grams,candidate,distribution,candidate,expected value, ble score,smooth approximation, ble score,true  ble score,scaling parameter,approach infinity,expectation,approximation,taylor se ries,prior work,second order taylor approximation,eisner,first-order approximation,order taylor approxi mation,expectation operator,gradient,chain rule,gradient,first order approximation,analytical gradient,first-order taylor approximation,finite-difference gradient,firstand second-order approximation,gradient,cosine similarity,measurement,arbitrary point,convergence,2-regularized  mer,final gradi ent,partial derivative,regular ization penalty,equation,component,gradient,gradient,regularization,0-norm,search,search strategy,direc tions,steepest increase,eisner,difference,context,difference,benefit,smooth approximation,likelihood,local opti mum,approximation error,original objective function,second,benefit,exact line search,step size,step size,mer line search,respect,direction,consideration,gradient-based search algorithm oper,gradient gt,first order taylor ap proximation,current scaling pa rameter,search,optimum,line search,improvement,small tolerance threshold,new line search,increase,parameter,cooling schedule,eisner,objective function,estimate,search,new line search,exceeds,inability,current optimum,sharp approximation,mean line search,procedure,full pas,update,improvement,computational complexity,gradient,computational cost,asymptotic complexity,single exhaustive line search,logm log,number,sentence,possible translation,number,feature,sentence,model score,linear function,step size,dot product,overall cost,upper envelope,sentence,equation,linear time,envelope,overall cost,envelope,piecewise constant,sentations,loss function,per-sentence envelope,global representation,direction,implementation,adjacent pair,piecewise smooth loss function representation,single list,log pass,merging runtime,gradient,sentence,probability,gradient,n-gram count,gradient,arithmetic operation suffice,loss value,gradient,gradient,algo rithmic complexity,conventional approach,coordinate ascent,random di rections,runtime,single iteration,gradient finding,expensive part,convex opti mization,course,overall runtime,convex optimization,number,gradi ent evaluation,convergence,empirical comparison,method,special case,difference,prior direction,current direction,individual linear function,number,changed dimension,coordinate ascent,linear function,intercept,equation,translation,prior step size,feature value,prior coordinate,feature value,new coordinate,optimization,speedup,random vector,conjugate direction,non-sparse direction,language pair train tune dev test gb mc,pa r eh rm,datasets,experimental condition,5 e xperimental design following hopkins,experimen tal setup,synthetic data,motivation,synthetic data,quality,optimization method,global optimum,hopkins,ob jective function,vector,search,real translation setting,learner,simple scenario,little hope,synthetic data experiment,hopkins,dimen sionality,feature,random number,interval,synthetic dataset,source,sentence,trans lation,hypothesis,sentence,hypothe si,dot product,gold weight vector,pseudo-bleu score,transla tion,model score,leu  score,translation,model score,sentence, a b leu ,normalization,impact,search,result,translation experiment,multi stack phrase-based decoding,report result,feature set,non-linear feature,gradient boosting machine,toutanova,objective function,piecewise constant,plateau containingw,optimal value,function,feature,cherry,feature set,sparsehrm,distinct experimental condition,next paragraph,sparsehrm augment baseline,relative frequency,lexicalized phrase translation score,translation direction,language model feature,language pair,distortion penalty,phrase count,reordering feature,experimental condition,phrase table,mum phrase length,reference,training set,phrase table,language model,tune set,optimization,dev set,hyperparameters,regularized  mer,test set,fi nal result,experimental condition,weight,base feature set,test datasets,500-best list,result,rerank ing performance,different feature set,optimization method,lower-cased ble,papineni,feature,toutanova,feature,decision tree weak learner,fea tures,phological attribute,corpus,sen tence pair,hong kong portion, ldc data, nis t mt evaluation,test set, nis competition,4-gram language model,xinhua portion,english gigaword corpus,target side,bitext,dataset,technical domain,software man uals,language pair,language model,large model,billion,language model,target side,parallel training,sparsehrm set,cherry,sparse,feature,phrase,fea tures,indicator,orienta tion,derivation,lexical content,word cluster,frequent word,chinese english,system,mt evaluation,bl eu number,feature, ble gradient random directionspowell,co sin number,feature, ble gradient random directionspowell,ascent figure,change, ble score,cosine similarity,gold weight vector,number,feature increase,noisy synthetic experiment,gradient-based direction,method,increase,number,dimension,direction finder,optimum,language model,target side,parallel training data,arabic,chinese,chinese system development set, nis mt05 evaluation,material, nis training corpus,cover newsgroup,weblog domain,experiment,synthetic data scenario,previous section,hopkins,optimization task,af ter,pseudo-bleu score,standard deviation,result,noisy data,conclusion,hopkins,standard mer,many dimension,experiment,gradient direction finder,section,direction finder,bl eu line search iteration, ble gradient, ble gradient coordinate ascent,ascent figure,comparison,convergence,coordinate ascent, ble direction finder,noisy experimental setting,dimension,effectiveness,noisy data,figure,decrease,cosine,search algorithm,decrease,search error,addition,true optimum,figure,convergence,ascent,experimental result, gbm feature,section,koehn-style coordinate ascent,optimizer featur,regularization,gradient-based direc tion finder,variant,single starting point,uniform weight,additional random,random walk,opti mizer,hyperparameters,held-out set,parameter,regularization penalty,pa rameter,sentence-level ver sion,parameter,corpus-level length,reference,latter scaling parameter,gradient-based direction finder,following strategy,optimization,optimum,coordinate ascent,gradient direction finder,optimum improves,coordinate direction,search,tune dev test feat,tune dev test mer,pro w0,dimension, gbm feature,model parameter,tune set,regularized mer,different hyperparameters,regularization weight,experimental condition,performance,bl eu regularization weight, ble gradient coordinate ascent figure,different value,regularization weight,comparable result,hyperparameter,length,problem,system,sentence,hyperparameter,regularization penalty,translation length,dev dataset,tune set,comparison,system,discrep ancy,length,hyperparameter,length,manner,dev set,offer several finding,competitive result,small set,feature,large set,feature,test set,unregularized  mer,performance,increase,test set,result,unregularized  mer,regular,number,feature,gbm experimental setting,figure,larized  mer,gradient direction finder,coordinate ascent,regularization setting,algorithm,coordinate ascent,good direction finder,method,suboptimal regularization parameter,result,sparsehrm feature, gbm feature,version,large set,feature,question,large feature set,complexity analysis,section,dependence,number,feature,optimization time,system,chinese-english, gbm feature, pro optimizer,minute,average,gradient direction finder,minute,average,account,chinese-english,sparsehrm feature,average optimization time,method,average,experimental setup,cherry,sparse  hrm,decoder,scenario,improvement,cherry,tune dev test feat,tune dev test mer,mer uniform,mer w0,pro w0,dimension,sparsehrm feature, mer ex periments,point w0,uniform vector,first place,disadvantage,good initializer,context,non-convex op timization,non-convex problem,machine learning,deep neural network,word alignment model,ini tializers,decent performance,extensive research,problem,good initializers,word alignment,common practice,search,non-convex optimization problem, ibm model,solution,simpler model, ibm model,work mer,extension,target,ex tensive research,macherey,galley,recent work,composable approximation,evaluation,eisner,chiang,hopkins,gimpel,cherry,foster,surrogate loss function,reg ularization term,previous work,penalty,example,pre-trained dnn,shallow network,performance,shallow network,pre-training,weight,context,related effect,smooth objective function,regular set,parameter,approach,new research,direction,smooth surrogate loss function,method,better direction,tendency,indirect way,tuning set,line search,direction,separate dataset,8 c onclusion,number,feature,thanks,regularization,direction finder,search,increase, ble score,result,un derstanding,standard  mer,number,feature,analysis,hopkins,difference,tween  mer,optimization,surrogate loss function,acknowledgment,anonymous reviewer,helpful comment,suggestion,comparison,performance,performance degrades,reference peter,vincent,della pietra,stephen,della pietra,robert,mercer,mathematics,statistical machine translation,parameter estimation,comput,linguist,daniel cer,dan jurafsky,christopher,manning,regularization,search,minimum error rate training,proceeding,third workshop,statistical machine translation,colin cherry,george foster,strategy,statistical machine translation,pro ceedings,conference,north american chapter,association,computational linguis tic,human language technology,colin cherry,phrase,translation,sparse feature,proceeding,conference,north american chap ter,association,computational linguistics,human language technology,david chiang,yuval marton,philip resnik,large-margin training,structural translation feature,proceeding,con ference,empirical method,natural language processing,david chiang,kevin knight,wei wang,new feature,statistical machine translation,proceeding,human language technology,annual conference,north american chap ter,association,computational linguistics,david chiang,hierarchical phrase-based transla tion,computational linguistics,jeffrey flanigan,chris dyer,jaime carbonell,large-scale discriminative training,statistical ma chine translation,held-out line search,pro ceedings,conference,north american chapter,association,computational linguis tic,human language technology,michel galley,chris quirk,optimal search,minimum error rate training,proceeding,conference,empirical method,natural language processing,kevin gimpel,ramp loss minimization,machine translation,proceed ings,conference,north american chapter,association,computational linguis tic,human language technology,li deng,maximum,ble training,phrase,lexicon translation mod el,proceeding,50th annual meeting,association,computational linguistics,long paper volume,mark hopkins,jonathan may,rank ing,proceeding,conference,empir ical method,natural language processing,mahata,approximate l0 norm minimization algorithm,compressed sen,acoustic,speech,signal processing,philipp koehn,hieu hoang,alexandra birch mayne,christopher callison-burch,marcello federico,nicola bertoldi,brooke cowan,wade shen,christine moran,richard zen,chris dyer,ondrej bojar,alexandra constantin,evan herbst,open source toolkit,statistical machine translation,demonstration session,philipp koehn,pharaoh,beam search decoder,phrase-based statistical machine translation model,shankar kumar,wolfgang macherey,chris dyer,franz och,efficient minimum error rate train ing,minimum bayes-risk decoding,translation hypergraphs,lattice,proceeding,joint conference,47th annual meeting,international joint conference,natural language processing, afn lp,hugo larochelle,yoshua bengio,louradour,pascal lamblin,strategy,deep neural network,taskar,end-to-end discriminative approach,chine translation,international conference,com putational linguistics,association,franz josef och,method,automatic evaluation metric,machine translation,proceeding,20th international conference,computational linguistics,wolfgang macherey,franz och,ignacio thayer,jakob uszkoreit,lattice-based minimum error rate training,statistical machine translation,pro ceedings,conference,empirical method,natural language processing,david  mca llester,joseph keshet,generaliza tion bound,consistency,latent structural probit,ramp loss,advance,robert,chris quirk,random,minimum error rate training,statistical machine translation,proceeding,international conference,computational linguistics volume,preslav nakov,francisco guzman,stephan vogel,sentence-level  ble,yield short translation,proceeding, col ing ,franz josef och,hermann ney,discriminative training,maximum entropy model,statistical machine translation,proceeding,annual meeting,association,computational linguis tic,franz josef och,minimum error rate training,statistical machine translation,proceeding,annual meeting,association,computa tional linguistics,kishore papineni,salim roukos,todd ward,wei jing zhu,method,automatic evalu ation,machine translation,kishore papineni,discriminative training,linear programming,proceeding  iee e in ternational con ference,acoustic,speech,volume,powell,efficient method,minimum,function,several variable,derivative,william,teukolsky,william,vetter ling,flannery,numerical recipe,scientific computing,cambridge university press,edition,antti-veikko rosti,bing zhang,spyros matsoukas,richard schwartz, ble training,sys tem combination task,proceeding,sixth workshop,statistical machine translation,jason eisner,minimum risk,log-linear model,proceed ings,main conference poster session,kristina toutanova,byung-gyu ahn,non-linear feature,machine translation,machine,proceeding,annual meeting,association,computational linguistics,volume,short paper,taro watanabe,jun suzuki,hajime tsukada,hideki isozaki,large-margin training,sta tistical machine translation,proceeding,joint conference,empirical method,natu ral language processing,proceeding,conference,empirical method,october,association,computational linguistics asymmetric feature,human generated translation sauleh eetemadi michigan state university,microsoft,com abstract distinct property,subject,research,linguistics,many year,recent year computational method,lin guistic theory,ba roni,bernardini,many characteristic,comparison,original text,prior research,monolingual feature,original text,contribution,bilingual fea tures,dif ferences,translation direction,linguistic phenomenon,phrase,sentence level,mono lingual statistic,document level,bilingual feature,monolingual feature,prior work,kurokawa,translation direction,1 i ntroduction,many year,linguis tic,pattern,characteristic,translated text,pattern,translationese,volansky,simplification,process,translation,simplification process,several level,example,lexical variety,translated text,rare word,translator,explicit,translation,cultural context,speaker,source language,manifesta tion,pattern,argument,heavy use,cohesive marker,translated text,koppel,normalization,translator,translation,source text,native language,figure,section,difference,frequency,translated text,fellow,example,translated english,research,volansky,cohesive marker,translated text,past year,technique,standard machine,algorithm,baroni,bernardini,bayesian logistic regression,koppel,classifier,following task,specific language,original,translated text,source language,translation,text chunk pair,language,direction,translation,stated motivation,empirical validation,translationese,volansky,statistical machine trans lation,knowledge,trans lation direction,training,test data,lember,figure,europarl word cloud data visualiza tion,original,lembersky,lember,customized version,europarl,mehler,processed version,hansard,kurokawa,translated versus original text,limited resource,translation direc tion,account,statistical ma chine translation system,translation quality,lembersky,statistical machine translation,trans lation direction information,several factor,limited labeled data,amount,language,domain,significant improvement,current meth od,translationese detection,different corpus,example,classifier,europarl corpus,in-domain accuracy,out-of-domain accuracy,text chunk size,high accu racy,translationese detection,koppel,similar task,sentence,word cloud,word cloud,tm package,fellow,europarl parallel data,translation di rection,mehler,hucompute,accuracy drop,percentage point,kurokawa,detection accuracy drop,reduction,chunk size,parallel data,sentence level,small chunk,detection method,suitable,figure,effect,chunk size,translationese detection accuracy 2m,limitation,sentence-level classification accuracy,non-domain-specific bilingual feature,sentence level,addition,accuracy,fine-grained feature,theory,cover new linguistic phenomenon,translation process,fast linear classi fier,online learning,vowpal wabbit,langford,hansard french english dataset,kurokawa,training,test data,experiment,distinct pattern,translationese,ba roni,bernardini,computational method,high accuracy,prior work,in-domain accuracy,chunk-level,feature,volansky,phenom ena,domain,example,figure,content word,commission,council,classification,gen eral linguistic phenomenon,reproduction,result,koppel,function word,feature,logistic regression classifier,description,text chunk,result,ac curacy,text chunk size,figure,aligned sentence pair,corpus,average human performance,precision,recall,similar task,test subject,domain,domain-specific lexical fea tures,baroni,bernardini,gen eral feature,high in-domain accuracy, pos tag,lexicalization,function word,baroni,bernardini,kurokawa,feature,bilingual feature,feature,parallel chunk,original,kurokawa,feature,monolingual feature,translated text,translation phenomenon,sentence level detection accuracy,report,percentage point drop,accuracy,chunk level,level classification,ilingual feature,translation direction classification,linguistic phenomenon,trans lation process,direction, pos tag  mtu,minimal translation unit,sentence pair,source,target word,following condition,menezes,alignment link,previous rule, pos tag,linguistic struc tures,linguistic structure,content word, pos tag,function word,language, pos  mtu,parallel corpus,parallel corpus,source,corpus,corresponding  pos tag,word-aligned sentence pair,word-aligned sen tence pair,source order,unigram,bi-gram,order gram feature,sequence,pos  mtu,example,sentence pair,figure,following  pos  mtu,distortion,addition,mapping,linguistic structure,interesting phenomenon,reordering,linguistic structure,translation,hy pothesis,fixed-order,free-order language,target,source,tone translation,fixed order language,re-ordering,grammaticality,target,pattern,distortion,tag  mtu feature,absolute distortion,word position difference,source,tar get, hmm distortion,word position difference,target,target,distor tions,sparsity,4 e xperimental setup,translation direction detection task ex,section,fast linear classi fier,online learning,vowpal wabbit,langford,classi fication feature,section,figure,sentence level translation direction detection precision,different feature,n-gram length,parallel corpus,sen tence pair,direction,sentence,language,customized version,europarl,mehler,con tains sentence pair,many language pair,language pair,sentence pair,direction,sentence,english,canadian hansard corpus,requirement,sentence pair,french,sentence,english,french,kurokawa,hansard data,training classifier, hmm word alignment model,feature,parallel text, wmt english-french corpus,preprocessing,feature extraction,ratio filter,english-french sentence pair,french-english sen tence pair,stanford  pos tagger,toutanova,manning,english,french side,corpus, hmm alignment model,4a character n-gram language model,language,source,side text,annotated language,5d uplicate sentence pair,hansard corpus, pos tag,difference,word breaking, pos tagger tool,word alignment tool,mismatch,simplicity,entire sentence pair,token mismatch, pos tag,sentence pair,direction,direction,balanced dataset,number,english-french sentence,sentence pair,direction,result,experiment,translation direction detection task,several result,unigram feature,accuracy,feature,pos minimal translation unit,dis tortion,accuracy,ad vantage,bilingual feature,prior work,monolingual feature,order feature,in-domain accuracy,advantage,low-order bilingual feature,cross-domain classification,description,english  pos tag,marcus,abeill,ecoises,ecoises,argent suffirait,number,feature ap,french,6 a nalysis,interesting aspect,feature,linguistic analysis,fea tures,pos  mtu feature,neg ative weight,context,common phrase,member,canadian parliament,underlying linguistic phenomenon,canadian parliament,plural noun,english,masculine form,single plural noun,en glish,english doesn,masculine,complete form,feature,word alignment model,dis courage one-to-many alignment,first noun,conjunction,7 c onclusion,future work,new feature,transla tion direction detection,leverage word align ment,source  pos,target  pos, pos  mtu,powerful tool,linguistic interaction,lan guages,translation process, pos mtu,lexical feature,corpus,domain,feature,high weight  pos  mtu feature,classification,training data,multiple domain,experiment,future work,multiple domain,cross-domain scalability, pos -mtu,addi tion,linguistic phenomenon,translation direction,statistical machine translation quality,future direction,sentence level translation direction detection,statistical machine translation output quality,investi gation,linguistic interpretation,individual feature,op posite translation direction,new linguistic phenomenon,translation process,author,lee schwartz,classification feature,lin guistic insight,thoughtful comment,detailed feedback,reviewer,reference anne abeill,ois tou ssenel,treebank,anne abeill,editor,treebanks,volume,speech,language technology,netherlands,mona baker,corpus linguistics,transla tion study,implication,application,technology,honour,john sinclair,marco baroni,silvia bernardini,new approach,machine,difference,literary,linguistic computing,ian fellow,wordcloud,word cloud,pack age version,zahurul islam,alexander mehler,cu tomization,europarl corpus,translation study,philipp koehn,europarl, a p arallel corpus,statistical machine translation,conference proceeding,tenth machine translation sum mit,phuket,moshe koppel,noam ordan,dialect,proceeding,nual meeting,association,computational linguistics,human language technologies-volume,association,computational linguistics,david kurokawa,cyril goutte,pierre isabelle,automatic detection,impact,machine translation,twelfth machine translation sum mit international association,machine transla tion,association,machine transla tion,america,angford, a s trehl,vowpal wabbit online learning project,gennadi lembersky,noam ordan,shuly wint ner,translation model,lationese improves,proceeding,13th conference,european chapter,associ ation,computational linguistics,association,computational linguistics,gennadi lembersky,noam ordan,shuly wint ner,language model,machine trans lation,computational linguistics,gennadi lembersky,noam ordan,shuly wintner,statistical machine translation,translation model,mitchell,marcus,mary ann marcinkiewicz,beatrice santorini,large anno,corpus,penn treebank,linguist,chris quirk,arul menezes,phrase,conventional wisdom,statistical machine translation,proceeding,main conference,human language technol ogy conference,north american chapter,association,association,computational linguistics,kristina toutanova,christopher,manning,knowledge source,maximum entropy part-of-speech tagger,pro ceedings,joint  sig dat co nference,empirical method,natural language process ing,large corpus,conjunction,annual meeting,association,associa tion,computational linguistics,stephan vogel,hermann ney,christoph tillmann,hmm-based word alignment,statistical translation,proceeding,conference,computational,association,computational linguistics,vered volansky,noam ordan,shuly wintner,feature,linguistic computing,page fqt031,human language technology,annual conference,north american chapter,los angeles,california,association,computational linguistics extracting parallel sentence,comparable corpus,document level alignment jason,center,chris quirk,chrisq,kristout microsoft,quality,system,amount,parallel sentence,train ing,recent year,several approach,parallel sentence,comparable data,news article,time period,munteanu,web page,similar structure,resnik,resource,wikipedia,line encyclopedia,article,many language,parallel sentence extraction,document level alignment,observation,parallel sen tence pair,close proximity,feature,additional annotation,wikipedia,feature,induced lexicon model,result,accuracy,sentence extraction,downstream im provement, smt system,1 i ntroduction,statistical machine translation system,parallel corpus,training,ma jor factor,performance,language pair,large amount,parallel data,language pair,research,author,intern ship,microsoft research,domain,parallel corpus,quality,translation,many parallel corpus,news domain,parliamentary proceeding,translation qual ity suffers,system,domain,parallel corpus,semi-parallel corpus,several domain,language pair,cor pora consist,document,language,detailed description,previous work,ex traction,parallel sentence,comparable cor pora,coarse document-level similarity,document pair,paral lel sentence,similar web page,resnik, htm struc ture,munteanu,use publication date,vector-based similarity,bilingual dictionary,similar news article,promising document pair,next step,parallel sentence,seed parallel data,word align ment model,word alignment,word alignment model,classifier,gual sentence pair,parallel,classifier,sentence pair,docu ments,typically,pruning,number,tence pair,method,news corpus,web page,little attention,wikipedia,source,parallel sen tences,wikipedia,annotated article alignment,much work,bilingual lexi con,dataset,adafre,similar sentence,wikipedia article pair,precision,small num ber,extracted sentence,thoroughly investigate wikipedia,viability,comparable corpus,novel method,parallel sentence ex traction,section,multilingual re source,wikipedia,section,fur ther background,previous method,parallel sentence extraction,comparable corpus,approach,global sentence alignment,document,section,approach,previous meth od,datasets,wikipedia,language pair,show improvement,downstream  smt performance,paral lel data,2 w ikipedia, a c omparable corpus wikipedia,wikipedia,online collabo rative encyclopedia,wide variety,language,english wikipedia,article,language edition,article,article,different language,interwiki,valuable resource,parallel sentence,document alignment,interwiki,english wikipedia,non-english wikipedias,wikipedia,markup,useful indica tor,parallel sentence extraction,many hy perlinks,article,valuable source,hyperlink,similar sentence,arti figure,caption,english,spanish cles,interwiki,wikipedia,central source,different language,identification,caption,par allel,minor form,markup,similar content,language,section heading,section,feature,markup,non-parallel corpus fung,cheung,fine-grained description,non-parallel corpus,noisy parallel corpus,document,many parallel sentence,comparable corpus contain topic,document,translation,corpus fung,cheung,examine,bilingual document,wikipedia,special case,aligned article pair,english en try,antiparticle,sentence,spanish,english entry,john calvin,noisy parallel,comparable article pair,wikipedia author,article,language,others,french german polish italian dutch portuguese,number,aligned bilingual article,wikipedia,language,english,content,ar ticles,translation,independent edits,language,3 m odels,parallel sentence extraction,section,method,parallel sentence,ble document,related problem,automatic document alignment,web corpus,number,researcher,resnik,tillmann,corpus,docu ment alignment,problem,detail,method,cor pora,document alignment,aforementioned algorithm,binary classifier,ranker much,previous work,binary classifier,sentence pair,munteanu,tillmann,standard parallel corpus,po itive example,various heuristic,prob lem,munteanu,filter,neg ative example,high length difference,low word overlap,alternative approach,ranking model,sentence,source document,sentence,target document,formulation,problem,class imbal ance issue,binary classifier,binary classifier approach,ranking approach, a m aximum entropy classifier,munteanu,sequence model,wikipedia article pair,par allel sentence,cluster,global sen tence alignment model,phe nomenon,comparable cor pora,global sentence alignment,alignment,church,source,target sentence,source sentence,hidden vari,corresponding target sentence,discriminative  crf,word alignment model,blunsom,feature,feature,category,feature,word alignment,feature,munteanu,feature, ibm model,alignment, hmm word alignment,direction,source,source,feature,alignment,log probability,alignment,number,unaligned word,longest,unaligned sequence,number,fertility,feature,dependent,word alignment model,sentence length feature,alignment,sentence length,length ratio,source,target sentence, a p oisson distribution,feature,difference,relative doc ument position,sentence,aligned article,similar topic progression,feature,sentence pair,binary classifier,ranking model,distortion feature,sequence model,additional dis tortion feature,difference,position,current aligned sentence,feature bin,distance,absolute difference,position,sentence,actual position,feature,wikipedia markup three feature,wikipedia,markup,number,sentence pair,inverse frequency,document,fea ture,image feature,sentence,caption,list feature fire,sentence,indicator feature,negative value,feature,sentence,feature,null align ment,ranker,bias feature,non-null alignment,word-level induced lexicon,common problem,approach,paral lel sentence classification,alignment model,unrelated corpus,low recall,unknown word,candi date sentence-pairs,approach,problem,self-training,munteanu,self trained sentence pair extraction system,new lexical item,parallel sentence,wikipedia,article pair,parallel sentence,many word,phrase,good transla tions,alternative approach,acquisition,parallel sentence extraction,lexicon model,ap proach,unsupervised lexicon induction,compara ble corpus,knight,haghighi,briefly,lex icon model,sentence-extraction,lexicon model,probabilistic modelp,tar get language,source language,article,target,source language,sentence extraction,difference,word pair,small set,annotated wikipedia article pair,source language,source word,context,article pair,source word,corresponding transla tion,target article,word-level annotated article,disjoint,sentence-aligned arti cles,section,following feature,lexicon model,translation probability,translation probability, hmm word align ment model,seed parallel data,probability,direction,log-probabilities,direction,position difference,absolute value,difference,relative position,word w,article,function,edit distance,source,target word,edit distance,different al phabets,determin istic phonetic translation,common alphabet,translation,promising area,improvement,similar source,information,seed lexicon,knight,fea ture space,haghighi,feature,word w,article,article,local context window,several scor,function,translation correspon dence,context, ibm model,seed parallel data,feature,distributional similarity measure,previous work,difference,article pair,distributional similarity,feature,similarity measure,previous work,lexicon induction,source headword,distribu tion,context position,context word v,position,context word,headword,weight,adjacent position,weight,position,weight,likewise,distribution,target word,context, ibm model,seed parallel corpus,cross-lingual context distribution,similarity,word w,jensen-shannon divergence,distribu tions,position,target word,small set,feature function,weight,log-linear ranking model,word-level annotated wikipedia article pair,new translation table plex,summation,occurrence,source,target word,wikipedia article,new translation table,hmm word-alignment model,dis tortion probability,parallel data,sentence extraction model,feature, hmm word alignment model,seed data,restrict,attention,occur rences,rare word,distribution,contribution,context position,word pair,distinct source,tar get word,computational overhead,little impact,final similarity score,new  hmm model,training data,bulgarian,annotated wikipedia article pair,feature weight,bulgarian,word-level,wikipedia article,twenty wikipedia article pair,language pair,bulgarian english,sentence,source language,po sible parallel sentence,target language,target language,experi ments,quality level,sentence,parallel fragment,sentence,paral lel,sen tences,direct translation,experiment,sentence pair,quality,positive example,resulting datasets,research,microsoft,people,wikidownload,europarl corpus, jrc aquis corpus,bulgarian,article title,parallel wikipedia document,trans lations,wiktionary entry,5-fold cross-validation,document pair,language condition,binary classifier,ranker, crf model,paral lel sentence extraction,precision recall,minimum bayes risk,target sentence,correct target sentence,null loss,precision,trade-off, crf model,minimum risk decision rule,summary measure,performance,different level,recall,average precision,online collaborative dictionary,wikipedia,language pair binary classifier ranker  crf avg prec,avg prec,avg prec,average precision,recall,precision,recall,precision,language pair,experiment,wikipedia feature,lexicon feature,ranker  crf avg prec,avg prec,direction,intersected,intersected wiki,intersected wiki lex,direction,intersected,intersected wiki,intersected wiki lex,direction,intersected,intersected wiki,intersected wiki lex,average precision,recall,precision,recall,precision,ranker,language pair,wikipedia feature,lexicon feature,recall,precision,percent,different model,language pair,next set,experiment,effect,wikipedia specific feature,ranker,asymmetric model,di rections,output,intersec tion,result,agreement,asym metric model,machine translation,effec tive,bulgarian-english  crf,regression,wikipedia feature,auxiliary signal,potential par allelism,lexicon-based feature,bulgarian,crf model average precision,language-specific training data,result,exploration,first successful practical application,induced word translation, smt evaluation,present result,context,full ma chine translation system,potential utility,standard phrasal  smt sys tem,testbed,conventional set,phrasal,source,target,source,lexical weighting model,direction,lan guage model,word count,phrase count,distortion penalty,lexicalized reordering model,extracted wikipedia data,standard form,parallel sentence,number,system,language pair,training condition,medium,data condition,downloadable corpus,europarl,german english, jrc acquis,bulgarian-english,additionally,wikipedia article,parallel sentence,medium data condition,data condition,medium data,cludes,broad range,available source,resnik,united nation,phrase book,software documentation,condition,impact,additional parallel sentence,wikipedia,system training data,null loss,estimated precision,percent,precision,percent,characteristic,data set,amount,parallel sentence,comparable corpus,average wikipedia article,handful,parallel sentence,fertile ground,mt system,extracted wikipedia data,impact,broad domain test set,initial experimentation,little  ble gain,in-domain test set,europarl,out-of-domain training data,appropriate phrasal translation,broad domain test set,bing translator,sample,trans lation request,translation,stan dard development,test set,portion,large system,development,language pair,test set,minimum error rate training,final evaluation,new test set,language pair,parallel sen tences,wikipedia article,test data,sentence pair,adequacy,test set,research,microsoft,people,wikidownload,characteristic,test set,system,result,extracted wikipedia data,medium data condition,translation,formance,condition,extracted wikipedia sentence,translation quality,held-out wikipedia article,medium data,wikipedia,quality,large system,wikipedia data,large data condition,substantial improvement,5 c onclusions,first substantial contribution,wikipedia,useful resource,par allel data,sheer volume,extracted parallel sentence,wikipedia,result,wikipedia,construction,several valuable resource,community,research,document pair,edited test set,hopefully,research,wikipedia,resource,machine translation,prior pairwise mod el,ranking approach,sentence pair extraction,ranking approach,problematic class imbalance issue,im proved average precision,simplicity,clarity,sentence alignment,article,substan tial improvement,task accuracy,409 german english spanish english bulgarian english,medium type,sentence,large type,sentence,wiki type,statistic,training data size,language pair,german english spanish english bulgarian english dev,sentence,wikitest sentence,statistic,test data set,language pair training data dev  a t,medium wiki,large wiki,medium wiki,large wiki,medium wiki,large wiki,various training,test condition,first column,minimum error rate training,column,held-out test set,data condition,extracted wikipedia sentence,absolute  ble difference,corresponding system,wikipedia extract,small sample,annotated article,global level feature,learned classifier,language,improvement,comparable corpus,document structure,meta-data,ad dress,question,future work,initial investigation,substantial gain,duced word-level lexicon,combination,sen tence extraction,word pair,respect,seed parallel lexicon,reference,similar sentence,multiple language,wikipedia,proceeding,phil blunsom,trevor cohn,discriminative word alignment,conditional random field,proceeding, l m ercer,mathematics,statistical machine translation,parameter estimation,compu tational linguistics,cheung,multi-level bootstrap,parallel sentence,quasi comparable corpus,proceeding,ternational conference,computational linguistics, w c hurch,word correspondence,parallel text,proceeding,workshop,speech,natural language,aria haghighi,percy liang,taylor berg-kirkpatrick,dan klein,bilingual lexicon,monolingual corpus,proceeding,roy bar-haim ido,ido dagan,bill dolan,lisa ferro,danilo giampiccolo,bernardo magnini,idan szpektor,knight,translation lexicon,monolingual corpus,proceeding, acl workshop,unsupervised lexical acquisi tion,philipp koehn,franz josef och,daniel marcu,statistical phrase-based translation,pro ceedings,edmonton,canada,europarl,parallel corpus,statisti cal machine translation,mt summit,volume,pereira,con ditional random field,probabilistic model,seg menting,sequence data,proceed ings,international conference,machine learning,accurate sentence align ment,bilingual corpus,lecture note,computer science,improv,machine translation performance,non-parallel corpus,computational linguistics,franz josef och,minimum error rate training,statistical machine translation,proceeding,annual meeting,association,computational linguistics,sapporo,kishore papineni,salim roukos,todd ward,wei jing zhu,method,automatic eval uation,machine translation,proceeding,annual meeting,association,computational linguistics,philadelpha,pennsylva nia,automatic identification,word trans lations,unrelated english,german corpus,proceeding, a s mith,parallel corpus,computational linguistics,simple sentence-level extraction algorithm,comparable data,pro ceedings,eam-search extraction algo rithm,comparable data,proceeding,tillmann,word alignment,statistical translation,proceeding,conference,computational,wikipedia,wikipedia,adaptive parallel sentence,web bilingual news collection,pro ceedings, iee e in ternational conference,data mining,proceeding,demonstration session,association,computational linguistics msr  spl,language analysis toolkit  c hris quirk,pallavi choudhury,jianfeng gao,hisami suzuki,wen-tau yih,montreal road   o ttawa,ontario,chrisq,pallavic,hisamis,kristout,mgamon,scottyih,lucyv microsoft,com colin,bstract, msr  spl,toolkit,lan guage analysis,easy access,linguistic analysis tool, nlp group,microsoft research,traditional linguistic analysis tool,part-of-speech tagger,constituency,dependency parser,velopments,sentiment detection,valid morphology,re search, msr  sp lat ,toolkit,web service,broad set,language,ntroduction,availability,annotated data set,community standard,penn treebank,marcus,many research institution,core natural language,component,part-of-speech tag gers,chunkers,parser,many difference,component,noticeable variation,component output,experimental setting,improvement,specific component feature,improvement,differ ently-trained linguistic component,tokeni zation,community,difficulty,task organizer,analysis,task data,instance,bionlp,task organizer,output,num ber,parsers1,system,unfamiliar tool,many community member,downloads, nlp tools2,ac cessibility,replicability,core component,  o ur toolkit,spirit,efficient linguistic tool,course,research,available resource,community,exam ple,valid base form,semantic role analyzer,component,researcher,project, nl component,allow researcher,result,advantage, msr  sp lat ,web service,share new component,on-going basis,functionality,constituency parsing 1 s,description,resource,addition,task data,2 s ee,example,stanford,software,informatics,incubator,apache,syntactic parser, msr  spl attempt,parse tree,penn tree bank specification,marcus,rep resentation,notion,syntactic constituent,instance,sentence,colorless green idea,following parse tree,instance,parse tree,green idea,wall street journal portion,penn treebank,coarse grammar,grammar symbol,series,refinement,fine-grained category,capture,im plicit correlation,split-merge method,petrov,new symbol,new unique symbol label,grammar,original rule,refinement,small amount,random noise,probability,production,new grammar parame ters,accelerated form,roweis,split symbol,contribution,likelihood,original form,parameter,split-merge iteration,optimal accuracy,threshold,minimal impact,development,accuracy,initial coarse pas,length,sentence,search space,coarse parse,chart cell,hollingshead,classifier,constituent,position,instance,constituent seldom end,number,chart cell,runtime,minimal impact,accuracy,dependency,dependency par, msr  spl,syntactic governor,hese dependency tree,output,constituency parser,collins,maximal projection,parent word,child word,parent,semantic role,semantic role labeling component, msr  sp lat ,semantic role,verb accord,propbank specification,palmer,semantic role,broad-coverage shallow semantic analysis,syntax,phenome na,co-reference,quantification,example,sentence,window,window,phrase,window,syntactic role,phrase,sentence,semantic role,actual labeling scheme,numbered argument label,core argument,adjunct-like argu ments,meaning,numbered argument,agent-like role,patient-like role,implementation, srl system,approach,palmer,log-linear model,argument identification,classification,single syntax tree, msr  spl split-merge parser,non-overlapping argument,dynamic programming algo rithm,toutanova,analyzer,sentence boundary,offset,character range,raw form,string,normalized form,close pa rentheses, -lr band  -rr,ambiguity,parenthesis,syntactic structure,finite state ma,simple rule,abbreviation detects sentence boundary,high accuracy,regular expression,stemming,porter stem ming,inflectional morphology,derivational morphology,analyzer,stem form,standard porter stem,algorithm,porter,application,cluster ing,algorithm,citation form,presentation,lemma analyzer,inflectional morphology,dictionary lookup form,example,lemma form,input token,broad-coverage grammar  nlp win,heidorn,large corpus,analyzer us derivational morphology,dictionary lookup form,derivation,base type,ex ample,base form,base form,addi tion,static list,base form,broad-coverage grammar  nlp win,heidorn,large corpus,token form,corpus,base form,maximum entropy markov model,part-of-speech tag,penn treebank,optimized implementation,high accuracy,test set,thousand,second,chunker,caded markov model,penn treebank,accuracy,benchmark dataset,chunker,large corpus,web document,flexibility, a w eb service, msr  spl toolkit,web service,access,new tool,sentiment analysis,process,language analysis,english,direction,katakana word,cherry,suzuki,toolkit,transliteration candidate,probability,direction,included service,subject,object,triple,functionality,feature,sys tem,bionlp,web service reference,web service,series,analysis tool,analysis,main web service call,analyze,parameter,language,english,raw text,analyzer,access key,constrain usage,analysis,analyzer,simple  jso,javascript object notation,many programming language,addition,web service call,available lan guages,analyzer,analyzer,language,data format,standard set,data representa tions,component,expression,part-of-speech tag,dependency tree,parent index,website,authoritative description,analysis format,speed speed,analysis,component,analyzer,sentence sepa ration,tokenization,part-of-speech tagging process thousand,sentence,second,constituency parser,second,request,paragraph,impact,network latency,6 c onclusion,others,courage people,feedback,collaboration,community,7 s cript outline,interactive ui,figure,arbitrary sentence,desired level,analysis,output,toolkits,demonstration,participant,quality,utility, msr  spl tool,research,microsoft,hisami suzuki,discriminative sub,transliteration,proceeding,head-driven statistical model,natural language parsing, phd dissertation,university,jian-yun nie,jian zhang,endong xun,ming zhou,chang-ning huang,query translation,statistical model,proceed ings,assistance,somers,natu ral language processing,technique,application,processing,new york,beatrice santorini,mary ann marcinkiewicz, a l arge annotated corpus,english,penn treebank,dan gildea,paul kingsbury,prop osition bank,annotated corpus,71-105 martin porter,algorithm,suffix stripping,pro gram,leon barrett,romain thibaux,dan klein,accurate,compact,interpretable tree annotation,proceeding,kristy hollingshead,chart cell,quadratic complexity context-free inference,proceeding,sam roweis,adaptive,relaxed bound optimization method,proceeding,aria haghighi,christopher,global joint model,semantic role,martha palmer,feature,semantic role labeling,proceeding,choudhury,scott count,michael gamon,equal exploring human emotional state,social medium,accepted,presentation, ic wsm ,munmun,choudhury,scott count,michael gamon,classification,human affective state,social medium,accepted,presentation,short paper, icw sm, f igure,screenshot, msr  spl interactive ui showing,functionality,interface, naa cl,proceeding, naa cl-hlt,atlanta,georgia,association,computational linguistics beyond left-to-right,multiple decomposition structure,hzhang isi,edu kristina toutanova microsoft research redmond,kristout microsoft,com chris quirk microsoft research redmond,chrisq microsoft,com jianfeng gao microsoft research redmond,jfgao microsoft,com abstract standard phrase-based translation model,context dependence,tween translation unit,result,large phrase pair,target language mod el,contextual effect,translation,n-gram model,capture contextual dependency,phrase boundary,channel model,direction,textual information,multiple decomposition structure,dynamic bidirectional decomposition,resulting model,intrin sic task,lexical selection,full mt system,n-best rerank ing,experiment,ad ditional contextual modeling,phrase-based system,direc tion,conditioning,consis tent benefit,important direction,language pair,ntroduction,translation procedure,classical phrase,translation model,input sentence,sequence,phrase,phrase,reordering,translation,candi date,linear combination,conven tional model,phrase-based channel model,phrase,large uni gram,target language mod el,target language model,research,author,internship,microsoft research,weak extent,lexicalized reordering model,lexical dependency,span phrase boundary,formation,source side,larger,cap ture,contextual dependency,phrase,individual phrase,limitation,several researcher,bilingual n-gram markov model,marino,contextual depen dencies,phrase pair,requirement,source,respective language,language pair,significant typological di vergences,dif ficult,synchronized sequence,synchronized unit,whole sentence,approach,incor poration,syntax-based mt system,phrasal translation system,addition,phrasal translation system,modeling,con text,robust estimation,long phrase,phrase-based system,traversal order,translation unit,many po sible order,source,target,natural choice,unambiguous unit,middle,sentence,building outwards,dynamic decomposition order,several language pair,distinct order,isolation,combination,work marino,translation model, a m arkov model,bilingual n-grams,state-of-the-art performance,conventional phrase-based model,explored factorized n-gram ap proaches,large n-grams,small unit,asynchronous order,source,target,durrani,joint model,translation,prior approach,similar model,syntax,system,dependency translation model,menezes,syntax,trans lation system,target language syntax system,markov model,min imal rule,translation probability,context information,parent rule,vaswani,prior work tends,probability,markov rule,additional sig,replacement,distribution,lex ical weighting,tive frequency estimate,non-compositional unit,inclusion,informa tion,prior work,combina tions,multiple decomposition order,dynamic decomposition,useful context,translation differs,language pair,important finding,many language pair,standard phrase-based approach,proposal,tribution,translation, mtu markov model,additional signal,translation,3 m tu n-gram markov model,word-aligned text,n-gram markov model,traversal order,zuotian yesterdaym3,heldm4,null them5,   h uitan meeting,huitan,null figure,word alignment,minimum translation unit,definition, mtu informally,notion,minimal translation unit,translation rule,con straints,ous  mtu,small phrase pair,phrase pair,empty source,empty target side,insertion,deletion phrase,conven tional phrase pair,composition,size limit,word-aligned sentence pair,sequence,source word,se quence,target word,word align ment relation,source,translation unit,sequence,sequence,definition,phrase pair,constraint,translation unit,partition,sen tence pair,source,target word,minimal translation unit,par tition,average unit size,number,example,figure,word-aligned sentence pair,corresponding set,min imal translation unit,algorithm,phrase extraction,n-gram markov model,imal rule,reason,segmentation,sentence pair,composed rule,probability estimation compli,second,phrase pair,result,sparse data issue,model quality,therefore,n-gram model,minimal translation unit,clean choice,segmen tation,distribution,context,crease,markov model,markov model,large phrase-based translation approach,stan dard phrase-based model,large unigrams,contextual information,n-grams,mini mal translation unit,robust contextual model,segmentation, mtu enumeration order,joint probability distribution,aligned sentence pair,decomposition,generation order,sentence pair,single sequence,lan guage modeling,sequence,chan nel modeling,default enumeration order,different decomposition order,part-of-speech tagging,entity recog nition,tsuruoka,tsujii,formation,use ful,particular disambiguation choice,re search,different decomposition order,machine translation,additional challenge,opportunity,biguity,number,possible  mtu,million,opportunity,phenomenon,machine translation,natural decomposition order,machine translation,source,sentence order,source left-to-right,left-to-right order,aligned set,definition,deleted word,following defi nition,source position,target,position,last source word,preceding non null,target word,target position,null corresponding,source,figure,posi tion,left-to-right order,target side,complete  mtu sequence,source left-to right order,m1-m2-m3-m4-m5,sequence,target left-to-right order,m3-m4-m5-m1-m2,decomposition structure,language,enumeration order,sentence pair,sequence,probability,sentence pair,example,3-gram mm probability,sentence pair,figure,source left-to-right order,different con text,disambiguation,decomposition order,source order,independence assumption,right-to-left,result,addition,basic decompo sition order,performance,cyclic order,cyclic,source,target sentence order,cyclic depen dency network model, pos tagging,toutanova,baseline,previous work,dynamic decomposition order,tsuruoka,tsujii,cyclic order,right neighbor  mtu,example,prob ability,sentence pair,figure,source cyclic order,3-gram model,n-gram markov model,correct application,scoring sequence,max prod uct approximation,previous work,kneser-ney smoothing,atomic unit,vocabulary,n-gram model,n-grams,parallel mt training data,different mtu enumeration order,target-order decomposition,distribution,target,tences,corresponding source side,likewise source order,mod el,distribution,source sentence,unordered target side, mtu sequence,approach,phrase,language,translation  mtu mm,additional gain,mul tiple translation  mtu mm,exical selection,empirical evaluation,different mtu decomposition order,simplified machine translation task,lexical selection,source sentence segmentation,minimal translation unit,corresponding target side,minimal translation unit,problem,target side,target mtu,brevity,figure,lexical selec tion task,part-of-speech tagging,dif ficult,predicted variable,sequence,target language word,million,possible outcome,zuotian yesterdaym3,heldm4,null them5,   h uitan meeting,huitan,null figure,lexical selection,constrained mt setting,performance,different  mtu decom position order,combination,decomposition order,simplified setting allows,experimentation,im pact,factor,full machine trans,search error,phrase table pruning,interaction,tagging task,trigram  mtu model,basic decomposition order,mtu markov model,tar get sentence order,right-to-left,target sentence,source sentence order,right to-left,source sentence order,cyclic order,source,target,regardless,decomposition order,beam search decoder,sim ilar,phrase-based machine transla tion,decoder,target hypothesis,left to-right target sentence order,translation,next source  mtu,con text,top scoring complete hypothesis,first  mm tus,partial hypothesis,source order model,lower-order approximation,trigram  mtu markov model score,future score,context,hypothesis,construction,additional context,exact score,method,differ ent decomposition order,product,system com bination,product method,ma chine translation setting,probability,different model,log-linear model,machine translation,similar scoring function,hypothesis,apply hypothesis recombination,hy potheses,respect,contin uations,recombination,standard-phrase,decoder,difference,target,context,future ex tension,weight,different model,development, mer training, ble score,method,model combination,previous work,differ ent decomposition,system combination method,prior work,machine translation,right-to-left machine,lation system,sumita,sentence-level system combina tion,system,different  mtu markov model,likely translation,system,hypothesis,system,possible distinct translation,candidate hypothesis,normalized probability,system,normalizing,hypothesis,system,probability,system,final scoring function,hypothesis,combined list,candidate,weight,combination,product model,dynamic decomposition order,complex combination method,possible decomposition order,transla tion,constraint,possible decomposition order,feature,candidate decomposition,method dynamic combination,translation,highest-scoring decomposition order,translation,method,bidirectional tagging approach,tsuruoka,tsujii,approach,combination,target language order,source language order,complex ity,figure,possible decomposition,short  mtu sequence,structure,figure,different decomposition,graphical model,parent,context,target  mtu,decomposition,following parent configuration,parent,figure,left parent,left-to-right decomposi tion order,right parent,right-to-left decomposition order,mixture,parent configuration,composition order,decomposition order,varies,translation,translation,directed graphical model,probability,assignment,variable node,product,local probability,parent,definition,assignment,linear model,con figuration feature,log-probability feature,configuration feature,indicator,par ent configuration,setting,feature,decomposition,figure,assignment,variable,log-probability feature value,appropriate n-gram model,left parent,log-probability, l2r model,right parent,r2l model,cyct model,right parent,translation,sentence,hidden decomposition,addition,assignment,final score,translation,decomposition,linear combination,feature value,model log-probabilities,configuration type,feature weight,parent con figuration,configuration weight,fea ture weight,component model,model weight,final score,second decomposi tion,assignment,figure,main difference,ap proach,tsuruoka,tsujii,beam search,hypothesis recombination,exact decoding,hypothesis set,parameter,probability,dif ferent model,preference,certain type,decomposition,example,right-to-left decomposi tions,language pair,left-to-right decom position,additional difference,prior work,definition,possible decompo sition order,structure,tsuruoka,tsujii,trigram baseline model,structure,subset,tsuruoka,tsujii,sixteen possible parent con figuration,right parent,n-gram markov model,probability,prior work,sixteen model,additional gain,structure,training time,runtime memory require ments,machine translation task,maximization,decomposition structure,translation,simple linear function,feature,maximum,linear function,translation,fixed decomposition,linear function,fea tures,translation,maximum,linear function,hypothesis,transla tions,rt training,weight,dynamic combination method,combination,approach,training,local simplex method search, mer solution,weight vector,left-to-right decomposition,weight vector,right-to-left decomposi tions,experiment section,result,weight,development,performance,impact,full mt system,n-best reranking,phrase-based mt system,output,translation,candidate translation,access,phrase,alignment,phrase pair,source sentence,candidate translation,word-aligned parallel sentence pair,mtu sequence,sentence pair,probability, mtu markov mod el, mtu mm log-probabilities,original mt feature,1000-best list,weight vector,system,original feature, mtu markov model log-probabilities,development,6 e xperiments,experimental result,lexical selec tion task,language pair,datasets,different language,detail,section,lexical selection,lexical selection experiment,training portion,datasets,training set,sec tions,lex-train, mtu markov model,possible translation,source,decomposition,hypothesis,n-best list,much variety,translation option,interesting direction,future research,lexical selection result,lex-dev,combination weight,system,several  mtu mm,final evaluation result,possible translation,source  mtu,translation,lex-train,lex-dev set,sentence pair,lex-test set,sentence pair,test set,sen tences,full mt training set, ble score,dividual  mtu mm,language pair,baseline,frequent tar,source  mtu,unigram mm,correct trans lation,correct target,vocabulary,available  mtu,large difference,baseline,oracle performance,importance,context,accurate pre diction,decomposition order varies,language,language,right-to-left,source order,target order,right to-left,target order,statistical significance test,difference, l2r model,stan dard,prior work,performance,significance,paired bootstrap test,method,de composition order,section,result,tgtproduct,tgtsyscomb,tgtdynamic,allproduct,allsyscomb,lexical selection result,combination,mtu markov model,target-order decomposition,table look,decomposition,baseline,target order combination,baseline-1,single target  mtu markov model,baseline-2,individual model,product model tgtproduct,product,target-order  mtu mm,allproduct,product, mtu mm,dynamic decomposition model tgtdynamic,slight,significant gain,baseline,combination model,baseline,takeaway,experiment,mul tiple decomposition order,product,agreement,good choice,dynamic decomposition method,promise,simpler product approach,decomposition,result,pa rameter,decomposition,parameter,datasets,setting,training corpus,sentence pair,hongkong portion, ldc data, nis tmt evaluation,test set,development set,test set,baseline phrasal system,5-gram language model,modified kneser-ney smoothing,kenser,xinhua portion,english gigaword corpus,english word,dataset,language training dev test chs-en  1 m, nis t02, nis t05 deu-en, k w mt06dev,en-bgr  4 m ln,data set,different language pair,machine translation,training set,sentence,english monolingual data,mil lion sentence,language model training,velopment set contains,sentence,final test set,in-domain test set,sentence,kneser-ney lan guage model,separate feature,gram lm,parallel portion,5-gram lm,monolingual corpus,dataset con,sentence,several data source,acquis,steinberger,development set,sentence,english side,news test data,bulgarian side,human translation thereof,mixture,source,training set,system,single four-gram target language model,target side,parallel corpus,system,phrase table,maximum length,reordering model,chinese-english sys tem,alignment,alignment, hmm model aug,heuristic,grow-diag-final-and,tune parameter,random restarts,develop ment,case-insensitive  ble u-4,evaluation,papineni,4 m m phrs,5-gram  mtu trans,result,test set,performance,baseline,experiment,detailed experiment,chinese english,main conclusion,language pair,impact,5-gram  mtu markov model,combination,amongst,decomposition order,individual  mtu mm,significant improvement,baseline,result,individ ual model,combination,direc tions,individual direction,difference,additional experiment,mtu mm,effective use,context,phrase boundary,estimate,phrasal transla tion probability,last row,result,combination, mtu mm,phrasal, mtu mm,inside phrase,improved smoothing,phrase relative frequency count,large improvement,improvement,practice,lan guage pair,additional improvement, mtu mm stem,cross-phrase context,tausdata,combination heuristic,one-to-many alignment,ex traction,minimum translation unit,refinement,combination, ble score,difference,paired bootstrap p-value,result,individ ual 3-gram  mtu markov model,com bination,5-gram model,german-english datasets,individual 3-gram markov model,significant improvement,combination,individual model,vidual 5-gram model,combination,improvement,total increase,baseline,gram model,setting,training set,successful training,capacity,creased context size,ambiguity,morphologically-rich bulgarian word,similar pattern,combination,dividual one,5-gram model,individual 3-gram model,baseline,significance level,combination,baseline,threshold,phrase  mtu mm,result,baseline,improvement,context,phrase boundary,final result,result,reviewer,cent work,problem,significance test,machine trans lation,randomness,local optimum,method lead,large vari ance,development,performance,different run,optimization,different ran dom seed,stratified approximate randomization statis tical significance test,optimizer instability,english-bulgarian system,combination,3-gram mm,combination,5-gram mm,parameter,language pair,3-gram phrs,5-gram phrs,german-english test,result, mtu translation model,minimal translation unit,phrasal system,significant improvement,distinct language-pairs,importance,decomposition order,probability, mtu sequence,simplified lexical selection task,large difference,performance,different decomposition,decomposi tions,language,multi ple method,decomposition,simple product approach,result,lexical selection task,full mt system,difference,decomposition,future work,additional decomposition order,dependency tree,machine translation model,language-modeling level,first pas decoding,reference jonathan,chris dyer,alon lavie,hypothesis,statistical machine translation,optimizer insta bility, f y von,bilingual gram language model,statistical machine transla tion,machine translation,special issue,frontier,nadir durrani,helmut schmid,alexander fraser,joint sequence translation model,proceeding,annual meeting,association,computational linguis tic,human language technology,portland,oregon,association,computational linguistics,andrew finch,eiichiro sumita,bidirectional phrase-based machine translation,proceeding, emn lp,xiaodong,word-dependent transition model,word alignment,statistical machine translation, wmt workshop,reinhard kenser,hermann ney,backing-off,m-gram language modeling,philipp koehn,christof monz,manual,au tomatic evaluation,machine translation,eu ropean language,proceeding,workshop,statistical machine translation,philipp koehn,franz josef och,daniel marcu,statistical phrase-based translation,philipp koehn,statistical significance test,machine translation evaluation,proceeding,gispert,mr costa-jussa,gram-based machine translation,computational lin guistics,robert,chris quirk,random,minimum error training,statistical ma chine translation,coling-08,franz josef och,hermann ney,discrimina tive training,maximum entropy model,statis tical machine translation,proceeding,franz joseph och,minimum error training,sta tistical machine translation,kishore papineni,salim roukos,todd ward,wei jing zhu,method,automatic eval uation,machine translation,annual meeting,chris quirk,arul menezes,phrase,conventional wisdom,sta tistical machine translation,proceeding,hu man language technology conference, naa cl,main conference,association,computational linguistics,ralf steinberger,bruno pouliquen,anna widiger,camelia ignat,toma erjavec,dan tufis,dniel varga, jrc acquis,parallel corpus,language,kristina toutanova,dan klein,christopher,manning,yoram singer,feature-rich part-of-speech tagging,cyclic dependency network,pro ceedings, hlt -naa cl,yoshimasa tsuruoka,ichi tsujii,bidi rectional inference,easiest-first strategy,sequence data,proceeding,ashish vaswani,david chiang,rule markov model,fast tree-to string translation,proceeding,annual meeting,association,computational linguis tic,human language technology,portland,oregon,association,compu tational linguistics,proceeding,annual meeting,association,computational linguistics,portland,oregon,association,computational linguistics,bilingual morpheme segmentation,alignment,context-rich hidden semi-markov model jason naradowsky,department,computer science university,massachusetts amherst amherst,edu kristina toutanova microsoft research redmond,kristout microsoft,com abstract,unsupervised dynamic graphical model,morphological segmen tation,bilingual morpheme alignment,statistical machine translation,model ex,hidden semi-markov chain model,output node,special struc tures,conditional probability distribu tions,lex ical source-side information,morphological segmentation,morpheme segmentation,target lan guage,competi tive word alignment system,alignment qual ity,monolingual morphological seg mentation,ac curacy,previous state-of-the-art model,arabic,hebrew datasets,ntroduction,enduring problem,statistical machine trans lation,sparsity,word alignment model,modern mt system attempt,capture,probability,token ei,translation,assumption,word-based tokenization,concep tual mapping,language,unrelated lan guages,common task,disparate morphological system,asymmetric conceptual bur den,lexicon,language,problem,sparsity,large number,word form,research,author,internship,microsoft research,productive process hin ders attempt,concise mapping,con cepts,instance,bulgarian adjective,marking,gender,number,definiteness,following tree,bulgarian word,definite,indefinite marking,bulgarian form,red contrast,english,informa tion,modified word,sep arate function word,comparison,language,adjective,alignment model,much data,uniform distribution,inflected form,comparable statistic,research,amount,large role,system,overall performance,sparsity,complication,lexical sparsity,desire,alignment,contiguous phrase,alternative,word alignment,morpheme alignment,align ment,meaningful sub sequence,to-1 mapping,semantic unit,language,estimate,red flower,tsvet det  adj nn,vb  prn,te figure,depiction,morpheme-level alignment,dark line,stem-focused alignment strategy,traditional word,phrasal alignment model,thin line,fine-grained alignment,morpheme,alignment,english,bulgarian,morpheme-specific alignment reduces sparsity,red flower,inflected form,templatic morphology,simpler segmentational approach,plural marker,english,sparsity,additional place,inflection,wordforms,alignment statistic,result,alignment quality,following section,dynamic graphical model approach,monolingual morphological segmentation,bilin gual morpheme alignment,statistical model,bilingual setting,model relies,lexical source-side information,morpho logical segmentation,dependency analysis,morpheme segmentation,tar get language,monolingual setting,effective use,context,feature-rich mod eling,probability,morpheme,morpheme transition,word boundary,additional source,information,powerful bias,learning,asymp totic running time,inference algorithm,monolingual model,system,state-of-the-art segmenta tion performance,arabic,hebrew data set,bilingual model,system,performs,word alignment model,previous work,morpheme segmentation,alignment,gildea,habash,segmentation,alignment,gold-standard segmenta tion,bilingual model,monolingual model,segmentation  f-m easure,probability,target lan guage sequence,consisting,se quence,morpheme,alignment,target,source morpheme,source language,quence,consisting,sequence,example morpheme segmentation,align ment,phrase,english-arabic,english bulgarian,figure,task setting,source,target language,morpheme segmentation,source,en glish,language,morpheme segmen tation,target language,alignment,tween source,target morpheme,source-side input,gold morphological segmentation,dependency tree analysis,resource-poor language,modeled language,common translation task,additional information,source,feature,infor mation,translation model,hidden-markov model,word alignment,cherven,graphical depiction,transliteration,first bulgarian word,figure,trigram dependency,clarity,graphical model,lin guistic intuition,morpheme segmentation,alignment,hidden semi-markov model,hidden target morpheme seg mentation,additional observa tion layer,observed word boundary,represent target sentence,morpheme,sequence,log-linear model,context,morpho-syntactic mapping,source,target language,hidden state space,code morpheme type prefix,suffix,ad dition,alignment,segmentation,formation,notation,possible morphological seg mentation,alignment,sentence pair,following random variable,morpheme,seg mentation,target sentence,example,figure,word boundary,example,non-space character,target string,word boundary,target character,example,cyrillic version,wb variable,wb vari ables,morpheme boundary,corresponding char acter,hidden segmentation vari ables,observed,wb variable,morpheme variable,word boundary vari ables,constraint,word boundary wbt,entail,bold letter,vector,variable,assumed parametric form,learned distribution,inference algorithm,wb variable,observed source language mor phemes,ad ditional information,source,last part,hidden model state repre,alignment,target,source mor phemes,target morpheme,factored state,source word,morpheme type prefix,suffix,source mor pheme,desired proba bility,target morpheme,morpheme type,align ments,word boundary,source,factor,detail,formulation,full extent,dependency,factor,monolingual segmentation,bilingual joint seg mentation,alignment,relation ship,prior work,impact,novel component,experiment,source sentence,morpheme,monolingual morpheme segmen tation model,perfor mance,previous state-of-the-art model,word boundary component,alignment transition,morpho logical type component,state space,minimal dependency,morpheme,lation model,joint tokenization,alignment model, ibm model-1,gildea,morpheme translation model,morpheme translation probability,standard dependence,source morpheme,pendence,state tai,source sentence,multiple option,amount,context,context,bi gram dependency,target language morpheme,dependence,previous boundary vari ables,dependence,source mor pheme eai, pos tag,multiple conditioning variable,backoff form,lan guage modeling,example,mor pheme translation probability,m-step,joint count,marginal count,order distribution,similar way,unigram character language model,hierarchical smoothing,approximation,hierarchical dirichlet prior,maximum aposteriori estimation,explicit treatment,ary variable,pendence,variable,word boundary,morpheme,four-gram model,target morpheme,dependency,bigram model,hidden mor phemes,word boundary generation model,pb distribution,probability,word boundary,sequence model,sentence,basic hidden semi-markov model com,word boundary,powerful predictor,morpheme segment,example,common prefix,low word boundary,common suffix,log-linear model,word boundary,observed left,right context feature,morfessor,creutz,boundary,ary symbol,morpheme state,morpheme,special generative process,boundary,previous morpheme state,morpheme,boundary,boundary,inclusion,complexity,inference,inclusion,distribution,likelihood,word consisting,morpheme,estimation,likelihood,particular morpheme,middle end,factored state variable tai word boundary,likelihood,morpheme,source word,particular po tag,particular conditioning con text,distribution,experiment,pt distribution,multiple context vector,hierarchical smoothing,distribution,different granularity,distortion,distribution, 1 t raditional distortion model,probability,alignment,previous alignment,large distance,aligned token,addition,state space,mor pheme type,spe cial log-linear model form,integra tion,rich morpho-syntactic context,log-linear model,unsupervised learning,local multinomial distribution,global distribution,special log-linear form,inclusion,feature,transition,morpheme type,transition,source morpheme,feature,example value,example,feature,transition,bulgarian suffix te,first english morpheme,suffix,bulgarian root tsvet,first feature,absolute dif ference,information, hmm word alignment model,phrase translation model,position ai,source morpheme,distor tion,distance,number,source word,distance,feature name  wor d distance,distance,intuition,consecutive morpheme,target word,proximity,source word,morpheme,target word,binned distance,distortion,distance,feature  sam etarget  wor,consecu,complexity,exposition,final transition,special state,source sentence end,last target morpheme,feature value mor ph  dis tance ,wor d distance  1b inned morph distance,bin ned word  dis tance ,figure,feature,log-linear distortion model,transition,example sentence pair,feature,differ ent alignment possibility,conjunction,feature,transition behavior,target word, dep  rel ation  feature,pendency relation,source word,source morpheme,rela tionship exists,alignment,source word,feature,several feature conjunction,target word,distance feature,length penalty,gildea,exponential length penalty,morpheme length,maximum likelihood under-segmentation solu tion,morpheme length,pa rameter,annotated development set,morpheme-segmentation,performs,penalty,inference,inference,em training,aligned sentence pair,e-step,hidden variable configuration,m-step,model parameter, lbf g,m-step,distortion model,count interpola tion,translation,word-boundary model,computation,expectation,e-step,semi-markov chain model,hidden state label,source morpheme time num ber,target morpheme type,forward,backward dynamic programming pass,length,target sentence,character,number,source morpheme,maximum mor pheme length,complete listing,dynamic programming solution,dynamic program,tokenization model,gildea,morpheme,factored alignment state space,inference algorithm,infer ence, hmm model,segmentation,running time,morpheme boundary,target side,corpus,frequent prefix,suffix,simple trie-based method,schone,jurafsky,prefix,suffix,segmentation,belong,prefix,suffix,substring,number,prefix,suffix,maximum recall,segmentation point,allowable segmentation,inference,improvement,complete branch,potential suffix,inclusive,sub branch,list comprises,frequent,complete branch,potential prefix,3 e valuation,majority,paral lel phrase,previous work,snyder,barzilay,corpus,short phrase,english,hebrew,arabic translation,unmodified version,corpus,purpose,morphological segmentation accuracy,morpheme alignment accuracy,en glish arabic subset,corpus,gold stan dard alignment,morpheme,mor phological segmentation,previously-annotated gold standard arabic morpho logical segmentation,english,morphological analyzer,correction,native speaker,morphological alignment,monolingual segmentation model,unsupervised morpheme seg mentation,4 r esults,series,simplification,complete model,impact,individual modeling decision,monolingual setting,source,target sentence,unigram model,length penalty,first model,unigram mono lingual segmentation model,exponential length penalty,gildea,model-up,unigram,probability,target morpheme sequence,spe cial case,full model,transition,word boundary probability,mor pheme type,conditioning,mor pheme translation model,parameter,probability,morpheme,ate morpheme,additional parameter,significant impact,performance,result,length penalty power,gird search,crements,performance,development,phrase pair,language,optimal number,prefix suffix,performance,development set, 3m orpheme type model,next model,un igram model,penalty,hidden ta state,mor pheme type,monolingual setting,ta state,different configuration,feature,distortion model,mor pheme translation model,vari ant, hmm model,length penalty,hidden state,allowable transition,prefix,transi,suffix,word boundary,model model-hmmp,log-linear distortion model,feature rich translation model,model defi nition,word boundary information,conditioning,word bound aries,pb pre dictive word boundary distribution,full model,word boundary finally,full monolingual model,distribution,word boundary variable,model model fullmono,context feature,conditional pd distribution,language,morpheme,pre fix,suffix,achiev able recall,prefix,suffix,maximum recall,arabic treebank data,number,prefix,suffix,maximum recall,lation unigram distribution,modelhmmp-basic,iteration,detail,result,different model configuration,result,datasets,main result,derived list,prefix,suffix,segmentation point,limited list,comparison,result,segmenta tion point,unigram model,penalty,dict-model-up,segmenta tion point,performance,introduction,hidden morpheme state,substantial improvement,arabic,result,datasets,small improvement,unconstrained model,cludes,component,word boundary pre diction,dict-model-hmmp,result,language,model-hmmp,first unconstrained model,sequence,previous state-of-the-art seg mentation performance,full model dict-monofull,substantial improvement,previous state-of-the-art result,cor pora,point improvement,point improvement,hebrew,configuration,distortion model,language,morph state transition,boundary feature,translation model,hebrew,arabic,arabic,hebrew,unconstrained model,affix dictionary,previous state-of the-art model,unconstrained model,segmentation error,system,dis -4n ote,inclusion,different distribution,number,morpheme,positive impact,arabic hebrew  atb p r f1  p r f1  p r f1,monofull,figure,result,morphological segmentation,monolingual variant,result,prior work,comparison,automatically-derived list,possible prefix,suffix,model name,tributions,frequency,particular error, a z ipfian skew,arabic,frequent error,er rors,comparison,hebrew,frequent error,isolated error,arabic,tendency,over-segment certain character,correct morpheme,particle,isolated error,system,segment,character aleph,source,single character,latter functioning,problematic arabic character,cognate word,biblical text,large number,hyper-parameters,annotated devel opment,length penalty,parameter,subset,variable,component sub-models,advantage,previous state-of-the-art model,snyder,barzilay,datasets,parameter,morfessor,creutz,alignment next,full bilingual model,sim pler variant,word alignment,morpheme-level annotation,morpheme alignment,word alignment,align ment performance,result,different segmen tations,comparably,ibm model4,figure,re sults,addition,alignment error rate,different segmentation model,morphological segmentation,word-alignment  wdh mm model performs,english word,arabic word,arabic,direction,many-to-one correspondence,tween english word,arabic morpheme,alignment,direction,standard grow-diag-final method,gildea,termed model-1,full bilingual model,model-1,model-up,morpheme,source morpheme,full bilingual model,form model-1,segmentation,specific form,full model,previous experiment,best segmentation,development set,arabic,model condition,wdh mm  gdf,figure,morphological segmentation f1,bilingual variant, wdh mm,gold standard alignment,hebrew data set,phemes,source morpheme,bound ary model,number,mor phemes,source part-of-speech,target morpheme,distortion model,word-based absolute dis tortion,distortion,morpheme type,source-part-of-speech tag,arabic outperforms,word alignment error rate,hebrew,similar boundary model configuration,simpler uniform transition distortion distribution,bilingual model,monolingual one,finding,previous work,segmentation,particular linguistic convention,morpheme,gildea,habash,result,snyder,barzilay,general claim,arabic dataset,word-alignment evaluation,sentence,short phrase,phrase,translation,sentence length,stan dard parallel corpus,warrant,model evaluation,large-scale alignment setting,elated work,unsupervised tokenization,alignment model,gildea,barzilay,nguyen,unigram model,tokenization, ibm model-1,special case,snyder,barzi lay,hierarchical bayesian model,learning,monolingual segmen tations,cross-lingual alignment,incorporating morphological information,reasonable attention,exam ple,improve ments,czech input,morphological decomposition,combination,lemmatization,pseudowords,morpheme,yeniterzi,oflazer,morpholog ical disparity,language,unique way,english syntactic element,function word,dependency relation,morpheme,rule-based postpro cessing,standard word alignment,attempt,morpho-syntactic alignment,mor phological analysis task,6 c onclusion,unsupervised model,mor pheme segmentation,alignment,hid den semi-markov model,linguistic information,alignment qual ity,monolingual morphological seg mentation,new state-of-the-art level,datasets,quantitative im provements,word segmentation,word alignment,true potential lie,interpretation,word alignment,improvement,translation quality,acknowledgement, acl reviewer,valuable comment,version,michael,contribution,corpus annotator,arabic aspect,reference taylor berg-kirkpatrick,alexandre bouchard-cote,john  den ero,dan klein,feature,proceeding,north american chapter,association,tagyoung chung,daniel gildea,unsuper,tokenization,machine translation,confer ence,empirical method,natural language pro,mathias creutz,krista lagus,morpheme segmentation,morphology,speech lang,process,nizar habash,fatiha sadat,arabic prepro cessing scheme,statistical machine translation,north american chapter,association,com putational linguistics,xiaodong,word-dependent transition model,word alignment,statistical machine translation,statistical mt work shop,philip koehn,pharaoh,beam search decoder,phrase-based statistical machine translation mod el,online em,north american association,thuylinh nguyen,stephan vogel,nonparametric word segmentation,machine translation,proceeding,international con ference,computational linguistics,franz josef och,hermann ney,statistical alignment model,proceeding,annual meeting,association,computa tional linguistics,hoifung poon,colin cherry,kristina toutanova,morphological segmentation,log-linear model,north american chap ter,association,computation linguistics human language technology,conference,daniel jurafsky,knowlege free induction,morphology,latent semantic analysis,proceeding,conference,regina barzilay,unsuper,multilingual learning,morphological segmen tation,stephan vogel,hermann ney,christoph tillmann,statistical trans lation, col ing ,com putational linguistics,kristina toutanova,hermann ney,bayesian semi-supervised chinese word segmentation,statistical machine translation,kemal oflazer,syntax-to morphology mapping,factored phrase-based statis tical machine translation,proceeding,association,computational linguis tic,proceeding,annual meeting,association,computational linguistics,shortpapers,portland,oregon,association,computational linguistics,initialization matter, ibm model,multiple optimum,non-strict convexity kristina toutanova microsoft research redmond,kristout microsoft,com michel galley microsoft research redmond,com abstract contrary,popular belief,optimal parameter, ibm model,large class,continuum,prob ability mass,translation,magnitude,variance,optimal model parameter,linear programming,proach,multiple random trial,demonstrate,result,variance,log-likelihood,alignment error rate,ntroduction statistical alignment model,machine translation,question answering,textual entailment,non-nlp application area,information retrieval,berger,lafferty,object recognition,duygulu,complexity,probabilistic model,hidden correspondence,development, ibm model,im pact,sequence,simpler,simpler model,complex one,first model,sequence,reliable initializer,convexity, ibm model,large space,parameter value,op timal value,magnitude,problem,optimal parameter,solu tions,linear equality,different parameter value,objec tive,linear programming approach,percentage,model parameter,number,word type,uncertain translation probabil ities,achieved variance,parameter,different random initial ization,impact,initialization,log-likelihood,alignment error rate,experiment,initialization,matter,practice,2 p reliminaries,appendix,convexity,strict con vexity,function,vanden berghe,section,gener ative model,genus tive process,source sentence,alignment,corresponding tar,generative process,length,uniform distribution,mass function proportional,source word position,detail,initial guess,position,target sentence,uniform distribution,source word,translation probability distribution,target,first position,trainable parameter,lex ical translation probability,source,target vocabulary,log-probability,single source sentence,target sentence,translation parameter, ibm model,maximum likelihood estimation,corpus,negative log-likelihood minimization,negative log likelihood,matrix,translation probability,length probability,alignment probability,respect,translation parame ters,optimization problem,subject,constraint,parameter,well-formed probability,em algorithm,problem,lo cal optimum,objective function,dempster,3 c onvexity analysis, ibm model  1i,section,optimization problem,ibm model,convex,multiple parameter setting,optimal value,function,vandenberghe,nega tive log-likelihood,negative logarithm,parameter,negative logarithm,following simple counterexample,function,vector notation,vector,ele ments,setting,defini tion,strict convexity,strict convexity re,former expression,function,con vex,composition,linear function,negative log-likelihood objective,overall objective,objective,con vex,inequality constraint,equality constraint, ibm model,op timization problem,convex optimization prob lem,local optimum,global op timum,objective,con vex,multiple distinct parameter val ues,optimal value,next section,actual space,optimum,log-likelihood function,concave function,parameter,negative log-likelihood function,section,fact incorrect,section,multiple distinct pa rameter value,global optimum,objective function,strict convexity,objective function,function,optimum solution,vandenberghe,experiment,modus tollens,4 s olution space,section,parameter,maximum,log-likelihood,ibm model,simple example,optimal parameter,sentence pair,entire training data,likelihood, nul word,phrase sentence,courte sentence,ent way,instance,phrase sentence,maximum likelihood value,divergent set,parameter,courte sentence,op timum,example,small size,laxity,example,co-occurs,e1 short e2 sentence,solution space,def inition, ibm model,log-likelihood,section,distinct set,parame ters,minimum negative log-likelihood value,distinct model,negative logarithm,e2 co-occur,source word,probability mass,log-likelihood,distribution,adjustment,estimate,equation,optimal parame ters,equation,maximum log likelihood parameter,em algorithm,convergence,em parameter,right hand side,equation,right hand side,solution space,maximum log-likelihood,condition,interior-point method,karmarkar,maximum divergence,optimal model parameter,linear objective function xtk,column-vector,pa rameters,pre-existing set,maximum log-likelihood parameter,em parameter,vector x1,cosine similarity,xk doesn,cosine similarity,previous parameter vector,infinity,solution,system,solution,solution,latter case,system,solution,parameter,greedy procedure,feasible region,convex polytope,mini mum cosine similarity,problem,di ameter,polytope,number,variable,kaibel,divergence,procedure,substan tial,section, 1e m-lp -1e m-lp -8e m-lp,percentage,target word,distribution,cosine similarity,5 e xperiments,section,solution space,bulgarian-english paral lel data drawn, jrc -aqu corpus,sentence pair,representative,amount, smt system,language pair,figure,relies,method,remain,em-lp-n method,method,section,sentence pair,em-rand-n,sentence pair,convergence,different random,cosine similarity,resulting model,surprising result,lp-128,target token type,cosine similarity,con trastive model,cosine,log-likelihood,short sentence example,section,training,cosine similarity,word type,large portion,first method,divergent optimal model parameter,large linear program,linear system,million,sentence pair,use em-rand,model space,training,divergence,op timal model,em-rand,result,random initialization trial,additional statistic,em-rand-n experiment,row repre sent statistic,training,first column,second column,percent,target word,co-occur,word type,fifth column,percent,word type,translation distribution,non-unique type,minimum cosine,different optimal parameter vector,percent,non-unique type,non-coupled word,column,stan dard deviation,log-likelihood,differ ent random trial,difference,log-likelihood,uniformly initialized model,random trial,training,size increase,percentage,non-unique trans lation probability,coupled word,translation parameter,convergence,sizable portion,non-coupled word,additional pattern,co occurrence,result,percent,word type,data-sets,pair english-bulgarian cor pu,bulgarian word type,english-german corpus,wmt workshop,callison-burch,german word type,log-likelihood statistic,experiment,data-sets,thousand,iteration,standard deviation,training,reasonable data size,uniformly initialized model performs,small data size,random model,data size,sentence pair,impact,initialization,ibm model,experiment,alignment error rate,differ ent model,performance,performance,competitive hmm alignment model,parameter,dataset,experiment,english-french parallel data,hansard,evaluation consists,sentence,development,different training set size,small set consisting,sentence pair,reasonably-sized dataset,sen tence pair,data size condition,performance,perfor mance,parameter, ibm model,training, 5 e iteration,standard setting,setting,start training,uni form,random parameter,detail,result,experiment,experimental condition,initialization,uniform versus random,number,iteration em,iteration versus,number,alignment error rate,training,iteration,random initialization,random trial,different ini tialization,mean  aer,setting,several conclusion,agreement,current practice,iteration,training result,fi nal performance, hmm model,performance,minimum  aer, ibm -1 h mm,-1k rand,uni form,random initialization,uniform,uniform-initialized model,random trial,corresponding uniform model,advantage,randomly,creased training data size,advantage,perplexity,6 c onclusions,theoretical analysis,ex periments, ibm model,large variance,optimal parameter value,variance,significant fraction,word type,re sults,variance,predictive performance,trained model,log-likelihood,word-alignment error rate,magnitude,development,information,simple co occurrence,fertility,order alignment model,surface form,reason,property,berg-kirkpatrick,im pact,non-determinism,order model,standard alignment model sequence,insight,impact,finer-grained feature,alignment,acknowledgement,chris quirk,galen andrew,valu able discussion,suggestion,reference taylor berg-kirkpatrick,john  den ero,dan klein,painless,feature,human language technology,annual conference,north american chapter,association,com putational linguistics,association,computational linguistics,adam berger,john lafferty,information re trieval,statistical translation,proceeding, acm  sig ir conference,research,devel opment,information retrieval,stephen boyd,lieven vandenberghe,convex optimization,cambridge university press,vincent,della pietra,stephen,della pietra,mathematics,statistical machine translation,parameter,computational linguistics,chris callison-burch,philipp koehn,christof monz,kay peterson,omar zaidan,editor,pro ceedings,joint fifth workshop,statistical ma chine translation,maximum likelihood,incomplete data,em algorithm,journal,royal statistical society,se ries,kobus barnard,david forsyth,recognition,machine translation,lexicon,fixed image vocabulary,proceeding,volker kaibel,pfetsch,tu berlin,algorithmic problem,polytope theory,dagstuhl seminar,new polynomial-time algorithm,linear programming,combinatorica,december,franz josef och,hermann ney,sta tistical alignment model,proceeding,annual meeting,association,computational linguistics,ralf steinberger,bruno pouliquen,anna widiger,camelia ignat,tomaz erjavec,dan tufis, jrc acquis,parallel cor pu,language,proceeding,5th international conference,language resource,hermann ney,christoph tillmann,statistical trans lation,proceeding,computational linguistics,convex function,convex optimization problem,domain,function,convex set,definition function,convex iff dom,convex set,definition convex optimization problem,function,equal ity constraint,feasible set,constraint,local optimum,problem,global optimum,local optimum,unique global optimum,proceeding,50th annual meeting,association,computational linguistics,republic,association,computational linguistics multilingual named entity recognition,parallel data,metadata,south korea,kristout microsoft,com hwanjo yu pos tech pohang,south korea,method,label multi-lingual data,entity tag,prior work,wikipedia metadata,weak annotation,wikipedia metadata,infor mation,english-foreign lan guage parallel wikipedia sentence,com bination,novel semi-crf model,foreign sentence tagging,con text,parallel english sentence,standard annotation projec tion method,method,wikipedia metadata,technology, nlp application,state-of the-art statistical model,large amount,training data,linguistic exper tise,high-accuracy model,large number,language, ner analyzer,many language,algorithm,foreign language entity,metadata,semi-structured wikipedia repos itory,inter-wiki link,article category,cross language link,richman,schone,parallel english-foreign lan guage data,high-quality  ner tagger,english,annotation,foreign language,yarowsky,petrov,monolingual tagger,analyzer,lan guages,burkett,burkett,research,author,internship,microsoft research,high-accuracy ner,foreign language,element,wikipedia metadata,approach,projection-based approach,parallel sentence,wikipedia,statistical model,information,joint model,burkett,bilin gual feature,log-linear framework,advan tage,summing,matchings,source,target entity,conditional model,target sentence annotation,aligned en glish source sentence,english sentence,source,feature,exact inference,standard semi-markov  crf model inference technique,sarawagi,semi-crf model im,performance,projection model,f-measure,f-measure,small number,annotated sentence pair,datasets,task setting,section,baseline method,a w ikipedia metadata-based tagger,cross lingual projection tagger,section,section,case study,dif ferent foreign language,foreign language sentence,training,test data,wikipedia,wikipedia,article,english wikipedia,bulgarian wikipedia,korean wikipedia,figure,gold-standard ne label,word alignment,dataset,parallel-foreign sentence,com parable document,inter-wiki link,approach,small amount,article-pairs,document-level  crf model,parallel sentence extraction,english-korean sen tence pair,english bulgarian,english-korean sentence pair,source,target,entity,word-alignment link,named entity,language,figure, a b ulgarian english sentence pair,alignment,entity annotation scheme,label  gpe,organization,annotation guideline,location,annotation process,re source,english-korean datasets,annotator,annotation,english sentence,annotator,disagreement,discussion,foreign lan guage sentence,performance,precision,recall,f-measure,par tial credit,entity,total number,english,bulgarian,korean entity,percent age,entity,entity,language,data size,language entity,english-korean data characteristic,coarse,feature,evaluation,datasets,research,microsoft,people,entity,parallel,language,phenomenon,parallel sentence,different amount,information,language,detail,information,entity,language,non-entity phrase,bulgaria,versus,divergence,english-korean dataset,english-bulgarian one,iki-based tagger,annotating sentence,wikipedia metadata,approach,richman,schone,entity annotation,english,foreign phrase,wikipedia,wikipedia metadata,following source,formation,wikipedia,category,notation,english document,article link,phrase,article,article,language,interwiki link,figure,candidate ne,english,bulgarian sentence,baseline tagger,article,language,article,language,addition,wikipedia-derived resource,ap proach,en glish category key-phrases,ne tag,expert knowledge,non-english lan guage,main idea,ap proach,implementation detail,english language phrase,entity categorization,english article title,article,category information,category-to-ne map,assignment,phrase,category title,ne tag,example,article,category,people,example,figure,article,igor tudor,category,people,full map,richman,schone,article-level annotation,article link,local english wiki-based tagger,global english wiki-based tagger,detail,local englishwiki-based tagger,wiki-based tagger tag phrase,english article,article,phrase,ne-tagged arti cles,example,phrase,article,igor tudor,ar ticle,local english wiki-based tagger,phrase,article,phrase,article,tagger,english phrase,regular expres sion,filter,number,ne tag,global english wiki-based tagger,tagger,phrase,ne tag,phrase,categorized article,fre quent label,example,current article,article,ti tle,article,local global wiki-tagger,entity,local wiki tagger,non-conflicting en tities,global tagger,local foreign wiki-based tagger,local english tagger,dif ference,ne tag,foreign lan guage article,ne tag,en glish article,inter wiki link,cate gory phrase,ne tag,foreign language,inter-wiki link,knowledge,foreign language,foreign language,algo rithm,local english wiki-based tagger,entity,cap italization,number,ko rean,concept,capitalization,global foreign wiki-based tagger,local global tagger,cate gorization,foreign article,figure,english,bulgarian string,global wiki-based tagger,global wiki-based tag ger,multiple label,string,different sens,different oc currences,multiple possible label,figure,figure,result,stanford  ner tagger,english,finkel,report,performance,stanford tagger,local wiki tag gers,precision,recall,local global wiki tagger,local global tagger,language,iki-tagger lg wiki-tagger stanford tagger prec rec f1 prec rec f1 prec rec f1 english,english,korean,english-korean wiki-based tagger performance,english,bulgarian,lo cal tagger,korean,precision,global tagger,absence,capitalization filter,korean,precision,bulgarian,english,stanford tagger,wiki-based tagger,useful information,4 p rojection model table,english wiki,tagger,ko rean one,abundance,com pleteness,english data,wikipedia,cir cumstances,previous research,annotation,english,resource-poor language,yarowsky,approach,log-linear model,projection,wiki-based tagger,training data,sentence,wikipedia article,projection model,section,semi-crf model,section,foreign sen tences,english-foreign sentence pair,wikipedia,projection,ranking task,source entity,possible candidate target entity,source entity,target span,ne label,source entity,probability distribution,target span,source entity si,parameter vector,fea ture vector,candidate entity pair,formulation,fixed set,english source entity si,model project,entity,foreign entity,projection model,10-fold cross-validation,dataset,training,gold english entity,entity alignment,target entity,test time,local global wiki-based tagger,english entity,annotated alignment,feature,feature,detail,analogous feature type,final direct semi-crf model,feature,category,word alignment,feature, hmm word align ments,direction,feature,posterior alignment link probability,viterbi,alignment,posterior proba bilities,probability,direc tions,source,target sentence,source entity,position,potential corresponding target entity,position,word-alignment derived feature,en tities,entity,analogous estimate,probability,direction,posterior probability,entity, hmm di rection,source,target entity,phrase pair,viterbi alignment,standard phrase ex traction heuristic,feature,similarity,source,target entity,pronunciation,transliteration model,cherry,suzuki,english person name,foreign language name,wikipedia,transliteration model,n-best list,transliteration,eign string,example,transliteration,english,bulgarian equivalent,igor tudor,figure,igor twoodor,igor twoodore,igore twoodore,phonetic similarity,source,target entity,levenshtein,distance metric,source entity,transliteration,target,10-best list,un-normalized levenshtein distance, a b leu- type measure,n-gram overlap,position length,report,length,position,english,foreign entity,feature,degree,source,target entity,global wiki-taggers,english,foreign language,stanford tagger,english,indicator fea tures,different source-target tagger combination,tagger,assignment,candidate entity,model evaluation,f-measure,projec tion model,english korean datasets,10-fold cross-validation,model performance,foreign lan guage ne f-measure,wiki-based tagger performance,last line,baseline,detailed evaluation,understanding,strength,limitation,projection approach,direct semi-crf model,estimate,upper bound,performance,projection model,oracle,oracle,impact,source,projection model,english entity,corresponding foreign entity,english entity,first oracle  ora cle1,access,gold standard english entity,gold-standard word alignment,foreign word,eign language sequence,phrase pair,source,tity word sequence,standard phrase extraction heuristic,source entity,word alignment,foreign phrase,english phrase,performance,oracle,percentage,source-target entity,second oracle  ora cle2,performance,projection model,gold-standard source entity,corresponding target,tities,projection model,gold-standard alignment,projection model,feature,test set,gold standard english entity,performance, ora cle2,automatic word alignment,phonetic corre spondence,korean,perfor mance drop,f-measure,next section,method english-bulgarian english-korean prec rec f1 prec rec f1 ora cle1,english-korean projection tagger performance,non-oracle projection model,access,informa tion,local global wiki-based tagger,english entity,alignment information,projection model,feature,projection model,wiki-tagger,feature,feature,difference,accuracy,pro jection model, ora cle2,wiki-based english tagger,bulgarian,projec tion model pm wf,performance,baseline wiki-based tagger,source entity,language pair,entity annotation,source,target wiki-based annotation,korean,model performance,oracle information,projection model,performance,difference,performance,english,korean wiki-based tagger,drawback,projection model,target entity,candidate,source entity,entity,source entity,account,source ne tagger,source,information,target sentence context,en tity consistency constraint,short coming,direct semi-crf model,next section,5 s emi-crf model semi-markov conditional random field,semi -cr f,generalization,la bel,segment,input sequence,individual element,feature,complete segment, a n tagger,foreign sentence,context,source sentence,ne annotation,semi-crf defines,distribution,foreign sentence,segmentation,segment,entity,segment,length,distribution,notation,sarawagi,segmentation,foreign sentence,start position tj,position uj,segment,adjacent segment label,appli cation,feature,segment,fea tures,segment,information,english sentence,exter nal annotation,sentence pair,feature vector,segment,weight vector,feature,probability,segmentation,equation,normalizer,valid segmentation,feature,real-valued feature,semi-crf model,example feature,val ues,feature,segment,length,bulgarian equivalent,label  gpe,english-bulgarian sentence pair,figure,feature,english,foreign sen tence,external annotation,semi-crf model formulation,fixed labeling,english sentence,different,ne tag,candidate english,foreign sentence substring,wiki-based tagger,stanford tagger,external annotation,annotation type,word alignment,transliteration model,section,alignment link,english,foreign token, hmm word alignment,probability,direction,different character-based distance metric,transliteration,foreign word,english word,transliteration model,distance metric,section,example bulgarian correspondent,figure,english,forward,backward  hmm,transliteration distance measure,third annotation type,foreign candidate entity string,sequence,english candidate entity,candidate english entity,entity,wiki-based tagger,stan ford tagger,english candidate,tities,inconsistent,foreign candidate seg ments,english candidate entity,projection model,section,projection model,source-target entity pair,source,target candidate entity,example target segment,corresponding source candidate entity,local global wiki-tagger,global wiki-tagger,feature,category,foreign wiki-based tagger feature,feature,target segment,extract indicator,segment,local global wiki tagger,example segment,sentence,figure,global tagger,label  gpe,feature,value zero,addition,whole segment,tag combination,individual word,segment,segment,first section,several feature type,example,foreign surface-based feature,feature,orthographic property,distinguish several word type,capitalization,distinguish number,punctuation,addition,word cluster,jcluster, 1w look,property,individual word,concatenation,seg ment,addition,feature,segment,second section,several feature,label match,english,foreign entity,feature,english segment,candidate tar,segment,english segment,different english tagger,candidate target label,addition,segment level comparison,tag assignment,individual source token,individual target token,word alignment,transliteration link,last section,sample feature,feature,rce-e- wik i-tag-match  look,correspond,source entity,local global wiki tagger,candidate target entity,feature,stanford tagger,global wiki-tagger,real-valued fea tures, sco re-source-e-wiki-tag-match re,matching,source,target candidate entity,pro jection model,label match,confident matchings,target,confident one,experimental result,main result,10-fold cross-validation,projection experi ments,projection model,baseline,bottom,joshua goodman http,research,microsoft,en-us downloads,c86c-4d80-aa0d-53c97ba7350a default,method english-bulgarian english-korean prec rec f1 prec rec f1 mon,english-korean semi-crf tagger performance,feature description example value wik i-tag-match ,sou rce-e-possible -glo bal ,sou rce-e-all-tag-match ,sco re-source-e-global-tag-match,sco re-source-e-stanford-tag-match -1t,feature,example value,performance,fea tures,feature,bilingual label match,wiki-tagger,feature,monolingual,feature,feature,performance,full bilin gual model,feature,english,entity,main result,full semi-crf model,baseline projection,wiki-taggers,f-measure,full model,base line result,f-measure,semi-crf,performance,projection model,semi-crf model,contribution,english sentence context,point increase,f-measure,versus,f-measure,point increase,versus,additional gain,candidate source entity,english tagger,language pair,model bi-all,semi-crf,projection model,performance,projection model,comparing bi,projection model,bulgarian,korean,semi-crf,assumption,correspondence,source,target enti tie,information,multiple source,target tagger,method,foreign sentence,english-foreign sentence pair,next step,mono lingual ne tagger,foreign language,wikipedia,preliminary result,performance,measure,monolingual model,prior work,wikipedia metadata-based ne tagging,richman,schone,lingual projection,entity,interesting work,entity,language,approach,bilingual labeling model,burkett,snyder,barzilay,source,target sentence,contrast,english sentence,tag foreign sentence,context,english sentence,joint log-linear model,burkett,semi-crf approach,enumeration,n-best candidate,english sentence,n-best candidate,foreign sentence,lapping entity annotation,english sentence,7 c onclusions,resource,wikipedia,metadata-based approach,projection-based approach,ducing,entity annotation,foreign lan guages,direct semi-crf tagging model,foreign sentence,parallel sen tence pair,projection,f-measure point,reference david burkett,john blitzer,dan klein,joint parsing,alignment,weakly synchronized grammar,proceeding, naa cl,david burkett,slav petrov,john blitzer,dan klein,monolingual model,unannotated bilingual text,proceeding,fourteenth conference,computational natural language learning,uppsala,sweden,association,computational linguistics,colin cherry,hisami suzuki,discrimina tive substring,transliteration, emn lp,dipanjan da,slav petrov,part-of-speech tagging,bilingual graph-based pro jections,proceeding,annual meet ing,association,computational linguistics,human language technology,port land,oregon,association,computa tional linguistics,donghui feng,ming zhou,new approach,entity alignment,proceeding,conference,empirical meth od,natural language processing  emn lp,jenny finkel,trond grenager,christopher,non-local information,information extraction system,gibbs sampling,fei huang,stephan vogel,named entity translation,bilingual,entity,philipp koehn,franz josef och,daniel marcu,statistical phrase-based translation,robert,translation,entity phrase,parallel corpus,franz josef och,hermann ney,sta tistical alignment model,proceeding,annual meeting,association,computational linguistics,alexander,richman,patrick schone,wiki resource,entity recognition,sunita sarawagi,william,conditional random field,information ex traction,advance,neural information pro,sunita sarawagi,william,conditional random field,information ex traction,advance,neural information pro,system,bilin gual parsing,factored estimation,english,korean, emn lp,chris quirk,kristina toutanova,parallel sentence,compara ble corpus,document level alignment,association,computational linguistics,benjamin snyder,regina barzilay,crosslin gual propagation,morphological analysis,david yarowsky,grace ngai,richard wicentowski,multilingual text analysis tool,ro bust projection,corpus,proceeding,annual meeting,association,computational linguistics,bulgaria,august,association,computational linguistics learning non-linear feature,machine translation using gradient boosting machine kristina toutanova microsoft research redmond,kristout microsoft,byung-gyu ahn,edu abstract,non-linear feature,machine translation,new feature,a b leu- related objective,local phrase,antees,asymptotic complexity,machine translation decoding,crease,gra dient,machine,friedman,newweak learner,feature,regression tree,differen tiable loss function,result,small gain,perfor mance,method,dramatic gain,feature induction,important machine learning task,ntroduction,linear model,machine translation,de-facto standard,researcher,large number,additional feature,tarowatan,chiang,param eter,method,chiang,hop kin,cherry,foster,pa rameter space,significant feature,effort,practition er,linear model,re searcher,important feature conjunction,jagarlamudi,related field,web search ranking,non-linear feature,dramatic improvement,quality,burges,research,author,intern ship,microsoft research,main insight,machine translation setting,share result,language pair,recent work,linearity assumption,mt feature,nguyen,non-parametric model,complete translation hypothesis,re-ranking setting,framework,non-linear feature,regression decision tree,regression tree,non linear feature combination,original fea tures,friedman,feature,differentiable loss function,applica tion,feature,regression decision tree,loss function,pairwise,log-loss, pro method,parameter tuning,hop kin,process,duced feature,phrase-pairs,language model,context,result,language pair,feature induction approach,small gain,performance,overall,method,promise,dramatic gain,web search,original feature,induction algorithm,full integration,sub stantial performance improvement,2 f eature,machine,linear model,machine translation,translation hypothesis,weighted sum,input feature,hypothesis,figure, a b ulgarian source sentence,conference,bulgaria,candidate transla tion,global feature,translation,smoothed relative frequency estimate,estimate,phrase-pair,language model log-probabilities,target phrase word,context,feature,weight,feature,hypothesis score,current state-of-the-art model,phrase-pairs,language model,context,hypothesis,hypothesis recombina tion,machine translation decoding,accurate search,exam ple,figure,show  a b ulgarian source sentence,latin script,translation,phrase-pairs,translation,phrase-pair,local feature function value,mini mal set,feature,simplicity,hypothesis-level,fea ture value,phrase-level,feature value,translation,feature weight,complete hypothesis,global feature value,local feature value,limited context outside,phrase-pair,language model score,re-ordering score,feature,phrase-pairs,context,state-of-the-art linear model,decomposable feature,additional feature,new feature,hypothesis,phrase-level score,new local phrase-level feature,non-linear combination,original phrase-level feature,figure,example,decision tree feature,left decision tree,right decision tree,constant node,induced feature,example,figure,new feature,intuition,feature,new feature,regression,cision tree,figure,example,intuition,phrase pair,training corpus,example,first phrase pair p1,figure,lexical weighting channel model score,smoothed relative frequency channel estimate,sion tree feature h1,figure,capture,tuition,feature value,phrase-pair,feature,effect,new feature h1,importance,lexi cal weighting score,phrase-pairs,low joint count,regression tree fea,constant leaf node,deeper tree,complex condition,several input feature value,non-leaf node,comparison,input feature value,threshold,leaf node,input feature,factor,regression tree,linear node,leaf node,expression,input feature,different coefficient,example,leaf node,h1 return affine function,deci sion tree feature,constant-valued leaf node,right-hand-side tree,figure,decision tree,constant,conjunction,several binary-valued input feature function,binning,real-values feature,conjunction,binned value,new feature,methodology,framework,gradient,decision tree weak learner,fried man,framework,original input feature,differ entiable loss function,detail,algorithm,initial feature,baseline mt system,relative frequency,lexical weighting channel model weight,language model,distortion penalty,word count,phrase count,multiple lexicalized re,weight,distortion type,feature,base feature,input set,feature,crease,possibility,useful feature combi nation,feature induction method,large feature set,feature,source,target word count feature,joint phrase count,lexical weight ing score,alternative word-alignment model,morpheme,dicator lexicalized feature,insertion,dele tion,language,cluster,insertion,deletion indicator,hard word clustering,cluster,signature,phrase-pairs,feature,weak learner induction,loss function,pair-wise ranking log-loss,pro parameter,method,hopkins,model score,hypothesis hi, ble score,first hypothesis, ble score,second hypothesis,specified threshold,sentence,corpus,sentence,hypothesis,loss-function,hypothesis model,implementation,sentence,translation,transla tions,probability proportional, ble score difference,difference,threshold,hypothesis pair, ble difference,computation,sentence-level  ble uscores,smoothing,computation,n-gram precision,parameter,figure,gradient,algorithm,local feature function,gradient,method,additional feature,func tional gradient,target loss function,next weak learner,feature,negative gradient,feature,hypothesis,loss function,function,local phrase-pair,context score,hypothe s,decompose,enumeration,phrase pair,context,input feature vector,phrase-pair,context,phrase-pair,pair wise log-loss,function,phrase,gradient,algorithm,figure,first step,algorithm,phrase-pair,linear function,input feature val ues,feature weight, pro loss,function,initial score,hopkins,method,parameter,fixed input feature,linear model, lbf g,optimization,exam ples,figure,iteration,parame ter vector,topology,parame ters,decision tree,feature value,compari son cutoff,val ues,leaf node,new decision tree,language train dev-train dev-select test chs-en, nis t02, nis t05 fin-en,data set,language pair chinese english,chs-en fin-enfeatures tune dev-train test dev-train testbase  mer,result,language pair,different weight,method,feature set,new feature,linear coefficient,feature,function,pa rameter,new model score,old model,weighted contribution,new feature,learn ing,linear model,input feature,additional decision tree feature,time-intensive step,algorithm,se lection,next decision tree,functional gradient,respect,phrase,current model score,derivation,gradient,regression tree,mean-square error minimization,direction,negative gradient,target,feature,phrase-pair,context,stance,setting,pa rameters,mean-squared-error minimization,algorithm,minimization,standard greedy tree-growing algorithm,breiman,weight,weight,initial feature,weight,duced learner,l2 penalty,parameter,3 e xperiments,experimental result,language pair,summarizes statistic,language pair,training set,phrase table,language model,a d ev-train set,feature weight,feature, a d ev-select set,hy perparameters, pro tuning,stop ping point,hyperparameters,boost ing method, a t est,final re sults,training corpus,sentence pair,hongkong portion, ldc data, nis t mt evaluation,dev-train,test set, nis competi tions,mt system,phrasal system,gram language model,xinhua por tion,english gigaword corpus,phrase table,maximum phrase length,data set,technical domain,software manual,language pair,language mod el,large model,billion,language model,target side,parallel training,port performance, ble u-sbp  metric pro,chiang,vari ant,papineni,strict brevity penalty,long translation,sentence,brevity penalty,sentence,short transla tion,chiang,several undesirable property,correlation,human judgement,experiment,different feature set,hyperparameters,stable result,correlation,dev-train,dev-select,test result,exper iments,weight,base fea ture set,section,dev-train,dev-select,test datasets,500-best list,result,report performance,re-ranking,500-best list,different feature set,parameter,method,baseline,base feature,performance,language pair,tuning set,test set,large feature,fea tures,section, mer training,feature,result, pro tuning,large set,quarter, a b leu-sbp  point,result,base feature,lan guage pair,performance,gradient,method,addition,decomposable feature,combination,global feature value,lose decomposability,fea tures,partial hypothesis,method,speed disadvantage,performance,n-best list re-ranking,potential accuracy gain,meth od,performance,addition,ficient decoder integration,gradient boosting result,boost-local model,large feature,improvement,boost-global method brings,degrada tion,large difference,perfor mance,different decision tree leaf node type,different maximum number,leaf node,boost-local model, fin -enu,maximum,leaf node,linear leaf value,new feature,performance,dev-select set,induced feature,finnish,combination,language model,channel model score,combination,word count,channel model score,combina tions,channel,lexicalized reordering score,example,feature,contribu tion,relative frequency channel score,phrase,many target word,channel model contribution,phrase,boost-local model,chs-enu,maximum,constant-values leaf node,new tree feature,fea tures,phrase pair,context,input fea ture,determined cutoff,conclusion,new method,feature combination,machine transla tion,decoding complex ity,small improvement,lan guage pair,re-ranking setting,im provements,original feature,duction algorithm,full integration,substantial perfor mance improvement,alternative way,non-linear feature,product,input feature,alternative,regression tree,reference leo breiman,jerome friedman,charles,olshen,classification,regression tree,chapman,chris burges,tal shaked,erin renshaw,matt deed,nicole hamilton,greg hullender,gradient descent,colin cherry,george foster,strategy,statistical machine translation,steve  den eefe,yee seng chan,hwee tou,decomposability,metric,improved evaluation,efficient algorithm, emn lp,david chiang,yuval marton,philp resnik,large margin training,struc tural translation feature,knight,new feature,statistical machine translation,naa cl,jonathan clark,alon lavie,chris dyer,system,many domain,open-domain statisti cal machine translation,feature augmentation,jagadeesh jagarlamudi,main adaptation,machine translation,unseen word,jerome,friedman,greedy function approx imation,gradient,machine,annals,statistic,mark hopkins,jonathan may,ranking, emn lp,patrick nguyen,milind mahajan,non-parametric feature,statis tical machine translation,second workshop,statistical machine translation,franz josef och,hermann ney,discrimina tive training,maximum entropy model,sta tistical machine translation,kishore papineni,salim roukos,todd ward,wei jing zhu,method,automatic evaluation,machine translation,tarowatanabe,jun suzuki,hajime tsukuda,hideki isozaki,large-margin training,statistical machine translation, emn lp,qiangwu,christopher,burges,krysta,jianfeng gao,infor mation retrieval measure,information retrieval,derivation,derivative,function,phrase level,context score,derivative,respect,number,phrase-pairs,context,hypothesis,sentence,input feature vector,interchange,phrase-pair,context,input feature vec tor,derivative,respect,phrase,parameter,loss function,loss function,huge number,parameter,instance,phrase pair,context,translation,loss function,arbitrary way,rection,direction,negative gradient,phrase-pair,context pr,hypothesis,sentence,phrase-pairs,context share,input feature,implementation,exposition,different train ing instance,gradient,respect,single sentence,account,hypothesis,right hypothesis,hypothesis con,boosting step,deci sion tree,negative gradient,feature induction algorithm,crease,phrase,hypothesis,first hypothesis,hypothesis,advantage,phrase,weaker hypothesis,high score,proceeding,annual meeting,association,computational linguistics,baltimore,maryland,association,computational linguistics graph-based semi-supervised learning,translation model,hany hassan,kristina toutanova,chris quirk microsoft research redmond,kristout,chrisq microsoft,com abstract statistical phrase-based translation,translation rule,bilingual corpus,used monolin gual evidence,feature,translation candidate,semi-supervised graph-based approach,new translation rule,monolingual data,tech nique,phrase graph,source,target language,lingual corpus,graph propaga tion identifies translation,phrase,bilingual cor pu,similar phrase,similar translation,result,large arabic-english system,medium-sized urdu-english system,approach,performance,competitive phrase,system,consistent im provements, 4 b leu  point,standard evaluation set,1 i ntroduction statistical approach,parallel corpus,translation rule,probabil ities,large amount,phrase-based translation system,chiang,state-of-the-art result,many ty,diverse language pair,factor,suc ce,technique,parallel data availabil ity,resource-rich language,re liable translation,multiword phrase,chal lenge,adequate phrasal inventory,first author,microsoft research,effective translation,problem,many language pair,par allel resource,parallel data,monolin gual resource,abundance,monolin gual data,phrasal translation,parallel data,challenge,translation,monolingual data,interest,several way,callison-burch,haghighi,knight,troduces,new take,problem,semi-supervised learning,trans lation rule,probability,parallel data resource,source side,phrase,known translation,bilingual corpus,unlabeled phrase,mono lingual corpus,monolingual data,edge strength,previous work,irvine,callison-burch,razmara,approach, oov mitigation,entire translation model,evidence,monolingual text,enhance ment,result,improvement,target side,translation,parallel data,target graph,translation option,structured graph propagation algorithm,translation information,unlabeled phrase,source,target phrase similarity,mate probability distribution,translation,source target el gato los gatos un gato,cat target prob,perro target prob,canine,dog catlike figure,example source,target graph,approach,phrase,source side,corresponding translation,target side,phrase,source,target side,phrase,conditional probability distribution,target phrase,parallel corpus,unlabeled source phrase,tional phrase, smt sys tem,secondary phrase,approach,arabic english,sce narios,amount,mono lingual corpus,improvement, 4 b leu  point,large language model,2 g eneration,ropagation,translation distribution,source phrase,phrase table,parallel corpus,par allel,monolingual corpus,probability distribution,target phrase,sufficient parallel resource,basic translation model,stan dard technique,availability,monolingual corpus,source,target language,technique ap ply,phrase,length,bigram phrase,substantial computational cost saving,monolingual data,separate similarity graph,phrase,word sequence,source similarity graph,phrase node,sequence,source language,source phrase,baseline phrase table,labeled phrase,conditional empirical probabil ity distribution,target phrase,parallel data,unlabeled phrase,algorithm find label,translation,unlabeled phrase,graph-based representation,la bel space,phrasal translation inventory,source side,target phrase node,parallel corpus,unlabeled phrase,possible target translation,possible target transla tions,unlabeled source phrase,probability distribution,target,graph propagation technique,generation,graph construction,propagation step,generation,objective,generation step,target graph,additional target phrase,unlabeled source phrase,full set,possible translation,phrase,generation,phrase node,target phrase,baseline phrase table,target graph,black node,target phrase,source phrase,bigram,target phrase,variable length,generation component,ob servation,structured label space,translation candidate,source phrase,similar phrase,different label,target translation,exponential dependence,length,stance,target phrase inven tory,parallel corpus,unlabeled instance,target,label space,unknown phrase,ve way,n-grams,maximum gram order,monolingual data,strategy,combinatorial explosion,number,target phrase,target space,linguistic information,mor phology,toutanova,chahuneau,baseline system,ate candidate,novel trans lation candidate,white node,probability,propagation,candidate,new translation candidate,baseline system,unlabeled source bigram,m-best translation,candidate phrase,target monolingual corpus,passed-through  oov word,invalid translation,new translation candidate,morphological infor mation,segment word,prefix,suffix,linguistic re source,morphological ana lyzer,context-independent analysis,word type,function,source,target word type,function,source,target sequence,sequence,morphological generation step,target graph,target word sequence,monolingual data,stem sequence,target,baseline phrase table,phrase,morphological variant,ex isting phrase,graph construction,source bigram phrase,target language phrase,variable length,phrase table,gen eration step,pairwise phrase similar ities,monolingual corpus,source,target side,distributional feature,context,phrase,phrase,pwords,phrase,o-occurrence count,feature,context word,monolingual corpus,standard practice,distributional similarity,cosine sim ilarity,phrase,vector,similarity,simi lar phrase,phrase,k-nearest neighbor similarity matrix,source,language phrase,propagation,co-occurrence count,phrase,inverted index data structure,mapping,feature,context word,co-occur,feature,window,index structure,graph construction cost,similarity,sub set,possible pair,phrase,phrase,feature,candidate translation list construction,translation candidate,unlabeled source phrase,probabil ity distribution,translation,graph propagation,probability,candidate,source,unlabeled phrase,neighbor,target phrase,transla tions,source phrase,unlabeled source phrase,un gato,source,others,candidate,generated candidate,unlabeled phrase,baseline system,frequent word,monolingual corpus,mapping,high en tropy feature,much information,k-nearest neighbor,transla tion candidate,method,target graph,minimal impact,decoder output,catlike,morphologically-generated candidate,source unlabeled phrase,target word sequence,mono lingual data,stem sequence,baseline,target translation,source phrase,stem sequence,unlabeled source phrase,candidate,stem-level translation probabili tie,morpheme-level lexical weighting probabili tie,language model,candidate,candidate,po sible source,lexical score,lexical model,baseline sys tem,top candidate,phrase,translation candidate list,figure,example output,system,handful,unlabeled source phrase,source,neighbor,graph propagation graph propagation algorithm transfer,formation,unlabeled node,structure,appli cation,certain number,problem,probability dis tribution,translation candidate,target,graph propagation,probability,candidate,source phrase,iteration,neighbor,similar node,quantity,propagation proba bility,exact form,graph propagation algorithm,pur pose,source phrasal node,refers,source phrase,neigh bors,k-nearest neighbor,probability,target phrase,phrasal,lation,source phrase,classic propagation algorithm,bilingual lexicon,duction,tamura,razmara,algorithm,cosine similarity,phrase,phrase,account source language similarity,phrase,observation,translation candidate,source phrase,propagation probability,phrase,target side,translation candidate list,original lp formulation,side information,generated transla tion candidate,unlabeled phrase,translation candidate,translation,labeled phrase,phrase,information,labeled phrase,candidate,probability mass,translation candidate,generation step,label propagation,similarity structure,target graph,structure,graph propagation,source graph,author,label propagation,effort,structured label,definition,target similarity,source similarity,therefore,final update equation,formulation,target phrase graph,propagation probability,probability distribution,propagation step,fixed list,translation candidate, slp algo rithm,convergence,graph propagation,unlabeled phrase,categorical distribution,translation candidate,phrase pair,relevant feature,phrase pair,log-probability fea tures,likelihood feature,lexical weighting feature,addition,sophis,manning,fea tures,phrase pair,ward phrasal probability,forward likelihood probability,acquired phrase,backward phrasal probability,phrase pair,marginal probability,source,phrase,monolingual data,baseline system,lexical model,forward,lexical score, hrm probabil ities,new phrase pair,baseline system,backing-off,average value,phrase,similar length,3 e valuation,extensive evaluation,ine various aspect,approach,overall system performance,language pair,arabic-english evaluation,decision,development,iteration,wall-clock time,minute,method,property,technique,impact,phrase,latter experiment,importance,generated candidate,morphological knowledge,generation process,formance,effect,large 5-gram language model train,english token,nature,improvement,evaluation,noisy parallel data,realistic low-resource language pair,language model,approach,noisy parallel data,traditional  smt system,baseline phrasal system,com parison,translation candidate,unlabeled phrase,baseline,state-of-the-art phrase-based system,word alignment,lexicalized hidden markov model,phrase ta ble,grow-diag-final heuristic,baseline feature,lexical,phrasal, 5 h rm,lan guage model,word penalty,phrase length feature,distortion penalty feature,feature weight,secondary phrase table,phrasal,fea tures,system,distortion limit,case-insensitive  ble,papineni,translation quality,datasets bilingual corpus statistic,language pair,corpus,sentence pair,standard  ldc corpus, nis t mt,mt08 arabic-english evaluation set,newswire,weblog domain,reference,tuning,urdu english,training corpus, nis t ur du-english mt evaluation,fil tering,4l dc2007t08,parameter description value,candidate list size,candidate,generation stage,p w indow size,feature,phrase,q f ilter,frequent word,inverted index data structure,graph construction,source,target side share,k n umber,neighbor,phrase,source,target graph,parameter,sparsity,r m aximum size,translation candidate list,unlabeled phrase,parameter,explanation,function,tences,dictionary entry,tuning,test data con,mt09 evaluation corpus,mixture,web text,corpus sentence word,ar-en train,ur-en train,bilingual corpus statistic,urdu-english datasets,contains statistic,monolingual corpus,experiment,cor pora,sentence,source,target phrase match,pute feature,graph construction,ara bic,experiment,monolingual cor pora, afp arabic,english gigaword corpus,similar date range,corpus sentence word ar comparable,en  i c,ur noisy parallel,en ii noisy parallel,monolingual corpus statistic,urdu-english evaluation,monolingual corpus,noisy parallel,comparable component,english side,arabic-english corpus,english side,urdu-english corpus,urdu-english experiment,non-comparable monolingual text,graph construction,urdu side,web-crawler,subset, afp gigaword english corpus,english,addition,corpus,parallel,monolingual data,timestamps,compa rable english corpus, elr a ur du,gual data,470k-sentence,noisy parallel,ei ther,parallel data,non-comparable monolingual data,graph construction,parameter,reminder,terpretation,experimental variation,first set,experiment,im pact,bigram,ba sic unit,representation,performance,account source sim ilarity,vast majority,didates,labeled neighbor,propagation,source graph dras,generated candidate,experiment,reasonably-sized 4-gram language model,english monolingual corpus,present,result,variation,account,candi date,bigram, ble gain,test set,baseline,importance,translation,sparser bigram,reason,underperformance,underline,importance,trans lation space,generated candidate,candidate,unigrams,bigram,source graph,experimental clarity,phrase length,halfmono,monolingual comparable corpus,improve ment, ble point,monolingual data,system,interestingly,candidate,monolingual corpus,candidate,lp-halfmono,result,arabic-english evaluation,importance,target,translation candidate generation,2-gram comparison,importance,emphasiz ing phrase,monolingual data show,tivity,monolingual corpus size,morphological information result,additional improvement,additional,candi date,experiment,simple hand-built arabic morpho logical analyzer,word type,regular expression,english lexicon,morphological analyzer,morphological candidate,small amount,improvement,genuine  oov,large language model effect,experiment,improvement,extraction,language model char acteristics,semi-supervised learning phase,orthogonal piece,evidence,improvement,large language model,question,5-gram language model,sentence,various source,web-crawled data,wikipedia,candidate,baseline,generation,labeled neighbor,la bel,dc2011t07,statmt,result,large language model scenario,language model,present,result,lan guage model,addition,phrase,genuine transla tion improvement,language model effect,examination,difference,system,improvement,bigram,trigram, ble score precision,n-gram,quality,candidate,baseline system,output,system,output analysis section,robustness,result,language pair,urdu english,low resource pair,approach,experiment,large language model,baseline-generated candidate,extreme setup,base line system,source,target graph,first setup,noisy parallel data,graph construction,augment,non comparable corpus,result,base line,second setup,baseline system,noisy parallel text,reinforcement strong reinforcement,extinction  oov,thwart,abdalmahmood,abdul mahmood mahmood,nine example output,system,baseline,property,approach,example,arabic source,urdu source,system candidate,candidate,phrase,neighbor,candidate,result,base line noisy,method,noisy parallel data,graph construction,parallel,ex amine,realistic scenario,non-comparable monolingual text,graph con struction,slp noisy,baseline noisy,result,urdu-english evaluation,experiment,language model,generation,candidate,baseline system,first setup,huge improvement,lp noisy,monolingual data,noisy parallel data,graph construction,method,supervised baseline approach,noisy parallel data,conjunction,assumption,nature,corpus,non-comparable monolingual text,english side,large language model,excess,difficult evaluation scenario,technique,genuine translation improvement,ve memorization,n-gram sequence,analysis,output figure,sample hypothesis,system,baseline,reference translation,output,system,origin,neighbor,arabic-english example,first example,source bigram,baseline system,sub optimal translation,system,correct translation,reinforcement,second example,baseline system,system,perfect translation,fourth ex amples,bigram phrase,much bet ter translation,lexical translation,baseline,fifth arabic-english example,pitfall,over-reliance,distributional hypothesis,source bigram corresponding,almahmood,entity,mahmood,english,translation,distributional hypothesis,sixth example,morphological informa tion,novel candidate, oov word,analyzer,candidate,urdu-english example,example,bigram,par umeed,baseline system,monolingual corpus,context,unlabeled bigram,graph structure,correct form,flu ent,correct sentence,lan guage model,example,show case,baseline,common word,conversation,system,reasonable candidate,spirit,seed lexicon,different language,monolingual corpus,distributional similarity,word context,others,knight,inter alia,downstream perspective,translation,small number,oftentimes,recent improvement,tamura,irvine,callison-burch,graph-based flavor,label propagation-based approach,seed lexicon,evaluation,top-3 accuracy,unigrams,razmara,irvine,callison burch,conduct,extensive evalua tion,graph-based  bli technique,emphasis,end-to-end  ble evaluation,entire translation model,previous  bli work,approach,account source-side similarity,latter work,sub set,language pair,structured propagation algorithm,approach,mul tiple translation candidate,top translation,klementiev,method,pre-existing phrase table,small bilingual lexicon,performs,lingual corpus,operational scope,ap proach,scenario,unknown phrase pair,translation candidate generation,unknown phrase,estimation,phrasal proba bilities,phrase pair,graph structure,monolingual data,separate gener ation step,important role,good performance,method,series,heuristic,narrow setting,notion,translation consensus,similar sentence,source side,similar target language translation,graph-based approach,alexandrescu,kirchhoff,method,label propagation algorithm,generalization,single label,formation,decoder,algorithm,propagation step,former work,sentence,latter,framework,sub-spans,sen tences,new translation pair,phrasal probability,new pair,re-estimate phrasal probability,graph structure,additional feature,non-parallel data,ma chine translation,several different angle,paraphrase,third language,callison-burch,monolingual corpus,distributional similarity,marton,cross-lingual information retrieval technique,potential sentence-level translation candidate,com parable corpus,corpus,comparable corpus,problem,knight,knight,monolingual view,problem,combine phrase table,log-linear model,feature weight training,5 c onclusion,approach,translation model,bilingual corpus,large amount,monolingual data,source,target language,provements,strong baseline,evaluation set,scenario gain,excess, 4 b leu  point,future,graph structure,distributed representation,author,chris dyer,arul menezes,anonymous reviewer,helpful comment,suggestion,reference andrei alexandrescu,katrin kirchhoff,graph-based learning,statistical machine trans lation,proceeding,human language tech nologies,annual conference,north american chapter,association,association,computational linguistics,rej bojar,christian buck,chris callison-burch,christian federmann,barry haddow,philipp koehn,christof monz,matt post,radu soricut,lucia specia,finding,work shop,statistical machine translation,pro ceedings,eighth workshop,statistical ma chine translation,bulgaria,au gust,association,computational linguistics,chris callison-burch,philipp koehn,mile o borne,statistical machine trans,paraphrase,proceeding,human language technology conference,naa cl,main conference,association,computational linguistics,victor chahuneau,eva schlinger,chris dyer,rich language,synthetic phrase,emn lp,david chiang,hierarchical phrase-based trans lation,computational linguistics,kevin knight,scale deci pherment,out-of-domain machine translation,proceeding,joint conference,empir ical method,natural language processing,computational natural language learning,association,computational linguis tic,pascale fung,lo yuen yee,ir approach,new word,compa rable text,proceeding,annual meet ing,association,computational linguis tic,international conference,computa tional linguistics volume,association,com putational linguistics,michel galley,christopher,manning,effective hierarchical phrase,association,computational linguis tic,aria haghighi,percy liang,taylor berg-kirkpatrick,dan klein,bilingual lexicon,monolingual corpus,proceeding,columbus,association,computational linguistics,ann irvine,chris callison-burch,comparable corpus,low re source machine translation,proceeding,eighth workshop,statistical machine transla tion,bulgaria,august,sociation,computational linguistics,ann irvine,chris callison-burch,bilingual lexicon induction,multiple monolingual signal,proceeding,conference,north american chapter,association,computational linguistics,human language technology,atlanta,georgia,association,computational lin guistics,alexandre klementiev,ann irvine,chris callison burch,david yarowsky,toward sta tistical machine translation,parallel corpus,proceeding,13th conference,euro pean chapter,association,computational linguistics,avignon,france,association,computational linguistics,philipp koehn,kevin knight,translation lexicon,monolingual corpus,proceeding, acl workshop,unsupervised lexical acquisition,franz josef och,daniel marcu,statistical phrase-based translation,pro ceedings,conference,north amer ican chapter,association,computational linguistics,human language technology vol,association,computational linguistics,shujie liu,ming zhou,translation consensus,structured la bel propagation,proceeding,50th annual meeting,association,computational lin guistics,long paper volume,association,computational linguistics,yuval marton,chris callison-burch,philip resnik,statistical machine trans,monolingually-derived paraphrase,proceeding,conference,empirical method,singapore,august,association,computational linguistics,david  mcc losky,eugene charniak,mark john son,effective self-training,proceeding,human language technology conference, naa cl,main conference,association,computational linguistics,franz josef och,minimum error rate training,statistical machine translation,proceeding,annual meeting,association,computa tional linguistics volume,association,com putational linguistics,kishore papineni,salim roukos,todd ward,method,automatic eval uation,machine translation,reinhard rapp,word translation,non-parallel text,proceeding,nual meeting,association,kevin knight,eign language,proceeding,annual meeting,association,computational lin guistics,human language technology,oregon,association,computational linguistics,majid razmara,maryam siahbani,gholamreza haf fari,anoop sarkar,graph propagation,out-of-vocabulary word,statis tical machine translation,proceeding,association,association,computational linguistics,matthew snover,bonnie dorr,richard schwartz,language,translation model adaptation,comparable corpus,proceeding,conference,empirical method,association,computa tional linguistics,akihiro tamura,taro watanabe,eiichiro sumita,bilingual lexicon extraction,compara ble corpus,label propagation,proceeding,joint conference,empirical method,natural language processing,kristina toutanova,hisami suzuki,achim ruopp,morphology generation model,machine translation,proceeding,columbus,asso ciation,computational linguistics,jiajun zhang,chengqing zong,phrase-based translation model,monolingual data,application,adaptation,pro ceedings,annual meeting,associa tion,computational linguistics,volume,long paper,bulgaria,august,association,computational linguistics,xiaojin zhu,zoubin ghahramani,laf ferty,gaus sian field,harmonic function,proceeding,twentieth international conference,proceeding,fifteenth conference,computational natural language learning,portland,oregon,association,computational linguistics learning discriminative projection,text similarity measure wen-tau yih kristina toutanova john,scottyih,kristout,jplatt,meek microsoft,com abstract traditional text similarity measure,semantic relatedness,novel discriminative training method,project,raw term vector,com mon,low-dimensional vector space,ap proach,optimal matrix,cosine,projected vector,large number,example,high dimensional space,dif ferent task,cross-lingual document retrieval,ad relevance measure,method,state-of-the-art ap proaches,high accuracy,low dimension,1 i ntroduction measure,text similarity,many application,ir community,example,combination,corpus,knowledge,method,word similarity,agirre,large scale web corpus,typed entity,pantel,degree,similarity,document,classical ir prob lem,document retrieval,application,vector-based similarity method,term vector,origi nal text object,weight,importance,pre-selected function,vector,cosine,output,final similarity score,ap proach,instance,term vector,raw data need,pruned inverse index,fast similarity search,main weakness,term-vector representation,influence,final similarity score,illustrative ex ample,term-vectors,purchase,automobile,vector,similar concept,similarity score,function,cosine,jaccard,cross-lingual setting,language vocab ularies,term-vector rep resentations,similarity,document,different lan guages,general strategy,prob lem,raw representation,common concept space,extensive approach,method,category,generative topic model,la tent dirichlet allocation,probabil ity distribution,hidden topic,lin ear projection method,latent semantic anal ysis,projec tion matrix,original term-vectors,dense low-dimensional space,metric learn,approach,high-dimensional space,dhillon,new projection learn,framework,similarity learning,concept vector representation,input text ob jects,general siamese neural network architecture,bromley,approach,identical network,put layer,original term vector,output layer,projected concept vector,model parameter,weight,projection matrix,raw term vector,similarity score,output vector, s2n et,linear projection,ric learning approach,additional ad vantage,method,model form,objective function,true evaluation,interest,target task,performance,meth od,number,labeled example,property,cru cial,method,comparable cross-lingual document,accuracy,dimension,concept space,monolingual setting,relevance,ad landing page,performance,number,ap proaches,raw  tfi df cosine baseline,survey,emphasis,ap proaches,experimental comparison,method,report,extensive experimental study,revious work,section,ap proaches,high-dimensional term vector,document,document-specific distribution,finite number,document,word token,topic-specific word distribution,latent dirichlet allocation,proper generative model,document,place dirichlet prior,parameter,experiment,implementation,maximum,inference,bayesian inference method,asuncion,topic model,tuples,doc uments,translation,multiple lan guages,document,language,instance,extension,view document,tu ple,document,language specific,word-topic-distribution  mul ti,additional model,close variant,doc uments,language share,word-topic distribution parameter, map inference, jpl sa,paired document,prior topic distribution,similar fraction,constraint,expectation,po terior regularization,ganchev,linear projection method,method,term vector,low-dimensional concept space,latent seman tic analysis,document,corpus,performs,singular value,eigen-decomposition,correlation matrix,sim ilar,component analysis,covariance matrix,prac tice,term vector,correlation matrix,covariance matrix,different way,instance,comparable document,different lan guages,generalized eigen problem,noise covariance matrix,com parable document,canon ical correlation analysis,projection,cross covariance,projected vector,distance metric learning,similarity,vector,equivalent,distance,cosine score,bijection mapping,eu clidean distance,unit vector,learns  a m ahalanobis distance,standard,euclidean distance,similarity,element,different dimension,positive semi-definite matrix,vector,computational complexity,general mahalanobis matrix,dimensionality,input vector,method,high dimensional problem,text domain,special metric learning approach,high-dimensional space,example,high dimen,metric learning,dhillon,regular projection ma trix,information-theoretic metric learn,dtvp vq,tw tw figure,learning concept vector,output layer,small number,concept node,weight,linear combination,original term weight,3 s imilarity learning,given pair,document,real-valued similarity score,projection matrix,term-vectors,low-dimensional con,similar document,sim ilarity,framework,projection,section,model design,training process,model design,network structure,consists,lay er,input layer,raw term vec tor,original vocabulary,associated value,term-weighting function, tfi df,put layer,learned low-dimensional vector rep resentation,relationship,output layer,ele ment,new concept vector,final similarity score,cosine function,standard choice,document similarity,similarity function,output,concept node,linear com,bination,weight,orig inal term vector,complete bipartite graph,output,concept node cj,sigmoid,result,current design,model form,low-rank projection matrix,comparison,projection method,concise matrix notation,raw d-by-1 term vector,projection matrix,k-by-1 projected concept vector,loss function,training procedure,term vector,similar ity score,cosine value,concept vector,projection,true label,loss function,many application,similarity score,text object,example,query document,comparable document,target language,document,scenario,similarity measure,good ordering,target similarity score,pairwise,similarity score,vector pair,term vector,first pair,similarity,difference,similarity score,following logistic loss,cosine function,scaling factor,magnifies,prediction error,dif ference,large enough1,ex periments,gradi ent,method,gradient,whole batch,quasi-newton optimiza tion method  l-b fgs ,nocedal,wright,presentation,gradient derivation,appendix,optimization problem,good projection matrix,training time,local minimum,regularization,learned model,early stop ping,latter,experiment,4 e xperiments,ap proaches,different task,cross-lingual document retrieval,ad relevance measure,comparable document retrieval,growth,multiple language,demand,cross lingual document,instance,machine trans,system,sentence,parallel,comparable document,munteanu,ord-level translation lexicon,comparable document,cross-lingual document retrieval task,query document,language,similar document,corpus,language,comparable document retrieval,wikipedia dataset,data set,wikipedia document,parameter,baseline,experiment,language,english,spanish,article,english, a s panish article,language,wikipedia community,fair compari son,term vector,data split,previous study,number,document pair,training development,dimensionality,raw term vector,english document,document,vice versa,result,direc tions,performance,metric,top-1 accuracy,document,similarity score,true comparable document, s2n et model,compara ble document pair,positive example,negative example,independent example,training,computation,batch gradient,com pact matrix operation,training,matrix,formance,development set2,approach,method,clude result,addition,improved  jpl sa, cpl sa,setting,separate vocab ularies,language,poly-lingual topic model,em iteration,jensen-shannon distance,l1 distance, hdl algorithm,algorithm,number,example increase,negative docu ment pair,training,outperforms,random,cl-lsi matrix,example,number,dimension, mrr score,cl-lsi,matrix,mrr score,figure,mean reciprocal rank versus dimension,wikipedia,result,cl-lsi,hyper-parameter setting,initial model,matrix,result, mrr performance,development set,different dimen sionality setting,concept space,figure,dimension,result,addition,method,differ ent dimension,input vector,low-dimensional space,efficiency,instance,dimension,aleady performs,dimension,averaged top-1 accuracy,mrr score,method,test set,dimensionality,method,development set,method,difference,accuracy,ad relevance paid search advertising,main revenue source,modern commercial search engine,satisfactory user experience,impor tant,relevant ad,regular search,unpaired t-test,bonferroni correction,difference,algorithm dimension accuracy  mrr s2n et,cpl sa,jpl sa,test result,comparable document retrieval,wikipedia,result,cl-lsi,result,previous work,ad relevance,appropriate term-vectors,broder,section, s2n et,ad pair,vector rep resentation,monolingual setting,ad relevance dataset,consists,unique query,bing search engine,number,result,total number,query-ad pair,dataset,query-ad pair,experi ment,binary classification prob lem,superset,disjoint,pairwise comparison,training,evaluation,rele vance order,subset superset disjoint,dataset,training,validation,little content,web relevance feedback technique,broder,pseudo document,data set,search engine,result page,snippet,pseudo-document,raw term vector,ad side,ad landing page,short ad-text,vocabulary set contains,document frequency table,large collection,web document,pre-selected threshold,depends, s2n et,preference pair,following way,rel evant ad,loss function,similarity score,sample,training pair,train ing example, jpl sa,parallel corpus,rele vant pair,negative exam ples,irrelevant pair,training query,document,relevance information, s2n et,method,ent application scenario,ad relevance measure,ad filter,similar ity score,decision threshold,ir relevant,evaluation metric,scenario, roc analysis,ranking scenario,relevance score,sce nario,performance,standard ranking,kekalainen,different method,basic term vec tor representation, tfi df weighting,baseline,raw input,linear pro jection method,result,devel opment, pca performs,mod el, pca matrix,summarizes result,test set, tfi df,dimension,configuration setting,validation,strong baseline,monolin gual ad relevance dataset,method,dimension,raw  tfi df cosine measure,eval uation,difference,tfi df,cpl sa,jpl sa, ndc score,cosine sim ilarity,different vector representation,di mension, tfi df,figure, roc curve,cpl sa,similarity score,ad filter,nificant4,contrast, cpl sa, ndc score, auc value,cosine score,vector represen tations,ad filter, roc curve,fo cusing,low false-positive region,similar ity score,vector,quality,raw  tfi df representation,ap proaches,per formance,low false-positive region,consis tent, auc score,dimensional ity,concept vector,subset,paired-t test,corresponding  auc score,paired-t test,difference,p-value,efficient processing,quality,concept vector representation,variable, ndc score,different di mensions,result, tfi df, cpl sa,dimension, s2n et surpasses,dimension,dimen sionality increase, ndc score,dimension,discussion,strong performance,different task,simple model,empirical suc ce,factor,loss function,training example,target task,large number,example,exam ples,matrix,initial model,cross-lingual document retrieval,linear projection method,generative topic model,scalability,method,eigen decomposition,training time,complex ity,covariance matrix,number,dimension,regular eight-core server,projection matrix,experi ments,training time,number,dimension,training example,iteration,projec tion,gradient derivation,complexity,num ber,distinct term-vectors,number,non-zero element,sparse term-vectors,dimensionality,concept space,cross-lingual document retrieval,iteration,minute,iteration,gradient computation,speed-up,cluster,tfi df  hdl r cplsa pca s2ne t100  s2n, s2n et500  s2n, s2n et1000, ndc score,different dimension,dimension,raw  tfi df representation,reference,high-level design,siamese architecture,bromley,chopra,network construction,loss func tion,training process,previous work,example,application,face verification,chopra,convolutional network,contrastive loss function, ae ucliden distance,contrast,network, s2n et,linear projection ma trix,pairwise loss function,learning framework,several neural network,approach,autoencoders,hinton,salakhutdinov,low-dimensional word representation,col lobert,weston, s2n et,ranknet,burges, a s iamese neu ral network,ranking function,strategy,document,distance metric learning,high dimensionality,problem,different scalability issue,experiment,al gorithm,small number,simi larity dissimilarity constraint,labeled ex amples,large number,example,hyper parameter setting,performance,iteration,iteration,application,concept vector,traditional ir task,instance,semantic analysis,retrieval re call,wikipedia,companion pa,various topic mod el, s2n et,ranking func tion,text categorization,simi larity,kernel,learning algorithm,classification accuracy,representative approach,latent semantic kernel,ker nel function,document collection,term-similarity,linguis tic knowledge,wordnet,basili,bloehdorn,moschitti,6 c onclusions,discrimina tive approach,projection matrix,raw term-vectors,low-dimensional space,method,cosine score,projected vector,reliable similarity measure,strength,model design,different task,cross-lingual document retrieval,prior approach,ad selection,filtering,alo outperforms,method,technique,raw  tfi df vector,success,different direction,enhance,future,instance,non linear transformation,addition,text object,differ ent distribution,span ish document,different matrix,model expressivity,s2n et,text similarity task,word similarity,entity recognition,discovery,reference eneko agirre,enrique alfonseca,keith hall,jana kravalova,marius pasca,aitor soroa,similarity,relatedness,wordnet-based approach,proceeding,hlt -naa cl,arthur asuncion,max welling,padhraic smyth,yee whye teh,inference,topic model,roberto basili,marco cammisa,alessandro mo chitti,effective use,wordnet semantics,kernel-based learning, con ll,andrew,jordan,john lafferty,latent dirichlet alocation,machine learning research,stephan bloehdorn,alessandro moschitti,semantic kernel,text clas sification,andrei,broder,peter ciccolo,marcus fontoura,evgeniy gabrilovich,vanja josifovski,lance riedel,search,web relevance feedback,jane bromley,bottou,isabelle guyon,yann  lec un,cliff moore,roopak shah,signature verification,time delay neural network,interna tional journal pattern recognition,chris burges,tal shaked,erin renshaw,ari lazier,matt deed,nicole hamilton,greg hullender,gradient descent,landing page,search ad selection,sumit chopra,raia hadsell,yann  lec un,similarity,ap plication,verification,proceeding,ronan collobert,jason weston,unified ar chitecture,natural language processing,deep neural network,multitask learning,nello cristianini,john shawe-taylor,huma lodhi,latent semantic kernel,journal,intelligent information system,inderjit,dhillon,metric learning,high dimensional problem,brian kulis,prateek jain,suvrit sra,inderjit,dhillon,ric learning,scott deerwester,susan dumais,george furnas,thomas landauer,richard harshman,latent semantic analysis,journal,american society,information science,diamantaras,cipal component neural network,theory,appli cation,wiley-interscience,dumais,letsche,michael,littman,thomas,landauer,automatic cross linguistic information retrieval,latent seman tic indexing, aaa i-97 spring symposium series,cross-language text,speech retrieval,ofer egozi,evgeniy gabrilovich,shaul markovitch,concept-based feature generation,selection,information retrieval,pascale fung,lo yuen yee,ir approach,new word,compara ble text,proceeding,joao graca,jennifer gillenwater,ben taskar,posterior regularization,latent variable model,technical report m -ci s-09-16,university,pennsylvania,jianfeng gao,kristina toutanova,wen-tau yih,clickthrough-based latent semantic model,web search,hinton,dimensionality,neural network,sci ence,thomas hofmann,probabilistic latent semantic indexing,kekalainen,ir evaluation meth od,relevant document,si -gi,dekang lin,automatic retrieval,clustering,similar word,christopher,manning,prabhakar raghavan,hin rich schu,introduction,information re trieval,cambridge university pres,david mimno,wallach,jason naradowsky,andrew  mcc allum,polylingual topic model, emn lp,dragos stefan munteanu,daniel marcu,machine translation performance,non-parallel corpus,computational linguistics,jorge nocedal,stephen wright,numerical optimization,springer,edition,john platt,kristina toutanova,wen-tau yih,translingual document representation,discrimi native projection, emn lp,reinhard rapp,automatic identification,word translation,unrelated english,german cor pora,proceeding,joseph turian,lev ratinov,yoshua bengio,word representation,simple,general method,semi-supervised learning,alexei vinokourov,john shawe-taylor,nello cris tianini,semantic representation,cross-language correlation analysis,patrick pantel,semi-automatic entity,refinement,wen-tau yih,ning jiang,similarity model,ad relevance measure, mlo ad  nip,workshop,online advertising,gradient derivation,gradient,loss function,projected concept vector,gradient,cosine score,following step