proceeding,conference,empirical method,sydney,association,computational linguistics phrasetable,statistical machine translation george foster,roland kuhn,howard johnson national research council canada ottawa,ontario,canada firstname,abstract,different strategy,give result,translation,smooth ing,relative frequency estimate,smoothing technique,con sistent gain,1 i ntroduction smoothing,important technique,statistical nlp,perennial data sparseness,empirical distribution,training corpus,statistical machine translation,state-of-the-art phrase-based  smt relies,large set,ngram pair,source,target language,translation probability,million,phrase,excellent candidate,publication,technique,detail,first system atic study,method,phrase-based smt,new idea,method,oth er,main purpose,vent new method,method,experiment,many language pair,consistent gain,translation performance,surface,many combina tions,technique,source phrase,translation,associated translation probability,joint frequency,source target phrase,word-aligned parallel corpus,maximum-likelihood estimation,relative frequency,con ditional probability,estimation problem,obvious example,phrase pair,con stituent phrase,corpus,conditional probability,estimated probability,evidence exists,typical case,latter,constituent,phrase,phrase pair,direct com petition,estimation bias,favour,infrequent pair,degrade translation quality,excellent discussion,tech niques,goodman,goodman,differs,ngram lm smoothing,follow ing way,individual unseen event,decoder,phrase translation,non-zero count,estimate,probability mass,unseen translation,probability mass,translation,obvious lower-order distribution,backoff,important tech niques,ngram lm smoothing,bine estimate,previous,previous,direct analog,phrasetable smoothing,object,word sequence,language,contrast,single word,decomposition,purpose,various way,special feature,phrasetable smoothing problem,give evaluation,perfor mance,phrase-based  smt system,section,brief description,phrase-based  smt system,section,tech niques,section,review previous work,sec tion,experimental result,section,concludes,future work,2 p hrase-based statistical mt given,source sentence,phrase-based  smt system,target sentence,likely translation,search,viterbi approximation,likely combination,alignment,argmax,tar get phrase,source phrase,translation,kth target phrase,first approximation,exception,dif ferent phrasetables,parallel,certain class,entity,feature function,weight,algorithm,development corpus,feature,length,single-parameter distortion penalty,phrase reordering,translation model probability,language model probability,kneser-ney smoothing,sri lm toolkit,stolcke,fea tures,phrase,phrase,phrase probability,feature,filter,possible translation,source phrase,top-ranked translation,accord,joint count,phrase induction algorithm,symmetrized word alignment gener,technique smoothing,recipe,conditional distribution,pure relative frequency estimate,joint count,data sparsity,spirit,relative frequency estimate,high complexity,high variance,low bias,complexity,vari ance,high bias,bet ter performance,new data,main ingredient,recipe,probability distribution,relative frequen cies,parameter,complex,technique,distribution,relative frequency estimate,choice,distribu tion,combina tion technique,discussion,relative frequency distribution,choice,distribution,approach,phrase table,black-box technique,inside phrase,atomic object,expression,nothing,contrast,glass-box method break,component word,black-box approach,sim pler,little attention, smt literature,interesting aspect,approach,technique,technique,problem,prob lem,bigram conditional probabil ity,experimental result,technique,good-turing,fixed-discount,kneser-ney,modified kneser-ney lm,glass-box method,phrasetable smoothing,author,sec tion,author,lexical distribution,inde pendence assumption,possibility,spirit,lm lower-order estimate,estimate,wildcards,section,choice,combination technique,variety,glass-box smoothing distribution,combination technique,linear interpolation,black-box smoothing,log linear interpolation,glass-box smoothing,black-box smoothing,backoff scheme,interpolation scheme,scheme,higher-order distribution,smooth backoff distribution,threshold,version,probability mass,unseen event,interpolation scheme,coefficient,goodman,key difference,interpolation,backoff,former approach,information,distribution,higher-frequency event,low-frequency event,phrasetable smooth ing,prediction,zero-count,direct impact,interpolation,suitable approach,relative-frequency estimate,glass-box smoothing distribution,ployed loglinear interpolation,tradi tional approach,glass-box smoothing,difference,loglinear interpola tion,bernoulli distribu tions,method,plinear,ploglin,ploglin,serf extreme value,inter mediate value,plinear,opposite property,extreme value,intermediate value,advantage,loglinear interpolation,loglinear weight,true objective function,instance  ble,translation model,weight,lim itation,experiment,loglinear weight,glass-box tech niques,al gorithm,linear weight,black-box technique,glass-box technique,ad vantage,different smoothing technique, ble implementing,al gorithm,linear weight,priority,discussion,single set,conditional distribution,phrase,differ ent length,different statistical property,separate phrasetables,purpose,similar strategy,smoothing scheme,individual smoothing scheme,black-box technique,good-turing,fixed-discount technique,fixed-discount inter,unigram distribution,kneser-ney fixed-discount,glass-box technique,koehn-och-marcu  ibm smoothing,experiment,individual scheme,loglinear com binations,black-box technique,glass box technique,good-turing good-turing smoothing,well-known tech nique,church,formula,modified count value,subsequent relative-frequency estimate,number,intuitive motivation,formula,relative-frequency estimate,corpus,good turing smoothing,instance,phrase pair,large corpus,solution,problem,technique,church,linear least square,function,result,reliable value,error term,fitted value,implementation,separate count,length,total count mass,unseen phrase pair,context,proportion,final estimate,fixed-discount method fixed-discount method,fixed discount,non-zero count,probability mass,distribution,kneser,interpolated version,fixed-discount,goodman,origi nal backoff version,phrase pair,distribution,distribution,malization constraint,number,phrase,choice,kneser-ney lower-order distribution,proportion,unique target phrase,source phrase,target phrase,new context,kneser-ney smoothing distribution,discounting coefficient,leave one-out analysis,kneser-ney smoothing distribution,modified kneser-ney,extension,goodman,specific coefficient,small count value,maximum,formu la,lexical decomposition,glass-box technique,source phrase,inde pendence assumption,approach,source word,dependent,variant,probability,translation,relative-frequency estimate,corpus,implementation,probability,noisy-or combination,translation,complement,translation,likely alignment connection,implementation,method,connection,probability,lm ngrams,naturally-ordered sequence,distribu tions,last word,context,phrasetable smoothing,others,technique,estimate,particular target,wildcards,original relative frequency,simple scheme,combin,target phrase,tf-idf,reverse,particular source,wildcards,new glass-box smoothing technique,considerable appeal,spirit,collins,backoff method,prepositional phrase attachment,collins,goodman,comprehensive survey,evalua tion,technique,language mod, ibm model,alignment probability,combina tions,sentence length,position,training data,lexical probability,rare word,word-alignment perfor mance,langlais,report negative result,synonym-based smoothing,lexical probability,phrase,phrase,phrase-based  smt,zero probability,phrase induction,dif ferent variant,glass-box smoothing,lexical smoothing,estimate,pure relative frequency one,loglinear model,witten-bell smoothing,black-box technique,phrasetable count,comparison,method,witten-bell,goodman,kneser-ney smoothing,method,5 e xperiments,experiment,broad-coverage one,european language pair,tech niques,small training corpus,chinese,experiment,technique,large train,corpus,black-box technique,smoothed phrase table,phrase table,glass-box technique,phrase table,original rf phrase table,replacement,black-box smoothing,loglin ear fashion,glass-box distribu tion,weight,velopment corpus,significance,result,different method,1000-fold pairwise bootstrap,confidence level,broad-coverage experiment,benefit,small corpus,exercise,access,resource,statistical phrase,translation system,number,language pair,corpus,sentence,proceeding,european par liament,separate sentence-aligned parallel cor pora,sentence,language pair,source,lan guages,provided 2000-sentence dev set,loglinear parameter,3064-sentence test set,result,discount coefficient,loglinear combination,kn3 phrasetables,phrasetables,combination,rf zn-ibm1,phrase table smoothing,minimum improvement,difference,meth od,kneser ney,significant im provement,gt smoothing,minimum gain,discounting co efficients,relative frequency,additional zens-ney,kneser ney,kneser-ney,zens-ney,clear gain,method,language,approach,chinese-english experiment,effect,corpus,experiment,chinese-english translation,corpus, nis t mt,evaluation,gov speech test,large size,out-of-domain un corpus,phrasetable,parallel corpus,subset,english gigaword corpus,lm training material,multi-p3 dev,eval-04 test,chinese-english corpus table,contains result,chinese-english experiment,fixed-discount,uni gram,koehn-och-marcu,method fr,broad-coverage result,section,broad-coverage experiment,black-box smoothing technique,rf baseline,large-corpus setting,meth od,fixed discount variant,little dif ference,glass-box method, kom -ibm,combination,result,rf zn-ibm1,con strast,situation,broad-coverage set ting,rf zn-ibm1,glass-box combination,method  ble score rf,chinese-english result,difference,broad coverage setting,chinese-english setting,broad-coverage corpus,chinese english learning curve,rf zn-ibm1,kn3-zn-ibm1 method,figure,result,kn3 zn-ibm1 curve,obvious characteristic,method,particular cor pu sample,bl eu proportion,corpus learning curve,method rf zn-ibm1 kn3 zn-ibm1 figure,learning curve,glass-box com binations,6 c onclusion,future work,tech niques,different translation setting,eu ropean language pair,small cor pora,chinese,translation,large corpus,technique,category,black-box method,phrase-pair count,glass-box method,compose phrase probability,lexical proba bilities,implementation,black-box tech niques,linear interpolation,relative frequency estimate,distribution,glass-box technique,log linear fashion,relative-frequencies,black-box estimate,technique,significant gain,pure relative-frequency estimate,small-corpus setting,technique,loglinear combination,kneser ney count,zens-ney glass-box smoothing,average gain,relative frequency,large-corpus setting,technique,log linear combination,relative-frequency estimate,zens-ney smoothing,method,slight advantage,koehn-och-marcu,black box method,kneser-ney,bet ter,small corpus,good turing,corpus,alterna tives,future work,current work,coincide,black box,glass-box distinction,conclusion,lower-order distribution,sec tion,phrase length,author,colleague michel simard,stimulating discussion,first author,colleague,delicacy,maple syrup,material,opinion,finding,conclusion,recommendation,material,author,reference peter,stephen,della pietra,vincent della,pietra,robert,mercer,mathematics,machine translation,parameter,timation,computational linguistics, itc irst  smt system,proceeding,mt summit,phuket,thailand,september,international association,machine translation,stanley,joshua,goodman,empirical study,technique,lan guage modeling,technical report tr-10-98,com puter science group,comparison,enhanced good-turing,estimation,probability,english bigram,computer speech,language,prepositional phrase attachment,backed-off model,proceed ings, acl workshop,massachusetts,ismael garc,francisco casacuberta,mann ney,search al gorithm,statistical machine translation,pro ceedings,5th international conference,volume,sydney,australia,december,joshua goodman,progress,language modeling,computer speech,language,trevor hastie,robert tibshirani,jerome fried man,element,statistical learning,springer,reinhard kneser,hermann ney,backing-off,m-gram language modeling,pro ceedings,international conference,acous tic,speech,detroit,philipp koehn,franz josef och,daniel marcu,statistical phrase-based translation,ed uard hovy,editor,proceeding,human lan guage technology conference,north ameri,chapter,association,computational linguistics,edmonton,alberta,canada,ed inburgh system description, nis t mt evaluation,proceeding,machine translation evaluation workshop,philippe langlais,guihong cao,fabrizio gotti,task system description,proceeding, acl workshop,build ing,using parallel text,uni versity,michigan,ann arbor,daniel marcu,william wong,phrase,joint probability model,statistical machine translation,proceeding,conference,empirical method,natural language pro,robert, ibm word alignment model,proceeding,nual meeting,association,hermann ney,ute essen,reinhard kneser,probabilistic dependency,stochastic language modelling,computer speech,language,formula,word probability,ee transaction,acous tic,speech,december,franz josef och,minimum error rate training,statistical machine translation,proceeding,annual meeting,association,kishore papineni,salim roukos,todd ward,wei jing zhu,method,automatic evaluation,machine translation,september,andreas stolcke,extensi ble language,toolkit,proceeding,international conference,denver,colorado, naa cl workshop,statistical machine translation,statmt,richard zen,hermann ney,phrase-based statistical machine transla tion,proceeding,boston,proceeding,international conference,computational linguistics,coling,manchester,august,joint conference,empirical method,natural language processing,computational natural language learning,prague,association,computational linguistics improving translation quality,phrasetable j h oward johnson,joel martin interactive information group national research council canada ottawa,ontario,canada firstname,george foster,roland kuhn interactive language technology group national research council canada gatineau,canada firstname,phrase table,statistical machine translation,technique,significance testing,phrase pair co-occurrence,parallel corpus,saving,reduc tion, ble score,im provement,effect,state-of-the-art phrasetable smoothing,1 i ntroduction,important part,process,large table,phrase pair,translation,large corpus,aligned sentence,phrase,estimate,con ditional probability,useful feature weight,source sentence,candidate translation,choice,translation,combination,probability,feature weight,much discussion,estimate,probabilites,estimate,feature,translation,cursory glance,phrasetables,translation,translation,obvious way,reduction,translation quality, ble score,impression,grand scheme,large ta bles,large data structure,resource,process,effort,large table,fea tures,sophisticated search,phrasetables,straightforward approach,significance testing,approach,quality,translation, ble score,saving,number,discarded phrase pair,sub stantial,phenomenon,art smoothing,phrasetable probability,section,basic idea,statistical machine translation,sig nificance,association,contingency table,independence,filtering algorithm,phrase pair,significance test,section,number,experiment,phenomenon,measure,magnitude,sec tion,present,result,experiment,summary,discussion,2 b ackground theory,statistical machine translation,source phrase,translation,associated translation probability,joint frequency,source tar get,word-aligned parallel corpus,joint count,phrase induction algorithm,symmetrized word alignment gen,source sentence,phrase-based  smt system,target sentence,likely translation,search,viterbi approximation,likely combination,alignment,argmax,tar get phrase,source phrase,trans lation,kth target phrase,feature function,weight,algorithm,development corpus,feature,length,single-parameter distortion penalty,phrase reordering,translation model probability,4-gram language model probability,kneser-ney smooth ing, sri lm toolkit,stolcke,feature,phrase,phrase,phrase probability,feature,filter,possible translation,source phrase,top-ranked translation,reviewer,translation,subject,pruning technique,beam search,search parameter,standard practice,phrase translation model probability,several technique,foster,discussion,significance,contingency table,phrase pair,source side,corpus,m-gram,target side,corpus,number,parallel sentence,occurrence,source side,number,parallel sentence,occurrence,source side,number,parallel sentence,occurrence,target side,number,parallel sentence,enough information,contin gency table,unconditional relation ship,standard statistical technique,importance,association,con tingency,probability,observed table,chance,inde pendence,significance test,intro ductory statistic,chi-squared test,small table,column,contingency table,fisher,exact test calculates,observed table,hypergeometric distibution,observed table,probability,probability,probability,chance,association,significance,agresti,excellent introduction,general idea,significance test ing,contingency table,fisher,exact test,significance,gold standard,precise proba bilities,realistic assumption,chi-squared test,log-likelihood-ratio test,approximate test,significance,asymptotic assumption,small count,co-occurrence,word alignment,multiple co-occurrence,single aligned sentence pair,multiple time,possible way,m-grammatch,single sentence pair,sentence pair,signifi cance testing,word association,log likelihood-ratio test,fisher,exact test,fisher,exact test,practical method,number,technique,logarithm,factorial,available numerical approxima tions,well-known recurrence,convergence,significance,significance pruning,phrasetables,phrase,weakly,chance,occurrence,corpus,result,artifact,combination,effect,several estimate,concept,overfit,aspect,training data,prediction,phrase,certain level,significance,data structure,general term,pruning,candidate translation,source phrase,bad idea,phrase,low combination,shorter phrase,translation,corpus,intuition,phrasetable smoothing,phrasetable pruning,infrequent phrase,corpus,favour,combination,shorter phrase,probability,neg ative,natural log,probability,phrase pair,p-value,phrase pair,advantage,ordinary-sized number,happy convention,important special case,phrase pair,corpus,component,parallel corpus,phrase pair,1-1-1 phrase pair,corresponding table,1-1-1 contingency table,comment,p-value,fisher,exact test,threshold,negative logarithm,useful threshold,small positive number,threshold,result,1-1-1 phrase pair,threshold,result,1-1-1 phrase pair,1-1-1 phrase pair,large part,phrase table,important observation,contingency table,significance,p-value,1-1-1 table,threshold,phrase,common strategy,count phrase pair,effect,threshold,3 e xperiments,corpus,experiment,num ber,comparative study,workshop,statisti cal machine translation,material,parallel corpus,french,english,spanish,english,german,english,language model,english,french,spanish,europarl resource,europarl,change,corpus,unicode  utf,phrasetables,conditional probability,phrasetables,m-grams,fisher,exact test,phrase pair,pruning threshold,number,combination,ent pruning threshold,pruning,ad dition,number,algorithm,smoothing,good-turing smoothing,kneser-ney,parameter smoothing,loglinear mixture,feature,zens-ney,foster,effect,significance,corpus,series,experiment,corpus,mt06 chinese,ob jective,method,preferred phrasetable smoothing technique,threshold,phrasetable size,threshold,phrasetable size,result,smoothed meth od,leu  point,corpus size,number,parallel sentence,chinese,chinese,corpus,phrase table,un corpus,parallel corpus,different,threshold,pruning,addition,aggressive method,pruning,phrase pair,special treatment,threshold,threshold,spe cial series,singleton,threshold,significance level,prun ing,phrase pair,result,result,experiment,ta bles,various parallel corpus,number,parallel sentence,experiment,threshold,phrasetables,threshold,aggressive pruning,phrasetable size,large corpus chinese,english data,pruning,main result,chinese,english large corpus ex periments,result,fig ure,result,distinct phrase pair,distinct phrase pair,artificial separation, 1 b leu  point,essential point,compensation, ble co-ordinate,result,following subsection,function,threshold, ble score,bold font,addition,duce  ble,many case,threshold,cor responds,phrase table,chinese,english large corpus run,crease,reduction,function,fraction,simple function,threshold,fraction,stable observation,experiment,strong relationship,large corpus table,small corpus phe nomenon,sizeable benefit,phrase table reduction,modest improvement,question,improvement,improvement,something,benefit,benefit,reduction,comment,question,phrase pair,1-1-1 phrase pair,component,phrase pair,phrase table,experiment,threshold,chinese,english large corpus experiment,good opportunity,significance level,phrase,marginal count,significance,threshold,con figuration,benefit,poor performance,whole idea,5 c onclusions,main conclusion,standard diag andmethod,aggres,significance,phrasetable smoothing, ble score,aggressive signifi cance,phrasetable smoothing,improve ment,aggressive pruning,preservation, ble score,pres ence,large-scale pruning,strong effect,moderate size phrasetables,oc cur,phrasetables,phrasetables,corpus,percentage,similar effect,decrease,benefit,phrasetable smoothing,foster,result,corpus size,increase,number,phrase pair,increase,number,intuition,approach,similar effect,fisher,exact test,question,phrase pair,phase pair,isolation,analysis,corpus,random process,answer,phrase pair,association,general applicability,evidence,corpus,removal,1-count phrase pair,significance,threshold,simple ap proaches,implementation point,significance test,ap proaches,log-likelihood-ratio,enough alternative,example,interaction,se lection,beam search,candidate,forward conditional probability,result,small threshold,much wider,search,experiment,reasonable time,choice,reduction,sig nificance,large threshold,choice,intermediate threshold,extra prun, ble score,small amount,choice,search,threshold,phrase table,large threshold,question,true shape,threshold,expected operat ing level,subject,alternative,beam width,number,important way,code base,frequency,signifance evaluation,problem,example,skip-n gram,vari able size,approach,method,proximate pattern,original goal,character,phrasetables,useful diagnostic technique,understanding,good phrasetable,language,morphological analysis,segmentation,good table,standard method,negative-log-p-value promise,useful feature,cknowledgement,material,opinion,finding,conclusion,mendations,material,author,alan agresti,introduction,categorical data analysis,stephen,della pietra,vincent,della pietra,robert,mercer,mathemat ic,statistical machine translation,parameter,timation,computational linguistics,philipp koehn,europarl, a m ul tilingual corpus,evaluation,ma chine translation,unpublished draft,pkoehn publication,pdf george foster,roland kuhn,howard johnson,statistical machine translation,proceeding,conference,empirical method,natural language process ing,sydney,australia,reinhard kneser,hermann ney,backing-off,m-gram language modeling,pro ceedings,international conference,acoustic,speech,detroit,philipp koehn,franz josef och,daniel marcu,statistical phrase-based translation,eduard hovy,editor,proceeding,human language technology conference,north american chap ter,association,computational linguistics,edmonton,alberta,canada,log-likelihood-ratios,significance,rare event,proceeding,conference,empirical method,natu ral language processing,barcelona,gov speech test,franz josef och,minimum error rate training,statistical machine translation,proceeding,annual meeting,association,kishore papineni,salim roukos,todd ward,wei jing zhu,method,automatic evaluation,machine translation,statistical machine translation,statmt,org wmt06 andreas stolcke,extensible language,toolkit,proceeding,inter national conference,denver,colorado,september,richard zen,hermann ney,improvement,phrase-based statistical machine translation,pro ceedings,boston,threshold threshold phrasetable fr,relative frequency,good-turing none,kneser-ney,parameter,zens-ney none,threshold threshold phrasetable nist04 nist05 nist06-gale nist06-nist zens-ney smoothing,phrasetables,proceeding,human language technology conference,north american chapter,new york,association,computational linguistics segment choice model,feature-rich model,global   d istortion,statistical machine translation  r oland kuhn,denis yuen,michel simard,patrick paul,  g eorge foster,eric joanis,howard johnson  i nstitute,information technology,national research council,canada gatineau,michel,simard,patrick,george,foster,johnson,denis yuen,mucous gmail,com  a bstract,new approach,distortion,phrase,sequence,choice,translation,approach yield,probabilistic distortion model,probability,possible phrase reordering,segment choice,sentence pair,approach, scm offline,test data,perplexity,language model,decision-tree-based  scm,chinese-to-english translation,baseline distortion penalty approach,confidence level,1 i ntroduction,defining  scm,context,phrase-based mt,istortion,phrase-based mt,phrase,source-language sentence change,translation,phrase,target-language trans lation,mt system,arbi trary reordering,phrase,distortion penalty proportional,difference,original phrase order,ome interesting recent research,narrow window,phrase,tillmann,tillmann,paper intro,lexical feature,distortion modeling,recent paper,collins,major gain,parse tree,source sentence,reordering rule,source,target-language-like word order, o ur model,source sentence,distortion,assumption,generation,hy potheses,segmentation,complete source sentence,translation hypothesis,new hypothesis,phrase,re quire,operation,inwards-outwards hypothesis con struction,predictable order,segment,source sentence,hypothesis,collins,preoccupation,method,source,example, a d sh,german-to-english translation,case information,ich habe da buch gelesen,english,distor tion,german segment,english-like word order,translation,segment,phrase,example,german-to-english  dsh,series,segment choice,figure,left-to-right decoder,candidate,leftmost segment,candi date,candidate,da buch,candidate,decoder,assign probability,segment choice,available choice,equal probability,segment,uniform  scm,probability,figure,probability,probability,uniform  scm,little use,mt system,section,informative  scm, sc m offline,test corpus,corpus,distortion corpus,defining disperp,ultimate reason,performance,mt system,training,large-scale mt system,new  scm,distortion component,effect,total score,phrase translation,target language model,quick standalone,statistical language model,perplexity,jelinek,overall probability, scm assigns,test corpus,representative,quality,distortion perplexity,probability, scm assigns,sentence,test corpus,numerous  dsh,probability,corpus,total number,segment,mean number,choice,disperp,corpus,segment choice,simple  a p,uniform  scm assigns, dsh dk,illustrative  sc m,sentence,segment,original order,hree segment,source,decoder,choice,probability,leftmost,predictor,last phrase,phrase,predictor,position,source,target,next  dsh position,parallel,pre dictor, f igure,segment choice prediction example model,leftmost,predic tor,leftmost segment,probability,segment,others uniform probability,predictor,probability,segment,first word,last word,uniform probability,model combine,leftmost,leftmost,segment,uniform probability,segment,segment,uniform probability,course,factor,figure,probability,distortion penalty,system,predictor,ai start position,source phrase,ith target phrase,source phrase,th target phrase,total distortion,product,phrase distortion penalty,penalty,non normalized probability,decoder,source,target,development data,penalty,penalty,probability,penalty,uniform model,disperp experiment,held-out data performs,dis perp,realistic measure,parameter,priori,trainable pa rameter,distortion model,several trainable parameter,constructing  a d istortion corpus,disperp,complex  scm,corpus,representative example,several way,corpus,experiment,mt system,bilingual sentence-aligned corpus,sys tem,second pas,training corpus,phrase table,standard dis tortion penalty,best-fit phrase alignment,source,target,sentence pair,alignment yield  a d sh,segment,original position,source,leave-one-out procedure,information,sentence pair,sen tence pair,initial experiment,result,segment-aligned cor pu,phrase table,source sentence,trainable decision tree  scm almost,machine learning technique,trainable  scm,decision tree,result,soft ware engineering reason,quick way,variety,feature,feature, n d t,number,choice,moment,highest-numbered dt,choice,choice tree,2-choice tree handle case,segment,probability,choice tree,seg ments,choice tree,differ ent,others,segment,choice,choice,left-to-right decoder,sentence,choice tree,probability,choice tree,probability,hypothesis,4-choice tree,choice tree,2-choice tree,disperps,test corpus  dsh,left-to-right way,number,choice,probability,n-choice dt,probability,segment,original source position,last word,figure,scheme,r seg ment,first word,second-closest segment,segment,penalty,penalty,segment,right segment,figure,question type,choice dts figure,main type,question,tree-growing,position question,word-based question,position question,location,length,seg ments,position question,dis tance,first word,segment,answer,segment,last  dsh segment,source,question,leftmost,predictor,function,segment,question,seg ment,second last segment,word-based question,segment,allow ing question,position,segment,question,syntax,  f igure,example,choice,segment,dt rep,number,data item,probabili tie,smoothing,zero probability, f igure,example,choice tree,label closest,figure,choice dt,probability,segment closest,segment,uniform distribution,probability,data item,second-pass  dsh corpus,segment  dsh,exam ple,seven-choice case,choice case,choice dt,item po,uestions,original position let po,  q uestions,word position,egment order question   l,choice dts,dt training method,tain probability distribution,lazarid,4 d isperp experiment, scm disperp experiment,english-chinese task,direction,distortion,english,chinese-like phrase order,distortion,english-like phrase,reason,detail,english,experiment,development data,distorted chinese experiment,release, fbi corpus,xinhua news story,training corpus, fb segment alignment,development,corpus,disjoint set,segment alignment,disperp result,corpus,four-dt model,training alignment,po 100-wd qns  f igure,several  scm,distorted chinese figure,show disperp result,axis show number,log scale,advance,single parameter,en tire training set, 62k  fbi alignment,amount,training data,normalized version,distortion penalty,model  a-d,dt-based  scm,figure,t-based  scm,choice,choice,word-based question,word-based question,frequent chinese word,training corpus,system,disperp drop,num ber,alignment,effect,question,question,signifi cant disperp improvement,amount,training data,effect,word qns,fourdt model,training alignment,four dts,po 100-wd qns  f igure,word-based question,four-dt,result,example,segment,choice,number,tree allows,multi-segment case,training data,optimal number,tree depends,amount,training data,amount,alignment,number,figure,parameter,significant im pact,disperp,question,chinese word,number, 32k alignment,po 100-wd qns  f igure,number,dts   i figure,number,frequent chinese word,question,13-dt system, 32k alignment,improvement,frequent word,behaviour,english,experiment,question,frequent word,significant improvement,equal share,disperp, 32k alignment,log scale,-dt system  f igure,dt system,mt experiment,question,frequent chinese word,88k alignment,disperp,mt experiment,baseline model system,5 m achine translation experiment, sc m,source sentence,system,segmentation,unconsumed part,source,result,one-word segment,realistic segmentation model,r treatment,chinese-to-english mt experiment,corpus,mt system,phrase table,parallel text, ni st mt05 chinese-english evaluation,xinhua corpus,eng lish language model,cor pora,gigaword,subset,training corpus,corpus,component weight,experimental result,evaluation set,mteval  nis t04,hrase table,training cor pu,diag-and,method, ibm model,initial word alignment,author,unsmoothed relative frequency,decoder,log-linear combination,phrase translation model,direction,trigram language model,word penalty,lexical weighting,op tional segmentation model,phrase penalty,distortion model,weight,component,method,max-bleu training,develop ment set,decoder,dynamic programming beam-search,uture-cost estimate,distortion mod el,baseline penalty model,decoding result,pp pp dp dt bl eu,beam  f igure, nis t04,show experimental result,system,distortion penalty,system,dt-based  scm,default beam width,wider beam,notation,decoding time,presence,phrase penalty component,advantage,difference,dt system,dp system, bl eu,bootstrap confidence interval,1000-fold resampling,resolution,result,firm conclusion,1000-fold bootstrap, nis t04,pairwise system comparison,show result, bl eu comparison,system,system,column,system,observation,comparison,system,system,dp system,underlined result,beam search,system,phrase penalty,system,discussion,new class,probabil istic model,distortion,choice,translation,recent dis tortion model,tillmann,tillmann,phrase,position,offline com parison,parameter,cor pu,disperp,variant,dt system,system,distortion penalty, a c hinese-to-english task,pairwise bootstrap comparison,dt-based distortion,penalty-based system,computational cost,large quantity,phrase table,amount,training data,major problem,dt training,low pro portion,chinese-english sentence pair,dt training,selection bias,performance,alignment algorithm,smoothed phrase table,johnson,segment alignment,dt-based distortion model,square,number,source sentence,long sentence,challenge,weight optimization step,experiment,language pair,johnson,source sentence,sentence,distortion penalty,principled ap,proach,source sentence,reordering,segmentation model,number,source segment,phrase penalty,sophisticated model,segmentation model,system,source sentence,decoding,accurate future cost function,beam search,obvious system improvement,advanced word-based feature,question,word class,illmann,tillmann,n-best list,decoder,several  scm,assumption,right-to-left  scm,target hypothesis,source sentence,vice versa,differ ent approach,dt-based  scm,approach,output class,par ticular segment,source sentence,sequence,segment,segment,segmentation,source sentence,  r eferences   p,mer cer,mathematics,statistical machine translation,ku erov,statistical machine translation,ann arbor,pruning algorithm,jelinek,speech recognition,reading,speech recognition,waibel,mor gan kaufmann,larkin,smoothed phrase table,segment choice mod el,workshop,statis tical machine translation, a b eam search decoder,machine trans,statistical machine translation,vancouver,canada,lazarid,decision tree,acoustic modeling,spoken lang,philadelphia,pennsylvania,alignment template approach,statistical machine translation,linguistics, f ranz josef och,method,automatic evaluation,tillmann,statistical machine translation,tillmann,tillmann,statistical translation,proceeding, acl workshop,building,using parallel text,ann arbor,computational linguistics,por tage, a p hrase-based machine translation system  f,martin,aaron tikuisis,information technology,information technology,waterloo,ontario,canada firstname,uwaterloo,bstract,participation,portage team, nrc canada,shared task1,workshop,building,using parallel text,cuss portage,statistical phrase-based machine translation system,present experimental result,language pair,french-english task,multiple re source,technique,contribution,german-english lan guage pair,rapid growth,internet,rapid growth,information exchange,different language,related technology,information flow,speaker,different lan guages,internet,data-driven approach,translation system,practical solution,longstanding goal,cheap natural language processing,portage,statistical phrase-based machine translation system,different language pair,statmt,org wpt05 mt-shared-task new system,main goal,workshop,different language pair,baseline performance,purpose,comparison,system,future improvement,standard configuration,phrase-based  smt,language pair,french english,canada,demographic,policy,official bilin gualism,participation,stream,french-english stream,additional data resource,hand-coded rule,number,stream,provided resource,statistical framework,several automatic method,finnish morphology,remainder,fol low,section,architecture,portage system,hand-coded rule,language,section,section,concludes,pointer,future work,2 p ortage   p ortage,main phase,preprocess ing,raw data,translation sugges tions,phrase,translation hy potheses,error-driven rescoring,preprocessing,necessary first step,raw text,source,target lan,format suitable,model train ing,decoding,foster,supplied europarl corpus,segmentation,tokenization,french,convention,hansard corpus,french-english resource,section,alignment,algorithm,segmentation,tokenization procedure,anguages,rich morphology,statistical machine translation,available data lack instance,possible form,translation sys tem,language like german,new word,hyphen,crucial step,preproc,language,finnish text,addition,simple operation,rule-based component,num bers,source text,translation,target text,component,hansard corpus,europarl,hansard,development data,language,test data,decoding,central phase,search,hypothesis,prob ability,translation,current source sentence,log-linear combination,main component,trigram language model,phrase translation model,distortion model,word-length feature,trigram language model, sr ilm  toolkit,stolcke,phrase-based translation model,described,relies,symmetrized  ibm model,word-alignments,phrase pair induction,distortion model,exception,final cost,sentence ending,weight,component,log linear model,iterative process,translation hy,entire search space,source sentence,variant,powell,algorithm,weight,hypothesis,translation,implementation,algorithm,different ad hoc strategy,weight,dur ing,exception,ability,transla rent language pair,iteration,algorithm,french english,grid search,language,actual translation,decoder,dynamic programming beam search algorithm,pharaoh,pharaoh extension,raw output,strategy,nbest translation,method, ble score,final pas,algorithm,previous sec tion,decoder,addition,basic fea tures,initial model,cluded  ibm,model probability,direction, ibm 1-based feature,lan guage,satisfactory tions,language,missing-word feature,direction,3 e xperiments,shared task,experiment,evaluation,portage,diffe re ask,training data,sentence,french,english,finnish,spanish,german,matched english translation,lan translation,english,  p ortage,comparative study,different resource,training data,icipation,th  h-e nglish ta,sentence,language,addition,sentence,hansard corpus,official record,canada,english lan guages,translation model,decoding,development test data,first part,sentence,language,reference translation,optimization,weight,decoding,rescoring model,number,n-best list,second part,sentence,lan guage,referenc,evaluation,performance,translation model,experiment,french-english task,language pair,ex periments,hniques,europarl corpus,training data,europarl,hansard,training data,number,europarl,number,preprocess,french english task,first column,method,second column,result,third column,comparison,method,improve ment,lan guage model,translation model,europarl,hansard corpus,number,negative impact,ranslation el,  bl eu score,art  e f renc,increased trade,north merica,function,good counterpoint,french-english test sentence,noteworthy feature,result,improvement,out-of-domain hansard corpus,performance,weight optimization,result,importance,training,test domain,related point,number,date translation rule,performance drop,typographical convention prevalent,hansard,result, wp t05 french-english task,difference, ble score,first rank participant,difference,leu  score,second ranked participant,experiment,language,workshop,good opportunity,corpus,difficulty,considerable use,addition,complex morphology,principle,eng lish,result,number,po sible statistical approach,word form,result,baseline,french,english,canada,extra effort,difficulty,translation,tween spanish,english,result,language pair,participant,morphological rf meeting,association,computational fr statistical machine transla ge id ke ki,meeting,association,com ne trans oc,40th annual meet fr proceeding,ph parl,multilingual corpusfor   p ation model,proceeding,association,ma chine translation,america,ble  2 b leu  score,spanish-english test sentence,baseline,preprocessing,special setting,weight,distortion,word penalty,lan guage model,translation model,grid search,extra  ble point,ur final result,spanish english task,difference,4 c onclusion,participation,shared task,workshop,building,using parallel text,evaluation,portage,statistical machine translation system,language pair, ble score,spanish english,eleven team,re sults, nrc team,fourth rank,slight difference,port age,first stage,implementation,different pair,language,evaluation,problem,system,weight optimization,number,date rule,out-of domain corpus,difficulty,complex language,planned future work,exploitation,comparable corpus,statistica machine transl knowledge,feature,rescoring,eferences andreas stolcke,extensible language modeling toolkit,anz josef och,hermann ney,statisti cal alignment model,proceeding,nual linguistics,hong kong,october,anz josef och,daniel gildea,sarkar,kenji yamada,alex fraser,shankar kumar,libin shen,david smith,zhen jin,dragomir radev,mor gasbord,feature,orge foster,simona gandrabur,graham russell,michel si mard,statistical machine translation,rap development,limited resource,proceeding,mt summit ix,new orleans,september,vin knight,ishwar chander,matthew haines,hatzivassiloglou,eduard hovy,richard whitney,kenji yamada,knowledge gap, a b road-coverag mt system,proceeding,international joint conference,shore papineni,salim roukos,todd ward,wei jing zhu, a m ethod,automatic evaluation,machine translation,proceeding,40th annu putational linguistics  acl,philadelphia,robert,accurate sentence alignment,bilingual corpus,machine transla tion,research,proceeding,5th conference,association,machi lation,america,tiburon,heidelberg,germany,discriminative training,maximum entropy model,statistical machine translation,proceeding ing,association,anz josef och,minimum error rate training,statistical machine translation,annual meeting,association,com putational linguistics,sapporo,ilipp koehn,euro evaluation,machine translation,university,southern california,hilipp koehn,pharaoh, a b eam search decoder,phrase-based statistical machine transl,proceeding,workshop,statistical machine translation,new york city,association,computational linguistics por tage,smoothed phrase table,segment choice model howard johnson national research council institute,information technology interactive information,canada  k1a,howard,johnson,fatiha sadat,george foster,roland kuhn,michel simard,eric joanis,samuel larkin national research council institute,information technology interactive language,canada,firstname,improvement,partici pation,shared task, naa cl,workshop,statistical machine trans lation,phrase table smoothing,global dis tortion,feature-rich model,numerous improvement,software base,ntroduction,statistical machine translation system portage, naa cl,workshop,sta tistical machine translation,good opportu nity,available data set,benefit,number,feature,section,change,past year,par ticipation,section,method,extension,section,result,tab ular form,conclusion section,result,2 p ortage,second participation,portage,description,base system,portage,research vehicle,development,totype system,state-of-the-art,custom,decoder,rescoring module,weight,number,feature,source sentence,change,phrase-based  smt relies,conditional distribu tions,joint frequency,source target phrase,aligned parallel corpus,relative-frequency estimation,con ditional distribution,relative-frequency estimation,well-known problem,rare event,instance,phrase pair,constituent,corpus,probabil ity,probabili tie,evidence exists,translation,rare pair,frequent pair,probability,perfor mance,problem,strategy,good-turing technique,church,replaces,joint frequency,number,distinct pair,total count mass,unseen pair,proportion,frequency,phrase,estimate,estimate,second strategy,kneser-ney smoothing,kneser,interpolated vari ant,goodman,num ber,distinct phrase,co-occurs,approach,phrase-table smoothing contrast,previous work,phrase probability,word-pair probability,log-linear model,approach,combi nation,future work,feature-rich dt-based distortion,recent paper,new class,distortion,phrase-based system,situation,distortion score,drastic reordering,source sentence,reordering,conventional penalty-based distortion,distortion,particular kind,decision tree,question,question,distance,phrase,beginning,source sentence,phrase,word-based question,question,presence,absence,corpus,segment-aligned bilingual sentence pair,good-turing smoothing,formula,decoder,segment-aligned corpus,phrase translation model,large bilingual cor pu,conjunction,distor tion penalty,alignment,phrase,source-language sentence,corresponding target-language sentence,second bilingual corpus,first corpus,phrase translation model,second corpus,alignment,overfitting,alignment algorithm,statistic,particular sentence pair,sentence pair,experiment,translation,chinese,en glish,interest,experiment,onw mt data,feature-rich dt-based distortion model,language pair,3 a pplication,shared task,method,resource exercise,first exercise,condition,effect,research,development,second exercise,translation,language model,exercise,english,french,spanish,ger man,baseline,third exercise,generation,good-turing smoothing,language pair,phrase-tables,improvement,result,baseline,fourth ex ercise,penalty-based distortion,distortion,fifth ex ercise, a k neser-ney phrase table,alternative,good turing,exercise,1-best result,result,feature function,distortion mod,result,result,fourth exercise,rescoring,open resource exercise,exercise,com parative study,additional training data,french-english shared task,result,improvement,different resource,french english pair,language,addition,training resource,europarl,hansard,bilingual dictionary,translation model,english side,english language model,termi nological lexicon,statistical machine transla tion engine,straightforward operation,attached prob ability,approach,consists,translation candidate,source term,phrase,second part,contribution,sentence,en glish,europarl parallel corpus,sentence,french,english,hansard parallel corpus,offi cial record,canada,parliamentary debate,sentence,french,english,bilingual dictionary  gdt,lan guage model,en glish part,europarl,hansard,provided europarl corpus,october-december,development,test data,addi tional english language model,un parallel corpus,supplied europarl corpus,segmentation,tokenization,french,convention,aujourd,aujourd,hansard corpus,french-english resource,align ment,algorithm,segmentation,granddictionnaire,tokenization procedure,english preprocessing,lower-casing,punctua tion,result,number, ble score,correspond,multi-corpora result,open re source exercise section,resource exercise,result,shared-task submission,choice,direction,research,test result,shared-task sub mission,validation,conclusion,multiple training cor pora,re-tokenization,french,enhanced language model,overall success,english-french translation track,result,in-domain test data,ranking table drawn,organizer,adequacy,fluency, ble score,5 c onclusion,language model,pa rameters,reproduces,result,tiny improvement,language model,english yield,a b leu  point,kneser-ney phrase table,half  a b leu  point,good-turing,decision tree,distor tion,small improvement,rescoring,im provement,test set,result,phrase-table smoothing,feature-rich decision tree distortion mod,additional work,good pay-back,avenue,investigation,clearly,acknowledgement,aaron tikuisis,denis yuen,important contribution,portage code base,open resource result,devtest,devtest,langue franc,permission,empirical study,technique,language modeling,technical report tr-10-98,computer science group,comparison,good-turing,estimation method,probability,english bigram,com puter speech,language,backing-off,m-gram language modeling,international conference,acoustic,speech,signal process,detroit,segment choice model,feature-rich model,global distortion,statisti cal machine translation,publication,hlt -naa cl conference,tikuisis,workshop,building,parallel text,ann arbor,tra duction automatique statistique combinant diffe,ressources,belgium,improvement,phrase,statistical machine translation,boston,proceeding,second workshop,statistical machine translation,prague,association,computational linguistics integration,arabic transliteration module, a s tatistical machine translation system mehdi,science simon fraser university,canada mmostafa sfu,rc institute,information technology,canada firstname,abstract,in-depth analysis,tegration,arabic-to-english translit eration system,general-purpose phrase-based statistical machine translation system,integration,dif ferent aspect,improve ment,integra tion,experi ments,transliteration module,situation,test data,entity,theoretical maximum improvement,oracle,development,test set, oo word,vocabulary source word,phrase table,1 i ntroduction transliteration,practice,writing system,writing system,frequent candidate,transliteration,person name,location,ganizations,comprehensive bilingual dictionary,transliteration,certain natural language processing application,named entity,application,translitera tion,problem,effect,aforementioned application,investigation,transliteration,self-contained task,challenge,real applica tion,new challenge,efficacy,transliteration module,real mt system,performance,limited domain,large amount,training data,unseen data,argument,matter,unseen name,people,location,urrent mt system,unknown name,final target text,method,reader,source language,informa tion,source,target language,different script,partial information,speech,individual,location,sentence,usability,translation,importance,evaluation method,mt community,papineni,automatic evaluation,mt output,metric n-gram similarity,mt output,reference,different word,equal weight,evaluation,transliteration,case significant impact,integration,practical us,dicates,readability, bl eu score,advantage,translit eration system,right translation,language model,ordering,example,phrase table1,mt system,plain arabic text,american authority,security,mt system,dallas,dulles,english equivalent,decoder,following sentence,american authority,security,airport,dallas,american authority,security,dulles,system,probability distribution,parallel training data,proper name,training data,chance,test data,translation table,mt system,rich phrase table,common name,test data,self-contained transliteration module,1 a table,conditional probability,target phrase,source phrase,vice versa,2 n ote,language model,translation model,primary use,transliteration module, smt system,phrase table,translation,performance improvement,transliteration module,mt system,improvement,dif ficult, oov word,misspelling,source text,example,development test,evaluation,similar auto,almost,mt evaluation,reference translation,gold standard,metric,mt output,problem,single equivalent,target language,target language,gold standard,transliteration module,correct interpretation,credit,limited num ber,correct name,reference,first impression,inter pretations,reference,transliteration module,chance,perform ance,practice,reference,transliteration,ambiguity,transliteration module,correct transliteration,decoder,credit,transliteration,reference,example,reference,different interpretation,swerios,swiriyus,severius,sweires,quick query,google,acceptable,terpretations,severios,sewerios,sweirios,active re search field,al-onaizan,knight,abduljaleel,larkey,kle mentiev,sproat,knowledge,little published work,transliteration,real mt system,hassan,sorensen,arabic,input text,mt system,system,different case,word-based ne transla tion,phrase-based ne translation,presence,transliteration module, bl eu score,final output, ble increase, bl eu point increase,difference,method,transliteration,trans literation, ble point,person name,different method,transliteration module,mt system,choice,section,transliteration module,output, mt system,section,evaluation,inte gration,section,2 o ur approach,detail,approach,overview,portage,machine translation system,experiment,property,portage,statistical phrase-based  smt system,pharaoh,source sentence,target sentence,joint probability,target,phrase alignment,loglin ear model,feature,loglinear model consist,phrase-based translation model,relative frequency,lexical probability estimate,gram language model,kneser-ney smooth ing, sri lm toolkit,single parameter distortion penalty,phrase reordering,word-length penalty,weight,loglin ear feature,algorithm,system,leu  score,development corpus,phrase pair,parallel corpus,diag-and phrase induction algorithm,symmetrized word alignment gener, sgm l-like markup,arbitrary entity,input text,markup,translation,external source,entity,rule-based translation,number,transliteration module, smt system,capability,detail,technique,many different  smt system,example,different transliteration,probability,occurrence,arabic input text,portage,decoder,phrase table,marked-up text,portage,phrase table,candidate,markup,candidate,language model,decoder,system,small arbitrary probability,unigram probability,unseen word,different method,transliteration module, mt system,second method, ne tagger,external tool,ne tagger,arabic input text,transliteration module,probability,candidate,markup capability,portage,arabic text, sgm l-like tag,different probability,different candidate,marked-up text,method,marked-up text,new phrase table,arabic input text,phrase table,weight,phrase table,decoder,phrase table,phrase table,translation,main difference,method,system,allows,bleu optimal weight,ne phrase table,weight,method,portage,arabic  oov,transliteration module,top candidate,portage,arabic  oov,transliteration module, sg ml-like tag,different probability,different candidate,marked-up text,method,powerful ne tagger,high recall value,recall value,development,different ne tagger,tagger,tagger,different research group,recall,respec,purpose,method,transliteration module,internal phrase table,observation,phrase table,reliable source,information,transliteration,transliteration,method,arabic name,common word,arabic name,hani abu nahl,mt system output,advantage,method,ne detector,correct translation,third method,advantage,decoder,internal feature,language model,candidate,transliteration module,fourth method,mt system,suggestion,transliteration module,internal phrase table,phrase,reliable source,information,translation quality,bad transliteration,original word,third method,advantage,internal decoder feature,second pas,fourth method,experiment,following example,approach,example,suppose,following sentence,arabic plain text,following output,blair accepts,report,hutton,transliteration module,transliteration module,english candidate,different probability,section,following markup text,additional guidance,language model,decoder,different markup suggestion,example,following output,hutton report,3 t ransliteration system,section,brief overview,transliteration system,experiment,full description refer,ashani et,three phase transliteration,transliteration module,noisy channel framework,adapted spelling-based generative model,al-onaizan,knight,consecutive phase,viterbi algorithm,number,monolingual dictionary,close entry,invalid candidate,arabic,diacritic,writing,equivalent,account,letter,different pass,different way,system,transliteration,hidden diacritic,example,arabic input,output candidate,system,possible blank,character,language model,possible output,others,character-level translation model,approach,bduljaleel,larkey, ldc catalog,candidate,google unigram,combination,monolingual dictionary,person name,close match, hm output candidate,levenshtein distance,task-specific change,module due,nature,development test set,reference,major change,phase three, oo word,development test set,monolingual dictionary,pipeline,levensthtein distance,dictionary entry,final output,dictionary,dictionary part,execution,final output,output,google unigram filtering,pipeline, hmm probability,transliteration module, hmm probability score,candidate,mt system,probability score,practice,translitera tion score,example,consecutive candidate,probability,decoder,val ues,similar difference,typical difference,internal feature,internal feature,exponential difference,candidate,candidate, hmm probability,top candidate,probability,decoder,log-linear fashion,exponent, hmm probability,weight,probability,weight,way decoder weight,decoder,weight,example,distribution,prefix detachment,arabic,rich language,tokenization,composite word,chance,phrase table,many time,main part,named entity,detail,morphology,frequent prefix,meaning,prefix,transliteration module,second time,whole word,output candidate,decoder,top  5 h mm,transliteration module,google unigram model,candidate word,certain threshold,internet,hundred,unwanted sequence,letter,top-5 candidate,output list,google unigram model,transliteration module,correct equivalent,literal transliteration,information,entity,arabic script,valuation,metric,ne translation performance4,purpose,ne translation,standard,ancient name,sophisticated morphologi cal transformation,example,abraham,english,ibrahim,arabic,gov speech test,example,training data, ni st machine translation evaluation,bilin gual training corpus,sentence pair,newswire,language model,english half,corpus,english gigaword corpus,feature weight,multiple translation part,corpus,sentence pair,test data, nis t mt,evaluation, ni st mt05 evaluation,development,blind test set,development test set,sentence,sentence,entity,blind test set,sentence,entity,number,sentence,experiment,whole text  oov sentence oov ne sentence dev test set,blind test set,distribution,sentence,test set,result,baseline,portage,transliteration module,development,blind test set,second column, ble score,section, ble score,result,test set, bl eu score,method,column,baseline method  3 m, 4 o racle dev,different test set,small portion,test set,entity, ble score,different sub-portions,test set,sentence,sentence,entity, ble increase,different portion,test set,baseline method  4d, oov sentence,oov ne sentence, oov sentence,oov ne sentence,different portion,test set,upper bound,much applying,transliteration module,overall result,oracle-like dictionary,test set,markup arabic text,markup input,mt system,result,column,performance,system,perfect accuracy,transliteration,human translator,reference,achieves,maximum gain,5 c onclusion,integration,trans literation module,system,arabic,final version,translitera tion module,english letter sequence,arabic letter sequence,typical case,arabic,diacritic,english letter sequence,next phase,module,english letter,third phase,module,huge collec tion,english unigrams,impossible english word,possible method,module, smt system,method,ne tagger,quality,experimen,method,top-scoring candidate,transliteration module,translation,arabic  oov,output multiple candidate,transliteration module, smt system,language model,candidate,experiment,method,experiment,importance,accurate transliteration,many practical  smt application,reference nasreen abduljaleel,larkey,statisti cal transliteration,english-arabic cross lan guage information retrieval,proceeding,twelfth international conference,information,knowledge management,kevin knight,machine transliteration,arabic text,proceeding, acl workshop,computational approach,semitic language peter,vincent,della pietra,robert,mercer,mathematics,statistical machine translation,pa rameter estimation,computational linguistics hany hassan,jeffrey sorensen,integrated approach,arabic-english named entity transla tion,proceeding, acl workshop,compu tational approach,niversity,michigan,ann arbor mehdi,kashani,fred popowich,anoop sarkar,automatic transliteration,proper noun,arabic,proceeding,second workshop,computational approach,arabic script-based language alexandre klementiev,dan roth,entity transliteration,discovery,franz josef och,daniel marcu,statistical phrase-based translation,pro ceedings, hlt -naa cl,edmonton,canada franz josef och,minimum error rate training,statistical machine translation,proceeding,annual meeting,association,computation linguistics,sapporo kishore papineni,salim roukos,todd ward,wei jing zhu, a m ethod,automatic evaluation,machine translation,proceeding,40th annual conference,association,howard johnson,roland kuhn,aaron tikuisis, a p hrase-base machine translation system,proceeding, acl workshop,building,using parallel text,ann arbor,michigan richard sproat,tao tao,chengxiang zhai,entity transliteration,sidney,australia,proceeding,second workshop,statistical machine translation,prague,association,computational linguistics mixture-model adaptation, smt george foster,roland kuhn national research council canada,abstract,mixture-model approach, a s tatistical machine translation system,new domain,weight,text distance,compo nents,number,variant,approach,cross-domain versus dynamic adaptation,linear versus loglinear mixture,language,transla tion model adaptation,different method,weight,granularity,source unit,method,ble percentage point,state-of-the art non-adapted baseline system,1 i ntroduction language,different gen re,empirical mod el,corpus,car-repair manu al,instance,appli cation,tourism,ideally,al way,bilin gual application,parallel training corpus,spe cific domain,parliamentary proceeding,problem,statistical machine translation system,parameter,information,test domain,basic setting,cross-domain adaptation,small sample,parallel in-domain text,future text,dynamic adaptation,domain informa tion,adaptation,current source text,translation,approach,setting,in-domain development corpus,broad adjustment,individual source text,method,classical technique,mixture modeling,hastie,involves,training corpus,different component,current context,mixture modeling,simple framework,many different variant,low dimensional,number,sub-models increase,amount,reliability,discriminative  smt training,chal lenge,large parameter set,tillmann,mixture weight,setting,cross-domain adaptation,knowl edge,source,target text,in-domain sample,weight,dynamic adaptation,training,problem,reference text,solution,multi-domain development sample,parameter setting,new domain,mixture weight,method,little hope,new domain,weight,function,distance,knowledge,proach,adaptation,main contribution,second contribution,broad investiga tion,large space,alternative,mixture-modeling framework,simple genre,corpus decomposition,following choice,cross-domain versus dynamic adaptation,linear versus loglinear mixture,translation model adaptation,various text distance metric,different way,dis tance metric,weight,granularity,source unit,remainder,section,briefly,phrase-based  smt system,section,describes mixture-model adapta tion,section,experimental result,section,previous work,section,concludes,hrase-based statistical mt,baseline,standard phrase-based  smt sys tem,source sentence,target sentence,likely translation,argmax,target phrase,source phrase,translation,kth target phrase,feature function,weight,algorithm,development corpus,feature,length,single-parameter distortion penalty,phrase reordering,translation model probability,4-gram language model probability,kneser-ney smoothing,sri lm toolkit,phrase translation model probability,feature,different estimate,conditional probability,relative frequency,probability,phrase probability,feature,filter,possible translation,source phrase,top-ranked translation,joint count,phrase,duction algorithm,symmetrized word alignment,3 m ixture-model adaptation,approach,mixture-model adaptation,corpus,different component,criterion,test domain,cross-domain adaptation,param eters,development corpus drawn,test domain,fu ture document,dynamic adaptation,global param eters,development corpus drawn,several different domain,set mix ture weight,function,distance,corpus component,component model,single global model,previous section,aspect,algorithm,detail,corpus,different genre,source,simplest way,material,adaptation,alternative,corpus,component model,language,translation model fea tures,translation model,corpus com ponent,global  ibm,word alignment,degradation,align ment quality,corpus,component-specific relative frequency,phrase pair,lexical probability,global  ibm,procedure,component-specific language model,target half,cor pu component,procedure,global model,section,addition,component model,large static global model,combining framework,commonly-used framework,mixture model,language,translation model,component,corresponding weight,global model,mixing parameter,global weight,weight,feature,loglinear model,contrast,mixing,combined model,loglinear weight,weight,component,global loglinear combination,conse quence,linear weight,standard minimum-error training technique,loglinear model,distance metric,standard distance metric,relation,current source,source text,tf idf,information retrieval,vector,component,doc ument,element,relative fre quency,component,docu ment,proportion,component,technique,semantic property,singular value decomposition,rank reduced approximation,original matrix,document frequency,tech nique,document,training corpus,component,projection,component,doc ument vector,previous paragraph,reduced space,perplexity,jelinek,standard way,quality,language model,test text,probability,ngram language model,compo nent,final distance,probability,ngram probability,word sequence,com ponent,em algo rithm,weight,likelihood,weight,distance,experiment,probability difference threshold,metric,distance,fact proximity,convention,closer,adaptive parameter,adaptation,mixture weight,usual loglinear parameter,section,adaptation,cross-domain setting,preference,word penalty,ative lm tm weighting,target domain,dynamic adapta tion,absence,in-domain devel opment corpus,information,weight,adapted model,feature,system,method,mixture weight,combining framework,linear,adaptive setting,cross domain,loglinear mixture weight,loglinear combining framework,section,mixture weight,loglinear parameter,cross-domain adaptation,loglin ear mixture model,dynamic adap tation,linear mixture weight,adaptive setting,linear mixture weight,function,distance metric,section,distance,cur rent text,simple approach,weighting,weight,corresponding distance,different distance metric,complementary information,optimal weight,non-linear function,distance,linear combination,metric,sigmoid function,relative predictive power,sigmoid,suppress contribution,component,normalization constant,approach,parameter,dis tance,parameter,particular model,parameter,global loglinear weight,al gorithm,single distance,downhill simplex algorithm, ble score,development corpus,tractability,standard practice,technique,monotonic align ments,approach,avoid condi,dynamic adaptation,genre preference,development corpus,cross-domain adaptation,development corpus,test domain,downhill simplex optimization,linear weight,yield maximum ble score,development corpus,final variant,linear mixture weight,cross-domain,dynamic adap tation,approach,global loglinear weight,mixture pa rameters,cross-domain adaptation,distance,current source text,distance,domain development corpus,metric,source text,4 e xperiments,experiment, nis t mt,chinese data set,corpus,training corpus,component,corpus,excep tion,newswire component,corpus,target,cross-domain adaptation,high-quality training material,cross-domain development, nis t04 nw,newswire subset,evalu ation,dynamic adaptation development, nis t04-mix,balanced mixed-genre subset,evaluation set,cross-domain adaptation,evaluation,dynamic adaptation,different development corpus,cross-domain,dynamic adaptation,static baseline model,adaptation setting,corresponding develop ment,result,section, ble score,role corpus genre,train  fbi s04,hk han,hk law,hk news press release,newswire,sinorama news mag,un proceeding,dev  nis t04-nw nw,test  nis t05,corpus,genre column,nw newswire,sp speech,editorial,ng news group,bn broadcast news,bc broadcast con versation,linear versus loglinear combination table,comparison,loglinear mixing framework,uniform weight,linear mixture,mixture model,baseline,linear mixture,loglinear mix ture,result,development set,loglinear model,component weight,linear model,global lm,tm weight,non-smooth component model,scheme,kneser-ney phrase table,foster,binary feature,phrase pair presence,different component,problem,algorithm,good maximimum,setting,re sult,experiment,involve,ear mixture,combination,loglinear mixture,uniform linear mixture,linear versus loglinear combination,distance metric,performance,distance metric,section,difference,tm adaptation,lm metric,source,slight advantage,vector space metric,experiment,metric source text target text lm tm lm tm tf idf,perplexity,distance metric,linear combination,top right corner,performance,parame,function,source-side em, lsa metric,weight optimization,technique,downhill simplex,param eter,performance,normalized source-side em,first line,additional test,test corpus,result,compromise,downhill simplex,global weight,single starting point,monotone decoding,lm tm em-src,direct optimization,weighting technique,linear combina tion, nis t04-nw development set,cross-domain versus dynamic adaptation table,show result,cross-domain adaptation,source-side em,linear weight ing,tm adaptation,test-set improvement, 1 b leu point,baseline,lm adaptation,tm adaptation,performance, nis t06 out-of-domain test set,newswire portion,tm adaptation,lm adaptation,individual,information,model dev test nist04nist05 nist06 nw nist baseline,em-src lm tm,cross-domain adaptation result,contains result,dynamic adaptation,source-side em,linear weight,baseline,performance,tm adaptation,baseline,leu  point,per formance,cross domain adaptation,second line,in-domain test,dy namic adaptation,mixed-domain set,model dev test nist04nist05 nist06nist06 mix nist gale baseline,cross lm,dynamic adaptation result,src-side em distance,hybrid adaptation result,show result,hybrid approach,section,global weight, nis t04-nw,linear weight,current test file,per formance,cross domain adaptation,impor tant,good fit,mixture weight,source granularity,result,final experiment,effect,source granularity,dynamic adaptation,source-side em distance,whole test set,document,global weight,condition,little difference,ap proaches,genre-based adaptation,slight advantage,granularity dev test nist04nist05 nist06nist06 mix nist gale baseline,effect,source granularity,dy namic adaptation,work mixture modeling,standard technique,ma chine learning,hastie,language model,speech recognition,application,instance,cross-domain topic mixture,osten dorf,dynamic topic mixture,kneser,steinbiss,hierachical mixture,yarowsky,cache mixture,de mori,previous work,adaptive  smt,ir technique,relevant sub set,training corpus,adapted model,co sine distance,current source document,relevant parallel text,adapted translation model,background information,alignment,hildebrand,similar approach,sentence level,language model,model adaptation,perplexity heuristic,optimal size,rele vant subset,differ ent sentence-level strategy,language model adap tation,nbest list,baseline system,similar sentence,monolin gual target-language corpus,approach,advantage,lm adaptation,parallel corpus,disadvantage,trans lation pass,self-training approach,two-pass algorithm,baseline sys tem,translation,confidence fil tering,parallel corpus,test set,standard phrase-extraction tech niques,adapted phrase table,system,output,parallel training corpus,algorithm,average entropy,target-side language model,fixed number,cluster,source sentence,language model,cluster,likelihood,sentence,ir approach,ueffing,method,corpus division,sentence,little surface similarity,current source text,statistic,translation,instance,probability,pertinent word,previous approach,weight,component,degree,relevance,binary distinction,non-relevant component,6 c onclusion,future work,number,approach,mixture-based adaptation,translation,component model,proportion,weight,current text,ngram language model mixture,corpus component, ble point,sophisticated ap proach,mul tiple distance metric,positive result,unsucessful optmization proce dure,conclusion,linear mixture,metric,vs-based one,adaptation,adapted tm,improve ment,cross-domain adaptation,dy namic adaptation,good fallback strategy,source granularity,genre level,document,test-set level,future work,optimiza tion procedure,parameterized weight function,bilingual metric,domain adaptation,combina tions,cross-domain,dynamic adaptation,reference peter,stephen,della pietra,vincent della,pietra,robert,mercer,mathematics,machine translation,parameter estimation,com putational linguistics,yarowsky,chinese-english machine translation system,lan dauer,harshman,radu florian,david yarowsky,dynamic non local language,hierarchical topic-based adaptation,college park,maryland,george foster,roland kuhn,howard johnson,statistical machine translation, emn lp,sydney,australia,trevor hastie,robert tibshirani,jerome friedman,element,statistical learning,springer,almut silja hildebrand,matthias eck,stephan vogel,alex waibel,adaptation,transla tion model,statistical machine translation,information retrieval,budapest,ostendorf,long dis tance dependence,language,topic mixture,dy namic cache model, iee e tr an,speech,language processing,frederick jelinek,statistical method,reinhard kneser,volker steinbiss,dynamic adaptation,stochastic language model, ica ssp ,minneapolis,philipp koehn,franz josef och,daniel marcu,statistical phrase-based translation, naa cl,roland kuhn,renato de mori,cache-based natural language model,percy liang,dan klein,ben taskar,end-to-end discriminative ap proach,machine translation,franz josef och,minimum error rate training,statistical machine translation,sapporo,kishore papineni,salim roukos,todd ward,wei jing zhu,method,automatic evaluation,machine translation,september,william,teukolsky,william,vetter ling,flannery,numerical recipe,university press,christoph tillmann,tong zhang,discrimi native global training algorithm,nicola ueffing,machine trans lation,workshop,richard zen,hermann ney,improvement,phrase-based statistical machine translation,boston,sumita, nic t-atr  statistical machine translation system, iws lt,evaluation,iws lt,matthias eck,stephan vogel,model adaptation,statistical machine translation,structured query model, col ing,geneva,august,proceeding,second workshop,statistical machine translation,prague,association,computational linguistics rule-based translation,statistical phrase-based post-editing michel simard,nicola ueffing,pierre isabelle,roland kuhn interactive language technology group national research council,canada gatineau,canada,firstname,article,machine translation system,automatic post-editing strategy,input text,target-language,rule-based mt system,statistical phrase-based system,implementation,approach, sys tran, por tage mt,shared task,sec ond workshop,statistical machine trans lation,experimental result,test data,previous campaign,1 i ntroduction simard,sta tistical phrase-based machine translation system,rule-based machine translation system,motivation,repetitive nature,rule-based system,appropriate training material,statistical mt system,systematic er rors,post-editing effort,statistical system,output,rule-based system,source language,reference hu man translation,target language,training material, ape layer,process,rule-based system,specific application domain,approach,large improvement,performance,baseline rule-based system,similar statistical phrase-based mt system,source text,simard,al report,reduction,post-editing effort,input rule-based translation, 5 b leu  point improvement,direct smt approach,impressive result,unusual context,training,test corpus,collection,post-edited machine trans lations,corpus,english-to-french,paral lel,source language text,machine translation,target language,commercial rule,mt system,final target-language version,machine translation,corpus, smt standard,source-language data,french to-english direction,author,important question,result,quantity,result,dependent nature,translation,automatic post-editing approach,machine,hu man translation,question,shared task,second workshop,statistical machine translation,auto matic post-editing strategy,put text,target-language,rule-based system, sys tran,output,statistical phrase-based sys tem, por tage,system,detail,section,experi mental result,section,2 s ystem description,system,main component,rule-based mt system,initial translation,target language,statistical phrase-based post-editing system,domain-specific correction,adaptation,output,component,rule-based translation,initial source-to-target language translation, sys tran machine translation system,version,detailed overview, sys -tr system,dugast,english-to-french configuration,system,system,specialized lexica,feature,system,out-of-the-box,configuration,output,rule-based mt system,post-editing layer,domain-specific correction,adaptation,operation,translation, por tage system,state-of-the-art statistical phrase-based machine translation system,national research council,general description, por tage,participation,configure, por tage system,post-editing,manner,corresponding translation system,detail,main feature,configuration,distinct phrase table,phrase pair,europarl,news commentary training corpus re,log-linear model,joint prob -1a version, por tage,canadian university,research,education purpose,ability estimate,standard frequency-based conditional probability estimate,variant,method,foster,4-gram language model,europarl,news commentary target language corpus,language model,mini-corpus,test-relevant target language sentence,training material,standard information retrieval technique,europarl,news commentary target-language corpus,training data ideally,training material,post-editing layer,system,corpus,parallel version,raw machine translation output,post-edited version,translation,initial study,simard,training data,source-target parallel corpus,source portion,parallel corpus,target lan guage,rule-based mt component,post-editing component,translation,source,material,target portion,parallel corpus,material,simard,target,source,machine translation,source,target,machine,source,initial motivation,current work,performance, ape approach,different translation,europarl,stran ,por tage,stran ,por tage,system performance,figure,single-reference  ble score,detokenized translation,version,transla tion,effort,english french language pair,translation direc tion,system,eu roparl domain,news commentary domain,system,identical configuration,phrase table,log-linear model fea tures,difference,adapted language model,specific text,parameter,log-linear model,domain-specific development set,europarl domain system,dev2006,devtest2006 data set,news com,optimization procedure,weight,europarl-trained phrase table,europarl,main system,news commen tary domain system,3 e xperimental result, ble score,system,test data,test2006,europarl,result,comparison, sys tran system,post-editing layer, por tage mt sys tems,source,first observation,simard,al study,crease, ble score,increase,spectacu lar,europarl domain,english,system,news commentary domain,performs,english,french,leu point,contrast,europarl domain,ap proaches,similar performance,news commentary corpus,50k sentence pair,mil lion word,language,mil lion sentence pair,europarl corpus,result,conjecture,simard,al study,domain,limited quantity,available training data,un derstand,behavior,series,smt system,europarl data,increas ing amount,training data,learning curve,figure,simard,al study, ape system,crossover,simard,sentence pair,approach,impressive feature, ape strategy,little data,rule-based system,sentence pair,english-to-french,combination mt system,post-editing strategy,statistical phrase-based system,output,translation system,experiment,system,experiment,section,phrase table,trigram language model,rescoring,short sentence,co re training sentence,co re training sentence,europarl data,amount,training data, por tage  smt, sys tran mt, por tage  ape,conclusion,post-editing,rule-based mt system, ble score,training data,performs,direct phrase-based mt strategy,fur thermore,result,training data,post-editing component,post-edited translation,standard parallel corpus,ex periments,post-editing,effec tive,little training data,phrase-based translation,amount,number,investigation,example,phrase-based  ape,au tomatic domain-adaptation,rule-based method,proach,standard,lexical customiza tion,method,rule-based mt ven dors,experiment,identical configuration,direct  smt system,phrase-based system, ape task,example, ape layer,real source language text,addition,mt output,front end rule-based system,processing,phrase-based post-editing layer,question,internals,rule-based component,direc tions,acknowledgement,collaboration,many thanks,jean senellart,jens stephan,dimitris sabatakakis,people, sys tran,reference,statisticalpost-edition, sys tran rule-based translationsystem,proceeding,second workshop  ons tatistical machine translation,prague,johnson,statistical machine translation, inp roceedings, emn lp,sydney,tikuisis,pro-ceedings, acl workshop,building,usingparallel text,ann arbor,isabelle,sta tistical phrase-based post-editing,human lan-guage technology,conference,thenorth american chapter,association,com-putational linguistics,proceeding,main con-ference,rochester,johnson,pro-ceedings,second workshop,statistical ma-chine translation,prague,czech republic,proceeding,fourth workshop,statistical machine translation,athens,greece,association,computational linguistics stabilizing minimum error rate training george foster,roland kuhn national research council canada,method,feature weight,system,cedure,well-known problemwith och,procedure,small change,system,number,feature,stability,procedure,different random seed,core component,procedure,powell,system,many feature,extensive variation,outcome,development data,test data,variation,propose modification, mer proce dure,stability,performance,test data,1 i ntroduction recent approach,chiang,log-linear model,probabilistic feature,log linear weight,translation,formance,development corpus,essen tial step, smt training,performance,test corpus,weight,difficult problem,function,log-linear weight,decoding,expensive operation,function,efficient gradient-based optimization,procedure,widely-used ver sion,computational cost,key technique,weight,n-best list,transla tion,possible hy potheses,probable hypoth esis,weight, ble score,n-best entry,variant,powell,algorithm,set ting,n-best list,alternat,decoding, ble maximization operation,new hypothesis,current list,weight,subsequent decoding step,process,new hypothesis,procedure,practice,decoder,general-purpose optimization algo rithm,small change,system,large fea ture set,well-known problem,procedure,contribution,feature,measured gain,performance,new feature,setting,unrelated parameter,n-best list,feature,poten tial,significant gain,procedure,good weight,stabil ity,procedure,different condition,variation,test-set score,different random seed,powell,algo rithm,extensive variation,large feature set,main factor,occasional failure,procedure,good maximum,development set,failure,maximum,test set,problem,propose solution,stability,overall procedure,revious work one possible approach,log-linear weight,feature,n-best list,procedure,weight,disadvantage,approach,iteration,decoding,full devel opment,downhill simplex method,weight,iteration,convergence,iteration,monotone decoding,phrase,tar get language mirror,source language,cettolo,federico,simplex method,weight,decoder,experiment,chinese-english data,iter ations,stable performance gain,procedure,experiment,different training criterion,result,criterion,research,improving,procedure,fea ture weight,n-best list,weight,starting point,weight,previous set,n-best hypothesis,ran dom,random walk,previous max ima,uni form distribution,criterion,performance,ble score,development test set,instance,variance, ble score,held-out test data,contribution,ingenious method,n-best hypothesis,itera tion,search,weight,n-best list,choice,starting point,modified ver sion,powell,diagonal,direction,random,ob jective function,powell,optimum,modified version,version,powell,heuris tic search algorithm,philipp koehn,koehn coordinate descent,development,test data set,kirchhoff,weak learner,boosting algorithm,n-best reranking task,good result,interesting work,generalization,procedure,macherey,generalization,candidate hypothesis,iter ation,procedure,lattice,n-best list,proportion,search space,graph density,phrase,n-best size,octillion,experimental result,lattice variant,procedure,n-best variant,test data,lattice variant,n-best approach,convergence behaviour,lattice variant,n-best variant,insight,current paper,lattice variant,procedure,procedure,initial set,weight,translation,source sentence,n-best list,powell,algorithm,weight, ble score,hypothesis,n-best list,weight,decoder,pro ce repeat,n-best list,practice,criterion,convergence,minimum weight change,weight, ble score,decoder,output,procedure,di rect search,weight,maxi mum  ble score,many different set,weight,translation,procedure,decoder,mag nitude,direct approach,main trick,n-best list,represen tative,search space,weight,ble score,hy potheses,n-best list,algorithm avoids weight,good score,n-best list,bad one,decoder,bad hypothesis,weight,n-best list,choice,weight,future iteration,corresponding guarantee,weight,good score,decoder,bad one,weight,ble score,n-best list,easy problem,candidate weight set,hypothesis,current weight set,measure  ble,scoring hypothesis,source,algorithm,feature,weight,op timum value,linemax algorithm,optimization,powell,algorithm,global max imum,powell,many different randomly-chosen initial weight,good maximum,4 e xperimental setup,experiment,standard phrase-based  smt system,linear combination,weight,original coordinate,corpus num sent,chinese toks,development,test corpus,log-linear combination,feature function,separate word alignment,diag-and,extraction,used beam search,algorithm,chiang,separate log-linear model,phrase-table feature,4-gram lan guage model feature,distortion feature,word-count feature,feature,phrase-table feature,4-gram lan guage model feature,distortion feature,word-count feature,feature,phrase-table feature,large model,globally-trained  hmm,phrase,non-un portion,training cor pora,separate phrase table,relative-frequency,conditional phrase-pair probability,direction,source,vice versa,language model feature,large log-linear model,non-un corpus,phrase table feature,small model,individual table,joint count,relative fre quencies,experiment,chi nese english data,mt evaluation,sentence pair,un corpus,sentence pair,mate rial,english gigaword corpus,language model training,separate devel opment corpus,evaluation,webtext drawn,training material,disjoint,train ing set,test-set  ble score variation,different random seed,dev set,avg column,average  ble score,difference,maximum,mini mum score,standard deviation,corpus,corpus,reference translation,stability,response,algorithm,small change,system configuration,seed value,random number gen erator,powell,algorithm,different seed value,algorithm,maximum,100-best list,result,different log-linear model,previous section,development set,similar pat tern,small model,considerable variation,test-set  ble score,large model,average difference, ble score,absolute,average standard deviation,confidence level,boot strap,varia tions,variation,algorithm,development-set ble,certain run,different maximum,extent,test set,factor, ble score,development corpus,large model,corresponding standard deviation,effective convergence,dev nist04 nist06 inter,spearman,test-set  ble,large log-linear model,final column show,nist06 correlation,different degree,success,variation,development,account,vari ation,test-set score,correla tion,result,velopment,test corpus,rank correlation,many example,development-set score,test set score,correlation,test-set score,last column,velopment,test set,test set,log-linear weight,development corpus,random seed,result,indicate,stability prob,weight,large number,feature,baseline solution,problem,number,different ran dom seed, ble score,test set,weight,new data,procedure,nist04 corpus,weight yield,leu  increase,nist06,average value,operating,reverse direction,increase,nist04,3these increase,average,increase,development,comparison,baseline single-mert procedure,test set,model selection,development set,nist06,different feature set,test set,later evaluation,number,run nis t06  ble,number,random run,dev1 figure,result,nist06 test corpus,nist04,weight,num bers,random draw,magnitude,standard deviation,obvious drawback,technique,expensive  mer procedure,many time,potential gain,stability,procedure,bootstrap simulation,development,behaviour,nist06 score,nist04 score,result,figure,obvious optimal point,standard deviation,variance,following section,alternative,large model setting,maximization,section,problem,improv,maximization procedure,devel opment corpus,maximum,variance,test-set score,previous work,performance,powell,algorithm,degree,approximation,current n-best list,true search space,test set,multi-mert strategy,regime,substantial bias, cf igure,true objective function,bold curve,n-best approximation,algorithm,false maximum,hypothesis,n-best list,local peak,bl eu iter ble,och iteration,figure,development-set  ble score,och iteration,dev2 corpus,figure,true space,maximum,approxi mate,figure,evidence,practice,evolu tion,decoder  ble,iteration,promising area,itera tion,afterwards,region,true  ble,failure,powell,algorithm,n-best list,various simple strategy,local-maximum behaviour exhib,figure,powell,algorithm,standard form,baseline implementation,algorithm,powell,weight set,previous iteration,certain number,randomly-generated weight,tal number,powell,algorithm,probability,strategy,ran dom number generator,global seed value,iteration,algorithm,implementation,random,powell,different och iteration,ground,function,second strategy,ob servation,first several iteration,algorithm,powell,result,weight set,randomly-generated set,algo rithm,alternative,result,previous och,itera tions,iteration,powell,result,iteration,al gorithm,final strategy,algorithm,por tion,search space,maximum-bleu result,powell,algo rithm,subsequent decoding step,weight vector,high  ble score,weight,weight vector,powell,current iteration,vector,distance,previous weight,distance,vector,previous weight,minimum l2 distance,weight vector,previous  m o ch iteration,weight,im portance,algorithm,search,maxi -4w,new maximum,current number,minimum,experiment,total number,different result,mum found,simulated anneal,parameter,control,current och iter ation,strategy,random seed,development corpus,weight selection strategy,different set,parameter,assigns equal weight,novelty,first iteration,first parameter ization,weight,novelty decay,final iteration,result,strat egy,combination,technique,parametrization,weight selection,strategy,development,average,baseline,signifi,variation,different run,performance,weight selection,parameter,sig nificant difference,setting,tuning,parameter,re sults,expensive procedure,good fallback,strategy,result,final gain,weight selection,7 g eneralization,section,performance,development set,performance,weight vector,dev-set ble score,different test-set score,several vector,charac teristic,experiment,intrinsic property,good predictor,test-set performance,weight,scale invari ant,sample,development corpus,history,performance,various strategy,maximization,dev corpus,base line,baseline,section,re-seed,random generator re-seeding,history,accumu lation,weight,weight selection,strat egy,section,strategy,alternate approach,reg ularization method,average  ble score,maximum,surro gate,maximum,maximum,technique,single dimen sion,powell,algorithm,dimension,vector output,pow ell,individual weight,normal distribution,variance,vector,n-best list,average score,perturbed vector,weight-selection method,previous section,result,regularized weight selection,weight selection,baseline  mer algorithm,regu larization,little effect,weight selection approach,result,different setting,standard weight selection technique,combination,re-seeding,history accumulation strate gy,systematic improvement,average test-set  ble score,baseline,variance,performance,various  mer tech niques,test corpus,configuration,procedure,8 c onclusion,stability,different random seed,powell,algorithm,effect,small change,system,test-set  ble score,percent,algorithm,different random seed,bootstrap analy si,ex pensive,many time,weight,result,held-out corpus,expensive simple strategy,local maximum, ble score,variance,attempt,strategy,future work,improved variant,powell,algorithm,investigation,9 a cknowlegement,material,opinion,finding,conclu sion,recommendation,ma terial,author,reference daniel cer,daniel jurafsky,christopher,regularization,search,minimum error rate training,proceeding, acl work shop,statistical machine translation,columbus,mauro cettolo,marcello federico,min imum error training,log-linear translation mod el,international workshop,spoken language translation,september,david chiang,hierarchical phrase-based model,statistical machine translation,pro ceedings,annual meeting,associ ation,ar bor,michigan,kevin duh,katrin kirchhoff,beyond log linear model,minimum error rate training,n-best re-ranking,proceeding,nual meeting,association,liang huang,david chiang,forest rescor ing,integrated language mod el,proceeding,45th annual meeting,association,czech republic,philipp koehn,franz josef och,daniel marcu,statistical phrase-based translation,ed uard hovy,editor,proceeding,human lan guage technology conference,north ameri,chapter,association,computational linguistics,edmonton,alberta,canada,franz josef och,ignacio thayer,jakob uszkoreit,lattice-based minimum error rate training,statistical machine transla tion,proceeding,conference,em pirical method,honolulu,robert,chris quirk,random,minimum error rate training,statisti cal machine translation,proceeding,inter national conference,manchester,august,franz josef och,daniel gildea,sanjeev khudan pur et al,final report,john hopkins,summer workshop,syntax,statistical ma chine translation,minimum error rate training,statistical machine translation,proceeding,annual meeting,association,william,teukolsky,william,vet terling,flannery,numerical recipe,university press,richard zen,hermann ney,phrase-based statistical machine transla tion,proceeding,boston,richard zen,sasa hasan,hermann ney,systematic comparison,training criterion,sta tistical machine translation,proceeding,conference,empirical method,prague,czech re public,proceeding,international conference,computational linguistics,coling,beijing,august,phrase clustering,tm probability,paraphrase,phrase table  1r,  2e van stratford  1n ational research council,canada  2u niversity,waterloo  1f,stratford gmail,com  a bstract,phrase,sys tem,information,phrase,clustering,source language,target-language phrase,clustering,language,clustering,phrase cluster,many possible us,probability, smt system,phrase-cluster-derived probability esti,baseline loglinear feature combination,relative fre quency,lexically-weighted condition,probability estimate,curve experiment,baseline,maximum gain, ble point,200-400k sentence pair,sentence pair,amount,training data,literature,original smoothing approach,1 i ntroduction,related work,target-language,many statistical machine trans,system,arbitrary sequence,contiguous word,complex heuristic,bilingual corpus,phrase-based system,word-based system,useful entity,bet ter estimate,backward,probability,probability,source-language phrase,target-language phrase,current work,foster,relative frequency estimate,number,estimate,estimate,phrase,different idea,estimate,phrase,similar meaning,experiment,method,improvement,lexical esti mate,non-compositional phrase,bucket,method,phrase,smoothing,research,schwenk,continuous space gram model,neural network,translation probability,schwenk,technique,system,paraphrase,key paper,bannard,callison-burch,extraction,paraphrase,bilingual parallel corpus,allison-burch et,paraphrase gen eration,son-burch,quality,marton,pa raphrases,monolingual data,distribu tional information,paraphrase,system,sentence,source-language,target language,similar meaning,paraph ras,previous work,paraphrase,translation,source-language phrase,system,system training,approach,situation,new information,target,source phrase,system,phrase table,paraphrase,source,target phrase,phrase table,paraphrase,source phrase,phrase table,ur work,differs,pa raphrases,information,source,pivot language,thesaurus,system,phrase table,respect,chiang,classic work,hierarchical phrase-based system,chiang,chiang,different type,formation,phrase table,ecause,difference,paraphrasing,phrase,ap proach,input information,approach,conditional probability,phrase cluster given phrase cluster,source,target language,derive estimate,conditional probability,clustering,source phrase belongs,target phrase belongs,cluster,singleton phrase,others,phrase,total number,observation,training data,phrase,english cluster c,phrase,burgundy,observation,training data,number,co-occurrence,training data,source-language cluster c,phrase-cluster-based probability,corresponding relative frequency estimate,opposite,phrase,train ing data,train ing,valuable extra information,argument applies,estimation,phrase,information,phrase,similarity,phrase,phrase cluster,count-based metric,edit-based metric,phrase co occurrence count,latter,phrase,advantage,count-based metric,similar translation,phrase,similar meaning,dissimi larity,word sequence,cluster,metric,total count,phrase co-occurrence,noisy alignment process,edit-based metric,inde pendent,phrase,similar word sequence,different meaning,experiment,combination,edit-based metric,phrase,metric,effort,count-based component,count-based similarity,phrase,similarity,phrase,high count,phrase-cluster-based estimate,phrase,low count,phrase,phrase,3-15 observation,training data,phrase-cluster-based probability estimate,count-based clustering,overview,count-based phrase,language,source,target,cluster,phrase,language,language,cluster phrase,language,enough clustering,ach phrase,phrase cluster,vector,co-occurrence count,similarity,phrase cluster,count vector,figure,source phrase s1,target phrase,source similarity com putation,bracket,italic,similar normalized vector,figure,phrase s1,phrase,new vector,real life,source language,source language side,example,get-language clustering,target similarity cal culations,previous source clustering,coordinate,manner,language,final output,joint phrase cluster count,previous section,count-based clustering,detail count-based similarity,noisy process,transformation,information retrieval,salton, mcg ill,cluster  f igure,example,phrase,source similarity computation,tween source cluster c,factor,information content,number,cluster,source side,par ticular target cluster ct,number,source cluster c,co-occur,target similarity computa tion,source similarity computation,co-occurs,source cluster,contribution,little information,vector,tf-idf count,total num ber,observation,vector,similarity,tf-idf vector,co sine measure,salton, mcg ill,family,probabilistic metric,similar vec tor,unmodi fied count,vector,tf-idf transformation,purpose,similarity calculation,  n ow,probabilistic metric,count vector,function,measure,normalized vector,count vector,follow ing measure,accuracy,merges,vector,small count,aver age impact,iiapl  vuvuvu,initial experiment,phrase cluster,intui tive sense,cluster,large number,observation,language side,phras e,wildly disparate meaning,monster cluster,count vector,decision,different semantics,cluster,small count vector,next round,merging,black hole,  t deal,problem,vvuvvui vu,measure,distribution,average probability loss,observation,second term,average probability loss,observation,vector pair,vector,large loss,parent,  i practice,metric,dice coef ficient,distance,number,non-zero count entry,number,count entry,edit-based similarity,experiment,count-based metric,edit-based metric,little effort,edit metric, mc w stand,phrase p1,number,metric doesn,take word,account,future work,difference,content word,dis tance,phrase cluster,cluster,phrase,scarlet,cluster,dark burgundy,number,observation,bracket,edit distance,clus ters,distance,phrase,observa tions,cluster,distance,cluster,definition,example,phrase cluster,english phrase cluster, c-e experiment,edit-based information,phrase,bracket,low count,edit distance,morphology,phrase,phrase,emancipation,count informa tion,common stem,  f igure,show part, a f rench phrase cluster, f-e experiment,surface form,phrase,something,exception,pa faire,something,illustrates,edit distance,negative word,veiller,faire de, f igure,partial french phrase cluster 4 e xperiments,experiment,pas phrase-based  smt system,phrase table, hmm alignment,system,distance-based distor tion component,7-word distortion limit,cube pruning,chiang,loglinear feature combination,language model,distortion component,relative frequency esti mators,lexical weight estimator,com ponents,effec tive lexical smoothing technique,phrase cluster-based component,additional loglinear feature function,weight,feature function,lattice  mer,macherey,method, f-e task,experiment,corpus,different size, c-e data, nis t1,evaluation,bilingual corpus,un corpus,hong kong hansard,hong kong law corpus,translation model,5-gram language model,english side,parallel data,cludes, ni st,material,evaluation,test set,figure,training,development,test corpus,number,sentence,number,reference,test set,gov speech test,   c hi eng,test  nis t06, ni st08,gigaword,statistic,chinese-to-english task,re eng train europarl,gigafren,statistic,french-to-english task, l ang,count-1 count-1  s rc, t gt,phrase class, f-e task, f-e track data set,parallel europarl data,newstest,test set,reference,source input sentence,language model,english side,parallel data,english side,gigafren corpus,train ing,development,test corpus, f-e task,amount,phrase,data couldn,phrase,statmt,org wmt10,parameter,number,merge op erations,iteration,percentage,number,potential same-language phrase pair,simple criterion,overlap,translation, fbi corpus, c-e data,parameter,english,amount,french,english,result,total phrase,language end,cluster,eligible phrase,phrase,translation probability,language pair,preliminary test, map ldiceedit,cosineedit,close runner-up,result,evaluation, ibm  ble,papineni,case-insensitive matching,first expe riment,effect,phrase cluster,feature,various amount,training data,figure, ble score improve ments,language pair,result,test set,data size,sentence,medium amount,training data, f-e training data,sentence,improvement,8 m english word,detail,improvement, nis t06 test,cluster feature,experiment,reviewer,significance test,individual result,individual result,probability,null hypothesis,method,effect,fair coin,independence approximation,research,paraphrase,small amount,training data,contrast,approach,medium amount,training data,200-400k sentence,property,count-based clustering,clustering,much data,clustering,relative frequency,phrase cluster probability estimate, f igure,average  ble improvement,f-e task,experiment,decision, dma pl,cosine,count-based component,experi ments, dma pled,cosineedit, nis t06, nis t08,news test2009,tiny advantage, dm aple dit,wrong decision,edit component,logous experiment, dma pled,test set,right decision,final experiment,phrase,clustering, c-e system,clustered phrase,chinese,english,phrase,cluster,previous system,surprise,slight improvement, c-e system, nis t06, nis t08,system,clustering,phrase,cluster,system,english phrase,cluster, d ata size nist06 nist08 baseline phrase-clustering improv,baseline phrase-clustering improv,various training corpus,baseline result,result,phrase clustering,absolute improvement,corpus size,sentence,ata size newstest2009 newstest2010 baseline phrase-clustering improv,baseline phrase-clustering improv,various training corpus,baseline result,phrase clustering feature,result,phrase clustering,absolute improvement,system al,newstest2009,newstest2010,decision,phrase,experiment,mi take,han dling,phrase,edit component,similarity,phrase,cluster,5 c onclusion,future work,source-language,target language,phrase table,cluster,estimate,consistent  bl eu gain,baseline,lexical smoothing,experiment,phrase-based system,method,hierarchical phrase-based  smt,syntactic  smt system,several possi bilities,future work,new applica tions,phrase cluster,experiment,phrase cluster,train ing data,phrase cluster,non-zero probability,training data,co-occur,decoder,phrase,basic unit,phrase cluster,instance,tri cluster model,proba bility,phrase,function,phrase cluster,phrase cluster ci-1,lexicalized distortion model,distortion event,phrase cluster, smt grammar,terminal,phrase,parent,terminal,phrase cluster,several way,edit distance,phrase,phrase cluster,dis tance,large impact,phrase,count-based metric,large proportion,edit distance,weight,word substitution,insertion,deletion,count-derived phrase cluster,content word,negative word,weight,distance,phrase cluster,edit distance,phrase,observation,distance,phrase cluster,figure,phrase edit distance,cluster,distance,cluster,minimum,average pairwise edit distance,characteristic phrase,cluster phrase,infor mation,phrase table,fu ture,formation,paraphrase,context,phrase,monolingual corpus,information,pivot lan,phrase,phrase,language,cluster,algorithm,clus tering,instance,probability,phrase,probability,neighbour,primitive way,latent structure,joint phrase count,principal component analysis,related algo rithm,callison-burch,ann arbor,statistical machine translation using pa,paraph ras,honolulu,october,ann arbor,statistical machine translation,sydney,australia,rescoring,integrated language model,prague,university press,uszkoreit,lattice-based minimum error rate training,honolulu,october,singapore,august,method,automatic evaluation,philadel phia,salton, mcg ill,introduction,schwenk,costa-juss,prague,czech republic,boston,pivot approach,extracting paraphrase pattern,colum bus,proceeding,conference,empirical method,natural language processing,massachusetts,october,canada,discriminative instance weighting,domain adaptation,statistical machine translation george foster,cyril goutte,roland kuhn national research council canada,alexandre-tache,abstract,new approach,adapta tion,out-of-domain phrase pair,relevance,target,general language,previ ous work,discriminative weighting,finer granularity,prop erties,instance,com ponents,simpler training proce dure,instance,mixture-model framework,consistent improvement,wide range,baseline,1 i ntroduction domain adaptation,common concern,empirical  nlp application,domain,additional data,domain,principle,perfor mance,practice,challeng ing,target domain,background data,developer,system,additional complication,heterogeneous na ture, smt component,word-alignment model,language model,translation model,single universal approach,adaptation,problem,parallel corpus,performance,target,amount,material,reasonable performance,standard adaptation problem,simplicity,technique,straightforward manner,general case,multiple sub-domains,large body, smt adaptation,several new idea,example,belonging,general language,pre vious approach,example,target domain,ef fective,setting,dis parate,domain-specific example,maximum-entropy model,latent variable,degree,speci ficity,related idea,simpler way,feature,domain-specific version,effective ap proach,multinomial model,core  smt component,natural method,split feature,instance-weighting approach,domain-specific ex amples,framework,fea tures,degree,generality,output, svm classifier,intersection,positive ex amples,second contribution,instance,weighting,phrase pair,sentence pair,natural instance,sen tences,domain-specific,general language,instance,sentence sim ilar improvement,haemoglobin level,scientific literature,epoetins,presence,general phrase,previous work,matsoukas,sentence,sub-corpus,genre membership,improvement,approach,linear mixture model,con ditional phrase pair probability,likelihood,empirical joint phrase-pair distribution,velopment,effective alter native,weight,similar maximum likelihood approach,foster,language model,compar ison,information-retrieval inspired baseline,sentence,language model perplexity,straightforward technique,bet ter,adaptation task,standard method,representative sentence,match result,section,baseline technique, smt adaptation,section,instance-weighting ap proach,experiment,section,sec tion,previous work, smt adap tation,section,concludes,2 b aseline  smt adaptation technique standard  smt system,hierarchical param eter structure,top-level log-linear weight,small set,complex feature,log probability,internal parameter,objective,top level weight,small development set,approxi,sentence pair,amount,setting,weight,im portant feature,probability,target word,translation model,probability,source phrase,phrase,vice versa,alignment procedure,phrase table,tm distribution,simple baseline,natural baseline approach,success,domain, out cor pu,contribu tion,contribution,separate, out model,combination,easy way,domain-specific lm,top-level log-linear model,optimal weight,potential drawback,number,feature,foster,linear combination apart frommert difficulty,conceptual problem,log-linear combination,fea ture probability,different fea tures,high-scoring candidate,tm probability,adaptation,suitable framework,mixture model,domain,linear combination,domain-specific probability,weight,linear weight,standard  mer procedure,hid den,top-level probability,previous work,foster,prob lem,weight,corpus log likelihood,training criterion,precludes,exact line-maximization,powell,algorithm,instance,weight vector,element,domain,corresponding domain-specific model,empirical distribution,target language,corpus,dev set,equivalent,well-defined objective,parallel corpus,previous worker,ad hoc,scheme,sumita,foster,final con ditional estimate,phrase table,likelihood,joint empirical phrase pair,word-aligned corpus,direct parallel,joint empirical distribution ex,dev set,alternative form,linear combination,combination,bacchi,phrase table,probability,parameter, a d irich let,phrase probability,posterior estimate,corpus,weight,evidence,criterion,non-adapted  ibm model,available, out data,themap combination,tm probabil ities,technical difficulty,coherent count,standard lm,technique,kneser,information retrieval,number,approach,sentence pair,individual source sentence,hildebrand,individual target hypothesis,sentence pair,corpus,system,matching,sentence level,informa tion,baseline,simple sentence selection algorithm,parallel sentence pair,perplexity,target half,lan guage model,number,top-ranked pair,dev-set  ble score,3 i nstance,sentence-selection approach,binary distinction,non-useful part,matsoukas,weight,sentence pair,relative-frequency phrase-pair probability,weight,sen tence,perceptron,boolean feature,collection,genre membership,matsoukas,alapproach,sev eral way,weight,individual phrase,sentence,example,introduction,right granularity,domain effect,second,division,cor pu,manually-assigned portion,feature,usefulness,phrase pair,instance-weighting model,general linear combination,weight,parameter,problem,reconstitut,joint count,conditional estimate,marginals,overall adapted tm,combination,corpus,relative-frequency estimate,instance-weighted model, out cor pu,combination,fixed-weight linear combination, am ap combination, a m ap criterion,weighted phrase-pair count,modified count,prior distribution,prior weight,original  out count,feature,usefulness,mixing parameter,feature weight,maximum likelihood,direct objective,matsoukas,iterative approxi mation,effi cient,maximization,popular  l-b fgs  algorithm,nocedal,gradient information,conditioning,brevity,probability,support,dis tribution,dev set,typical  mer run,interpretation,variant,joint  out count,multinomial phrase probability,likelihood,respect,following derivation,solution,similarity,approximat,logistic function,output,application,interesting al ternative,function exp,output,alternate approximation,ad ditional assumption,support,variant,experiment,final alternate approach,weighted joint frequency,conditional estimate,approach, a m ap-style combination,training data,reliable performance,strategy,simple feature,feature,logistic weighting model,degree,phrase pair belongs,general language,simi larity,domain,general-language feature,straightforward cue,frequency,centrality,model score,burstiness,total number,ut-corpus frequency,rarest source,target word,perplexity, out  ibm,di rections,average,minimum source,target word,document frequency, out corpus,anonymous reviewer,experimental setting,document bound aries,approximation,setting,con sistency,minimum source,target word value, out corpus,following statistic,degree,burstiness,bursty behaviour,sentence,distance,number,sentence,sentence,total number,sentence,number,sentence,similarity-to-in feature,word frequency,various model,corpus,source,target perplexity,target,respect,perplexity,direc tions,numerical problem,feature,dividing,standard deviation, svm feature,addition,simple feature, svm classifier,feature, out phrase pair,phrase table, out training corpus,instance weighting model,phrase pair,intersec tion, out phrase table,positive example,alternate definition,negative example,source phrase,intersection, out translation,source phrase,chinese experiment,source lm, ldc segmenter,chinese model,system,classifier,definition,accuracy,development set,phrase pair, out table,feature,instance-weighting model,4 e xperiments,system,translation experiment,dif ferent setting,first setting,corpus,tiede mann,cor pu,statmt,org europarl,english french translation,direction,test set,corpus,figure,sample sentence,domain,second setting,news-related sub corpus, nis t09 mt chinese,evaluation8,hong kong law,hong kong hansard,dev cor pu, nis t05 evaluation set,randomly-selected material re,training set, nis t06,nis t08 evaluation set,domain,test corpus match,corpus,setting,corpus sentence,europarl,eme dev,nis t out ,nis t in train,nis t in,nis t06 test,nis t08 test,corpus,gov iad mig test,reference medicine,silapo,epoetin alfa,silapo,qui contient,tine alfa,matter,national court,je voudrais pre,adresse du commissaire liikanen,pa aise,figure,sentence pair,europarl text,standard one-pass phrase-based sys tem,fea tures,relative-frequency tm probability,direction,4-gram lm,kneser-ney smooth ing,word-displacement distortion model,word count,feature weight,phrase table,phrase,separate alignment,length limit,translation,source phrase,tm part,current log-linear model,result table,show result,setting,meth od,section,simple baseline,section,natural baseline,baseline,pure system,log-linear combi nation,loglin,pure system,ir system,multiple,eme training corpus,perfor mance,log-linear combination,mixture baseline,linear lm, map tm,non-adapted counterpart perform,log-linear combi nation,tm component,linear lm,enfr nst06 nst08,loglin,lin lm,lin tm,map tm,lm lin tm,lm map tm,iw gen map,iw sim map,iw svm map,result,english, nis t ch,en glish translation, nis t06, nis t08 evaluation set,number, ble score,linear tm,result,log-linear com bination, eme setting,nature,setting,log-linear combination,intersection,domain,somewhat,large systematic difference, map combination,block contains instance-weighting mod el,feature, a m ap tm combination,linear lm mixture,weight,uni form,version,section,origi nal frequency,good performance,final weighted frequen cies,instance-weighting model,equivalant model,instance weight,log-linear baseline,large margin,final block,show model,feature subset, svm feature,general-language feature,slight advantage,similarity feature, svm feature,related work,matsoukas,discriminative cor pu weighting,non discriminative,instance,matsoukas,alresults,out-of-domain corpus,heterogeneous training data,matsoukas-style iden tity feature,instance-weighting model,author,respect,non-adapted baseline,instance-weighting frame work,compassing,possibility,setting,corpus,connection,feature,general copy,first glance,specific general distinction,fea tures,instance,multino mial model,correspondence,instance,feature,correspondence,conditional multinomial probability,ply daume,approach,multinomial,mechanism,split feature,recent work,finkel,manning,approach,hierarchical  map framework,problem,major theme, smt adaptation,hilde brand et,mixture,sumita,fo ter,schroeder,approach,method,monolin gual in-domain text,training,bertoldi,federico,schwenk,senellart,word alignment model,extraction,civera,dev set,latent topic distribution,source,language,fea tures,sentence level,different category,sentence,sumita,6 c onclusion,approach,instance-weighting phrase pair,out-of-domain corpus,in-domain performance,out-of-domain phrase pair,simple feature,feature,logistic model,overall weight,phrase pair,frequency,relative-frequency estimate,dif ferent weight,direction,hese estimate,relative-frequency estimate,in-domain phrase table,mixing,smoothing,instance-feature weight,efficient maximum-likelihood procedure,small in-domain development corpus,positive result,sim ple phrase-based system,different adaptation setting,english french europarl,performance,non-news portion, nis t09,material,performance,news-related corpus,instance,approach,wide range,baseline, 2 b leu  point,non-adapted baseline,equivalent mixture model,identical training procedure,instance,approach,competitive  smt system,stance weighting,standard  smt component,lexical ized distortion,baseline,matsoukas,alapproach,benefit,phrase pair,full sentence,sophisticated instance weighting feature,degree,gen erality,phrase pair,reference,proceeding,45th annual meeting,association,czech republic,michel bacchiani,brian roark,murat saraclar,model adaptation,mation,perceptron algorithm,marcello federico,main adaptation,statistical machine translation,monolingual resource,alfons juan,adaptation,statistical machine translation,mixture mod,daniel marcu,adap tation,statistical classifier,journal,artificial intelligence research,frustratingly easy domain adap tation,eiichiro sumita,dynamic model interpolation,statistical machine translation,proceeding, acl workshop,statistical machine translation,columbus,jenny rose finkel,christopher,manning,hierarchical bayesian domain adaptation,proceed ings,human language technology conference,north american chapter,association,boulder,roland kuhn,mixture-model adaptation,roland kuhn,min imum error rate training,matthias eck,stephan vogel,alex waibel,adaptation,translation model,statistical machine translation,formation retrieval,proceeding,10th  eam tco nference,budapest,chengxiang zhai,instance,domain adaptation,kneser,hermann ney,backing-off,m-gram language modeling,pro ceedings,international conference,acoustic,speech,detroit,philipp koehn,josh schroeder,experiment,domain adaptation,statistical machine transla tion,proceeding,second workshop,sta tistical machine translation,prague,czech republic,association,computational linguistics,philipp koehn,franz josef och,daniel marcu,statistical phrase-based translation,proceed ings,human language technology conference,north american chapter,association,edmonton,nocedal,limited mem ory method,large scale optimization,mathemati cal programming,jin huang,qun liu,statistical machine translation performance,data selection,optimization,proceeding,conference,empirical method,prague,czech republic,spyros matsoukas,antti-veikko,bing zhang,discriminative corpus,estima tion,machine translation,proceeding,conference,empirical method,proceeding,human language technology conference,north american chap ter,association,boston,franz josef och,minimum error rate training,statistical machine translation,proceeding,annual meeting,association,holger schwenk,jean senellart,translation model adaptation,arabic french news translation system,lightly-supervised training,proceeding,mt summit  xii,ottawa,canada,september,inter national association,machine translation,yik-cheung tam,ian lane,tanja schultz,bilingual-lsa,lm adaptation,spoken lan guage translation,collection,multilingual parallel corpus,mitkov,editor,recent advance,natural language processing,volume,john benjamin,amsterdam philadelphia,nicola ueffing,gholamreza haffari,anoop sarkar,statistical machine translation,proceeding, acl workshop,sta tistical machine translation,prague,proceeding,workshop,statis tical machine translation,athens,zhanyi liu,alignment model adaptation,domain-specific word alignment,proceeding,43th annual meet ing,association,michigan,hermann ney,dependent statistical machine transla tion,september,bing zhao,matthias eck,stephan vogel,model adaptation,statistical machine translation,structured query model,proceed ings,international conference,geneva,august,proceeding,joint conference,empirical method,natural language processing,computational natural language learning,jeju island,association,computational linguistics enlarging paraphrase collection,generalization,instantiation atsushi fujita future university hakodate 116-2 kameda-nakano-cho,hakodate,hokkaido,041-8655,alexandre-tache,boulevard,canada pierre,isabelle,roland,kuhn nrc,paraphrase acquisition method,uncovers,exploit generali tie,paraphrase,paraphrase pat tern,lect novel instance,method,bilingual parallel,monolin gual corpus,source,high-quality seed paraphrase,latter,paraphrase,pattern,monolingual cor pora,bilingual corpus,paraphrase,quality,bilingual corpus,experiment,number,paraphrase pair,monolingual corpus,large multiple,number,seed paraphrase,human evaluation,paraphrase sub stitution test,paraphrase pair,reasonable qual ity,seed paraphrase,1 i ntroduction paraphrase,equivalent expression,language,equivalence,fundamental semantic relationship,technique,paraphrase,important role,wide range,natural language processing task,madnani,last decade,automatic acquisition,knowl edge,paraphrase,corpus,attention,many researcher,knowledge,equivalent sub-sentential expression,resemble,control system,challenge,paraphrase,good coverage,targeted class,paraphrase,low proportion,incorrect pair,matter,resource,paraphrase pair,high recall,high precision,various type,corpus,monolingual corpus,source,high coverage paraphrase acquisition,bilingual text avail,method,monolingual cor pora,distributional hypothesis,harris,expression,similar context,similar meaning,distributional criterion,dif ficult,real paraphrase,expression,antonym,cousin word,contrast,bannard,callison-burch,bilingual parallel corpus,good source,high quality paraphrase,paraphrase,together expression,translation,language,translation,specific meaning,context,aforementioned ap proach,expression,manner,correct paraphrase,cov erage problem,bilingual parallel,monolingual text,objective,para phrase,high quality,bilingual parallel corpus,large quantity,monolingual corpus,method,general pattern,paraphrase,bilingual parallel,monolingual source,information,high-quality set,paraphrase,bilingual parallel cor pu,paraphrase pattern,appropriate instance,pattern,potential paraphrase,mono lingual corpus,method,section,method,section,section,experiment,paraphrase,present statistic,coverage,method,section,human evaluation,quality,acquired paraphrase,section,2 l iterature,paraphrase acquisition,section,corpus-based method,paraphrase acquisition,classification,hashimoto,similarity,alignment-based method,similarity-based method technique,cor pora,distributional hypothesis,harris,large quantity,mono lingual data,many language,large number,paraphrase candidate,pantel,dienes,bha gat,ravichandran,feature,context,target ex pression,contextual feature,criterion,feature,aggregation function,drawback,contextual simi larity,high score,non-equivalent expression,antonym,cousin word,preci sion,result,mechanism,marton et al2011,alignment-based method pair,expression,expression,different language,paraphrase,hypothesis,barzi lay,al2003,monolingual parallel corpus,multiple human translation,source,parallel sen tences,sub-sentential paraphrase,recent advance,callison burch,method,sub sentential paraphrase,bilingual parallel cor pora,translation table,alignment,expression,phrase,subtrees,parallel sen tence pair,expression,language,ex pressions,language,pivot language,paraphrase,likelihood,paraphrase,shared trans lations,factor,number,number,occurrence,ex pression,language,brockett,paraphrase,translation,language,travers,multiple translation table,bilingual parallel corpus,approach,suffers,cover age problem,monolingual parallel,bilingual parallel corpus,monolingual non-parallel corpus,acquired pair,expression,non paraphrase,roneous alignment,corpus,monolingual comparable corpus,source,paraphrase,alignment,method,instance,multiple news arti cles,shinyama,al2002,barzilay,al2004,wubben,al2009,corpus,crowdsourcing,availabil ity,monolingual comparable corpus,language,approach,corpus,small collection,paraphrase,hashimoto,limitation,sentence,constitute explicit definition,particular word,phrase,monolingual non parallel web document,sentence,noun phrase,corre sponding phrase,sentence pair,limita tion,approach,considerable amount,corpus construc tion,paraphrase extraction step,summary existing method,corpus,principal re source1,monolingual non-parallel corpus,lingual parallel corpus,monolingual comparable corpus,bilingual parallel corpus,matter,resource,paraphrase,high recall,precision,possible excep tion,method,hashimoto,al2011,large amount,method,method deal,expression,surface level,exploit generality,paraphrase,coverage,high precision,furthermore,method,bilingual parallel,monolingual non-parallel corpus,source,paraphrase,process,figure,high-quality seed,bilingual parallel corpus,alignment-based method,method,paraphrase,generalization,novel set,paraphrase pair,mono lingual non-parallel corpus,learned pattern,paraphrase pair,monolingual corpus,re ranking paraphrase,bilingual parallel corpus,knowledge,bilingual comparable corpus,source,paraphrase,monolingual non-parallel corpus step,paraphrase acquisition step,paraphrase pattern induction step,instance acquisition,health issue,regional issue,regional issue,regional problem,communal issue,problem,spatial issue,bilingual parallel corpus figure,process,paraphrase acquisition,set pseed,process,set phvst,last stage,process,paraphrase acquisition,first step,high quality paraphrase,alignment-based method,monolingual parallel corpus,similarity-based method,parallel corpus,various option,standard technique,bannard,callison-burch,bilin gual parallel corpus,section,phrase-based  smt frame work,re sults,method,phrase pair extraction process,phrase, smt system,high recall,increased robustness,translation process,result,naive application,paraphrase acquisition method,expression,exact paraphrase,instance,algorithm ex,counterpart,sen tence pair,technique,candidate translation pair,unreliable translation pair,johnson,al2007,phrase,stop word,punctuation mark,language,interest,pivot language,initial set,paraphrase pair,sanitized translation table,control device,device,control system,controlling device,figure,control apparatus,control apparatus,control apparatus,figure,control device,discard pair,difference,stop word,school,singular-plural difference,family unit,language,interest,morphological variant,europe,gender,reliable pair,dotted line,figure,phrase,phrase,vice versa2,paraphrase pair, lhs phrase lp, a r h phrase rp,iff lp,condition,word sub-sequence,likely paraphrase, rhs phrase rp, a l h phrase lp,legitimate source,rp iff rp,following condition,word sub-sequence,likely source,direction,intersection,result,denkowski,rhs phrase, lhs phrase,candidate pair,reliability score,threshold,conditional probability,denkowski, rhs phrase,contextual similarity,mono lingual corpus,spe cific recipe,comprehensive comparison,recipe,contextual simi larity,particular recipe,experiment,section,paraphrase pattern induction,seed paraphrase,paraphrase pattern,instance,paraphrase,paraphrase pattern,restraint system,movement,racism,middle eastern country,middle east,word pair, rhs phrase,variable slot,singular-plural variant,stop word,lexical cor respondences,system,apparatus,rich language resource,method,resource-poor language,gen eral paraphrase pattern,jacquemin,fujita,al2007,ap proaches,variable slot,paraphrase,similarity,pantel,szpektor,context,callison-burch,al2009,instance acquisition given,paraphrase pattern,novel instance,novel paraphrase,monolingual non-parallel corpus,appropriate slot-fillers,expression,element,pattern,stop word,monolingual corpus,pattern,inappropriate pair,legitimacy,slot-filler,expression,variable slot, rhs phrase,pattern,k-tuple,paraphrase,contextual similarity,monolingual corpus,phrase,dissim ilar context,recipe,threshold value,experiment,contextual similarity,antonym,cousin word,sim ilar context,problem,framework,semantic equivalence,guaran teed,result,corresponding pattern,bilingual parallel corpus,characteristic,different pair,paraphrase,quality,paraphrase,high quality paraphrase,non-equivalent pair,contextual similarity,real paraphrase,section,meth od,high-quality seed,instance,supervised method,hashimoto,al2011,existence,feature,expression,para phrase,many pair,output,high potential,alternative seed,method,advantage,method,labeled data,method,al2009,hashimoto,al2011,4 q uantitative impact,different set,corpus,data source,setting,english para phrase,europarl,english-french version,eu roparl parallel corpus3,sen tence pair,english, 56m word,french,bilingual par allel corpus,english side,en glish side,french-english corpus4 consisting,sentence,monolingual data,patent,japanese-english patent translation data,sen tence pair,morpheme,106mwords,english,bilingual parallel corpus,english side,sentence,chapter, ntc ir,patent document,monolingual data,behavior,method,different amount,bilingual parallel data,curve experiment,in-house tokenizer,segmentation,english,french sentence,japanese sentence,statmt,org europarl,statmt,org wmt10 training-giga-fren,sourceforge,version,pa rap hra se pai r,english side,bilingual corpus prawpraw,pa rap hra se pai r,english side,bilingual corpus prawpraw,paraphrase pair,europarl,translation pair,paraphrase pair,english word,french word,japanese morpheme,bilingual parallel corpus,translation ta ble,sentence pair,maximum phrase length,translation pair,significance,technique,johnson,threshold,contextual feature,similarity,paraphrase pair,4-grams,occurrence,phrase,compromise,expen sive,approach,bag-of-words,accurate,expensive approach,syntactic feature,pantel,shinyama,al2002,al2003,szpektor,ontextual similarity,cosine,fea ture vector,statistic,number,paraphrase pair,bilingual parallel corpus,general trend,cor pu,paraphrase,initial set,technique,large por tion,europarl,patent,similarity,statmt,org moses,alignwords,useless pair,figure,result,widely-used threshold value,conditional prob ability,denkowski,percentage,paraphrase pair,corpus size,europarl,patent,threshold value,corpus,following experiment,convention thp,quality,paraphrase pattern,result,cor rect paraphrase pair,control apparatus,device,figure,paraphrase pattern figure,number,paraphrase pattern,method,cover age,rigid form,pattern,europarl,contrast,propor tion,patent,pattern,patent domain con,many expression,technical term,similar variation,construction,pattern,one-variable pattern,total pattern,different variant,europarl,patent,one-variable pattern,variable pattern,forth focus,complex pattern,two-variable pattern,setting,future work,pa rap hra se pat tern,english side,bilingual corpus,patent,patent,europarl,europarl,figure,paraphrase pattern,english side,bilingual corpus,patent,patent,europarl,europarl,figure,coverage,paraphrase,pa rap hra se pai r un iqu e l h ph ra e,english side,bilingual corpus pair,phvstlhs,phvstpair,pseedlhs,pa rap hra se pai r un iqu e l h ph ra e,english side,bilingual corpus pair,phvstlhs,phvstpair,pseedlhs,paraphrase pair,unique  lhs phrase,europarl,paraphrase pattern,novel paraphrase pair,monolingual non-parallel corpus,experiment,one-variable pattern,sin gle word,slot-fillers,large number,paraphrase pair,figure,similarity,instance,full size,bilingual parallel corpus,patent,seed paraphrase,novel paraphrase,method,number,unique  lhs phrase,phvst cover,highlight,large ratio,number,paraphrase pair,number,unique  lhs phrase,bilingual corpus,small amount,europarl data,method,minimum amount,difference,average number, rhs phrase,relative yield,figure,bilingual cor pu,alignment-based method,bilingual corpus,many  rhs phrase,unique lhs phrase,reliance,conditional prob ability,surface level processing,con trast,method,number, rhs phrase, rhs phrase,similarity,corresponding  lhs phrase,limitation,method,high yield,small num ber,paraphrase pattern,bilingual corpus,relative yield,monolingual corpus,instance,patent,monolingual document,experiment, ntc ir project7,relative gain,in-domain versus general-purpose corpus,ra tio,st o p se ed,english side,bilingual corpus lhs,patent,europarl,europarl,figure, rh hra s,english side,bilingual corpus phvst,patent,patent,europarl,europarl,figure,average, rhs phrase, lhs phrase,pa rap hra se pai r probability,thp phvst,patent,patent,europarl,europarl,pa rap hra se pai r similarity,th phvst,patent,patent,europarl,europarl,paraphrase pair,threshold value,number,para phrase pair varies,conditional probabil ity,contextual similarity,figure,result,full size,bilingual corpus,number,paraphrase pair,increase,threshold value,benefit,generalization,instantiation method,paraphrase pattern,paraphrase pair,proba bility,threshold value,novel paraphrase,result,individual paraphrase pair,contextual similar ity,many pair,incorrect instance,corresponding pattern,threshold value,many pair,similarity,quality,translation,5 h uman evaluation,quality,quality,substitution test,sub-sentential paraphrase,sentence,test corpus,different sentence,instance,roof look,prehistoric lizard,prehistoric lizard,human evaluator,original sentence,paraphrased sen tence,5-point scale grade,callison-burch,paraphrased sen tence,meaning,meaning,original sen tence,result,human labor,evaluator,time several paraphrase,source phrase,instance,evaluator,following sentence,addition,prehistoric lizard,roofwould look,prehistoric lizard,experiment,paraphrase,source phrase,evaluator,number,paraphrase candidate,evaluation,previous work,callison-burch,al2011,paraphrase,europarl corpus,news sentence,para phrase example,english part  ofw mt,unique sentence,europarl,para phrase,paraphrase,patent document,following reason,general area,news sentence,in-domain evaluation,domain expert,para phrase,domain,domain,nevertheless,circum,domain,interesting research question,human labor,evaluation,sen tences,moderate length,10-30 word,suf ficient,succinct context,multiple paraphrase candidate,stricted phrase,paraphrase,paraphrase,phrase token,unique phrase token,unique paraphrase,phrase token,example,people,high level,english proficiency,inter-evaluator agreement,different pair,evaluator,example,exam ples,unequal length,evaluator,5-point binary n g  m g  m b,precision,binary classification,result table,average,original 5-point scale score,percentage,example,binary judgment,callison-burch,example,grammaticality score,meaning score,paraphrase,high performance,effectiveness,tech niques,performance,paraphrase,grammaticality,meaning,callison burch,evaluator,high-level command,english,agreement,binary class,crite rion,agreement,criterion,low either8,promising way,qual ity,paraphrase pattern,legitimate paraphrase,scored paraphrase ex amples,threshold,seed para phrase,conditional probability e,bilingual parallel corpus,contextual similarity,monolingual non parallel corpus,figure,average score,example,paraphrase,threshold value,figure,threshold value,others,number,callison-burch,chance agreement,distribution,human score,cor es imilarity,paraphrase example,threshold value,threshold value,others,number,scored example,filtering,threshold value,better-quality set,instance,large threshold value,significant,kendall,contextual similarity,human score,grammaticality,meaning,result,accurate filtering,6 c onclusion,general pattern,paraphrase,large number,high-quality paraphrase pair,bilingual parallel,monolingual non-parallel cor pora,experiment,corpus demon,method,informa tion,small bilingual parallel corpus,large amount,information,large monolingual non-parallel corpus,hu man evaluation,paraphrase substitution test,paraphrase,reasonable quality,original objective,monolingual corpus,large quantity,paraphrase,quality,paraphrase,bilingual parallel corpus,quantity part,objective,quality part,main direction,future work,in-depth anal y,method,instance,performance,phrase substi tution,noisy seed paraphrase,quan tity,investigate similarity metric,future work,interesting question,section,exploitation,pattern,curve experiment,dif ferent amount,monolingual data,compari son,general-purpose monolingual corpus,interest,sophisticated paraphrase pattern,instance,pattern,lexical resource,developed paraphrase col lection,application,sentence compression,lapata,ganitkevitch,al2011,machine translation,callison-burch et al2006,marton,colleague,national research council canada,george foster,eric joanis,samuel larkin,technical support,first author, a j sps ,japan society,promotion,science,post doctoral fellow,research abroad,reference colin bannard,chris callison-burch,bilingual parallel corpus,proceed ings,annual meeting,association,regina barzilay,kathleen,paraphrase,parallel corpus,pro ceedings,annual meeting,association,regina barzilay,lillian lee,unsupervised approach,multiple sequence alignment,proceeding,hu man language technology conference,north american chapter,association,rahul bhagat,deepak ravichandran,scale acquisition,paraphrase,surface pattern,proceeding,annual meeting,association,chris callison-burch,philipp koehn,mile o borne,statistical machine translation,paraphrase,proceeding,human lan guage technology conference,north american chapter,association,chris callison-burch,syntactic constraint,paraphrase,parallel corpus,pro ceedings,conference,empirical meth od,tsz ping chan,chris callison-burch,benjamin van durme,para phrase,monolingual distributional similarity,proceeding,workshop,geometrical model,william,parallel data,paraphrase evaluation,pro ceedings,annual meeting,association,jacob cohen,coefficient,agreement,nom inal scale,educational,psychological measure ment,trevor cohn,mirella lapata,sentence com pression,word deletion,proceeding,international conference,michael denkowski,alon lavie,meteor,reliable optimization,evalua tion,machine translation system,proceeding,workshop,bill dolan,chris quirk,chris brockett,construction,large paraphrase cor pora,exploiting,parallel news source,proceeding,20th international conference,andy way,translation,source language paraphrase lattice,proceeding,conference,empirical method,atsushi fujii,masao utiyama,mikio yamamoto,take hito utsuro,terumasa ehara,hiroshi echizen-ya,sayori shimohata,overview,patent translation task, ntc ir-8 workshop,pro ceedings, ntc ir-8 workshop meeting,atsushi fujita,shuhei kato,naoki kato,satoshi sato,compositional approach,dy namic phrasal thesaurus,proceeding, acl -pa scal workshop,textual entailment,juri ganitkevitch,chris callison-burch,courtney napoles,benjamin van durme,sentential paraphrase,bilingual parallel cor pora,text-to-text generation,proceeding,conference,empirical method,zellig harris,mathematical structure,lan guage,chikara hashimoto,kentaro torisawa,stijn de saeger,ichi kazama,sadao kurohashi,paraphrase,definition sentence,proceeding,annual meeting,association,christian jacquemin,paradig matic representation,term variation,proceed ings,annual meeting,association,howard johnson,joel martin,george foster,roland kuhn,translation quality,proceeding,conference,empirical method,nat ural language processing,maurice kendall,new measure,rank correla tion,biometrika,philipp koehn,franz josef och,daniel marcu,statistical phrase-based translation,proceed ings,human language technology con ference,north american chapter,ciation,philipp koehn,statistical machine translation,cambridge university press,stanley kok,chris brockett,right paraphrase,good time,proceeding,human language technology,annual conference,north american chapter,association,dekang lin,patrick pantel,discovery,infer ence rule,question answering,nitin madnani,bonnie,phrasal,sentential paraphrase,survey,data-driven method,computational linguistics,yuval marton,chris callison-burch,philip resnik,statistical machine translation,monolingually-derived paraphrase,proceeding,conference,empirical method,yuval marton,ahmed el kholy,nizar habash,polarity-dissimilar distributional paraphrase,statistical machine translation,proceeding,workshop,lien max,example-based paraphrasing,improved phrase-based statistical machine translation,proceeding,conference,empirical method,marius pa,dienes,needle,haystack,paraphrase acquisition,proceeding,international joint con ference,bo pang,kevin knight,daniel marcu,syntax-based alignment,multiple translation,paraphrase,new sentence,proceeding,human language technol ogy conference,north american chapter,association,fatiha sadat,howard johnson,akakpo agbago,george foster,roland kuhn,joel martin,aaron tikuisis,proceeding, acl workshop,building,using parallel text,yusuke shinyama,satoshi sekine,kiyoshi sudo,ralph grishman,automatic paraphrase acqui sition,news article,proceeding,ido dagan,entail ment rule,unary template,proceeding,international conference,sander wubben,antal van den bosch,emiel krahmer,erwin marsi,headline,automatic paraphrase acquisition,proceeding,european workshop,nat ural language generation,shiqi zhao,haifeng wang,ting liu,paraphrase pattern,bilin gual parallel corpus,natural language engineering,proceeding, naa cl-hlt,atlanta,georgia,association,computational linguistics adaptation,reordering model,statistical machine translation boxing chen,george foster,roland kuhn national research council canada,abstract previous research,knowledge,previous work,adaptation,phrase,mixture model adaptation,lexical ized rm,formance,system,domain-adapted tm,corpus,reordering character istics,particular phrase pair,particular training corpus,unsuit,vice versa,mix ture weight,additional contribution,improvement,model adaptation,in-domain sample,instance,document frequency,experiment,technique,yield significant perfor mance improvement,1 i ntroduction,system,main component,information,word sequence,phrase,source language,target language,information,probable word sequence,target lan guage,source sentence,target sentence,parallel data,target-language data,language,translation practice differs,di alects,particular author,publication,domain,particular combination,fac tor,perfect match,training data domain,domain, smt system,bet ter performance,system,test domain,offline domain adaptation,system,sample,translated sentence,test domain,deployment,popular variant,offline adaptation,linear mixture model adaptation,training corpus,separate model component,linear combination,sample,weight,component,foster,sample,corpus,others,corpus,weight,combination,previous research,domain adaptation,translation,domain,example,chinese translation,english word,animal,computer hardware,translation,trans lation,people,taiwan,computer hardware,translation,lm adaptation,contrast,rm model adaptation, smt performace,behaviour,particular language pair,particular domain,instance,chinese,arabic,certain word,english translation,long-distance movement,original position,others,original position,particular chinese adverb,particular arabic noun,long-distance movement,english,domain,others,section,rm adaptation,performance,phrase-based  smt system,implementation,linear mixture model,rm adaptation,effective rm adaptation,in-domain sample,orienta tion count,document frequency,phrase pair,improvement,rm adaptation,fac tor,behaviour,phrase,differs,bilingual corpus,second,corpus,instance,comparable corpus,bilin gual lexicon,formation,poor source,formation,corpus,overall quality,early  smt system,change,word order,sentence,penalty,decoder,next source phrase,phrase,source sen tence,system penalizes deviation,monotone order,magnitude,penalty,source sentence,source phrase,source phrase,many  smt system,distance-based penalty,feature,tillmann,sophisticated type,reorder,consistent performance gain,possible orientation,source phrase,orientation,phrase,phrase,source sentence,orientation,new phrase,pre vious phrase,orientation,estimated probability,source language,target-language word,pre vious phrase pair,galley,manning,individual phrase pair,contiguous se quence,phrase pair,phrase pair consistency requirement,external link,classification,orientation,phrase,decoder,possible source phrase,po sible source phrase,future,lex icalized,probability,ori entation,respect,previous phrase pair,following phrase pair,distri butions,rientation count,word-aligned corpus,method,ome researcher,right version,orientation,4-orientation scheme,significant gain,3-orientation one,cherry,probability,recursive map,parameter,perplexity,held-out data,orientation,respect,previous context,shift-reduce parser,orientation,respect,context,coverage vector,cherry,3 r m ad aptation,previous work,foster,foster,linear mixture model technique,rm adaptation,technique,separate model,training corpus,weight,weighted component model,single model,sub-corpora,global reordering model probability,sub-corpus,weight,foster,em algorithm,weight,probability,phrase-pair orientation,devel opment,empirical distribution,dev set,separate set,weight,distribution,respect,previous phrase pair,next phrase pair,development,equation,domain development set,dev set, smt system,sentence,smoothed conditional distribution, map technique,multiply,joint distribution,nothing,statistic,mixture tm,over-fitting,over-fitting problem,phrase pair,cate gories,document-frequency weighting mixture model,existence,multiple training corpus,domain,recent paper,phrase pair,general language,others,foster,phrase pair,training corpus,general language,training corpus,information,domain-specificity,estima tion,mixture rm weight,intuition,phrase pair,general language,sub-corpus weight,behaviour,domain,intuition,empirical distribution,following factor,number,smoothing term,corpus segs,tok genre,nw financial  90k,financial gale bc,bc gale bn,bn ng gale nw,nw gale wl,wl hkh,hansard,legal hkn,nw isi,nw lex ne,lexicon others,nw sinorama,nw wl nis t06,nw bn ng nis t08,nw wl table,column,united nation proceeding,experiment,different setting, nis t op,us data,chinese,en glish,english token,sub-corpora,origin,statistic,training corpus,development,test set,training corpus,number,percentage,training data,training cor pora consist,parallel sentence pair,lex ne corpus,exception,comparable data,latter,lexicon,entity,velopment,evaluation, nis corpus,gov itl iad mig openmt12,cfm corpus segs,toks genre gale bc,bc gale bn,bn gale ng,ng gale nw,nw gale wl,wl isi,nw tot al,nis t06,nw wl nis t08,nw wl nis t09,nw wl table,column,second setting,arabic,en glish data,un data,training data,training data,origin,statistic,training corpus,development,test set,language pair,comparable isi data,large proportion,training data,english word,evaluation set,devel opment,test set,system experiment,in-house phrase-based system,phrase table,phrase pair,sepa rate alignment,length limit,trans lation model,direction,ing term,equation,optimization,distortion limit,feature,lexical weighting,direction,word count,gram lm,target side,parallel data,6-gram english gigaword,baseline loglin,result,variant,rm adaptation,system chinese arabic lm tm adaptation,baseline con,batch lattice,cherry,foster,result,main baseline,training data,separate log-linear feature,corpus-specific rms,case-insensitvie ibm  ble u-4,papineni,ble score,test set,follow ing,bootstrap-resampling test,significance,significant gain,baseline,model adaptation,data setting,document frequency weighting,equation,dev-set smooth ing,improvement,technique,significant improvement,second experiment,improve ment,rm adaptation,baseline,adapted lm,technique,linear mixture,em-tuned weight,strong base line,language pair,improvement,arabic,third experiment break,last line,individual adapted model,lm adaptation,tm adaptation,comparison,rm adaptation,improvement,arabic,tm adaptation,chinese,method,lm adaptation,significant gain,baseline,5 a nalysis,rm adaptation work,behaviour,phrase pair,domain,rm adaptation pointless,no-one,section,factor,observed gain,weighting,corpus quality,answer,question,cor pora,training rms,others,fur thermore,corpus,vice versa,illustrate,weight,rm mixture model,weight,isi sub-corpus,par ticular exhibit,striking pattern,lm mixture,moderate,tm mixture,rm mixture,english word,arabic training data,weight,rm mixture,reflection,sign weight,isi corpus,comparable data,sentence pair,sourceand target-language side,mutual translation,valuable source,in-domain n-grams,noisy source,in-domain phrase pair,unreliable source,re-ordering pattern,chinese-english sub-corpora,rm mixture model,arabic-english sub-corpora,rm mixture model,mixture weight,comparable data,misleading impression,phrase,chinese source,english,reference translation,chinese source,comparable data,phrase,certain corpus,information,quality corpus,weight,optimal weight,corpus,optimal weight,domain match,rm adaptation,poor-quality data,rm adaptation,american list,tariff,retaliation,chinese,unreasonable demand,american,protection,intellectual property right,  f igure,example,sentence pair,comparable data,underlined word,number,trans lations,corpus  m s  d c ount,gale bc,gale bn,gale nw,gale wl,others,sinorama,orientation frequency,respect,previous phrase,considers,high-quality data,training rms,comparable data,differ ences,behaviour,difference,word frequency,domain,domain-dependent difference,phrase pair,example,various corpus,strong difference,behaviour,hong kong,corpus,instance fbi,corpus  m s  d c,gale bn,gale ng,gale nw,gale wl,orientation frequency,phrase pair,work  ale ml,respect,previous phrase,hong kong corpus,probability,proba bility,phrase pair,corpus,disparity,chance,behaviour,phrase pair,work  ale ml,different sub-corpora,chinese example,sig nificant difference,pattern,cer tain corpus,instance,gale bc swap,attested phrase pair,probability,gale ng,probability,behaviour,theory,mandarin chi,single language,spoken form,language,cantonese,hokkien,shanghainese,practice,many speaker,mandarin,language,language,influence,people,teract,word order,mandarin,mainland china,hong kong,taiwan,different word order,hong kong mandarin,cantonese,taiwan mandarin,hokkien,instance,adverb,mandarin,standard word order,cantonese,verb ad verb,common word order,speaker,writer,mandarin,hong kong,represent,arabic word  ale ml,buckwalter transliteration, f igure,example,different word ordering,different area,verb adverb,language,figure,different word order,mandarin source affect,en glish,situation,element,dialect adaptation,ea ger,hypothesis,arabic,different di alects,arabic,dialect,mandarin,reordering,difference,arabic training,dialect,rm adaptation,el ement,genre adaptation,hypothesis,corpus-dependent reorder ing pattern,particular phrase pair,performance improvement,rm adaptation,experiment,highly-specific phrase pair,section,strategy,high document-frequency,phrase,influence,weight,artifact,implementation,similar strategy,probability,phrase pair,prob ability,orientation,phrase pair,particular sub-corpus,example,sub-corpus iwill,probability,mixture model,penalty,sub-corpora,low mixture weight,resulting mixture model,global distribution,equation,large drop,performance,instance,arabic  ble score,original strategy,instance weighting,similar strategy,phrase pair,result,penalty,work domain adaptation,active topic, nlp re search community,application,system,considerable attention,previ ous work, smt adaptation,adaptation,approach, smt model adaptation,mixture model,transductive learning,data selection,data weighting,phrase sense disambiguation,research,mixture model,log-linear mixture,foster,approach,sub-models,instance,several different tm,several different lm,different type,instance,mixture tm,schroeder,sub-models, smt log-linear frame work,transductive learning,mt system,general domain data,in-domain monolingual data,bilingual sentence pair,additional training data,schwenk,bertoldi,federico,axelrod,search,bilingual sentence pair,in-domain,training data,selection criterion,matsoukas,foster,phillips,sennrich,rich feature,weight,train ing data,sentence,phrase pair level,instance,sentence,corpus,domain,low weight,sentence,corpus,general nature,weight, jhu workshop,domain adapta tion,translation model adaptation,ap proach,context,phrase,system,appropriate translation,adaptation,7 c onclusions, smt system,domain,system,mixture model approach,domain adaptation, smt system,knowledge,first attempt,literature,experiment,tation,translation quality,system,lm adap tation,modifica tions,mixture model adaptation,smoothing,orientation count,document frequency,phrase pair,lm adaptation,smoothing,performance,rm adaptation,rm adaptation, smt performance,factor,information,corpus,com parable corpus,dialect genre effect,implicit instance weighting,edu workshop,reference amittai axelrod,jianfeng gao,adaptation,pseudo in-domain data selec tion, emn lp,nicola bertoldi,marcello federico,main adaptation,statistical machine translation,monolingual resource,proceeding,workshop,statistical machine translation,athens,boxing chen,min zhang,n-best hypothesis,smt self enhancement,roland kuhn,george foster,howard johnson,feature function,new way,phrase table,mt summit,colin cherry,george foster,tun ing strategy,statistical machine translation,naa cl,colin cherry,robert,chris quirk,hierarchical re-ordering,permutation parsing,phrase-based decoding,george foster,roland kuhn,mixture-model adaptation,proceeding, acl work shop,statistical machine translation,prague,george foster,cyril goutte,roland kuhn,discriminative instance,domain adapta tion,statistical machine translation,proceeding,conference,empirical method,boston,michel galley,effective hierarchical phrase,emn lp,hawaii,october,fei huang,bing xiang,feature-rich discrimi native phrase, col ing ,philipp koehn,josh schroeder,experiment,domain adaptation,statistical machine transla tion,proceeding,second workshop,sta tistical machine translation,prague,czech republic,association,edin burgh system description, nis t mt eval uation,proceeding,herbst,open source toolkit,statistical machine translation,demon stration session,philipp koehn,pharaoh,beam search decoder,phrase-based statistical machine translation mod el,proceeding,conference,sociation,machine translation,america,georgetown university,springer-verlag,jin huang,qun liu,statistical machine translation performance,data selection,optimization,proceeding,conference,empirical method,prague,czech republic,spyros matsoukas,antti-veikko,bing zhang,discriminative corpus,estima tion,machine translation,proceeding,conference,empirical method,singapore,robert,william lewis,intelligent selection,language model training data,kishore papineni,salim roukos,todd ward,wei jing zhu,method,automatic eval uation,machine translation,proceeding,40th annual meeting,association,philadel phia,phillips,machine translation,second-order taylor approx imation,weighted translation instance,mt sum mit,holger schwenk,investigation,large scale lightly-supervised training,statistical machine translation, iws lt,rico sennrich,unsuper vised cluster,domain adaptation,statistical ma chine translation,christoph tillmann,tong zhang,localized prediction model,statistical machine translation,proceeding,annual meeting,asso ciation,ar bor,michigan,nicola ueffing,gholamreza haffari,anoop sarkar,statistical machine translation,proceeding,45th annual meet ing,association,czech republic,bing zhao,matthias eck,stephan vogel,model adaptation,statistical machine translation,structured query model,proceed ings,international conference,geneva,august,proceeding,annual meeting,association,computational linguistics,uppsala,sweden,association,computational linguistics bilingual sense similarity,statistical machine translation  b,george foster,roland kuhn national research council canada,alexandre-tach,boulevard,george,foster,roland,kuhn nrc,bstract,new algorithm,sense similarity,phrase,parallel cor pora,sense similarity score,algorithm,statistical machine trans lation,sense similarity,source,translation rule pair,similarity score,addi tional feature,translation model,prove translation performance,significant im provements,state-of-the-art hierarchical phrase-based machine translation system,ntroduction,context,underlying idea,context,distribu tional hypothesis,harris,similar context,similar mean ings,sense similarity,distribution,corpus,hindle,burgess,landauer,dumais,turney,pantel,lapata,common procedure,various feature,context,corpus,similarity,similarity function,fea tures,surface window,fixed size,burgess,grammati cal dependency,pantel,lapata,ty function,cosine distance,salton, mcg ill,similarity function,bullinaria,jaccard coefficient,frakes,baeza-yates,measure,monolin gual sense similarity,many application,synonym,dumais,word sense disambigua tion,yatbaz,vector space model,sense similarity,mul tilingual condition,assumption,similar meaning,comparable context,language,application,translation pair,unrelated corpus,vec tor,different language,common space,initial bilingual dictio,previous work,sense similarity,parallel corpus,translation probability,parallel corpus,co-occurrence count,question,sense similarity,parallel corpus,multi lingual application,question,sense similarity, smt task,translation rule,word-aligned sentence pair,training cor pu,wrong word alignment,source,target side,real example,rule table,training data,section,many hong kong resident,source,target side,semantic similar ity,context,source,target side,new algorithm,sense similarity,phrase,different language,source,target side,translation rule,statistical machine translation perfor mance,work attempt,sense similarity,different languag e,contexts1,contribution,new bilingual sense similarity algorithm,machine trans,hierarchical phrase-based  smt system,baseline,computation,sense similarity,hierar chical rule,ierarchical phrase-based mt system,chiang,formal syntax,translation,method,transla tion model,linguistic syn tactic information, sc fg rule,following form,non-terminal symbol,non terminal,source,target,con sisting,non-terminal symbol,one-to-one correspondence,non-terminals,detail,section,technique,translation selection,source-side context,particular translation,source rule,source target ini,meeting rule,context,meeting rule,context,context,meeting,context,meeting  f igure,example,hierarchical rule pair,context feature, r ule frequency,traction,word-aligned sentence pair,feature,chiang,chiang,fea tures,verse rule-based conditional probability,verse lexical weight,method,performance,language pair,chinese english,phrase-based method,phrase,normal phrase-based model,long-distance reordering,chiang,chiang,joshua implementation,method,3 b ag-of-words vector space model,sense similarity,previous work,source,feature vector,feature,context word,co-occurs,translation rule,context feature,hierarchical phrase-based translation,translation rule,non terminal,source,instance,particular phrase pair,training corpus,context,non-terminals,context,sub-phrases,non-terminals,remainder,phrase pair,example,figure,meeting,initial phrase,meeting,meeting,meeting,context feature,tar get,context feature,meeting,context feature,meeting,meeting,context feature,source-side context feature,bag-of-words model,translation rule pair,context word,training data,bags-of-words,consist,col lections,source,target context word,source,target side,source context word,source side,target context word,target side,source,target side,vector fv,source,target context feature,cor responding bag,feature weighting scheme,pointwise mutual information,church,feature value,context word,frequency count,co-occurring,context word,total frequency count,context word,weight,turney,estimate,em pirical probability,towards infrequent word feature,add-k smoothing, kr cf kcrf kcrf kcrf crw,tunable global smoothing,number,imilarity function,many possibility,simi larities,bags-of-words,different lan guages, ibm model,probability,cosine distance similarity function, ibm model  1 p robabilities, ibm model,similarity function,geometric mean,bag probabili tie,source word,combina tion,performance,standard  ibm model,probability,bfpbfp,probability,translation, ibm model,probability,vector space,common way,semantic similarity,vector space cosine distance,similarity function,vector,different word,different lan guages,dimension,vector,vec tor,similarity,vector,dimension-to-one-dimension,context word,dimension,vector space,lan guage,language,initial bilingual dictionary,vector space mapping,  o ur goal,source pattern,tar get pattern,vector,target language,vector space,source language,representa tion av,source language space,weight,ith source feature,linear combination,target feature,source feature weight,target feature weight,probability,transformed vector,target vector,weight,lexical probability, ib model,source vec tor,mapped vector av,di mensions,cosine distance similarity,standard cosine distance,inner product,vector,similarity,ij ejif af,number,source,bag-of-words,source,target feature,transformed weight,target fea tures,source dimension,improved similarity function,information,origi nal similarity function,bm model,proba bilities,cosine distance similarity function,similarity function,new algo rithm,figure,fullec,context,definition,section,full training data,coocfc,coocec,context,co-occur,constraint,fullf cooc f c,original similarity function,context vector,full training data,new similarity function,full cooc cooc cooc,full f c csimccsimccsim,parameter, f igure,context,context,whole training data,dif ferent sens,whole training data,language,sense pool,full fc coocfc full ec coocec,subset,whole sense,coocffullf ccsim,similarity,whole sense pool,sense pool,co-occurs,coocefulle ccsim,analogous similarity,metric,similarity,vec tor,language,cosine dis tance,similarity,straightfor ward,large size,vector,vector mapping,vector,coocecoocf ccsim,similarity,context vector,co-occur, ibm model,probability,cosine distance similari ty function,therefore,degree,bilingual semantic simi larity,source,target translation unit,monolingual semantic similarity,occurrence,source,target unit,occurrence,sense similarity measure,5 e xperiments,algorithm,bilingual sense si milarity,machine translation,sense simi larity score,feature function,translation model,different language pair,chinese-to-english task,ex periments,data condition,first one,large data condition,training data,evaluation chinese-to english track,bilin gual corpus,un corpus,hong kong hansard corpus,translation model,second one,small data condition, fbi s3 corpus,translation model,language model,first one,gram lm,target side,large data condition,second lm,5-gram lm,gov speech test, ld c2003e14,english gigaword corpus,language model,experiment,chinese,develop ment,test set,data condition,development set, ni st,material,evaluation,test set,figure,training,development,number,sentence,number,reference,test set,hi eng  p,   d ev,test  nis t06, ni st08,gigaword,statistic,training,chinese-to-english task,german-to-english task,data set,parallel training data con,target word,dev set,test set contain,sentence,refer ence,target-language half,parallel training data,language model,result,baseline,translation model,chiang,chiang,decoder,joshua5,open-source hierar chical phrase-based machine translation system,evaluation, ibm  bl eu,papineni,case-insensitive matching,bootstrap,result,addi tional experiment,smoothing constant,vector,computing time,translation,statmt,org wmt06,ccb joshua index,top context word,feature value,original similarity function,context vector,full training data,improved similarity, ibm model,probability,series,additional expe riments,small data condition,observ,result,vector,fullfc,fullec n1,coocfc,coocec n2,vector,following process,performance,performance,setting,default,experiment,lgorithm  nis,baseline,alg1  ibm,alg1  cos,alg2  ibm,result,small data chinese-to english  nis task,original simi larity function,improved similarity, ibm model,probability,cosine distance similarity function,result,baseline,  c h-en de-en algorithm  nis,baseline,alg2  ibm,result,large data chinese-to english  nis task,german-to-english  wmt task,additional experiment,stop word,context vector,consistent improvement,context vector,feature,performance,chinese-to-english small data condition,performance,baseline,consistent improvement,improved similarity function alg2,monolingual semantic similarity,bilingual se mantic similarity,accu racy,similarity estimate,performance,baseline,alg2 cosine similarity function,baseline,report,performance,chinese-to-english  nis large data condition,german-to-english  wmt task, ibm model,cosine distance similarity function,significant improvement,test set,similari ty function,comparable result,6 a nalysis,effect,single feature,similarity score,coocefulle ccsim,coocecoocf ccsim, ibm mod,probability,coocecoocfibm ccsim,first study,feature,im pact,result,result,feature,improvement,coocecoocfibm ccsim score,latter,number,con text feature,many rule,extreme exam ple,context word,vector,source,target context fea tures,translation probability,context word,coocecoocfibm ccsim,translation proba bility,context word pair,coocecoocfcos ccsim,coocffullf ccsim,improvement,possible explanation,following example,transliteration,person,translation,different source context,chinese word,synonymous word,rivulet,coocffullf ccsim score,clearly,wrong translation,bad mistake,similar trans lation distribution,system distinguish,monolingual similarity score,ability,alternative,phrase translation,similarity function,alg2 consis,improvement,incorpo rating,monolingual similarity,source,target side,ef fectiveness,algorithm,e_ld  ce_ sd,baseline,alg2  ibm,alg2  cos,result,feature,effect,similari tie,similarity score,feature,improvement,practice,feature,report,result,small data condition,improvement,improvement,test set,performance,extra feature,dev set, a lgorithm dev  nis,baseline,alg2  ibm,alg2  cos,result,combination,similarity score,improvement,test set,comparison,simple contextual feature,question,si milarity feature,function,sim ple feature,additional experiment,small data chinese-to-english task,following feature,context word,proportion,context,context,property,context,ec e n,frequency count,co-occurring,context word, f eature dev  nis,baseline,result,simple feature,context,small data  nis task,im provements,significant effect,test set,show result,system,small data,condition,feature,improvement,significant effect,simple feature,context,context feature,sense similarity,null context feature,context word,definition,con text,section,first case,rule pair,full sentence-pair,training data,second case,rule pair,source,target context,span limit,initial phrase,extract context,chinese-to-english  nis task,context,german-to-english task,number,uniform number,bi lingual sense similarity score,number,null context feature,result,weight,null context feature,experiment,sec tion,penalty,courage,context,alg2  cos,weight,chinese-to english small data task,large data task,german to-english task,discussion,se mantic similarity,bilingual hierarchical rule,several observation,feature,nature,meaning,similarity score,system,result,feature,context word,addition,bilingual similarity,alg2 re,degree,monolingual similarity,source,target unit,ambiguous rule,related mean ings,mechanism,sec tion,synergistic effect,bilingual similarity feature,feature,similarity,con text,instantiation,approach,semantic information,extensive work,semantics,key paper,carpuat,source-language context,translation,hierarchical  smt,recent work,feature, smt log-linear model,gimpel,chiang,co herent set,target word,individual phrase translation,bangalore,applicable rule,translation,source,target context,new ground,mantic role,semantic parser,source,target language,ur work,ap proaches,hierarchical rule,degree,bilingual semantic similarity,source,target translation unit,monolin gual semantic similarity,occurrence,source,translation,current source context,work rate,current context,8 c onclusions,future work,approach,vector space model,similarity,parallel corpus,statistical machine translation,bilingual sense similarity,algorithm,significant improve ments,question,section,sense similarity,parallel corpus,algorithm,multilingual application,bilingual sense similarity,hierarchical phrase-based system,method,syntax-based mt system,phrase-based mt system,difference,definition,context,syntax-based system,context,phrase-based system,context,phrase,sur rounding word,size window,future work,algorithm,syn tax-based mt system,phrase-based mt sys,different context feature,technique,training, smt system,instance,bilingual word alignment,training data,haffner,sta tistical machine translation,global lexi cal selection,sentence reconstruction,machine translation,della pietra,mathematics,statistical machine translation,parameter estimation,com putational linguistics,bullinaria,semantic representation,word co-occurrence statistic,computational study,behavior research thods,carpuat,statistical machine translation,word sense disambig uation, emn lp,carpuat,translation,discourse,  p roceedings, naa cl  hlt workshop,se mantic evaluation,chiang,word sense disambiguation,statistical machine translation,chiang,hierarchical phrase-based model,statistical machine translation,chiang,hierarchical phrase-based transla tion,computational linguistics,knight,new feature,statistical machine translation,word association norm,mutual information,baeza-yates,editor,formation retrieval,data structure,algo rithms,statistical view,bilingual lexicon extraction,parallel corpus,non-parallel corpus,gimenez,marquez,discriminative phrase selection,gimpel,rich source-side context,statistical machine translation,harris,distributional structure,statistical machine translation,lexicalized rule selec tion,hindle,classification,predicate argument structure,statistical phrase,translation,edmonton,statistical significance test,ma chine translation evaluation,barcelona,landauer,solution,problem,latent semantic analysis theory,acquisition,induction,representa tion,knowledge,psychological review,zaidan,joshua,open source toolkit,parsing-based machine translation,athens,automatic retrieval,clustering,similar word,montreal,canada,maximum entropy,rule selection model,syntax,statistical machine translation,proceed ings, emn lp,honolulu,burgess,high dimensional semantic space,lexical co occurrence,behavior research method,instru ments,computer,statistical machine translation,discrimina,trigger-based lexicon model, emn lp,minimum error rate training,statistic al machine translation,lapata,dependency-based con struction,semantic space model,computational linguistics,pantel,word sens, acm  sig kdd co ference,knowledge discovery,data mining,edmonton,method,automatic evaluation,ma chine translation,proceeding,automatic identification,word translation,unrelated english,german corpus,salton,introduction,modern information retrieval,raw-hill,turney, toe fl,twelfth european conference,machine learning,berlin,germany,semantic role,noisy channel model,unsupervised word sense disambigua tion,improvement,phrase,statistical machine translation,proceed ings, naa cl-hlt,waibel,sta tistical machine translation,proceeding,barcelona,proceeding,50th annual meeting,association,computational linguistics,republic,association,computational linguistics por, a p recision-order-recall mt evaluation metric,tuning  b,roland kuhn,samuel larkin national research council canada,alexandre-tach,boulevard,roland,samuel,larkin nrc,evaluation metric,human judgment,principle,metric,system,requirement,linguistic resource,optimization difficulty,new mt evaluation,precision,recall,external resource,correlation,human judgment, bl eu, por t-tuned mt system,u-tuned baseline,experimental condition,language pair,achieves,performance, ble tuning,metric,human evaluation,comparison,output,source sentence,human judge, por t-tuned output,preference,1 i ntroduction automatic evaluation metric,quality,key part,system, po rt,precision-order-recall tunable,comparison,different system,different version,system,tuning,parameter value,system training,latter,invention,related tuning method,method,different system parameter value,evaluation,development,reference translation,evaluation metric,papineni,doddington,lrscore,osborne,external linguistic information,banerjee,eteor-next,denkowski,snover,mterater,parton,limited linguistic resource,synonym dictionary,part-of-speech tagging,word root list,sophisticated metric,semantic analysis,translation,metric,evaluation,metric,human judgment,translation quality,recent  wm t ev aluation task report,callison-burch,callison-burch,reason,evidence,metric yield,mt system, ble tuning,metric,human evaluation,second,similar algorithm,chosen,iu et al, tes la,human judgment,tunable metric,pilot task,callison-burch,osborne,output, lr score-tuned system,versus  bl eu-tuned system,mt system,different combination,statistic,final definition,precision,recall,strict brevity penalty,chiang,strict redundancy penalty,quadratic mean expression,expression,new measure,long-distance,short-distance word,short-distance,later section,experiment,definition,  r esults,human judgment,translation quality,outperforms,respect,tuning,important result,yield system,translation, bl eu,automatic metric,human judgment,data condition,language pair, por first,n-gram precision,whole text,multiple reference,closest reference length,translation hypothesis,number,reference, ble  bl eu,geometric average,n-gram precision,brevity penalty,translation length len,reference length,tlenrlenebp, por  po rt,component,precision,recall,strict brevity penalty,chiang,strict redundancy penalty,ordering measure,design,exhaustive experiment,development data set,rationale,choice, po rt,reconsiders,design decision,average precision,average recall, po rt,arithmetic average,n-gram precision,penalty,short mt output,chiang,translation,input sentence,reference,recall,method,equality,quadratic mean,precision,recall,measure word ordering measure,permutation,original source-language word sequence,permutation,sequence,mt output,permutation,measure,mt evaluation metric,osborne,distance,kendall,metric lrscore,version, lr score,isozaki,distance,metric,permutation,word alignment,word alignment,source input,reference,beforehand,default setting,word alignment,source input,translation,decoder,word alignment,permutation,relation,null relation,word alignment,forbidden type,relation,osborne,one-to many alignment,single source word,first target word,many-to-one alignment,monotone order,target word,source word,target word position,previous source word,target position,  a fter,normalization,permutation,p1 reference,p2 hypothesis,np2  h,integer,position,first word,7th source word,metric,distance measure, ppp pdist,ppd ist,similarity,permutation,spearman,punishes long-distance reordering,instance,movement,example,  r ef,paris hyp, hmm word alignment,second distance measure,jump width,sequence,long distance,internal order,following,jump width punishment,winter,paris hyp,winter,second distance measure,ppppppdist,similar permutation,ordering measure v,harmonic mean,segment level,multiple reference,segment level,similarity,document level,weighted arithmetic mean,number,segment,document,length,reference,metric finally,measure,free parameter,importance,ordering measure,experiment,chinese-english data,language pair,word alignment information,3 e xperiments,evaluation metric,evaluation, wm data,english-to-all submission,language,test set statistic, po rt,source-target word alignment,reference,mt output, wmt data,spearman,rank correlation coefficient,correlation,system level human judgment,translation,human judgment score,translation,system,system,callison burch, po rt,ranking,human one,segment level,callison-burch,kendall,rank correlation coefficient,mteval-v13a, met eor , por perform matching, s et year lang,system sent-pair test1,statistic, wmt dev,test set,etric into-en out-of-en sys, me teor, po rt,correlation,human judgment, wmt  p ort ,segment level correlation,human judgment,english,english,performance,evaluation,system,performance,possible reason, met eor  v1,system level, wm submission,language pair,similar word order,factor, po rt,big role,source-target word alignment,reference,test set,alignment, gi za model, a m etric,first set,experiment,data condition,small data condition, fbi s2,translation,reordering model,target word,4-gram lm,target side,large data condition,gram lm,english gigaword,large data condition, ni st3,bilingual corpus,hong kong hansard,translation model,reordering model,target word,large data,small data,development,test set,dev set, ni st,evaluation, ni st,reference,test set,third data condition,canadian hansard data,word token,loglinear combination,4-gram  lm,target side,parallel training data,english gigaword 5-gram  lm,dev set,sentence,test set,sentence,reference,test set,fifth condition,german --e nglish europarl data,parallel corpus,german token,english token,german-to-english,english-to-german,condition,target side,parallel training data,english gigaword,dev set,news test,test set,reference,test set, ld c2003e14,gov speech test,experiment,lowercase european-language text, mos e,decoder,lexicalized reordering,translation model,language model,phrase penalty,  t uning,n-best  mer, mos e,tuning experiment,case matching,experiment,version, bl eu,chiang,baseline,result,original  ibm  ble,result,original  ibm  ble,automatic metric first, por t-tuning yield system,different translation,first row,percentage,identical sentence output,test data,second row,similarity,output,word level, 1-t er,type give system,output,word level,contrast,output word,fr-en differ,small zh-en large fr-en han de-en  wm en-de  wm,similarity, por t-tuned system output,test data,ask  t une evaluation metric, bl eu  mtr  1-t er  por,small  bl eu  po rt,zh-en large  bl eu  po rt,fr-en han,eu  po rt,de-en  wm  bl eu  po rt,en-de  wm  bl eu  po rt,automatic evaluation score,test data,result,baseline,show translation quality, ble uand  po rt-tuned system,automatic metric,new metric  por, 1-t er,metric,quality,average,relevant test set,twenty comparison,french english,twelve case,fr-en output,fr-en result,others,striking advantage, ble tuning,possible score,system,translation,metric,appear,chinese-to-english task, ble score, ble tuning,significance, bl eu score,chinese english,internal test,systematic difference,dev-set  bl eu,emphasis,yield model,language pair,human evaluation,output, bl euand  por t-tuned system,example,condition,condition,english-to-german,pairwise comparison,translation,system,callison-burch,example,reference,output, po rt-tuned system,evaluator,colleague,bad translation,human evaluation,metric,condition,example, bl eu-tuned output, ble output, por t-tuned output, por output,condition,example,manual evaluation,subset,sentence,first subset,common set,subset,separate file,common set,evaluator,example,unique example,example,evaluator,example, por t-tuned output,fleiss,common set,inter-annotator agreement,annotator,i-th annotator,annotator,answer,everybody,annotator,evaluator,common set,pairwise comparison,evaluator,output,system,output,preference,human preference,output,system, ble u-tuned system,significance level,people,advantage, ble tuning,translation task,language pair, po rt tuning,french-english tuning,difference,example,condition,system,human evaluation easier,result,possible factor,long distance,english,french,similar word order,language pair,result,section,version,factor,  p ort  win  ble,equal total zh-en,fr-en han,de-en  wm,human preference,output,advantage,100-best hypothesis,data condition,similar implementation,average time,iteration,model loading, me rt4,tuning,100-best hypothesis,average time,iteration,minute,word alignment error,word alignment,quality,word alignment,source,reference,chinese tree bank,experiment,cluster,average time,iteration,queuing,bracketed time,reference,sentence,target word,reference,automatic word alignment, giz word alignment,dev set,condition,alignment,gold standard  ctb,baseline,differs,table  4 b leu  baseline,dev set, t une  ble u mtr  1-ter  por  bl eu,fr-en han,impact,measure,analysis,detail,detail,ordering measure help,performance,ordering measure,automatic score,european language pair,chinese-english,influence,measure,european pair,similar word order,  m easure,chinese-english tuning,result,language pair,measure,partial answer,human word alignment,original definition, t une  ble u meteor  1-t er  bl eu, po rt, po rt, po rt,comparison,ordering measure,replacing,ask  t une, ni st08  ble  po rt, ct b bleu  po rt,test set, a related question,much word,improvement,chinese-english word,measure,permutation,section,measure,effect,measure,zh-en large condition,reference alignment, nis t06, nis t08 reference alignment,implies output,reference, por t-tuned system,word order, ble u-tuned system,combination,test set,measure,advantage, por tuning,reliable test set,hand-aligned  ctb data,impact,strict redundancy penalty,ordering measure,number,number,translation,system,similar number,qmean-tuned system,translation, ble u-tuned system,qmean-trained system,reference,qmean translation,precision,strict redundancy penalty,outlier,output,similar n-gram statistic,ask tune 1-gram 4-gram bp,small  bl eu qmean,zh-en large  bl eu qmean,fr-en han,eu qmean,de-en  wm  bl eu qmean,en-de  wm  bl eu qmean,4 c onclusions,new tuning, smt system,precision,recall,strict brevity penalty,strict redundancy penalty,system level,segment level,segment level,result,mt system,translation,system,several language pair,automatic metric,human evaluation,future work,free parameter,language pair,mt evaluation,improved correlation,human judgment,proceeding, ac l wo rkshop,machine translation,osborne,metric,proceeding,meta-evaluation,machine translation,proceeding,machine translation research,proceeding,zaidan,finding,joint workshop,statistical machine translation,metric,machine translation,proceeding,zaidan,finding,workshop,statistical machine translation,proceeding,manning,lexical metric,phrase-based statistical mt system optimization,proceeding,maximum similarity, bl eu,enhanced ranking metric,translation metric,improved evaluation,efficient algorithm,proceeding,denkowski,meteor paraphrase table,evaluation support,target language,proceeding,joint fifth workshop,metricsmatr,doddington,automatic evaluation,machine translation quality,n-gram co-occurrence statistic,proceeding,nominal scale agreement,many raters,psychological bulletin,van genabith, wmt metricsmatr,proceeding,joint fifth workshop,statistical machine translation,metricsmatr,automatic evaluation,translation quality,distant language pair,proceeding,kendall,ew measure,biometrika,open source toolkit,statis tical machine translation,proceeding,prague, met eor ,automatic evaluation,machine translation,machine translation,sentence,linear programming-based analysis,proceeding,joint fifth workshop,statistical machine translation,metricsmatr,evaluation metric,translation utility,semantic role,proceeding,minimum error rate training,statistical machine translation,proceeding, ac l-2003,sapporo,ystematic comparison,various statistical alignment model,computational linguistics,manning,robust machine translation evaluation,entailment feature,proceeding,method,automatic evaluation,machine translation,proceeding,chodorow,proceeding,translation edit rate,targeted human annotation,proceeding,association,machine translation,schwartz,fluency,adequacy,exploring different human judgment, a t unable mt metric,proceeding,fourth workshop,statistical machine translation,athens,spearman,measurement,association,american journal,psychology,tillmann,word alignment,statistical translation,proceeding,proceeding,annual meeting,association,computational linguistics,bulgaria,august,association,computational linguistics vector space model,adaptation,statistical machine translation boxing chen,roland kuhn,george foster national research council canada,new approach,adaptation,general idea,vector profile,in-domain development,profile,instance,vector,di mensionality,number,train ing subcorpora,vector re,contribution,particular sub corpus,phrase,dev set,phrase pair,train ing data,vector,feature,similarity score,vector represent,coding feature,phrase pair,closeness,cheap form,instance,phrase pair,ex periments,large scale  nis evaluation data show improvement,strong base line,arabic,chinese,non-adapted baseline,signifi cant improvement,circumstance,baseline,linear mixture model adaptation,informal analysis, vsm adaptation,good choice,meaning,ntroduction,translation model,system,parallel data,language,translation practice differs,dialect,partic ular author,publication,particular combi nation,factor,fect match,training data domain,domain, smt system,performance,system,test domain,domain adaptation,active topic,research commu nity,application,system,considerable attention,approach, smt model adaptation,mixture model,transductive learning,data selec tion,instance weighting,phrase sense disam biguation,research,mixture model,log-linear mixture,foster,approach,sub model,instance,several different tm,several different lm,different type,stance,mixture tm,schroeder,sub-models,smt log-linear framework,transductive learning,mt system,general domain data,domain monolingual data,bilingual sentence pair,additional train ing data,schwenk,bertoldi,federico,hildebrand,axelrod,search,bilingual sentence pair,domain,training data,instance,approach,matsoukas,foster,phillips,sennrich,rich feature,weight,training data,sentence,phrase pair level,example,sentence,subcorpus,domain,low weight,sentence,subcorpus,general na ture,weight, jhu workshop,domain adapta tion,translation model adaptation,approach,context,phrase,system,appropriate translation,new instance weight,approach,adaptation,foster,approach,phrase pair, vsm approach,word-based fea tures,expensive training procedure,distributional property,phrase pair,vector,representa tion,dev set,similarity,phrase pair,vector,vector,feature,decoder,phrase pair,sense closer,initial ex periments,different similarity func tions,bhattacharyya coefficient,jensen-shannon divergency,cosine measure,vsm adaptation,non-adaptive baseline,bhattacharyya similarity,experiment,vector space, vsm adaptation,various way,experiment,definition,contribution,phrase pair,phrase pair,training subcorpus,vari ant, vsm adaptation,super ficial resemblance,adaptation,mixture model,foster,approach,information,subcorpora,data origi nate,key difference,phrase pair,dis tribution,subcorpora,aggregated distribution,phrase pair,dev set,mixture model,phrase pair,distribu,edu workshop,group dasmt tion,subcorpora,probability,prevalence,subcorpus,much finer granularity,mix ture model adaptation,nothing, vsm idea,vector space,subcorpora,instance,source language,cluster,target language,cluster,dev set,phrase pair,source bag,target bag,vector,phrase pair,similarity,subcorpora,several way,vector space,result,variant,experiment,many information retrieval,natural language processing application,instance,sense similarity,many researcher,feature,context,corpus, a v sm,ply similarity function,hindle,burgess,turney,experiment,training data,subcorpora,instance,chinese-english training data,subcorpora,section,subcorpora,domain vec tor,standard tf,corpus,corpus si,maximum raw count,phrase pair,max ci,inverse document fre quency,measure,subcorpora,standard formula,number,subcorpora,smoothing term,in-domain dev,word alignment,phrase,usual way,dev set,distribution,phrase pair,dev data,subcorpora,domain informa tion,dev vector,total number,source target phrase,dev data,joint count,phrase pair fj,dev set,vector,feature,phrase pair,instance,equation,raw marginal count,phrase pair,variant, vsm adaptation,definition,vector space,existence,sub corpus,definition,vector,similarity function,experiment,vector similarity function,similarity score,vec tor,in-domain dev set,vec tor,phrase pair,decoder fea ture,many similarity function,purpose,commonly-used function,kazama,cosine measure,belong,different fam ilies,similarity function,fidelity family,shannon,entropy family,inner prod uct family,bc similarity,performance,subsequent experiment,bc score,weight,vector,weight,probability distribution,phrase pair,phrase pair,dev data,subcorpora,similarity score,absolute discounting,probability distribution,discounting value,proba bility mass,zero probability,smoothing,probability distribu tions,held-out data,similarity function,cosine,corpus segs,tok genre,nw financial  90k,fin gale bc,bc gale bn,bn ng gale nw,nw gale wl,wl hkh,legal hkn,nw isi,nw lex ne,nw sinorama,nw wl nis t06,nw bng nis t08,nw wl table,genre column,experiment, nis t op,chinese,compris,english running word,training data,corpus,origin,information,training,development,test set,training sub corpus,number,percentage,training data,training subcorpora consist,parallel sentence pair,lex ne cor pora,exception,comparable data,latter,lexicon,entity,development set,evalua tion,web-genre material, nis corpus,second setting,arabic,english data,un data,gov itl iad mig openmt12,cfm corpus segs,gale bc,bc gale bn,bn gale ng,ng gale nw,nw gale wl,wl isi,nw tot al,nis t06,nwl nis t08,nwl nis t09,column,training data,origin,summarizes information,train ing,development,test set,language pair,comparable isi data,large proportion,training data,english word,evaluation set,development,test set,system experiment,in-house phrase-based system,phrase table,phrase pair,separate alignment,length limit,direction,hierarchical lexicalized reorder,manning,distortion limit,feature,lex ical weighting,direction,word count,4-gram lm,target side,parallel data,6-gram en glish gigaword,system,batch lattice,cherry,foster,result,baseline,approach,tm domain adaptation ap-1288 proaches,log-linear combination,subcorpus,schroeder,weight,minimal error rate training,linear combination,subcorpus,weight,em algorithm,likelihood,joint empirical phrase pair count,in-domain dev data,detail,foster,section,performance,dev set,arabic-to-english system,chinese-to-english exper iment,arabic dev,result,exper iment,language pair,perfor mance,chinese-english system,case-insensitive  ibm  ble,matching, ble score, nis t06, nis t08, nis t09,arabic,following,bootstrap,significance,ta bles,significant gain,baseline,performance,differ ent similarity function,bhattacharyya,result,function,improvement,significant im provements,baseline,signifi cant margin,bhattacharyya coefficient,overlap,probability distribution,statistical sam ples,population,phrase pair,distribution,superior performance,experiment,next set,experiment,vsm adaptation,bc similarity function,baseline,training data,comparison,different similarity func tions,significant gain,baseline,respec,loglinear tm,linear tm,result,variant,adaptation,component,subcorpora,log-linear combination performs,baseline,algorithm,log-linear combination, ble score,baseline system,log-linear combination system,arabic, ble score,base line system,log-linear com bination system,global model,loglinear combination,improve,baseline,lan guage pair,linear mixture,baseline,lan guage pair,linear mixture,course,baseline,question, vsm performance,linear mixture,answer,arabic,linear mixture,argument,superi ority,linear mixture,convinc ing,significance,test set,result,vsm adaptation,mix ture tm adaptation,language pair, vsm result,linear tm,src tgt,joint src,joint tgt,joint src tgt,result,adaptation,maginal count,vector,joint count,phrase pair,next experiment,joint count,source,marginal count,result,source,target marginal count,result,feature set,decoder  vsm feature,joint count feature,source marginal count feature,target marginal count fea ture,instance,last row,result,feature,weight,source,target marginal count,useful information,performance,source,information,3-feature ver sion, vsm yield,baseline,arabic,chinese,english,result,joint count version,lin ear mixture,arabic,linear mixture,chinese,significance test,mixture, nis t06,result,3-feature version,new re sults,conclusion,arabic don,change,3-feature  vsm,su perior,mixture, nis t06 test set,3-feature  vsm,significant edge,linear mixture,nis t08 test set,fair summary,feature  vsm adaptation,mixture adaptation,arabic,linear mixture adap tation,chinese,last set,experiment,ques tion,system,linear mixture model adaptation,performance,foster,linear mixture,linear mixture,linear mixture,translation model,result,lin ear tm mixture,lin ear lm mixture,result,different combination,mixture mod el,significant gain,base line,result,topmost result,instance,initial chinese system,linear mixture lm adaptation,1-feature  vsm adaptation,performance,improvement sig nificant,3-feature  vsm,performance,arabic, vsm adaptation,im prof performance,significance,system,linear tm,linear lm adaptation,improvement,im provement,linear tm adapta tion,system,result, vsm adaptation,linear mixture adaptation,formance,significant amount,informal data analysis,intuition, vsm adaptation im, ble score,output,baseline,system,chinese test data,example,system,source-language,phrase,target-language,english,translation,bhattacharyya score,similarity,phrase,difference,transla tions,secondary effect, vsm adaptation,chinese vsm,arabic vsm,result,linear mixture adaptation,linear language model adaptation,lin-tm,linear translation model adaptation,significant gain,language model,system,baseline system, a b hattacharyya,change,phrase,interesting pattern,system,base line,synonym,stance,informal genre,weblog,system,informal word,baseline,formal word,sim ilar meaning,vice versa,formal genre,surprise,example,system,baseline,different mean ing,many example,system,baseline,meaning,consideration,example,first example,similarity,similarity,situation,system,prefers,translation,output,system,result, vsm adaptation,formal word,trans lation,informal weblog text,legal text,system,synonym,news story,legal text,cho sen,arrest,synonym,partial list,phrase,single word,system,output,baseline,first member,system,second member,chinese phrase,english,second word,bc score,dev set,synonym,near-synonyms,different sens,exception,center,differ,gunmen-mobsters,champion-star,caricatures-cartoons,spill-leakage,hiv-aids,inkling-clues,behaviour-actions,deceit trick,onclusions,future work,new approach,adaptation,statistical machine translation,vector space model,approach,similarity,vector repre,particular phrase pair,phrase ta,vector,dev set,feature,phrase pair,decoder,approach,language pair,large performance improvement,non-adaptive baseline,local ruffian,hooligan,villager,villager,hooligan,villager,killer,perpetrator,perpetrator,example, vsm chooses translation,consideration,linear mixture adaptation tech niques,number,different way,experiment,vector space,subcorpora,na ture,training data,convenience,many way,vector space,situation,vector space,bag-of-words topic model,feature,vector space,fea tures,subcorpora,experiment,information,reference amittai axelrod,jianfeng gao,adaptation,pseudo in-domain data selection, emn lp,nicola bertoldi,marcello federico,main adaptation,statistical machine translation,monolingual resource,proceeding,workshop,statistical machine translation,athens,measure,divergence,statistical population,probability distribution,bulletin,calcutta mathematical society,sung-hyuk cha,comprehensive survey,dis tance similarity measure,probability,sity function,international journal,mathe matical model ind method,min zhang,n-best hypothesis,smt self enhancement,roland kuhn,george foster,howard johnson,ing feature function,new way,phrase table,mt summit,colin cherry,george foster,tun ing strategy,statistical machine translation,naa cl,george foster,roland kuhn,mixture model adaptation,proceeding,acl workshop,statistical machine translation,prague,george foster,cyril goutte,roland kuhn,discriminative instance,domain adap tation,statistical machine translation,proceed ings,conference,empirical method,boston,michel galley,effective hierarchical phrase, emn lp,hawaii,october,almut silja hildebrand,matthias eck,stephan vogel,alex waibel,adaptation,transla tion model,statistical machine translation,information retrieval,proceeding,10th eam t co nference,budapest,donald hindle,classification,predi cate,argument structure,proceeding,annual meeting,association,fei huang,bing xiang,feature-rich dis criminative phrase, col ing,ichi kazama,stijn de saeger,kow kuroda,masaki murata,kentaro torisawa,a1292 bayesian method,robust estimation,distribu tional similarity,proceeding,nual meeting,association,uppsala,swe den,philipp koehn,josh schroeder,experi ments,domain adaptation,statistical machine translation,proceeding,second workshop,statistical machine translation,prague,czech republic,association,herbst,open source toolkit,statistical machine translation,statistical significance test,ma chine translation evaluation,proceeding,conference,empirical method,barcelona,dekang lin,automatic retrieval,clustering,similar word,proceeding,montreal,quebec,canada,jin huang,qun liu,improv,statistical machine translation performance,training data selection,optimization,pro ceedings,conference,empirical meth od,prague,burgess,high-dimensional semantic space,lexical co occurrence,behavior research method instru ments,computer,spyros matsoukas,antti-veikko,bing zhang,discriminative corpus,estima tion,machine translation,proceeding,conference,empirical method,singapore,robert,william lewis,intelligent selection,language model training data,kishore papineni,salim roukos,todd ward,wei jing zhu,method,automatic evaluation,machine translation,proceeding,40th annual meeting,association,philadelphia,phillips,ing machine translation,second-order taylor approximation,weighted translation instance,mt summit,holger schwenk,investigation,large scale lightly-supervised training,statistical ma chine translation, iws lt,rico sennrich,perplexity minimization,translation model domain adaptation,statistical machine translation,peter turney,synonym,pmi-ir versus lsa,twelfth european conference,machine learning,berlin,germany,nicola ueffing,gholamreza haffari,anoop sarkar,statistical machine translation,proceeding,nual meeting,association,czech republic,bing zhao,matthias eck,stephan vogel,model adaptation,statistical machine translation,structured query model,pro ceedings,international conference,geneva,au gust,proceeding,workshop,statistical machine translation,metricsmatr,uppsala,sweden,association,computational linguistics fast consensus hypothesis regeneration,machine translation  b,george foster,roland kuhn national research council canada,alexandre-tach,boulevard,george,foster,roland,kuhn nrc,bstract,fast consensus hy pothesis regeneration approach,ma chine translation,advan tages,feature-based fast consensus,previous work,hypothesis regeneration,wider search space,con sensus decoding,consistent improvement,language pair,improvement, bl eu,competitive single-pass baseline,chinese-to english  nis task,system,two-pass process,first pas,algorithm,translation n-best list,translation,second pas,various re-ranking algorithm,final translation,re-ranking al gorithms,decoding,gildea,phisticated additional feature function,hypothesis,evaluation metric,loss function,decision criterion,mt performance,specific loss function,sentence-level  ble loss function,ve  mbr algorithm,loss function,hypothesis,small number,de nero,fast consensus,algorithm,similarity score,feature expec tations,translation n-best list,transla tion,linear similarity function,unigram precision,  r e-ranking approach,performance,n-best list,content,complementary strategy,con tent,n-best list,search space,three-pass  smt process,hypothesis regeneration pas,decoding,rescoring pass,new hypothesis,original n-best hypothesis,n-gram expansion,confusion-network decoding,re-decoding,hypothesis regeneration method,com parable improvement,conjunction,rescoring model,final translation candidate,approach,different method,local feature func tions,translation model,hypothesis,rich global feature function,local feature function,approach,de pendent,expensive feature,rescoring,fast consensus hy pothesis regeneration method,advantage,feature-based fast consensus,hypothesis regeneration,feature-based similarity loss func tion,evaluation metric, ble score,hypothesis regeneration procedure,partial hypothesis,beam search,final translation,ap proach,pas hypothesis regeneration,ap proach,search space,sus decoding,advantage,n-gram expectation,linear  ble,gram expectation,full-length hypo thesis,n-gram expectation,fixed length partial hypothesis,hypothesis regeneration,forward n-gram expansion,bidirectional n-gram expansion,forward,n-gram expansion,experimental result,consistent improvement,baseline,language pair, ble point,competitive baseline,chinese-to english  nis task,ast consensus hypothesis regenera tion,hypothesis regeneration method,n-gram expansion,confusion network,re-decoding produce,formance,n-gram expansion method,n-gram expansion,search space,target string,n-gram language model,n-best hypothesis,hypothesis regeneration,bidirec tional n-gram expansion n-gram expansion,n-gram language model,translation n-best list,translation,partial hypothesis,partial hypothesis,sentence,symbol,par tial hypothesis,beam-search algorithm,function,ward language model,information com plementary,information,forward language model,forward gram expansion,backward n-gram expansion,hypothesis regeneration procedure,backward n-gram expansion,partial hy potheses,last word,translation n-best list,ex pansion,example,backward gram expansion,second row,bi-grams,original hypothesis,first row,third row,par tial hypothesis,backward n-gram expansion method,fourth row,new hypothesis,backward n-gram expansion,original hy pothesis list,original hypothesis,week work,week work,n-gram expansion partial hyp,new partial hyp,work new hypothesis, f igure,example,original hypothesis,bi-grams,partial hypothesis,overlapped n-1-gram,new hy potheses,backward n-gram expan sion,function,search,partial hypothesis,beam-search,function,beam-search algorithm,impor tant,addi tional global feature,partial hypothesis list,efficient way,porate,evaluation metric, ble score,candidate,func tions,method,romble et,fast consensus decod,n-best  mbr decoding,translation,expected loss,respect,candi date,hypothesis,loss function,translation, ble score,papineni,translation performance,loss func tion, mbr objective,translation,n-best  mbr decoding,n-best list,baseline decoder,lattice,decoding,candidate,lat tice,hypothesis regeneration,transla tions,baseline decoder,n-best list,translation lattice,translation,eu score,length,hypothesis,scor ing process,hypothe si regeneration,beam search procedure,extension,linear function, a t aylor approximation,logarithm,corpus  ble,tromble et,original  bl eu score,hypothesis,eep eeeebleu,precision,n-grams,hypothesis,brevity penalty,length,corpus log-bleu gain,first-order taylor approxima tion,logarithm,corpus  ble,nn eeceeeg,matched gram,constant weight,held-out data,gram count,n-best list,translation,linear corpus  ble,n-gram expectation-based linear corpus  bl eu,partial hypothesis,n-gram indicator function,n-gram,real-valued n-gram expectation,different,lattice,decoding,n-gram expectation,original translation n-best list,translation,n-grams,translation n-best list,translation,exten sion,expectation,n-gram count,par tial translation,length,partial hypo thesis,instance,length,partial hypothesis,n-gram count expec tations,partial original transla tions,rea son,solution,informa tion,word ordering,others,beginning,translation,frequency,others,full translation,process,hypothesis re generation,precise  bl eu,translation candi date, ble score,n-gram expectation-based  ble,nt nt nn thc tecethc ee ehb leuhsc,n-gram,hypothesis,final translation,fast consensus decod,gram feature expectation,translation,others,similarity,feature, ble score,differ ence,translation,fast consensus decoding, mbr decod ing,hypothesis regeneration,new translation,gram expansion,fast consensus hypothesis regeneration,new hypothesis list,forward,n-gram expansion,function,final translation,func tion,origi nal hypothesis,hypothesis,original hypothesis,n-best list,translation forest,new hypothesis,forward,ward n-gram expansion,new hypothesis list,bi directional n-gram expansion,3 e xperimental result,experiment,translation n-best list,state-of-the-art phrase-based statistical machine translation sys tem,detail,phrase table,symmetrized  ibm, hmm alignment,system,distance-based distortion component,7-word distor tion limit,cube pruning,chiang,log-linear fea ture combination,language model,distortion component,translation model,phrase,word penalty,weight,feature function,lattice  mer,macherey,different language pair,chi nese-to-english task,training data,evaluation chinese-to english track,bilingual corpus,translation model,language model,first one,5-gram lm,target side,parallel data,gov speech test,gram lm,so-called english giga word corpus,   d ev,test  nis t06, ni st08,gigaword,statistic,training,chinese-to-english task,experiment,chinese,develop ment set,balanced-genre web text,material,evaluation,test set,figure,training,number,sentence,reference,test set,german-to-english task,data set,parallel training data con,sentence pair,target word,dev set,test set contain,sentence,reference,source input sentence,target-language half,parallel training data,language model,result,evaluation, ibm  ble,papineni,case-insensitive matching,ur first experiment,1000-best list,chinese-to-english task,comparison,experiment,two-pass,three-pass hypothesis regeneration,n-gram expan sion,rescoring,three-pass,system,rescoring model,feature,translation lexicon score, hmm model,posterior probability,sentence length,language model,complete description,result, ble u-4,statmt,org wmt06,testset  nis,translation performance, ble u-4,1000-best list,chinese-to-english task,result,three-pass hypothesis regeneration,fast consensus,result,hypothesis regeneration,gram expansion,bi-directional n-gram expansion,performance,baseline,three-pass hypothesis regeneration,gram expansion,three-pass,improvement,rescor ing,three-pass hypothesis regeneration,hypothesis,scoring feature function,balance,experi ment,consensus,baseline,forward,result,consensus decoding,fast consen sus hypothesis regeneration,improvement,three-pass hypothesis regeneration,three-pass,hy pothesis list,forward,testset average time,average processing time,test set,different system,n-best list regeneration,re-ranking,consensus hypothesis regenera tion,fea ture,latter need,additional feature,experiment,processing time,second experiment,n-best list,chinese-to english,german-to-english task,re sults,first experiment,experiment,enlarg,n-best list,performance signifi,bi-directional n-gram expansion,improvement, ble u-score,de-en test,base line, l ang,ch-en de-en testset  nis,translation performance,effect,extension ac,expectation,n-gram count,partial hypothesis,whole candidate translation,section,tiny improvement,test set,expectation,n-gram count,partial hypo thesis,translation performance,1000-best list,expectation,n-gram count,whole hypothesis,expectation,n-gram count,partial hypothesis,discussion   t,search,partial hypothesis,pruning,n-gram expan sion,different new hypothesis list,example,figure,original hypothesis,figure,beam size,original hypothesis,forward,n-gram expansion,different new hypothesis list,figure,work  f igure,different new hypothesis list,forward,n-gram expansion,bi-directional n-gram expansion,cho sen translation,source sentence,decoder, nis test set,ward n-gram expansion, nis test set,backward n-gram expansion, nis test set,prof bidirectional n-gram expansion,good way,search space,4 c onclusions,future work,fast consensus hypothesis regeneration approach,machine translation,advantage,feature-based con sensus decoding,hypothesis regeneration,approach,previous work,hypothesis regeneration,wider search space,consensus decoding,consistent improvement,lan guage pair,n-best list,translation lattice,forest, mbr decoding,gildea,tromble,expectation,n-grams,trans lation,future work,hypothesis regeneration,n-gram language model,translation,cettolo,translation,generative n-gram lan guage model,denmark,regene rating hypothesis,statistical machine transla tion,knight,fast con sensus decoding,translation forest,singapore,wambacq,backward language model, ica ssp ,salt lake city,chiang,forest,proceeding,open source toolkit,statistical machine translation,prague,minimum bayes-risk decoding,statistical machine translation, naa cl,uszkoreit,lattice-based minimum error rate training,statistical machine translation,proceed ings, emn lp,honolulu,minimum error rate training,statistic al machine translation,mor gasbord,feature,statistical machine trans lation, naa cl,automatic evaluation,ma chine translation,macherey,lattice minimum bayes-risk decoding,statistical machine translation, acl workshop,gildea,efficient multipass,proceeding,proceeding,workshop,statistical machine translation,metricsmatr,uppsala,sweden,association,computational linguistics lesson, s amuel larkin,boxing chen,george foster,ulrich germann,roland kuhn   n ational research council,translation task, acl  wmt,eval uation,notable improvement,version,portage,efficient im plementation,lattice  mer,portage,chinese,mt evaluation, ni st09 evaluation,participation,interesting difference,certain weak spot,system,problem,system,several lesson,general interest,ntroduction portage,statistical machine translation sys tem,national research council,two-pass phrase-based system,translation task,english,english,french,recent year,chi nese-english translation, gal project, nis evaluation,english,french,canada,official language,portage,language pair,portage,canada,translation,english,english,french,result,direction,version,portage,problem,system,solution,ortage system description,core engine,training data, nrc system,standard two-pass phrase-based approach,major feature,first-pass loglinear model,phrase table,alignment, hmm alignment,distance-based distortion model,lexicalized distortion model,else dynamic mixture,phrase ta ble,joint count table,relative frequency estimate,lexical estimate,forward,backward,tional probability,lexicalized distortion probability, hmm count,feature,discontinuous feature,fol lowing,phrase,phrase pair,ap-based backoff,scheme,data sparseness,probabili tie,dynamic mixture lm,linear mixture,ngram model,weight,perplexity,current source text,foster,henceforth,namic lm,cube-pruning algorithm,chiang,7-word distor tion limit,usual implementation,distortion limit,new phrase,first non-covered word,new phrase,first non-covered word,notwith,distortion limit,contiguous phrase,source word,target,loglinear weight,max-bleu algorithm,lat tices,macherey,detail,lattice  mer,next section,second pas,1000-best list,first pas,additional feature,various lm, ibm model probability,length,posterior probability,frequency,mismatch indicator,quality,maximum,large set,partial ly-overlapping rescoring feature,greedy feature selection,baseline,training data,workshop, ldc resource,refers,lingual data,europarl,english,english,domain,refers, wmt parallel training data,news commentary,preprocessing,english,french preand post-processing tool, wmt web site,training,english,french text,language specific tokenizer, hmm approach,lexical probability,transition probability,3-gram lm,tru ecase,sentence-initial word,final detokeni zation step,tokenization,system configuration,evaluation,several way,resource,configuration, ble score,lattice  mer,n-best  mer,parameter,result,  e system component,domain,phrase table,gigafren,domain,distance-based distortion model,5-gram french lm,4-gram lm,french half,gigafren, 4 l m,french half,parallel corpus,5-gram lm,domain,4-gram lm,gigafren,5-gram lm,5-gram lm, f-e system,mirror image, e-f sys tem,etails,system,implementation, lme rt,notable recent change,system,feature,loglinear model,n-best  mer,instability,convergence,local optimum,foster,method,stability,complete lattice,candidate translation,decoding run,n-best list,variety,poor local optimum,algorithm,attention,time resource issue,implemen tation,lattice output,decoder,al gorithm,function,finite state equivalence algo rithm,deterministic finite state machine,second helpful idea,feature,function,phrase,translation length,translation model probability fea,phrase-feature table,feature,language,distortion model,careful coding,data structure,memory footprint,complete lattice,decoder,development,lattice,decoder run,excessive memory re quirements,acceptable perfor mance,lattice,decoder run,information,convergence,n-best  me rt, lme rt,reviewer,lattice,graph density,solution,memory problem,single sentence,implementation,impact,performance,option,openfst,lat tice,  p owell,good convergence,feature,simple coordinate search,problem,many correlated fea tures,multiple translation,language model,contour,function,learning,new search direction,difficult case,single optimum,dominates,difficulty,new direction,search,ten iterates,original co-ordinate,optimum,direction,local gradient,ran dom direction,iteration,direction,method,n-best  mer,1-dimensional  mer optimization,region,figure,problem,reality,2-dimensional search isn,problem,difficulty,di mension grows,high dimension,good direction,compromise,property,aggressive search,direction,new di rection vector,new direction,random rotation,ortho gonal transformation,coordinate,new direction,new coordinate,random coordinate,process,convergence,future work,random re,algorithm,additional insurance,premature convergence,ur  lme rt implementation,improvement,over-fitting problem,many correlated feature,preparation,evaluation, lme rt,n-best  me rt,feature,  a fter, wmt submission, lme rt implementation,submission, e-f submission,n-best  mer,system,bug-fixed  lme rt, ble gain, lme rt, wm t2010,n-best  me rt,particular case, f-e system, f igure,convergence,smooth feature space,convergence,feature space,4 p roblems,solution,fixing  lme rt   j ust,evaluation,discrepan cy, ble score, lme rt optimization, lm ert  code,version,french refer ence,memory,rt experiment,english,target language,bug hadn,bug didn,affect character,7-bit  asc ii set,english one,character,candidate transla tions,correct translation,accent, ble score,bug cost,internal version,system,buggy  lme rt,system,n-best  me rt,bug didn,affect  f-e score,ev  wmt, lm ert , lm ert ,fixing odd translation,evaluation,system,test data,bad behaviour,transla tions,proper name,apparent passthrough,english word,french side,  e xamples, e-f translation,proper name,submission,different sentence,joint tugluk,oleson, lme rt bug,bad translation,example,ur system, oov word,training data,bad alignment,dispropor tionate effect,source word,capital,signal,passthrough feature function,sen tence,sentence start,capitalized form,bar rack obama,phrase table entry,weight,feature function yield,tiny improvement, e-f system, lme rt,larg er improvement,test corpus,example, lme rt,ex amples,problem,passthrough function, ble gain,human being,apparent pas,instance,test data,translation,forward probability,source,problem,backward probability,valid french transla tions,loglinear combination,decoder,french translation,phrase table,sentence pair,translation,english sen tence,english sentence,original english sentence contains,english word,identical twin,english side,training data,sentence pair,sen tence contains word,english sentence,high backward probability,problem,apparent passthrough,weight,backward probability component,performance,english contamination,french side,parallel training data,random sample,sentence,common english function word,manual inspection,accurate estimation,legitimate french sentence,english word,english work,wouldn,contamination,contamination,europarl,gigafren,language,english,corpus,fre quent,  c ontamination,strange form,english sentence,french side,sentence,short english word sequence,short french word sequence, a f rench col umn,alter nate column,sentence,corruption didn, wmt data collec tion,detail,sentence contains word,english twin,serious damage,backward probability,hypothesis,parallel,monolingual training data, e-f system,language,trenkle,sentence pair,french side,high probability,sentence,high non french probability,guesser,assessment,news commentary sentence,sive level,news commentary sentence pair,sentence pair,sentence,  d ev  wmt,baseline,filtered,result,consis tent gain,hypothesis,source-language word,paired target sentence,system performance,backward probability,problem,  p ost-evaluation,arrange ment,training data,language direction,together,disparate corpus,domain,higher-quality,domain corpus,news corpus,weight,europarl,harmful overlap,new set,french lm,system,french lm,section, e-f system,shuffle,dynamic lm,5-gram lm,french side,europarl,news commentary,passthrough function,language filtering,section,training data,dis tortion model,system,bug-fixed version, lme rt,section,experiment,new french lm, e-f system,small decrease, nr c bleu,small increase, wmt newstest,newstest, f-e experiment,improvement,individual un, e-f  ble gain,feature function,small gain,test data, e-f lm training data,statistical fluctuation,improvement,evaluation  e-f system,quote normalization,training,test data,diverse single quote,ascii single quote,diverse double quote,ascii double quote,average result, wm t2010, ble point,original system,improvement,original system,final improved system,rescor ing,post-evaluation rescored gain,experiment,lized distortion,improved system,component, bl eu,system,n-best  mer,incorporation,6-feature lexicalized distortion, lme rt,incorpo ration,feature,  o ur truecaser doesn,truecasers, wmt group,tru ecasing,language direction,others,truecaser,relevant data,3-gram case-pattern statistic,unigrams,truecaser,case information,source word,corresponding target word,reviewer,several lab,separate truecaser,truecase text,approach, nis t ch,poor performance, wm data,sepa rate truecaser,lesson,5 l essons,improvement,system,n-best  me rt,large gain,non-buggy  lme rt,n-best  mer,result,outlier,experiment,similar configuration, lm ert ,n-best  mer,post-evaluation,minor improvement,case-based pas,function,language,normalization,collective ly,nice improvement,nothing,performance,lesson,system,relevant lan guage pair,original version, lme rt,target language,accent,  e uropean language pair,information, wmt system,design decision,chinese english,case information,source,tar get,upper-case word,proper noun,foreign-language contamination,training data,  w hen,evaluation,several year,system paper,previous year,system paper,noisy train ing data,source word,  w illiam cavnar,john trenkle, n-g ram,text categorization,symposium,document analysis,daniel jurafsky,regularization,search,min imum error rate training,workshop,roland kuhn,minimum error rate training,workshop,roland kuhn,mixture model adaptation,workshop,david chiang,forest rescor ing,amittai axelrod,alexandra birch mayne,chris callison-burch,mile osborne,david talbot,edinburgh system description,macherey,franz josef och,jakob uszkoreit,lattice-based min imum error rate training,statistical machine translation,minimum error rate training,ichard zen,hermann ney,improvement,proceeding,workshop,statistical machine translation,edinburgh,association,computational linguistics amb er,enhanced ranking metric  b,roland kuhn national research council,canada,gatineau,canada first,bstract,metric  bl eu,extra penal tie,text processing variant,little linguistic information,system-level cor relation,sentence-level consistency score,human ranking,state-of-the-art performance,1 i ntroduction automatic evaluation metric,quality,critical role,devel opment,statistical mt system,several metric,recent year,etrics,papineni,dodding ton,snover,linguistic information,surface,banerjee,eteor-next,denkowski,snover, tes la,limited linguistic resource,synonym dictionary,part-of-speech tag ging,paraphrasing table,sophisticated metric,semantic analysis,metric,bet ter correlation,human judgment,standard evaluation,following fact,language,word segmentation decision,im portant, mt system,quality point,metric,modified version,ranking,translation,human ranking,ranking, amb er variant,information source,mild lin guistic flavour,morphological knowledge,suffix,prefix,surface comparison,2 a mber,penalty,penaltyscoreamber,address weakness,literature,callison-burch,denkowski,sophisticated formula,penalty,score first,score part,geometric av erage,n-gram precision,arithmetic average,precision,recall,arithmetic average,measure,precision,recall,n-gram precision,recall,geometric average,n-gram preci sion avgp,score part, bl eu,arithmetic average,n-gram precision,recall,f-measure,arithmetic average,f-measure,preci sion,recall,weighted average,dev set,various penalty,original brevity penalty,product,various penalty,ipenpenalty,weight,penalty peni,penalty,transla tion,input sentence,reference,reference,length,word ir,long sen tences,recall,recall,precision,sentence,difference,penalty,length,character,penalty,wordmatches,free parameter,word alignment,translation,reference,number,wordmatchesbigrammatcheschunks,example,following two-sentence trans lation,reference,matched word,unmatched word,m1 m2 m3 m4 m5 m6,m7 m8 m9 m10 m11 m12 m13,bigram,matched word,bigram,m1 m2 m3 m4 m5m6,m7 m8 m9m10 m11 m12 m13,matched unigrams,bi-grams,conti nuity penalty,rtngrams nc tp,good translation,number,stop word,reference, am ber ,indo-european language,short word,character,stop word,bas wdp ,number,short word,translation,reference,dcl wdp ,number,long word,character,translation,ref erence,spearman,isozaki,penalty,similarity,word order,translation,reference,termine word correspondence,translation,reference,position,sentence,spearman,correlation,translation,reference,distance,i-th element,book like,book  t,vector,reference,translation rank vector,spearman,correlation score,vector,negative value,correlation score,penalty  nsc,kendall,o borne,isozaki,pre vious example,rank vector,translation,integer,correlation,pairsall pairsasingincre,kendall,correlation,transla tion,book like,negative value,coefficient score,penalty  nkc,original  ble metric weight,different n-grams,different amount,information,tf-idf,information value,matching strategy,original  ble,strategy,n-gram matching, amb er,matching strategy, am ber  variant,precision,recall,tween word,word1 word2,precision,word1 word2,precision, rou ge,precision, amb er score,different type,preprocessing,final score,average,default  amb er variant,possible text input,variant,stemmed,letter,suffixed,letter,longer-than-4-letter word,sub-words,letter,letter,letter,letter,becomes,letter,middle part,sub-word sequence,prefix,suffix,english prefix,suffix,internet1,language,linguistic knowledge,aspect, amb er,long word,small word,letter,3 e xperiments,experimental data, amb er, wmt data,all-to-english submission,english-to-all sub mission,test set statistic,dev test1 test2 test3 year,xx-en xx-en xx-en en-xx system,statistic,test set,org wiki list_of_greek_and_latin_roots_ in_ english,default setting,evaluation,free pa rameters,system level correlation,human judgment,following default setting,parameter,penalty,penalty weight,average,input text type,normalized text,default,tf-idf,strategy,flexible-gap gram, n ame,penalty weight value  sb, cs bp, cs rp, sw dp, lw dp, ns cp, nk cp,weight,penalty,evaluation metric,spearman,rank correlation coefficient,correlation, amb er,hu man judgment,translation,system level,human judgment score,translation,system,translation,system,callison-burch,metric,ranking,human one,sentence level,ranking,sentence pair,human judgment,result,result,section,pare  amb er,metric,original  ibm  ble, met eor  v1,result,version, amb er,tokenization,lowercasing,default version,baseline,experi ments,version, amb er perform, met eor ,system,sentence level,etric   d ev,eu_ibm,baseline,   n  me teor,result, amb er v  ble, met eor   s econd,impact,different type,preprocessing,combination,evaluation,result,sub-words improves,sentence-level correlation,pre processing split word,eng lish prefix,suffix,variant,result,target,english,system-level correlation,sentence-level consistency,non english word,english morpholo gy,performance,czech share,word root,english,underlined result, amb er,default,perform, amb er,preprocessing,impact,parameter,none tf-idf,tf-idf,tf-idf,performance, i nput   d ev,varying  amb er preprocessing,linguistic bold,non-ling,tf-idf   d ev,baseline,none tf idf sys,effect,tf-idf, amb er,penalty,weight,penalty,original value,sys tem-level performance degradation, lw dp,useful penalty,perfor mance,firm conclusion,retuning,weight,penalty,fu ture work, p enalties,baseline, -s bp sys, -s rp sys, -c sbp  sys, -c srp  sys, -s wdp  sys, -l wdp  sys, -c tp sys, -c kp sys, -n scp  sys, -n kcp  sys,penalty, amb er,bold  m,default,n-gram sys,fxd-gap n-gram sys,flx-gap n-gram sys,skip n-gram sys,matchings,strategy, amb er,effect,matching strategy,result,default strategy,matching,fixed-gap n-grams,flexible-gap n-grams,skip n-grams,combina tion,performance,system,sentence level,onclusion, amb er,new machine translation,modification,formula,several new penalty,human judg ment,different preprocessing type,tf-idf,strategy,choice,impact,performance,va riant,disadvantage,light linguistic knowledge,eng lish morphology,language,linguis tic information,human judgment, me teor,variant, amb er share  bl eu,virtue,linguistical ly,stop word list, lwd penalty,synonym,paraphrasing,n-gram matching,  a mber,weighted com bination,cheap fea tures,word surface form, mt quality,feature,effective strategy,correlation,weight,feature,future work,weight,feature, am ber ,banerjee,mt evaluation,improved corre lation,human judgment,proceeding, acl workshop,machine translation,summarization,osborne,quality,proceeding,joint fifth workshop,statistical machine translation,metricsmatr,meta-evaluation,ma chine translation,proceeding,machine transla tion research,proceeding,manning,lexical metric,phrase-based statistical mt sys tem optimization,proceeding,maximum similarity,translation metric,improved evaluation,efficient algorithm,proceeding, emn lp,denkowski,meteor paraphrase table,evaluation sup port,target language,proceeding,joint fifth workshop,statistical machine transla tion,metricsmatr,automatic evaluation,machine translation quality,n-gram co occurrence statistic,proceeding,van genabith, wmt metricsmatr,proceeding,joint fifth workshop,statistical machine translation,metricsmatr,automatic evaluation,translation quality,distant language pair,proceeding, met eor ,automatic evaluation,machine transla tion,machine translation,automatic evaluation,summary,proceeding,workshop,trans lation evaluation,sentence,linear programming-based analysis,proceeding,joint fifth workshop,statistical machine transla tion,metricsmatr,manning,robust machine translation evaluation,en tailment feature,proceeding,method,automatic evaluation,ma chine translation,proceeding,translation edit rate,targeted human annotation,proceeding,association,machine translation,schwartz,fluency,adequacy,dif ferent human judgment,fourth workshop,statistical machine translation,athens,greece,proceeding,workshop,statistical machine translation,association,computational linguistics improving  amb er,mt evaluation metric  b,roland kuhn,george foster  n ational research council canada,alexandre-tach,boulevard,roland,george,foster nrc,recent paper,change,first one,incorporation,penalty,second one,downhill simplex algorithm,weight,component, amb er,impact,change, wmt metric task,change,performance,improvement,new version, am ber ,correlation,human judgment,1 i ntroduction  am ber ,machine translation evaluation,advantage,papineni,complete language independence,rapid computability,correlation,human judg ment,weighted combination,cheap feature,word sur face form,machine translation metric,source,knowledge,syntactic resource,surface form,hypothesis,reference,knowledge,simplicity,improvement,penalty,weakness,version, am ber ,free parameter,simplex algorithm,tuning,2 a mber  am ber ,product,penalty,score part,penalty part,weighted average,n-gram precision,f-measure,arithmetic average,precision,recall,arithmetic average,f-measure,precision,recall,weighted product,several different penalty,quation,original  amb er paper,ten penalty,penalty,normalized spearman,correlation penalty,normalized kendall,correlation penalty,model word reorder ing,penaltyscoreamber,ipenpenalty,weight,score com ponent,weight,penalty peni,addition,complex score,alty factor,ber  differs,fixed n-grams,different kind,flexible n-grams,com puting score,penalty, amb er score,different type,different combination,several text pre,technique,lowercasing,word splitting,final score,average,experiment,preprocessing,3 i mprovements,penalty,simple matching algorithm,isozaki,1-1 word alignment,hypothesis,reference,  a fter word alignment,reference,normalized position,hypothesis,hypothesis,position,corresponding word,reference,unaligned word,p1 reference,p2 hypothesis,np2  s,winter,paris hyp,winter,reference,hypothesis,position,position,matching word,winter,metric,distance measure, ppp pdist,ppd ist,similarity,permutation,spearman,punishes,instance,movement,example,  r ef,paris hyp, hmm word alignment,second distance measure,jump width,sequence,long distance,internal word order,following,jump width punishment,winter,paris hyp,winter,second distance measure,ppppppdist,similar permutation,ordering measure v,harmonic mean,geometric mean,segment level,document level,weighted arithmetic mean,number,segment,document,length,reference,text preprocessing,penalty part, amb er,weighted product,several component penalty,original version, amb er,component penalty,new version,penalty,new version, amb er incorpo rate,penalty,spearman,correlation,kendall,correlation,recent ly,   a utomatic tuning,free parameter, amb er,section,experiment,free parameter,metric,previous sec tion,downhill simplex method,nelder,multidimensional optimization technique,geometrical consideration,good performance,variety,application,experiment, wmt metric task data,english-to-all submission,language,statistic,data set, s et year lang,system sent-pair test1,statistic, wmt dev,test set,dev set,test set,spearman,rank correlation coefficient,correlation,system-level human judgment,translation,human judgment score,translation,system,system,callison burch,new ver sion, amb er,ranking,human one,segment level,callison-burch,kendall,rank correlation coefficient,vari ant, amb er,variant  amb er,variant,result,preprocessing,tokenization,tokenization,casing,letter,sub-words,letter,let ters,letter,letter,becomes,letter,middle part,explana tion, amb er,external resource,stemmer,phological analyzer,maximal lan guage independence,poor man,letter,approximation,letter,information,number,gender,ome information,new language,new indo-european language,information hidden,complex word,result,table 2-4 compare,correlation,variant, amb er,human judgment,version,instance,segment-level correlation,paired compari son,paired compar isons,system,con dition,out-of-english value,performance, am ber1,version, amb er1,cludes,penalty,system,segment level,result,impact,english,segment level,result,  a mber,correlation,human judgment,performance,manu ally, amb er1, amb er1,param eters,simplex method,tuning,dev set,possible combination,out-of english,system segment level,re sults,test set,change,im pact,segment level,  a mber,simplex change into-en   s ystem,correlation,human judgment, t hen,performance, am ber1, amb er1,simplex method,new version, amb er,change, amb er2,major improvement, amb er1,segment level,english,segment level,impact,change,percentage improvement,improvement,change,actual improvement,improvement,system level,english,change,small improvement,change,  a mber, amb er2 change into-en system,correlation,human judgment,course,new version,answer,question,version, bl eu,mteval-v13a,clear advantage, amb er2,system,segment level,english,english,  b leu amber2 change into-en system,correlation,human judgment,5 c onclusion,change,metric described,exper iments,new version, amb er,improvement,original version,correlation,human judgment,system level,segment level,good evaluation,good tuning,vice versa,parallel, amb er,evaluation,machine translation, po rt differ,many detail,underlying philosophy,surface similarity,hypothesis,reference,external resource,linguistic knowledge,result, amb er re,  r eference,zaidan,finding,joint workshop,statistical machine translation,metric,machine translation,proceeding,meta-evaluation,ma chine translation,proceeding,larkin, a p reci sion-order-recall mt evaluation metric,publication,proceeding, bl eu,enhanced ranking metric,proceeding,sixth workshop,statistical machine transla tion,edinburgh,scotland,automatic evaluation,translation quality,distant language pair,proceeding,nelder,simplex method,function minimization,method,automatic evaluation,ma chine translation,proceeding,flannery,numerical recipe,spearman,measurement,sociation,american journal,tillmann,word alignment,statistical translation,proceed ings