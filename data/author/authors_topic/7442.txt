proceeding,human language technology conference,conference,empirical method,vancouver,october,association,computational linguistics incremental  lta g pa,libin shen,aravind,joshi department,computer,information science university,pennsylvania philadelphia,edu abstract,cremental parser, lta g-spinal,vari ant,parser,full adjoining operation,dynamic predi cate coordination,non-projective de pendencies,formalism,generative capacity,using gold standard  pos tag,section,parser,f-score,syntactic dependency, lta derivation tree,dependen cies,head rule,example,magerman,formalism,computa tional perspective,recent review,schabes,intro duction,adjoining operation, tag formal ism,strong genus tive power, tag formalism,attractive analysis,natural language,lombardo,demonstrate,adjoining operation,eager incremental processing,vijay-shanker,first  tag parser, a c yk-like algorithm,adjoining operation,time complexity,lta parsing, cfg parsing,length,sentence,many  lta parser,head-driven earley style parser,lavelli,head-corner parser,van noord,high time complexity prevents,real-time application, lta g-spinal,interesting subset,strong generative power,statistical incremental parsing, lta g-spinal,parser,first comprehensive attempt,efficient statistical parsing,formal grammar,generative power,full adjoining operation,dynamic predicate coordination,pendencies,treebank, lta g-spinal formalism, lta g-spinal treebank,detail,different kind,elementary tree,initial tree,auxiliary tree,name implies,initial tree, lta g-spinal,anchor,auxiliary tree,operation,elementary tree,derivation tree,adjunction,conjunction,lta g-spinal elementary tree,operation,example,figure,figure,character,operation,attach,adjoin,formal result,relationship,spinal form context-free tree grammar,fujiyoshi,ka sai,riezler,maxent model,k-best par,rule-based  lfg parser,andseemswhichparsera meto tt tt ta tc vp  xpx p xpxp figure,example,attachment, lta g-spinal,adjunction,chiang,combination,substitution,sister adjunction,attachment operation,ambiguity,argument,adjunct,adjunction,foot node,auxiliary tree,adjunction operation,wrapping,sister ad junction,adjunction,property,incremental parser,conjunction,sarkar,lta g-spinal,conjunction operation,spinal elemen tary tree,contrac tion set,conjunction,formalization,con junction,special adjunction, lta g-spinal treebank,propbank,palmer,annotation,relation,traditional  lta gltag spinal preserve,strong genus tive power, lta spinal,restriction,sch abes,generative capacity,example, lta spinal grammar,feature,rochester sanjeev khudanpur john hopkins,anoop sarkar simon fraser,libin shen,pennsylvania david smith john hopkins,katherine eng stanford,viren jain,michigan abstract,methodology,rapid exper imentation,statistical machine translation,large number,feature,baseline system,feature,wide range,syntactic representation,feature value,log-linear model,scoring candidate translation,n-best list,feature weight, ble eval uation,held-out data,present re sults,small selection,feature,syntactic representation,enormous progress,statistical technique,recent year,state-of-the-art statistical system,translation,obvious error,grammatical error,clude lack,main verb,wrong word order,wrong choice,function word,frequent problem,grammatical nature,content word,incorrect punctuation,problem,variety,new feature,candidate translation,high-quality statistical translation system,baseline,new feature,exist ing set,log-linear model,easy integration,new feature,base line system,n-best list,candidate transla tions,new feature,framework,different type,fea tures,feature,syntactic analysis,source,target sentence,grammaticality,translation,lower-level feature,n-best list,global sentence-level feature,baseline system,n-best rescoring framework,experiment,selection,new fea tures,word-level feature,part-of-speech tag,syntactic chunk,feature,treebank-based syntactic par,source,target sentence,og-linear model,statistical mt,translation,source language,target language,target,possible target sentence,sentence,alternative,source-channel ap proach,log-linear combination,feature function,framework,feature function,feature function,direct translation probability,standard criterion,training,log-linear model,probability,parallel train,corpus consisting,sentence pair,formance,translation quality,system,reason,parameter,held-out data,difficult optimiza tion problem,search space,figure,example segmentation,chinese sentence,english translation,alignment template,certain property,search,detail,method,feature weight,baseline mt system,alignment,baseline mt system,alignment template system,detail,tillmann,short description,baseline model,probability model,alignment template sys tem,sentence,distinct stage,source sentence word fj1,phrase,phrase,alignment template,sequence,chosen alignment template,phrase,translation,sequence,phrase,sequence,baseline system,following feature function,alignment template selection,alignment template,probability,relative frequency,corresponding feature function,log-linear model,log probability,product,alignment template,word selection,feature,lexical translation probability,relative frequency,highest-probability word level alignment,training sentence,translation probability,source,target position,alignment template,position-independent probability,feature,monotonic alignment,phrase level,amount,non-monotonicity,distance,source language,alignment template,target language,model feature,language model feature,standard backing,word-based tri gram language model,generet,wessel,system,different lan guage model feature,different corpus,news part,bilingual training data,large xin hua news corpus,large  afp news corpus,chinese news text,word phrase penalty,word penalty feature,length,target sentence,feature,sentence,phrase penalty feature,number,phrase,long phrase,phrase,conventional lexicon,baseline alignment template system,chinese english lexicon,lexicon entry,potential phrase translation pair,alignment tem plate system,lexicon entry,normal translation probability,fea ture function,number,lexicon entry,additional feature,major advantage,log linear modeling approach,new feature,variety,feature,deeper syntactic representation,source,target sentence,alignment,new feature,feature value,baseline feature,re-estimated feature weight,development data,re sults,test data,3 e xperimental framework,chinese-english data,recent evaluation,large amount,sentence-aligned training corpus,multiple gold standard reference translation,standard data set,result,system,addition,chinese allows,chinese syntactic treebank,parser,baseline mt system,chunk-aligned parallel training corpus,corpus,basic training corpus,alignment template transla tion model,word lexicon,phrase lexicon,corpus,english word,large part,corpus,sub-sentence level,existence,long sentence,training process,manageable word alignment training,development corpus,training cor pu,discriminative training,model parameter,log-linear translation model,experiment,report,cor pu,sentence, 25k word,language,test corpus,test corpus,quality,feature function,sentence, 25k word,development,test data,english,ref erence,translation,chinese sentence,reranking,n-best list,oracle,sentence,development,blind test corpus,different alternative transla tions,baseline system,n-best candidate translation,search,n-best candidate translation,discriminative training,model parameter,new search algorithm,development,efficient search algorithm,long-range dependency,research topic,rerank,strategy,new dependency,search algorithm,pendency,n-best list,possibility,improvement,n-best list,quality,n-best list,improvement,perfect reranking algorithm,oracle translation,translation,n-best list,method,ble score,oracle sentence, ble score,reference translation,ble score,oracle sentence,reference translation,differ ent set,oracle sentence,ble score,reference translation,sentence,leu  score,reference,cho sen,oracle,3-reference ble score,corpus-level holistic nature,ble score,optimal set,oracle translation,greedy search algorithm,oracle translation,local optimum,dependence,starting point,significant problem,oracle  ble,different size,n-best list, avb leur,respect,reference translation,different choice,reference,avb leur,rr opt,first method,theoretical upper bound, ble score,method,1000-best list,tain oracle translation, ble score,human translation,oracle translation,human  ble score,test data,translation,human  ble score,second method,different reference,selection,scoring,1000-best list,oracle translation,relative human  ble score,result,oracle experiment,feature,significant computation,hy pothesis,translation candidate,experiment,test set,1-best oracle,benchmark,contri butions,additional feature,remain der,preprocessing,precursor,various syntactic fea tures,report,syntactic represen tations,involved part-of-speech tagging,chunking,chinese,english side,training,development,test set,part-of-speech tagger,un grammatical mt output,n-best list,unexpected result,tagger,example,cd open jj border nn city,achievement,remarkable jj,achievement,tagger,training data,position,present tense verb tag,addition,inaccura cies,mt system,difference,tagger,problem,example,mt data,news article headline,headline,wall street journal text,tagger,tagger,full sentence,normalized punctuation,punctuation,sen tence,punctuation tag,evi dence,cc opening,cd border nn city  nns remarkable jj achievement,parser,example,parser,verb phrase,none exist,following example,tagger,sentence,effect,serious implication,syntactic feature function,feature,verb phrase,solution,feature,probability,parse subtree,tag sequence,verb phrase,solution,detailed feature,structure,verb phrase,4 w ord-level feature function,feature,source,target string,problem,translation choice,content word,incorrect punctuation,model  1 s core,feature function,bag-of-word trans lation model,possible alignment probability,lexical co-occurrence effect,effect,seman tic coherence,translation,probability,translation pair,training data,subset,english side,en tire corpus,baseline mt system,missing translation word pair,unknown word,constant,average,search initial point,feature function,improvement,overlap,word selection feature,baseline system,performing fea tures,tendency,baseline sys tem,content word,word selec tion coherence,effect,effect,proper verb-noun combination,verb-preposition combina tion,lexical re-ordering,alignment template,figure,alignment,baseline system,various con figuration,left right-monotone,lexicalized re-ordering,left-monotone model,total proba bility,monotone,corner,upper right corner,first word,current,last word,total probability,product,alignment template,right-continuous model,total prob ability,corner,upper right cor ner,previous,first word,cur rent,last word,total probability,product,alignment template,probability,full training data,hallow syntactic feature function,shallow syntax,output,part-of speech tagger,chunkers,feature,strength,tagand chunk-based trans lation system,schafer,yarowsky,baseline system,projected  pos language model,feature,chinese  pos tag sequence,surro gate,chinese word,movement,chinese word,movement,attempt,movement,chinese  pos,feature,weak model,word movement,baseline system,chinese  pos sequence,word alignment,relative position,chinese tag,feature function,relative position,measure,open border city,example tagging,english hy pothesis,chinese sentence,feature function,log probability,trigram language model,sequence, hmm alignment model,tillmann,case movement,speech,projected  pos feature function,performing shallow syntactic feature function,feature function,trade-off,word-based model,full generative model,shallow syntax,6 t ree-based feature function syntax-based mt,promise,others,alshawi,bangalore,douglas,feature,treebank-based syntactic analysis,source,target sentence,grammatical error,output,baseline system,parse tree probability,straightforward way,statistical parser,system,parser probability,feature function,feature function,result,reason,ex periment,used statistical parser,probability,grammatical sentence,average log probability,collins parser,reference translation,hypothesis 1-best oracle reference log,parseprob,average parser log-probability,1-best translation,average parse log probability,oracle,reference translation,parser,probability,ungrammatical mt output,grammatical human translation,reason,mt output,unseen word,frequent word,language model probability,experiment,effect,parser probability,word unigram probability,parser probability,feature function,improvement,tree-to-string alignment tree-to-string model,several syntax,translation model,conditional probability,yamada,knight,yamada,knight,model performs,opera tions,parse tree,child node,optional word,leaf english word,chinese word,operation,probability,operation,probability,operation,training algorithm,en glish parse tree-chinese sentence pair,probability,operation,everything,varies,possible alignment,particular operation,edge eki,phrasal translation,input parse tree,yamada,knight,english phrase cov, a c hinese phrase,regular reordering,insertion,leaf word translation,english parse tree-chinese sentence pair,mil lion word,english side,collins,parser,limitation,model operation,base mt system,translation,big word jump,child node,reordering probability,prun ing,alignment,probability,threshold,possible alignment prob ability, a c hinese sentence,english parse tree,probability,alignment,fol lowing,feature function,reetostringsum,htreetostringviterbi,n-best list,sentence length,development sen tences,test sentence,average,search initial point,htreetostringsum,htreetostringviterbi,development sentence,oracle sentence,produced sentence,problem,n-best list,long  cpu hour,addition,short sentence,long sentence,syntac tic tree,source,target language,tree-to-string model,operation,probability,source,target language,chinese,english parser,tree-to-tree alignment model pre,gildea,dle dependency tree,word-level alignment,baseline mt system,probability,tree-to-tree alignment model,word-level alignment,candidate translation,feature,rescoring system,parameter,tree transformation operation,sentence pair,parallel chinese english data,corpus,lexical translation probabili tie pt, ibm model,mil lion word training corpus,sparseness,lexical translation probability,tree-to-tree model,much training data,tree-to-tree model,discrimination,oracle experiment,first sentence,n-best list,candi date, ble score,1000-best list,993-sentence development set,sentence,branching factor,chinese,en glish tree,result,sentence,oracle,prob ability,source chinese dependency parse,n-best hypothesis dependency parse,feature function,word-level alignment,baseline,markov assumption,tree alignment,tree-based feature function,following limitation,full parse tree model,long sentence,flat constituent,n-best list,experiment,addition,parse tree,source,target parse tree,section,problem,simple markov model,tree-based alignment,tractability,coverage,n-best list,unconstrained tree-based model,markov model approach,coverage,n-best list,addition,approach,parse tree,algorithm,word alignment,parameter,maximum number,tree fragment,maximum height,tree fragment,chi nese sentence,subtrees,subtree,chinese,english,chinese subtree,english subtree,subtrees,parameter value,subtree pair,property,template,complex way,source,target,figure,parameter,sentence pair,experiment,tree fragment,parameter,subtree-pairs, a m arkov assumption,tree-to-string translation model,pair ings,sentence pair,subtree-pairs,feature function,sentence pair,tree-to-string translation model,logptree-to-string,markov assumption,tree alignment,figure,markov assumption,tree alignment,string model,section,coverage improvement,coverage,performing single syntactic feature,using  tag elementary tree,word alignment,section,method,full parse tree,method,decomposition,parse tree,fragment,original parse tree,figure,formalism,definition,tree fragment,addition,original parse tree,fragment,fragment, a t ag elementary tree,compo sition, tag elementary tree, a t ag,tion tree,decomposition,parse tree,decomposition, tag elementary tree,parse tree,source,target sentence,head-word,argument,complement,informa tion,heuristic,contempo rary statistical parser,en glish,word alignment information,decomposition, tag elementary tree,ag elementary tree,several model,score word align ments,alignment,mentary tree,source,target, tag elementary tree,aligned word fi,alignment,unigram model,alignment,conditional model, sri lan guage modeling toolkit,parse tree, tag elementary tree,chi figure,word alignment, tag elementary tree,english,unigram model,conditional model,ibm model,tree-to-string markov fragment,right-continuous alignment template,tag conditional bigram,left-monotone alignment template,projected  pos lm,combination,result,baseline feature,new fea ture,baseline,com bination,new feature,7 c onclusions,discriminative reranking,n-best list pro,state-of-the-art statistical mt system al,benefit,off-the-shelf parser,chunkers,tagger,syntac tic well-formedness,mt output,result,single new feature,confi dence interval,bootstrap,method,addition,experiment,single feature,multiple feature,greedy approach,feature, ble score,feature integration,feature,single fea ture,significant improvement,ibm model,success,weakness,baseline system,con tent word,word selection,effect,example,source language word,major goal,treebanks,chinese,english,state-of-the-art deep,shal low parser,mt quality,syntactic feature,statisti,significant improvement, ble score,poten tial reason,section,off-the-shelf tagger,parser,various problem,ous mismatch,parser training data,application domain,parser probability,feature function,potential improvement,parser,full training data,baseline system,1000-best list,potential im provements,improvement,n-best list,word graph representation,candidate,sensi tive,grammaticality,mt output,improvement,system,output,ble u-based optimization,feature weight,corpus,discriminative train ing,evaluation,confidence interval,ur discriminative training technique, ble score,development corpus,problem,large number,feature,corpus,discriminative training,vestigate alternative discriminative training criterion,amount,tagger,parser,magnitude,parallel training data,baseline system,word-based feature,comparable amount,treebank,significant im provements,first large scale integration,syntactic analy si,many different level,state-of-the art phrase-based mt system,methodology,log-linear feature combination approach,discriminative reranking,n-best list,state-of-the-art baseline system,member,large team,hundred,syntactic fea ture function,common platform,acknowledgment,material,na tional science foundation,reference alshawi,srinivas bangalore,shona douglas,dependency translation model,collection,finite state head transducer,computational linguistics,della pietra,vincent,della pietra,mathematics,sta tistical machine translation,parameter estimation,compu tational linguistics,gildea,daniel,tree-based alignment,ma chine translation,annual meeting,association,frank wessel,ex tension,absolute discounting,language modeling,fourth european conf,speech communica tion,technology,madrid,franz josef,minimum error rate training,statisti cal machine translation,annual meeting,association,franz josef,hermann ney,discriminative training,maximum entropy model,statistical ma chine translation,40th annual meeting,association,franz josef,hermann ney,alignment tem plate approach,statistical machine translation,computa tional linguistics,accepted,publication,franz josef,christoph tillmann,hermann ney,alignment model,statistical machine translation,joint  sig dat co nf,empiri cal method,natural language processing,large corpus,schafer,charles,david yarowsky,statistical ma chine translation,coercive two-level syntactic transduc tion,conference,empirical meth od,stephan,hermann ney,christoph tillmann,statistical translation,col ing ,computational lin guistics,copenhagen,denmark,machine translation,stochastic grammatical channel,annual meeting,association,computational lin guistics,computational linguistics,montreal,canada,yamada,kevin knight,syntax-based sta tistical translation model,annual meet ing,association,france,yamada,kevin knight,decoder,syntax,40th annual meeting,asso ciation,discriminative,machine translation libin shen dept,science univ,pennsylvania philadelphia,libin sea,anoop sarkar school,science simon fraser univ,franz josef och info,science institute univ,southern california marina,och isi,abstract,application,technique,problem,machine translation,sentence,source language,baseline sta tistical machine translation system,ranked best list,candidate translation,target language,novel perceptron,algorithm,quality,machine translation,baseline system,evaluation,experimental result,chinese-english large data track evaluation,theoretical analysis,algorithm,experiment,state-of-the art performance,machine translation,noisy-channel model,foundation,ten year,so-called reranking tech niques,maximum entropy model,gradient method,significant improvement,novel machine,mt task,algorithm,improvement,natural language parsing,performance,al gorithms,application,perceptron,boosting,machine,community,novel discriminative ranking,ordinal regression,algorithm,recent year,technique,machine translation,reranking problem,natural language,clas sification problem,regression problem,certain condition mt,dif ferent,special issue,technique,mt task,algorithm,mt rerank,experimental result,algorithm,start-of-the-art result,chinese-english large data track evaluation,generative model,seminal  ibm model,generative model,mt task, ibm model,sequence,hidden markov model,speech recognition,problem,source,tar get sentence,observation,alignment,hidden information,parallel text,em algorithm,source channel model,translation,target,language,source,sentence,generative probability model,language model,generative probability,candidate transla tions,translation model,gener ative conditional probability,source sentence,candidate translation,lexicon,single-word, ibm model,word context,account,unlikely alignment,result,additional decoding complexity,several mt model,extension,ibm model,intuition,additional linguistic constraint,decoding perplexity,translation quality,waibel, smt model,phrase-based alignment,transla tion model,phrase,accuracy,translation,language,differ ent word order,two-level alignment model,shallow phrase structure,alignment,tem plate,phrase reordering,word alignment,template,phrase,translation,level alignment,long distance,alignment model,constraint,alignment,probabilistic syn chronous context-free grammar,syntax model, a t reebank,knight,statistical parser, a t reebank,source language,parse tree,alignment,gildea,alignment model,output,statistical parser,source,tar get language,translation model,tree align ments,cloning,tree-based alignment model,discriminative model,mt och,framework,direct translation,conditional model,maximum entropy model,small number,feature function,source,target sentence,translation gen,baseline mt system,total num ber,feature function,feature function,complex statistical model,exam ple,alignment template feature function,approach,minimum error train,error rate,automatic mt evaluation metric,experiment,approach,re sults,maximum mutual information cri terion,parameter estimation,approach,feature,alignment template approach,minimum error training,large number,feature func tions,different feature function,syntactic well-formedness,mt output,1000-best list,baseline mt system,test dataset, nlp task,machine translation,parsing,natu ral language processing,generative model,recent year,technique,discriminative reranking,sig nificant improvement,various machine learn,algorithm,parse reranking,boosting,collins,collins,support vector machine,technique,error reduction,labeled recall precision,generative parsing model,discriminative reranking method,notion,margin,distance,candidate parse,reranking problem,classification problem,pairwise sam ples,new perceptron-like ordinal regression algorithm,parse reranking,algorithm,pairwise sample,training,margin,distance,tween par,different rank,addition,uneven margin technique,purpose,ordinal regression,algorithm,mt reranking,new perceptron-like reranking algorithm,ordinal regression,machine learning,ranking,ordinal regression,rerank,motivation,ordinal regression algorithm,previous work,ranking,dinal regression,margin,distance,consecutive rank,large margin ap proaches,prank algorithm,variant,perceptron algorithm,multi ple bias,boundary,consecutive rank,crammer,singer,harring ton,section,prank algorithm,reranking task,introduction,global rank,ap proach,ranking problem,classification problem,method,pairwise sample,assumption,sample,consecutive rank,problem,ma chine translation,reranking approach,baseline system,candidate,candi date,feature,new ranking,candidate,candidate translation,advantage,discriminative reranking discriminative reranking,global feature,baseline system,feature,various kind,fine-grained smoothing issue,statis tical machine,approach,many  nlp task,enables rapid experimentation,complex feature function,complex decoding step,n-best list,translation,problem,mt first,discriminative reranking,machine translation,parse rerank ing,algorithm,machine translation,candidate,th position,source sentence,ranking,quality,candidate,parse reranking,parallel hy perplanes,supertagger,application,np chunking libin shen,aravind,joshi department,computer,information science university,pennsylvania philadelphia,edu abstract supertagging,process,correct elementary tree,correct supertag,supertags,syntactic dependency, pos tag,novel method,sparse network,sequential model,supertagger,distance syntactical depen dencies,supertagger,accuracy,su pertagger,np chunking,su pertags,absolute increase,f-score,transforma tion,surpertagger,efficient way,syn tactic information,1 i ntroduction,schabes,ag-group,sentence,el ementary tree,supertag,srinivas,process,correct supertag,input sentence,attrac tive,syntac tical information, pos tag,useful pre-parsing tool,parsing,srinivas,correct supertag,supertag, lta parser,sentence,suggests,time complexity,supertagging,pos tagging,length,put sentence,np chunk,application,supertag,two-phase par,chunking,marcus,chuck ing,transformation,machine,technique,winnow,matsumoto,pereira,collins,learning,result,literature,regularized winnow,parsing result,english slot grammar-based parser,chunker,result,absolute increase,f-score,approach,purpose,ideally,chunker,n-best result,tacher us,result,dilemma,syntactic constraint,chunking phase,reason,pos tag,good labeling system,enough linguistic knowledge,labeling system,great deal,syntactic information,possible elementary tree, lta parser,correct elementary tree,sen tence,elementary tree,parse tree,sentence,elementary tree,supertags,infor mation, pos tag,chunking accuracy,supertags,long dis tance dependence,supertaggers,local information,full advantage,complex information,supertags,syntactic dependency,context,new model,supertag,sparse network,novel method,sequential model,punyakanok,contrast, a s now  classifier, pos tag,input sentence, pos tag,supertag,previous word,corresponding snow classifier,method,sparse data problem,force snow,difficult case,con text, pmm suffers,label bias problem,lafferty,method,problem,method,local normalization step,result,supertagger,hand-coded supertags,supertags,dataset,supertagger,accuracy,supertagger,np chunking,purpose,syntactic information,np chunking,machine,well-known algorithm,com munity,text chunking,machine,research,contribution,supertags,re spect,ramshaw,marcus,original work,baseline,su pertags,machine,algorithm,ramshaw,marcus,transformation,ramshaw,marcus,algorithm,supertags, pos tag,dataset,supertags,increase,transformation,supertag ging,labeling system,performance,np chunking,supertag ger,opportunity,advanced machine,technique,performance,syntactic information,supertags,np chunking,srinivas,trigram model,su pertagging,good-turing discounting tech nique,back-off model,supertag,lexi cal preference,contex tual preference,supertags, wsj section,section,section,accuracy,test data,srinivas,np chunking,f-score,similar result,tri gram supertagger,approach,test data,uesd heuristic rule,np chunk,supertags,heuristic rule,system,good result,first attempt,fast  tbl,flo rian, a t bl program,ramshaw,marcus,experiment,standard dataset,srinivas,supertagger,srinivas,training,test data,fast  tbl,second round,supertags, pos tag,dataset, pos tag,f-score,supertags,f-score,becuase srinivas,supertag,trigram model,supertags,long distance dependence,supertaggers,local information,full advantage,strong capability,long distance dependency,supertaggers,full advantage,information,number,equivalence class,eval uation,trigram model,co occurrence dependence,head word,dependent,phrase,nonexecutive director,occurrence,influence,lexical selection,window,head trigram model,lexical selection,su pertags,head word,supertags,interest,performance,traditional trigram model,traditional tri gram model,head trigram model,trigram mixed model,context,current word,supertag,previ ous word,context,previous word accord,mixed model,accuracy,dataset,srinivas,mixed model,accuracy,addition,pairwise voting,accuracy,voting algorithm,application,reranking libin shen,aravind,joshi department,computer,information science university,pennsylvania philadelphia,joshi linc,abstract,voting algorithm,reranking,sequential model,risk formulation, pac framework,voting algorithm,algorithm,parse reranking problem,recall,pre cision, wsj section,penn treebank,many machine,hyperplane,training sample,dis tinct class,margin,ability,margin,reason,superiority,classifier,addition,high perfor mance,input data,high dimensional feature space,kernel,incorporation,sequential model,problem,obvious reason,output,distance,hyperplane,probability,possible solution,problem,result,probabili tie, a s igmoid function,viterbi search,probability,approach,purpose,so-called global optimization1,approach,local feature,left to-right scanning strategy,non generative markov model,quadratic optimization,margin maximization,label bias problem,transition,state compete,transition,lafferty,local normalization,result,label bias problem,discriminative machine,al gorithms,sequential model,generative system,us global fea tures,local feature,lo cal normalization,output,approach,impact,label bias problem,victim,label bias problem,chance,rerank ing,recent year,technique,so-called history-based model,collins,collins,history-based model,current decision,decision,special form,sequential model,generality,collins,algorithm,output,parser,collins,markov random field,boosting approach,collins,schapire,parse reranking problem,tree kernel,collins,number,common subtrees,reranking approach,novel  svm,voting algorithm,alternative way,large margin classifier,sequential model,parse tree,training sample,parse tree,sample,pref erence relation,context,ordinal regression,herbrich,al gorithm,modification,large margin rank boundary,ordinal regression,algorithm,problem, a s hort introduction,section,short introduction,support vector machine,vapnik,definition,yi repre,input vector,d-dimensional space,training sample,hyperplane,hyperplane,hyper plane,training data,margin,sample,margin,non-separable case,positive slack variable,training,problem,lagrange multiplier,total number,training sample,weighting parameter,mis-classification,linearly non-separable sample,kernel trick,separate training sample,high-dimensional feature space,function,d-dimensional input vector,hyperplane,higher-dimensional feature space,stitute,function,kernel function,training phase,following qp problem,test vector,decision function,training vector,la grange multiplier,support vector,total number,support vector,decision function,support vector,function,kernel,well-defined kernel,function,well-defined kernel,mer cer,theorem,vapnik,positive semidefinteness property,discrete kernel,convenient way,function,well-defined kernel,function,kernel,mapping function,method,string subsequence kernel,cristianini,shawe-tayor,tree kernel,collins,large margin classifier svm,large margin classifier,hyperplane,margin,validity,large margin method,theorem,framework2,data error,number,training sample,capacity,learning machine,dimension,vapnik,measure,complexity,hypothesis space,capacity,learning machine,drawback,vc dimension,structure,mapping,sam ples,hypothesis,possible output,learning machine,measure,so-called fat shattering dimension,shawe-taylor,vc dimension,voting al gorithm,family,hypothesis function,dimension,function,margin,maximum number,sample,subset,theoretical accuracy,actual performance,ability,margin,reason,superiority,classifier,sample,margin,func tion,upper bound,expected error,theorem,shawe-taylor,theorem,new voting algorithm,theorem  1 c,real-valued function class,fat-shattering function,learner,example,expected error,new  svm,voting algorithm let xij,jth candidate parse,ith sentence,training data,ith sentence,positive sample,negative sample,experiment,di jkstra,sample,positive sample,negative sample,similar idea,early work,parse reranking,algorithm,collins,sample,margin,score function,parameter vector,collins,parameter vector,function,parameter vector,return,feature vector,sample,defined function,advantage,difference,next section,margin,single parse,sample,extra constraint,selection,decision function,constraint,section,practical advantage,kernel,kernel function,single par,preference kernel pk,preference kernel,context,ordinal regression,herbrich,decision function,distinct par,sentence,ith support vector,total number,support vector,training sample,respect,origin,hyperplane,origin,parallel hyperplane,origin,margin,outcome,hyperplane,origin,therefore,test parse,preference kernel pk,kernel,possible kernel,next section,kernel,linear kernel,tree kernel,collins,feature,linear combination,feature,decision function,feature,vec tor,dot product,kernel,computational complexity,linear kernel,length,vector,goodness,linear kernel,test phase,coefficient,support vec tor,advance,test parse,computational complexity,number,support vector,collins,tree kernel tr,total number,common sub-trees,parse tree,dynamic programming,computational complexity,tree size,test parse,computational complexity,number,support vector,algorithm,kernel firstly,preference kernel pk,suppose kernel,definition,hence kernel pk,margin bound,voting,expected error,voting, pac framework,approach,ordinal regression,key idea,equiva lence,voting risk,classification risk,parse tree,sentence,appropriate loss function,voting problem,parse scoring function,classification problem,loss function,risk rvote,voting problem,risk rclass,classification problem,definition,assumption,sentence,sentence,idd assumption,practice,number,sentence,sentence,idd property,arbitrary pair,sample,theorem,section,following theorem,theorem  2 i gf,training data,confidence,justifying pairwise sample,obvious way,single parse,parse tree,training sample,sentence,positive sample,negative sample,pairwise system,mar gin,sentence,incorrect par,sentence,suppose,function result,sample,constraint,reason,training sample,single par,sentence,format,deci sion function,single par,sample,constraint,coefficient,sentence,hy pothesis space,prior knowledge,different segment,distinct par,elated work,parse tree,preference relation,ordinal regression algorithm,herbrich,object,training sample,exam ple,object,training data,object,sample,preference,preference kernel,herbrich,format,purpose,ordinal regression algorithm,ordinal regres sion search,regression function,ordinal value,algorithm,voting prob lem,result,algorithm,def inition,margin,ordinal regression,margin,regression,ordinal value,algorithm,margin,matsumoto,np chunking task,typical labeling prob lem,deterministic algorithm,collins,algorithm,loss function,feature space,feature,collins,voted perceptron,gorithm,parse reranking,freund,schapire,graepel,error bound,perceptron,margin,training data,algorithm,margin,variant,percep tron algorithm,approximate maxi mal margin classifier,krauth,mezard,gentile,decision hyperplanes,maximal margin,algorithm,accuracy,training,variant,perceptron algo rithm,advantage,large margin,training data, nlp application,sample,kernel trick,margin,method,soft margin,5 e xperiments,analysis, svm light,joachim, svm clas sifier,soft margin parameter,default value, svm light,data set,collins,collins,penn wsj treebank,marcus,train ing data,section,final test,data contains,sentence,distinct par,average,training sentence,sentence,development data,training complexity, svm light,number,training sample,solution,scaling difficulty,kernel fisher discriminant,salomon,train ing data,training,slice con,sentence,slice contains positive sample,neg ative sample,sentence,log likelihood,sentence,average,result,simple combination,cessor,result,subdivision,training data,take advantage,global opti mization ability,effort,new algorithm,new algorithm,following reason,im provement,computing resource,linear classifier,theory,current size, nlp application,text chunking,parse reranking,last reason,state-of-the-art result,linear kernel,tree kernel,linear kernel test,dataset,collins,experiment,distinct slice,svm result,mapping  svm,result,probability, a s igmoid,development data,parameter,result,section,bracket,sentence, 0 c b, 2 c b,percentage,sentence,bracket,collins,sentence,model lr lp cbs  0 c b  2 c b co99,sentence,model lr lp cbs  0 c b  2 c b co99,result,ith  svm,maximal value,experiment,development data show,result,result,log-likelihood,parser,collins,weight,log-likelihood,addition,precision,recall,system,bracket,number,bracket,feature,development data,result,performance,system,result,charniak,result,boosting system,collins,percentage,sen tences,bracket,collins,full advantage,margin maximiza tion,figure,learning curve,figure,development dataset,collins,number,y-axis stand,number,slice baseline,result,section,bracket,collins,sentence,weight,log-likelihood,parser,proper value,depends,training data,result,training data,limitation,local optimization,next experiment,tree kernel,collins,addition,tree kernel,lin ear kernel,experimental result,table  2t,result, svm system,result,voted perceptron algorithm,collins,whole training dataset,6 c onclusions,future work,new approach,sequential model,novel svm,voting algorithm,parse reranking problem,risk formula tion, pac framework,voting algorithm,algorithm,prob lem,linear kernel,tree kernel,accuracy,tree kernel,many unrelated feature,account,linear kernel,feature,large set,possible feature,context-free grammar,feature,current feature,context-free grammar,many useless fea tures,tree kernel sys tems,useful feature,advantage,derivation tree,elementary tree,schabes,basic idea,elemen,segment,derivation tree,algorithm,sequen tial model,supertagging problem,problem,np chunking,rerank,training dataset,feature size,voting problem,acknowledgment,michael collins,data set,anoop sarkar,comment,anonymous reviewer,helpful comment,reference,roukos,towards history,grammar,probabilistic parsing,proceeding,rens bod,grammar,experience,theory,maximum-entropy-inspired parser,proceeding, naa cl,michael collins,nigel duffy,convolution kernel,natural language,proceeding,michael collins,nigel duffy,al gorithms,kernel,discrete structure,voted perceptron,proceeding,michael collins,head-driven statistical model,natural language parsing,thesis,univer sity,pennsylvania,michael collins,discriminative reranking,nat ural language parsing,proceeding,inter national conference,shawe-tayor,introduction,support vector machine,method,cambridge university press,emma dijkstra,support vector machine,parse selection,master,thesis,edinburgh,yoav freund,robert,schapire,mar gin classification,perceptron algorithm,ma chine learning,claudio gentile,new approximate maximal margin classification algorithm,journal,machine learning research,thore graepel,ralf herbrich,robert,williamson,margin,sparsity,advance,thore graepel,klaus obermayer,margin rank boundary,ordinal re gression,advance,large margin classifier,thorsten joachim,large-scale support vector machine,advance,method,schabes,tree-adjoining gram mar,rozenberg,salomaa,editor,hand book,formal language,volume,mezard,optimal stability,neural network,journal,physic,taku kudo,yuji matsumoto,support vector machine,proceeding, naa cl,pereira,condi tional random field,probabilistic model,segmen tation,sequence data,proceeding,ralf herbrich,john shawe taylor,jaz kandola,perceptron al gorithm,uneven margin,proceeding,international conference,machine learning,mitchell,marcus,beatrice santorini,mary ann marcinkiewicz,large annotated cor pu,english,penn treebank,computational linguistics,john platt,probabilistic output,support vector machine,comparison,likelihood method,advance,jesper salomon,simon king,mile osborne,framewise phone classification,support vector machine,proceeding, ics lp,john shawe-taylor,bartlett,robert,williamson,martin anthony,structural risk minimization,data-dependent hierarchy,ee trans,information theory,schuurmans,introduction,large margin classifier,schuurmans,editor,advance,large margin classifier,vladimir,vapnik,statistical learning theory,john wiley,vladimir,vapnik,nature,statistical learning theory,springer,edition, lta g ba,feature,parse reranking,libin shen dept,university,pennsylvania,edu anoop sarkar school,computing science simon fraser university,aravind,joshi dept,university,pennsylvania joshi ci,edu abstract,source,feature,output,statistical parser,notion,tree ker nel,arbitrary sub-trees,derivation tree, lta formalism,ad dition,original definition,tree kernel,feature,labeled recall,precision, wsj section,penn treebank,sentence,length,result,tree kernel,relative difference,score im provement,linear kernel,feature,1 i ntroduction recent work,statistical parsing,al ternatives,maximum likeli hood estimation,parameter,alternative,collins,discriminative method,parse ambiguity,discriminative method,ranking,multiple choice,plau sible parse tree,sentence,particular distribution,stochastic process gener,alternative par,michael collins,experiment,anonymous reviewer,comment,sec ond author, nse rc,feature function,arbitrary aspect,flexibility,feature,fea tures,character,application,feature,n-grams, nlp application,linguistic insight,problem,entire space,gram feature,kernel representation,example,polynomial kernel,se quences,possible n-gram fea tures,introduces,many noisy feature,accuracy,problem,kernel function,particular  nlp application,tree kernel,collins,statistical parsing,addition,n-gram feature,complex high-level feature,accuracy,discriminative model,statistical parsing,ex ample,possible sub-trees,fea tures,collins,sub-trees,mean ingless,source,noisy feature,efficiency,accuracy,arbitrary set,sub-trees,ele mentary tree,lexicalized tree adjoin,schabes,valid set,feature,sub-trees,feature,discontinuous sub-trees,previous tree kernel definition,arbi trary sub-trees,feature,parse reranking problem,collins,collins,algorithm,reranker,tree kernel,derivation tree,extract feature,derivation tree,tree kernel,linear kernel,feature,exper iments,tree kernel,derivation tree,notion,tree kernel,power ful,exicalized tree adjoining grammar,section,brief introduction,lexicalized tree adjoining grammar,detail,schabes,elemen tary tree,elementary tree,possi ble tree structure,elementary tree,initial tree,auxiliary tree,elementary tree,op erations,substitution,adjunction,substitution,initial tree,adjunction,auxiliary tree,addition,adjunction,sister adjunction, lta statistical parser,chiang,combination,elementary tree,derived tree,history,derived tree,elementary tree, lta formalism,exam ple,pierre vinken,non-executive director,derived tree,example, pos tag,elementary tree,sentence,deriva tion tree,history,tree combination,root node,foot node,treebank tree,sister adjunction,sub-trees,sister,derivation tree,elementary tree name,location,parent elementary tree,location,gorn tree address,vinken vp,vp vp join np,board pp,non-executive director figure,parse tree,example,elementary tree,example,property,factor recursion,clause structure,statement,linguistic con straints,constraint,example,derivation tree,example,property,redefined tree kernel,experiment, lta grammar,elementary tree,terminal symbol,frontier,3 p arse reranking,recent year,technique,statistical parser,history-based model,feature,performance,motiva tions,feature,generative model,corporate feature,various kind,rerank,nature,rerank ing,global feature,vinken,derivation tree,elementary tree,analysis,sentence,example,feature,arbitrary sub-trees,parse tree,feature,derivation tree,arbitrary feature,statistical parsing task, wsj penn treebank,performance,positive contribution,convincing test,feature,dataset,dataset,collins,collins,algorithm,markov random field,boosting al gorithm,loss function,feature space,fur thermore,rich feature,limitation,generative model,statistical parsing,collins,voted percep tron algorithm,parse reranking,s0 np00,join010 np011,figure,example,elemen tary tree,unique node address,gorn notation,daughter,first daughter,mean ingless,tree kernel,number,com mon sub-trees,parse tree,feature,tree kernel,fea tures,collins,collins,result,collins, a s vm,rerank,algorithm,preference kernel,reranking problem,distinct kernel,tree kernel,linear kernel,prefer ence kernel, lta g ba,feature,tree kernel,easy way,sim ilarity,parse tree,meaningless sub-trees,consideration,example sentence,example,parse tree,sentence,meaningless sub-trees,number,meaningless sub-trees,misleading measure,good parse tree,number,meaningless sub-trees,number,useful sub-trees,efficiency,accuracy,test data,unwanted sub-trees,hypothesis space,learning machine,expected accuracy,test data,hypothesis,meaningful sub-trees reveal correlation,interest,stochastic model,sub-tree,derivation tree,valid sub-derivation,derivation tree,accurate measure,similarity,motivation,tree kernel,derivation tree,feature,derivation tree,differ ent,feature,dependency graph,derivation tree,many complex pattern,tree name,attachment site,word dependency,traditional dependency graph,example,derivation tree,example,optional modifier,contrast,extra vp node,sub-trees,pp modifier,addition,sub-trees,word vinken,discontin,feature,comparison,collins,collins,new feature,performance,hypothesis,feature,novel set,abstract feature,feature,collins,feature,performance,extracting derivation tree, lta derivation tree,parse tree,consideration,reranker,solu tion,elementary tree,derivation tree,parse tree,n-best statistical parser,training,test data consists,n-best output,collins parser,collins,detail,collins parser,lexicalized context free grammar,statistical model,parse tree,elementary tree,derivation tree,parse tree,terminal sym bol,different word,parse tree,join np-a,director,non-executive director figure,sample output parse,collins parser,parser,derivation tree,substitution,non terminal,sub-trees,derivation tree,adjunction,sub tree,non-terminals,sub-trees,derivation tree,sister adjunction,method,elementary tree,derivation tree,output,algorithm,input parse tree,algorithm,derivation tree extraction,chiang,n-best set,parse tree,chiang,tech niques, lta grammar extraction see,vijay-shanker,using derivation tree,ploy derivation tree,us tree kernel,derivation tree,original definition,tree kernel,abstract feature,derivation tree,linear kernel, svm result,tree kernel,derivation tree, svm result,linear kernel,feature,lso note,root node,foot node,auxiliary tree,vector space,linear kernel,feature,feature,derivation tree,following  lta feature,derivation tree,feature,parent,parent elementary tree,child elementary tree,operation,substi tution,adjunction,sister adjunction,gorn address,parent,feature,exicalized elementary tree,elemen,lexical item,feature,exicalized bigram,bigram,parent,elementary tree,lexicalized tree kernel,collins,notion,tree ker nel,number,common sub-trees,parse tree,parse tree,tree kernel,recursive function,number,ith child,weight coefficient,importance,large sub-trees,bracketing tag,dif ferent number,bracketing tag,collins,lexical item,leaf node,parse tree,decomposition,pattern,vector,lexical information,sub-trees,leaf node,introduction,parameter,lexical information,sub-trees,root node,sub-trees,lexical item,ex ample,decomposition,feature,lexical information lex,lexical ized tree,im mediate child,irrelevant lexicalization,pattern tree,vector,lexical information,lexical item,root node,tree node,lexicalized tree kernel,original recursive func tion,parse tree node,pattern,parse tree node,number,common element,vector,example,element,vector,lexicalized tree kernel,number,common sub-trees,following constraint,root node,new tree kernel,lexicalized tree kernel,lexicalized tree kernel,high dimensional space,tree kernel,collins,important advantage,lexicalized tree kernel,collins,sub-trees,lexicalized tree kernel,pattern tree,lexical item,leaf node,pattern tree,lexical information,result pattern forest,ex periment,sentence,collins,training data,shared structure,number,pattern forest,total number,parse tree,tree kernel,derivation tree,tree kernel,derivation tree,modifica tions,original recursive definition,tree kernel,derivation tree,recursive function,root node,elementary tree,number,initial tree,aux iliary tree,re cursive function,bracketing tag,number,distinct operation,substitution,adjunc tion,substituted child,computation,tree kernel, cfg parse tree,problem,adjoined child,sentence,penn treebank,example,general motor acceptance corp,example,sub-trees,initial tree,number,common sub-trees increase,tree kernel,similar par,sentence,experimental evidence indi,accuracy,therefore,derivation tree,sub-trees,adjunction branch,number,constrained common sub-trees,derivation tree kernel,recursive function dt,derivation tree node,chil dren,original recursive function,derivation tree node,number,common sub-trees,adjunction child,ith adjunct,jth adjunct,tree kernel,derivation tree,well-defined kernel function,definition,new tree kernel,lexicalized tree kernel, lta derivation tree,5 e xperiments,voting algorithm,reranking experiment,preference kernel,parse tree,reranking model,data set,collins,penn  wsj treebank,training data,section,fi nal test,training data contains,sentence,distinct par,average,training sentence,sentence,development data,computational complexity,training,sentence,slice contains,itive sample,negative sample,sen tence,log likelihood,sentence,sample,average,tree kernel  svm,limitation,resource,result,tree kernel,simple com bination,outcome,result,linear kernel  svm,feature,num ber,bracket,collins,parser model,com putation,score sco,output,output,linear kernel,log-likelihood,num ber,bracket, svm system prefers,bracket,result,system,high precision,low recall,number,feature,recall,precision,weight pa rameters,development data,result,sentence,sentence,model lr lp cbs  0 c b  2 c b co99,sentence,model lr lp cbs  0 c b  2 c b co99,result,section,bracket,sentence, 0c b, 2 c b,percentage,sentence,bracket,result,rel ative difference,score improvement,linear kernel,feature,non-trivial improvement,number,bracket,result,benefit,feature,hypothesis,feature,novel set,abstract feature,feature,collins,error reduction,result,dataset,collins,reduction,collins,feature,tree kernel,arbitrary sub-trees,dis tinct slice,result,individ ual  svm,simple combination,overall performance,feature, lta gfi gure,comparison,performance,individual svm,feature,x-axis stand,y-axis stand,improvement,single  svm,several reason,full task,train ing slice,local optimization,global optimization,feature,linear kernel,tree kernel,last reason,importance,feature,shortcoming,kernel method,coefficient,feature,training,herbrich,coefficient,fea tures,6 c onclusions,future work,method,feature,experimental result,feature,improvement,tuned result,fea tures,labeled recall,precision, wsj sec tion,penn treebank,sentence,length,result,sub-tree,deriva tion tree,feature,small set,sub-trees,linear kernel,tree kernel,relative differ ence,score improvement,linear kernel,feature,future work,light-weight machine,al gorithms,training,vari ant,perceptron algorithm,training data chunk,advan tage,global optimization,search,relevant feature,reference,roukos,history-based grammar,probabilistic parsing,efficient implementation, dop model,vijay-shanker,extraction,penn treebank,automatically extracted tree adjoining grammar,convolution kernel,natural language,algorithm,kernel,discrete structure,voted perceptron,head-driven statistical model,natural language parsing,thesis,university,discriminative reranking,natural lan guage,parameter estimation,statistical parsing model,theory,practice,distribution-free method,kernel classifier,theory,schabes,tree-adjoining grammar,rozenberg,salomaa,editor,handbook,mal language,volume,voting algo rithm,application, con ll,vapnik,nature,statistical learning theory,springer,relationship,gram mar,treebanks,natural language,thesis,university,pennsylvania,chinese word segmentation, lmr tagging nianwen xue inst,research,cognitive science university,pennsylvania philadelphia,edu libin shen dept,computer,science university,pennsylvania philadelphia,edu abstract,present chinese word segmentation algorithm,called  lmr tagging, lmr tagger,maximum en tropy markov model,transformation-based learning,result, lmr tagger,opposite direction,system,f-scores,academia sinica corpus,hong kong city university corpus,1 s egmentation,tagging,english text,sentence,se quences,white space,chi nese text,sentence,string,chinese character,similar natural delimiters,first step, a c hinese lan guage processing task,sequence,sentence,mark boundary,appro priate place,reality identifying word,chinese,non-trivial problem,large body,research,chinese language processing community,sproat,automatic word identification,chinese lie,successful resolution,ambi guities,proper way,out-of-vocabulary word,ambiguity,chinese word segmenta tion,differ ent word-internal position,proper context,sentence,position,chinese word segmentation,hanzi tagging problem,machine-learning algorithm,appro priate position,several reason,approach,chinese word,char acters,result,number,position,principle,possible position,substantial number,constrained manner,example,plu ral marker,word-final position,chinese word,new word,number,hanzi stay,new hanzi,position,different tag,left periphery,mid dle,right periphery,approach,word seg mentation,process, lmr tag,sequence,sequence, lmr tag,morpheme,prefix,absence,suffix,absence,distribution,lmr tag,machine learn,algorithm,problem, pos tagging,iob tagging,text chunking,algorithm,algorithm,imple ment,maximum entropy tagger, at ransformation,algorithm,re sults,tagger,maximum entropy tagger,tagging,large set,feature,generative model,maximum entropy markov model,pos tagging,detail,ratnaparkhi, lmr tagger,prob ability model,probability model,possible context,history,possible tag,joint probability,history,workshop,frontier,linguistically annotated corpus,sydney,association,computational linguistics issue,english treebank,propbank  o,babko-malayaa,ann biesa,ann taylorb,szuting yia,martha palmerc,  m itch marcusa,seth kulicka,libin shena  au niversity,colorado malayao,skulick,libin linc,martha,palmer colorado, a bstract,propbank,semantic role label,syntactic constituent,parsed tree,treebank,automatic semantic role label,domain,local ity,predicate,ar guments,principle,practice,propbank annotator,choice,treebank,result,syntactic feature,automatic semantic role label,system,contradictory,mismatch,syntactic bracketing,semantic role,ntroduction,propbank corpus,entire penn treebank,predicate argument structure,semantic role label,syntactic constituent,penn treebank,propbank annotator,possible argument,syntactic structure,parse tree,located constituent,argument label,one-to-one mapping,syntactic constituent,semantic argument,practice,propbank annotator,choice,penn treebank,propbank,penn treebank,syn tax,semantics interface,immedi ate problem,automatic semantic role label,system,semantic role,system,many syntactic feature,parse tree,discrepancy,training data inconsistent,contradictory,detail,mi match,syntactic bracketing,semantic role,source,disagreement,disagreement,manual adjudication,agreement,semantic representation,treebank   t,penn treebank,syntactic structure,syntactic argument structure,rough semantic information,treebank anno tation,part-of-speech tagging,part-of-speech tag,particularly relevant,prop bank work,gerund,verbal part,santorini,syntactic annotation task,constituent boundary,empty category,relationship,constituent,argument adjunct structure,particular subset,adverbial role,syntactic node label,entire constituent,associated argument,modifier,structure,syn tactic movement,sub-constituents,treebank annotation,original position,relationship,co-indexing,example,direct object,entail, whn node,question word,relative clause,journal ist,prepo sitional phrase,riyadh,argu ment,verb sent,position,relative clause,belongs, sb ar node,relative clause con stituent,np-sbj,advp -mnr,mpty subject,move ment,null subject,infinite clause,syntax,null sub ject,infinitive clause complement,syntax,coindexing,semantic coindexing,propbank anno tation,distinction,syntactic argument,adjunct,verb phrase,functional dashtags,structural difference,argument,adjunct,vp node,distinc tion,vp-level modification,s-level modification,constituent,sister,constituent,dashtag,dashtag,modifier,sentence,dashtag,dashtag,dverbial constituent,specific functional dashtag,specific type,annotation sys tem,nside np,argument adjunct distinction,argument constituent, sb ar,head noun,adjunct constituent,head noun,propbank   p ropbank,annotation,predicate-argument structure,structure,babko malaya,propbank annotation,argument labeling,annotation,modifier,co-reference chain,empty category,consistent argu ment label,different syntactic realization,window,example,semantic argument,numbered argument label,verb basis,second task,propbank annotation,functional tag,modifi er,manner,discourse con nectives,purpose,direction,others,propbank annotation,antecedent,argument,subject,example,treebank,propbank,empty catego ries,sentence,co-reference, r el,  a rg0,following section,propbank annotation result,structure,certain respect,treebank structure,section,present,approach,difference,tween treebank,propbank,respect,third task,empty category,antecedent,section,introduces mi match,syntactic constituency,tree bank,propbank,mismatch,future work,2 c oreference,syntactic chain,ropbank chain,syntactic chain,treebank,nominal semantic coreference,coreferring np,syntactic antecedent,example,propbank guideline,treebank,what-1,uch chain,movement,subject,object con trol,instance,syntactic antecedent,ex ample illustrates,subject,infinitival verb,gerund,antecedent,sentence,syntactic chain,politician, a rg0,choose  g,propbank,semantic argument,tween empty category,coreferring np,difference,treebank,prop bank annotation,prop bank annotation,propbank annotator,struct syntactic chain,tag empty cate gories,argument,example,new approach annotator,arg1 argument,what-1,second stage,syntactic chain,coindexation,treebank,coreference annotation,resource,antecedent,empty category,empty subject,infinitival verb,gerund,  o ne,advantage,approach,different type,result,syntactic movement,coreference,direct coreference chain,example,semantic type link,indi rect,empty category,antecedent,yntactic chain,treebank,annotation,direct coreference chain,treebank,category,treebank,semantic type link,relative clause,coindex link,antece dent,empty category,entity,certain kind,rela tionship,example,relative clause,answer,treebank,object,relative pronoun,original propbank annotation,relative pronoun,semantic type,answer,answer rel,additional link,answer,many application,preference,semantic type,verb argu ments,new annotation scheme,annotator,label trace,ar guments,propbank annotation,next stage,relative pronoun,addition,direct coreference chain,identity relation,coindexed element,illustrate,coreference chain,many sen tences,direct speech,clause,utterance,problem,treebank,propbank annotation,treebank,original annotation style,trace coindexed,ar gument,syntactic movement,musical act,new record label,reebank annotation,propbank,different piece,utterance,musical act,new approach,tree bank annotation,clause,empty category indi,ellipsis,propbank annota tor,null element,coreference,special tag,3 d ifferences,syntactic constituency,extraction,mismatch,propbank,treebank,necessary change,treebank,propbank,instance,mismatch,method,argu ment location,discontinuous argument, a rgument location,parse tree,syntactic structure,sentence,semantic argument occupies specific syntactic location,subject position,verb complement location,predicate,argument,sister node,sister node,predicate,ancestor,propbank argu ments,predicate spine,vp coordination case,ex ample,following case,problematic one,argument pp node,deeply,np node,connection,main predicate verb,example, a p ropbank annotation error,following case,problem,argm pp,sister node,predicate verb,vp coordination structure,basket,expensive market,iscontinuous argument,prop bank annotator,several treebank constituent,continuous argument,different opinion,propbank,treebank anno tators,interpretation,sen tence structure,example,following case,prop bank,disagreement,tachment, a t reebank annotation error,region,necessary mechanism,accounting item,accounting item, a ll,example,following category,one-to-one mapping,attachment ambiguity,mismatch,treebank,propbank constituent,result,biguous interpretation,common ex amples,modifier attachment ambi guities,pp attachment,biguous interpretation,manual adjudication, p p-at tachment,typical case,pp attachment annotation disagreement,letter,write arg1,letter arg2,mary  i,propbank,disagreement,cludes,argument,frameset,writer,   a rg2,beneficiary  e xamples,modifier attachment ambiguity,many case,mi match,directional adverbial,tree bank,adverbial, ad vp,argument,question,propbank,separate argm-dir,everything,treebank annotation,argm-dir,example,propbank annotation,treebank,sentential complement,significant mismatch,treebank,propbank annotation,tential complement,infinitival clause,small clause,treebank annotation,sentential com plements,example,treebank annotation,sentence,sentential complement,market active un der,subject,clause,subcon stituent,separate argument,market,djp-prd ,keep arg1,market arg2,active  i propbank,important criterion,argument,argument,terpretation,argument,example,perception,intensional verb,others,clause,causative verb,perception,proposition,intensional verb,entitle,proposition,argument,criterion,argument,syntactic consideration,propbank,example,treebank,evidence,syntactic category,argument,decision process,small clause,clausal argument,small clause,finite clausal complement,non-finite clausal comple ment,small clause complement,np-sbj,obligatory nature,secondary predi cate,construction,deci sion,small clause,example,obligatory part,sentence,sen tence,different sense,infinitival clausal com plements,distinction,single argument,np object,argument,original treebank policy,criterion,np object,infinitival argument,  r esultative construction,source,mismatch,treebank,small clause,propbank annotation,treebank,number,small clause,certain verb,resultative structure annotation,mismatch,sentential complementation,treebank policy,s-clauses,propbank,clause,separate argument,mismatch,verb-by-verb basis,propbank,consider,argument,argument,treebank,analysis,label verb,small clause analysis,structure,structure,label verb,ex ample,parent,structure,treebank,propbank requirement,label verb,syntax,semantics,example,important feature,prop bank,treebank annotation,phrasal,  p ropbank,phrasal verb,others,separate predicate,semantic role,separate propbank entry,tree bank,phrasal verb,second part,phrasal verb,verb particle combination,treebank,propbank annotator,treebank la,second part,phrasal verb,prepositional phrase,inconsistency,japanese institutional investor,semiannual payment,vestment,investment,ropbank annotation,   a rg1,investment,separate predi cate,propbank,conjunction   i,propbank,clause,argument,parallel,treebank,example,np john,constituent,tree bank,conjuncts,propbank policy,modifier,example,temporal argm,second con junct,propbank,proposition,become    a rg1,attorney general    a rg0,   p rop2,governor  i treebank,conjoined np,constituent,one-to-one mapping,propbank,treebank,propbank annotation,sentence,proposition,conjoined phrase,argument,corpus,one-to-one mapping,construc tions,treebank annotation,ent syntactic category,constituent,policy,treebank,coindexation link,corresponding constituent,mary-1,chocolates-2,policy,problem,one-to-one mapping,propbank annotator,flower,argument,second like relation,sentence,several type,mismatch,annotation,english treebank,propbank,coreference,syntactic chain,difference,syntactic constituency,syntax,se mantics,mismatch,tree bank decision,syntactic consideration,propbank decision,weight,semantic representation,difference,annotation policy,prop bank,treebank,appropriate way,fourth source,mismatch,annotation error,treebank,propbank,mismatch,cor rection,  r eferences olga babko-malaya,propbank annotation guideline,mpalmer project_pages pbguidelines,ann bies,mark ferguson,karen katz,robert mac intyre,guideline,treebank  ii style,penn treebank project,university,pennsylvania,department,computer,martha palmer,towards ro,high performance word sense disambigua tion,english verb using rich linguistic fea tures,proceeding,international joint conference,schas berger,penn treebank,argument structure,proceeding,human language technology workshop,marcinkiewicz,large annotated corpus,english,penn treebank,dan gildea,paul kingsbury,proposition bank,annotated corpus,semantic role,computational linguistics,svartvik,omprehensive grammar,english language,longman,santorini,part-of-speech tagging guideline,penn treebank project,university,penn sylvania,department,computer,information science technical report ms-cis-90-47,proceeding,conference,empirical method,natural language processing,honolulu,october,association,computational linguistics lta g de pendency,bidirectional incremental construction libin shen bbn technology,com aravind,joshi university,pennsylvania joshi ci,edu abstract,new archi tecture,parsing,bidirectional incremental parsing,novel algorithm,cremental construction,many structure,problem,algorithm,dependency parsing,significant improvement,accuracy,result,data set,1 i ntroduction,phrase,bidirectional incremental,self-contradictory,first sight,left-to-right parsing,context,conventional parsing,meaning,incremental parsing,bidirectional parsing,bidirectional sequential classification method,tagger assigns label,confidence,turn serve,context,operation,bidirectional tagger,result,literature,standard  ptb dataset,method,structure learning,search space,structure learning,con fidence score,search, lta depen dency parsing, tag parsing,problem,high computational complexity,reg ular parsing,algorithm,variant,parsing,word dependency re lations, lta derivation,full-fledged tree,parsing strategy,nat ural language parsing,chart parsing,incremental parsing,input sentence,substring,sen tence, cfg parsing,chart parser,possible structure,po sible cell,partial order,dynamic programming,fragment,hy pothesis,whole hypothesis,conditional independence,sumption,context rep resentation,performance,johnson,tractability,much internal information,hypothesis,design,hypothe s,collins,charniak,del icate balance,expressiveness,tractabil ity,important role,natural language parsing,recent work,incremental parsing,collins,problem,incremental parser,tree structure,left context,access,whole tree,rich context,formation,expense,search,k-best result,parsing,incremental par,search,analysis,complex structure,anal y,conditional inde pendence,assumption,particular approach left-to-right incremental parsing,similar way,major problem,left-to-right approach,structural information,left side,right side,parsing,bidirectional construction natural way,problem,bidirectional search,direction,incremental parsing,greedy search,hypothe,building analysis,furthermore,tree relation,framework,sentence,search,direction,left-to-right parsing,special case,incremental parsing,complex structure,partial analysis,bottom-up information,collins,rich context,partial result,bidirectional labelling,operation,k-best candidate,normal greedy search,effective way,algorithm,parsing,problem,sentence,vertex,neighboring word,section,decoding,training algorithm re,graph-based incremental construction,many structure,problem,algorithm,lexicalized tree adjoining grammar,schabes, lta dependency parser, lta treebank,experimental result, ptb section,lta treebank,accuracy, lta dependency,result,data set,la belling,appropriate evaluation,experiment, lta treebank,derived tree, lta treebank, cfg tree,metric,labeled precision,recall,evaluation,2 g raph-based incremental construction,data structure,problem,dependency,example,hidden structure,symmetric relation,element,ap plication,dependency parsing,input graph,ver tices,hidden structure,vertex vek,vertex vsk,graph-based incremental construction algo rithm,hidden structure,vertex,hypothesized hidden structure,hypothesized hid den structure,operation,hypothesized hidden struc ture,process,con struction,output,opera tion,operation,dependency parsing,incrementality,substructure,building block,right incremental construction,special case,approach,question,construction,operation,example,first step,dependency parsing,dependency label,problem,feature,substructure,operation,context,suppose,weight,feature,next section,parameter,hypothesized hidden structure,beam search,section, a p erceptron,algorithm,collins,parameter,data structure,algorithm,fragment,connected sub-graph,fragment,hypothe,hidden structure,fragment hypothesis,possible frag ment hypothesis,operation,fragment,fragment,fragment,operand,dependency relation,fragment,suppose,fragment,op eration,fragment hypothesis,feature,fragment hypothesis,vice versa,dependency relation,level-0 dependency,level-1 dependency,level-0 dependency,feature,hypothesis,vertex xi,hypothesis,vertex,level-1 dependency,feature,hypothesis,nearby vertex,learning algorithm,level-0 dependency,learning algorithm,data structure,hypothesis,dependency relation,detail,level-1 formalism,reason,page space,conference pa,experiment,performance,level-1 dependency,level-0 dependency,interested reader,detailed description,learning algorithm,level-1 dependency,algorithm algorithm,procedure,building hy,beam width,search,weight vector,op eration,hypothe s,hypothesis,beam search,hypothesis,candidate hypothesis,next step,search,various direction,hypothesis,vertex,example,depen dency parsing,initial value,possible pos tag,single word,possible hypothesis,ini tial hypothesis,whenever,hy pothesis,weight vector,suppose,algorithm  1 i ncremental construction require,beam width,require,repeat,arg max,coursesthe figure,initialization top k-best hypothesis,segment,hypothesis,segment,seg ment,new candidate hypothe s,hypothesis,example,example,dependency,incremental construction algorithm,input sentence,student,course,candidate  pos tag,linear struc ture,level-0 dependency,beam width,fragment,depen dency link,parent,figure,result,initialization,fig ure,result,first step,fragment,course,figure,result,second step,student,figure,result,third step,course,ited space,rest operation,description,function,algorithm,coursesthe figure,step  1d t nn  vbm d cd nn dt nn nn nn cd nn student,coursesthe figure,hypothesis,vertex,initial fragment hypothesis,xi vi con,vertex,candidate op erations,current hypothesis,exist segment,possi ble operation,fragment hypothesis,result,example,opera tion,segment,candidate operation,respect,segment,segment,top candidate,hypothesis,hypothesis,segment,sub-set,top hypothesis,segment,hypothesis,segment,segment,new candidate hypothesis,dt nn  vbm d cd nn dt nn nn cd nn student,course md,figure,step  3a, 2 p arameter optimization,gold standard,initiate,arg max,update,function,seg ment,top candidate,segment,3 p arameter optimization,previous section,algorithm,graph-based incremental construction,weight vector,algorithm, a p er ceptron,algorithm,weight vector,training data,gold standard hidden structure,al gorithm,gold standard hr,search,operation score,algorithm,negative sample,search,positive sample,hypothesis,fragment,candidate hypothesis,operation score,weight vector,candidate,new weight,performance,per ceptron,margin,training,krauth,hypothesis,weight,collins,freund,schapire,algorithm,tag de pendency,new algorithm,dependency, lta g tr eebank,penn treebank,marcus,proposition bank,palmer,treebank,ate various dependency parser,yamada,mat sumoto,magerman,syntactic label,local context,dependency relation, lta gtr eebank reveals,information,follow ing,reason, lta architecture,dependency,propbank, lta g tr,bank extraction,structure, lta g tr eebank,predicate adjunc tion,predicate coordination,dependency relation,approach,struc tures,big problem,general rep resentation,dependency relation,ad junction,coordination,algorithm,nice solution,problem,attach packagesunion,attach attach figure,predicate adjunction, lta g tr eebank, lta g tr eebank,spinal template,projection,lexical item,template,derivation tree,topology,derivation tree,dependency relation, lta dependency,operation, lta gtr eebank,adjunction,co ordination,attachment,substitution,sister adjunction,traditional lta,dependency relation,approach, lta dependency,non-projective relation thanks,operation,adjunction, lta g tr eebank,passive  ecm verb,auxiliary tree,addition,adjunction,many case,discontinuous argument,prop bank,example,propbank,first union,package,customer group,irst union,package,customer group, lta g tr eebank,subtree,derivation tree,figure,special aspect, lta g tr eebank,representation,predicate coordination,figure,representation,following sentence,couldn,resist,soggy loafer,coordination,coord-structure,resist,attach attach coordination figure,predicate coordination continuedstock,attach,attach figure,non-projective adjunction,coord-structure,coord-structures,ambiguity,argument sharing,incremental construction, lta derivation tree,hypothesis,fragment,par tial derivation tree,fragment hypothesis,nearby fragment combine,partial deriva tion tree,partial derivation tree,attachment,root node,adjunction,adjoined subtree,derivation tree,example, ual corp,adjoins,attache,derivation tree,figure,predicate coordination,operation,incremen tal processing,coordinated structure,parent node,left side,structure,resist,conjoin figure,conjunction,s1 s2 m1,mr m2 attach figure,representation,parent,con juncts,coordination,attach ment,sample,figure,feature,section,feature,lta dependency,operation,posleft,posright,attach,adjoin,conjoin,direction,operation,posleft,posright, pos tag,operand,feature, pos tag,lexical item,context,feature,main-node,oper ation,sub-node,parent,main-node,figure,operation,subtrees,right context,flat sen tence,hypothesis tree,right context respec,pos tag,lexical item,feature, lta depen dency,feature,feature,operand,operand,sibling,gold standard  pos tag,feature, pos tag,context,level-1 dependency,feature,root node,hypothesis partial derivation tree,neighborhood,half check,full check feature,grammatical check,example,figure,attache,nothing,right side,right side,half check feature,completeness,right half,rightmost descendant,leftmost descendant,operation,operation,full check feature,discussion,adjunction,conjunction,con ditions,5 e xperiments,data set, lta g tr eebank,training,feature selection,comparison,different model,beam size,experiment,level-0 dependency,system,ac curacy,sentence,sec ond, a x eon,hz processor,level-1 dependency,parser,sentence,level-1 dependency,much improvement,level-0 feature,useful informa tion,specific application,system,dependency parser,accuracy,category description,operand feature,operand,feature,operand feature,operand,feature,addition,feature,sibling feature,main node,feature,standard  pos tag,feature, pos tag,context,feature,tree context,level-1 dependency,feature,context,feature,flat sentence,feature,parent,feature,feature,context,operation model accuracy shen,level-0 dependency,level-1 dependency,experiment, lta g tr eebank dency,number,system,dependency,magerman,example,ya mada,matsumoto,experiment, lta corpus,lta dependency,pendencies,deeper relation,adjunction,non-projective dependency,depen dencies,predicate adjunction,example,figure,explicit representation,predi cate coordination,deeper relation,example,figure, lta dependency con tains,magerman,dependency,explicit representation,predicate coordination,de pendencies,argument,6 d iscussion,approach,fragment,hidden structure,labelling task,problem,interest,graphical model,lafferty,taskar,con struction problem,labeling problem,adjunction,prediction coordination,dis tance dependency, lta dependency,approach,novel alternative,algorithm stem,perceptron training,collins,method,many  nlp task,shallow processing,collins,word alignment,algorithm,algorithm,similar way,algorithm,dependency,hidden structure,distance dependency,hidden structure,linguistic consideration,search strategy,bidirectional depen dency parser,bidirectional cfg parser,rodrguez,selection,deci sion,action,discriminative learning,context information,7 c onclusion,bidirectional incremen tal parsing,new architecture,novel algorithm,graph-based incremen tal construction,algorithm,dependency parsing,deep relation,approach,parser, lta g tr ee bank,experimental result,significant im provement,system,incre mental construction,structure,problem,high computational complex ity,example,machine translation,se mantic parsing,rodrguez,probabilistic mod elling,island-driven parsing,international work shop,maximum-entropy-inspired parser,proceeding,meeting,north ameri,chapter,association,computational lin guistics,collins,incremental parsing,perceptron algorithm,proceeding,annual meeting,association,collins,head-driven statistical model,natural language parsing,thesis,university,discriminative training method,hidden markov model,theory,experiment,perceptron algorithm,proceeding,conference,empirical method,search optimization,approximate large margin method,structured prediction,proceeding,ternational conference,margin clas sification,perceptron algorithm,machine learning,linguistic tree representation,computational linguistics,schabes,tree-adjoining grammar,rozenberg,salomaa,editor,handbook,formal language,volume,head-driven parsing,proceeding,workshop,optimal stability,neural network,journal,physic,pereira,condi tional random field,probabilistic model,segmen tation,sequence data,proceeding,international conference,machine learn,large annotated corpus,en glish,penn treebank,computational linguistics,pereira,case factor diagram,structured probabilistic modeling,crammer,pereira,large-margin training,dependency parser,pro ceedings,annual meeting,association,discriminative framework,bilin gual word alignment,proceeding,human lan guage technology conference,conference,em pirical method,kingsbury,proposition bank,annotated corpus,semantic role,computational linguistics,bi-directional context free grammar parsing,natural language process,artificial intelligence,incremental  lta g pa r,proceeding,human language technology conference,conference,empirical method,bidirectional sequence classification,pro ceedings,45th annual meeting,association,treebank,new resource,incremen,dependency,semantic parsing,language re source,evaluation,statistical  lta g pa rsing,thesis,university,koller,max-margin markov network,proceeding,matsumoto,statistical,pendency analysis,support vector machine,proceeding,conference,empirical method,natural language processing,singapore,6-7 august, afn lp effective use,linguistic,contextual information,statistical machine translation libin shen,jinxi xu,bing zhang,spyros matsoukas,bzhang,smatsouk,abstract current method,lexical feature,machine translation,difficulty,realistic mt task,large number,parame ters,method,con textual feature,problem,state-of the-art hierarchical mt system,fea tures,non-terminal label,non-terminal length distribution,source string context,source depen dency lm,effectiveness,technique,signif icant improvement,strong base line,arabic-to-english translation,improvement,lower-cased  ble, nis t mt,mt08 newswire data,output,chinese-to-english translation,im provements,mt08 newswire data,1 i ntroduction linguistic,context feature,sparse lexical feature,research,method,feature,practical translation task,several prob abilistic model,contextual information,mt decoding,new feature,scalabil ity problem,new model, nis tmt,mt08 data,signifi cant improvement,strong baseline system,previous work,length preference,source side context,broadly,approach,perceptron,online,algo rithm,weight,feature,tillmann,method,lex ical feature,feature weight,substan,large development set,result,tuning,development set,test set,over-fitting,practical use,remedy,syntactic label,small fraction,bi-lingual feature,chiang,chiang,benefit,lexical feature,possible generic solution,lexical feature,large space,bi-lingual feature,open question,approach,single score,likelihood,translation,rich feature,example,maximum entropy,max ent,method,carpuat,itty cheriah,roukos,method,over-fitting problem,ex pense,benefit,discriminative train ing,rich feature,feature space problem,carpuat,hierarchical decoder,feature,single side,feature space problem,complexity,maxent training,a m axent model,ambiguous hierarchical lhs,left-hand side,source side,translation rule,different target side,possi ble label,sample set,indi vidual maxent model,number,feature,number,sample,individual maxent model,global maximum,addition,maxent model,small set,maxent model,ittycheriah,roukos,distribution,training data,training data,test data,competitive perfor mance,addition,filtering method,practical issue,method,real mt task,application,streamed input,new input sentence,document,training,fur thermore,translation,source sentence,source sen tences,maxent model,sentence,translation,sentence,change,maxent model,rich bi-lingual lexical information,practical translation task,approach,approach,simple proba bilistic model,n-gram model,large-scale training,real data,state-of-the art system,speech recognition,unique contribution,efficient statistical model,context information,feature function,practical translation task,ittycheriah,roukos,adaptation,sampling,train ing corpus,advantage,leu  point,general system,contextual feature function,high-level description,feature,detail,feature,section,first feature,non-terminal label,head word,target non terminal,transfer rule,feature,ambiguity,translation rule,bene fit, pos tag,bad target side tree structure,enhancement,target,pendency language model,second feature,length dis tribution,non-terminals,english,language,deep structure,different syntactic structure,complexity,constituent,preference,non terminal,transfer rule,probability distri bution,length,similar idea,length,provided insignificant improvement,crucial difference,approach,length preference,length distribution,non-terminals,smoothed gaussian,improvement consis,third feature,source side context,neighboring word,input span,selection,target,lation,context infor mation,specific technique,context language model,whole training data,constraint,maxent training,fourth feature,structural informa tion,source side,decoder,source,side dependency tree,pendency lm,source,target,translation hypothesis,intuition,likelihood,source struc,evidence,plausibility,translation hypothesis,bad one,experimental setup,string-to-dependency decoder,baseline,reason,strong baseline,validity,improvement,baseline model,state-of-the-art performance,mt evaluation,algorithm,feature,source dependency,natural extension,to-tree model,tree-to-tree model,generality,result,feature,different language pair,papineni,snover,feature,non terminal label,length distribution,source side context,mt performance,source dependency feature,improvement,context feature,original string-to-dependency model,translation rule,string,non-terminals,source side,well-formed dependency structure,target side,well-formed dependency struc ture,single-rooted dependency tree,hiero system,chiang,non-terminal,string-to-dependency model,pendency structure,non terminal,example,source sentence,jiantao zhuyao baohan liang,literal translation,individual word,reference translation,review,single source word,many english word,example,jiantao,review,review,review,review,suppose,source-string-to-target-dependency trans lation rule,figure,constraint,substitution,translation,jiantao,x-1 slot,problem,search space,label system,target side,whole target dependency structure,figure,target,pendency sub-structure,substitution,sub-structure,substitution,unmatched label,practice,soft constraint,penaliz,substitution,unmatched label,new feature,number,time substitu tions,unmatched label,deriva tion,translation hypothesis,feature,translation rule,rule extraction,training example,sub tree,dependency structure, pos tag,head word,non-terminal corresponds,single-rooted tree,target side,substitution,unmatched one,penalty,length distribution,english,length,phrase,syntactic structure,sentence,example,possessive relation,latter,mother,length,translation rule,length distribution,transfer rule,variance,training data,xx jiantao,xx jiantao review x x,baohan xx,zhuyao figure,translation rule,jiantao,jiantao review x x,baohan,nns  vbz nn,zhuyao figure,translation rule,multiple label tion,translation rule,training example,length,source span,frequency histogram,translation rule,histogram, a g aussian distribution,practice,fre quency histogram,variance,length,squared length,translation rule,training,length,source span,non-terminal,i-th occurrence,training,following quantity,variance,length distri bution,translation rule,oc currences,training,smoothing,esti mate,common smoothing method,maximum,gauvain, map distribution,weight,many way,prior distribution,example,non-terminals,individual non terminal type,practice,variance,method,performance,poisson distribution,performance,gaussian distribu tion,penalty,non-terminal,length,source span,method,problem,length bias,rule selection,maximum entropy method,stud y,baseline string-to-dependency system,probability,translation rule,decod ing,sentence context,reality,translation,context dependent,defect,new feature,context language model,motivation,feature,fluence,selection,transfer rule,input span,problem,ex ample,section,source span,rule selection,zhuyao baohan,literal translation,many candidate translation,phrase,example,translation,zhuyao bao han,context-based probability,jiantao,jiantao,source word,source span zhuyao baohan,training data,jiantao,review,third-person singular,consist,context event,training data,context lm,source word,tri-gram probability,right side,source span,implementation,right context lm,training data,rule extraction procedure,3-gram event,left side,right side,partial hypothesis,context lm score,leftmost,rightmost,hypothesis,source context,product,right context lm,new feature,scoring function,please note,approach,approach,dependent rule selection,ittycheriah,roukos,large num ber,feature,weight,maximum entropy method,con text dependency,ngram lm problem,witten-bell discounting,e timation,context lm,benefit,estimation,context lm,new weight,function,source dependency language model,context lm,previous sec tion,source word,current source span,decod ing,source context,source side dependency language model,feature,motivation,advantage,long distance dependency relation,source word,translation theory,string-to-dependency rule,baseline system,dependency-to-dependency rule,dependency-to-dependency rule,record,source string,source dependency structure,figure,amples,dependency-to-dependency rule,string-to-dependency decod,algorithm,baseline,dependency-to-dependency theory,source,target depen dency,chart parsing,source string,source dependency lm score,target side score,procedure,new feature,source side dependency lm,target side,ill-formed source dependency,source dependency lm,source side,bi-lingual training data,witten-bell,source dependency lm score,likelihood,source,xx jiantao,xx jiantao review xx,figure,dependency-to-dependency translation rule,decoder,source dependency tree,dependency model,source side,training data,source dependency tree,frag ments,translation rule,source dependency lm score,measure,translation rule,training data,therefore,source dependency lm score serf,feature,structural con text information,long distance relation,source context lm,struc tural context information,partial dependency structure,source context lm work,look-ahead feature,3 e xperiments,experiment,impact,feature,cumula tive impact,baseline syntactic label,baseline syntactic label,baseline syntactic label,distribution context lm,lower-cased ibm  ble,powell,method,powell,n-best translation,ostendorf, ibm  ble,motivation,improve ment, nis t mt 02-05,training data,arabic-to-english data contain  29m arabic word, 38m en glish word,sakhr-a2e,sakhr-e2a,chinese-to-english data,chinese word,english word, dar pa  gal program,5-gram string lm,english side,parallel data,english gigaword corpus,bulyko,dependency lm,english side,parallel training data,purpose,english side,parallel data,separate model,arabic,arabic training data,chinese training data,source dependency lm,chinese side,chinese-to-english parallel data,good arabic parser compatible,sakhr tokenization,source side,source dependency lm,source dependency structure,well-formedness constraint,source side,procedure,source side constraint,model mt06 mt08 ble u ter bleu  ter,mixed decoding,rescoring, ter percentage score,mt08 arabic-to-english newswire set,string-to-dependency rule,several dependency-to-dependency rule,different source dependency structure,dependency-to-dependency rule,string-to dependency rule,centage score,arabic,chinese-to-english translation re,context lm feature,length feature,syntax label feature,small improvement,condition,feature,significant improvement,baseline,lower-cased  ble,output,improvement,lower-cased  ble,re-scoring,improvement,condition,metric specific over-tuning,source dependency lm,improvement,baseline,possible reason,source,target parse tree,stand-alone parser,compatible structure,source,target side,well-formed constraint,useful transfer rule,bi-lingual parser,paral lel treebanks, nlp community,problem,search space,dependency-to dependency decoding,source dependency information,tech niques,problem,future,4 d iscussion linguistic information,example,syntac tic structure,source language,pre-processing step,phrase-based decoding,shallow syntactic analysis, pos tagging,mor phological analysis,phrasal decoder,syntax-based system,galley,venugopal,non-terminals,translation rule,substitution,gildea,target tree,scoring,translation theory,mar ton,resnik,feature,constituent label,hiero system,chiang,limitation,mer training,feature space,system,problem,model mt06 mt08 ble u ter bleu  ter,mixed decoding,rescoring, ter percentage score,mt08 chinese-to-english newswire set,chiang,online learn,method,crammer,singer,large set,feature, smt system,translation rule,attention,sentence context,carpuat,ittycheriah,roukos,appropriate translation rule,input span,context,put sentence,direct translation model,roukos,context information,neighboring word,maximum entropy model,correct transfer rule,similar technique,hi ero system,model differs,previous work,contextual informa tion,5 c onclusions,future work,contextual feature,hierarchical decoding,non-terminal label,length distribution,context lm feature,significant improvement,chinese to-english translation, nis t mt,state-of-the-art string-to dependency baseline,previous work,robust probabilistic model,contextual information,method,practical translation task,direction, a g aussian model,contextual fea tures,dependency-to dependency method,bi-lingual parser,acknowledgment, gal program,algorithm,minimization,derivative,makhoul,model adaptation,machine translation,speech,proceeding, iee e in ternational conference,acous tic,speech,carpuat,context-dependent phrasal translation lexicon,statistical machine translation,proceeding,machine translation summit,resnik,line large-margin training,structural translation feature,proceeding,conference,empirical method,new feature,statistical machine translation,proceeding,human language technol ogy conference,north american chapter,association,hierarchical phrase-based model,statistical machine translation,proceeding,annual meeting,association,chiang,hierarchical phrase-based transla tion,computational linguistics,crammer,singer,ultraconservative online algorithm,multiclass problem,journal,machine learning research,thayer,scalable infer ence,training,context-rich syntactic model,annual meeting,association,computational lin guistics,computational lin guistics,gauvain,chin-hui lee,posteriori estimation,multivariate gaussian mix tureobservations,markov chain,ee transac tions,speech,audio processing,lexicon model,statistical machine translation,proceeding,conference,empirical method,natural language process,statistical machine translation,lexicalized rule selection,proceeding, col ing ,roukos,direct translation model,proceeding,human lan guage technology conference,north ameri,chapter,association,translation model,proceeding,conference,empirical method,natural language process,taskar,end-to-end discriminative approach,chine translation,annual meeting,association,computational linguistics,resnik,soft syntactic con straints,hierarchical phrased-based translation,proceeding,annual meeting,association,integra tion,diverse recognition methodology,reevaluation,nbest sentence hypothesis,pro ceedings, dar pa workshop,speech,method,automatic evaluation,gildea,parser,language model,statistical machine translation,eighth conference,association,machine translation,efficient method,minimum,function,several variable,derivative,discriminative reranking,machine translation,proceeding,human language technology conference,north american chapter,association,weischedel,ew string-to-dependency machine translation algo rithm, a t arget dependency language model,proceeding,annual meeting,association,makhoul,translation edit rate,human annotation,proceeding,association,machine translation,discrimina tive global training algorithm,annual meeting,association,computational lin guistics,computational lin guistics,efficient two-pass approach,proceeding,hu man language technology conference,north american chapter,association,chinese syntactic reordering,statistical machine transla tion,proceeding,conference,em pirical method,natural language processing,proceeding,45th annual meeting,association,computational linguistics,prague,czech republic,association,computational linguistics,learning,lshen bbn,com giorgio satta dept,university,padua i-35131 padova,aravind,joshi department, cis university,pennsylvania philadelphia,edu abstract,guided learning,new learning framework,bidirectional sequence classification,inference,local classifier,single perceptron,algo rithm,algo rithm,error rate,standard  ptb test set,relative error reduction,result,data set,feature,1 i ntroduction many  nlp task,sequence clas sification problem, pos tagging,chunking,incremental parsing,traditional method,problem,whole task,individual task,put sequence,small task,fixed order,previous small task,later task,maxent markov model,example,method,lafferty,approach,called label bias problem,general solution,sequence,undirected graph,individual task,taskar, crf method,large margin method,gold standard sequence la,incorrect labellings,com plexity,quadratic programming,large mar gin approach,large scale  nlp task,collins, a p erceptron,algorithm,sequence classification,traditional left-to-right order,solution,label bias problem,undirected method,perceptron,algorithm,upon collins,algorithm,bidirec tional searching strategy,context information,little extra cost,bidirectional strategy,main problem,inference,tsu ruoka,tsujii,easiest-first ap proach,computation com plexity,inference,accuracy,labeling,easiest-first approach,heuristic rule,inference,training,maxent clas sifier,individual labeling,novel learning frame work,learning,classifi cation,individual token,inference order selec tion,single learning task,ceptron,algorithm,collins,algorithm,tagging,clas sic sequence learning problem,system,error rate,standard  ptb test set,error reduction,previous best system,toutanova,fea tures,deterministic search,error rate,relative error reduction,deterministic algorithm,tsu ruoka,tsujii,new  pos tagger,toutanova,tsuruoka,tsujii,context feature,bidi rectional search strategy,algorithm,percep tron learning,collins,integration,individual clas sification,inference order selection,learning,bidirectional labeling,example,bidirectional labeling,inference algorithm,learning algorithm,example,suppose,input sentence agatha,w1 w2 w3 w4 w5,ambiguity,determiner,preposition,conjunction,penn treebank,interesting,correct label,bidirectional inference,sample,suppose,beam search,window,con text feature,first step,hypothesis,example,label vbn,favorable action,candidate hypothesis,assignment,con text feature,hy potheses,fa vorable label,w1 w2 w3 w4 w5,second step,favorable ac tion,assignment,label jj,context,hypothesis,span book interesting,favorable label,interesting,context,w1 w2 w3 w4 w5,label  vbd,tagged span,w1 w2 w3 w4 w5,next step,suppose,label dt,context,right side,favorable action,w1 w2 w3 w4 w5,last step,label  nnp,agatha,out-of-vocabulary word,context, vbd dt,w1 w2 w3 w4 w5,simple example,advantage,flexible search strategy,hypothesis,candidate,dynamic programming,question,formal definition,inference algorithm,next section,input sequence,al gorithm,hypothesis,length,label sequence,hypothesis,context,example,tri-gram model,left boundary,right boundary,hypothesis,outside token,left interface,right interface,right interface,length,right interface,hypothe s,practice,ma trix mp,hypothesis,associated top hypothesis,hypothesis,top state,therefore,hypothesis,hypothesis,action,hypothesis,context,action,subsequence,algorithm  1 i nference algorithm require,beam width,require,accepted span,initialize,candidate span,repeat,update,update,action,hypothesis,top hypothesis,context state,linear function,weight vector,feature vector,algorithm,algorithm,inference algorithm,input sequence,parame ters,beam width,number,vector,action,accepted span,empty set,candidate span,hypothesis consisting,single action,hypothesis,example agatha,book interesting,previous subsection,possible  pos tag,w4 book,recent action,hypothesis h441,sign nn,action,feature,local context,action,example,left word,feature,neighboring tag,initialization,operation,solved tag,algorithm,whole sequence,detail,action,hypothesis,labeling action,next move,removed span,con text,new candidate span,accepted span,context,different state,previous example,w4 book,w5 interesting,candidate span,hypothesis,recent action,con text hypothesis,context,hypothesis,action,left context state,hypothesis,possible  pos tag assignment,possi ble state combination,neighboring span,score action,assignment,feature,action h251,left tag  vbd,right tag nn-jj,detail,feature func tions,section,example,feature,hypothesis score,beam width,top hypothesis,hypothesis,action score,new candidate span,state con,hypothesis,multiple hypothesis,example,dt-nn-vbd-dt-jj,dt -nn -vbn dt-jj,interface dt-nn,depends,valid candidate,accepted span,algorithm,new span,overlap ping span,number,algorithm performs,iteration,run ning time,length,input sequence,learning algorithm,section,guided learning,ceptron,algorithm,weight vector,algorithm,gold standard hypothesis,input sequence xr,gold standard sequence,inference algorithm,next move,algorithm,top hypothesis,gold standard,algorithm,weight vector,perceptron style,fea tures,gold standard action,feature,action,top hypothesis,updated weight vector,element,hypothesis,possible span,context span,action score,updated weight vector,special aspect,algorithm,action,confidence,next move,hypothesis,overall quality,partial result,selection,next action,action,hypothesis,hypothesis,top partial result,soundness,guided learning algorithm,aspect,algorithm,weight update,incorrect state,action score,action,gold standard action,algorithm  2 g,learning algorithm require,training sequence pair,require,beam width,iteration,load sequence xr,gold labeling,initialize,accepted span,initialize,candidate span,repeat,promote,re-generate,gold standard action,next step,top hypothesis,action,favorable action,weight,second aspect,action score,gold standard hypothesis,oth er,hypothesis,corresponding span,algorithm,reason,context hypothesis,gold standard hypothesis,hypothesis,respect,equation,context hypothesis,gold standard hypothesis,gold standard,positive sample,negative sample,weight,stochastic approximation,gradient,squared error,sample,widrow,algorithm,strategy,sample,training,framework,learning,reinforcement learn ing,learning,vised learning,inference,partial output,local clas sifier,inference,lo cal classification,learning phase,learning,reinforcement learning,local step,undesirable labeling action,gold standard,approach,generated negative sam ples,negative sam ples,inference,current weight vector,experiment,averaged per ceptron,collins,freund,schapire,perceptron,margin,krauth,performance,work tsuruoka,tsujii,bidirectional pos tagger,inference,easiest-first heuristic,result,left-to right scan,right-to-left scan,inference,training,local classifier,toutanova, a p o tagger,cyclic dependency network,inference,approach,large beam width,ambiguous hypothesis,approach,system,large beam,section,deterministic infer ence,good result,guided learning,search algorithm,perceptron,develop,mechanism,bidirectional search,algorithm,similar work,collins,collins,left-to right search,al gorithm,flexibility,search,addition,treat ment,action,hypoth esis,discussion,section,learning algorithm,collins,search,hypothe si,gold standard,candidate,search,gold standard compat ible hypothesis,future expansion,weight,correspond,guarantee,dated weight,gold standard compatible hypothesis,algo rithm,gold standard compatible hypothesis,weight update,result,sentence,weight vector,gold standard parse,algorithm,weight update,aspect,algorithm, mir algorithm,crammer,singer,cor rect hypothesis,correct order,operation,weight update,aggressive learning,4 e xperiments,guided learning algorithm,experiment,standard data set,ratnaparkhi,collins,toutanova,tsuruoka,tsujii,feature set template error a r atnaparkhi,suffix,experiment,development data,beam width,training,development,test set, pos tag,mrg file,data set,previous work,development,feature,number,iteration,training,experiment, pos tag,ratna parkhi,tag set,learning algorithm,result effect,feature,experiment,effect,feature,template,feature,experiment,beam width,balance,accuracy,guided learning algorithm,development data,4-8 itera tions,training data,error rate,development,different feature,fea ture,ratnaparkhi,prefix,suffix,lexical feature,tri-gram context feature,fol lowing,collins,rare word,ratnaparkhi,feature,sys tem report,error rate,develop ment data set,feature template,ratnaparkhi,bidirectional search,tri-gram feature,bi-lexical feature,prefix,suffix,length,toutanova,tsuruoka,tsujii,error rate,fea ture,final experiment,test data,effect,search,learning strategy,second set,experiment,effect,package,search aggressive,to-r yes,bi-dir yes,bi-dir,experiment,development data search method,strategy,beam width,feature set,experiment,error rate,development data set,l-to-r,bi-dir,search method,aggres,non-aggressive learning strategy,beam width,bidirec tional search,error rate,comparable number,search space,bidirectional search,aggressive learning,sample,aggressive learning,bidirectional ap proach,advantage,left-to-right search,accuracy, pos tagging,result,gold-standard tag,left-to-right search,training,performance,left to-right search,non-aggressive learning,bidirectional search,left-to-right search performs,gold-standard tag,experiment,learn ing,ambi guities,recent work,variant,algorithm,dency parsing,significant improvement,left-to-right non-aggressive learning strategy,comparison,comparison,previous work, ptb test section,tsuruoka,tsujii,collins,guided learning,feature,tsuruoka,tsujii,toutanova,guided learning,feature,learning,feature,comparison,previous work,experiment,system,feature,beam width,number,iteration,training data,respect,velopment data,error rate,test data,deterministic search,error rate,result,data set,toutanova,re sult,relative error reduction,result,feature,experiment,toutanova,crude com pany name detector,feature,significant improvement,per formance,feature,purpose,compari son,feature,framework,5 c onclusions,guided learning,new learning framework,bidirectional sequence clas sification,infer ence,local classifier,single perceptron,algorithm,novel algorithm,error rate,standard  ptb test set,relative error reduc tion,result,toutanova,data set,fea tures,deterministic search,error rate,relative error reduction,deterministic algorithm,tsu ruoka,tsujii,error rate,inter-annotator discrepancy,standard test set, pos tagging,improvement,reference,bottou,orique,apprentissage connexionniste,application,la reconnaissance,pa role,thesis,universite,collins,incremental parsing,perceptron algorithm,discriminative training method,hidden markov model,theory,experiment,perceptron al gorithms,singer,ultraconservative online algorithm,multiclass problem,journal,machine learning research,search opti mization,approximate large margin method,structured prediction,margin classifi cation,perceptron algorithm,machine learning,svmtool,general po tag ger generator,support vector machine,optimal stability,neural network,journal,physic,pereira,conditional random field,probabilistic model,segmentation,sequence data,large annotated corpus,english,penn tree bank,computational linguistics,maximum entropy part-of-speech tag ger,bi-directional context-free grammar parsing,natural language processing,artifi cial intelligence,incremental  lta g pa rsing,bidirectional  lta g de pen dency parsing,koller,max-margin markov network,singer,feature-rich part-of-speech tagging,cyclic dependency network,tsujii,bidirectional inference,easiest-first strategy,sequence data,parser,speech understanding system,technical report,proceeding,columbus,association,computational linguistics a n,string-to-dependency machine translation algorithm,lshen bbn,jxu bbn,weisched bbn,com abstract,novel string-to dependency algorithm,statistical machine translation,new framework,target dependency language model dur,long distance word relation,tra ditional n-gram language model,ex periments,string-to-dependency decoder,point improvement,point improvement,standard hierarchical string-to string system,chinese-english evaluation,1 i ntroduction,recent year,hierarchical method,statistical machine translation,graehl,knight,chiang,palmer,language pair,chinese-to-english translation,state-of the-art hierarchical system,significant advan tage,phrasal system,mt accuracy,ex ample,chiang,hiero system,point improvement,chinese-english evaluation set,start-of-the-art phrasal system,hierarchical mt approach,string-to-dependency model,source side,string,target side,dependency struc tures,target side,dependency structure,large set,non-constituent transfer rule,enable efficient,dy namic programming,dependency language model,long-distance word relation,traditional n-gram language model,target string,comparison purpose,hiero decoder,chiang,baseline,to-dependency decoder,point improvement,chinese-english mt evaluation set,section,dis cuss previous work,hierarchical mt,pendency representation,re search,section,string-to-dependency decoding,section,illustrates,dependency language model,sec tion,implementation detail,mt system,experimental result,sec tion,compare,related work,section,draw conclusion,section,hierarchical machine translation graehl,knight,target tree-to-source-string transducer,translation, xrs rule,right-hand-side,target side,non-terminals,source side,string,galley,string-to-tree model,context-free parse tree,target side,multi-level transfer rule,hiero decoder,chiang,quire explicit syntactic representation,source,target,string,decoding,chart parsing,hierarchical string-to-string model,palmer,interesting figure,dependency tree,sentence,tree-to-tree approach,shieber,sch abes,translation,depen dency treelet,source,target side,decoding,tree transduction,source side depen dency,tree-to-tree model,structural information,tree-to tree model,advantage,string-to tree model,translation accuracy,search space,motivation,desirable trade-off,model capability,search space,dependency structure,rule representation,dependency tree dependency tree,long-distance relation,tween word,sentence,parent word,root word,figure,example,dependency tree,arrow point,parent,example,word find,dependency tree, cfg tree,constituent label,dependency relation,semantic struc ture,sentence,dependency tree,desirable prior model,target sentence,motivation,well-formed dependency structure,so-called well-formed target dependency structure,following consideration,dynamic programming,palmer,restriction,dependency treelet,transfer rule,size limit,high dimensionality,hypothesis represen tation,shared structure,efficient dynamic programming,galley,nt slot,combination,search space,fur thermore,structure,advantage,dynamic program ming,position,dependency tree,rule coverage marcu,many useful phrasal rule,hierarchical rule,representation method,transfer rule,galley,example,english,valid string-to-tree transfer rule,partial constituent,number,technique,galley,artificial constituent node,phrase,interest,bi narization method,many non-constituent rule,example,ex ample,eefe et al,result,method,well-formed dependency structure,coverage,non-constituent rule,dependency structure,flexibility,dependency tree,representation method,constituent,palmer,well-formedness,dependency,dynamic pro gramming,2 s tring-to-dependency translation,well-formed dependency,string-to-dependency grammar,transfer rule,hiero system,chiang,terminal,source language,terminal,source string,target string,dependency structure,alignment,undesirable structure,dependency structure,addi tion,well-formedness requirement,partial decoding result,shared structure,multiple partial result,result,depen dency structure,dependency tree,sub-root,sub-root,depen dency structure,dependency structure,common head,sibling,complete constituent,de pendency structure,structure,meaningful non-constituent structure,example,modifier,dependency struc tures,well-formed structure,system,well-formed struc tures,bottom-up style,description,clear definition,structure,section,formal definition,well-formed structure,combinatory operation,well-formed structure,decod ing,formal definition,framework,dependency lan guage model,example,formal definition,dn represent,parent word id,example,left hand side,course,formalism,multiple nt,dependency,dependency structure,following condition,addition,category,following condition,category,category,right dependent,dependency structure,dependency structure,figure,example,fixed structure,figure,example,structure,figure,ill-formed dependency structure,structure,figure,interestingwill,ill-formed dependency structure,child word,continuous segment,example,well-formed floating dependency structure,operation,well-formed dependency structure,category one,purpose,depen dency structure,sibling,common parent,well-defined entity,constituent,well-formed partial structure,target side,partial dependency structure,pendency structure,bottom-up decoding,solution,category,well-formed dependency structure,category,combinatory oper ations,category,category,certain category operation,corresponding tree operation,dependency structure,category,dependency structure,result,com binatory category operation,meta category operation,unary operation,operation,fixed structure,floating structure,following theorem,definition,theorem  1 a,structure,floating structure,outside word,fixed structure,interesting la la la ra ra lc rc figure,dependency tree,a1  ta,element,result,category,example,fixed structure,floating structure,structure,direction,fixed structure,tree operation,pendency structure,formal definition,figure,opera tions,figure,traditional dependency tree,figure,operation,partial dependency struc tures,parent subtrees,traditional depen dency formalism,fixed struc ture,floating structure,fixed structure,complete sibling,concate nation,fixed structure,structure,floating structure,structure,direction,flex ibility,operation,la la la,la la lc,operation,well-formed structure vantage,various translation fragment,transfer rule,figure,show alternative way,op erations,well-formed structure,structure,bottom-up style,operation,operation,cat egories,convenience,meta category operation,combinatory operation,definition,oper ations,left direction,right direction,definition  4 c ombinatory category operation,soundness,complete ness,category operation,one-to-one mapping,condition,definition,operation,dependency structure,category,completeness,suppose,operation op,furthermore,suppose,dependency tree,red apple,red depend,category,string,da red apple,dapple,theorem,combinatory operation,category,confluence property,result dependency structure,category,dependency tree,category calculation,category,dependency structure,operation,decoding,example,depen dency structure,right adjoins,suppose,structures2,definition,category operation,rule extraction,string-to dependency rule,procedure,chiang,tree structure,target side,string,sentence-aligned bi-lingual training data,erate word level alignment,statistical  cfg parser,english side,training data,extract dependency tree,magerman,heuristic rule, giz alignment,target dependency tree,rule extraction procedure,4-tuples,valid phrase alignment,source phrase,word index,category,example,figure,phrase,alignment3,dependency structure,valid phrase template,valid rule,valid rule tem plate,valid phrase alignment,sub-structure,sub-structure d2,example,figure,valid rule template,ele ments,source,transfer rule,system,previous work,hierarchical mt,galley,chart parsing,dependency,hidden structure,source fragment,parser,source cell,bottom-up style,transfer rule,source side,completed rule,dependency structure,component dependency structure,target dependency structure,hypothesis dependency structure,shared forest,structure, and -3b,vice versa,floating structure,several dependency link,structure,application,component or-structures,or-structure rep resents,alternative  and structure,character,information,up-level and structure,traditional tri-gram language model,leftmost,rightmost,single nt,formalism,nt la bel,dependency structure,left side,right side,information,category,dependency structure,next section,tend category,dependency language model,3 d ependency language model,dependency tree,figure,probability,probability,right side generative probability,left side,wh-as-head,dependency language model,right side probability,dependency language model score,partial hypothesis,bottom-up decoding,information,category,category,dependency structure,right side,right side,category,section,boundary child node,deplm score,detail,4 i mplementation detail feature,probability,source side,target side,probability,target side,source side,word alignment probability,number,target word,number,concatenation rule,dependency language model,discount,ill-formed dependency,feature,system,feature,translation,chiang,concatenation rule,backup,5th feature,number,con catenation rule,translation,sys tem,substitution,dependency struc tures,unmatched category,dis count,substitution,weight optimization,weight,several round,decoding-optimization,k-best result,op timizer,powell,method,optimization,random,weight vector,last iteration,1000-best translation,chiang,3-gram lm score,5-gram lm score,offline,5 e xperiments,experiment,baseline,replication,hiero system,string-to-string mt system,baseline,transfer rule,target side,well-formed dependency structure,str-dep,string-to-dependency system,dependency,hiero system,baseline,string-to dependency model,similar rule extrac tion,algorithm,system,non-terminal label,major dif ference,representation,target structure,dependency structure,string,comparison,contribution,dependency information,papineni,chinese english large track data, ldc corpus,bilingual training data,source target,hierarchical rule,subset,training data,phrasal rule,chiang,english side,subset,5-gram lm,corpus, ldc gigaword corpus,bulyko,weight, nis t mt,model rule,filtered  26m str-dep  27m,number,mixed decoding,rescoring, ter score,test set,number,transfer rule,training data,tuning,test set,constraint,well-formed dependency structure,rule size,little bit,incor porating dependency structure,string-to-dependency rule,baseline rule, ter score,output,string-to dependency system,point improvement,baseline,to-string system,5-gram rescoring,point improvement,improve ment,filtered model,im provement,filtered string-to-string rule,projection,to-dependency rule,depen dency structure,improvement,performance,dependency structure,dependency lm,significant improvement,iscussion,well-formed dependency structure,data structure,previous work,mono-lingual parsing,eisner,mc donald,structure,various translation fragment,training data,operation,mono-lingual parsing,artificial ambiguity,derivation,charniak,two-step string to-cfg-tree translation model,syntax-based language model,translation,target parse,first step,construction,target,complexity,dependency lm model,target word,dependency tree,single-step system,dependency lm,hierarchical mt system, cfg tree,dependency lm,structured lm,long-distance re lations,bottom-up style,left-to-right style,7 c onclusions,future work,novel string-to dependency algorithm,statistical machine trans lation,comparison purpose,hiero system,chiang,fewer rule,point improvement,point improvement,decoding output,chinese-english evaluation,dependency,desirable plat form,linguistic knowledge,future,research,direction,translation,feature,ex ample,propositional structure,palmer,structure,predi cates,argument,acknowledgment, gal program,roger bock,ivan bulyko,mike kayser,john makhoul,spyros matsoukas,antti veikko rosti,rich schwartz,bing zhang,experiment,construc tive comment,reference,makhoul,model adaptation,machine translation,speech,proceeding, iee e in ternational conference,acoustic,speech,yamada,syntax,language model,statistical machine transla tion,proceeding,chiang,hierarchical phrase-based model,statistical machine translation,proceeding,annual meeting,association,chiang,hierarchical phrase-based translation,computational linguistics,syntax-based mt learn,proceeding,conference,em pirical method,palmer,machine translation,probabilistic synchronous dependency insertion gram mar,proceeding,annual meeting,association,ann arbor,michigan,bilex ical context-free grammar,head automaton gram mar,proceeding,annual meeting,association,phrasal cohesion,statistical machine translation,proceeding,conference,empirical method,translation rule,proceeding,human language technology conference,north american chapter,association,thayer,scalable inference,training,context-rich syntactic model,annual meeting,association,computational linguistics,knight,tree transducer,proceeding,human language technol ogy conference,north american chapter,association,chiang,k-best parsing,proceeding,international workshop,statistical decision-tree model,proceeding,annual meeting,association,knight,statistical machine translation,target language phraases,proceeding,conference,empirical method,crammer,pereira,large-margin training,dependency parser,pro ceedings,annual meeting,association,systematic comparison,various statistical alignment model,computational linguistics,minimum error rate training,sta tistical machine translation,erhard,hinrichs,dan roth,editor,proceeding,annual meeting,association,sapporo,kingsbury,proposition bank,annotated corpus,semantic role,computational linguistics,method,automatic evaluation,cherry,de pendency treelet translation,phrasal  smt,proceeding,annual meeting,association,ann arbor,michigan,schabes,synchronous tree ad joining grammar,proceeding, col ing ,makhoul,translation edit rate,human annotation,proceeding,associ ation,machine translation,syntax tree,syntax-based machine transla tion accuracy,proceeding,conference,empirical method,natural language process,chelba,jelinek,syntactic dependency,structured language model,proceeding,40th annual meeting,association,proceeding,conference,empirical method,natural language processing,massachusetts,october,association,computational linguistics statistical machine translation,grammar libin shen,bing zhang,spyros matsoukas,jinxi xu,bzhang,smatsouk,com abstract,modern machine translation practice,sta tistical phrasal,hierarchical translation sys tem,huge set,trans lation rule,bi-lingual train ing data,approach,result,efficiency issue,suffers,sparse data problem,factorized grammar,linguis tic grammar construction,trans lation rule,prob lem,method,advantage, xta g en glish grammar,extraction,factorized rule,various setup,low-resource lan guage translation,consistent sig nificant improvement,state-of the-art string-to-dependency baseline system,bi-lingual training data,1 i ntroduction statistical phrasal,chiang,machine translation system,large set,translation rule,bi-lingual training data,heuristic method,word alignment result,experience, 50m word,engineering challenge,search efficiency,common practice,problem,development set,rule extraction,decoding phrase,real distributed system,strategy,research system,segment,translation,large rule,information,training data,linguist,grammar con struction field,perfect solution,similar problem,answer,grammar,linguist,linguistic structure,template,lexical item,template,family,family,lexical item,template,family,example,hand-crafted grammar,tree adjoin,schabes,malism,grammar,factorization, lta e-tree template,lexical item,factorized,burden,search,sparse data problem,low-resource language translation,factored model,lexical item,occurrence,training,new rule,template family,lexical item,offline,factorization approach,morphological level,previous study,factoriza tion,rule structure,rich  xta gen glish grammar,effect,factorized trans,grammar,various setup,low-resource language translation,low-resource mt suffers,poor generalization capability,lation rule,high-level linguis tic knowledge,generalization,gram mar,consistent significant improvement,papineni,string-to dependency baseline system,bi-lingual training data,compact hand-crafted translation rule,automatic rule,efficient statistical translation model,leverage generic linguistic knowledge,short description,baseline system,section,factorized translation gram mar,section,xta g en glish grammar,extraction,factorized rule,section,implementation,section,experimental result,section,2 a baseline string-to-tree model,baseline,new algorithm,string-to-dependency system,several reason,baseline,syntactic tree structure,target side,linguistic information,second,depen dency structure,structure grammar,string-to-dependency system,state-of-the art performance,translation accuracy,im provement,system,convinc ing,brief description,base line string-to-dependency system,completeness,reader,related information,baseline string-to-dependency model,translation rule,source,target,source side,string rewriting rule,target side,tree rewriting rule,non-terminals,source,non-terminals,decoding phase,non-terminal replacement,decoding,generic chart,algorithm,source side,translation rule,hypothesis tree struc ture,matched span,mono-lingual parsing,special case,generic algorithm,source string,projection,tree structure,figure,example,string-to dependency translation rule,con venience,source,target,upper-cased word represent source,word represent target,non terminal,non-terminal alignment,subscript,figure,top box,source side,bottom box,target side,function word,source language,question,3 t ranslation, a f actorized grammar,example rule,figure,suppose,test segment,source side,source word,example,second rule,figure,translation rule,x1  hat e x2  fun,figure,training data,figure,missing rule,syntactic semantic class,source,target language,validity,hypothesis rule,factorized grammar,generalization problem,addition,translation rule,new formalism,factorized rule,translation rule,lexical item,unlexicalized tem plate,solution,x1   li ke x2,x1 x2 x1   ha te x2,x1 x2 x1   li ke x2   fu n_q,x1 x2 figure,example,string-to-dependency translation rule,x2 vbz x1 x2 x1 x2 vbz x1 x2 x1 x2   fu n_qvb,x2 figure,template,figure,  ha te x2   fu n_q hate,x1 x2 figure,example,missing rule,language,head word,word pair,lexical item, pos tag,original rule,unlexicalized rule template,example rule,figure,lexical item,third rule,resultant template,figure,base form,third person singular present form,penn treebank representation,marcus, xta g en glish grammar,tree template,transitive verb,family,transi tive verb,family,struc tural variation,word class,template family,example,figure,template,lexical item,family,template,lexical item,family,indirection,generalization capability,x1 x2 vbz x1 x2 family transitive_3 x1 x2   fu n_qvb,x2 x1   fu n_pa,template,lexical item,family,figure,replac, pos tag,second template,figure,correct inflection,template,lexical item,indirection,desirable back-off model,template pr,lexical item,suming,good estimate,training data,second generative model,learning,family,related probabil ities,family,target,side linguistic knowledge,section,def inition,family,lexical item,family,distribution,source side,rule tem plate,target side,rule template,back-off conditional model,template,template,lexical item, mle model,training data,smoothed probability,parameter,ex periments,similar way,discussion,factorized model,previous sec tion,sparse data problem,low-resource translation task,training data,learn family,unsupervised learn,hard translation problem,diffi culty,training data,many case,infor mation,example,target language,rich resource,source language,linguistic knowledge,target side,bi-lingual structure,translation model,x-to-english translation task,next section,unsupervised learning,factor,translation grammar,future research, a m ono-lingual grammar,section,x-to-english trans lation,english resource,factorized translation grammar,example,approach,language pair,certain linguis tic resource,figure,family,intersection,word family,lan guages,refine ment,english word family,example,sub-set,english transitive family,template,fam ilies,figure,bi-lingual family,english family,initial value,unsupervised learning,english family,source side information,figure,template,family,word graph,figure,large mono-lingual data,hand-crafted solution,g en glish grammar,large-scale en glish grammar, tag formalism ex,lexicalization,unification-based fea ture,syn tactic,tree database,syntactic database,information,figure,many useful linguistic annota tions,feature, xta g en glish grammar,tem plate,family,individual template,lexical item,family,individual template,addition,english morpho logical lexicon,inflected item,resource,pos tag,inflection,lexical item,application,verb fami,adjective,adverb,family,english word,fam ilies,bi-lingual lexical item,family,association table,section,course,linguistic resource,similar family informa tion,verbnet,kipper,wordnet,fellbaum,5 i mplementation nowadays,machine translation system,decoder,scratch,various module,solution,research purpose,common practice,new translation model,system,effect,new model,example,tree-based model,carreras,collins,phrasal decoder,sub-clause translation, den eefe,knight, a t ag,translation model,fg-based model,possible adjunction operation,result,syntax-based decoder,similar method,new decoder,factorized grammar,string-to dependency rule,combination,template,lexical item,offline mode,rule generation method,knight,procedure,rule extraction phase,string-to-dependency rule,information,available online,vbz x1 x2 family transitive vb,x2 vbd x1 family intransitive,hate open happen figure,template,family, xta g en glish grammar,extracted rule,template,lexical item,delexicalization,figure,lexical item,template,fig ure,template,lexical item,family,target en glish word,english word,family,uni formly,family,sufficient statistic,back-off model,family,fre quent template,lexical item,family,new rule,original one,conditional probability,combined set,frequent tem plate,family,rough approxima tion,exact implementation,new decoder,factorized grammar,template,experiment,approximation,significant improvement,small training data set,template application,fline mode,decoding,optimization algorithm,baseline,de coder,generic chart,algorithm,target dependency tree,source string,optimizer, l-b fgs  algorithm, ble score,n-best hy potheses,devlin,6 e xperiments,low-resource setup,performance,gram mar,low-resource mt setup,sparse data problem,major issue,enough training data,factorized grammar,real low-resource language,low-resource setup,language pair,arabic,newswire,web genre,experiment,section,language,resource,effect,data size,section,section,exam ples,template,arabic-to-english training data,language,arabic-to-english training data contains,target,arabic-english dictionary, 89k item,development set, gal e p4 set,test set,mt system,segment,tes t-2,test set,mt combination system,mod el tun e test,arabic-to-english web baseline,chinese-to-english newswire baseline,chinese-to-english web baseline,experimental result,ble score,document, ble score,document, met eor  score,chinese-to-english training data contains,target, 68k item,development data setup,arabic to-english experiment,chinese-to-english translation,morphol ogy poor language,morphology rich language,arabic-to-english translation,oppo site direction,factor,grammar help,newswire,language,experimental result,condition, ble score,doc uments, ble score,document,system,difficult document,certain percentile evaluation,met eor ,banerjee,system,system,factorized grammar,ble improvement,condition,significance, ble improvement,paired bootstrap, ble improvement,confi dence level,new system, met eor ,training data size,experiment,section,effect,data size,arabic web,experi ments,original arabic-to-english train,target word,sub-sets,whole data set,average  ble improvement,test set,observation,ble improvement,significance test re sults,training,figure,improvement,train ing data,baseline mt model suffers,sparse data problem,training data,reason,improve ment diminishes,full data set,rough approximation,frequent tem,advantage,paradigm,next section,mod el  siz etune,baseline,baseline,baseline,baseline,baseline,experimental result, ble score,document, ble score,document, met eor  score,ent data size,logscale tes t-1 figure,confidence range,factorized grammar, tes t-1,example template figure,arabic-to-english template,interesting one,pronoun,problem,arabic,template,sophisticated solution,tem plate,semi-automatic way,source counterpart,target treelet, xta g en glish grammar,ent data size,logscale tes t-2 figure,confidence range,factorized grammar, tes t-2,generic rule,hand craft translate rule,people,rule-based mt system,7 c onclusions,future work,novel statistical ma chine translation model,factorized structure,translation grammar,sparse data problem,burden,search,im minent issue,popular phrasal,chical mt system,vvb tmp l_1 x1  vv bd x1 tmp l_121 tmp l_31 x1,vbg x1 tmp l_151 tmp l_61 x1 vbn,x1 tmp l_181 tmp l_91 x1  vv bd x1,x1 vbd,x1 x2 vbz x1 x2 figure,arabic-to-english template,transitive verb family,low-resource language translation,x-to-english translation task,case study,method,family informa tion, xta g en glish grammar,extraction,factorized rule,new model,low-resource translation,factorized model,significant improvement,system,bi-lingual training data,various language pair,factorized translation grammar,interesting way,syntactic resource,high potential,future research,meth od,estimation,family,template,lexical item,target linguistic knowledge,nice starting point,unsupervised learning algorithm,factorized representation,discriminative learning,fea tures,template,family,good generalization capability,acknowledgment, gal program3,aravind joshi,scott miller,richard schwartz,anonymous reviewer,approved,public release,opinion,article presentation,au thor presenter,official view,policy,de fense advanced research project agency,department,defense,reference satanjeev banerjee,alon lavie,meteor,mt evaluation,improved cor relation,human judgment,proceeding,annual meeting,association,xavier carreras,michael collins,non projective parsing,statistical machine translation,proceeding,conference,empirical method,natural language processing,singapore,david chiang,hierarchical phrase-based model,statistical machine translation,proceeding,annual meeting,association,steve  den eefe,kevin knight,machine translation,proceeding,conference,empirical method,natural language processing,singapore,jacob devlin,lexical feature,statistical ma chine translation,master,thesis,maryland,christiane fellbaum,editor,wordnet,elec tronic lexical database, mit press,aravind,yves schabes,grammar,rozenberg,salo maa,editor,handbook,formal language,springer-verlag,karin kipper,anna korhonen,neville ryant,martha palmer,extensive classification,en glish verb,proceeding, eur alex,translation mod el,proceeding,conference,empiri cal method,natural language processing,philipp koehn,daniel marcu,statistical phrase,translation,proceeding,human language technology conference,north american chapter,association,computational linguistics,edmonton,canada,philipp koehn,statistical significance test,machine translation evaluation,proceeding,conference,empirical method,natu ral language processing,barcelona,daniel marcu,wei wang,abdessamad echihabi,kevin knight,statistical machine translation,syntactified target language phrase,proceeding,conference,empirical method,natural language processing,large annotated corpus,en glish,penn treebank,computational linguistics,hermann ney,alignment template approach,statistical machine translation,computational linguistics,salim roukos,todd ward,method,automatic evaluation,libin shen,ralph weischedel,new string-to-dependency machine translation,target dependency language model,proceeding,annual meeting,associ ation,spyros matsoukas,ralph weischedel,effective use,contextual information,statistical ma chine translation,proceeding,confer ence,empirical method,natural language pro cessing,lexicalized tree,gram mar,pennsylvania,proceeding,conference,empirical method,natural language processing,seattle,washington,18-21 october,association,computational linguistics,hidden,translation rule libin shen persado,street new york,shen persado,kitchawan road yorktown height,abstract,machine translation system,large set,translation rule,independent event,short paper,novel method,observed generation output,compact hidden model,generalization capability,preliminary generative model,experimental result,point im provement, ter -ble,strong base line,chinese-to-english translation,1 i ntroduction,system,example,chiang,large rule,million,translation rule,system,transla tion rule,dense feature,key statistic,training data,word translation probability,phrase transla tion probability etc,common fea tures,connection,translation rule,translation rule,indepen dent event,sparse feature,watanabe,chiang,extent,problem,feature,appearance,certain frequent word,signifi cant improvement,automatic evaluation metric,sparse feature,plenty,model translation rule,relationship,translation rule,view rule,discrete,unrelated event,ran dom variable,hidden model,generative process,possible generative process,factor ized structure,weighted hypergraphs,fi nite state machine,approach,com pact model,generalization capability,translation rule,training date,work-in-progress,hidden relation,preliminary experi ments,point improvement, ter -bl eu,strong baseline,chinese-to-english translation,grammar,paral lel training data,frequency,bilin gual translation rule,hidden model,translation rule,example,weighted hypergraph,finite state ma chine,convenience,section,meta-rule,translation,hypergraph hr,possible derivation dr,derivation,hyperpath,meta rule,hy pergraph hr,translation rule,share node,meta-rules,hypergraphs,compact model,section,method,feature,compact model,parameter,meta-rules,meta-grammar e,observed translation grammar,probability,translation rule,separability,practice,bottom-up dynamic programming,different rule,share node,meta-rules,underlying relationship,translation rule,by-product,generative model,log-likelihood,translation rule,new dense feature,experi ments,sparse feature,likelihood,translation rule,function,training data,generative model,pre vious work,chiang,ad vantage,discriminative model,individual weight,factor,automatic score,practice,meta-rule,sparse feature,feature value,default value,feature,experiment,system,log-likelihood feature,feature,natural question,binary sparse feature,active feature,meta-rules,translation rule,feature space,meta-rules,connection,trans lation rule,feature value,effect,intuition,posterior probability,meta-rule,posterior,follow,common practice,posterior feature,scaling factor,posterior model,scaling factor,experiment,system,log-likelihood feature,parameter estimation,underlying model,traditional em algorithm,bayesian method,next section,example,hidden model,em algo rithm,parameter,frequency,derivation,expectation step,derivation,probability,maximization step,derivation,proportion,posterior probability,3 c ase study,section,meta-grammars,method,feature,similar technique,state machine,underly ing model,generic model,section,experimental result,section,meta-rules,translation rule,source,target word string, pos tag,source,target side,simplicity,first attempt,special word, pos tag,suppose,hinese-to-english translation rule,qu zhijiage,chicago,translation rule, pos tag,underlying model,erate translation rule, pos tag,trans lation rule,section,translation rule, pos tag,target,generative model,meta-rules, pos tag string,probability,translation rule,product,meta-rule probability,various derivation,underlying model,feature,generative model,trans lation rule, pos tag,example,figure,top box repre,source side,bottom box,target side,word align ments,figure,example,number,source token,translation rule,uniform distribution,example,source side,binomial distribution,variable,continuous word,proba bility,example,probability,chunk nr vv,figure,suppose,target side,p vbz ,figure,probability,first meta-rule,number,source token,number,target token,probability,second one,probability,derivation,source,target side,meta-rule,derivation,split ting,source side,distribution,hyperparameters,em algorithm,sparse feature,meta-rule feature,word alignment,alignment,meta-rule,meta rule,alignment,meta rule,implementation detail,possible meta-rules,translation rule,optimiza tion method,sparse feature,chiang, l-b fgs ,matsoukas,feature space,dimension,purpose,frequency,method,meta-rule feature,meta-rules,number,source side,target side,top k-percentile,meta-rules,meta-rules,feature,test-1 shortcoming,filtering method,feature,positive indicator,low frequency negative indicator,feature,various level,frequency,class feature,3-tuple,number,source,target word,integer part,log2 value,feature frequency,training data,meta-rule feature,class feature,meta-rule feature,class feature,feature,4 e xperiments,experiment,web genre,chinese-to-english translation,training set,parallel sentence, dar pa  bol t mt task,contains,sentence,ref erences,test set,test-1,similar source,sentence,test-2,web part,mt08 eval uation data,baseline system,home-made hiero,style system,baseline rule,con tains,dense feature,sparse feature optimization algorithm, mir recipe,chiang, ter -ble,snover,papineni, t-b score,baseline,system,competitive  ble score,mt08-wb,system,evaluation1,thanks,feature,baseline system,training,system,consis tent improvement,test set,optimization,marginal im provement,limitation,generative feature,meta-rules,bi nary sparse feature,point improvement,advantage,individual meta-rule weight,generative model,proper smoothing,5 d iscussion,case study,section,hidden state,hidden structure,pos tag,example,alternative,unsupervised nt splitting,approach,insight,mono-lingual lin guistic grammar generation,research,effective way,redundancy,grammar,schabes,shieber,sch abes,pioneer work,knight,operation,context,encouraging result,gov iad mig test,meta-level gram mar,parallel operation,shieber,schabes,effort,statistical modeling,well-recognized lin guistic insight,future work,novel method,translation rule,observed generation output,compact hidden model,case study,method,rich rule,feature,hid den model,preliminary experiment, ter -ble,strong baseline,chinese-to-english translation,future work,following aspect,number,source token,semi-supervised learning,hidden model,reordering,non-terminals,struc tural information,lexical model,posterior model,bayesian method,exhaustive translation rule,compact meta grammar,new translation rule,ultimate goal,acknowledgment,anonymous reviewer,valuable comment,haitao mi,martin cmejrek,data preparation,first author, dar pa un der grant hr0011-12-c-0015,opinion,finding con,article presentation,au thor presenter,ofcial view,policy, dar pa,reference abhishek arun,philipp koehn,online,method,discriminative training,phrase,statistical machine translation,proceeding,new feature,statistical machine translation,proceeding,human language technol ogy conference,north american chapter,association,computational linguistics,david chiang,hierarchical phrase-based model,statistical machine translation,proceeding,annual meeting,association,steve  den eefe,kevin knight,machine translation,proceeding,conference,empirical method,natural language processing,singapore,mark dras,meta-level grammar,synchronous tag,translation,paraphrase,proceeding,annual meeting,associ ation,martin cmejrek,bowen zhou,soft syntactic constraint,hierarchical phrase-based translation,latent syntactic distri butions,proceeding,conference,empirical method,natural language processing,aravind,yves schabes,grammar,rozenberg,salo maa,editor,handbook,formal language,springer-verlag,aravind,masako takahashi,tree adjunct grammar,journal,computer,system science,philipp koehn,daniel marcu,statistical phrase,translation,proceeding,human language technology conference,north american chapter,association,computational linguistics,edmonton,canada,daniel marcu,wei wang,abdessamad echihabi,kevin knight,statistical machine translation,syntactified target language phrase,proceeding,conference,empirical method,natural language processing,australia,spyros matsoukas,antti-veikko rosti,bing zhang,discriminative corpus weight estimation,machine translation,proceeding,con ference,empirical method,natural language processing,hermann ney,alignment template approach,statistical machine translation,computational linguistics,salim roukos,todd ward,method,automatic evaluation,carlos prolo,xtag english gram mar,metarule,proceeding,ternational conference,computational linguistics,ralph weischedel,new string-to-dependency machine translation,target dependency language model,proceeding,annual meeting,associ ation,yves schabes,grammar,proceeding, col ing,computational linguistics,helsinki,finland,matthew snover,bonnie dorr,richard schwartz,micciulla,john makhoul,translation edit rate,human annotation,proceeding,association,machine translation,america,isozaki,large-margin training,statistical ma chine translation,proceeding,confer ence,empirical method,natural language pro,automatic grammar generation,different perspective,thesis,university,pennsylvania,string-to-dependency statistical machine translation libin shen,raytheon  bbn technology ralph weischedel,raytheon  bbn technology,novel string-to-dependency algorithm,statistical machine translation,target dependency language model,long distance word relation,traditional n-gram language model,experiment,algorithm,significant improvement,mt performance,state-of the-art hierarchical string-to-string system, nis t mt,system,sentence,flat string,drawback,traditional n-gram lm,long range word rela tions,predicate,argument attachment,translation quality,hierarchical string-to-dependency translation model,dependency lm,n-best output,alternative translation,structural soundness,structured output,dependency tree,dependency lm scoring,transla tion rule,system,target side,dependency structure,target side,well-formed dependency structure,bad translation rule,enable efficient,dynamic programming,flexibility,well-formed dependency structure,structure,large set,non-constituent transfer rule,comparison purpose,baseline,hiero decoder,chiang,state-of-the-art hierarchical string-to-string model,experiment,string-to-dependency decoder,mt performance,moulton street,e-mail,libinshen gmail,moulton street,e-mail,jxu bbn,moulton street,e-mail,submission, 6 m arch,submission,publication,association,improvement, ble score, 2 b leu  point, nis t ar,chinese-to-english newswire test set,section,briefly discus previous approach,section,overview,string-to-dependency translation system,section,complete description,system,formal definition,well-formed dependency structure,operation,key property,section,implementation detail,rule extraction,decoding,dependency lm score,translation rule,experimental result,section,related work,section,draw conclusion,section,phrase-based system,system,sequence,phrase,translation,reordered sentence,translation option,source phrase,prominent feature,system,n-gram lm,quality,translation hypothesis,drawback,system,structural information,output,translation hypothesis,structural soundness,hiero system,chiang,major breakthrough,translation rule,hierarchical manner,source,target side,translation rule,string,hierarchical string to-string model,hierarchical nature,decoder,ability,translation quality,structural relation,predicate,argument agreement,yamada,knight,syntax-based translation model,source parse tree,target string,method,quality,source side parsing,target information,source side analysis,translation model,source parse forest,mt input,translation error,source side analysis,galley,mt model,target parse tree,syntactic structure,target language,galley,approach,tree transducer,graehl,knight,context-free parse tree,target side,knight,coverage,big issue,constituent,translation rule,carreras,collins,string-to-tree mt model,schabes,champollion,translation rule,source string,target elementary tree,hypothesis tree,adjoining operation,nt slot,substitution, lta g-spinal parsing,carreras,collins,constraint,nt slot,adjoining operation,flexible composition,search space,search space,knight,mt model,implementation, a t ag grammar,equivalent tree insertion,explicit adjoining operation,system,search space,sub-trees,nt substitution,many researcher,tree-to-tree approach,shieber,schabes,advantage,structural knowledge,example,palmer,menezes,cherry,tree-to-tree model,rich structural information,output,mt performance,grammar,search space,eisner,necessity,loose transformation,tree-to-tree model,string-to-dependency translation,system,problem, smt approach,respect,dependency lm,long-distance relation,sec ond,well-formed dependency structure,translation hypothesis,effective trade-off,model coverage,complexity,dependency-based translation,language model,system,dependency tree,output,dependency lm,translation hypothesis,described,dependency lm,long-distance word dependency,quality,output,figure,example dependency tree,arrow point,parent,example,word find,purpose,comparison, smt system,n-gram lm,translation hypothesis,feature weight,probability,target,source,probability,source,prior probability,target,sentence,computational linguistics volume,number  4i,function,dependency lm score,target dependency tree,section,dependency lm,traditional n-gram lm,several feature,decoder,section,feature,decoder,well-formed dependency,central question,system design,dependency structure,translation rule,extreme,arbitrary multiple level treelet,palmer,menezes,cherry,translation rule,fragment,parse dependency tree,maximum coverage,translation pattern,suffers,data sparseness,large search space,extreme,constituent,robust model,small search space,many useful transfer rule,system,target side hypothesis,well-formed dependency structure,section,formal definition,trade-off,rule coverage,model robustness,complexity,well-formed dependency struc ture,sequence,sibling,well-formed dependency structure,variety,non-constituent rule,addition,complete constituent,example,translation system,partial constituent,valid dependency structure,well-formed dependency structure,target hypothesis,operation,pendency structure,bottom,weischedel string-to-dependency statistical machine translation,category,undesirable structure,search space,dependency structure,well-formedness requirement,partial decoding result,result,dependency structure,consist,sub-root,complete constituent,dependency structure,structure consist,number,common head,sibling,complete constituent,structure,meaningful non-constituent structure,example,modifier,dependency structure,well-formed structure,system,section,formal definition,well-formed structure,combinatory operation,example,formal definition,understanding,dn represent,parent word id,example,following condition,category,following condition,category,left side,category,represent,right dependent,dependency structure,computational linguistics volume,number  4e,dependency structure,figure,example,fixed structure,figure,example,structure,figure,dependency structure,structure,figure,figure,child word,figure,continuous segment,example,well-formed floating dependency structure,floating structure,element,fixed structure,desirable property,meta category operation,convenience,single category,well-formed structure,figure  2f ixed dependency structure,figure,dependency structure,figure,ll-formed dependency structure,weischedel string-to-dependency statistical machine translation definition  3l,structure,category cat,right side  and,definition,operation,purpose,dependency structure,sibling,common parent,well-defined entity,constituent,well-formed partial structure,target side,partial dependency structure,possible well-formed dependency structure,ill-formed one,bottom,solution,category,well-formed depen dency structure,category,combinatory operation,category,category,certain category operation,corresponding tree operation,dependency structure,cate gory,combined dependency structure,result,combinatory category operation,operation,well-formed dependency structure,operation,well-formed dependency structure,formal definition,figure,operation,figure,traditional dependency tree,figure,operation,partial dependency structure,well-formed structure,well-formed structure,structure,traditional dependency formalism,fixed structure,floating structure,fixed structure,sibling,concatenation,fixed structure,structure,floating structure,struc tures,direction,flexibility,operation,advantage,various translation fragment,transfer rule,figure,show alternative way,operation,well-formed structure,structure,bottom,operation,dependency structure,multiple derivation,various rule,different training sample,flexibility,computational linguistics volume,number  4f igure  5o perations,well-formed structure,figure  6t,derivation,example dependency tree,meta operation,category,meta category operation,category operation,meta operation,unary operation,operation,fixed structure,floating structure,theorem,theorem  1a,structure,floating structure,outside word,condition,structure,condition,condition,fixed structure,condition,condition,fixed structure,weischedel string-to-dependency statistical machine translation therefore,fixed structure,unification,element,result,category,example,fixed structure,floating structure,structure,direction,fixed structure,operation,category,category operation,convenience,category operation,dependency structure operation,meta category operation,combinatory category operation,definition,operation,definition  5c ombinatory category operation,computational linguistics volume,number  4b,definition,dependency structure operation,category op erations,one-to-one correspondence,correspondence,following theorem,theorem  2s uppose,well-formed dependency structure,theorem,sketch,induction,number,dependency structure,operation,category operation,requirement,category represent,ith category operation,dependency structure,operation,soundness,completeness,soundness,completeness,operation,dependency structure,operation,well-formed structure,well-formed structure,well-defined dependency structure,operation,well-defined dependency structure,proof theorem,theorem,well-defined dependency structure,generality,leftmost child,left child,sub-trees,structure,child c1,sub-structures,weischedel string-to-dependency statistical machine translation,implementation,mt system,system,source sub-string,target dependency structure,target side,translation rule,tree grammar,tree grammar,formed structure,concatenation,non-terminal slot,substitution,grammar,substitution,original  tag,takahashi,lta g-spinal,champollion,mt model,carreras,collins,major problem,approach,system,nt substitution,search problem,nt slot,substitution,training data,combina tion,well-formed dependency structure,nt slot,nt slot,well-formed structure,sub-structures,dependency information,translation rule,training data,word-to-word alignment,target parse tree,next section,similar strategy, den eefe,knight, a t ag,equivalent  tig,addition,special rule,neighboring hypothesis,special rule,nt slot,target dependency structure,glue rule,chiang,translation rule,grammar,string-to-dependency grammar,transfer rule,terminal,source language,terminal,target language,source string,target string,dependency structure,alignment,left hand side,source,target,rule extraction,string-to-dependency rule,parallel training data,procedure,chiang,tree structure,target side,string,sentence-aligned bilingual training data,word level alignment,statistical  cfg parser,1 l ater,article,label information,soft feature,single nt type,useful information,soft feature,example,length distribution,training data,detail,computational linguistics volume,number  4f igure  7a,example,rule extraction procedure,example,non-terminal,hierarchical translation rule,english side,training data,extract dependency tree,magerman,heuristic rule,transfer rule,word alignment,target dependency tree,rule extraction procedure,valid span template,source phrase,alignment 2 a,well-formed dependency structure,valid rule template,inference,valid rule template,valid span template,sub-structure,sub-structure d2,figure,inference rule,nt slot,enough word,alignment,grammar,nt slot,source element,previous work,chiang,feature,source,lexical translation probability,conditional probability,extracted rule,jth word,source side,nth word,target side,vice versa,floating structure,several dependency link,weischedel string-to-dependency statistical machine translation,previous work,hierarchical mt,chiang,galley,decoding problem,target dependency tree,hidden structure,decoding,hidden structure,transfer grammar,language model,string n-gram lm,parser,source cell,bottom,transfer rule,source side,completed rule,de pendency structure,component dependency structure,correspond ing nt,target dependency structure,hypothesis,shared forest, and structure,application,component or-structures,alternative and structure,necessary information,hypothesis,level hypothesis,dynamic programming,example,n-gram string lm,decoding,leftmost,rightmost,hypothesis,dependency lm,decoding,state information,boundary information,dependency structure,purpose,dependency lm,structure,next section,category,dependency language model,using dependency lm score,dependency tree,figure,probability,probability,right side generative probability,left side,wh-as-head,wl1 wh-as-head,wh-as-head,formula,sibling word,computation, sto probability,implementation,inside dependency lm probability,practice,right side probability pr,similar way,computational linguistics volume,number  4w,independence assumption,formula,choice,tri-gram model,experiment,trade-off,model robustness,sharpness,training data,dependency language model score,partial hypothesis,bottom,information,category,category,dependency structure,left side,right side,left side,category,furthermore,operation,section,boundary child node,deplm score,using label,transfer rule,formalism,previous section,single non-terminal type,information,training data,example,target dependency structure,training data,information,structure,decoding phase,problem,whole target structure side,sub-structure,sub structure,nt label,penalty,replacement,obvious choice, pos tag,head word,fixed tree,previous example,target structure,mean verb,non-3rd person sin gular present,whole target structure,example,preposition,penalty,system, pos tag,head word,fixed structure,generic label,structure,nt substitution,mismatch,penalty,floating structure,extension,basic formalism,dependency structure,previous section,representation,translation rule,decoder,dependency structure,fixed type,whole structure, pos tag,head word,nt slot,weischedel string-to-dependency statistical machine translation,dependency structure,extra field,dependency structure,hypothesis,detail,feature,source side,target side,log probability,target side,source side,log probability,word alignment,number,target word,number,special rule,section,log probability,log probability,dependency lm,discount,ill-formed dependency,discount,unmatched label,feature,transla tion,fifth feature,number,adjoining,concatenation rule,translation,string lm score,dependency lm score,feature,practice,hypothesis,well-formed structure,derivation,purpose,null dependency structure,operation op,operation,hypothesis,null dependency structure,calculate dependency lm,related word,discount,eighth feature,source,null dependency structure,unde fined operation,example,right floating structure,fixed structure,source,target structure information,translation rule,parser,parse tree,short segment,example,dictio nary item,so-called phrasal rule,null dependency structure,phrasal rule,lexical item,last feature,number,substitution,unmatched label,partial hypothesis,suf ficient statistic,feature calculation,example,lm score calculation,similar exten sion,dependency lm score,nt label,beam search,chiang,speedup,chart parsing,computational linguistics volume,number,computational complexity,length,source sentence,beam width,maximal number,transfer rule,translation grammar,number,empirical result,weight,several round,optimization,k-best result,optimizer,powell,method,optimization,random,weight vector,last iteration,improved result,000-best translation,technique,chiang,tri-gram string lm,output,5-gram string lm,algorithm,weight,baseline,hierarchical string,translation,replication,hiero system,chiang,baseline,target side,well-formed structure,rule extraction,dependency lm,string-to-dependency system,target dependency structure,dependency lm,enhanced str-dep model, pos tag,hiero model,baseline,string-to dependency model,similar rule extraction,algorithm,major difference,representation,target structure,dependency structure,string,comparison,contribution,dependency information,papineni,roukos,snover, met eor ,banerjee,automatic score,crude approximation,translation quality,technique,metric,multiple metric,false conclusion,metric-specific improvement, nis t mt 02-05,training data,arabic-to-english mt,bi-lingual sentence,ten corpus,ssu sac2,chinese-to english mt,bi-lingual sentence,dependency lm,parallel training data,english side,parallel data,separate model,arabic,arabic training data,chinese training data,5-gram string lm,weischedel string-to-dependency statistical machine translation table  1n umber,transfer rule,model arabic-to-english chinese-to-english baseline,english side,parallel data,english gigaword corpus,bulyko,number,transfer rule,training data,tuning,test set,constraint,well-formed dependency structure,rule size,little bit,incorpo rating dependency structure,string-to-dependency rule,baseline, met eor ,system comparison,lower-cased  ble score,decoding output,system,significance, met eor ,paired bootstrap,baseline,confidence level,insignificant difference,baseline,str-dep model decoder,5-gram rescoring,im provements,improve ments, ble improvement,5-gram score, pos label,transfer rule, ble score,average,overall  ble improvement, met eor  percentage score,mt06 arabic-to-english newswire set,model  ble u ter meteor,mixed decoding,computational linguistics volume, met eor  percentage score,mt08 arabic-to-english newswire set,model  ble u ter meteor,mixed decoding,arabic-to-english translation,condition,chinese-to-english task,result, met eor ,new model,translation accuracy,filtered string-to-string rule,projection,to-dependency rule,performance,dependency structure,result,filtered model,many useful rule,structural constraint,tri-gram score,filtered model,little bit,5-gram rescoring,baseline, met eor  score,different performance,difference,source language,tokenization method, met eor  percentage score,mt06 chinese-to-english newswire set,model  ble u ter meteor,mixed decoding, met eor  percentage score,mt08 chinese-to-english newswire set,model  ble u ter meteor,mixed decoding,str-dep,purpose,filtered model,structural constraint,rule filtering,rule size,useful training data,structural constraint,introduction,dependency lm,non-terminal label,rule filtering,related work fox,palmer,menezes,cherry,purpose,word relation,dependency structure, cfg structure,complete constituent,number,technique,rule coverage,galley,artificial constituent node,phrase,interest,binarization method,knight,many non-constituent rule,eefe et al,result,method,charniak,knight,yamada,two-step string-to-cfg-tree translation model,syntax-based language model,translation,target parse,first step,crucial difference,tree-based lm,com plexity,contrast,system,dependency lm,unpromising hypothesis,dependency lm,structured lm,chelba,jelinek,jelinek,motivation,long-distance relation,difference,dependency lm,bottom,mt system,structured lm,difference,long-distance relation,word re-orderings,well-formed dependency structure,data struc tures,previous work,monolingual parsing,eisner, mcd onald,crammer,pereira,structure,defined state,derivation,monolingual parsing,computational linguistics volume,number,derivation,parse tree,spurious ambiguity,derivation,derivation model,eisner,prerequisite,bi-lexical probability model,many derivation model,mt model,motivation,various translation fragment,training data,opera tions,monolingual parsing,artificial ambiguity,derivation,difference,structure,whereas,structure,eisner,direction,formalism,well-formed structure,operation,well-known approach,left raising,operation,string-to-dependency formalism,special case,schabes,source side,string,multi-rooted structure,adjoining operation, lta spinal,champollion,sister adjunction,variant,rambow,shanker,chiang,carreras,collins,schabes,constraint,tree operation,conclusion,future work,article,novel string-to-dependency algorithm,statistical ma chine translation,target dependency language model,long dis tance word relation,decoding,traditional n-gram language model,state-of-the-art hierarchical string-to-string system,string-to dependency system,overall gain, ble score,lower-cased decoding output,dependency,desirable platform,linguistic knowledge,approach,deeper linguistic feature,propositional structure,palmer,gildea,kingsbury,structure,article,predicate,argument,acknowledgment,hr0011-06-c-0022, gal program,opinion,finding,article presentation,author presenter,official view,policy,defense advanced research project agency,department,defense,colleague roger bock,ivan bulyko,mike kayser,approved,public release,spyros matsoukas,antti-veikko rosti,rich schwartz,bing zhang,rabih zbib,experiment,constructive comment,article,mike kayser,manuscript,zhifei li,anonymous reviewer,suggestion,article,reference banerjee,satanjeev,alon lavie,meteor,mt evaluation,improved correlation,human judgment,proceeding,annual meeting,association,weischedel string-to-dependency statistical machine translation bulyko,spyros matsoukas,richard schwartz,long nguyen,john makhoul,model adaptation,machine translation,speech,proceeding, iee ein ternational conference,acoustic,speech,carreras,xavier,michael collins,non-projective parsing,statistical machine translation,proceeding,conference,empirical method,natural language processing,singapore,carreras,xavier,michael collins,terry koo,dynamic programming,perceptron,feature-rich parsing,proceeding,conference,computational natural language learning,charniak,eugene,kevin knight,knight yamada,syntax-based language model,statistical machine translation,proceeding,chelba,ciprian,frederick jelinek,language modeling,computer speech,language,chiang,grammar,proceeding,annual meeting,association,hong kong,chiang,hierarchical phrase,statistical machine translation,proceeding,annual meeting,association,chiang,hierarchical phrase-based translation,computational linguistics,den eefe,kevin knight,machine translation,proceeding,conference,empirical method,natural language processing,singapore,den eefe,kevin knight,wei wang,daniel marcu,syntax-based mt learn,proceeding,conference,empirical method,natural language processing,prague,martha palmer,machine translation,probabilistic synchronous dependency insertion grammar,proceeding,annual meeting,association,eisner,non-isomorphic tree mapping,machine translation,proceeding,annual meeting,association,sapporo,eisner,giorgio satta,bilexical context-free grammar,head automaton grammar,proceeding,annual meeting,association,phrasal cohesion,statistical machine translation,proceeding,conference,empirical method,natural language processing,galley,michel,jonathan graehl,kevin knight,daniel marcu,steve  den eefe,wei wang,ignacio thayer,scalable inference,training,context-rich syntactic model,annual meeting,association,computational linguistics,international conference,computational linguistics,sydney,galley,michel,mark hopkins,kevin knight,daniel marcu,translation rule,proceeding,human language technology conference,north american chapter,association,computational linguistics,graehl,jonathan,kevin knight,tree transducer,proceeding,human language technology conference,north american chapter,association,computational linguistics,martin,mejrek,jason eisner,gerald penn,owen rambow,dragomir radev,yuan ding,terry koo,kristen parton,natural language generation,context,machine translation,final report, jhu summer workshop project,john hopkins university,david chiang,k-best parsing,proceeding,international workshop,parsing technology,vancouver,masako takahashi,tree adjunct grammar,computational linguistics volume,number  4j ournal,computer,system science,aravind,schabes,tree-adjoining grammar,rozenberg,salomaa,editor,handbook,formal language,volume,springer-verlag,berlin,philipp,statistical significance test,machine translation evaluation,proceeding,conference,empirical method,natural language processing,barcelona,philipp,daniel marcu,statistical phrase,translation,proceeding,human language technology conference,north american chapter,association,computational linguistics,edmonton,magerman,statistical decision tree model,proceeding,annual meeting,association,computational linguistics,daniel,wei wang,abdessamad echihabi,kevin knight,statistical machine translation,syntactified target language phrase,proceeding,conference,empirical method,natural language processing,sydney,mcd onald,koby crammer,fernando pereira,large margin training,dependency parser,proceeding,annual meeting,association,liang huang,qun liu,forest-based translation,proceeding,annual meeting,association,minimum error rate training,statistical machine translation,proceeding,annual meeting,association,sapporo,hermann ney,systematic comparison,various statistical alignment model,computational linguistics,palmer,martha,daniel gildea,paul kingsbury,proposition bank,annotated corpus,semantic role,computational linguistics,papineni,kishore,salim roukos,todd ward,method,automatic evaluation,arul menezes,colin cherry,dependency treelet translation,phrasal smt,proceeding,annual meeting,association,rambow,shanker,david weir,d-tree grammar,proceeding,annual meeting,association,computational linguistics,lucas champollion,aravind,treebank,new resource,dependency,semantic parsing,language resource,evaluation,aravind,incremental  lta g pa rsing,proceeding,human language technology conference,conference,empirical method,natural language processing,vancouver,aravind,bidirectional incremental construction,proceeding,conference,empirical method,natural language processing,spyros matsoukas,ralph weischedel,effective use,contextual information,statistical machine translation,proceeding,conference,empirical method,natural language processing,singapore,shieber,stuart,yves schabes,grammar,proceeding, col ing ,international conference,computational linguistics,helsinki,jason eisner,quasi-synchronous grammar,alignment,soft projection,syntactic dependency,proceeding, hlt -na acl wo rkshop,statistical machine translation,snover,matthew,bonnie dorr,richard schwartz,linnea micciulla,john makhoul,translation edit rate,human annotation,proceeding,association,machine translation,america,weischedel string-to-dependency statistical machine translation steedman,syntactic process, mit press,kevin knight,daniel marcu,syntax tree,syntax-based machine translation accuracy,proceeding,conference,empirical method,natural language processing,prague,ciprian chelba,frederick jelinek,syntactic dependency,structured language modeling,proceeding,40th annual meeting,association,yamada,kevin knight,syntax-based statistical translation model,proceeding,annual meeting,association,toulouse,proceeding,annual meeting,association,computational linguistics,bulgaria,august,association,computational linguistics two-neighbor orientation model,cross-boundary global context hendra setiawan,bowen zhou,bing xiang,watson research center,kitchawan road yorktown height,bxiang,abstract long distance reordering,challenge,statistical ma chine translation research,key con textual information,confine,translation unit,orientation decision,anchor,multi-unit chunk,phrase,max imal orientation span,global parameter,local decision,state-of-the-art string-to-dependency translation system,efficacy,pro posal,large-scale chinese-to-english translation task, nis t mt,advanced model, ter improvement,1 i ntroduction long distance reordering,challenge,research,challenge,accurate reordering hinge,ability,global reordering decision,reordering decision,context,multiple translation unit,previous approach,cross-unit contextual information,define translation unit,phrase,phrase-based smt,translation rule,syntax-based  smt,popular dis tortion,reordering model,phrase, smt focus,orientation,imme diate neighboring translation unit,transla tion rule,syntax-based  smt come,strong context-free assumption,confine,cross-boundary contex tual information,reordering model,incorpo rate contextual information,iden tify anchor,region,source sentence,pattern,region,con sistent,word alignment,mul tiple translation unit,anchor,boundary,translation unit,orientation,anchor,two-neighbor,maximal span,next section,mechanism,accurate global reordering decision,following reason,orientation decision,anchor,contrast,one-sided decision,unigram formulation,order formula tion,second,reordering,translation unit,multiple unit,contrast,reordering,individual translation unit,global reordering parameter,underlying local reordering decision,effectiveness, tno model,state-of-the art syntax-based  smt system,lexical translation,introduction,nonterminals, scf rule,degree,generalization,context-free assumption,malism,ability,fluence global reordering decision,cross-boundary context,syntax-based system,ability,accurate global reordering deci sion,contribution,prac tical method, tno model,syntax-based translation,integration,decoding,syntax-based  smt proceeds,bottom-up fashion,top-down parsing,full context,efficient shift-reduce algorithm,accumulation,partial context,bottom-up fashion,process,absence,full context,efficacy,proposal,large scale chinese-to-english translation task,introduction, tno model,significant gain,state-of-the-art string-to dependency  smt system,additional state-of-the-art fea tures,experimental result car, scf g-based  smt system,mod el,system,phrase, smt system,section,formulation,tno model,section,concept,maximal orientation span,section,variant, tno model,different model complexity,sec tion,training procedure,parameter,section,shift-reduce algorithm, tno model,syntax-based smt,section,experiment,result,related work,section,conclusion,section,wo-neighbor orientation model given,possible chunk,anchor,mod el,orientation,anchor,identity,anchor,ambiguous re,pattern,anchor,training data,linguistic analysis,source sentence,experiment,simple heuristic,part-of-speech tag,section,particular anchor,neighbor,right neighbor,j4j3 ei4i3,particular pair,right neighbor,orientationof cl,orientation value,nagata,represent,source,target phrase pair,j2j1 ei2i1,subscript,superscript,starting,sourcephrase,figure,aligned chinese-english sentence pair,circle,alignment point,black circle,anchor,neighbor,first clause,monotone,reverse,target order,source order,intervening phrase,aligned sentence pair,chiang,f77 e77,neighbor,right neigh bors,orientation val ues,neighbor,neighbor,orientation,right neighbor,f66 e99,f88 e55,orientation,anchor,neighboring chunk,orientation,two-neighbor orientation model,following form,conciseness,reference,context,reference,3 m aximal orientation span, tno model,possible pairing, tno model,right neighbor,j2j1 ei2i1,left andthe right  mos,arg max,arg max,example,right mos,anchor,solid line,beyond,computation,key benefit,global parameter,local reordering,cheating exercise,chinese sentence,following set,hierarchical phrases3,aozhou1shi2x1,australia1 is2x1,beihan4x1,x1with3 north4 korea,have5dipl,guojia9 zhi10 yi11,one11of10the few8 countries9 that7x1,hierarchical phrase,trans lation model,local ambiguity,local reordering,lexical mapping,hierarchical phrase,example,cisions,curate global reordering,crucial role,anchor,use hierarchical phrase-based translation system,system,few8 countries9 that7,australia1 is2x1,beihan4x1,few8 countries9 that7,australia1 is2,x1with3 north4 korea,byu3 beihan4,cyou5bangjiao6,one11of10the few8 countries9 that7,australia1 is2,have5dipl,with3 north4 korea,derivation,aozhou1shi2,yu3beihan4x1,x1with3 north4 korea,aozhou1shi2,yu3beihan4,australia1 is2,one11of10the few8 countries9 that7x1,with3 north4 korea,australia1 is2,one11of10the few8 countries9 that7,derivation,correct translation,identifier,alphabet letter,hand side,chor de,superscript,source word,target word,projection,internal word alignment,practice,target word,use index,sub sequent section,possible derivation,dicates,first operand,second operand,derivation tree,application,first derivation,incorrect reordering,correct one,simple example,local decision,accurate,ambigu ity,real translation task,local decision,formation,ambiguity,second derivation, mos gen,incorrect derivation, mos learnt,derivation,informa tion,source sentence,complete translation,word alignment, mos extrac tion procedure,derivation,right  mos,right  mos pre,left  mos,incor rect derivation,left  mos,f61 e61,correct derivation,left  mos,incorrect deriva tion doesn,correct translation,explicit  mos,mechanism,crucial global reordering ambiguity,ability,local model,illustration,cross-boundary context,context-free assump tion,hierarchical phrase-based formalism,full derivation,rule boundary,angle brack,beginning,rule xa,derivation,anchor,boundary,box frame,rule boundary,rule boundary,left  mos,correct derivation,formulation,formulation,tno model,require enumerating,possible pair,decomposition,variant,factor,factor,addi tional feature,log-linear framework,smt system,decomposition,generative story,right neighbor,ble alternative,empirical result,different variant,factor,different probabilistic conditioning,factor,strong independence assumption,description,follow,dependent, pol dependent, por dependent,multinomial distribution,accurate one-sided decision,decision,deficiency,non-zero probability,improbable assignment,orientation value,monotone adjacent,left neighbor,adjacent,right neighbor, mos related information,anchor, tno model training,ent training regime,discriminative,generative,specific,procedure,anchor,corresponding  mos,statistic,extract feature,training data,training,iden tification,region,source sentence,anchor,chinese-english experi ments,anchor,single-word chunk,word class,closed-word class,close resemblance,setiawan,part-of-speech tag,adjective,possible chunk,functionminc,minc return,j2j1 ei2i1,algorithm,j2j1 ei2i1,thechunk,algorithm,right  mos,algorithm,left  mos,anchor,termediate parameter,active search range,training,discrimi native classifier,orientation val ues,normalized posterior,additional feature score,log lin ear framework,classifier,rich set,binary feature,syntactic feature,function,j2j1 ei2i1,chunk output,j4j3 ei4i3,j4j3 i4 i3,j4j3 i4 i3,location,elementary feature,classifier,actual word,parent,parse tree,actual target word,previous word,next word j2,parent,rsparent,parent,lanchorslex,previous anchor,mosl int slex,actual word,ext slex,actual word,mosl int spos,ext spos,mosr int slex,actual word,ext slex,actual word,mosr int spos,ext spos,clas sifiers, mos feature,addition,feature,compound feature,conjunction,lexical,lexical,number,fea tures,compound feature,feature,combination,com pound feature,hundred,million,feature,training data,number,manageable size,l1-regularization,training,force sparse solution,off-the-shelf  lib -li near toolkit,training,number,feature,classifier,feature,classifier,relative fre quency principle,sparsity issue,mosl int spos,ext spos,mosr int spos,condition  pml,ori entation,follow,training data,target string,source index,symbol,xc have5 dipl,application,shift-reduce parsing algorithm,derivation, tno model,syntax-based smt system,mos modeling,method,training,last stage,decision,late application, tno model,utility,section,algorithm,incremental construction,com putation, tno model,partial derivation,close resemblance,shift-reduce algorithm,cumulate,information,derivation,al gorithm,input stream,applies,operation,beginning,stream,shift op eration,input stream,symbol,symbol,re duce operation,reduction rule,topmost element,algorithm ter minates,input stream,parent,later stage,put stream,target string,symbol,source index,element,target string,reduction rule,application,reduction rule,anchor,execution trace,algorithm,derivation,algorithm,empty stack,project,source index,target word,target string,right fashion,target word,source index,shift operation,symbol,anchor,operation,special treatment,anchor,symbol read,entire stack,example,algorithm,entire stack,algorithm,incremental con struction,example,application,current left  mos,algorithm,appli cation,rulexb,partial hypothesis,example, tno model,g-based translation,full derivation,example,orientation value,neighbor,statement,section,neigh bor,orientation value,formal proof,intuition,derivation, scf g-based translation,sub set,f66 e99,consequently,model score,decoding process,7 e xperiments,baseline system,state-of-the-art string to-dependency system,system,parallel sentence, dar pa bol t ch inese-english mt task,training cor pora,mixed genre,newswire,weblog,broadcast news,broadcast conversation,sion forum,various source,un data,baseline model,feature,two-neighbor orientation model,addition,standard feature,tion probability,feature,state-of-the-art base line,provenance feature,chiang,large 6-gram language model,english word,multiple corpus,english side,parallel corpus,corpus,google news,class-based language model,english sentence,parallel corpus,backbone,string-to-dependency system,3-gram model,right dependency,un igram,target side,bi lingual training data,two-neighbor orientation model,subset,aligned sentence pair,tuning,development set,sentence,corpus,weight,hopkins,blind test set,performance, nis t mt,evaluation set,sentence,newswire,sentence,weblog,weight,de velopment,test set,experimental result,nis t mt,newswire,weblog,column,classification accuracy,subset,training data,number,ref erence,feature,classifier,several gold standard information,anchor,target word,anchor,related feature,orientation,right  mos,acc mt08,mt08  wbb leu ter bleu  ter s2d, nis t mt,result,baseline string-to-dependency system,two-neighbor orientation model,ble result, ble score,column, ter score,performance,baseline,to-dependency syntax-based  smt,first line,performance,neighbor orientation model,empirical result,intuition,cross-unit contextual information,condition, ble score,improvement,inclusion,formation,feature,newswire,weblog,improve ment,inclusion,explicit  mos modeling,significant  ble score improvement, ter improvement,newswire,weblog,mixed result,ble score improvement,weblog text,biguous orientation span, tno model,encour,result,advanced model,sig nificant improvement,newswire domain,strong string-to-dependency syntax-based  smt,additional state-of-the-art feature,work intersects,many different respect,section,probabilistic conditioning, tno model, mos modeling, tno model,phrase,process,left-to-right fashion,current phrase pair,orientation,strong independence assumption,phrase pair,original intent,sparsity concern,conditioning,formula,example,various linguistics,part-of speech,dependency information,predicate-argument structure,original formulation, mos concept,galley,manning,phrase-based decoding,respect,multi-block unit,overes,orientation,multi-block unit,data sparsity issue,effort,hi erarchical phrase,syntax-based  smt,syntactic parse constituent,input sentence,chiang,marton,resnik,boundary,training data,boundary,recent work couple,decision,additional feature,hierarchical phrase,chiang,nonterminal label,venugopal,zollmann,vo gel,anchor,function word class,function word-centered model,se tiawan,setiawan,discriminative treatment,feature, mos modeling,incorpo rating global context,costa-jussa,fonollosa,genzel,visweswariah,tromble,eisner,input sentence,target language order,target lan guage order,crucial difference, smt decoder,9 c onclusion,novel approach,long-distance reordering,global cross-boundary contextual information,ap proach, a t wo-neighbor orientation model,joint modeling,orientation decision,modeling,maximal span,reordered chunk,concept,maximal orientation span,version,algorithm,syntax-based  smt system,empirical result,intuition,cross boundary contextual information improves,lation quality,large scale chinese-to-english translation task,significant improve ment,strong baseline,future,research,anchor,linguistics fea tures,dependency structure,strength,modeling,maximal orientation span,acknowledgement,support, dar pa un der grant hr0011-12-c-0015,opinion,finding,arti cle presentation,author presenter,official view,poli cies, dar pa,reference nguyen bach,qin gao,stephan vogel,source-side dependency tree,subtree movement,constraint,proceed ings,canada,august,interna tional association,machine translation,pi-chuan chang,huihsin tseng,dan jurafsky,christopher,manning,chinese grammatical relation,proceeding,third workshop,syn tax,structure, naa cl  hlt,boulder,col orado,association,computational linguis tic,stanley chen,exponential language model,proceeding,human language tech nologies,annual conference,north american chapter,association,compu tational linguistics,boulder,col orado,association,computational linguis tic,david chiang,yuval marton,philip resnik,large-margin training,struc tural translation feature,proceeding,conference,empirical method,natu ral language processing,honolulu,hawaii,october,david chiang,steve  den eefe,michael pust,easy improvement,lexical weighting,proceeding,annual meeting,association,computational linguistics,human language technology,portland,oregon,association,computational linguistics,david chiang,hierarchical phrase-based model,statistical machine translation,pro ceedings,annual meeting,associa tion,ann arbor,michigan,association,computational linguistics,costa-jussa,fonollosa,statistical machine,proceeding,conference,empirical method,nat ural language processing,sydney,australia,association,computational lin guistics,rong-en fan,kai-wei chang,cho-jui hsieh,xiang rui wang,chih-jen lin,large linear classification,journal,michel galley,christopher,manning,effective hierarchical phrase,proceeding,conference,empirical method,natural language process ing,honolulu,hawaii,october,sociation,computational linguistics,dmitriy genzel,source side reordering rule,large scale machine trans lation,proceeding,international conference,computational linguistics,coling,beijing,august,organizing committee,mark hopkins,jonathan may,ranking,proceeding,conference,empirical method,natural language process ing,edinburgh,association,computational linguistics,zhongqiang huang,martin cmejrek,bowen zhou,soft syntactic constraint,hierar chical phrase-based translation,latent syntac tic distribution,proceeding,con ference,empirical method,natural language processing,octo ber,association,computational linguistics,philipp koehn,hieu hoang,alexandra birch,chris callison-burch,marcello federico,nicola bertoldi,brooke cowan,wade shen,christine moran,richard zen,chris dyer,ondrej bojar,alexan dra constantin,evan herbst,open source toolkit,statistical machine transla tion,yuval marton,philip resnik,soft syntac tic constraint,hierarchical phrased-based trans lation,proceeding,annual meet ing,association,computational linguis tic,human language technology,columbus,masaaki nagata,kuniko saito,kazuhide yamamoto,kazuteru ohashi,clustered global phrase,statistical machine translation,proceeding,interna tional conference,computational linguistics,annual meeting,association,compu tational linguistics,sydney,au tralia,association,computational linguis tic,jan niehues,muntsin kolss,os-based model,long-range reordering,pro ceedings,fourth workshop,statistical ma chine translation,athens,greece,association,computational linguistics,hendra setiawan,min-yen kan,phrase,function word,proceeding,45th annual meeting,sociation,computational linguistics,prague,czech republic,association,computational linguistics,hendra setiawan,min yen kan,philip resnik,topological ordering,function word,hierarchical phrase-based translation,proceeding,joint conference,nual meeting,international joint conference,natural language processing, afn lp,suntec,singapore,august,association,computational linguistics,libin shen,ralph weischedel,new string-to-dependency machine translation,gorithm,target dependency language model,proceeding,columbus,association,computa tional linguistics,libin shen,spyros matsoukas,ralph weischedel,effective use,contextual information,statistical ma chine translation,proceeding,con ference,empirical method,natural language processing,singapore,august,asso ciation,computational linguistics,christoph tillman,unigram orienta tion model,statistical machine translation,hlt -naa cl,short paper,boston,massachusetts,may  2 m,asso ciation,computational linguistics,christoph tillmann,tong zhang,block bigram prediction model,speech,jason eisner,problem,translation,proceed ings,conference,empirical method,natural language processing,singapore,august,association,computational linguistics,ashish venugopal,andreas zollmann,stephan vogel,preference grammar,softening syntactic constraint,statisti cal machine translation,proceeding,human language technology,annual confer ence,north american chapter,associa tion,computational linguistics,boulder,colorado,association,computa tional linguistics,karthik visweswariah,rajakrishnan rajkumar,ankur gandhe,ananthakrishnan ramanathan,jiri navratil,im proved machine translation,proceeding,conference,empirical method,natural language processing,edinburgh,association,computational linguistics,deyi xiong,min zhang,syntax-driven bracketing model,phrase,translation,proceeding,joint con ference,47th annual meeting,international joint conference,natural language processing, afn lp,suntec,singapore,august,association,computational linguistics,deyi xiong,min zhang,translation boundary,phrase-based decoding,human language technology,annual conference,north american chapter,association,computational lin guistics,los angeles,california,association,computational linguistics,deyi xiong,min zhang,translation,predicate-argument structure,proceeding,50th annual meet ing,association,computational linguis tic,volume,long paper,jeju island,association,computational linguistics,richard zen,hermann ney,discrimina tive reordering model,statistical machine trans lation,human language technology confer ence,north american chapter,associ ation,computational linguistics,proceeding,workshop,statistical machine translation,association,computational linguistics,andreas zollmann,stephan vogel,word class approach,pscfg rule,machine translation,proceeding,annual meet ing,association,computational linguis tic,human language technology,oregon,association,com putational linguistics