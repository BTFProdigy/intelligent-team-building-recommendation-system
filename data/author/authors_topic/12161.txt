proceeding,human language technology conference, naa cl,companion volume,new york city,association,computational linguistics aut omated  qua lity  mon itoring for call  cen ters  usi ng  spe ech and nlptechnologies,watson research center,yorktown height,abs tractth,automated system,qual ity score,call center conversation,system com bine speech recognition,pattern matching,maximum entropy classification,quality,spectrum,human monitoring,process,asr transcript,standard quality control question,agent use courteous word,phrase,question-based score,probability,maximum entropy,feature,max imum silence length,occurrence,n-gram word sequence,system,associated manual evaluation form,present precision,recall result,amount,effort,system,number,bad call,current policy,randomly sam,application,research prototype,conjunction,million,help-desk call,call center,typical call center operation,random sample,human monitor,respect,variety,quality,question,account,agent request error,message,problem,problem,agent maintain appropriate tone,volume,process suffers,number,important problem,monitoring,double,opera tor,monitor,second problem,small sample,fraction,percent,third problem arises,random sampling,human monitor,quality-monitoring system,problem,automatic speech recognition,call center,default quality score,feature,key-words,key-phrases,number,hesitation,average silence duration,default score,worst-to-best,sorted list,human evaluator,a-priori reason,something,automatic quality-monitoring problem,variability,ques tions,question,agent use courteous word,phrase,key word,phrase,others,human-level knowledge,example,com pany,monitor,question,ownership,ques tions,call-quality,variability,approach,partial score,subset,question,maximum entropy classifier,feature,probability,belonging,approach,final result,interpolation,result,fixed amount,effort,number,bad call,triple,call-ranking approach,significant previous scholarly research,automated call-routing,classification,automated quality monitoring,speech recognition system,mono audio data, ibm call center,tran scribed,speaker turn,word tran scriptions,corresponding time,speaker change,training data,forced-alignment,speaker boundary,test set,speaker,speech,speaker independent system,raw acoustic feature,segmentation,recognition,feature,segmentation,manual incremental,manual adaptation,automatic incremental,segmentation clustering,adaptation type,accuracy,bottom,random,accuracy,question answering system,si acoustic model, 50k gaussians,quinphone cross-word acoustic context,technique,incremental speaker adaptation,context,speaker-adaptive training,feature-space normalization,canonical acoustic model,non-linguistic source,speech variability,canonical feature space,trained transform,speaker,recognition model,resulting feature space,adaptation,incremental adaptation,transformation,conversation-side,full output,speaker independent system,latter,transformation,decoded output,speaker,sys tem,current time,speaker adaptive transforms,future sentence,advantage,incremental adaptation,single decoding pas,off-line adaptation,decoding process,per formance,approach,full offline adaptation,incremental version,segmentation,speaker clustering,segmentation procedure,speech,non-speech prior,rea son,non-speech segment,computational load,recognition,speech segment,segment,speaker,speaker adaptation,clustering,k-means,segment,single diagonal covariance gaussian,symmetric  k-l divergence,gaussians,im pact,automatic segmentation,error rate,accuracy,bottom,random,accuracy,maximum entropy system,accuracy,bottom,random,accuracy,question,section,technique,call quality,technique,train ing development set,quality evaluation,test set,quality,service,help-desk represen tatives,human monitor,random sample,evaluation form,question,subset,question,automatic method,guideline,appropriate closing script,customer,question,human-level knowledge,pertinent question,clarity,problem,available resource,problem,question,technique,example,question,appropriate closing script,good partial match,anything,answer,question,test set,human evaluator,accuracy,system,number,bad call,sorted list,number,good call,accuracy number,maximum entropy ranking,alternative,arbitrary feature,speech recognition output,correlate,outcome,probability,feature,automatic transcription,entropy,system,transcription,manual evaluation,following equa tion,feature,normalizing factor,indicator function,parameter,training,hand-guided method,feature,specifi, vip phrase,candidate feature,generic  asr feature,number,he itations,total silence duration,relevant feature,threshold,feature,final set,fea tures,generic feature, vip phrase,weight,different feature,many hesitation,long silence,equation,accuracy,system,bottom,mechanism,fixed number,evaluation ques tions,global one,entire call,unique score,interpolation weight,held-out set,weight,maximum entropy model,accuracy,combined system,accuracy,individual system,com plementarity,application,section,user interface,automated quality monitoring application,section,evaluation form,respect,quality-related question,process,user interface,efficient mechanism,human evaluator,specific agent,specific agent,automated quality,user interface,web application,back-end database,content management system,evaluation form,overall score,server location,duration,figure,interface,ability,answer,evaluation form,evaluation form,addition,interface,eval uator,ability,summary statistic,average score,additional information,quality,system,mul tiple location,daily-basis,transcribe,supervisor,monitoring,monitoring purpose,precision,section,precision,recall number,identification,test set,call center personnel,manual score,quality,monitoring,quality score,summary figure,precision,recall,function,number,monitoring,reality,small number,human attention,precision,backend,infor mation integrator,content,application,websphere,function,number,bad call,total number,recall,number,bad call,total number,bad call,test set,observed performance,performance,random selection,oracle,ideal performance,oracle performance,perfect automatic ordering,figure,show precision performance,monitoring regime,small fraction,recall performance,regime,low volume monitoring,recall,oracle,performance,random-selection,figure,number,bad call,automated ranking,number,random selection,low-monitoring regime,technique triple,final measure,performance,figure,scatterplot,computer ranking,human-human scatterplot,automated system,quality moni,call center,combination,maximum entropy classification,feature,question,simple pattern-matching,system,human monitor,bad call,random selection,function,number,bad call,efficient,result,efficiency,hu man monitor,many bad call,amount,carpenter,ector-based natural lan guage call,com plex call classification,hacioglu,all-type classifica tion,unsupervised training,call center domain,ars u-2003,active learning,automatic speech recognition,call classification,end-to-end performance,call classification,data confusion reduction,model tolerance enhancement,interspeech-05,conversational telephony system,rich transcription,eurospeech-2005,feature,speech recognition,tional linguistics,proceeding, naa cl,short paper,boulder,colorado,association,computational linguistics fast decoding,kingsbury,watson research center yorktown height,ny 2ib m ha,research lab mount carmel,haifa abstract information retrieval,spoken-term detec tion,broadcast news,phone conversation,conference call,meeting,great interest,government,business community,requirement,high-quality,effect,sub-word information, oov query term,trade-off,search accu racy,audio transcription,hy brid  lvc sr approach,indexing,search,phonetic confu sion,posterior probability,neural network,retrieval, oov query,method,data set, nis t std  task,1 i ntroduction indexing,retrieval,speech content,vari ous form,broadcast news,customer care data,on-line medium,interest,wide range,application,market,telligence gathering,customer analytics,line medium search,key information retrieval technology,open vocabulary search,large collection,spoken document,approach,saraclar,sproat,speech,eu project, her mes,word-fragment transcript,represent,sequence,syllable,word-fragments,popular approach,subword decoding,clements,siohan,bacchiani,representation,phone confusion probability,approximate sim ilarity measure,chaudhari,picheny,architecture,first step,speech, asr system,phonetic transcript, lvc sr system,trained speaker-independent recognizer,feature,quinphone acoustic model,context dependent state,gaussians,acoustic model,language model,decoding,tri gram model,collec tion,data source,caption, gal e br,conversa tions data,word-fragment language model,fragment inventory,greedy search algorithm,fragment,possible fragment,entire pro nunciation, oov term,real time factor we rfi gure,speed v,sub-word unit,accuracy,decoding,standard likelihood-based beam pruning,many viterbi decoder,gaussian shortlisting,gaussians,acoustic model,cluster,single gaussian,decoder,new observation vector,likelihood,observation,cluster model,cluster,likelihood,observation likelihood,mixture component,top maxl1 cluster,component,default,low likelihood,trade-off,accuracy,pruning parame ters,different value,pa rameters,measure,accuracy,ex ample,system,minute,elapsed time,minute,speech,figure,effect,spoken term detec tion dev06 test set,indexing,search,main difficulty,information,low accuracy,transcription,interest,tities,content word,accuracy,transcript,number,substitution,deletion,insertion,respect,correct audio transcript,enhancement,recall,precision,word confusion net,1-best path word transcript,in-vocabulary query, oov query,combination,phonetic search,fuzzy phonetic search,lucene1,apache open source search,search,word-fragment index,word fragment,indexing,transcript,basic unit,gin time,duration,posterior probability,inverted index, a l ucene-based indexing scheme,occurrence,transcript,timestamp,posterior probability,confi dence level,occurrence,posterior probability,representation,indexing,different type,transcript,single index,retrieval,vocabulary, asr system,word transcript, oov part,different algorithm,fuzzy search,word-fragment transcript,search,word-fragment,phonetic transcript,query term,pho netic representation,candidate list,query unit,inverted index,fuzzy search,trieve several fuzzy match,edit distance,substitution cost,confusion matrix,lucene,apache,edit distance,threshold,dynamic programming algorithm,confusion cost,matrix,distance computation,implementation,procedure,minimal cost,sequence,certain threshold,occurrence,po terior probability,indexed unit,occur rence,weight,example,weight,word match,phonetic match,na ture,query term,indexed unit,hybrid wordfragment indexing,hybrid system,word portion, asr system,lexicon,fre quent,frequency,acous tic training data,hybrid lm training set,evaluation set,relative entropy criterion,siohan,bacchiani,5-gram phone language model,fragment,21k fragment, 21k word,composite  42k vocabulary,fragment token,word token,word-fragments,hy brid lm,conjunction,acoustic model,section,eural network,posterior,fuzzy search,decoded transcript,search query,recognition error,method relies,transcript,phonetic represen tations,confusion,confusion matrix,matrix,broadcast news,velopment data,system,picheny,neural network,acoustic model,kingsbury,result,confusion estimate,input feature frame,context dependent  hmm state,beginning,mid dle,context dependent state,central phone identity, asr system,alignment,development data,training transcript,result,sequence,state label,input data,phone identity,frame class label,state posterior,output,ral network acoustic model,prior probabil ities,training set,sub-sequence,input speech frame,time index,neural network,neural network output,prior probability,log domain,state label,po terior,collapsed phone,result,analysis,following set,association,large constant,time index,context dependent state,confusion matrix entry,total count,matrix correspond,ref erence,column,observation,probability,observed phone,column,true phone,5 e xperiments,result,performance,spoken term detection system, det curve,trade-off,false alarm, nis tstd ,evaluation,effect, nis t std ,dev06 data,query term,indexing,many time,real time, wer increase, atw measure,word-fragments,performance, oov query,search,simple word search,primary advantage,hybrid decoding scheme,separate word,fragment,scheme,indexable unit,blue line,fig ure,hybrid setup,performance,example,search,different decodes,real time,hybrid system,performance,real time,hybrid system,word-fragment system,preliminary result,fuzzy search,output, atw performance,exact search,figure,consen sus output,retrieval result, oov term,fuzzy search,1r eal time factor wv exactword exactwordandfrag exacthybrid figure,effect,exactword,exactwordandfrag lie,6 c onclusionin,effect,spoken term detection task,hybrid system,fuzzy search,phone confusion probability, oov retrieval,picheny,improvement,audio search,high order confusion estimate,on-line distance learning module,lattice-based optimization,sequence classification criterion,neural-network acoustic modeling,siohan,vo cabulary independent spoken term detection,spoken term,evaluation plan,gov speech test,doc std06 evalplan-v10,sproat,lattice-based search,spoken utterance retrieval,vocabulary independent search,spontaneous speech,siohan,bacchiani,dependent audio search,graph index,interspeech,human language technology,annual conference,north american chapter,los angeles,california,association,computational linguistics,model adaptation,information-theoretic criterion ariya rastrow1,frederick jelinek1,abhinav sethy2,bhuvana ramabhadran2,language technology center,excellence,center,language,speech processing,john hopkins university ariya,jelinek jhu,asethy,com abstract,novel general framework,unsupervised model adapta tion,method,entropy,regularizer,semi-supervised learning,technique,cludes,sta bility,posterior,model parameter,addition,conditional entropy,parameter,low con ditional entropy,stable decision rule,application,framework,language model interpolation weight,speech recog nition task,broadcast news data,lecture data,new technique,comparable performance,supervised estimation,inter polation parameter,1 i ntroduction,machine learning technique,classification,principle,assump tion,reasonable amount,training data,test data,underlying distribution,success,statistical model,latter assumption,many appli cation,model adaptation,distribution,test data,plenty,specific domain genre,source domain,little amount,domain genre,problem,model adaptation,trained mod el,source domain,rich amount,target domain,different method,model adaptation,literature,conditional probability,input distribution,szummer,jaakkola,la bel,dense region,input distribution,author,mu tual information,input feature,measure,label complexity,framework,label entropy,condi tional entropy,unlabeled data,regularizer,training,grandvalet,bengio,resource,target domain cat,technique,general framework,unsupervised adaptation,entropy,stability,entropy,assump tion,out-of-domain distribu tions,performance,initial model,in-domain data,little adjustment,initial decision boundary,out-of-domain data,2 c onditional entropy,adaptation,section,conditional entropy,relation,performance,objective function,main adaptation,conditional entropy,classification problem wherex,input feature,corresponding class label,conditional entropy,mea sure,class overlap,conditional entropy,classification performance,assigned label,data point,classification rule,number,possible class,conditional entropy,respect,true distibution,theorem,thomas,inequality,low probability,theorem,classification problem,true distribution,classification method,spe cific model structure,distribution,model parameter,assumed model space,theorem,input feature,classification task,possible classifier performance,overlap,feature,different class increase,conditional entropy,crease,performance,po sible classifier,structure,parameter,corollary  1p,probability,model parameter,conditional entropy,model parameter,low conditional entropy,low entropy model,formance,conditional entropy,framework,classification task,new concept,researcher,bengio,maxi mum likelihood criterion,semi-supervised set,parameter,lihood,unlabeled data,minimiz,entropy,method,prefers minimal class overlap,entropy minimiza tion,unsupervised non-parametric clustering method,significant improvement,hier archical clustering,method,mod el,low conditional entropy,decision boundary,low-density region,input distribution,assumption,advantage,unlabeled exam ples,grandvalet,bengio,many case,domain,domain,initial trained decision boundary,out-of-domain data,result,high conditional en tropy,new domain,tween distribution,model parameter,decision bound aries,low-density region,distri bution,minimum conditional entropy criterion,new domain,domain,optimal parameter,new domain,initial parameter,technique,paragraph,initial model parame ters,out-of-domain data,availability,enough amount,unlabeled data,in-domain task,following objective function,pa rameters,lp regularizer,parameter,initial values3,param eters,low-density separation,following section,drawback,objective function,adaptation,realistic sce narios,minimum entropy criterion,section,model param eters,minimum conditional entropy,decision boundary,low density region,input distribution,obvious assumption,low-density region,boundary,suitable ideal assumption,clas sification,practical problem,assump tion,conditional entropy,reason,regularizer,trivial solution,minimum entropy criterion convex,situation,minimization,parameter,trivial solution,example,mixture, 2-d gaus sian,particular mean,covariance matrix,gaussian corresponds,par ticular class,binary class situation,linear decision boundary,gaussians,covariance matrix,parameter,different situation,lapping class,non-overlapping class,left panel,distribution,right panel corresponds,situation,considerable overlap,later case,low-density region,parameter,minimum entropy,model conditional entropy,parameter,no-overlap,entropy,convex function,parameter,trivial solu tions,true prior,minimum entropy cri terion,solution,cision boundary,regularizer,assump tion,initial model,optimal solution,section,overlap,entropy,convex,parameter,next section,entropy stability concept,4 e ntropy-stability,previous section,mini mum entropy criterion, 2f igure,mixture,gaussians,corresponding bayes decision boundary,class overlap,parameter,considerable amount,overlap,class bound aries,region,class distribution,concept,entropy stability,boundary region,entropy-stability,reciprocal,recall,vector,vector,lp norm entropy stability,introduced concept,stability,label entropy,model parame ters,low-conditional entropy,ble decision rule,following theorem,entropy stability,stability,posterior prob ability,decision rule,parenthesis,weighted sum,log-likelihood,gradient,poste rior probability,sample  xp,expected sta bility,posterior probability,high value,stable decision rule,boundary,region,mixture,gaussians,example,decision boundary move,class specific region,parameter,class prior probability,entropy,decrease,assumption,class distribution,region,data point,change,entropy,stability,entropy,region,following subsection,new objective function,unsupervised adaptation method,input distribution,better objective function,entropy-stability con cept,region,overlapped part,distribution,assumption,valid region,decision boundary,minimum entropy criterion,optimum solution,parame ters,region,entropy-stability term,parameter,small amount,dev set,5 s peech recognition task,section,framework,speech recognition task,speech recognition task,sequence,speech signal,word sequence,possible output,compact representation,output label,word graph,lattice,recognition process,lattice,particular instant,possible word hypothesis,acoustic likelihood,language model likelihood score,example,purpose,demonstration likelihood score,mov ehave  vea  ve ry fin eoftenfast figure,sample recognition lattice,multiple alignment,confusion network,alignment,multiple string alignment,new approach,lattice,single alignment,word error,hypothesis,alignment,multiple alignment,new string edit distance,new alignment,word error,hypothesis,section,similar result,practice,main benefit,multiple alignment,hypothesis,word error,example,figure,word lattice,hypothesis alignment,word hypothesis,position,alignment,deletion,computation,word posterior probability,posterior probability,word hypothesis,posterior probability,lattice path,alignment,posterior probability,hypothesis,expected word error,posterior,position,alignment,pruning,lattice,low probability word,section,lattice example,lattice,likely hypothesis,unlikely hypothesis,recognition,lattice,conditional entropy,conditional entropy,lat tice,whereli,decoded lattice,speech recognizer parameter,calculation,entropy,distribution,distribution,large number,number,unlabeled utter ances,empirical value,conditional entropy,expectation,put distribution,entropy-stability term,empirical average,sample,number,hypothesis,lat tice,infea sibl,conditi nal entropy enumer,possible path,lattice,figure,p1r2 p2r1,first-order,expectation,semiring,defining multiplication,sum operation,first-order semir ings,corresponding posterior probability,finite-state transducer,hypothesis space,gradient,entropy,weight,firstand second-order semirings,eisner,semirings,corresponding operation,forward-backward algorithm,second-order statistic,entropy,gradient,entropy,entropy,total probability,lattice,lattice,first-order semir,non-normalized score,lattice, fst weight,define,operation,forward algorithm,calculation,weight,weight,final node,detail,second-order semirings,gradient,entropy,eisner,forward-backward algorithm,procedure,6 l anguage model adaptation language model adaptation,training data,test data,frequent scenario,system,applica tion domain,entity,n-gram sequence,domain,interest,example,conversational speech,different structure,class-room lecture,linear interpolation,method,new domain,bacchiani,linear inter polation,special case,estimation,n-gram lm,adaptation data,new domain,pb refers,out-of-domain,background,adaptation,mod el,interpolation weight,conventionally,held-out data,target domain,framework,enough amount,unlabeled data,target domain,resource,new domain,domain specific model,in-domain resource,interpolation weight,parameter,performance,interpolated model,in-domain out-of-domain model,regularization term,parameter,interpolation weight,purpose,parameter,equation 7 e xperimental setup, ibm speech transcription system,gal e di stillation go no-go evaluation,acoustic model,system,trained model,experiment,lm adaptation experiment,text consists,data source,caption,le phase 2 d istillation  gng evaluation supplemental mul tilingual data,hub4 acoustic model training tran script,caption,t4 newswire,gal e br oadcast conversation, gal e br,cast news,language model,kneser-ney smoothing,lexicon size,second source, mit lecture data,barzilay,target domain,language model adaptation experiment,in-domain lm building,unlabeled data,interpolation weight estimation,criterion,training data,hour dev set,interpolation,entropy,gradient,entropy,unsupervised training data set,result,next section,8 r esults,interpolation weight,criterion,differ ent point,objective function,entropy,gradient,entropy,decoded lattice, asr system, mit lecture,unlabeled training data,objective function,different value,model parameter,figure,conditional entropy,non-convex objective function,entropy-stability term,objective func tion convex,purpose,evaluation,result,objective function,hour  mit lecture,data scription,hour  mit lecture data,framework,re sults,objective function,optimal,figure,hour train,data transcription,supervised adaptation,andwer,inter polation,hour dev set,compara ble  wer,figure,new objective function, wer trend,interpolation,parameter,estimating,information-theoretic criterion therefore,vised method result,performance,adaptation,speech recognition task,onclusion,future work,notion,entropy stability,new criterion,adaptation,tropy minimization,entropy stability,en tropy stability criterion,parameter setting,stable decision,entropy minimization,hand tends,decision boundary,sparse region,input distribution,criterion,unsupervised pa rameter adaptation,real world scenario,class conditional distribution,conditional entropy,regularizer,knowledge,gradient,entropy,entropy-stability,literature,experimental result,criterion,entropy minimization,speech recognition task,unsupervised scheme result,performance,supervised technique,future work,criterion,log-linear model,machine translation,application,pand linear interpolation language model scheme,history,context dependent,weight,author,markus dreyer,zhifei li,insightful discussion,sugges tions,reference,saraclar,language model adaptation,advance,speech transcription,speech,lan guage processing,thomas,thomas,element,information theory,wiley-interscience,edition,grandvalet,yoshua bengio,learning,entropy minimization,advance,neural information,barzilay,recent progress,ken lecture processing project,interspeech,jing jiang,literature survey,domain adapta tion,statistical classifier,zhifei li,jason eisner,firstand second-order expectation semirings,application,risk training,translation forest, emn lp,tao jiang,min imum entropy clustering,application,gene ex pression analysis,proceeding, iee e co,tional system bioinformatics conference,lidia mangu,eric brill,andreas stolcke,consensus,lattice-based word error minimization,sixth european conference,speech communication,jaakkola,information,larization,advance,neural information processing system,workshop,replace,n-gram model,future,language modeling,association,sainath,brian kingsbury,earisoy,tsainath,com abstract,recent year,success,peplexity,conventional n-gram language mod el, nnl m,hid den layer,deep neural network,hidden layer,ture higher-level discriminative information,input feature,network,success,acoustic modeling,deep neural network language model,result,task demonstrate,lm offer im provements,single hidden layer  nnl,preliminary result,model language model,current state-of-the-art technique,language modeling,1 i ntroduction statistical language model,many natural language technology,machine translation,handwrit,recognition,correction,crucial component,system performance,statistical language model,probability distribution,possible word string,lan guage,state-of-the-art  asr system,n-grams,conventional language,approach,simplicity,good modeling performance,problem,n-gram language modeling,data sparseness,cor pora,zero probability,many valid word sequence,technique,goodman,n-grams,probability mass,n-grams,estimate,unseen data,smoothing,discrete nature,gram language model,generalization,chal lenge,notion,word sim ilarity,discrete enti tie,contrast,schwenk,em bed word,continuous space,bility estimation,single hidden layer neural network,expectation,proper training,word embedding,similar loca tions,continuous space,prob ability estimate,smooth function,con tinuous word representation,small change,feature result,small change,probabil ity estimation,generalization,bengio,schwenk,gauvain,schwenk,recur rent  nnl m,mikolov,mikolov,perplexity,improvement,conventional n-gram language model,alternate method,continuous space,mixture language model,sarikaya,n-grams frequency,acoustic feature,den layer,mul tiple hidden layer,higher-level,ab stract representation,example,neural network,raw pixel representation,tect different edge,middle layer,com plex,local shape,ab stract category,sub-objects,ob jects,bengio,improvement,computational resource,mutli-core  cpu,training strategy,hinton,improved performance,network,variety,pattern recog nition task,machine learning,bengio,sainath,network,number,nonlinearities,large number,context-dependent state,crucial ingredient,neural network,success,acoustic modeling,language modeling,feed-forward  nnl architec ture,bengio,neu ral network deeper,additional hidden lay er,neural network lan guage model,architecture,po tential,single hidden layer  nnl m,next sec tion,architecture,feed-forward nnl,section,detail,baseline,language model,set-up, dnn lm,preliminary result,section,section,related work,section,2 n eural network language model,section,general framework, nnl m,notation