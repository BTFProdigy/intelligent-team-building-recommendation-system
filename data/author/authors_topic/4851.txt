proceeding,conference,empirical method,natural language processing,singapore,6-7 august, afn lp refining grammar,hierarchical semantic knowledge xiaojun lin,yang fan,meng zhang,hearing research center key laboratory,machine perception,ministry,education,school,electronics engineering,computer science peking university,beijing,china linxj,fanyang,zhangm,abstract,novel method,grammar,parsing,semantic knowledge,hownet,hierarchical state-split ap proach,grammar,data-driven manner,semantic knowledge,splitting process,part-of-speech node,semantic tag,termi nal word,new tag,good start,knowledge-based criterion,hierarchical splitting,semantic-related tag,leviate overfitting,experiment,chinese,english penn treebank show,refined gram mar,semantic knowledge,performance,respect,chinese,parser,published result,high-performance parser,collins,charniak,johnson,petrov,strong context free assumption,original  pcf model,grammar,probability,treebank,therefore,va riety,technique,original grammar,lexicalization,annotation,author,structural feature,lexical head,phrasal node,significant improvement,collins,charniak,collins,charniak,problem,fundamental sparseness,manning,limitation,variety,technique,johnson,parent category,significant improvement,original  pcf g,penn treebank,automatic symbol splitting method,comparable performance,lexical ized parser,manning,matsuzaki,petrov,troduces,automatic hierarchical state-split ap proach,grammar,basic nonterminals,algorithm,method,nonterminals,ent degree,actual complex ity,grammar,previous work,automatic annotation,data-driven method,overfit ting problem,integrat,external information,novel method,strength,knowledge-driven strategy,grammar,petrov,semantic knowledge,hownet,hierarchical state-split process,general hypernym,hownet,semantic class,semantic class, pos node,new set,semantic-related tag,good starting annotation,search space,em algorithm,process,overfit ting risk,hierarchical hypernym-hyponym re lation,hypernym,hownet,splitting,new semantic,knowledge-based criterion,new tag,subcategories,spective,effectiveness,presented approach,several experiment,chinese,english,semantic knowledge,remainder,section,related work,lexical semantic related par,hierarchical state-split unlexicalized parsing,section,presented method,grammar refining,detail,sev eral experiment,evaluation,section,conclusion,section,grammar,improved hierarchical state-split process,semantic knowledge,related work,lexical semantic related parsing semantic knowledge,syntac tic ambiguity,variety,research,recent year,conviction,semantic knowledge,lexicalized parsing,lexicalized grammar,attempt,word sense disambiguation,unified model,subset,semcor,miller,parsing context,sense information,wordnet,improvement,performance,xiong et al,combine word sense,hownet,chinese semantic re source,generative parsing model,standard bilexical dependency,word class dependency,sparseness problem,lexicalized parsing,experiment,parse model,word sense,special hypernym,significant improvement,penn chi nese treebank,special hypernym,hypernym,different level,hypernym hyponym hierarchy,fujita,hinoki tree bank,training data,discriminative parse selection model,syntactic feature,word sense information,special hypernym,word sense informa tion,general concept,hand-craft sense informa tion,parse selection,agirre,charniak,content word,semantic class,wordnet,word semantic class,pro ce,parser training,significant improvement,parsing,prepositional phrase attachment task,preliminary work,semantic class,confusion,parsing,syntax,semantic information,hierarchical state-split parsing,context-free assumption,petrov,hierarchical state,approach,orig inal grammar,formance,basic nonterminals,method,complexity,grammar,symbol,new subcategories,likelihood computation,splitting stage,previous syntactic sym bol,subcategories,em al gorithm,probability,latent annotation,like lihood,training data,symbol,series,new subcategories,hierarchical fashion,method,strategy introduces,context information,refined grammar,formation,syntactic ambi guities,em algo rithm,global optimal solution,suboptimal configuration,good starting annotation,problem,search space,derived subcategories,accuracy,refined grammar,training data,fitting,extent,addition,different sym bols,specific number,subcat egories,example,comma  pos tag,subcategory,terminal comma,noun pos tag,verb  pos tag,subcategories,context dependency,symbol merging stage,leviate,defect,approach,symbol,likelihood,subcate gory,subcate gory,enough information,threshold,likelihood loss,merging stage,certain pro portion,subcategories,priority,informative subcategories,method,grammar step,overfitting risk,extent,data-driven method,problem,ex ternal information,hierarchical state-split approach,symbol,subcategories,several  pos tag,frequent word,result,subcategory, pos tag,semantic consistent,splitting,merging process, pos level,frequent word,sub category,several  pos tag,3 i ntegration,semantic knowledge,semantic knowledge,fine grammar,automatic hierar chical state-split approach,annotation,search space,em algorithm, pos node,general hyper nym,terminal word,new set,semantic-related tag,splitting,symbol,knowledge-based cri terion,hierarchical semantic knowledge,splitting,new semantic-related tag,hownet,semantic knowledge resource,hownet,common sense knowledge base unveiling concept,inter-conceptual re lations,chinese,english,knowledge base,graph structure,hownet,proper tie,concept,sememes,relation,sememes,sememe refers,basic semantic unit,english,chinese equivalent,sememe institution,relation,hownet,hypernym-hyponym re lations,location-event relation,time-event rela tions,vitality,full  oft,goveronmentthe goveronment,syntax tree,sentence,government,syntax tree, pos node,general hypernym,terminal word,hypernym-hyponym relation,example,hypernym,hierarchical hypernym-hyponym relation,speciality,generality,hierarchical semantic information,pernyms,special hypernym institu tion,general hypernym entity,hierarchical way,hownet,update,concept,sememes,sememes,entity,attribute,attribute value,sememe hi,training data,original motivation,grammar refinement,original symbol, pos tag,context,sentence,figure,example,different context dependency,hownet,different hypernym,objective thing,vitality,property,different sens,different syntax struc tures, pos tag,semantic knowledge,automatic hierarchical state-split ap proach,em algorithm,maximum,likelihood,splitting process,subcategories, pos tag,context dependency,method,suboptimal configuration,start point,therefore,good start,annotation,figure,pos node,hypernym,terminal word,annotation,problem,process,appropriate semantic granularity,polysemous word,semantic information,hierarchi cal hypernym-hyponym relation,hyper nyms,appro priate level,granularity,semantic class,notation, pos tag,search space,method,hi erarchical state-split process,annotation,structural infor mation,special kind,semantic class,structural information weaker,annotation,special hyper nym,advantage,latent annotation,training data,general hyper nym,example,figure,problem,polyse mous word,hownet,general hypernym,hyponym,schematic figure,hierarchical state-split process,subcategory,hypernym,appropriate level,hownet,representation,problem,large extent,first sense option,strategy,stance,target word,stance,hownet,addi tion, pos node,ter minal word,hownet,hierarchical state-split process,method,good starting annotation,semantic knowl edge,great use,au tomatic splitting process,parser,good starting annotation,automatic hierarchical state-split process,improve ments,original training data,process,gen eral hypernym,semantic repre sentation,hierarchical semantic knowledge,addition,auto matic process try,symbol,data-driven manner,overfitting risk,training data,hyper nyms,new set,semantic-related tag,refining process,semantic-related tag,process,hypernym,hierarchical semantic knowledge,subcategory,tag corresponds,appropriate special level,hypernym,hownet,example,sub category,appropriate hyponym,entity,hierarchical semantic knowl edge,original hierarchical state-split pro ce,semantic-related tag,mapping,subcategory,semantic-related tag,hypernym,appropriate level,hownet,likelihood judgment,knowledge-based criterion,new subcategories,parent tag,new subcategory,special hypernym,hyponym,schematic figure,process,left part,figure,subcategories,dashed line,subcategory,hypernym,right part,figure,hypernym node,hyponym,corresponding subcategory,splitting,mapping,subcategory,semantic-related tag,hypernym,ap propriate level,subcategory,dataset chinese english xue,marcus,trainset art,400-1151 section 2-21 devset article 301-325 section,testset article 271-300 section,experimental setup,product,orig inal category,subcategories,word set,subcategory,subcategory,specific hypernym,related word,hownet,new knowledge,criterion,semantic-related tag,purpose,hierarchical semantic structure,training data,4 e xperiments,section,several experiment,validity,grammar,semantic knowledge,experimental setup,experiment,chinese,english,fair comparison,previous work,standard corpus,parser,eva lb parseval reference implementation,berkeley,original automatic hierarchical state-split pro ce,semantic resource,parsing,hownet,subsection,statistical significance,dan bikel,evaluation comparator,default setting,iteration,experiment,different se mantic representation method,chinese,polysemous word,training, wsd strategy,first sense option,edu evalb,google,com berkeleyparser,dbikel software,agirre,subsection,semantic information,hierarchical relation,hypernym,specialty,generalization,hownet,appropriate level,granularity,resent word,training,different level,granularity,semantic repre sentation,experiment,automatic hier archical state-split process,different level,seman tic representation,semantic representation,general hypernym,special hypernym,result,figure,effectiveness,method,subsection, pos node,general hypernym,terminal word,parser performs,baseline,special hypernym,score start,training iteration,training,special hy pernyms,split-merge iteration baseline special hypernym general hypernym figure,performance,different semantic representation,training,semantic representation,training,special hypernym,training,general hypernym,training set,general hypernym,new semantic-related tag,train ing set,special hyper nyms,new tag,many tag,appropriate grammar,sub sequent step,over-splitting train ing,grammar refinement experiment several experiment,chinese,english,effectiveness,grammar,semantic knowledge,general hypernym,semantic represen tation,polysemous word,training, wsd strategy,first sense option,experiment,method,baseline,raw training,automatic hierarchical state split approach,se mantic annotation,raw train ing,general hypernym,se mantic representation,train ing approach,baseline,knowledge-based criterion,automatic hierarchical state-split process,semantic knowledge,section,parser,baseline parser,advanced parser,behavior,development,accuracy,iteration,sixth iter ation,result,fifth iteration,final test set,performance,performance,chinese figure,grammar,se mantic knowledge,formance,chinese,sentence,length,good start,annotation,parser,significant improvement,baseline,good start,annotation,semantic knowledge,splitting process,splitting,new semantic-related tag,semantic annotation,result,fifth iteration,error rate reduction,method,previous work,chinese,result,grammar,semantic knowledge,syntactic ambiguity,-lp lr f1,figure,performance,fifth iteration,chinese,sentence,length,method,baseline,parser,semantic annotation,automatic method,parser,semantic annotation,knowledge-based criterion,parser,lp lr 1l p lr 1c hiang,petrov,final parsing performance,previous work,chinese,state-of-the-art perfor mance,chinese,performance,english,effectiveness,method,language,experi ments,english,hownet,common sense knowledge base,chinese,english,knowledge source,experiment,method,en glish,sentence,length,re sults,parser,se mantic annotation,method,section,re sults,method,stable improvement,subcategory,subcategories,several subcategories,original training,good starting annota tions,semantic annotation,knowledge-based criterion table,performance,fifth iteration,en glish,sentence,length,method,baseline,parser,semantic annotation,automatic method,parser,semantic annotation,knowledge-based criterion,result,english,language dependent op eration,morphological processing,english word,hownet,base form,sin gular,semantic knowledge, pos tag,corresponding word,hownet,chinese,reason,improvement,english treebank,chinese,improvement,mor phological analysis,future,result,analysis,new strategy,grammar,sig nificant improvement,performance,section,grammar,different step,se mantic knowledge work,grammar,semantic knowledge,new semantic-related tag,method,refined subcate gories,refined subcategories,pos tag,original training,good starting annotation,several subcategories,frequent word,subcategories,semantic knowledge,previous one,example,original training,semantic con sistence,contrast,subcategories,good starting annotation,semantic consistent word,difference,automatic splitting process,number,subcategories,process,semantic-related tag,semantic-related tag,number,subcat egories,first part,pro ce,process,subcategories,automatic one,semantic structure,second part,subcate gories,automatic splitting process,third part vice verse,sub category,second part,functional cate gories,subcategories,third part,content category,splitting process,subcategory,functional category,subcategories,content category,tendency,accordance,linguis tic intuition,main effect,semantic-related automatic split semantic,tag number split,nn-attribute,nn-entity, 2v v-at tributevalue,vv-entity, 5c s-at tributevalue,cs-entity, 7p n-at tribute, 8n r-at tributevalue,number,subcategories,approach,automatic hierarchical state-splitting,splitting,knowledge-based criterion,splitting result,seman tic knowledge,overfitting risk,5 c onclusions,novel approach,tegrate semantic knowledge,hierarchical state-split process,grammar refinement,accuracy,ous method,improvement,aspect,original treebank, pos node,general hypernym,ter minal word,search space,em algorithm,initial restrict,splitting step,splitting process,knowledge-based crite rion,new semantic-related tag,hierarchical semantic knowledge,approach,knowledge-driven manner,experimental result,semantic knowledge,great use,syntactic disambiguation,analysis,refined grammar,method,content category,baseline method,function,acknowledgment,yaozhong zhang,enlighten ing discussion,anony mous reviewer,helpful com ments,national natural science foundation,national high tech,research,development program,national key ba sic research program,martinez,improv,parsing,pp attachment performance,sense information,statistical model,word-sense disambiguation,intricacy,collins,computational linguistics,charniak,context free grammar,word statistic,maximum-entropy-inspired parser,e c harniak,johnson,parsing,maxent discriminative reranking,latent infor mation,treebanks,lexicalised model,statistical parsing,collins,head-driven statistical model,natural language parsing,hownet chinese english conceptual database,technical re port online software database,keenage,tanaka,semantic information, hps parse se lection,workshop,deep linguistic processing,linguistic tree rep resentations,computational linguistics,manning,accurate,parsing,marcinkiewicz,large annotated corpus,en glish,penn treebank,computational linguis tic,tsujii,prob abilistic  cfg,latent annotation,george,miller,martin chodorow,shari landes,claudia leacock,robert,thomas,semantic concordance,sense identification, arp a-hlt wo rkshop,interpretable tree annotation,inference,unlexicalized parsing,penn chinese treebank,semantic knowledge,palmer,large scale,chinese corpus,realization,chinese,semantic,sentence type informa tion,master thesis,peking university,improved  crf,chinese language processing system, sig hanba keoff,xinhao wang,dianhai yu speech,hearing research center state key laboratory,machine perception,peking university,wangxh,zhangyaoz,abstract,system,system,sys tem,system,fourth international chinese language processing bakeoff,primary mod el, ner track,gram language model,system,ac count,level language information,performance,system,transformation,technique,post-processing,1 i ntroduction,open track,bakeoff,open  ner track,system,top level,several track,natu ral language processing track,excellent performance,test corpus,bakeoff,gen erative model,primary advantage,independence assump tions,multiple inter,feature,observation element,rela tion,basic unit,sequence,chinese character,level information,relationship,n-gram language model,system,word level language information,several pilot-experimental result,tagging error,pattern,error pattern,similar error, tbl post processor,system,addition,extra train ing data,people daily corpus,shiwen yu,transition rule,corpus,open track,remainder,fol low,scheme,system,section,section,evaluation result,system,conclu sion,section,2 w ord segmentation,w system,n-gram language model,post processing strategy,conditional random field conditional random field,statistical se quence labeling model,great success,natural language processing,chunking,fei sha,word segmentation,hai zhao,sixth  sig han wo rkshop,constraint,indepen dence assumption,natural language task,f model,observation,label sequence,observation,normalization term,fea ture function,clique,graphic,chinese character sequence,sentence, a c hinese character,label tag,position,hai zhao,character position,multi character word,single-character word tag,unigram feature template,current character,nth character,current character,basic bigram fea ture template,dependency,previous tag,multi-model integration,multi-model information,log-linear model,posterior probability,word sequence,char acter sequence,decision rule,parameter,standard approach,mini mum error rate training,machine transla tion, crf approach,special case,framework,following feature function,approach,logarithm,feature function,whole la bel sequence,character sequence,posterior prob ability,sub-sequence,n-gram language model,word information,log-linear model,feature function,dynamic programming search algorithm,efficient decoding,system,word lattice,word sequence,word lattice,decision rule,candidate word,word lattice,problem, oov word,unigram, oov word,minimal value,unigram score,language model,length, oov word,punishment factor,long  oov word,xin hao wang,post-processing strategy,division,combination rule,system,bakeoff,xinhao wang,post processing,system,sixth  sig han wo rkshop,chinese language processing,data transition,w open track,unique difference,closed track,additional training data,model refinement,simplified chinese track,additional training data,people daily cor pu,auto-extracted transition rule,process,heuristic strategy,con tains,raw people daily,system,closed track,cor pu,compare,result,people daily corpus,conflict pair,example,left phrase,people daily corpus segmentation guideline,right one,phrase,first set con,right phrase,second set,left phrase,second set,people daily cor pu,sentence,phrase,left side,first set,right one,transition rule,entity recognition,entity recognition track,character sequence,problem, ner sys tem,log-linear model,multi-model informa tion,error pattern,bl strategy,post-processing module,model description, ner track,log-linear model,logarithm,feature function,class-based n-gram lan guage model,label sequence,n-best tagging re sults,whole label sequence,character sequence,log-linear model,n-best tag,result, crf score,class-based n-gram language model score,chinese character,ten class,beginning,character,en tity,non-entity character,entity,person name,location name,organization name,basic feature,basic unigram feature,bigram transi tion,previous tag,class-based n-gram language model,class-based n-gram language model,character,single class,entity,single class,character sequence,label sequence,class sequence,sentence,class sequence,class-based gram language model,class se quence,analysis,experiment,tagging error,pattern,system,pattern,similar error,sixth  sig han wo rkshop,class sequence example transformation-based learning,symbolic ma chine,method,eric brill,main idea,transformation rule,tagging error,initial process,main procedure, tbl framework,initial state assignment,system,al lowable template,position window,name entity information,3-word window,combination consid,difference,result,system,similar error,part-of speech sequence,word sequence,system, ctb corpus,cor pora,limitation,resource,per formance, pos tag,previous word,feature,dynamic program ming strategy,closed track,feature,basic feature,combined feature,next word,current word,basic feature,anal ysis, oov word,last character,current word,length,cur rent word,effective feature,oov  pos,furthermore,long distance con straint word,current word,yan zhao,open track,nese parser,current word,feature,5 e xperiments,result,open ner track,n-gram language model,system,implementation, crf package1,taku kudo,maximum entropy toolkit2, sri lm toolkit,andreas stolcke,andreas stolcke,chinese word segmentation,closed track,bigram language model,training data,corpus,corresponding parameter,minimum error rate training approache,development data,development data,bakeoff,ten-fold cross val idation approach,pa rameter training,parameter,mean value,estimation,parameter,result,w system,closed track,word segmentation performance,different approach,closed track,open track,enough time,parameter estimation,new data,system,parameter,closed track,unique difference,chasen,org taku software,homepage,uk s0450736 maxent toolkit,sixth  sig han wo rkshop,chinese language processing track,extra training data,corpus,performance,chinese track,additional data,people daily corpus,transition strategy,tra ditional chinese track,additional data,training,early bake,system,ctb open track,training,early bakeoff,addi tional data,translated peo ple daily corpus,additional data,result,open w system,cit yu,word segmentation performance,different approach,result,system performance,parameter,useful parameter,closed track,bad role,open track,ad ditional training data,named entity recognition,closed  ner track,class-based tri gram language model,corpus,approach em,w track,parameter, ner system, tbl rule,five-fold cross val idation approach,post-processing procedure,report,result,closed ner system,experiment,method, tbl method,concurrent er rors,method,output result,output tag,cit yu,entity recognition f-value,different approach,closed track tbl,output probability,certain threshold, tbl result,training set,training data,development data,addition,corpus,chi nese treebank,training data, ctb open track,system,berke ley parser,slav petrov,long distance constraint word,per formance,method,corpus,performance,total-accuracy,different approach 6 c onclusion,system,bakeoff,ner system,log-linear model,tegrate  crf,language model,system,system integration approach, pos system,validity,addition,heuris tic strategy,additional train ing data,open w track,several post-processing strategy,system,sixth  sig han wo rkshop,chinese language processing reference jin kiat low,hwee tou ng,wenyuan guo,aximum entropy approach,chinese word seg mentation,proceeding,fourth  sig han wo rk shop,chinese language processing,jeju island,huihsin tseng,pichuan chang,galen andrew,daniel jurafsky,christopher manning,onditional random field word segmenter,sighan bakeoff,proceeding,fourth  sig han wo rkshop,chinese language processing,jeju island,hai zhao,chang-ning huang,improved chinese word segmentation system,conditional random field,proceeding,fifth sig han wo rkshop,chinese language processing,sydney,australia,wallach,conditional random field,introduction, cis tr ms-cis-04-21,huiming duan,specification,large-scale modern chinese corpus,proceeding, icm lp,urumqi,fei sha,fernando pereira,conditional random field,proceeding,ed monton,canada,franz josef och,hermann ney,discrimi native training,maximum entropy model,sta tistical machine translation,proceeding,40th annual meeting,association,franz josef och,minimum error rate train ing,statistical machine translation,proceeding,annual meeting,association,sapporo,xinhao wang,xiaojun lin,chinese word segmentation,maximum entropy,n-gram language model,fifth  sig han wo rkshop,chinese language pro,sydney,australia,eric brill,transformation-based error-driven learning,natural language processing,case study,part-of-speech tagging,computational lingusitics,xiaolong wang,bingquan liu,yi guan,fusion,trigger-pair feature,pos tagging,maximum entropy model,journal,computer research,development,andreas stolcke,proceeding,international conference,spoken language processing,denver,colorado,slav petrov,leon barrett,romain thibaux,dan klein,accurate,compact,inter pretable tree annotation,proceeding,ternational conference,computational linguistics,annual meeting,sydney,australia,sixth  sig han wo rkshop,chinese language processing proceeding,fifth  sig han wo rkshop,chinese language processing,sydney,association,computational linguistics chinese word segmentation,maximum entropy,n-gram language model wang xinhao,lin xiaojun,yu dianhai,tian hao,wu xihong national laboratory,machine perception,school,electronics engineering,computer science,peking university,wangxh,tianhao,abstract,chinese word seg mentation system,speech,hearing research group,na tional laboratory,university,third international chi nese word segmentation bakeoff,chinese character-based maximum entropy model,word segmentation task,classi fication task,system,linguistics information,n-gram language model,several post processing strate gy,open track,cor pora,system,evaluation,good performance,closed track,system,1 i ntroduction chinese word segmentation,core tech niques,chinese language processing,research interest,recent year,sev eral promising method,previous researcher,successful way,hwee tou ng,jin kiat low,chinese word segmentation task,classification problem,character,beginning,middle,multi character word,single-character word,emphasis,chinese character,debases,consideration,relationship,context word,several strategy,context word,relationship,linguistics information,system,n-gram language model,relationship,context word,desirable choice,system,scoring,analysis,preliminary experiment,combination ambiguity,division,combination strategy,sys tem,numeral word,number conjunction strategy,addition,long organization name problem,corpus,post processing strategy,organization name,remainder,fol low,section,system,detail,section,experiment,result,last section,conclusion,2 s ystem description,n-gram language model,several post processing strategy,system,detailed description,component,subsection,maximum entropy model,system,previous work,jin kiat low,hwee tou ng,word segmentation,4-classes learning process,beginning,middle,single-character word,following feature,jin kiat low,character,right position,open track,feature,external dictionary,current charac ter,punctuation,length,character,context,external dictionary,boundary tag,character,feature, a m model,output,character,regard,char acters,semiangle matrix,element wji,ma trix,ith charac ter,jth character,character,consequence,optimal segmentation re sults,overall score,dynamic programming algorithm,corresponding matrix,example,language model n-gram language model,method,natural language processing,context relation,system,bi gram model,path score,detail,bi gram,weight,word bound aries,approach,path score,following formula,jth character,last word,parameter,test set,international chi nese word segmentation bakeoff,vocabulary,bigram,unigram,unigram, oov word,minimal unigram value,length,word acting,punishment factor,long  oov word,post processing strategy,analysis,preliminary experiment,n-gram language model,several post processing strategy,final system,combination strategy,combination ambiguity issue,division,combination strategy,bigram,bigram,unigram,august,revolution,segmented word,training,bigram,august revolution,ap peares,character string,uni gram,training,bigram,subwords,example,economic system reform,instance,corresponding unigram,training,bigram,subwords,matrix,economic system,reform,exists,consequence,segment,numeral word,several word,instance,problem,numeral word processing strategy,strategy,arabic numeral,train ing,high frequency charac ters,num bers,training,numeral word issue,fol low,sentence,con joint word,numeral word,last char acter,former word,organization name,several word, msr corpus,system,corresponding strategy,problem,organiza tion name,training set,charac ters,prefix,frequency,child node,predefined threshold,frequency,current node,string,current node,prefix,child node,frequency,threshold,corresponding subtree,suffix,difference,character,lexical tree,successive word,2-5 word,following con ditions,number,full stop,suffix,appears,frequency,substring, oov word,multiple word,satisfy,condition,successive word,string,prefix,3 e xperiments,result,open track,corpus,corpus,corpus,system,system ii,system,maximum entropy toolkit,system,system,re gard,n-gram language model,post processing strategy,closed track,corpus,result,derived system,system  r p  f r oov rivia,effect,memodel,n-gram language model,post processing strategy,closed track,corpus,system ia,system ib,bigram lan guage model,system ic,division,combination strategy,numeral word,homepage,uk s0450736 maxent toolkit,processing strategy,system id,ganization name processing strategy,open track,external dictio nary,feature,external dictionary,source,chinese concept dictionary,stitute,computational linguistics,noun cyclopedia,word segmentation dictionary,institute,technology,chinese academy,sci ences,dictionary,insti tute,acoustic,dictionary,insti tute,computational linguistics,dictionary,big dictionary,dictionary,core dic tionary,following dictionary,word set,intersection,big dictionary,training data,training data,external dictionary,training data,effect,n-gram language model,strategy,open track,system io,basic feature,external dictionary,feature,derived system,system  r p  f r oov rivio,effect,memodel,n-gram language model,post processing strategy,open track,system ii,division,combination strategy,numeral word processing strategy,open track,cor pora  cki, cit yu,training set,test set,chinese word segmentation backoff,training,corpus  upu,cit yu,external dictionary,open track, msr a co rpus,official result,system ii, cit yu,corpus  r p  f r oov rivupuc,official result,system, upu cckip, cit yu, upu corpus,interesting observation,performance,open track,closed track,investigation,analy si lead,possible explanation,seg mentation standard,dictionary,external dictionary,differ ent, upu corpus,4 c onclusion,detailed description,several chi nese word segmentation system,n-gram language model,post processing strategy,closed track,integration,bi gram language model,recall ratio,performance,system,addition,strategy,combination ambiguity,numeral word,long organization name issue,evaluation result,valid ity,effectivity,approach,reference jin kiat low,hwee tou ng,wenyuan guo,maximum entropy approach,chinese word segmentation,preceedings,fourth sig han wo rkshop,chinese language process ing,hwee tou ng,jin kiat low,chinese part-of speech tagging,all-at-once,preceedings,conference,empirical method,zhang huaping,liu qun,chinese word rough segmentation, n-s hortest path method,journal,chinese informa tion processing