proceeding,joint conference, emn lp, con ll,shared task,jeju island,association,computational linguistics latent structure perceptron,feature induction,unrestricted coreference resolution eraldo rezende fernandes departamento,informa,tica puc rio rio,janeiro,brazil,puc-rio,janeiro,brazil cicerons,com ruy luiz milidiu,departamento,informa,tica puc rio rio,janeiro,brazil milidiu inf,puc-rio,br abstract,machine,system,large margin structure perceptron,coreference resolution,technique,latent corefer ence tree,entropy,feature induc tion,latent tree,learning problem,automatic feature induction method,nonlinear model,high performance,linear learning algo rithm,system, con ll,shared task,prises,language,arabic,chinese,english,system,lan guages,minor adaptation,language dependent feature,static list,pronoun,system,offi cial score,competitor,1 i ntroduction, con ll-2012 shared task,pradhan,modeling,coreference resolution,multiple language,participant,corpus,language,ara bic,chinese,english,corpus,ontonotes project,accu rate anaphoric coreference information,contain,iou annotation layer,tagging,syntax parsing,se mantic role,automatic identification,men tions,entity,infor mation,ontonotes layer,machine learning system,coref erence resolution,large margin structure perceptron algorithm,collins,fer nandes,milidiu,pre dictor,candidate men tions,document,clus ters,mention,predictor com,optimization problem,objective,function,clustering feature,clas sic cluster metric,objective function,metric,np-hard optimization problem,coreference tree,cluster,directed tree,mention,prediction problem,cluster,approach,coreference tree,training data,structure,la tent,latent structure perceptron,fernan de,brefeld,joachim,learning algorithm,power feature,guided feature induc tion,fernandes,milidiu,technique,several fea ture,capture coreference specific lo cal context knowledge,feature,duction technique,structure perceptron framework,efficient general method,strong nonlinear classifier,system, con ll-2012 shared task,arabic,chinese,en glish test set,official score,language,remainder,fol low,section,machine,unrestricted coreference resolution task,section,corpus preprocess,experimental finding,section,section,final re mark,ask modeling coreference resolution,men tion cluster,document,subtasks,mention detection,mention clus tering,first subtask,strategy,do santos,carvalho,subtask,complex output,structure,approach,many similar structure,ing  nlp task,collins,tsochantaridis,fernandes,brefeld,fernandes,milidiu,mention detection,text document,candi date mention,strategy,do santos,carvalho,basic idea,noun phrase,pronoun,en tities,noun phrase,mention,mention clustering,mention,subtask,training,mention,document,correct coreferring cluster,structure perceptron algorithm,predic tor,training,cor rect input-output pair,weight vector,parameterized predictor,clustering,mention,w-parameterized scoring function,clustering,large margin structure perceptron,fernandes,milidiu,training,loss function,prediction problem,loss-augmented predictor,non-negative loss function,candidate,differs,ground truth,training algorithm,tense use,predictor,prediction prob lem,classic clustering,metric,np-hard optimization problem,complexity,prediction problem,coreference tree,cluster,mention,coreference tree,directed tree,coreferring mention,represent,coreference rela tion,mention,figure,document,mention,cluster,plausible coreference tree,figure,north koreaa1,itsa2 door,secretary,herb3 visit,good start,remains,north korea,sa3 missile development program,itsa4 export,missile,figure,exemplary document,mention,cluster,letter,mention subscript,cluster,number,mention,4f igure,coreference tree,cluster,figure,semantics,coreference tree,structure,clustering task,concept,dependency relation,mention,aforementioned example,mention a3,north korea,mention a1,north korea,mention a2,document,forest,coref erence tree,coreferring cluster,simplicity,root node,coreference tree,artificial root node,document tree,figure,document tree,figure,figure,document tree,coreference tree,figure,artificial arc,training data,structure,la tent,latent structure perceptron,fernandes,brefeld,joachim,origi nal predictor,predictor,argmaxh,fea sible document tree,joint feature vector representation,mention,doc ument tree,latent predictor,maximum scoring,men tions,tree score,linear func tion,feature,straightforward procedure,cluster,subtree con,artificial root node,document tree,figure,latent struc ture perceptron algorithm,mention cluster,univariate counterpart,rosenblatt,convergence,argmaxh,wi figure,latent structure perceptron algorithm,structure perceptron,online algo rithm,training set,training instance,major step,prediction,current model,model update,dif ference,ground truth output,latent structure perceptron,additional step,latent ground truth,specialization,latent predictor,current model,algorithm,doc ument tree,clustering task,thereafter,unseen document,learned model,predicted document tree,predicted cluster,golden coreference tree,training,golden clustering,document tree,specialization,latent predictor,constrained latent predictor,constrained predictor,maximum scoring document tree,correct,mention,artificial node,cluster,predictor,subset,constrained tree,ground truth,iteration,model update,differ ence,constrained document tree,document tree,ordinary predictor,loss function,impurity,predicted document tree,modeling,simple loss function,many pre,constrained docu ment tree,artificial root node,different loss value,parameter,root loss value,tree edge,candidate corefer,mention,approach,previous structure,modeling,dependency par,fernandes,milidiu,prediction problem,maximum branching problem,chu-liu-edmonds algorithm,edmonds,structure perceptron,collins,robust model,ata preparation,corpus,training,test data,section,methodology,coreference arc,feature,coreference arc generation,prediction problem,mention,document,complete graph,document,mention pair,op tion,document tree,total number,mention,big por tion,incorrect,candidate men tion pair,filtering strategy,precision,concern,application order,filter,objective,small set,candidate arc,good recall,directed arc,following condition,number,mention,parameter,mention,head word,head word,mi match,head word,test shallow discourse,mention,pronoun,gender,number,speaker,animacy,pronoun,compatible pronoun,proper name,recall,language-dependent sieve,basic feature,basic feature,feature,positional informa tion,feature,do santos,carvalho,semantic feature,wordnet,basic feature,head word,pro noun,string match,head word,definitive np,demonstrative np,proper name,string match,mi head word,previ ous next, pos tag,pronoun,previous next,pronoun,number,gender,person,number,result,baseline system,mi head word,entity type,entity,semantic role,prev next predicate,concatena tion,semantic role,predicate,position,distance,sentence,distance,number,mention,distance,number,person name,applies,pronoun,mention,apposition,system,different lan guages,experiment,small change,system,different language,adaptation,input feature,language,different  pos tagsets,corpus,creation,static list,language specific pronoun,input feature,en glish corpus,arabic,chinese corpus,arabic corpus,speaker feature,language,basic feature,input feature,feature,ne data,chinese corpus,different  pos tagset,mapping,basic feature derivation stage,input feature,arabic,chinese,sieve-based arc generation,arabic,english corpus,specialization,first sieve parameter,arabic,chinese,english,arc generation,basic feature derivation step,system,static list,lan guage specific pronoun,experiment,information,golden coref erence chain,pronoun list,corpus,entropy guided feature induction,predictive power,sys tem,complex feature,combination,basic feature,previous sec tion,feature template,com plex feature,template,entropy,feature induction approach,fernandes,milidiu,milidiu,template,complex contextual information,dif ficult,feature induction mechanism,struc ture perceptron framework,efficient general method,strong nonlinear predictor,different template set,language,main difference,training data,result,dif ferent template set,english language,template set,template,different set,mention pair,filter,mention pair,filter,arabic,template set,lan guages,template,english language,final set,chi nese language,template,final set,arabic,4 e mpirical result,system,corpus,con ll-2012 shared task,corpus avail,language,arabic,chinese,en glish,language,result, cea fe,f-scores,unique score,language,official score, con ll-2012,language,system result,development,test set,development result,system,training set,result,dataset,train ing,development set,training,gold standard input feature,bet ter,au tomatic value, nlp task,golden value,additional noise,automatic feature,evaluation,automatic value, con ll,task corpus,system, con ll-2012 development set,language,arabic training cor,language muc b3  cea fe mean r p f1  r p f1  r p f1 arabic,english,official score,result,development set,muc b3  cea fe mean r p f1  r p f1  r p f1 arabic,english,official score,result,development set,root loss value,muc b3  cea fe mean r p f1  r p f1  r p f1 arabic,english,official score,official result,test set,supplementary result,parse quality,mention candidate,parse quality,candidate,golden mention boundary,golden mention,feature limitation,arabic,performance variation,language,impor tant parameter,root loss value,different loss function value,artificial root node,effect,pa rameter,creation,cluster,cluster,balance,precision,recall,develop ment set,root loss value parameter,arabic,chinese,english,system,development set,parameter,language,equivalent,parameter,result,parameter,balancing,precision,recall,f1 score,effect,arabic,chinese,unbalancing issue,language,official result,test set,perfor mances,performance,development set,offi cial performance,arabic language,development,performance,difference,ara bic training set,english counterpart,devel opment,training,final arabic system,official performance,supplementary result,task organizer,test set,additional experiment,key aspect,coreference resolution system,parse feature,mention candidate,clustering procedure,parse feature,official automatic parse,golden parse,ontonotes,mention candidate,ent strategy,automatic mention,golden mention,system,section,golden mention boundary,noun phrase,golden parse tree,au tomatic parse,input feature,golden men tions,non-singleton mention,men tions,entity cluster,im portant,golden mention information,golden boundary,ben eficial information,golden mention,auto gm result,result,mean f-score,language,golden mention,official score,result,non-singleton mention,final task complexity,golden mention boundary,mean f-score,chinese,language,result,information,tuning,additional information,learning problem,nev ertheless,language,result,ta bles,instance,recall precision balance,different configuration,experiment,golden parse feature,golden auto,big im provements,mean f-scores,language,chinese,5 c onclusion,machine,system,large margin latent structure perceptron,unrestricted coreference resolution,modeling approach,direct impact,final system performance,latent coreference tree,entropy,feature induction,experiment,latent coreference tree,complex ity,coreference structure,document,learning problem,feasi ble,empirical finding,entropy,feature induction enables,effec tive nonlinear classifier,system, con ll-2012 shared task,coreference resolution,language,ara bic,chinese,english,multi-language task,system,minor adaptation,language dependent feature,future work,second order feature,cluster sensitive feature,acknowledgment,conselho na cional,desenvolvimento cient,fico  e t ecnolo,amparo,pesquisa,janeiro,fundac,desenvolvimento cient,fico  e t ecnolo,first au thor, a c npq doctoral fel lowship,instituto federal,educac,ncia  e t ecnologia,arbores cence,directed graph,science sinica,michael collins,discriminative training meth od,hidden markov model,theory,experi ments,perceptron algorithm,proceeding,conference,empirical method,nat ural language processing,cicero nogueira do santos,davi lope carvalho,tree ensemble,unrestricted coreference resolution,proceeding,fif teenth conference,computational natural lan guage learning,shared task,portland,oregon,association,optimum branching,journal,re search,national bureau,standard,eraldo,fernandes,ulf brefeld,sequence,proceeding,european conference,machine learning,principle,practice,knowledge discovery,greece,eraldo,fernandes,milidiu,entropy,feature generation,structured learning,portuguese dependency,proceeding,conference,computational processing,volume,lecture note,computer science,heeyoung lee,peirsman,angel chang,nathanael chamber,mihai surdeanu,dan jurafsky,stanford,multi-pass sieve coreference resolution sys tem, con ll-2011,proceeding,fifteenth conference,computational natu ral language learning,shared task, con ll shared task,sociation,computational linguistics,ryan  mcd onald,koby crammer,fernando pereira,large-margin training,dependency parser,proceeding,annual meeting,association,ryan  mcd onald,kevin lerman,fernando pereira,multilingual dependency analysis,two-stage discriminative parser,proceeding,conference,do santos,duarte,phrase,entropy,transformation learning,proceeding,columbus,sameer pradhan,alessandro moschitti,nianwen xue,olga uryupina,yuchen zhang,multilingual unrestricted coreference,ontonotes,proceeding,sixteenth conference,frank rosenblatt,perceptron,perceiving,automaton,technical report,cornell aeronautical laboratory,al tun,margin method,interdependent output variable,journal,chun-nam yu,thorsten joachim,structural  svm,latent variable,proceeding,international conference