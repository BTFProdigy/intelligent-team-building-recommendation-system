proceeding,annual meeting,association,computational linguistics,uppsala,sweden,association,computational linguistics modeling semantic relevance,question-answer pair,web social community baoxun wang,xiaolong wang,chengjie sun,bingquan liu,lin sun school,computer science,technology harbin institute,technology harbin,china bxwang,wangxl,lsun insun,cn abstract,semantic relevance,tween question,candidate,detection,social medium corpus,deep belief network,semantic relevance,textual similarity,community-driven question,dataset,forum dataset,strat egy,performance,method,social community datasets,hand-annotating work,ex perimental result,method,traditional approach,forum corpus,1 i ntroduction,question,problem,much attention,past year,factoid question,related doc uments,international evalu ation,factoid qa task,annotated question,answer,im portant resource,researcher,non-factoid question,automatic qa system,user-generated question-answer pair,great importance,non factoid question,natural qa pair,people,com munication,internet social medium,online fo rum,system,plat form,ask question,answer,answer, cqa site,online forum,virtual society characteristic,people,discussion,certain domain,tech niques,travel,online forum,huge number,qa pair,noise infor mation,qa pair, cqa site,online forum,problem,question,answer,investi gation,community,obvious charac teristics,short content,person,informal tone,community,noisy environment,detection,novel approach,semantic relevance,qa pair,problem,semantic relationship,short text,simple textual fea tures,question,answer,social medium,short text,limitation,length lead,sparsity,addition,word frequency,frequency,little information,occurrence,situation,traditional relevance,method,word co-occurrence,cosine similarity,kl-divergence,question,zhidao,answer,answer semantic modeling,researcher,structural feature,behavior,model performance,contrast,effect,textual feature,formance,forum datasets,people,qa research,surdeanu,relationship, cqa system,online forum,open platform,people,nicate,qa pair, cqa system,ilarity,strategy,performance,datasets,addition,arduous hand-annotating work,method,first problem,semantic rel evance,question,answer,network,semantic relationship,qa pair,answer-to-question,word feature,traditional method,relevance calculating,second problem,semantic knowledge,solved question thread, cqa system,structure,feature, cqa page,forum thread,textual similarity,semantic information,cqa corpus,answer,model show good performance,social medium corpus,thanks,answer,thread,manual work,strategy,section,survey,related work,section,troduces,deep belief network,answer,tection,section,homogenous data,learning strategy,experimental result,section,conclusion,fu ture direction,section,question answer pair,recent year,early study,qa pair,jijkoun,riezler,call-center dialogue,berger,candidate answer,question, cqa page,challenging task,frame work,quality,answer,gurevych,transla tion,method,answer,surdeanu,approach,yahoo answer,surdeanu,candidate answer,ranking algorithm,word informa tion,combination,different kind,feature,people,considerable freedom,great number,irrel evant post,question,answer,exploratory study,tract input-reply pair,discussion-bot,outstanding research,forum qa extraction,question con text,answer,conditional random field,ranking algorithm,au thority,forum user,detection,binary clas sification problem,intuitive idea,davison,davison,high precision,corpus,importance,feature,answer,ques tion,problem,lexical gap,problem,lexical gap embedding,similar question,qa achieves,statistical machine trans,strategy,use translate model,lexi cal gap,question,qa col lections,method,semantic relationship,ques tions,answer,answer retrieval,riezler,berger,bernhard,gurevych,translation model,feature,answer ranking,structural feature,authorship,ac knowledgement,post position,non-textual feature,important role,extraction,feature,performance,structural feature,contribution,textual feature,mining,textual feature,research topic,strategy,question,social medium corpus,non-trivial task,deep research,question detection,algorithm,opinion question,email sum marization field,qa pair,email content,main element,email summarization,shrestha,deep belief network,qa pair due,feature sparsity,low word fre quency,social medium corpus,semantic relevance,ques tions,answer,co-occurrence fea tures,semantic link,question,answer,different lexical representation,se mantic knowledge,great num ber,question,information,answer,section,deep belief network,seman tic relationship,question,qa data,low-dimensional semantic-feature space,question,answer,restricted boltzmann machine,ensemble,binary vector,two-layer network,mension,approach, rbm ini,good performance,image process,hinton,salakhutdinov,hinton,deep graphical model,information re trieval field,semantic information hidden,word count vector,figure,two-layer network,bottom layer,visible vector,top layer,latent fea ture,matrix,symmetric,teraction term,visible unit,hidden unit,input vector,trained figure,boltzmann machine rbm model,hidden feature,minimum er ror,training algorithm,next subsection,ability,deep belief network,semantic relevance,tween question,answer, a d eep belief network,social medium corpus,answer,al way,several sen tences,answer,strong seman tic association,question,information,question,deep belief network,ques tion,answer,training object,reconstruction,pretraining process,good re gion,parameter space,illustration, dbn model,figure,variant,bottom layer,variant form,qa pair,classi cal  rbm,bottom layer,hidden,visible answer vector,question vector,hidden feature,pre-training procedure,architecture,bottom layer,binary feature vector,statistic,word occurrence,answer,hidden feature,figure,deep belief network,qa pair,ques tions,hidden feature,process,visible feature vector,answer,ith element,question vector,hid den feature vector,question,symmetric interaction term,hidden feature,hidden feature,training set,answer vector,bot tom layer,corresponding hidden fea tures,equation,equation,construct,bernoulli rate,question vector,hidden feature,equation,hidden feature,1-step contrastive divergence,hinton,parameter,gradient ascent,expectation,frequency,ques tion,feature,hidden feature,question data,corresponding expec tation,hidden feature,reconstructed question data,classical  rbm structure,middle layer,top layer,network,training method,input data,hidden feature,parameter update,gradient ascent,equation,vector,higher-level layer,training data,weight notice,greedy strategy,pre-training proce dure,weight,entire network,optimal reconstruction,weight,network,answer,input data,question,output unit,cross-entropy error function,network,backpropagation,experiment result,section,network performs,detection,best answer detection,deep belief network,qa pair,answer,question,vector,question,candidate answer,input unit,network,level-by-level calculation,corresponding feature vector,distance,mapped question vector,candidate answer vector,candidate answer,distance,homogenous data,section,strategy, dbn model,answer,forum datasets,single dataset,homogenous qa corpus,different source,motivation,homogenous question-answer corpus,different kind,cial medium,performance,hand-annotating work,question,computer technology domain,baidu zhidao, cqa corpus,thread,figure,comparison,post content length,computerfansclub forum4,online forum corpus,domain,corpus,explain,corpus,detail comparison,text style,word distribution,figure,post content length,corpus,comparison, cqa corpus,fo rum corpus,left panel,statistical result,baidu zhidao data,right panel,fo rum data,number,horizontal axis,post content,length,vertical axis rep,post content,content, cqa corpus,forum corpus,length,content length,text style, cqa system,online forum,figure,distribution,content length,figure,content,cor pora,short text,figure,percentage,concurrent word,top-ranked content word,high frequency,detail,frequency,corpus,cho sen,professional dictionary,computer knowl edge field,number,horizontal axis,figure,top content word,cfanclub,net corpus,vertical axis stand,per centage,corpus,top word,figure,distribution,concurrent content word figure,large number,ful word,corpus,high frequency,percentage,concur rent word,word distribution,corpus,different social medium site, cqa corpus,forum corpus,homogenous characteris tic,answer detecting task,simple strategy,hand-annotating work,question,baidu zhidao,answer,question,qa pair, cqa corpus,training,corpus,deep belief network, cqa corpus,answer, cqa data,forum data,feature,answer,social medium,pora suffers,problem,feature sparsity,high-dimensional feature vector,several non-zero dimension,large time consumption,dimension,feature vector,word fea tures,fre quent word,training,salakhutdinov,hinton,statis tic,frequency,rest word,much noise,occurrence,function word,feature,function word,short text,answer,non factoid question,example,answer,causation question,answer,manner question,ex ample,function word selection,figure,figure,example,function word selection,reason,frequent function word,answer,training set,short text,question,answer,500-dimensional vector,feature,corresponding word,5 e xperiments,question-answer semantic rele vance,method,ap proach,popular method,answer,experiment setup architecture,network,deep belief network,1500-1500-1000-600 ar chitecture,net work,network,dimensional binary vector,600-dimensional real-value vector,pretraining stage,bottom layer,entire training set,fine-tuning,method,conjugate gradients5,line search,algorithm,network,dataset,question,computer,network category,baidu zhidao, cqa corpus,thread,com puterfansclub,online forum,com puter knowledge,forum thread,forum corpus, cqa corpus,qa pair,training,manual work,answer,content, cqa page,testing set,content,question,candidate answer,average,answer,testing dataset,thread,forum corpus,training set,hu man work,answer,thread,thread,question,baseline,performance,method,main popular relevance,method,candidate answer,baseline,cosine similarity,question,candidate answer,cosine similarity,wak stand,weight,kth word,question,answer,tuebingen,b people,code minimize,weight,product,term frequency,inverse document fre quency,similarity,hownet6,elec tronic world knowledge system,powerful tool,computation,hu man language technology,similar ity,passage,semantic-similar word,passage,hownet,weighted average similarity,word pair,strat egy,baseline method,relevance,question,answer,divergence language model,ques tion,candidate answer,struct unigram language model mq,unigram language model,kl divergence,analysis,performance,approach,detection,metric,precision,metric,baseline method,method,result,forum data,baseline method,ad ditional,nearest answer,method,ranking strategy,candidate answer,question,po sition,effect,fine-tuning,result,method,fine-tuning,result,deep belief network,method,baseline method,main reason,improve ments,approach,semantic relationship,qa pair,training set,train ing,network,dif ferent source, cqa corpus,knowledge,network,baseline method,phenomenon,dicates,homogenous corpus,training,information,keenage,hownet,kl divergence,result,forum dataset,reason,un satisfying performance,baseline approach,basically,low precision,forum corpus,section,content,forum post,sparsity,feature,besides,message,online forum,synonymous word,significant situ ation,chinese forum,feature,qa pair,quite sparse,con tent word,question,mean ing,answer,cosine similarity,hownet,ap proaches,large number,hownet,similarity,question,answer,divergence suffers,problem,cosine similarity method,cosine similarity method,approach,improvement,baseline method,baseline result,online fo rum,complex environment,large amount,detection,traditional ir method,pure textual feature,good result,similar baseline result,forum answer ranking,davison,non textual feature,algorithm,perfor mance,baseline method,result,forum cor pu,possible reason,baseline approach,answer,strat egy,precision,precision,answer,forum data,fine-tuning,related work,result,precision,davison,rea son,phenomenon,pre vious work,non-textual feature,forum structure,authorship,po sition,feature,significant role,algorithm,performance,quality,corpus influence,result,ranking strategy,algorithm,dataset,davison,experiment,large amount,forum corpus,nothing extra,experimental result,cqa dataset,experiment,sample,question,sev eral candidate answer,answer,candidate answer,question,candi date answer,post time,real answer,question,experiment, cqa user,hownet,kl divergence,result, cqa dataset table,approach,dataset,improvement,high quality qa corpus baidu zhidao,candidate answer,noise information,addition,nearest answer,strategy,dataset,num ber,real answer,first answer post,result,position feature,answer,question thread,noise information, cqa corpus,baseline method,performance,approach,improvement,improvement, cqa dataset,perfor mance,previous experiment,training set,testing,corpus, dbn model, cqa data,experiment,fine-tuning,performance,forum data,result,improve ments,6 c onclusions,deep belief net work,approach,semantic rel evance,question,social community corpus,contribution,deep belief network,present show good performance,qa pair,semantic relevance,word fea tures,data driven approach,semantic knowledge,large amount,qa pair,semantic relevance,question,answer,textual similarity,forum datasets,qa pair extraction,intro duce,strategy,method show good performance,forum datasets,experimental result,method,traditional approach,forum corpus,future work,direction,performance,method,non textual feature,research,architecture,deep network,qa detection,author,anonymous re viewer,constructive comment,special thanks,deyuan zhang,bin liu,beidong liu,ke sun,insightful suggestion,reference adam berger,rich caruana,david cohn,dayne fre itag,vibhu mittal,lexi cal chasm,statistical approach,proceeding,annual international acm  sig ir conference,research,information retrieval,delphine bernhard,iryna gurevych,lexical semantic resource,question answer archive,translation-based answer find ing,proceeding,joint conference,47th annual meeting,ternational joint conference,natural language processing, afn lp,suntec,singapore,august,association,computational linguistics,gao cong,long wang,chin-yew lin,young-in song,yueheng sun,question-answer pair,online forum,annual international  acm  sig ir conference,research,development,infor mation retrieval,shilin ding,gao cong,chin-yew lin,xiaoyan zhu,conditional random field,tract context,answer,question,online forum,proceeding,columbus,association,computational linguistics,huizhong duan,yunbo cao,chin-yew lin,question,ques tion topic,question focus,proceeding,columbus,association,computational linguistics,donghui feng,erin shaw,jihie kim,eduard,intelligent discussion-bot,swering student query,threaded discussion,ccile paris,candace,sidner,editor,hinton,dimensionality,neural network,science,georey,hinton,product,expert,contrastive divergence,neural com putation,davison,classification-based approach,question,discussion board,international  acm  sig ir conference,research,development,information retrieval,jizhou huang,ming zhou,dan yang,chatbot knowledge,online discussion forum,ternational joint conference,artifical intelligence,morgan kaufmann publisher inc,joon ho lee,similar question,large question,swer archive,joon ho lee,soyeon park,framework,quality,answer,non-textual feature,valentin jijkoun,maarten de rijke,retriev,answer,question page,jung-tae lee,sang-bum kim,young-in song,hae-chang rim,lexical gap,tween query,question,large online,collection,compact translation model,conference,em pirical method,natural language processing,association,computational linguistics,minlie huang,xiaoyan zhu,opinion question,random walk,proceeding,joint conference,47th annual meeting,international joint conference,natural language processing, afn lp,suntec,singapore,august,association,computational linguistics,stefan riezler,alexander vasserman,ioannis tsochantaridis,vibhu mittal,yi liu,statistical machine translation,query expansion,answer retrieval,proceeding,45th annual meeting,association,computa tional linguistics,prague,czech republic,association,computational linguistics,ruslan salakhutdinov,geoffrey hinton,semantic hashing,reasoning,lokesh shrestha,kathleen  mck,de tection,question-answer pair,email conversa tions,proceeding,coling,geneva,switzerland,mihai surdeanu,massimiliano ciaramita,hugo zaragoza,answer,large online qa collection,proceeding,columbus,asso ciation,computational linguistics,baoxun wang,bingquan liu,chengjie sun,lin sun,chinese question-answer pair,online forum,proceeding, iee e in ternational con ference,system,cybernetics,proceeding,annual meeting,association,computational linguistics,bulgaria,august,association,computational linguistics multimodal  dbn,high-quality answer,baoxun wang,ming liu,xiaolong wang school,computer science,technology harbin institute,technology,china hfhu,bxwang,cn abstract,problem, cqa answer quality,clas sification task,multimodal deep belief net,approach,erates,joint rep resentation,non-textual feature,deep learning network,joint repre sentation,network,input feature,linear classifier,ex tensive experimental result, cqa datasets,effec tiveness,approach,1 i ntroduction,quality,answer,communi ty,question answering,portal,challenging task,straightforward approach,textual feature,text classification task,agichtein,word over-sparsity,inherent noise,content,classical bag-of-words rep resentation,qual ity,short text,typ ical approach,non-textual feature,high quality answer,mining,meaningful textual feature,non textual information,answer,performance,predict,answer quality,non textual feature,different kind,rep resentations,correlation,previous study,shallow model,correlation,multiple source,deep learning approach,problem,answer quality,approach,feature learning,training,former stage,deep network,unified representation,non-textual information,latter stage,output,network,linear classifier,prediction,related work,section,approach,experimental result,section,section,respec,conclusion,future direction,section,typical way,answer quality,various feature,machine,method,example,framework,qual ity,answer,non-textual fea tures,maximum entropy model,bian et al,feature,high quality answer,deep research,answer quality,pomer antz,logistic regression model,deep learning field,extensive study,hinton,co-worker,hin ton,hinton,salakhutdinov,salakhutdinov,hinton,initial ly,deep belief net,semantic relevance,qa pair,social communi tie,feature,disparate source,hot research topic,demonstrate,hidden represen tations,convolutional  dbn,excellent feature,visual recognition,3 a pproach,problem,high-quality answer prediction,classification task,figure,framework,approach,textual feature,non-textual feature ex textualfeatures non-textualfeaturescqaarchives classifierfusion representation featurelearning,training high-qualityanswers figure,framework,approach, cqa portal,db model,high-level representation,answer,high-level representation,deep architecture, a r bm model,linear classifier,representation,prediction,section,deep network,swer quality prediction,non-textual feature,distinct statistical property,correlation,dif ficult,shallow model,corre lations,informative unified represen tation,motivation,problem,unified represen tation,classification performance,restricted boltzmann machine,basic building block,feature,component,classical  rbm,two-layer undi,graphical model,stochastic visible nit,stochastic hidden unit,visible layer,hidden layer,symmetric matrix,classical  rbm,distribution,binary-value data,real-value input,gaussian  rbm,bengio,different,hypothesis,visible unit,gaussian  rbm,normal distribution,feature,illustration,feature,figure,data modality,two-layer  dbn sep,clarity,textual modality,example,construction,textual input vector,visible layer,hidden vector,conditional distribution,logistic function,parameter,perform,gradient ascent,algorithm,hinton,bottom layer,activation probability,hidden unit,training data,new layer,construction,non-textual modality,gaussian  rbm,real-value input,bottom layer,additional layer,training method,bottom,input vector,concatena tion,mapped textual vector,mapped non-textual vector,figure,feature,network,bottom part,joint representation,correlation,non-textual feature, a r bm,dis parate source,correlation,supervised training,classification,deep network,feature,non-textual data,classifier,unified representation,srivastava,salakhutdinov,lr classifier,final prediction,experiment,performance,basic feature textual feature,textual feature,frequent word,train ing dataset,word segmentation,stopwords removal,stemming1,result,answer,vector,distinct term,binary scheme,non-textual feature,previous work,pomerantz,feature,additional feature,complete list,feature type length,question title,description,integer length,answer integer number,unique word,answer,question integer number,comment,question integer number,question,answerer,integer number,question,answerer,answer ratio float table,summary,non-textual feature,4 e xperiments,experiment,datasets,dataset,baidu zhi dao2,question,travel,category,oth er dataset,yahoo answers3,dataset, zhi dao , yah oo,question,experimental datasets,er name,user profile web page,non-textual feature collection,ate unnecessary noise,ques tions,number,answer,english corpus,zhidao,answer,answer,answer,statistic,datasets,experiment,statistic item  yah oo  zhi dao,question,answer,answer,question,statistic,experimental datasets,baseline,evaluation metric,following method,base line,imple ment,approach,pomer antz,textual feature lr-t,non textual feature lr-n,simple combina tion lr-c,output,last hidden layer,lr model,fea ture set,textual feature,non-textual feature,high quality,precision,recall,positive class,overall accuracy,evaluation metric,model architecture,training detail, mdb architecture,classi cal  rbm,visible unit,hidden layer,unit respective ly,textual branch,gaussian  rbm,visible unit,hidden layer,non textual branch,joint layer,network,real-value unit,training stage,small weight-cost,learning rate,textu al data modal,non-textual data,monument,rest epoch,addition,non-textual data vector,unit standard variance,detail,deep architecture,hinton,result,analysis,first experiment,perfor mance,different method,fare comparison,liblinear toolkit4,logistic regression model,l2 regularization,training data,tw cjlin,average result,round experiment, yah oo, zhi dao ,method,comparing result, yah oo, mdb method,method,datasets,metric,recall,main reason,improvement,joint representation,modality,addition,representation,semantic relationship,non-textual information,complicated answer,high quality,low quality,method,comparing result, zhi daoth classification performance,textu al feature,average,non-textual feature,feature learn,strategy,simple combination,non textual feature,classification result,non-textual feature,reason,phenomenon,user-generated content,low word frequency,sparsity,textual feature,non-textual feature,length,statistical property,feature sparsity problem,extent,ince correlation,textual feature,non-textual feature,feature,classification performance,advantage,repre sentation,textual feature,non-textual feature,deep learning architecture,approach,quality,datasets,precision, zhi dao , yah oo,high quality answer,possible reason,quali ty,corpus,question,aver age,answer, zhi dao , yah oo,several answer,high quali ty,question,high quality answer,iteration,precision recall f1 accuracy figure,influence,iteration, mdb nin,second experiment,performance,different num ber,iteration,figure,metric,zhi dao ,iteration number,result,first observa tion,number,iteration,performance,result,iteration,representation power,large number,detri mental performance,large number,iteration,deep learning architecture,similar trend, yah oo,onclusions,future work,new perspec tive, cqa answer quality,informative unified representation,non-textual feature,concate,multimodal deep learning framework,unified representation,basic feature,isolation,combination,experimental result,approach,complementarity,non-textual feature,perfor mance,quality prediction,future work,se mantic analysis,short tex quality evaluation,research,approach,multimodal representation,author,anonymous re viewer,constructive comment,spe cial thanks,chengjie sun,deyuan zhang,insightful suggestion,national natural science foundation,reference,mishne,high-quality content,social medium,proceeding,internation,conference,web search,web data mining,yoshua bengio,pascal lamblin,dan popovici,hugo larochelle,greedy layer-wise training,deep network,advance,neural informa tion,system,jiang bian,yandong liu,ding zhou,eugene agichtein,hongyuan zha,reliable user,content,social medium,coupled mutual reinforcement,proceeding,international conference,world wide web,analysis,question answer portal,author ranking,inter national conference,web intelligence,intel ligent agent technology,volume,hinton,salakhutdinov,dimensionality,neural network,science,fast learning algorithm,deep belief net,neural com putation,hinton,product,expert,contrastive divergence,neural compu tation,hinton,practical guide,boltzmann machine,lecture note,com puter science,minlie huang,yi yang,xiaoyan zhu,quality-biased ranking,short text,microblog ging service,proceeding,5th internation al joint conference,natural language process ing,framework,quality,answer,non-textual feature,proceeding,nual international  acm  sig ir conference,re search,development,information retrieval,convolutional deep belief network,scalable un,learning,proceeding,annual international conference,machine learning,multimodal deep learning,proceed ings,international conference,hinton,deep boltz mann machine,proceeding,internation,conference,artificial intelligence,statistic,volume,pomerantz,answer quality,pro ceeding,international  acm  sig ir con ference,research,development,information retrieval,salakhutdinov,deep boltzmann machine,advance,semantic relevance,web social community,proceeding,annual meeting,association,computational linguistics,approach,semantic rele vance,chinese question-answer pair,m tr ansactions,asian language information processing,profile information,answer ranking,proceeding,international con ference,world wide web