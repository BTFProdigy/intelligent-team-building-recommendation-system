proceeding
,
conference
,
empirical
method
,
natural
language
processing
,
honolulu
,
october
,
association
,
computational
linguistics
indirect-hmm-based
hypothesis
alignment
,
output
,
robert
moore
,
electrical
engineering
,
microsoft
way
university
,
usa
seattle
,
panguyen
,
microsoft
,
com
yangmei
,
washington
,
a
bstract
,
new
hypothesis
alignment
method
,
output
,
system
,
synonym
matching
,
hypothesis
alignment
,
nlike
traditional
hmm
,
parameter
,
parameter
,
variety
,
source
,
word
semantic
similarity
,
word
surface
similarity,distance-based
distortion
penalty
,
ihm
m-based
method,state-of-the-art
ter
,
alignment
model
,
experiment
,
nis
benchmark
datasets
,
smt
system,method,chinese-to-english
translation
result
,
constrained
training
track
,
nis
t
op
,
mt
evaluation
,
various
machine
translation
task,confusion-network-based
system
combination
algorithm
,
output
,
system
,
consensus
output
,
bangalore
,
matusov
,
sequence
,
alternative
word
,
associated
score
,
consensus
output
,
alternative
,
sequence
,
overall
score
,
various
way
,
voting
,
microsoft
research
,
posterior
probability
estimate
,
combination
,
measure
,
feature
,
confusion
network
,
hypothesis
,
backbone
,
skeleton
,
literature
,
hypothesis
,
word
level
,
high
quality
hypothesis
alignment
,
performance
,
mt
hypothesis
alignment
,
different
hypothesis
,
different
synonymous
word
,
meaning
,
synonym
,
correct
translation
,
different
word
ordering
,
different
hypothesis
,
hypothesis
alignment
,
mt
hypothesis
alignment
,
synonym
matching
,
word
ordering
,
traditional
hmm
,
parameter
,
parameter
,
variety
,
source
,
word
semantic
similarity
,
word
surface
similarity
,
distance
,
distortion
penalty
,
large
amount
,
training
data
,
smt
system,method,result,chinese-to-english
test
,
constrained
training
track
,
nis
t
op
,
2
c
onfusion-network-based
mt
system
combination
,
current
state-of-the-art
,
confusion-network
,
mt
system
combination
,
colleague
,
major
step
,
figure
,
different
mt
system
,
hypothesis
,
backbone
,
hypothesis
alignment
,
method
,
hypothesis
,
minimum
average
distance
,
hypothesis
,
backbone
,
word
order
,
combined
output
,
hypothesis
,
backbone
,
symbol
,
null
word
,
alignment
normalization
algorithm
,
section
,
handling
,
word
re-ordering
,
confusion
network
,
aligned
hypothesis
,
sequence
,
alternative
word
,
local
feature
,
confusion
network
,
nice
sedan
e3
,
hypothesis
,
backbone
selection
e
,
good
car
,
good
car
,
nice
sedan
,
nice
car
,
confusion
network
f
igure,confusion-network-based
mt
system
combination
,
3
i
ndirect-hmm-based
hypothesis
alignment
i,confusion-network-based
system
combination
,
major
difficulty
,
hypothesis
,
backbone
,
possible
statistical
model
,
word
alignment
,
bilingual
word
alignment,indirect-hmm
method
,
monolingual
hypothesis
alignment
,
hypothesis
alignment
l
,
backbone
,
hypothesis
,
alignment
,
position
,
backbone
word
,
hypothesis
word
,
backbone
,
hmm
state
,
hypothesis
,
observation
sequence,first-order
hmm
,
emission
probability
,
backbone
word
,
position
,
last
state
,
length
,
backbone
,
alignment
,
hidden
variable
,
conditional
probability
,
hypothesis
,
backbone
,
backbone
word
,
hypothesis
word
,
backbone
word
,
hypothesis
alignment
,
emission
probability
,
similarity
,
backbone
word
,
hypothesis
word
,
similarity
model
,
transition
,
model
word
reordering
,
distortion
model
,
estimation
,
similarity
model
,
similarity
model
,
emission
probability
,
similarity
,
backbone
word
,
language
,
similarity
model
,
semantic
similarity
,
surface
similarity
,
overall
similarity
model
,
linear
interpolation
,
sem
ip
,
surface
similarity
,
semantic
similarity
,
target
word
,
semantic
similarity
model
,
source
word
sequence
,
hidden
layer
,
target
word,counter-part
,
source
sentence
,
source
side
,
last
step
,
generates
,
source
word
,
source
word
,
common
smt
scenario
,
large
amount
,
bilingual
parallel
data
,
translation
probability
,
source
word
,
target
word
,
vice
versa
,
conventional
bilingual
word
alignment
,
translation
model,source-to-target
word
alignment
model,sum-to-1
constraint
,
source
sentence
,
following
form
,
translation
model,target-to-source
word
alignment
model
,
method
,
target
word
,
constant
pnull,held-out
data
,
similarity
model
,
several
way
,
simple
model
,
exact
match
,
smoothed
surface
similarity
model
,
method
,
target
language
,
alphabetic
orthography
,
english
,
letter
sequence
,
similarity
measure
,
length
,
length
,
raw
similarity
measure
,
surface
similarity
score
,
exponential
mapping
,
raw
similarity
measure
,
length
,
factor
,
mapping
,
approach
infinity
,
exact
match
model
,
smoothed
similarity
model
,
result
,
exact
match
model
,
method
,
similar
performance
,
computation
,
result
,
similarity
model
,
estimation
,
distortion
model
,
distortion
model
,
transition
probability,first-order
dependency
,
word
ordering
,
bilingual
hm
m-based
word
alignment
,
transition
probability
,
direction
,
ip
null,source-to-target
translation
model
,
small
back-off
value
,
i
i
depend
,
jump
distance
,
bucket
,
implementation
,
bucket
,
probability
mass
,
transition
,
jump
distance
,
handful
,
parameter
,
em
algorithm
,
small
development
,
simple
model
,
experiment
,
s
ince
,
backbone
,
hypothesis
,
language
,
distortion
model
,
monotonic
alignment,non-monotonic
alignment
,
certain
penalty
,
distortion
model
,
following
form,factor,held-out
data
,
distortion
score
peak
,
monotonic
alignment,non-monotonic
alignment
,
monotonic
alignment
,
f
igure,distance-based
distortion
parameter
,
fixed
value
p0
,
probability
,
null
state,held-out
data
,
overall
distortion
model
,
alignment
normalization
g
,
viterbi
alignment
algorithm
,
alignment
,
backbone
,
hypothesis
,
h
owever
,
alignment
,
algorithm
,
confusion
network
,
reason
,
alignment
,
1-n
mapping,backbone,hypothesis,1-1
mapping
,
confusion
network
,
second
,
hypothesis
word
,
backbone
,
vice
versa
,
actual
null
,
right
place
,
hypothesis
,
backbone
,
alignment
,
viterbi
search
,
hypothesis
word
,
backbone
null
e
e1
,
backbone
word
,
hypothesis
word
f
igure
,
illustration
,
alignment
normalization
f
,
hypothesis
word
,
backbone
word
,
occupation
probability,forward-backward
algorithm
,
hypothesis
word
,
backbone
word
,
hypothesis
word
,
particular
null
,
backbone
side
,
backbone
word
,
backbone
word
,
backbone
word
e2
,
hypothesis
word
,
hypothesis
word
,
hypothesis
word
,
backbone
word
,
backbone
word
,
backbone
word
,
hypothesis
word
,
hypothesis
side
,
hypothesis
word
,
backbone
word
,
example
,
main
hypothesis
alignment
method
,
system
combination
,
previous
literature
,
gi
za
,
method
,
matusov
,
different
mt
hypothesis
,
hypothesis
,
test
corpus
,
hypothesis
pair
,
training
,
approach
,
conventional
hmm
model
,
ibm
model-1
,
combine
result
,
direction
,
system
combination
,
approach
,
improvement
,
number
,
hypothesis
pair
,
training
,
source
sentence
,
hypothesis
pair
,
data
sample
,
data
set
,
multiple
string
,
algorithm
,
levenshtein
edit
distance,er-based
method
,
snover
,
hypothesis
word
,
backbone
word
,
hypothesis
word
,
backbone
word
,
minimum
number
,
substitution
,
insertion
,
deletion
,
hypothesis
,
hypothesis
,
alignment
,
minimum
number
,
translation
edits,r-based
confusion
network
construction
,
system
combination
,
superior
performance
,
various
large-scale
mt
task
,
optimal
alignment
,
te
r-based
method
,
strict
surface
hard
match
,
synonym
,
alignment
allows,non-monotonic
word
ordering,non-monotonic
shift,matter,penalty,substitution,deletion,modeling,non-monotonic
word
ordering
,
i
contrast
,
method
,
ih
mm-based
method
,
similarity
model
,
bilingual
word
alignment
hmm
,
large
amount
,
surface
similarity
information
,
parameter
initialization
,
ib
m
mo
del-1
training
,
matusov
,
alignment
model
,
non
normalized
version
,
similarity
model
,
penalty
,
exact
surface
match
,
fixed
penalty
,
substitution
,
insertion
,
deletion
,
distortion
model
,
penalty
,
monotonic
jump
,
fixed
penalty,non-exact-match
penalty
,
hypothesis
alignment
method
,
karakos
,
method
,
hypothesis
alignment
,
incremental
alignment
method,heuristic-based
matching
algorithm
,
jayaraman
,
5
e
valuation
,
section
,
ihm
m-based
hypothesis
alignment
method
,
constrained
training
track
,
nis
t
op
,
compare
,
method
,
following
experiment
,
nis
t
bleu
score
,
evaluation
,
papineni
,
percentage
,
following
section
,
implementation
detail
,
implementation
,
backbone
,
top
hypothesis
,
single
system
,
backbone
,
uniform
posteriori
probability
,
loss
function
,
mb
computation
,
confusion
network
,
word
posterior
probability,system,hypothesis,rank-based
score
,
hypothesis
,
parameter
,
system
specific
rank-based
score,system,rank-based
score
,
hypothesis
,
system
,
position
,
hypothesis
alignment
,
alternative
word
,
position
,
system
,
system
specific
word
posterior
,
total
word
posterior
,
system
,
system
specific
posterior
,
system
weight
,
word
posterior
,
language
model
score
,
word
count
,
feature
,
confusion
network,m-way
system
combination
,
n
l
m,parameter,m-1
system
weight
,
factor
,
language
model
weight
,
weight
,
word
count
feature
,
powell
,
method
,
ble
score
,
language
model
,
experiment
,
trigram
model
,
english
side
,
parallel
training
data,5-gram
model
,
english
gigaword
corpus
,
ms
rlm
toolkit
,
nguyen
,
fluctuation
,
ble
score
,
inconsistent
translation
output
length
,
unsupervised
length
adaptation
method
,
expected
length
ratio
,
mt
output
,
source
sentence
,
development
set
,
maximum
ble
training
,
length
,
translation
output
,
weight
,
word
count
feature
,
output
source
length
ratio
,
experiment
,
length
adaptation
,
system
combination
output
,
whole
test
corpus
,
development
,
test
data
t
,
development
,
system
combination
parameter
training
,
sentence
,
previous
nis
t
mt
chinese-to-english
test
set
,
test
set
,
test
set,sentence,newswire,web-data
genre
,
test
set
,
reference
,
system
combination,10-best
hypothesis
,
source
sentence
,
test
set
,
single
system
,
output
,
mt08
test
set,log-linear
conditional
markov
model
,
toutanova
,
computation
effort
,
result
,
experimental
result
,
main
experiment
,
output
,
single
mt
system,tree-to-string
system
,
phrase
,
system
,
fast
pruning,phrase-based
system
,
syntactic
source,syntax-based
pre
,
system
,
hierarchical
system
,
chiang
,
lexicalized
re-ordering
system
,
pas
phrase-based
system
,
adapted
lm
,
foster
,
hierarchical
system,two-pass
,
parser-based
lm
,
confines
,
constrained
training
condition
,
ni
st
mt08
evaluation
,
single
system,maximum-bleu
training
,
different
subset
,
previous
nis
t
mt
test
data
,
bilingual
translation
model
,
semantic
similarity
,
word
dependent
hmm
,
parallel
sentence-pairs
,
training
corpus
,
constrained
training
condition
,
ter
alignment
,
ihm
m-based
method
,
smoothing
factor
,
surface
similarity
model
,
interpolation
factor
,
overall
similarity
model,factor,distance-based
distortion
parameter
,
setting
,
system
combination
result
,
ter
alignment
,
test
set
,
hypothesis
alignment
tool
,
experiment
,
snover
,
ter
com
,
following
experiment
,
dev
set
,
case
insensitive
ble
score
,
ihm
m-based
8-way
system
combination
output
,
single
system
,
method
,
ihm
m-based
method
,
bl
eu
point
,
mt08
test
set
,
ih
mm-based
system
combination
,
case
sensitive
ble
score
,
single
system
,
te
r-based
system
combination
,
single
system
,
dev
set
,
test
set
,
different
single
system
,
discrepancy
,
test
set
result
,
degree
,
mismatch
,
test
set
,
result
,
combined
system
,
dev
set
,
system
,
system
,
system
,
system
,
system
,
system
,
system
,
i
order
,
method
performs
,
system
,
mt
output
,
additional
single
system,system,sys-12
,
first
group
,
syntax
augmented
hierarchical
system
,
different
chinese
word
segmentation
,
language
model
,
second
group,sys-15
,
sys-13
,
phrasal
system
,
hierarchical
system,chiang,sys-15
,
syntax-based
system
,
galley
,
system
,
confines
,
constrained
training
condition
,
nis
t
mt,evaluation,10-best
mt
,
extra
system
,
present
,
system
combination
parameter
,
way
system
combination
,
system
weight
,
following
heuristic
,
total
system
,
total
system
,
weight
mass
,
first
group
,
original
weight
,
system
,
third
group
,
weight
mass
,
system
,
system
,
final
output
length
,
length
ratio
,
previous
8-way
system
combination,result,15-way
system
combination
,
method
,
1
b
leu
point
,
method
,
single
system
,
output
,
ist
ble
score
,
submission
,
nis
t
mt
,
knowledge
,
result
,
result
,
additional
single
system
,
nis
t
mt,system,system,system,system,system,system,result,15-way
system
combination
,
nis
t
mt
,
c2e
test
,
ih
mm
,
similarity
model
i
,
section
,
effect
,
semantic
similarity
model
,
surface
similarity
model
,
interpolation
weight
,
result
,
test
set
,
extreme
case
,
overall
similarity
model
,
semantic
similarity
,
case
insensitive
ble
score
,
case
sensitive
ble
score
,
test
set
,
accuracy
,
dev
set
,
extreme
case
,
rough
guess
,
system
weight
,
common
dev
,
surface
similarity
model
,
overall
similarity
model
,
performance
degrades
,
surface
similarity
information
,
monolingual
hypothesis
alignment,sub-models
,
effect
,
similarity
model
d
,
distortion
model
w,effect,distance-based
distortion
model
,
factor
,
example
,
linear
decay
distortion
model
,
quadratic
smoothed
distance-based
distortion
model
,
optimal
result
,
distance
,
distortion
model
,
effect
,
distortion
model
d
,
6
c
onclusion
synonym
matching
,
word
ordering
,
central
issue
,
hypothesis
alignment
,
ihm
m-based
method
,
hypothesis
alignment
,
similarity
model
,
synonym
matching
,
distortion
model
,
word
ordering
,
contrast
,
previous
method
,
similarity
model
,
surface
word
similarity
,
monolingual
word
alignment
,
smoothed
distance-based
distortion
model,first-order
dependency
,
word
ordering
,
approach
,
experimental
result
,
hypothesis
alignment
method
,
superior
result
,
nis
t
mt
,
c2e
test
,
method
,
system
combination
method
,
system
,
output
,
case
sensitive
ble
score
,
official
submission
,
author
,
chris
quirk
,
arul
menezes
,
kristina
toutanova
,
william
dolan
,
george
foster
,
roland
kuhn
,
jing
zheng
,
wen
wang
,
necip
fazil
ayan
,
dimitra
vergyri
,
nicolas
scheffer
,
andreas
stolcke
,
kevin
knight,jens-soenke
voeckler
,
spyros
matsoukas,antti-veikko
rosti
,
assistance
,
mt
system
,
valuable
suggestion
,
discussion
,
r
eferences
,
rinivas
bangalore
,
german
bordel
,
giuseppe
riccardi
,
consensus
translation
,
multiple
machine
translation
system
,
iee
e
asru,algorithm,minimization,derivative,prentice-hall
,
chapter
,
hierarchical
phrase-based
translation
,
computational
linguistics
,
roland
kuhn,mixture-model
adaptation
,
second
acl
workshop
,
statistical
machine
translation
,
jonathan
graehl
,
kevin
knight
,
daniel
marcu
,
steve
den
eefe
,
wei
wang
,
ignacio
thayer
,
scalable
inference,training,context-rich
syntactic
translation
model,word-dependent
transition
model
,
word
alignment
,
statistical
machine
translation
,
second
acl
workshop
,
alon
lavie
,
multi
engine
machine
translation
,
explicit
word
matching
,
jason
eisner
,
sanjeev
khudanpur
,
markus
dreyer
,
machine
translation
system
combination
,
acl
-
hlt
,
yi
guan
,
robabilistic
approach,syntax-based
reordering
,
statistical
machine
translation
,
ben
taskar
,
dan
klein
,
agreement
,
naa
cl
,
vgeny
matusov
,
nicola
ueffing
,
hermann
ney
,
consensus
translation
,
multiple
machine
translation
system
,
enhanced
hypothesis
alignment
,
chris
quirk
,
faster
beam
search
decoding
,
phrasal
statistical
machine
translation
,
jianfeng
gao
,
milind
mahajan
,
scalable
language
,
toolkit
,
nis
t
op
,
machine
translation
evaluation
,
gov
speech
test
,
doc
f
ranz
,
hermann
ney
,
systematic
comparison
,
various
statistical
alignment
model
,
omputational
linguistics
,
salim
roukos
,
todd
ward
,
wei
jing
zhu
,
method
,
automatic
evaluation
,
machine
translation
,
philipp
,
franz
josef
och
,
daniel
marcu
,
statistical
phrase
,
translation
,
arul
menezes
,
colin
cherry
,
phrasal
smt
,
bing
xiang
,
necip
fazil
ayan
,
output
,
multiple
machine
translation
system
,
naa
cl
-
hl
,
spyros
matsoukas
,
richard
schwartz,word-level
system
combination
,
machine
translation
,
bing
zhang
,
spyros
matsoukas
,
richard
schwartz
,
incremental
hypothesis
alignment
,
building
confusion
network
,
application
,
machine
translation
system
combination
,
third
acl
workshop
,
statistical
machine
translation
,
ew
string-to-dependency
machine
translation
algorithm
,
a
t
arget
dependency
language
model
,
acl
-
hlt
,
khe
chai
sim
,
william
,
woodland
,
statistical
machine
translation
system
combination
,
bonnie
dorr
,
rich
schwartz
,
linnea
micciulla
,
john
makhoul
,
translation
edit
rate
,
hisami
suzuki
,
achim
ruopp
,
morphology
generation
model
,
machine
translation
,
hermann
ney
,
christoph
tillmann
,
statistical
translation
,
michael
collins
,
philipp
koehn
,
emn
lp-conll
,
andreas
stolcke
,
jing
zheng
,
machine
translation,structured,web-based
language
model
,
iee
e
asru
,
qun
liu
,
shouxun
lin
,
phrase
reordering
model
,
statistical
machine
translation
,
proceeding
,
conference
,
empirical
method
,
natural
language
processing,singapore,6-7
august
,
afn
lp
joint
optimization
,
machine
translation
system
combination
x
,
microsoft
research
o
,
microsoft
way
,
com
kristina
toutanova
microsoft
research
o
,
microsoft
way
,
com
a
bstract
system
combination
,
powerful
method
,
joint
optimization
strategy
,
output
,
multiple
mt
system
,
word
alignment
,
lexical
selection
decision
,
feature
function
,
single
log-linear
model
,
algorithm
,
detail
,
new
feature
,
joint
decoding
approach,approach,comparison,confusion-network-based
system
combination
method
,
equivalent
feature
,
ntroduction
system
combination
,
powerful
method
,
strength
,
multiple
mt
system,result,bangalore,matusov,state-of-the-art
system
combination
method
,
several
input
translation
hypothesis,output,function,matusov,word-level
system
combination
,
sentence
re-ranking
method,phrase-level
combination,confusion-network-based
system
combination
,
example
,
figure
,
figure
,
translation
hypothesis,chinese-to
english
mt
system
,
general
idea
,
hypothesis
,
representation
,
figure
,
word
position
,
possible
word
,
column
,
final
output
,
column
,
real
word
,
example
,
distinct
sequence
,
choice
,
scoring
function,feature,log-linear
model
,
matusov
,
confusion
network
,
ordered
sequence
,
column
,
correspondence
set
,
ach
word
,
input
hypothesis
belongs
,
correspondence
,
correspondence
,
contains
,
input
hypothesis
,
final
output
,
final
word
,
output
,
correspondence
set
,
representation
,
arrange
word
,
correspondence
set
,
alignment
problem
,
order
correspondence
set
,
problem
,
confusion
network
,
decide
,
output
,
correspondence
,
lexical
choice
problem
,
current
state-of-the-art
approach
,
construction
,
confusion
network
,
backbone
hypothesis
,
backbone
hypothesis
,
final
system
output
,
guide
word-level
alignment
,
construction
,
column
,
possible
word
,
position
,
example
,
figure
,
second
hypothesis
,
backbone
,
hypothesis
,
backbone
,
alignment
,
empty
word,one-to-one
1
t
,
representation
,
acyclic
graph
representation
,
confusion
network
,
alignment
,
hypothesis
,
position
,
backbone
word
,
confusion
network
,
quality
,
selection
,
backbone
,
alignment
,
large
impact
,
performance
,
word
order
,
backbone
,
possible
word
,
position
,
alignment
,
possible
alignment
,
heuristic
technique,pair-wise
alignment
,
hypothesis
,
backbone
,
separate
processing
,
multiple
alignment
,
several
model,pair-wise
alignment
,
sophisticated
technique
,
hmm
model
,
matusov
,
al2008
,
krakos
,
method
,
hypothesis
,
backbone
,
optimal
behavior,example,state-of-the-art
word
alignment
model
,
hypothesis
,
figure
,
show
likely
alignment
link
,
hypothesis
,
hypothesis
,
similar
chinese
content
,
backbone
,
alignment
,
empty
word
,
network
,
result
,
process
,
undesirable
property
,
instance
,
separate
column
,
independence
assumption,pair-wise
alignment
,
example
,
method
,
hypothesis
,
backbone
,
instance
,
hypothesis
,
backbone
,
desirable
output
,
jeep
suv
,
confusion
network
,
re
reordering,column,cn-based
approach
,
backbone
,
alignment
,
correspondence
set
,
greedy
step
,
lexical
choice
,
final
output
,
backbone
,
alignment
,
auxiliary
scoring
function
,
heuristic
,
respect
,
good
translation
,
recent
approach
,
assumption
,
input
hypothesis
,
backbone
,
backbone
,
separate
cn
,
decision
,
later
decoding
stage
,
possible
order
,
alignment
,
matusov
,
joint
optimization
method
,
system
combination
,
method
,
alignment
,
lexical
selection
sub
problem
,
single
decoding
framework,log-linear
model
,
f
igure
,
mt
system
,
pair
wise
alignment,pair-wise
alignment
,
incremental
alignment
,
f
igure
,
correspondence
set
,
confusion
network,pair-wise
,
incremental
alignment
,
second
hypothesis
,
backbone
,
large
body
,
mt
system
combination,confusion-network
,
state-of-the-art
method
,
word
alignment
,
correspondence
set
,
method
,
selection
,
backbone
hypothesis
,
introduction
,
relation
,
specific
model
,
specific
,
function
,
confusion
network
algorithm,pair-wise
,
incremental,word-level
alignment
algorithm,correspondence,construction,problem,many-to-many
alignment
,
multiple
insertion
,
deletion
,
prior
work
,
number
,
heuristic
,
problem
,
matusov
,
ome
work
,
decision
,
principled
fashion,model-based
score
,
matusov
,
special
purpose
algorithm
,
heuristic
,
single
alignment
,
approach
,
heuristic
,
alignment
,
concept
,
backbone
,
combination
,
alignment
,
lexical
choice,confusion-network-based
algorithm
,
method
,
mt
system
combination,jayaraman,method,approach,word-level
system
combination
,
word
order
,
single
backbone
hypothesis
,
flexibility
,
selection
,
correspondence
set
,
decoding
,
confusion
network-based
approach
,
algorithm
,
several
important
difference
,
pair
wise
alignment
,
different
hypothesis
,
probability
,
hypothesis
,
hypothesis
,
uncertainty
,
correspondence
set
,
aligned
word
,
partial
hypothesis
,
search
,
hypothesis
,
heuristic
matching
,
unused
word
,
i
contrast
,
algorithm
,
definition
,
joint
scoring
model
,
account
alignment
uncertainty
,
combine
information,word-level
alignment
model
,
lexical
selection
model,sub-problems
,
word-level
system
combination
,
addition
,
language
model,word-voting
feature
,
feature
,
alignment
confidence,word-level
alignment
model,feature,re-ordering
,
distortion
model
,
respect
,
original
hypothesis,number,special-purpose
heuristic
,
phenomenon
,
unused
word
,
last
used
word
,
heuristic
,
search
,
assignment
,
hidden
variable
,
ordered
correspondence
set
,
output
variable
,
final
translation,comparison,confusion-network
,
method
,
impact
,
joint
decoding,sub-problems
,
3
n
otation
,
algorithm
,
notation
,
w
denote
,
hypothesis
,
multiple
mt
system,hypothesis,i-th
system
,
word
sequence,simplicity,system,1-best
hypothesis,combination,i-th
hypothesis,weight,i-th
system,scenario,n-best
list
,
individual
system,combination,weight,hypothesis,n-best
list,cn-based
system
combination
,
input
hypothesis
,
final
output
,
hypothesis
,
final
output
,
valid
complete
set,non-empty
word
,
hypothesis
,
algorithm
,
ordered
correspondence
set
,
joint
decoding
process
,
lexical
selection
,
presentation
,
feature
,
notation
,
sequence
,
correspondence
set
,
correspondence
,
position
,
respective
input
,
hypothesis
,
input
hypothesis
,
special
empty
word,position,li-th
word,i-th
hypothesis
,
position
,
original
hypothesis
,
correspondingly
,
example
,
correspondence
set
,
surface
form
,
different
hypothesis
,
single
candidate
,
different
original
word
position
,
decoding
process
,
joint
optimization
framework
,
system
combination
,
joint
decoding
framework
,
optimal
output
,
following
log-linear
model
,
possible
valid
arrangement
,
possible
order
,
possible
word
sequence
,
feature
,
feature
weight,log-linear
model
,
feature
a
set
,
feature
,
alignment
,
lexical
selection
sub
problem
,
feature
,
w
ord
posterior
model
,
word
posterior
feature
,
posterior
,
single
word
,
weighted
voting
score
,
number
,
length
,
output
word
sequence
,
empty
word,i-gram
voting
model
,
second
feature,bi-gram
voting
feature
,
weighted
position-independent
voting
score
,
global
bi-gram
voting
feature
,
conventional
cn-based
system
combination
,
flexible
order
,
joint
decoding
framework
,
distortion
,
different
ordering
,
distortion
model
,
distortion
cost
,
single
hypothesis
,
distortion
penalty
,
conventional
phrase
,
decoder
,
distortion
cost
,
position
,
distance
,
distortion
cost
,
position
vector
,
original
position
,
weighted
sum,single-hypothesis-based
distortion
cost,k-th
element
,
word
position
vector
,
purpose
,
distortion
feature
,
position
,
empty
word
,
position
,
last
visited
non-empty
word
,
overall
ordering
feature,feature,re-ordering
behavior
,
joint
decoding
framework
,
feature
,
language
model,bi-gram
voting
,
ordering
,
hypothesis
,
valid
complete
set
,
word
alignment
,
different
hypothesis
,
alignment
score
,
alignment
score
,
word
pair
,
word
pair,pair-wise
hypothesis
alignment
,
indirect
hmm
,
input
hypothesis,bi-directional
hypothesis
alignment
,
alignment
score
,
average
,
posterior
probability
,
alignment
link,direction,direction,posterior,held-out
validation,j-th
word
,
anchor
word
,
probability
,
whole
c
,
weighted
sum
,
logarithm
,
alignment
probability
,
global
alignment
score
,
different
hypothesis
,
common
cs
,
purity
,
entropy
,
distinct
word
,
global
entropy
score
,
ther
feature,log-linear
model
,
real
word,n-gram
language
model
,
hese
feature,sub-problems
,
feature
,
decision
,
alignment
,
lexical
selection
,
5
j
oint
decoding
,
core
algorithm
decoding
,
beam
search
,
translation
hypothesis
,
final
output
,
sentence
,
figure
,
decoding
process
,
example
input
hypothesis
,
figure
,
partial
sequence
,
correspondence
set
,
input
hypothesis
,
sequence
,
partial
output
hypothesis
,
initial
decoding
state
,
empty
sequence
,
empty
output
sequence
,
complete
output
candidate
,
input
word
,
state
figure
,
illustration
,
decoding
process
,
i
practice
,
feature
,
hypothesis
,
information
,
decoding
state
,
attribute
,
position
,
input
hypothesis,non-empty
word,tri-gram
lm
,
position
,
figure
,
visited
word
,
filled
circle
,
dotted
pattern
,
filled
circle
,
figure
,
hypothesis
,
third
word
,
hypothesis
,
last
word
,
estimated
future
score
,
expansion
,
figure
,
expansion
,
intermediate
state
,
seed
state
,
seed
state
,
choice
,
unvisited
word
,
example
,
word
jeep
,
first
hypothesis
,
word
suv
,
second
hypothesis
,
seed
state
,
seed
state
,
hypothesis
,
valid
alignment
link
,
seed
word
,
c
state
,
first
seed
state
,
first
hypothesis
,
seed
word
,
empty
word
,
second
hypothesis
,
word
suv
,
alignment
,
figure
,
cs
state
,
complet
,
current
c
,
epv
vector
,
c
state
,
expansion
,
translation
,
jeep
suv
,
confusion
network
,
figure
,
full
search
space
,
joint
decoding
,
product
,
alignment
,
lexical
selection
space
,
length
,
sentence
,
number
,
hypothesis
,
combination
,
therefore
,
technique
,
search
space
,
alignment
link
,
arbitrary
word
,
hypothesis
,
threshold
,
viterbi
alignment
,
direction
,
garbage
collection
problem
,
many
word
,
rare
word
,
alignment
score
,
top
link
,
alignment
,
real
word
,
expansion
,
new
state
,
preceding
state
,
ep
v
,
next
state
,
adjacency
,
position
,
empty
word
,
position
,
last
visited
non-empty
word
,
hypothesis
,
number
,
possible
c
state
,
number
,
hypothesis
,
c
state
,
alignment
score
,
top
k
c
state
,
technique
,
path
recombination,best-first
pruning
,
p
ath
recombination,risk-free
pruning
method
,
hypothesis
,
real
word
,
search
space
,
decoding
process
,
number
,
empty
word
,
certain
number
,
promising
path
,
overall
score
,
estimated
future
score
,
future
score
computation
,
future
score
,
future
cost
,
unfinished
path
,
unvisited
word
,
input
hypothesis
,
backbone
,
greedy
search
,
alignment
,
backbone
,
likely
word
,
alignment
link
score
,
hypothesis
,
hypothesis
,
word
order
,
backbone
,
form
a
c
,
process
,
search
beam
,
approximate
future
path
,
future
feature
score
,
decoding
process
,
leftover
word
,
section
,
technique
,
computation
,
future
score
,
method
,
future
score
,
input
hypothesis
,
final
future
score,hypothesis-dependent
score
,
leftover
input
word
,
certain
point
,
finished
path
,
input
word
,
example
,
situation
,
second
state
,
word
suv
,
third
input
hypothesis
,
adjacent
state
,
extra
score
,
leftover
word
,
ur
approach
,
output
translation
,
leftover
word
,
pseudo
c
,
hypothesis
,
extra
distortion
cost
,
example
,
second
state
,
mt
hypothesis
,
fifth
word
,
third
hypothesis
,
third
hypothesis
,
original
path,left-over
word
,
pseudo
c
,
new
inserted
pseudo
cs
,
word
count
feature
,
dependent
feature
score,bi-gram
voting
,
empty
word
,
distortion
score
,
example
,
figure
,
distortion
cost
,
position
,
distortion
cost
,
difference
,
word
position
,
s
core
,
feature
,
pseudo
c
,
word
posterior
,
c
count
,
local
score
,
future
score
,
process
,
extra
score
,
final
state
,
complete
score
,
complete
score
,
final
output
sentence
,
f
igure
,
leftover
word
,
pseudo
correspondence
,
6
e
valuation
,
experimental
condition
,
joint
decoding
method,threshold,alignment-score-based
pruning
,
maximum
number
,
standard
setting
,
joint
decoding
approach
,
test
set
,
nis
t
op
,
case
insensitive
ble
score
,
percentage
,
c2e
test
set,sentence,newswire,web-data
,
test
sentence
,
reference
,
human
translator
,
individual
system
,
experiment
,
official
submission
,
mt08
c2e
constraint-training
track,submission,1-best
translation
,
whole
test
set
,
feature
weight
,
original
test
set
,
test
set
,
dev
set
,
first
half,newswire,web-data
,
test
set
,
second
half
,
individual
system
,
ble
score
result
,
dev
set
,
system
,
system
,
subset
,
erformance
,
system
,
test
set,pair-wise
hypothesis
alignment
approach
,
incremental
hypothesis
alignment
approach
,
incremental
hmm
,
inchmm
,
lexical
translation
model
,
semantic
similarity
,
parallel
sentence
pair
,
training
corpus
,
ihm
m-based
approach
,
a
b
leu
-
,
loss
function
,
various
parameter
,
inchmm
,
dev
set
,
alignment
feature
score
,
joint
decoding
approach
,
final
combination
output
,
feature
,
feature
,
baseline
system
,
feature
,
joint
decoding
approach,feature,hypothesis,non-constant
feature
,
word
posterior
,
gram
voting
,
language
model
score
,
word
count
,
joint
decoding
approach
,
s
ystem
weight
,
feature
weight
,
powell
,
search
,
ih
mm-based
approach
,
system
weight
,
inchmm
,
joint
decoding
,
approach
,
feature
weight,max-bleu
training
method
,
performance
,
individual
system
,
test
set
system
id
,
test
system
,
system
,
system
,
system
,
system
,
comparison
,
baseline
,
ble
score
,
baseline
,
baseline
,
individual
system
,
incremental
hm
,
possible
reason
,
discrepancy
,
hypothesis
,
combination
,
experiment
,
performance
difference
,
method
outperforms
,
inchmm
baseline
,
comparison
,
joint
decoding
approach
,
baseline
,
dev
test
ih
mm
,
inchmm
,
joint
decoding
,
joint
decoding
,
inchmm
,
statistical
significance
level
,
paired
bootstrap
re
,
method
,
comparison
,
effect
,
alignment
pruning
,
allowable
link,bi-directional
viterbi
alignment
,
result
,
standard
setting,bi-directional
viterbi
alignment
,
slight
performance
degradation
,
ihm
baseline
,
fair
margin
,
joint
decoding
approach
,
ambiguous
1-to-many
alignment
,
proper
place
,
empty
word
,
comparison
,
different
setting
,
test
standard
setting
,
comparison
,
constraint
,
effect
,
flexible
word
ordering
,
experiment
,
different
constraint
,
ordering
,
decoding
process
,
first
case
,
word
order
,
backbone
,
input
hypothesis
,
mbr
-
ble
,
second
case
,
word
order,comparison,standard,backbone-free
word
ordering
,
constrained
setting
,
significant
performance
degradation
,
joint
decoding
approach
,
joint
optimization
,
alignment
,
word
selection
,
c
adjacency
constraint
,
search
,
benefit
,
flexible
word
ordering
,
effect
,
constraint
,
standard
setting
,
monotone
,
backbone
,
monotone
,
7
d
iscussion
,
joint
optimization
approach,word-level
combination
,
translation
hypothesis
,
multiple
machine
translation
system
,
conventional
confusion-network-based
method
,
alignment
,
different
hypothesis
,
flexible
word
ordering
,
decision
,
word
alignment
,
hypothesis
,
word
ordering
,
lexical
choice
,
final
output
,
feature
,
decoding
process
,
new
set,feature,alignment,behavior,method,state-of-the-art
baseline
,
nis
t
mt
,
c2e
task
,
joint
decoding
approach
,
baseline
,
ecause
,
complexity
,
search
,
challenge
,
approach
,
large
number
,
input
hypothesis,n-best
hypothesis,system,one-to-one
word
alignment,same-system
hypothesis,pre-computation
,
observation
,
disagreement
,
hypothesis
,
different
system
,
hypothesis
,
system
,
alignment
search
space,1-best
case
,
setting
,
performance
,
approach
,
opportunity
,
estimate
,
future
score
,
additional
feature
,
beside
potential
performance
improvement
,
effective
pruning
,
overall
decoding
process
,
reference
s
rinivas
bangalore
,
german
bordel
,
giuseppe
riccardi
,
consensus
translation
,
multiple
machine
translation
system
,
proceeding
,
iee
e
asru
,
jianfeng
gao
,
patrick
nguyen
,
robert
moore
,
indirect
hmm
,
hypothesis
alignment
,
output
,
machine
translation
system
,
proceeding
,
emn
lp
,
hyamsundar
jayaraman
,
alon
lavie
,
explicit
word
matching
,
proceeding
,
amianos
karakos
,
jason
eisner
,
sanjeev
khudanpur
,
markus
dreyer
,
machine
translation
system
combination
,
hilipp
koehn
,
statistical
significance
test
,
machine
translation
evaluation
,
proceeding
,
emn
lp
,
hilipp
koehn
,
pharaoh
,
a
b
eam
search
decoder
,
phrase
,
statistical
machine
translation
model
,
proceeding
,
incremental
hmm
alignment
,
mt
system
combination
,
proceeding
,
ercy
liang
,
ben
taskar
,
dan
klein
,
nicola
ueffing
,
hermann
ney
,
consensus
translation
,
multiple
machine
translation
system
,
enhanced
hypothesis
alignment
,
proceeding
,
ea
cl
,
vgeny
matusov
,
gregor
leusch
,
rafael
,
daniel
,
chelotte
,
marcello
federico
,
muntsin
kolss,young-suk
lee
,
matthias
paulik
,
salim
roukos
,
holger
schwenk
,
hermann
ney
,
system
combination
,
machine
translation
,
audio
speech
,
language
processing
,
chris
quirk
,
random
restarts
,
minimum
error
rate
training
,
statistical
machine
translation
,
proceeding
,
co
ling
r
obert
,
ibm
word
alignment
model
,
proceeding
,
n
ist
,
nis
t
op
,
machine
translation
evaluation
,
gov
speech
test
,
doc
f
ranz
,
minimum
error
rate
training
,
statistical
machine
translation
,
proceeding
,
k
ishore
papineni
,
salim
roukos
,
todd
ward
,
weijing
zhu
,
a
m
ethod
,
automatic
evaluation
,
machine
translation
,
proceeding
,
bing
xiang
,
necip
fazil
ayan
,
output
,
multiple
machine
translation
system
,
proceeding
,
spyros
matsoukas
,
richard
schwartz,word-level
system
combination
,
machine
translation
,
proceeding
,
bing
zhang
,
spyros
matsoukas
,
richard
schwartz
,
incremental
hypothesis
alignment
,
building
confusion
network
,
application
,
machine
translation
system
combination
,
proceeding
,
ac
l
wo
rkshop
,
ong
zhao,n-gram
,
feature
,
machine
translation
system
combination
,
proceeding
,
naa
cl-hlt
,
proceeding
,
naa
cl
,
short
paper
,
boulder
,
colorado
,
association
,
computational
linguistics
using
n-gram
,
feature
,
machine
translation
s
ystem
combination
y
,
zhao1
xiaodong
,
georgia
institute
,
technology
microsoft
research
atlanta
,
xiaohe
microsoft
,
com
a
bstract
conventional
confusion
network
,
system
combination
,
feature
,
measure
,
agreement
,
different
translation
hypothesis
,
paper
present
,
new
feature
,
agreement
,
different
hypothesis
,
performance
,
system
combination
,
first
one
,
sentence
specific
online
n-gram
language
model
,
second
one,n-gram
voting
,
experiment
,
large
scale
chinese-to-english
mt
task
show
,
feature
,
significant
improvement
,
translation
performance
,
combination
,
translation
result
,
1
i
ntroduction1
,
past
year
,
confusion
network
,
system
combination
approach
,
substantial
improvement
,
bangalore
,
multiple
system
,
confusion
network
,
hypothesis
,
network
,
sequence
,
correspondence
set
,
alternative
word
,
consensus
hypothesis
,
confusion
network
,
decoding
,
maximum
overall
confidence
score
,
confusion
network
,
yong
zhao
,
microsoft
research
,
confidence
score
,
hypothesis
,
various
way
,
fiscus
,
voting
,
frequency
,
word
occurrence
,
word
posterior
probability
,
voting
,
different
hypothesis
,
overall
confidence
score
,
log
linear
model
,
extra
feature
,
word
count
,
f
eatures
,
word
agreement
measure
,
past
work,matusov,utilization,n-gram
agreement
information
,
hypothesis
,
confusion
network
,
undesirable
spur
word
,
coherent
phrase
,
consensus
translation
,
gram
agreement
,
output
,
single
system,literature,n-gram
posterior
probability
,
source
sentence,n-best
list
,
single
mt
system,n-best
list
,
matusov
,
system
combination
,
translation
hypothesis
,
whole
test
corpus
,
single
mt
system
,
system
combination
,
new
feature,n-gram
agreement
measure
,
performance
,
system
combination
,
sentence
specific
lm
built
,
translation
hypothesis
,
multiple
system,context,large-scale
chinese-english
translation
task
,
2
s
ystem
combination
,
mt
o
ne
,
successful
approach
,
system
combination
,
confusion
network
,
multiple
mt
system
,
hypothesis
,
backbone
,
hypothesis
alignment,re-ranking
method
,
confusion
network
,
hypothesis
,
backbone
,
correspondence
set
,
competition
link
,
confusion
network
,
network
,
correspondence
,
final
consensus
output
relies
,
decoding
procedure
,
maximum
confidence
score
,
confusion
network,hypothesis,log-linear
sum
,
several
feature
function
,
source
language
sentence
,
total
confidence
,
confusion
network
,
feature
function
,
number
,
real
word
,
model
parameter
,
leu
score,held-out
development
set
,
3
n
gram
online
language
model
g
,
source
sentence
,
fractional
count
,
hypothesis
set
,
kronecker
function
,
posterior
probability
,
weighted
sum
,
system
specific
posterior
probability
,
system
,
weight
,
posterior
probability
,
indicator
function
,
system
specific
posterior
,
translation
hypothesis,output,n-best
list
,
straightforward
approach,n-gram
fractional
count
,
online
lm
score
,
confusion
network
,
additional
feature,log-linear
model
,
online
n-gram
lm
score
,
lm
score
,
hypothesis
,
new
n-grams
,
original
translation
hypothesis
,
approach
,
online
lm
,
linear
interpolation
,
different
order
,
implementation
,
interpolation
weight
,
combination
parameter,max-bleu
training
scheme,powell,search,gram-voting-based
confidence
m
,
feature
,
voting
,
single
word
,
new
feature
,
gram
voting
,
voting
score
,
hypothesis
,
posterior
probability
,
hypothesis
,
fractional
count,hypothesis,confidence,n-gram-voting-based
confidence
score
,
hypothesis
,
product
,
confidence
score,n-grams
,
confidence
,
confidence
score
,
original
hypothesis,n-gram
,
feature
,
final
log-linear
model
,
5
e
valuation,n-gram
,
feature
,
past
ni
st
open
mt
evaluation
,
experimental
result
,
case
sensitive
ble
score
,
papineni
,
system
combination
parameter
training
,
newswire
,
newsgroup
part
,
nis
t
mt
,
sentence
,
test
set
,
current
test
set
,
nis
t
mt
,
sentence
,
newswire
,
web
blog
data
,
test
set
,
reference
translation
,
sentence
,
o
utputs
,
single
mt
system
,
consensus
translation
,
system
,
various
translation
paradigm,phrasal,10-best
hypothesis
,
translation
,
ble
score
range
,
individual
system
,
test
set,experiment,state-of-the-art
system
combination
method,baseline,true-casing
model
,
toutanova
,
show
result
,
online
lm
feature
,
different
lm
order,result,2-gram
online
lm
,
half
ble
point
gain
,
baseline
,
lm
order,fluctuates,performance,gram-voting-based
confidence
feature,result,4-gram
confidence
feature
,
ble
score
keep,n-gram
confidence
feature,n-gram
voting
,
confidence
feature,feature,log-linear
model,result,observation,n-gram
voting
,
confidence
feature
,
high
order
n-grams
,
different
gram
order,3-gram
online
lm
,
confidence
score
,
ble
score
,
test
set
,
bl
eu
point
gain
,
baseline
,
mt08
test
set,result,1-gram
online
lm,2-gram
online
lm,3-gram
online
lm,4-gram
online
lm,result,n-gram
voting
,
confidence
feature,result,n-gram
online
lm,n-gram
voting
,
confidence
feature,3-gram
lm,4-gram
lm,3-gram
lm
,
6
c
onclusion,utilization,n-gram
agreement
information
,
translation
output
,
multiple
mt
system
,
performance
,
system
combination
,
extension
,
ni
p,workshop,speech,n-gram
,
feature
,
online
lm,n-gram
fractional
count
,
confidence
feature
,
gram
voting
score
,
experiment
,
ni
st
mt08
chinese-english
task
,
method
,
nice
improvement
,
translation
result
,
feature
,
translation
result
,
a
b
leu
score
,
improvement
,
r
eferences,fiscus,post-processing
system
,
reduced
word
error
rate
,
riccardi
,
consensus
translation
,
multiple
machine
translation
system
,
consensus
translation
,
multiple
machine
translation
system
,
enhanced
hypothesis
alignment,schwartz,word-level
system
combination
,
machine
translation,indirect-hmm-based
hypothesis
alignment
,
output
,
machine
translation
system
,
stolcke
,
consensus
,
speech
recognition
,
word
error
minimization
,
application
,
confusion
network
,
computer
speech
,
language
,
n-g
ram
posterior
probability
,
statistical
machine
translation
,
woodland
,
consensus
network
,
statistical
machine
translation
system
combination
,
segmental
minimum
bayes-risk
decoding
,
speech
,
audio
processing
,
method
,
automatic
evaluation
,
machine
translation
,
morphology
generation
model
,
machine
translation
,
system
combination
,
wor
kshop
,
speech,language,learning-based
method
,
system
,
system
combination
,
machine
translation
,
spoken
,
speech
,
language
processing
,
proceeding
,47
th
annual
meeting
,
ijc
nlp
,
afn
lp,suntec,singapore,2-7
august
,
afn
lp
incremental
hmm
alignment
,
mt
system
combination
chi-ho
li
microsoft
research
asia
,
zhichun
road
,
beijing
,
microsoft
,
microsoft
research
one
microsoft
way
,
redmond
,
xiaohe
microsoft
,
com
yupeng
liu
harbin
institute
,
technology
,
xidazhi
street
,
harbin
,
china
ypliu
mtlab
,
xi
nanjing
university
8
h
ankou
road
,
nanjing
,
china
xin
nlp
,
cn
abstract
inspired
,
incremental
ter
align
ment
,
alignment
,
hypothesis
alignment
method
,
conventional
mt
system
combination
,
incremental
manner
,
crucial
prob
lem
,
incremental
alignment
,
hypothesis
,
different
way
,
treat
cn
,
hmm
state
,
state
transition
,
distortion
,
covered
gram
,
treat
cn
,
hmm
state
,
state
tran
sition
,
distortion
,
compo
nent
translation
,
consensus
,
algorithm
,
hypothesis
,
multiple
ihm
m
,
component
,
lation
,
ap
proaches
,
incremental
alignment
,
incremental
ter
alignment
,
conven
tional
ihm
alignment,setting,chinese-to-english
track
,
nis
t
op
,
mt
evaluation
,
1
i
ntroduction
word-level
combination
,
confusion
network
,
matusov
,
approach
,
system
,
output
,
word
align
ment
,
backbone
,
skeleton
,
translation
,
hypothesis
translation
,
key
problem
,
approach
,
snover
,
alignment
,
baseline
,
couple
,
approach
,
alignment
,
karakos
,
re
sults
,
alignment
method,hypothesis,backbone,alignment,translation,pair-wise
alignment
strategy,low-quality
cn
,
align
ment
,
hypothesis
,
matter
,
alignment
,
hypothesis
,
ex
ample
,
backbone
,
computer
,
hypothesis
,
lap
top
computer
,
alignment
method
,
alignment
,
figure
,
alignment
,
hypoth
esis,backbone,translation,alignment,hypothesis,low-quality
cn
,
poor
trans
lations
,
poor
translation
,
language
model
,
distinct
arc
,
problem
,
incremental
alignment
,
hypoth
esis
,
backbone
,
good
cn
,
incomplete
sentence
,
low
language
model
score
,
figure
,
example
bad
confusion
network,pair-wise
alignment
strategy
,
result
,
hypothesis
,
hypothesis
,
hypothesis
,
final
cn
,
obser
vation
,
different
order
,
hypothesis
,
translation
quality
,
question
,
incremental
ter
alignment
,
perfor
mance,pair-wise
ter
alignment
,
incremental
strategy
,
pair
wise
strategy
,
ter
method
,
tion
quality
,
different
order
,
hypothesis
,
ques
tion
,
ihm
alignment
method
,
different
way
,
incremental
ihm
alignment
,
ex
periments
,
several
order
,
hypothe
s
,
response
,
question
,
notation
,
section
,
section
,
variation
,
basic
incremental
ihm
model
,
incihmm1
,
section
,
consensus
,
alterna
tive
way
,
optimal
alignment
,
alignment
normalization
,
hypothesis
,
section
,
experiment
result
,
analysis
,
section
,
figure
,
example
good
confusion
network
,
incremental
alignment
strategy
2
p
reliminaries
,
notation
,
confusion
network
,
elaboration
,
notation
,
finite
state
graph
,
many
span
,
word
position
,
con
tains
several
arc
,
al
ternative
word
,
position
,
weight
,
way
system
combination
task
,
follow
rosti,i-th
weight
,
hypothe
si,i-th
system
,
word
repre
,
conception
,
compact
form
,
net
work
,
figure
,
example
,
integration
,
skeleton
,
hypothesis
,
component
translation
,
example
,
figure
,
figure
,
tabular
form
,
component
translation
,
column
,
compact
form
,
alter
native
word
,
word
position
,
alternative
word
,
certain
word
po
sition
,
certain
translation
,
weight
,
translation
,
mt
system
,
mt
system
,
figure
,
example
,
confusion
network
,
tab
ular
form
rank-based
weight
,
different
system
,
adjustment
,
weight
,
weight
,
corresponding
row
,
elaboration
,
incremental
ihm
model
,
tabular
form
,
hypothesis
,
backbone
,
target
language,column,k-th
row,k-th
row,i-th
column
,
weight
,
weight
,
normalized
weight,bag-of-words
,
k-th
original
trans
lation
,
different
word
order
,
word
sequence
,
inserted
empty
symbol
,
sequence
,
serted
symbol
,
compact
form
,
ve
application
,
incremental
strategy
,
hmm
state
,
conditional
prob
ability
,
hypothesis
,
backbone
cn
,
similarity
model
,
dis
tortion
model
,
accordance
,
equation
,
similarity
,
hypothesis
word
,
span
ei
,
weighted
sum
,
similar
ities
,
equation
,
similarity
,
conventional
ihm
alignment
,
distortion
model
,
incremental
ihm
model
,
group
distortion
parameter
,
bucket
,
problem
,
incremental
ihm
,
bucket
,
conventional
ihm
,
transi
tion
,
formula
,
transition
,
incremental
ihm
,
backbone
,
incremental
ihm
,
special
property
,
insertion
operator
,
example
,
back
bone
cn
,
option
ei,i-th
span
,
option
,
th
span
,
first
round
alignment
,
hypothesis
word
,
consequent
cn
,
extra
span
,
option
,
th
span
,
distortion
bucket
,
equation
,
first
round
alignment
,
transition
,
second
round
alignment
,
transition
,
bucket
,
equation
,
backbone
,
monotonic
alignment
assumption
,
equation
,
possible
way
,
prob
lem
,
first
solution
,
transition
probability
,
weighted
average
,
different
dis
tortion
probability
,
second
solution
,
distortion
,
distortion
,
hypothesis
,
simple
weighting
,
covered
n-grams
distortion
model
,
monotonic
alignment
assumption,n-grams
,
state
transition
,
following
example
,
conventional
ihm
,
distortion
probabil
ity,transition,transition,i-th
word
,
backbone
,
incremental
ihm,i-th
span
,
arc
ea
,
probabili
tie
,
tran
sition
,
probability
p1
,
nothing
,
transition
probabil
ity
,
th
span
cover
,
probability
p3
,
transition
,
possible
case
,
probability
p2
,
unigram
ea
,
probability
p1
,
unigram
eb
,
probability
p2
,
bigram
eaeb
,
probability
p1
,
transition
probability
,
estimation
,
transition
probability
,
transition
,
possible
n-grams
,
tran
sition
,
corresponding
probabil
ities
,
possible
cell
sequence
,
transition
,
sequence
,
probability
,
th
span
,
empty
word
,
cell
sequence
,
length
,
particular
cell
sequence
,
cell
sequence
,
respect
,
length
,
parameter
,
ele
ment
,
particular
value
,
proba
bility
,
probability
,
transition
,
transition
probability
,
incremental
ihm
,
weighted
sum
,
probability
,
gram
jumping
,
conventional
ihm
distortion
probability
,
practice
,
possible
n-grams
,
transi
tion,number,n-grams
grows
,
length
limit
,
state
transition
,
transition
probability
,
equation
,
probability
,
state
transition
,
probability
,
transition
,
state
transi
tions
,
dynamic
pro
gramming
,
fixed
value
p0,transition,held-out
data
,
weighting
,
distortion
,
component
translation
,
problem
,
distortion
,
cn
span
,
gradual
extension
,
empty
word
,
problem
,
inserted
empty
word
,
rationale
,
distortion
model
,
distortion
model
,
ac
tual
word
sequence
,
implement
a
c
,
real
position,i-th
word
,
th
component
translation
,
real
position
,
refers
,
position
,
compact
form
,
inserted
empty
word
,
empty
word,position,non-empty
word
,
convenience
,
null
state
,
real
length
,
parameter
,
distor
tion
probability
,
incremental
alignment
process,number,non-empty
word
,
transition
,
row
index
,
represent
real
word
,
refers
,
conventional
ihm
distortion
probability
,
equa
tion
,
real
word
,
empty
word
,
conventional
hmm
,
word
align
ment
,
probability
,
transition
,
null
state
,
real
word
state
,
transition
,
real
word
state
,
null
state
,
real
word
state
,
empty
word
,
real
word
,
second
option
,
constraint
,
null
state
,
real
word
state
,
transition
,
first
transition
,
second
transition
,
null
state
,
empty
word
,
similar
logic
,
4
i
ncremental
alignment
,
consensus
decoding
,
multiple
ihm
m
,
previous
section
,
incremental
ihm
model
,
state
space
,
alternative
approach
,
component
translation
,
individual
,
align
ment
,
hypothesis
,
entire
network
,
individual
translation
,
dividual
translation
,
optimal
alignment
,
consensus
,
multiple
ihm
m
,
alignment
,
multiple
sequential
pattern
,
different
context
,
ex
ample
,
sreenivas
,
multi
pattern
dynamic
time
,
multiple
speech
utterance
,
method
,
align
ment
,
section
,
consensus
,
algorithm
,
alignment
,
hypothesis
,
translation
,
prerequisite
,
algorithm
,
function
,
span
index
,
corresponding
hmm
state
index
,
component
translation,function,section,accordingly,hypothesis,alignment,hypothesis,k-th
row
,
real
length
function,number,non-empty
word,k-th
row
,
hypothesis
,
alignment
,
weighted
sum,pair-wise
ihm
m,weight,k-th
row
,
op
timal
alignment
,
cn
span
,
hmm
state
,
pseudo
emission
probability
,
pseudo
transition
probability
,
ej
eaj
,
true
probability,sum-to-one
prop
erty
,
5
a
lignment
normalization
,
alignment
,
backbone
cn
,
hypoth
esis
,
principle
,
heuristic
,
con
struction
,
conventional
system
combina
tion
approach
,
incremen
tal
alignment
approach
,
heuris
tic
,
alignment
normalization
,
exception
,
mapping
,
map
ping
,
conversion
,
inser
tion
,
net
work
,
unreasonable
length
,
viterbi
align
ment
,
1-n
mapping
,
alignment
,
1-n
map
ping
,
n-b
est
alignment
,
nilsson
,
goldberger
,
example
,
hypothesis
word
,
alignment
,
alignment
,
re
duction
,
viterbi
probability
,
alignment
,
6
o
rder
,
hypothesis
,
default
order
,
hypothesis
,
hypothesis
,
ter
score
,
backbone
,
attempt
several
order
,
arbitrary
order
,
mt
system
,
translation
,
original
order
,
system
,
translation
,
next
system,rationale,system-based
order
,
transla
tions
,
system
,
translation
,
system
,
similar
translation
,
sec
ond,n-best
rank-based
order,translation,system,top-1
translation,system,system,translation,system,presumption,top-ranked
hypothesis
,
reli
able
hypothesis
,
hypothesis
,
randomness
,
system
,
randomness
,
a
b
ayes
risk
order
,
mt
system
,
bayes
risk,top-1
translation
,
hypothesis
,
bad
order
,
hypothesis
,
reversal
,
random
order
,
valuation
,
approach
,
incremental
ihm,respect,chinese-to-english
track
,
nis
t
op
,
order
example,hypothesis,example,refers,n-th
translation,m-th
system
,
sec
tions
,
incremental
ihm
,
distortion
model
,
incihmm1
,
incihmm2
,
consensus
decoding
,
multiple
ihm
m,cd-ihmm
,
baseline
,
method
,
incremental
ter
method
,
ihm
approach
,
development
,
newswire
,
newsgroup
section
,
test
set
,
entire
mt08
,
translation
,
source
sentence
,
test
set
,
mt
sys
tems,case-insensitive
ble
u-4
,
per
centage
,
evaluation
,
various
parameter
,
ihm
model
,
optimal
value
,
lexical
translation
probability
,
semantic
similarity
model
,
constrained
track
training
data
,
standard
hmm
align
ment
model
,
loss
function
,
approach
,
ihm
m-based
approach
,
incremental
system
,
default
order
,
hypothe
s
,
ter
score
,
backbone
,
hypothesis
,
incremental
ihm,n-best
rank
order
,
bayes
risk
system
order
,
high
est
ble
score
,
final
system
combination
output
,
feature
,
pa
rameters
,
feature
,
word
con
fidences
,
language
model
score
,
word
penalty
,
empty
word
penalty
,
decoding
parameter
,
maximum
ble
training
,
dev
set
,
training
,
decoding
process
,
dev
test
,
single
system,pair-wise
ter
,
incremental
ter,pair-wise
ihm
,
incremental
ihm
,
comparison
,
incihmm2
,
baseline
,
baseline
table
,
ble
score
,
baseline
combination
method
,
incihmm2
,
comparison
,
pairwise
,
incremental
ter
method
,
supe
riority
,
incremental
strategy
,
benefit
,
incremental
ter,pair-wise
ter
,
difference
,
test
set
,
experimental
condition,comparison,pair-wise
alignment
method
,
difference
,
possible
cause
,
discrepancy
,
different
dev
set
,
training
,
semantic
similarity
parameter
,
de
spite,pair-wise
ihm
method
,
strong
baseline
,
perfor
mance
,
incihmm2
,
incremental
ihm
approach
,
ble
point,pair-wise
ihm
baseline
,
ter
baseline
,
comparison
,
incremental
ihm
m
mo
dels
table
,
ble
score
,
incremental
ihm
approach
,
distortion
model
,
incihmm
approach
lead,performance,cd-ihmm
,
incihmm
,
distortion
,
method
dev
test
incihmm1
,
incihmm2
,
comparison
,
incremen
tal
ihm
approach
el
,
distortion
,
dis
tortion
,
word
sequence
,
distortion
model
,
word
sequence
,
sequence
,
component
translation
,
word
sequence
,
subsequence
,
various
component
trans
lations
,
section
,
number
,
sequence
grows
,
length
,
se
quences
,
decoding
process
,
variation
,
performance
,
similar
ble
,
implies
,
incorporation
,
word
sequence
,
distortion
model
,
extra
improvement
,
consensus
decoding
,
variation
,
incihmm
,
incihmm2
,
incihmm2
,
parameter
,
weighted
sum
,
various
proba
bilities
,
component
translation,contrast,equation,section,cd-ihmm
,
weighted
sum
,
logarithm
,
probability
,
component
translation,incihmm2,probability,cd-ihmm
,
product
,
probability
,
experiment
result
,
interaction
,
weight
,
probability
,
product
case
,
summation
case
,
impact
,
hypothesis
table
,
ble
score
,
incihmm1
,
different
order
,
hypothesis
,
column
,
reversal
,
im
pact
,
bad
order
,
ble
point
,
ran
dom
order
,
baseline
,
hypothesis
,
br
system
,
br
rank
,
random
,
comparison
,
various
order
,
bayes
risk
order
,
system
,
number
,
ble
score
,
test
set
,
good
performance,n-best
rank
order
,
bayes
risk
order
,
system
,
performance
,
performance
,
incremental
alignment
,
hypothesis
,
op
timal
order,hypothesis,system,n-best
list
,
8
c
onclusions
,
application
,
cremental
strategy,state-of
the-art
alignment
method
,
mt
output
com
bination
,
prob
lem
,
state
transition
,
differ
ent
solution
,
principle
,
sition
,
cn
span
,
transition
,
word
sequence
,
component
translation
,
consensus
,
approach
,
performance
,
distortion
model
,
incremental
ihm
,
incihmm1
,
incihmm2
,
superb
performance,comparison,pair-wise
ter,pair-wise
ihm
,
incremental
ter
,
hypothesis
,
bad
order
,
transla
tion
quality
,
ble
point
,
jianfeng
gao
,
patrick
nguyen
,
robert
moore,indirect-hmm
,
hypothesis
alignment
,
machine
translation
system
,
proceed
ings
,
emn
lp
,
damianos
karakos
,
jason
eisner
,
sanjeev
khudanpur
,
markus
dreyer
,
machine
translation
,
system
combination
,
alignment
,
proceeding
,
evgeny
matusov
,
nicola
ueffing
,
hermann
ney
,
consensus
translation
,
mul
tiple
machine
translation
system
,
enhanced
hypothesis
alignment
,
proceeding
,
nishanth
ulhas
nair
,
sreenivas
,
joint
decoding
,
multiple
speech
pattern
,
robust
speech
recognition
,
proceeding
,
dennis
nilsson
,
jacob
goldberger
,
sequen
,
n-b
est
list
,
hidden
markov
model
,
proceeding
,
ijc
ai
,
nis
t
op
,
machine
translation
evaluation
,
gov
speech
test
,
doc
franz
,
hermann
ney
,
ystematic
comparison
,
various
statistical
alignment
mod
el
,
computational
linguistics
,
pp
19-51
kishore
papineni
,
salim
roukos
,
todd
ward
,
wei
jing
zhu
,
a
m
ethod
,
automatic
evaluation
,
machine
translation
,
proceeding
,
spyros
matsoukas
,
richard
schwartz,word-level
system
com
bination
,
machine
translation
,
proceeding
,
bing
zhang
,
spyros
matsoukas
,
richard
schwartz
,
incremental
hypoth
esis
alignment
,
building
confusion
network
,
application
,
machine
translation
system
combination
,
proceeding
,
acl
work
shop
,
khe
chai
sim
,
william
,
hichem
sahbi
,
woodland
,
con
sensus
network
decoding
,
statistical
machine
translation
system
combination
,
proceeding
,
bonnie
dorr
,
rich
schwartz
,
linnea
micciulla
,
john
makhoul
,
translation
edit
rate
,
targeted
human
anno
tation
,
proceeding
,
proceeding
,
second
workshop
,
statistical
machine
translation
,
prague
,
association
,
computational
linguistics
training
non-parametric
feature
,
statistical
machine
translation
patrick
nguyen
,
milind
mahajan
,
xiaodong
,
microsoft
corporation
1
m
icrosoft
way
,
panguyen
,
milindm
,
xiaohe
microsoft
,
com
abstract
modern
statistical
machine
translation
sys
tems
,
component
,
feature
extraction
,
informa
tion,translation,log-linear
framework
,
feature
,
linearity
con
straints
,
combination
,
constraint
,
monotonicity
,
indepen
dence
,
feature
function
,
fea
tures,high-dimensional
space
,
empir
ical
bayes
reward
training
,
model
param
eters
,
parameter
,
feature
genus
tion
,
effect
,
human
expert
feature
design
,
preliminary
result
,
standard
task
,
encouraging
improvement
,
1
i
ntroduction
,
recent
year
,
statistical
machine
translation
,
quantum
leap
,
quality
thanks
,
tomatic
evaluation
,
papineni
,
optimization
,
conditional
log-linear
feature
combination
framework
,
berger
,
della
pietra
,
della
pietra
,
practice
,
re
cent
effort
,
feature
design
,
intelligent
feature,simplicity,log-linear
model
,
constraint
,
new
information
,
sys
tem
,
result
,
new
information
need
,
feature
function
,
human
knowledge
,
understanding
,
experimenta
tion
,
automatic
training,non-parametric
agnostic
feature
,
burden
,
optimal
parameterization
,
objective
func
tion
training
framework
,
new
non-parametric
feature
,
2
m
odel
,
section
,
general
log-linear
model
,
statistical
machine
translation
,
training
objective
function
,
algorithm
,
a
f
rench
,
source
,
sentence
,
surface
,
kt
outcome
,
english
,
target
,
hy
pothesis,surface,log-linear
model
,
prevalent
translation
model
,
modern
system
,
conditional
log-linear
model
,
hypothesis
,
feature
,
function
,
conditional
probability
,
hypothesis
,
partition
function
zft
,
vector
,
parameter
,
relative
importance
,
feature
function
compo
,
training
criterion
,
section
,
translation
result
,
figure
,
evaluation
,
translation
quality
,
ble
score
,
papineni
,
translation
,
human
reference,n-gram
overlap
count
,
test
set
sentence
,
total
count,n-grams
,
hypothesis,n-grams
,
hypothesis
,
quantity
,
notation
,
precision
ratio
pn
,
brevity
penalty
bp
,
account
,
short
sentence
,
average
length
,
sen
tence1
,
average
length
,
hypothesis
,
easy
way,n-best
list
,
overall
ble
score
,
oracle
ble
hypothesis
,
sentence
,
hypothesis
,
ble
score
,
sentence
,
practical
purpose
,
true
oracle
ble
,
likelihood
criterion
,
likelihood
,
oracle
hypothesis
,
single
reference
translation
,
infi
nite
amount
,
method
,
bayes
error
,
minimum
achievable
error
,
classification
task
,
others
,
maximum
likelihood
problem
,
maximum
,
posteriori
,
prior
distribution
,
practice
,
rosenfeld
,
variance
,
inverse
,
a
l
agrange
multiplier
,
optimization
,
euclidean
norm
,
likeli
hood
,
penalty
term
,
entropy
penalty
,
gaussian
prior
,
entropy
,
indepen
dent
,
feature
,
training
,
empirical
top-1
error
,
training
data,maximum-likelihood
,
partial
credit
,
sentence
,
ble
score
,
likely
hypothesis
,
reason
,
criterion
,
function
,
known
exact
efficient
op
timization,linear-time
algorithm
,
exact
line
search
,
objec
tive
,
method
,
conjunction
,
coordinate
projection
,
great
success
,
algorithm
,
partial
credit
,
confidence
pk
,
rect
hypothesis
,
likely
hypothe
si
,
eisner
,
pk
logb
,
ble
score
,
logrithm
,
previous
model
,
probability
mass
,
instance
,
large
norm
,
known
method
,
ef
ficient
approximation,criterion,high-dimensional
feature
space
,
main
motivation
,
objective
function
,
baseline
feature
,
data
set
,
criterion
,
result
,
minimum
error
rate
training
,
probability
measure
,
empirical
bayes
reward
,
divergence
,
training
algorithm
,
gradient
ascent
method
,
approximation
,
empirical
bayes
re
ward
function
,
empirical
bayes
reward
,
sentence
,
sentence
,
sentence
,
bur
densome
,
sufficient
statistic
,
function
,
first
order
approximation
,
respect
,
statistic
,
practice
,
effect
,
commut
,
expectation
,
reason
,
criterion
,
ap
proximation,linearization,first-order
approximation
,
interpretation
,
derivation
,
expectation
,
cur
rent
estimate,log-linear
model
,
hard
min
function
,
sigmoid
,
yielding
,
sigmoid
function
,
sufficient
statistic
,
gradient
,
objective
func
tion
,
chain
rule,respect,probability,log-precision
,
expected
count,n-gram
precision,n-gram
order
,
sufficient
statis
tic,precision,gradient,probability,precision,length,derivative,1-gram
component
,
derivative
,
experiment
,
ried
miller
,
gradient
ascent
al
gorithm
,
gradient
algorithm
,
gradient
component
,
iteration
,
objective
func
tion
,
little
memory
,
meta
parameter
,
iter
ations
,
stochastic
gradient
,
kushner
,
l-b
fgs
,
nocedal
,
wright
,
criterion
,
min
imum
error
rate
training,feature,log-linear
model
,
good
performance
,
practice
,
consideration
,
feature
engineer
ing
,
active
area
,
research
,
telligence
,
design
,
new
information
,
overall
score
,
extra
effort
,
feature
,
model
learn
,
experi
mentation
,
config
uration,non-parametric
feature
,
parameterization
problem
,
new
information
,
research
,
parameterization
,
system
,
continuous
invertible
transformation
,
original
input
,
feature
,
baseline
system
,
syntax
,
machine
translation
system
,
menezes
,
cherry
,
feature
,
feature
,
following
,
candidate
,
arget
language
model
,
giga
word
corpus
,
parallel
training
data,probability,position,target,re-ranking
framework,algorithm,re-ranking
framework
,
feature
,
feature
,
hypothesis
,
english
,
surface
,
contribution
,
word
count
,
instance
,
property
,
efficient
first-pass
decod
,
hypothesis
sentence,kt-best
list
,
entire
probability
space
,
computation
,
partition
func
tion,kt-best
hypothesis,subject,n-best
generation
scheme
inter
,
optimization
,
parameterization
,
new
feature,log-linear
model
,
embodiment
,
feature
,
following
property
,
onotonicity
,
ndependence
,
conjunction
,
feature
,
performance
,
region
,
region
,
instance
,
word
count
,
logarithm
,
goodness
,
hypothesis
,
feature
,
mono
tonic
,
instance
,
difference
,
tween
word
count
,
source
,
en
glish
,
target
,
absolute
value,inter-dependence
,
feature
,
example
,
multiple
lan
guage
model
score,feature,dimension,embodiment,non-parametric
processing
,
method
,
quan
tized
parzen
estimate
,
feature
density
function
,
parzen
window
,
early
empirical
kernel
method
,
probability
mass
,
density
function
,
parzen
win
,
converge
,
true
density
estimate
,
weak
assumption
,
feature
one
popular
way
,
continuous
feature,log-linear
model
,
single
continuous
feature
,
feature
,
bin
feature
,
indicator
function
,
original
continuous
feature
,
certain
range
,
equal
share
,
probability
mass
,
equiva
lent
,
maximum
likelihood
estimate
,
den
sity
function
subject
,
fixed
number
,
rectangular
density
kernel
,
mapping
,
respect
,
original
feature
,
sigmoids
,
boundary
,
bin
feature,requirement,linearity,monotonicity,feature,problem,inter-dependence
,
feature
,
dimensional
kernel
,
rectangular
window
,
direct
analogy
,
vector
quantization
,
specific
region
,
feature
space
,
aussians
,
mean
vector
,
new
feature
,
posterior
,
mixture
model
,
reasonable
choice
,
kernel
,
equivalent
result
,
amount
,
training
data
,
number
,
kernel
,
method
,
cluster
,
contrast
,
lossless
representation
,
canonical
way
,
clus
ter
,
standard
gaussian
mixture
training
,
single
gaussian
,
whole
data
set
,
gaussian
,
gaussians
,
mean
vector
,
gaus
sian,maximum-likelihood
,
expectation-maximization
framework
,
rabiner
,
number
,
gaussians
,
perceptron
kernel
,
quicker
way
,
kernel
,
equal
prior
,
global
covariance
matrix
,
sentence
,
training
set,top-1
candidate
,
differ
ent
,
approximate
maximum
oracle
ble
hypothesis
,
quick
way
,
oracle
ble
,
oracle
ble
,
next
section,estimate,kernel,re-estimation
formul
,
feature
,
empir
ical
maximum
bayes
reward
,
hyper
parameter
vector
,
feature
,
language
model
,
instance
,
weight
,
fea
ture
value
,
respect
,
ra
dient
ascent
,
respect
,
example
,
feature
,
posterior
,
gaussians
,
4
e
xperimental
result
,
experiment
,
standard
nis
t
mt
,
system
,
nis
t
sy
,
simple
baseline
,
exper
iments
,
system
,
menezes
,
cherry
,
system
,
sentence
,
source
language
sentence
,
evaluation
set,5-gram
target
lan
guage
model
,
gigaword
,
lingual
data
,
absolute
discounting
smoothing
,
single
decoding
,
system
,
hy
potheses,sentence,leave-one-out
training
,
enough
data,training,n-best
list,10-fold
leave-one-out
training
,
base
feature
extraction
model,held-out
set
,
process
,
system
,
decoding
,
process
,
convergence
,
iteration
,
decoding
,
hypothesis
,
decoding
,
hypothesis
,
combined
list
,
iteration
,
subsequent
experiment
,
feature
expansion
,
ble
u
tr
,
result
,
system
,
empirical
bayes
reward
criterion
,
gmm
feature
,
bin
feature
,
gmm
feature
,
modest
improvement
,
hyper
parameter
,
empirical
bayes
reward
,
first
question
,
cost
surface
,
standard
,
complex
cost
surface,non-linear
feature
,
special
care
,
op
timization,non-convexity
,
sensitivity
,
initialization
point
,
initial
ize
,
vertex
,
unit
hypercube
,
feature
,
experiment
,
histogram
,
ble
score
,
dev
data
,
conver
gence
,
figure
,
togram
,
example
dimension
,
figure
,
ble
score
,
lambda
,
ble
score
,
definitive
evidence
,
cost
surface
,
convex
,
practical
purpose
,
ble
score
,
ed
od
el
s
f
igure
,
histogram
,
ble
score
,
initialization
,
ed
od
el
s
f
igure
,
histogram
,
parameter
,
train
ing,initialization,feature,log-linear
model
,
bin
feature
model
,
equiva
lent
weight
,
figure
,
error
function
,
input
feature
,
cummulative
random
variable,weight,log-linear
model
,
weight
,
figure
,
monotonicity
constraint
,
val
ues
,
ble
score
,
ob
jective
,
training
,
training
objective
value
,
num
ber
,
similar
behavior
,
bin
id
va
lu
,
original
weight
,
weight
figure
,
bin
fea
tures
,
monotonicity
constraint
,
gmm
fea
tures,summary,baseline,log-linear
model
,
baseline
feature
,
baseline
feature
,
system
,
gmm
model
,
iterative
mixture
,
em
re
estimation
,
gaussians
,
gmm
ml-1k
,
gmm
ml-16k
re
,
perceptron
,
selec
tion
feature
,
training
,
algorithm
,
development
,
feature
,
sentence
,
hypothesis
,
experiment
,
prior
gaussian
prior
,
variance
,
velopment
set
,
gmm
-
pcp
,
regu
larization
,
positive
effect
,
development
ble
score
,
system
,
baseline
log-linear
model
,
additional
weight
,
iteration
,
convergence
,
ble
score
,
empirical
reward
,
development
ble
score
,
iteration
,
set
ting
,
training
data
,
ble
score
,
development
,
evaluation
,
cursory
experiment
,
mul
tiple
initialization
,
fi
nal
ble
score
,
gmm
feature
,
lin
ear
baseline
,
different
selection
method
,
number
,
kernel
,
perceptron
kernel
,
training
,
baseline
,
sured
significance
,
wilcoxon
,
rank
test
,
sentence
,
observation
,
difference
,
sig
nificant
,
improvement
,
local
optimum
,
original
feature,log-linear
mod
el
,
5
c
onclusion,non-parametric
feature
expansion
,
invariance
,
specific
embodiment
,
original
feature
,
feature
generation
model
,
feature
,
pansion
,
maximum
regular
ized
empirical
bayes
reward,end-to-end
framework
,
parameter
,
machine
translation
system
,
encouraging
result,hyper-parameter
re-estimation
,
presence
,
local
optimum
,
complex
original
feature
,
effectiveness
,
parameteri
zation
invariance
,
evaluation
,
compet
itive
baseline
,
reference
,
method
,
automatic
evaluation
,
della
pietra
,
aximum
entropy
approach
,
natural
language
processing
,
computational
linguistics
,
rosenfeld
,
survey
,
technique
,
ee
trans
,
speech
,
audio
processing
,
pattern
classification
,
scene
analysis
,
kushner
,
stochastic
approxi
mation
algorithm,application,springer-verlag
,
national
institute
,
standard
,
technology
,
numerical
optimiza
tion,springer-verlag
,
minimum
error
rate
training
,
morgas
bord
,
feature
,
discriminative
training
,
maximum
entropy
model
,
feature
,
cherry
,
de
pendency
tree
translation
,
fundamental
,
speech
recognition
,
adaptive
learning
algorithm
,
isc
vii,eisner,minimum-risk
annealing
,
proceeding
,
second
workshop
,
statistical
machine
translation
,
prague
,
association
,
computational
linguistics
using
word
dependent
transition
model
,
word
alignment
,
statistical
machine
translation
xiaodong
,
usa
xiaohe
microsoft
,
com
a
bstract
,
a
b
ayesian
learn
ing
,
method
,
word
dependent
transition
model
,
word
alignment
,
present
word
alignment
re
sults
,
canadian
hansard
corpus
,
conventional
hmm
,
ib
model
,
method
,
reduction
,
word
alignment,method,phrase-based
ma
chine
translation
system
,
absolute
improvement
,
ble
score
,
conventional
hmm
,
bm
model
,
word
alignment
,
1
i
ntroduction
word
alignment
,
important
step
,
modern
approach
,
statistical
machine
translation
,
classical
approach
,
word
alignment
,
ibm
model
,
alignment
model
,
discriminative
approach
,
approach
,
gildea
,
word
alignment
,
present
improvement
,
alignment
model
,
word
alignment
ap
proaches
,
good
performance
,
weakness
,
coarse
transition
model
,
alignment
model
,
hmm
transition
probability
,
jump
width
,
last
state
,
next
state
,
knowledge
,
transi
tion
probability
,
particular
source
word
,
transition
model
,
alignment
,
transition
model
,
pendent
,
approach
,
source
lan
guage
,
number
,
word
class
,
transition
parameter
,
word
class
,
jump
width
,
probability
,
transition
probability
,
word
dependent
self-transition
model
,
current
source
word
,
next
step
,
different
word
,
assumption
,
source
word
,
fertili
ty
,
generates
consecutive
word
,
target
language
,
probability
,
fertility
modeling,word-to-phrase
hm
,
source
word
dependent
phrase
length
model
,
length
,
consecutive
target
word
,
source
word
,
powerful
modeling
,
approximate
fertility
,
single
,
parameter
,
h
owever
,
method
,
proba
bility
,
state
occupancy
,
full
set
,
transition
probability
,
important
knowledge
,
forward
,
monotonic
alignment,non-monotonic
alignment
,
method
,
transition
model
,
hmm
alignment
model
,
source
word,self-transition
probability
,
probabil
ity
,
different
word
,
purpose
,
full
transition
model
,
source
word
,
key
problem
,
detailed
word-dependent
transition
modeling
,
data
sparsity
,
toutanova
,
word
dependent
self-transition
probability
,
global
hm
self-transition
probability
,
data
sparsity
problem
,
interpolation
weight,weight,hold-out
set
,
proposed
word
,
pendent
transition
model
,
large
number
,
parameter
,
data
sparsity
problem
,
sparsity
,
different
word,one-size-fits-all
interpolation
weight
,
simple
linear
interpolation
,
problem
,
bayesian
learning
,
transition
model
parameter
,
maximum
,
training
,
prior
distribu
tion
,
training
,
result
,
robust
model
,
next
section
,
review
modeling
,
transition
probability
,
conventional
hmm
alignment
model
,
equation
,
map
training
,
word
dependent
transition
model
,
section
,
word
alignment
result
,
significant
alignment
error
rate
reduction
,
baseline
hmm
,
ibm
model,phrase-based
machine
transla
tion
experiment
,
europarl
corpus
,
method
,
significant
ble
score
improvement
,
ibm
model
,
2
b
aseline
hmm
alignment
model
,
word
alignment
model
,
denote
,
french
sentence
,
english
sentence
,
alignment
,
position
,
english
word
,
french
word
,
word
alignment
,
a
h
mm
,
position
,
a
h
mm
state
,
sparse
data
problem
,
emission
prob
ability
,
transition
prob
ability
,
position
,
last
state
,
length
,
transition
probability
,
i
i
depend
,
jump
width
,
t
herefore
,
distortion
,
word
null
,
french
word
,
english
word
,
posi
tion
,
last
french
word,non-null
english
word
,
null
word
,
english
side,probability,hold-out
data
,
convenience
,
hmm
parameter
,
training
stage
,
efficient
expectation-maximization
al
gorithm
,
convergence
,
rabiner
,
interest
,
tran
sition
parameter
estimation
,
detail
,
mul
tinomial
distribution
,
iteration
,
distortion
,
fractional
count
,
transition
,
immediate
previous
iteration
,
forward
backward
algorithm
,
rabiner
,
bucket
,
implementation
,
bucket
,
probability
mass
,
transition
,
jump
width
,
separate
set
,
distortion
parameter
,
first
state
,
last
state
,
smooth
transition
probability
,
uniform
distribution
,
training
,
viterbi
decoding
,
alignment
sequence,ord-dependent
transition
model
,
alignment
model
,
previous
section
,
conventional
transition
model
,
source
word
position
,
limited
distortion
parameter
,
transi
tion
,
hmm
state
,
english
word
,
knowledge
,
transition
probability
,
particular
source
word
,
transition
model
,
transition
probability
,
pendent
,
probability
,
state
aj
_
,
english
word
,
position
aj
_
,
transition
parameter
_
_
,
_
jae
depen
dent
,
correspondingly
,
hmm
parameter
,
free
parame
ters
,
transition
probability
,
4
b
ayesian
learning,word-dependent
transition
model
,
maximum
,
posteriori
training
u
,
ml
training
,
estimation
formula
,
word
dependent
transition
probability
,
training
iteration
,
word
dependent
distortion
,
jump
width
,
kronecker
delta
function
,
many
non-frequent
word
,
data
sample
,
sparse
data
,
framework
,
gauvain
,
map
training
,
appropriate
prior
distribution
,
rate
prior
knowledge
,
model
parameter
e
timation
,
prior
distribution
,
distribution
,
model
parameter
,
english
sentence
,
relation
,
map
estimation
,
theorem
,
posterior
distribution
,
likelihood
function
,
transition
model
estimation
,
a
d
irichlet
distri
bution
,
following
form,bishop,hyper-parameters
,
prior
distribution
,
mathematic
tracta
bility
,
practice
,
em
algorithm
,
iterative
map
training
formula
,
transition
model
,
gauvain
,
ap
i
i,hyper-parameters
,
prior
distribution
,
bayesian
learning
,
prior
distribution
,
subjective
knowledge
,
method
,
word
independent
transition
probability
,
positive
parameter,hold-out
data
set
,
ef
fect
,
experimental
result
,
later
section
,
transi
tion
model
,
formula
becomes
,
frequent
word
,
large
amount
,
data
sample
,
data
distribution
,
rare
word
,
low
count
,
word
independent
model
,
weak
prior
,
transition
probability
,
training
data
,
prior
knowledge
,
word
dependent
transition
model,word-independent
transition
model
,
parameter
,
contribution
,
prior
distribution
,
model
training
,
word
alignment
performance
,
5
e
xperimental
result
,
word
alignment
,
canadian
han,english-french
corpus
w
,
word
dependent
transition
mod
el
,
word
alignment
,
eng
lish-french
hansard
corpus
,
subset
,
sentence
pair
,
experiment
,
test
sentence-pairs
,
test
sentence
pair
,
possible
alignment
,
annotation
,
word
alignment
performance
,
sure
gold
alignment
,
possible
gold
alignment
,
alignment
,
word
alignment
method
,
ibm
model
,
baseline
hmm
model
,
section
,
hansard
corpus
,
common
practice
,
translation
probability
,
uniform
distribution
,
word
pair
,
uniform
transition
probability
,
translation
probability
,
iteration
,
word
dependent
transition
model
,
setting
,
hmm
baseline
,
transition
prob
ability
,
ib
model
,
iteration
,
training
,
iteration
,
mod
el,iteration,effect,hyper-parameters
,
prior
dis
tribution
,
wdh
mm
,
figure
,
horizontal
dot
line
,
baseline
hmm,dash-line
curve
,
ae
r
,
wdh
mm
,
figure
,
valid
value
,
log
domain,left-most
point,figure,word-dependent
transition
model
,
sparse
data
problem
,
high
aer
,
increase
,
larg
er
value
,
robust
model
,
large
range
,
baseline
hm
,
prior
distribution
,
result
,
performance
,
baseline
hm
,
present
aer
result
,
combination
,
word
alignment
,
heuristic
,
similar
trend
,
aer
change
,
respec
,
detailed
comparison
,
ibm
model
,
baseline
hm
,
wdh
mm
,
ibm
model
,
superior
performance
,
baseline
hm
,
alignment
direction
,
combination
,
modeling
mechanism
difference
,
tween
hmm
,
hmm
baseline
,
wdh
mm
,
prior
parameter
,
log
scale,left-most
point
,
figure
,
result
,
combination
,
word
alignment
,
ib
model
,
comparison
,
ous
model
,
sentence
pair
,
number
,
percentage
,
ib
model
,
comparison
,
precision
,
various
model
,
sentence
pair
,
number
,
percentage
,
ib
model
,
comparison
,
recall
,
vari
ous
model
,
sentence
pair
,
number
,
percentage
,
europarl
corpus
,
wdh
mm,phrase-based
machine
translation
system
,
im
provement
,
word
alignment
,
mt
accuracy
,
ble
score
,
papineni
,
machine
translation
experiment,english-to-french
track
,
na
acl
,
europarl
evaluation
workshop
,
supplied
training
corpus
,
sentence
pair
,
text
data
,
expe
riment
,
word
clustering
,
word
class
,
baseline
hm
,
ibm
model
,
use
word-class
,
transition
model
,
wdh
mm,word-class
,
transition
model
,
prior
distribu
tion
,
ibm
model
,
regimen
,
iteration
,
iteration
,
iteration
,
alignment
,
direction
,
heuristic
rule
,
bilingual
text
,
maximum
phrase
length,phrase-based
mt
system
,
channel
model
,
direct
maximum
likelihood
estimate
,
probability
,
target
phrase
,
source
phrase
,
estimate
,
source
,
target
,
lexicon
weighting
feature
,
source
,
target
,
source
,
word
count
,
phrase
count,3-gram
language
model
,
workshop
,
hese
model,log-linear
frame
work
,
different
weight
,
weight
vector
,
english
sentence
,
french
translation
reference,experiment,sentence,log-linear
model
weight
vector
,
training
,
fter
mer
training
,
weight
vector
,
accuracy
,
development
set,sentence,development-test
set
devtest,sentence,out-of-domain
sentence
,
pharaoh
phrase-based
decoder,re-ordering
limit
,
default
setting
,
pa
rameters
,
present
ble
score
,
mt
system
,
different
word
alignment
,
test
set
,
show
ble
score
,
domain
test
,
show
mt
result,out-of-domain
test
set
,
prior
parame
ter
,
wdh
mm
,
horizontal
dash
line
,
hori
zontal
dot
line
represent
ble
score
,
base
line
hmm
,
devtest
,
test
set,dash-line
curve,dot-line
curve
,
ble
score
,
wdh
mm
,
figure
,
ble
score
,
prior
parameter
,
considerable
im
provement
,
ble
score
,
baseline
hmm
,
broad
range
,
reasonable
range
,
prior
distribution
,
horizontal
dash
line
,
bl
eu
score
,
baseline
hmm,nc-test
set,dash-line
curve
,
ble
score
,
wd
hmm
,
out-of-domain
test
,
bl
eu,out-of-domain
test,in-domain
test
,
possible
expla
nation,out-of-domain
data
,
robust
modeling
,
outlier
,
modeling
,
difference
,
experiment
,
conclusion
,
detailed
ble
u-wise
comparison
,
tween
baseline
hmm
,
wdh
mm
,
wdh
mm,performance,development-test
set
devtest
,
result
,
ibm
model,in-domain
test
set,improvement,out-of-domain
test
,
ble
score
,
test
set
,
devtest
,
test
f
igure
,
machine
translation
result
,
french
track
,
devtest
,
test
set
,
bl
eu
score
,
hmm
baseline
,
ble
score
,
wd
hmm
,
prior
parameter
,
log
scale
,
machine
translation
result
,
french
track,out-of-domain
test
set
,
bl
eu
score
,
hmm
baseline
,
ble
score
,
wd
hmm
,
prior
parameter
,
log
scale
,
model
devtest
test
nc-test
baseline
hmm
,
ib
model
,
comparison
,
ble
score
,
various
word
alignment
model
,
ll
number
,
percentage
,
wd
hmm
,
paired
bootstrap
,
method
pro
,
statistical
sig
nificance
,
test
result
,
ble
gain
,
wdh
mm
,
different
test
set
,
ibm
model
,
devtest
set
,
significance
level
,
significance
level
,
test
nc-test
wd
hmm
,
ibm
model
,
statistical
significance
test
,
ble
im
provement
,
baseline
,
ibm
model,devtest,nc-test
set
,
runtime
performance
,
wdh
mm
w
dhmm
,
normal
hmm
,
extra
memory
,
word
dependent
transition
model
,
vocabulary
size
,
source
language
,
distortion
set
,
runtime
speed
,
wd
hmm
,
ibm
model
,
result
,
euro
parl
english
,
french
alignment
,
fast
pc
,
16g
memory
,
iteration
,
training
,
itera
tions
,
wdh
mm
,
iteration
,
iteration
,
iteration
,
wd
hmm
,
end-to-end
word
alignment
,
model
runtime
,
comparison
,
runtime
performance
bew
teen
wdh
mm
training
,
ibm
model
,
training
,
gi
za
,
iscussion
work
,
transition
model
,
word
alignment,word-class
,
transition
model
,
transition
probability
,
sparse
data
problem
,
small
number
,
word
class
,
many
word
,
transition
model
,
toutanova
,
estimate
,
prob
ability
,
dif
ferent
word
,
later
deng
,
word
dependent
phrase
length
model
,
model
state
occupancy
,
probability
,
self
jumping
,
important
knowledge
,
different
position
,
word
depen
dent
,
interesting
comparison
,
wd
hmm
,
fertility-based
model
,
ma
jor
disadvantage
,
absence
,
mod
el
,
source
word
fertility
,
toutanova
,
word
dependent
self
transition
model
,
approxima
tion
,
number
,
consecutive
target
word
,
source
word
,
geometric
distribution
,
word
dependent
transition
model
,
weakness
,
full
word-dependent
transition
model
,
word
alignment
,
robust
model
estimation
,
sparse
data
condition
,
series
,
experiment
,
method
,
word
alignment
,
machine
translation
test
,
significant
improvement
,
baseline
hmm
,
complicated
ibm
model
,
word
alignment
model
,
various
word
alignment
,
machine
translation
task
,
author
,
chris
quirk
,
arul
menezes
,
assistance
,
mt
system
,
valuable
suggestion
,
discussion
,
r
eferences
,
bishop
,
pattern
recognition
,
machine
learning
,
mathematics
,
statistical
machine
trans
lation
,
parameter
estimation
,
computational
linguis
tic
,
phrase
alignment
,
statistical
machine
translation
,
proceeding
,
gauvain
,
maximum
a
p
,
estimation
,
multivariate
gaussian
mixture
ob
servations
,
speech
,
goodman
,
research
,
microsoft
,
statistical
phrase-based
translation
,
proceeding
,
statistical
significance
test
,
ma
chine
translation
evaluation
,
proceeding
,
pharaoh
,
a
b
eam
search
decoder
,
phrase
,
statistical
machine
translation
mod
el
,
proceeding
,
alignment
,
agreement
,
proceeding
,
improved
dis
criminative
bilingual
word
alignment
,
proceed
ings
,
comparison
,
align
ment
model
,
statistical
machine
translation
,
proceeding
,
statistical
alignment
model
,
proceeding
,
statis
tical
translation
model
,
informatik
,
rwthaachen
,
software
,
discriminative
training
,
maximum
entropy
model
,
statistical
machine
translation
,
proceeding
,
minimum
error
rate
training
,
statis
tical
machine
translation
,
proceeding
,
a
m
ethod
,
automatic
evaluation
,
machine
translation
,
proceeding
,
tutorial
,
hidden
markov
mod
el
,
application
,
statistical
word
align
ment
model
,
proceeding
,
tillmann
,
statistical
translation
,
pro
ceedings
,
gildea
,
stochastic
lexicalized
inversion
transduction
grammar
,
alignment
,
proceeding
,
proceeding
,
conference
,
empirical
method
,
natural
language
processing
,
edinburgh
,
association
,
computational
linguistics
domain
adaptation
,
pseudo
in-domain
data
selection
amittai
axelrod
university
,
microsoft
research
redmond
,
xiaohe
microsoft
,
com
jianfeng
gao
microsoft
research
redmond
,
jfgao
microsoft
,
com
abstract
,
efficient
domain
adaptation
,
statistical
machine
translation
,
sentence
,
large
general
domain
parallel
corpus
,
target
domain
,
sentence
,
simple
cross-entropy
,
method,sentence,in-domain
data
,
pseudo
in-domain
subcorpora
,
subcorpora
,
system
,
perform
system
,
entire
corpus,performance,domain-adapted
model
,
combination
,
true
in-domain
model
,
result
,
training
data
,
result
,
proper
domain-relevant
data
selection
,
inand
general-domain
system
,
system
,
formance
,
quantity
,
quality
,
available
training
data
,
conventional
wisdom
,
training
cor
pu,trouble,all-purpose
smt
system
,
enough
training
data
,
translation
task
,
formal
genre
,
coherent
translation
task
,
stylistic
prefer
ences
,
corpus
characteristic,all-encompassing
model,language,reason,in-domain
data
,
training
,
accurate
lexical
probability
,
par
allel
in-domain
data
,
performance
,
quan
tity,domain-specific
training
data
,
additional
parallel
data
,
specificity
,
broad
enough
pool
,
corpus
,
relevance
,
domain
adaptation
,
target
,
domain
,
small
amount
,
training
data
,
mt
system
,
target
domain,general-domain
corpus
,
stan
dard,out-of-domain
corpus
,
large
uncurated
corpus
,
target
domain
,
domain
adaptation
method
,
broad
category
,
adaptation
,
corpus
level
,
datasets
,
exten
sion
,
system
,
model
level
,
multiple
translation
,
language
model
,
weighted
man
ner
,
category
,
parliamentary
speech,method,sentence,general-domain
corpus,respect,in-domain
corpus,cutoff,subcorpus,domain-adapted
mt
system
,
data
selection
method
,
ap
plication,language-modeling
technique
,
third
method
,
account
,
bilingual
na
ture
,
mt
training
corpus
,
data
selection
method
,
large
general
training
corpus
,
translation
perfor
mance
,
2
b
leu
point
,
subcorpora
,
combination
,
domain
set,subcorpora,out-of
domain
,
something
,
translation
model
combination
method
,
tiny
translation
mod
el
,
model
combination
,
system
,
formance
,
current
standard
way,domain-adapted
mt
system
,
process
,
data
selection
,
underlying
assumption
,
domain
adaptation,general-domain
corpus
,
sentence
,
target
domain
,
train
ing,general-domain
corpus
,
cludes
sentence
,
domain
,
mechanism
,
domain
adaptation,portion,general-domain
corpus
,
complete
system
,
instance
,
problem
,
language
modeling,perplexity-based
selection
method,sentence,general-domain
corpus
,
plexity
score,in-domain
language
model
,
language
modeling,sentence,general-domain
corpus
accord,in-domain
perplexity
,
machine
translation
,
yasuda
,
foster
,
approach
,
difference
,
source
side
,
plexity
,
geometric
mean
,
perplexity
,
corpus
,
training
corpus
,
yasuda
,
percentage
,
cor
pu,in-domain
corpus
,
decrease
,
performance
,
general
method
,
matsoukas
,
weight
,
sentence
,
large
corpus
,
em
pirical
phrase
,
foster
,
extracted
phrase
pair
,
sentence
,
soft
decision
,
binary
decision
,
includ
ing
,
sentence
,
subcorpus
,
computational
complexity
,
possibility
,
effective
feature
,
matsoukas
,
source
doc
uments,perplexity-based
approach,cross-entropy
difference
,
ranking
function,cross-entropy
,
criterion
,
first
time
,
training
data
,
machine
translation
system,mt-specific
purpose
,
translation
model
combination
,
addition
,
performance
,
sin
gle
general
model
,
respect
,
target
domain
,
significant
interest
,
translation
model,general-domain
cor
pu,in-domain
corpus,in-domain
text,in-domain
corpus,general-domain
corpus,in-domain
data,expectation,general-domain
model,region,in-domain
model,coverage,non-existent
,
ngram
count
,
practice
,
practical
system
,
form
target-side
language
model
adaptation
,
ef
fects
,
translation
model
adaptation
,
phrase
,
identical
phrase
pair
,
unpre
dictable
behavior
,
identical
phrase
pair
,
source
table
,
experience
identical
entry
,
phrase
table
,
domain
,
foster
,
inand
general-domain
phrase
ta,log-linear
weight
,
standard
practice
,
schroeder
,
improvement
,
moses
smt
decoder
,
phrase
,
main
adaptation
,
approach
,
foster
,
schroeder
,
system
gener
,
method
,
section
,
3
e
xperimental
framework
,
experiment
,
interna
tional
workshop
,
con
sisting
,
transcription
,
conversational
speech
,
travel
,
corpus
,
adaptation
task,in-domain
data
,
iws
lt
corpus,sentence,chinese,english,general-domain
cor
pu
,
parallel
sentence
,
variety
,
available
datasets
,
web
data
,
private
translation
text
,
inand
general
domain
corpus
,
english
,
iws
lt
spontaneous
speech
challenge
task3
test
,
iwslt2010
,
condition
,
chinese
sentence
,
glish
reference
translation
,
recent
iws
lt
test
set
,
reference
trans
lations
,
system
description
,
data
selection
work,out-of-the-box
moses
framework
,
machine
translation
sys
tems
,
exception
,
phrase
table
,
large
out-of-domain
system
,
sentence
pair,cluster,word-dependent
hmm
,
moses
decoder
,
system
,
nis
mt-eval31a
,
iws
lt
evalutation
,
language
model
,
language
model
,
sentence
,
training
corpus
,
addition
,
normal
use
,
machine
translation
tuning
,
decoding
,
sri
language
model
,
toolkit
,
stolcke
,
lm
train
ing
,
language
mod
el
,
interpolated
modified
kneser-ney
discount
ing
,
goodman
,
good
turing
threshold
,
trigram
,
baseline
system,in-domain
baseline
,
translation
system
,
iws
lt
corpus
,
phrase
table,general-domain
base
line
,
sentence
pair
,
phrase
table
,
ble
score
,
baseline
single-corpus
system
,
corpus
phrase
dev
test
iws
lt
,
general
,
baseline
translation
result,general-domain
system
,
gov
iad
mig
tool
,
data
selection
method,technique,subset,general-domain
corpus
,
eye
towards
,
overall
translation
performance
,
data
selection,cross-entropy
,
section
,
method
,
sentence
,
general
domain
corpus
,
perplexity
score
accord
,
language
model
,
domain
corpus,perplexity,general-domain
corpus,expectation,in-domain
corpus
,
method
,
machine
trans
lation
,
perplexity
reduction
,
translation
performance
,
axelrod
,
proce
dure
,
cosmetic
change,cross-entropy
,
perplexity
,
perplexity
,
string
,
empirical
gram
distribution
,
language
model,cross-entropy
,
notation,cross-entropy
,
string
,
lan
guage
model
lmi,distribution,sentence,perplexity,sentence,in-domain
language
model
,
experiment
,
lan
guage
model
,
parameter
,
sec
tion
,
chinese
side
,
iws
lt
corpus
,
data
selection,cross-entropy
difference
moore
,
language
model
lmi,in-domain
corpus
,
construct
,
language
modellmo
,
similar
size,general-domain
corpus,general-domain
corpus
sentence,lowest-scoring
sentence
,
criterion
,
towards
sentence,in-domain
corpus,average,general-domain
corpus,experiment,in-domain
lm
,
previous
method
,
second
lm
,
random
subset
,
sentence
,
chinese
side
,
general
corpus
,
vocabulary
,
domain
,
bilingual
cross-entropy
difference
,
addition
,
monolingual
criterion
,
mt
data
selection
,
new
method
,
bilingual
nature,problem,cross-entropy
differ
ence,corpus,source,approach,source-side
language
model,section,similarly-trained
one
,
english
side
,
vocabulary
,
language
model
,
subset
,
general
domain
corpus,in-domain
corpus
,
5
r
esults
,
training
data
selection
,
baseline
result
,
translation
system,general-domain
corpus,system,in-domain
corpus
,
3
b
leu
point,method,section,best-scoring
sentence
,
general
domain
corpus
,
method
,
domain
,
parallel
data
,
general
corpus
,
source
side
cross-entropy
,
cross-ent
,
source-side
cross
entropy
difference,moore-lewis
,
regardless
,
method
,
overall
procedure
,
scoring
method
,
individual
sentence,general-domain
corpus
,
sentence
pair
,
general
corpus
,
net
effect
,
domain
adaptation
,
threshhold
filtering
,
new
mt
system
,
small
sub
corpus
,
baseline
model
,
entire
12m-sentence
general-domain
corpus
,
contains
ble
score
,
sys
tems
,
subset
,
general
corpus
,
method
sentence
dev
test
general
,
translation
result,subset,general-domain
corpus
,
method
,
sub
set,general-domain
corpus,cross-entropy
,
moore-lewis
,
bilingual
moore-lewis
,
state-of-the-art
machine
transla
tion
system,method,source-side
cross-entropy
,
general-domain
model
,
sentence
,
monolingual
method,source-side
cross-entropy
difference
,
general
domain
model
,
sentence
,
bilin
gual
moore-lewis
method
,
performance
,
available
training
data
,
pseudo
in-domain
data
,
result
,
meth
od,cross-entropy
,
moore-lewis
,
bilingual
moore
lewis,subset,general-domain
corpus
,
purpose
,
statistical
machine
translation,method,in-domain
data
hidden,in-domain
corpus,general-domain
corpus
,
baseline
language
model
,
domain
data,perplexity,held-out
dev
set
,
translation
model
,
top
sentence
,
ranking
method
,
language
model,subcorpora,perplexity,held-out
dev,figure,top-r
anked
gener
al-dom
ain
se
ntenc
e
,
-
l
ewis
bilingu
,
m-l
figure
,
corpus
selection
result,perplexity,top-ranked
sentence,subset,method,cross-entropy
method
,
others
,
perplex
ity
,
sentence
,
bilingual
moore
lewis,plexity,perplexity,in-domain
data
,
selection
method
,
domain
,
pseudo
,
domain
data
,
distribution
,
original
in-domain
corpus,evidence,result,in-domain
corpus
,
subcorpora
,
bilingual
moore
lewis
method
,
change
,
test
score
,
dissim
ilarity
,
underlying
data
,
datasets
,
method
sentence
dev
test
iws
lt
,
iws
lt
,
iws
lt
,
iws
lt
,
translation
result,in-domain
,
pseudo
in-domain
data
,
single
model
,
6
t
ranslation
model
combination
,
pseudo
in-domain
data,in-domain
data
,
multiple
translation
model,general-domain
corpus
,
linear
interpolation
common
approach
,
multiple
transla
tion
model
,
foster
,
linear
interpolation
,
inand
general-domain
translation
model
,
trans
lation
,
source
,
target
,
second
model
,
tunable
weight
,
increment
,
linear
interpolation
,
phrase
table
,
performance
,
individual
model
,
effective
use
,
translation
model
,
multiple
model
,
approach
,
schroeder
,
phrase
table
,
decoder
,
system
,
phrase
table
,
parallel
,
phrase
,
separate
set
,
weight
,
tuning
,
combined
translation
model
,
parameter
,
normal
single-table
system
,
overlap
,
phrase
ta
bles
,
multiple
decoding
path
,
phrase
pair
,
decoder
,
exact
overlap
,
phrase
ta
bles
,
effect
,
translation
model
combination
result
table,result,in-domain
translation
system,general-domain
system,in-domain
data
,
translation
model
,
overall
ble
score
,
explicit
model
,
result
,
2
b
leu
point
,
indi
vidual
model
,
interpo
,
system
dev
test
iws
lt
,
interpolate
iws
lt
,
iws
lt
,
translation
model
combination
result
,
translation
model
adaptation,decoder,multi-model
,
data
selection
approach
,
section
,
several
method
,
performance
,
single
general-domain
translation
system
,
training
corpus,information-theoretic
basis
,
small
number
,
sentence
,
section
,
translation
model
,
avail
able
data,in-domain
,
general-domain
,
performs
,
single
individual
translation
model
,
method
dev
test
iws
lt
,
iws
lt
,
iws
lt,moore-lewis
,
iws
lt,moore-lewis
,
iws
lt,moore-lewis
,
iws
lt
,
iws
lt
,
iws
lt
,
translation
result
,
pseudo
in-domain
translation
model,in-domain
data
,
pseudo
in-domain
data
,
general
domain
corpus,access,in-domain
corpus,in-domain
translation
model
,
translation
model
,
subcor
pora,moore-lewis
,
bilingual
moore-lewis
method
,
section
,
result
,
translation
system
,
pseudo
,
domain
subset
,
general
corpus
,
bilingual
moore-lewis
method,in-domain
model
,
system
combination
,
conventional
multi-model
approach
,
test
set,domain-adapted
system
,
phrase
table
,
sen
tences
,
standard
multi-model
sys
tem
,
sentence
,
tiny
combined
system,general-domain
system,in-domain
system
,
8
c
onclusions
sentence
pair,general-domain
corpus,in-domain
corpus
,
distribution
,
language
,
language
model
perplexity
,
nonethe
,
tiny
amount
,
pseudo
in-domain
data
,
entire
general-domain
corpus
,
pur
pose,domain-targeted
translation
task
,
effective
method
,
pseudo
,
domain
sentence,general-domain
corpus
,
translation
model
,
subcorpora
,
translation
system
,
entire
corpus
,
new
bilingual
moore-lewis
method
,
ma
chine
translation
scenario
,
ef
ficient
,
mt
domain
adaptation
,
trans
lation
model,general-domain
base
line
,
sen
tences
,
simple
technique,general-domain
training
corpus
re
,
increase
,
linear
,
terpolation
,
translation
model
,
translation
model
adaptation
,
multiple
path
,
technique
,
data
selection
,
model
com
bination
,
translation
system
,
available
data,state-of-the
art
translation
system
,
translation
performance
,
large
corpus,computationally-limited
environment
,
ordinary
computer
,
mobile
device
,
maximum
size
,
useful
general-domain
cor
pu
,
availability
,
translation
model
,
memory
,
reference
amittai
axelrod
,
language
model
,
thesis
,
univer
sity
,
edinburgh
,
scotland
,
alexandra
birch
,
mile
osborne
,
philipp
koehn
,
factored
translation
model
,
workshop
,
statistical
machine
translation
,
associ
ation
,
computational
linguistics
,
stanley
chen
,
joshua
goodman
,
em
pirical
study
,
smoothing
technique
,
language
modeling
,
technical
report
,
computer
science
group
,
harvard
university
,
matthias
eck
,
stephan
vogel
,
alex
waibel
,
model
adaptation
,
statistical
machine
,
translation
,
information
retrieval
,
language
resource
,
evaluation
,
george
foster
,
roland
kuhn,mixture-model
adaptation
,
workshop
,
statistical
machine
translation
,
association
,
computational
linguis
tic
,
george
foster
,
cyril
goutte
,
roland
kuhn
,
discriminative
instatnce
weighting
,
domain
adap
tation
,
statistical
machine
translation
,
empirical
method
,
natural
language
processing
,
jianfeng
gao
,
joshua
goodman,kai-fu
lee
,
toward
a
u
,
approach
,
statistical
language
modeling
,
asian
language
information
processing,xiaodong,word-dependent
transition
model
,
word
alignment
,
statisti
cal
machine
translation
,
workshop
,
statistical
ma
chine
translation
,
association
,
computational
lin
guistics
,
philipp
koehn
,
hieu
hoang
,
alexandra
birch
,
chris
callison-burch
,
marcello
federico
,
nicola
bertoldi
,
brooke
cowan
,
wade
shen
,
christine
moran
,
richard
zen
,
chris
dyer
,
ondrej
bojar
,
alexandra
con
stantin
,
evan
herbst
,
open
source
toolkit
,
statistical
machine
translation
,
demo
s
sion
,
association
,
computational
linguistics
,
philipp
koehn
,
josh
schroeder
,
experiment
,
domain
adaptation
,
statistical
machine
trans
lation
,
workshop
,
statistical
machine
translation
,
association
,
computational
linguistics
,
jin
huang
,
qun
liu
,
statistical
machine
translation
performance
,
data
selection
,
optimization
,
empirical
meth
od
,
natural
language
processing
,
computa
tional
natural
language
learning
,
spyros
matsoukas,antti-veikko
rosti
,
bing
zhang
,
discriminative
corpus
weight
estimation
,
machine
translation
,
empirical
method
,
natural
language
processing
,
robert
moore
,
william
lewis
,
intelligent
se
lection
,
language
model
training
data
,
association
,
computational
linguistics
,
preslav
nakov,english-spanish
sta
tistical
machine
translation
,
experiment
,
domain
adaptation
,
sentence
paraphrasing
,
tokenization
,
recasing
,
workshop
,
statistical
machine
transla
tion
,
association
,
computational
linguistics
,
franz
och
,
hermann
ney
,
ystematic
comparison
,
various
statistical
alignment
model
,
computational
linguistics
franz
och
,
minimum
error
rate
training
,
sta
tistical
machine
translation
,
association
,
compu
tational
linguistics
andreas
stolcke
,
extensible
lan
guage
modeling
toolkit
,
spoken
language
process
,
keiji
yasuda
,
ruiqiang
zhang
,
hirofumi
yamamoto
,
ei
ichiro
sumita
,
method
,
a
c
ompact
,
efficient
transla
tion
model
,
international
joint
conference
,
natural
language
processing
,
proceeding
,
joint
conference
,
empirical
method
,
natural
language
processing
,
computational
natural
language
learning
,
jeju
island
,
association
,
computational
linguistics
learning
lexicon
model
,
search
log
,
query
expansion
j
ianfeng
gao
microsoft
research
,
redmond
washington
,
com
s
hasha
xie
educational
testing
service
,
princeton
new
jersey
,
sxie
ets
,
org
x
iaodong
,
microsoft
research
,
redmond
washington
,
com
a
lnur
ali
microsoft
bing
,
bellevue
washington
,
com
a
bstract
,
web
search
,
lexicon
model
,
lexical
gap
,
web
document
,
user
query
,
user
query
,
clicked
document
,
evaluation
,
real
world
data
,
lexicon
model,ranker-based
qe
system
,
document
retriev
al
performance,state-of-the-art
log-based
qe
method
,
1
i
ntroduction
term
mismatch
,
fundamental
problem
,
web
search
,
document
,
different
vocabulary
,
language
style
,
effective
strate
gy
,
problem
,
additional
related
term
,
expansion
term
,
relevant
document
,
clickthrough
data
,
translation
model
,
ex
pansion
term
,
expansion
term
,
document
,
document
,
icon
model,query-title
pair
,
clickthrough
data
,
word
model
,
translation
probability
,
tween
single
word
,
second
model
,
lexi
calized
triplet
,
word
dependency
,
translation
,
bilingual
topic
model
,
distribution
,
hid
den
topic
,
translation
,
title
term
,
semantic
level
,
word
model
,
rich
set
,
expansion
candidate
,
triplet
,
topic
model
,
good
expansion
term,ranker-based
qe
system
,
web
search
result
,
form
log-based
qe
method
,
interest
,
user
log
,
recent
survey
,
baeze
yates,ribeiro-neto
,
log-based
qe
method
,
comparison
,
system
,
log
data
,
lexicon
model
,
term
correlation
model
,
knowledge
,
query
document
relation
,
direct
extraction
,
expan
sion
term
,
web
search
,
method
,
form
traditional
qe
method
,
log
data
,
local
analysis
model
,
important
advantage,log-based
qe
,
promising
technology
,
performance
,
commercial
search
,
traditional
qe
method
,
relevance
feedback,log-based
qe
,
expansion
term
,
search
log
,
term
correlation,pre-computed
offline
,
method
,
thesaurus
,
prager
,
document
collection,log-based
method
,
correlation
,
query
term
,
document
term
,
lexical
gap
,
second
,
search
log
,
query
document
pair
,
million
,
term
correlation
,
preference
,
ma
jority
,
term
correlation
,
accumulation
,
user
log
,
updated
user
interest
,
specific
time
,
riezler
,
corre
lation
model
,
context
information
,
riezler
,
a
q
system,system,query-snippet
pair
,
clickthrough
data
,
riezler
,
system
,
relevant
expansion
term
,
rich
context
information
,
noisy
expansion
,
language
model
,
phrase
translation
model
,
smt
system
,
component
model
,
sophisticated
technique
,
sparse
data
problem
,
correlation
model
relies
,
pure
count
,
term
frequency
,
smt
system
,
black
box
,
experiment
,
relative
con
tribution
,
different
smt
component
,
black
box
,
lexicon
model
,
simpler
qe
system
,
lexicon
model,black-box
smt
system
,
2
l
exicon
model
,
search
query
,
web
document
,
different
language
,
language
gap
,
document
,
sec
tion
,
translation
model
,
triplet
,
que
ry-title
pair
,
clickthrough
data
,
word
model
,
word
model
,
ibm
model
,
expansion
term
candidate
,
translation
probability
,
unsmoothed
unigram
proba
bility
,
word
translation
probability
,
query
title
pair
,
clickthrough
data
,
title
term
,
desired
expansion
,
paired
query
,
method
,
standard
procedure
,
statistical
word
alignment
model
,
model
parameter
,
probability
,
document
title
,
que
ries
,
entire
training
corpus
,
paired
query
,
translation
probability
,
ibm
model
,
length
,
length
,
optimal
word
transla
tion
probability
,
ibm
model
,
em
algorithm,number,iteration,held-out
data
,
triplet
model
,
word
model
,
triplet
model,inter-term
dependency
,
expansion
term
,
lexicalized
triplet
,
query
term
,
expansion
term
,
translation
proba
bility
,
triplet
model
,
normalization
factor
,
probability
,
triple
model
,
query
level
,
contextual
information
,
word
translation
,
word
model
,
em
algorithm
,
translation
probabili
tie,query-title
pair
,
number
,
possible
triplet
,
consequence
,
model
training
,
data
sparseness
problem
,
experiment
count-based
cutoff
,
manageable
size
,
web
doc
ument
ranking
,
search
query
,
relevant
web
document
share
,
common
distribu
tion
,
hidden
,
vocabulary
,
vector
,
candidate
expansion
term
,
document
,
document
term
,
describe
,
word
model
,
triplet
model
,
mapping
,
topic
level
,
language
independent
semantic
representa
tion
,
word
level
,
experi
ments
blt
,
different
set
,
expansion
term
,
word
model,tm-based
qe
,
different
word
distribution
,
a
d
irichlet
,
concentration
pa
rameter,topic-specific
query
term
distribution,topic-specific
document
term
distribution
,
distribu
tions
,
topic
distribution
,
a
d
irichlet
,
concentration
pa
rameter
,
expansion
term
candidate
,
possible
topic
,
training
,
method
,
ale
em
algorithm
,
parameter
,
joint
log-likelihood
,
query
title
pair
,
parameter
,
training
,
paired
query
,
lar
fraction
,
constraint
,
expectation
,
posteri
,
regularization
,
ganchev
,
3
a
ranker-based
qe
system,section,ranker-based
qe
system
,
lexicon
model
,
system
,
input
query
,
distinct
stage
,
candidate
generation
,
ranking
,
example
,
expansion
jaguar
finder
candidate
,
car
locator
jaguar
location
italic
,
expansion
term
,
locator
,
finder
,
location
,
example
,
original
query
,
expan
sion
candidate,ranker-based
qe
system
,
candidate
generation
,
input
query
,
sequence
,
stop
word
,
word
model
,
section
,
altered
word
,
word
transla
tion
probability
,
expansion
candidate
,
original
word
,
altered
word
,
candi
date
,
second
stage
,
expansion
candidate
,
ranker
,
lexicon
model
,
feature
,
e
xpansion
term
,
experiment
,
expansion
candidate
,
original
query
,
remainder
,
section
,
ranker
,
ranking
feature
,
ranker
parameter
,
ranker
,
ranker
,
mrf
model
,
joint
distribution
,
ex
pansion
term
random
variable
,
graph
consisting
,
query
node
,
expansion
term
,
graph
represent
random
variable
,
independ
ence
semantics
,
variable
,
markov
property,bishop,non-neighboring
node
,
observed
value
,
neighbor
,
clique
configuration
,
joint
distribution
,
random
varia
bles,clique,non-negative
potential
function
,
clique
configuration
,
compatibility
,
configuration
,
parameter
,
potential
func
tion
,
distribution
,
expansion
candidate
,
expen
sive
computation
,
expansion
candidate
,
unnormalized
joint
probability
,
mrf
potential
func
tions
,
exponential
form,real-valued
feature
function
,
clique
value
,
weight
,
feature
function
,
posterior
,
weighted
linear
combination
,
mrf
model
,
graph
structure
,
po
tential
function
,
graphical
model
representation
,
figure
,
expan
sion
term
,
original
query
,
pendent
,
clique
,
potential
function
,
feature
,
clique
,
feature
,
com
ponent
model
,
smt
system
,
clique
,
cat
egories
,
clique
,
query
node
,
expansion
term
,
potential
function
,
clique
,
translation
model
,
second
category
,
expansion
term
,
potential
func
f
igure
,
structure
,
markov
random
field
,
term
dependency
,
expansion
term
,
target
language
model
,
clique
,
single
ex
pansion
term
,
query
node
,
potential
function
,
clique
,
feature
function
,
log
probability
,
triplet
,
topic
model
,
second
type
,
clique
,
query
node
,
expansion
term
,
consecutive
order
,
expansion
,
potential
function
,
clique
,
feature
,
log
prob
ability
,
expansion
bigram
,
language
model
,
document
,
lafferty
,
bigram
probability
,
relative
frequency
,
bigram
,
bi
gram
probability
,
translation
probability
,
variant
,
triplet
model
,
section
,
model
variation
differs
,
respect
,
translation
,
different
direction
,
expansion
,
con
straint
,
triplet
,
contiguous
bigram
,
model
variation,query-title
pair
,
unigram
,
bigram
language
model
,
collection
,
document
title
,
unigram
probability
,
query
term
,
collection
,
clickthrough
data
,
third
type
,
clique
,
query
node
,
expansion
term
,
expansion
,
poten
tial
function
,
clique
,
feature
,
log
prob
ability
,
expansion
term
,
feature
capture
long-span
term
depend
ency
,
expansion
candidate
,
computation
,
translation
probability
,
triplet
model
,
sec
tion,expansion-to-query
direction
,
unigram
language
model
,
collection
,
document
title
,
clickthrough
data
,
co
occurrence
model
,
number
,
clickthrough
data
,
clique
,
query
node
,
fourth
type
,
clique
contains
,
expansion
term
,
potential
function
,
unigram
probability
,
unigram
language
model
,
collection
,
document
title
,
clique
,
consecutive
order
,
potential
function
,
bigram
probability
com
,
bigram
language
model
,
collection
,
document
title
,
clique
,
potential
function,co-occurrence
model
,
collection
,
document
title
,
parameter
estimation
,
mrf
model
,
feature
,
clique
,
bendersky
,
feature
,
feature
class
,
number
,
free
parameter
,
mrf
model
,
robustness
,
parameter
,
exponential
potential
function
form
,
ranker
,
nature
,
generative
model
,
pa
rameters
,
conventional
likelihood
,
ap
proaches
,
alaximum
likelihood
estimate
,
evaluation
,
effectiveness
,
a
q
method
,
method
,
search
engine
,
web
search
performance
,
better
qe
method
,
web
search
result
,
reason
,
parameter
,
ranker
,
web
search
,
experiment
,
objective
,
train
ing
,
kekalainen
,
quality
measure
,
training
,
multi
dimensional
optimization
problem
,
fea
ture
class
,
dimension
,
experiment
,
cal
algorithm
,
computation
,
gradient
,
performer
,
powell
search
algorithm
,
construct
,
virtual
direction
,
line
search
time
,
virtual
direction
,
optimum
,
line
search,one-dimensional
optimization
algo
rithm
,
implementation
,
averaged
precision
,
4
e
xperiments
,
performance
,
a
q
method
,
method
,
search
engine
,
web
search
performance
,
better
qe
method
,
web
search
result
,
correspondingly
,
query
set
,
d
ue
,
characteristic
,
qe
method
,
conduct
experiment
,
standard
test
collection
,
tre
data
,
related
user
log
,
therefore
,
previous
study
,
allthe
proprietary
datasets
,
commercial
search
engine
,
demon
strate
,
effectiveness
,
method
,
compar
,
previous
state-of-the-art
log
,
qe
method,judgment,consists,multi-term
english
query
,
average
,
que
ry
,
web
document
,
ach
query-url
pair
,
relevance
label,5-level
rele
vance
scale
,
document
,
meaning
,
judgment
,
search
engine
log
,
bot
query
,
unique
query
,
natural
query
distribution
,
quality
,
example
,
query
set
,
misspelled
query
,
navigational
query
,
transactional
que
ries
,
second
,
web
doc
uments
,
retrieval
result,query-document
pair,well-trained
assessor
,
white
space
,
number
,
inflection
treatment
,
judgment
,
datasets
,
training
,
test
set,dataset,query-title
pair
,
model
training
,
query
log
file
,
procedure
,
al
periments
,
subset
,
document
,
web
page
,
retrieval
experiment
,
title
text
,
web
search
performance
,
mean
ndc
,
ndc
score
,
trunca
tion
level
,
sig
nificance
test
,
paired
t-test
,
difference
,
system
table
,
main
document
,
result
,
different
qe
system
,
datasets
,
n
oqe
,
baseline
retrieval
system
,
raw
input
query
,
bm25
doc
,
different
qe
system
,
result
,
first
expand
,
docu
ments
,
respect
,
implementation
,
corre
lation-based
qe
system
,
following
step
,
1
n
oqe
,
mrf
wm
tm
,
mrf
wm
tm
bltm
,
ranking
result
,
different
query
expansion
system
,
superscript
,
significant
improvement
,
different
version
,
candidate
generator
,
ranker
different
feature
class
,
subscript
,
feature
class
,
function
,
feature
class
,
query
term
,
stopwords
,
document
,
query
term
,
title
term
,
document
,
evidence
,
expansion
term
,
whole
query
,
que
ry
,
expanded
query
,
document
,
function
,
term
correla
tion
model
,
document
,
search
log
,
normalized
tf-idf
weight
,
document
term
,
rela
tive
occurrence
,
document
,
significant
improvement
,
result
,
evaluation
,
document
,
search
log
,
encarta
website
,
data
set
,
result
,
recall
,
relevant
document
,
preci
sion
,
a
s
mt-based
qe
system
,
riezler
et
al
,
im
plementation,phrase-based
smt
system
,
standard
set
,
feature
,
translation
model
,
language
model
,
log
linear
mod
el
framework
,
riezler
,
al
translation
model,query-snippet
pair
,
language
model
,
implementation
,
trans
lation
model,query-title
pair
,
language
model
,
system
,
expansion
term,10-best
translation
,
original
query
,
nd
cg
,
result
,
con
clusion
,
riezler
,
alt
context
information
,
retrieval
pre
cision
,
noisy
expansion
,
oth
tc,state-of-the
art
qe
method
,
comparison
,
related
study,baseline,experiment,ranker-based
qe
system,section,rf-based
ranker
,
feature
,
variety
,
lexicon
translation
model
,
language
model,result,ranker-based
qe
system,state-of-the
art
qe
method
,
mrf
beat
,
significant
margin
,
simpler
system
,
text
translation
,
different
task
,
sm
component
,
regular
text
translation
,
expansion
term
,
de
tail
,
next
section
,
comparing
model
,
experiment
,
section
investi
gate
,
detail
,
effectiveness
,
different
model
,
lexicon
model
,
language
model
,
section
,
expansion
candidate
,
result
,
number
,
differ
ent
version,ranker-based
qe
system
,
version
,
candidate
generator
,
differ
,
fea
ture
class
,
subscript
,
ranker
,
discussion
,
result
,
lexicon
model
,
word
translation
model
,
section
,
word
model
,
term
correlation
model
,
training
method
,
comparison
,
experiment
,
word
model
,
correlation
model
,
initial
point
,
rezler
,
statisti
cal
translation
model
,
em
training
,
hidden
alignment
information
,
mapping
document
term
,
probability
distribution
,
result
,
hypothesis
,
notice
,
performs
tc
,
expansion
candi
date
,
word
translation
model
,
ranker
,
triplet
model
feature
,
formance
,
latter
,
sophisticated
system
,
result
,
smt
component
,
example
,
language
model
,
translation
,
word
model
,
triplet
model
,
word
model
,
contextual
information
,
latter
,
feature
,
ranker
,
little
improvement
,
ranker
,
triplet
model
feature
,
topic
model
,
word
model
,
triplet
model
,
bilingual
top
ic
model
,
different
set
,
expansion
term
,
lexi
con
model
,
result
,
combin
,
word
model
,
triplet
model
feature
,
bilingual
topic
model
feature
,
ranker
,
visible
improvement
,
nd
cg
,
position
,
qe
system
,
improvement
,
expansion
,
system
,
detail
,
several
interesting
finding
,
comparison
,
word
model
,
triplet
translation
model
,
effec
tive
,
long
query
,
que
ries
,
question
,
song
lyric
,
second
,
lexicon
model
,
bilingual
topic
model
,
expan
sion
,
entire
que
ry
,
individual
query
term
,
feature
,
expansion
term,entity,comparison,log-based
method
,
qe
method
,
automatic
relevance
feedback
,
com
munity
,
ir
performance
,
benchmark
datasets
,
lafferty
,
method
,
commercial
web
search
engine
,
rele
vant
document,pseudo-relevant
document
,
multi
phase
retrieval
,
automatic
relevance
feedback
,
method
share
,
simi
larities
,
example
,
parameter
,
qe
ranker
,
alethod
,
expansion
term
,
age
precision
,
mrf
model
,
previous
ly
,
relevance
feedback,pseudo-relevance
feedback
,
metzler
,
al
mrf
model
,
feature
,
ir
system
,
feature
,
statistical
translation
model
,
lafferty
,
al
xue
,
alveness
,
statistical
translation-based
approach
,
web
search
,
recent
study,phrase-based
translation
model
,
large
amount
,
construct
qe-oriented
transla
tion
model
,
capture
,
flexible
dependen
cies
,
addition
,
search
log
,
web
search
task
,
document
ranking
,
joachim
,
agichtein
,
al
search
query
processing
,
craswell
,
szummer
,
user
query
clustering,baeza-yates
,
tiberi
,
6
c
onclusions
,
previous
log-based
qe
method
,
direction
,
problem
,
source
language
,
target
language
,
document
,
technique
,
lexicon
model
,
triplet
,
user
query
,
clicked
document,ranker-based
qe
system
,
a
m
rf-based
ranker
,
lexicon
model
,
feature
,
experiment
,
web
search
task
,
real
world
data
set
,
posed
system
outperforms
,
state
of-the-art
qe
system,project,real-time
qe
system
,
web
search
,
simplicity
,
large
amount
,
clickthrough
data
,
model
training
,
simple
lexicon
model,state-of-the-art
qe
performance
,
ranker
,
flexible
framework
,
variety
,
feature
,
different
type
,
term
dependency
,
effective
way
,
web
search
performance
,
web
search
ranking
,
er
behavior
information
,
sig
ir
,
mod
ern
information
retrieval
,
semantic
relation
,
query
log
,
expansion
,
term
relationship
,
language
model
,
information
retrieval
,
ci
km
,
concept
importance
,
weighted
dependence
model
,
information
re
trieval
,
statistical
translation
,
sig
ir
,
recognition
,
ma
chine
learning
,
springer
,
mathematics
,
sta
tistical
machine
translation
,
good
expansion
term
,
pseudo
relevance
feedback
,
sig
ir
,
random
,
click
graph
,
sig
ir
,
query
log
,
knowledge
,
data
engineering
,
max
imum
likelihood
,
incomplete
data
,
em
algorithm
,
journal
,
royal
statistical
society
,
posterior
regularization
,
structured
latent
variable
model
,
journal
,
machine
learning
research
,
click
through-based
latent
semantic
model
,
web
search
,
sig
ir
,
clickthrough
,
translation
model
,
web
search
,
word
model
,
large
scale
ranker-based
system
,
correction
,
clickthrough
data
,
web
search
ranking
,
sig
ir
,
linear
discriminant
model
,
information
retrieval
,
lexicon
model
,
statis
tical
machine
translation
,
emn
lp
,
web
scale
language
model
,
search
query
processing
,
relevant
docu
ments
,
sig
ir
,
title
language
model
,
information
retrieval
,
association
thesaurus
,
information
retrieval
,
search
engine
,
clickthrough
data
,
statistical
phrase-based
translation
,
latent
concept
expansion
,
markov
random
field,relevance-based
language
model
,
sig
ir
,
improved
markov
random
field
model
,
verbose
query
,
markov
random
field
model
,
term
dependency
,
sig
ir
,
latent
concept
expansion
,
markov
random
field
,
irect
maximization
,
average
precision,hill-climbing
,
comparison
,
statistical
machine
translation,single-word
model
,
template
,
wordnet
hypernym
,
question
,
numerical
recipe
,
relevance
feedback
,
infor
mation
retrieval
,
sma
rt
retrieval
system
,
experiment
,
automatic
document
processing
,
snippet
,
query
expansion
,
col
ing
,
user
log
,
m
tois
,
expansion
,
global
document
analysis
,
retrieval
model,question,model-based
feedback,kl-divergence
retrieval
model
,
ci
km
,
method
,
language
model
,
ad
hoc
information
retrieval
,
sig
ir
,
proceeding
,
conference
,
empirical
method
,
association
,
computational
linguistics
modeling
interestingness
,
deep
neural
network
jianfeng
gao
,
patrick
pantel
,
michael
gamon
,
ppantel
,
mgamon
,
xiaohe
,
deng
microsoft
,
com
a
bstract
,
special
type
,
deep
neural
network
,
text
analysis
,
target
docu
ments
,
interest
,
source
document
,
signal
,
interestingness
,
click
transition
,
source
,
target
document
,
commercial
web
browser
log
,
million
,
web
transition
,
map
source-target
document
pair
,
vector
,
latent
space
,
distance
,
source
doc
uments
,
corresponding
,
target
,
ef
fectiveness
,
interestingness
task
,
automatic
highlighting,result,real-world
da
tasets
,
semantics
,
docu
ments
,
interest
ingness
,
icant
quality
improvement
,
classic
docu
ment
model,semantics,state-of-the-art
topic
model
,
1
i
ntroduction
task
,
interest
,
document
,
many
online
recommendation
system
,
recent
survey
,
deep
semantic
model
,
interestingness
task
,
document
semantics
,
crucial
role
,
automatic
highlight
ing
,
recommendation
system
,
person
,
location
,
organi
zation
,
interest
,
doc
ument
,
corresponding
text
span
,
keywords
afterwards
,
document
semantics
,
important
factor
,
interesting
,
example
,
article
,
article
,
character
,
keywords
,
entity
,
interest
,
system
,
interesting
document
,
supplementary
information
,
enti
tie
,
key
word
,
different
entity
,
interest
ing
supplementary
information
,
entity
,
many
peo
ple
,
singer
,
senator
,
article
,
paul
simon
,
content
,
concert
tour
,
first
context
,
article
,
family
,
notion
,
interestingness
,
notion
,
interestingness
,
deep
neural
network
,
speech
recogni
tion
,
hinton
,
computer
vision
,
krizhevsky
,
mar
koff
,
docu
ments
,
vector
,
latent
semantic
space
,
semantic
representation
,
neural
net
work
,
several
hidden
layer
,
spe
cial
convolutional-pooling
structure
,
keywords
,
extract
hidden
semantic
feature
,
different
level
,
abstraction
,
semantic
representation
,
deep
neural
network
,
training
,
back
propagation
,
respect
,
respective
interestingness
task
,
interest
,
signal
,
web
browser
transition
,
source
docu
ment
,
target
document
,
web
usage
log
,
commercial
browser
,
training
data
,
transition
,
interestingness
,
recent
success
,
deep
neural
network
,
markoff
,
speech
recognition
,
hinton
,
web
search
,
deep
neural
network
,
document
,
vec
tor
,
latent
semantic
space
,
relevance
,
tween
query
,
document
,
notion
,
interestingness
,
document
,
document
,
supplementary
information
,
entity
,
concept
,
document
,
overall
content
,
sec
ond
document
,
exam
ple
,
history
,
university
,
washington
,
president
obama
,
seattle
,
model
interestingness
,
significant
aspect
,
document
,
semantic
map
ping
,
document
,
sequence
,
prominent
key
word
,
keywords
,
entity
,
concept
,
interest
user,max-pooling
layer
,
deep
model,high-level
semantic
representation
,
whole
document
,
keywords
,
second
,
document
relevance
score
,
cosine
similarity
,
learned
semantic
space
,
semantic
representation
,
document
,
ranker
,
manner
,
result
,
document
,
document
,
distance
,
derived
feature
1
w
stress
,
click
signal
,
dataset
,
gold
standard
ranker
,
vector
,
high
score
,
inter
estingness
,
formation
,
entity
,
entity
,
subset
,
semantic
feature
,
corresponding
document
,
section
,
extension
,
significant
qual
ity
improvement
,
interestingness
task
,
formal
description
,
ds
sm
,
section
,
inter
estingness
function
,
data
set
,
interest
signal
,
notion
,
interestingness
let
,
document
,
inter
estingness
,
mapping
function
,
quantified
degree
,
interest
,
document
,
general
form
,
string
,
interestingness
function
,
document
structure
,
title
tag
,
hyperlink
,
web
interaction
data
,
document
,
plain
text
,
webpage
,
text
span
,
section
,
mani
festations
,
interestingness
,
ex
ample
,
twitter
,
frequent
sig
nal
,
webpage
,
hyperlink
,
user
click
,
hyperlink
,
anchor
,
modulo
case
,
erroneous
click
,
aggregate
click
,
interestingness
,
source
document
,
target
document
,
doc
uments
,
clicks1
,
s
ection
,
interestingness
,
access
,
document
structure
,
web
interaction
data
,
experiment
,
large
dataset
,
commercial
web
browser
,
specifi
,
occurrence
,
user
click
,
wikipedia
page
,
year
period
,
wikipedia
,
many
anchor
,
average
,
average
,
enough
traffic
,
transition
data2
,
transition
,
transition
,
section
,
task
specific
ranker
,
section
,
experiment
,
different
setting
,
interestingness
task
,
detailed
description,datasets,task-specific
datasets
,
section
,
section
,
architecture
,
ds
sm
,
parameter
estimation
,
hyperlink
,
xm
tag
,
document
,
highlighting
experiment
,
section
,
anchor
text
,
candidate
keywords
,
network
architecture
,
deep
neural
network
,
convolutional
structure,lower-case
bold
letter
,
column
vector,upper-case
letter
,
doc
ument
,
sequence
,
vec
tor
representation
,
input
layer
,
net
work
,
word
vector
,
word
vec
tor
,
word
vector,one-hot
vector
,
vo
cabulary
,
separate
tri-letter
vec
tor
,
word
boundary
symbol
,
nonzero
element
,
tri
letter
vector
,
word
vector,one-hot
vector,tri-letter
vector,tri-letter
vector,one-hot
vector
representation
,
aspect
,
different
oov,vocabulary,tri-letter
vector
,
colli
sion,second,variation,tri-letter
space
,
number
,
unique
english
word
,
total
number
,
distinct
tri
letter
,
english
,
frequent
30k
,
result
,
incorpo
rating
tri-letter
vector
,
representation
power
,
word
vector
,
input
layer
,
word
vector
,
text
span
,
high
degree,relevance,task-specific
heuristic
,
section
,
word
vec
tor
,
vector
,
summation
,
word
vector
,
figure
,
length
,
document
,
con
textual
information
,
plain
text,white-space
,
number
,
stem
ming
,
english
wikipedia
dump
con
sisting
,
article
,
wiki
medium
,
illustration
,
network
architec
ture
,
information
flow
,
corresponding
task
,
convolutional
layer
,
local
feature
,
word
sequence
,
length
,
contextual
vector
,
word
vector
,
surrounding
word
,
window
,
window
size
,
local
feature
vector
,
tanh
activation
function
,
window
,
word
se
quence
,
output
,
number
,
word
se
quence
,
local
feature
vector
,
global
feature
vector
,
fixed
size
,
document
length
,
subsequent
standard
affine
layer
,
design
,
max
operation
,
sequence
,
vector
,
network
,
invariant
local
feature
,
max
operation
,
di
mension,max-pooling
layer
,
prominent
keywords
,
docu
ment
,
procedure
,
figure
,
toy
example
,
convolu
tional
layer
,
word
document,4-dimensional
local
feature
vec
tor
,
distribution
,
example
,
prominent
topic
,
word
context
window
,
first
topic
,
prominent
topic
,
global
feature
vector
,
topic
distribution
,
whole
docu
ment
,
promi
nent
topic
,
prominent
topic
,
local
feature
vector
,
corresponding
word
,
local
feature
vector
,
keywords
,
document
,
f
igure
,
present
,
sample
,
document
snip
pet
,
keywords
,
procedure
,
figure
,
many
name
,
keywords
,
global
feature
vector
,
several
standard
affine
network
layer
,
nonlinear
activation
function,non-linear
feature
,
output
layer
,
linear
projection
matri-ces
,
parameter
,
fig
ure,pair-wise
rank
loss
,
source
document
,
candidate
target
document
,
construct
,
u1
u2
u3
u4
u5
w1
w2
w3
,
w1
w2
w3
w4
,
1
f
igure
,
toy
example,5-word
document
,
local
feature
vector
,
convolutional
layer
,
global
feature
vector,document,max-pooling
,
interestingness
score
,
difference
,
interestingness
score
,
interestingness
score
,
feature
vector
,
ds
sm
,
document
,
hid
den
interestingness
space
,
similarity
,
document
,
interesting
document
,
following
logistic
loss
,
experiment
,
result
,
negative
training
example
,
training
,
alternative
approach
,
loss
function
,
hinge
loss
,
cosine
similarity
function
,
scaling
factor
,
magnifies
,
dif
ference
,
exper
iments
,
loss
function
,
model
parameter,gradient-based
method
,
space
limitation
,
derivation
,
gradient
,
loss
function
,
reader
,
related
derivation
,
experiment
,
dss
m,mini-batch
stochastic
gradient
descent,mini-batch
,
source-target
docu
ment
pair
,
source
document
,
target
docu
ments
,
negative
training
samples3
,
dss
trainer
,
a
g
pu-accelerated
linear
algebra
li
brary
,
training
,
a
d
ssm
,
figure
,
principle
,
loss
function
,
clear
empirical
advantage
,
simpler
early
stop
approach
,
pilot
study
,
latter
,
experiment
,
ap
proach
,
course
,
model
training
,
entire
training
data
,
learning
rate
,
validation
data,held-out
,
tr
ain
_
,
training
,
experiment
,
ds
sm
,
converges
,
interestingness
task
,
ds
sm
,
feature
generator
,
output
layer
,
semantic
fea
tures
,
boosted
tree
,
partition
function
,
noise
contra
tive
estimation
,
gutmann
,
hyvarinen
,
future
work
,
comedy
,
comedy
art
festival
,
comedy
,
la
vega
,
inception
,
wheeler
opera
house
,
aspen
colorado
,
primary
sponsor,festival,co-sponsorship
,
caesar
palace
,
primary
venue
tb
geico
insurance
twix
candy
bar
,
smirnoff
vodka
hbo
,
festival
business
,
pri
mary
,
festival
,
standup
comedy
performance
appearance
,
television
show
,
american
comedy
series
,
walt
becker
,
ross
putman
,
netflix
,
char
acters
,
community
service
parole
group
,
parole
officer
brian
kubach
,
jake
gibson
,
aspiring
professional
starcraft
player
,
com
munity
service
,
forest
fire
,
breakup
,
community
service
,
bition
,
pro
fessional
gamer
,
mark
zuckerberg
,
sample
,
document
snippet,keywords,ranker,friedman,task-specific
data
,
feature
,
output
layer
,
direct
imple
mentation
,
section
,
model
training
,
interestingness
score
,
document
pair
,
cosine
similarity
,
feature
vector
,
runtime
,
4
e
xperiments
,
recall
,
section
,
system
,
interesting
keywords
,
doc
ument
,
mod
el
,
click
transition
data
,
sec
tion
,
anchor
,
source
document
,
candidate
keywords
,
terest
,
document
,
anchor
,
figure
,
ds
sm
,
specific
task
,
source
,
target
document
,
anchor
text
,
performance
,
highlighting
system
,
gold
standard
interestingness
function
,
interestingness
,
anchor
,
number
,
user
click
,
anchor
,
ideal
se
lection
,
interesting
anchor
,
jarvelin
,
kekalainen
,
eva
dataset
,
section
,
transition
distribution
,
test
set
,
stratified
sampling
methodol
ogy
,
ir
community
,
source
page
,
unique
source
docu
ments
,
frequency
,
occurrence
,
transition
,
source
page
,
transition
,
transition
,
bottom
,
transition
,
corre
sponds
,
transition
,
main
result
table
,
result
,
various
model
,
test
set
,
truncation
level
,
simple
heuristic
baseline
,
and
selects
,
random
anchor
,
selects
,
anchor
,
anchor
,
ranker
,
tra
in_2
,
section,feature,ranker,non-semantic
feature
,
feature
,
1
r
and
,
4
n
sf
,
interest
model
,
ta
il
test
set
,
statistical
significance,non-shaded
result
,
source
document
,
user
session
infor
mation
,
browser
log
,
document
,
position
,
anchor
,
document
,
frequency
,
anchor
,
anchor
density
,
paragraph
,
semantic
feature
,
source
,
target
document
,
browsing
transition
,
semantic
feature
,
dif
ferent
source
,
first
feature
source
,
output
layer
,
feature
generator
,
section
,
section
,
dss
m_bow
,
document,max-pooling
layer
,
source
,
semantic
feature
,
comparison
,
generative
semantic
model
,
joint
transi
tion
topic
model
,
lda
style
model
,
source
,
target
document
,
transition
,
feature
,
latent
variable
,
source
topic
model
,
target
topic
model
,
transition
model
,
seman
tic
model
,
contrast
,
effectiveness
,
human
model
er
,
effect
,
editor
,
wikipedia
,
semantic
feature
,
feature
number
,
multiple
thousand
,
feature
,
viable
solution
,
wikipedia
catego
ries
,
document
,
comparison
,
ds
sm
,
learned
ranker
,
feature
,
source
,
document
,
feature
,
source
,
target
,
src
tar
,
document
,
task
setting
,
access
,
content
,
source
,
target
document
,
practical
scenario
,
system
,
target
doc
ument
,
extra
step
,
suit
able
target
document
,
candidate
concept
,
entity
,
interest
,
analysis
,
result
,
performing
system
,
test
set
,
weak
baseline
score
,
reason
,
large
average
number
,
candidate
,
average
,
anchor
,
to
rso
,
average
number
,
anchor
,
unique
target
,
unique
target
,
semantics
,
document
,
important
signal
,
performance
,
interesting
comparison
,
semantics
,
deep
se
mantic
model
,
generative
topic
model
,
learned
dss
,
feature
,
thousand
,
feature
,
editor
,
wikipedia
category
feature
,
contrast
,
feature
,
perform
,
scenario
,
feature
,
mantic
feature
,
perfor
mance
,
fea
tures
,
source
,
target
document
,
scenario
,
manual
semantics
,
wca
outperform
,
diminish
ing
effect
,
to
rso
,
performing
,
result
,
modification
,
section
,
ds
sm_bow
,
network
struc
ture,benefit,max-pooling
layer
,
se
mantic
feature
,
highlighting
task
,
several
experiment
,
co
sine
score
,
output
layer
,
feature
,
procedure
,
section
,
direct
imple
mentation
,
cosine
,
feature
,
im
provement
,
cosine
,
semantic
feature
,
output
,
improvement
,
feature
,
ranker
,
interestingness
score
,
cosine
similarity
,
learned
semantic
space
,
5
e
xperiments
,
entity
search
,
evaluation
data
set
,
sec
ond
task,document,traffic-weighted
set
,
web
document
,
second
step,entity,document,in-house
,
entity
recog
nizer
,
entity
name
,
commercial
search
engine,top-100
retrieved
document
,
candidate
target
document
,
entity
,
source
doc
ument
,
entity
text,200-word
window
,
figure
,
entity
text
,
final
evaluation
data
set
,
source
document
,
average
,
source
docu
ment
,
target
document,source-target
document
pair,interestingness,annotator,5-level
scale
,
target
document
,
source
document
,
target
,
interest
,
scenario
,
ranking
scenario
,
interesting
docu
ments
,
document
,
terestingness
score
,
performance
,
truncation
level
,
sec
ond
scenario
,
interesting
result
,
scenario
,
target
docu
ments
,
interestingness
score
,
predefined
threshold
,
scenario
,
roc
analysis
,
area
un
der
,
main
result
,
main
result
,
single
model
result
,
direct
implementation
,
ranker
result
,
ranker
,
different
set
,
feature
,
source
,
target
document
,
includ
,
feature
,
single
model
,
highlighting
experiment
,
machine
,
single
model
,
tra
in_1
,
ranker
,
tra
in_2
,
analysis
,
result
bm
,
classic
document
model,robertson,zaragoza,bag-of-words
document
representation
,
bm25
term
,
function
,
set
ting
,
interestingness
score
,
doc
ument
pair
,
dot
product
,
term
vector
,
importance
,
contextual
information
,
different
way
,
term
vector
,
source
document
,
entity
text
,
entity
text
,
entire
source
document
,
formation
,
therefore
,
section
,
entity
text
,
implementation
,
word
translation
model
,
berger
,
laf
ferty
,
auc
1
b
m25
,
entity
,
2
b
m25
,
3
w
tm
,
4
b
ltm
,
5
d
ssm
,
6
d
ssm_bow
,
7
b
aseline
ranker
,
sta
tistical
significance,non-shaded
single
model
result
,
statistical
significance
,
re
sults
,
statistical
signifi
cance
,
result
,
unigram
probability,probability,source-target
docu-ment
pair,translation-based
approach
,
related
word
,
nonzero
,
result
,
performing
bilingual
topic
model,extension,hofmann,source-target
doc
ument
pair
,
em
algorithm
,
con
straint
,
source
document
,
document
,
prior
topic
distribution
,
similar
frac
tions
,
interestingness
score
,
following
story
,
word
dis
tribution
,
a
d
irichlet
,
topic
distribution
,
a
d
irichlet
,
blt
model
interestingness
,
account
,
semantic
topic
distribution
,
entire
docu
ments
,
result
,
outperforms
,
significant
margin
,
single
model,state-of-the-art
topic
model
blt
,
difference
,
tween
dss
,
detail
,
semantic
representa
tion
,
document
,
different
modeling
approach
,
nature
,
generative
model
,
semantic
representation
,
distribution
,
hidden
semantic
topic
,
dis
tribution
,
maximum
likelihood
estimation,log-likelihood
,
source-target
document
pair
,
training
data
,
document
,
hidden
semantic
space
,
paired
document
,
latent
space
,
unpaired
one
,
superior
performance
,
model
parameter
,
objective
,
interestingness
task
,
addition
,
difference
,
meth
od
,
different
model
structure
,
document
,
important
contextual
,
formation
,
word
order,inter-word
,
pendencies
,
semantic
representa
tions
,
document
,
sequence
,
capture
,
global
con
text,non-linear
semantic
feature
,
deep
neural
network
,
analysis
,
result
,
variant
,
dss
m_bow
,
convolution,max-pooling
layer
,
document
,
result
,
strate
,
effectiveness
,
convolutional
architecture
,
neural
network
,
addition
,
ranker
result
,
baseline
ranker
,
feature
,
many
count
,
single
model
score
,
perfor
mance
,
baseline
ranker,non-dssm
fea
tures
,
dss
score
,
single
feature
,
ranker
,
significant
improvement
,
combination
,
dss
feature
vector
,
source
,
feature
,
automatic
highlighting
,
contextual
entity
search
,
feature
,
output
layer
,
deep
semantic
model
result
,
significant
gain,non-semantic
feature
,
compari
son
,
semantic
model
,
addition
,
notion
,
relevance
,
section
,
interestingness
,
notion
,
salience
,
parajpe
,
alience
,
centrality
,
content
,
document
,
salience
,
interesting
ness
interact
,
exam
ple
,
news
article
,
president
obama
,
seattle
,
average
user
,
article
,
many
system
,
popular
content
,
lerman
,
huberman
,
highlighting
task
,
contrast
,
approach
,
reading
content
,
popular
content
,
current
docu
ment
,
popularity
,
ra
ther
poor
predictor
,
interestingness
,
contextual
entity
search
,
information
retrieval
problem
,
research
,
entity
resolution
,
stefanidis
,
l
atent
semantic
analysis
,
deerwester
,
semantic
model
de,hofmann,cross-lingual
case
,
document
,
different
language
,
deep
architecture
,
deep
learning
technique
,
hidden
structure
,
associ
,
feature
,
different
level
,
abstraction
use
ful
,
variety
,
hinton
,
socher
,
salakhutdinov
,
origi
nal
approach
,
unsupervised
version
,
deep
neural
network
,
hierar
chical
semantic
structure
,
document
,
approach
,
deep
neural
network,large-scale
query-document
pair
,
performance
,
convolutional
neural
network
,
text
pro
cessing
,
collobert
,
different
application
,
dss
described
,
section
,
variant
,
deep
neural
network
model
,
previous
study
,
7
c
onclusions
,
interestingness
,
many
online
recommendation
system
,
natu
rally
,
interest
signal
,
web
browsing
transition
,
webpage
,
interestingness
,
deep
neural
network
,
special
convolutional-pooling
structure,source-target
document
pair
,
vector
,
latent
semantic
space
,
ds
sm
,
transition
,
docu
ments
,
effectiveness
,
interestingness
task
,
auto
matic
highlighting,real-world
datasets
,
semantics
,
document
,
interest
ingness
,
new
model
,
cant
improvement
,
classic
document
mod
el
,
latent
,
semantics
,
state
of-the-art
topic
model
,
convolutional
architecture
,
future
work
,
method
,
interestingness
,
entire
user
session
,
sequence
,
prior
brow
,
interaction
history
,
session
,
additional
signal
,
interest
ingness
,
signal
,
causal
relation
,
consequence
,
ac
tions
,
effective
model
,
purpose
,
architecture
,
recurrent
neural
network
,
deep
semantic
model
,
dditional
author
,
microsoft
research
,
microsoft
way
,
yeshen
,
author
,
johnson
apacible
,
pradeep
chilakamarri
,
edward
guo,ye-yi
wang
,
guidance
,
valuable
dis
cussions
,
anonymous
re
viewer
,
comment
,
huberman
,
social
medium
,
forecasting
popularity
,
icw
sm
,
deep
architecture
,
fundamental
trend
,
machine
learning
,
information
re
trieval
,
statistical
translation
,
sig
ir
,
journal
,
semantic
approach
,
tual
advertising
,
mathematics
,
statistical
machine
translation
,
parameter
,
mation
,
computational
linguistics
,
hamilton
,
gradient
descent
,
ic
ml,primal-dual
method
,
recurrent
neural
network
con,echo-state
property
,
natural
language
processing
,
machine
learning
research
,
latent
semantic
analysis
,
journal
,
american
society
,
information
science
,
deep
neural
network
,
speech
recognition
,
related
application
,
overview
,
deep
convolutional
neural
network
,
trading
acoustic
invari
ance
,
phonetic
confusion
,
automatic
cross-linguis
tic
information
retrieval
,
latent
semantic
indexing
,
greedy
function
approxi
mation
,
gradient
,
machine
,
annals
,
statistic
,
interesting
thing
,
salient
entity
,
web
page
,
clickthrough
,
translation
model
,
web
search
,
word
model
,
continuous
phrase
representation
,
translation
modeling
,
click
through-based
latent
semantic
model
,
web
search
,
sig
ir
,
g
raf
,
deep
recurrent
neural
network,noise-con
trastive
estimation
,
new
estimation
principle
,
unnormalized
statistical
model
,
artificial
intelligence
,
statis
tic
,
stats2
,
acoustic
modeling
,
discov
,
binary
code
,
document
,
deep
generative
model
,
cognitive
science
,
probabilistic
latent
semantic
indexing
,
sig
ir
,
deep
structured
se
mantic
model
,
web
search
,
tion
method
,
relevant
doc
uments
,
sig
ir
,
imagenet
classification
,
deep
convo
lutional
neural
network
,
social
dynamic
,
popularity
,
computer
,
recurrent
neural
network
,
language
model
,
document
aboutness
,
implicit
user
feedback
,
document
structure
,
discriminative
projection
,
emn
lp
,
proba
bilistic
relevance
framework
,
foundation
,
latent
semantic
model
,
convolu
tional-pooling
structure
,
information
re
trieval
,
recursive
matrix-vector
space
,
entity
resolution
,
huberman
,
popularity
,
online
content
,
communica
tions
,
information
re
trieval
measure
,
journal
,
information
re
trieval
,
advertising
keywords
,
web
page
,
discriminative
projection
,
text
similarity
measure
,
con
ll
,
proceeding
,
naa
cl-hlt
,
atlanta
,
georgia
,
association
,
computational
linguistics
training
mrf
,
phrase
translation
model
,
jfgao
microsoft
,
com
x
,
xiaohe
microsoft
,
com
a
bstract
,
statistical
framework
,
phrase
translation
,
markov
random
field
,
model
al
low
,
arbituary
feature
,
phrase
pair,evidence,large-scale
discriminative
training
approach
,
stochastic
gradi
ent
ascent,n-best
list
,
bl
eu
,
objective
function
,
standard
phrase-based
statistical
machine
translation
system
,
code
change
,
runtime
engine
,
evaluation
,
europarl
translation
task
,
german
english
,
markov
random
field
model
,
perfor
mance,state-of-the-art
phrase-based
machine
translation
system
,
1
i
ntroduction
,
phrase
translation
model
,
phrase
table
,
core
component
,
system
,
common
method
,
phrase
table,two-phase
approach
,
bilingual
phrase
pair
,
extracted
heuristical
ly,word-aligned
training
da
,
second
phase
,
parameter
estimation
,
phrase
pair,counting,phrase,word-aligned
train
,
research
,
quality
,
phrase
table
,
princi
,
method
,
banchs
,
denero
,
parameter
estima
tion
phase
,
problem
,
phrase
translation
pair
,
new
phrase
translation
model
,
primary
concern
,
phrase
translation
pair
,
function
,
phrase
translation
probability
,
lexical
weight
,
statistical
framework
,
arbitrary
feature
,
phrase
pair
,
translation
,
unified
way
,
a
m
rf
model
,
s
econd
,
phrase
model
,
component
model
,
smt
system
,
good
translation
,
quality
,
translation
,
ble
score
,
parameter
,
phrase
model
,
component
model
,
respect
,
objective
function,evaluation,consideration,large-scale
discriminative
training
approach
,
pioneering
work
,
method
,
handful
,
feature
,
small
training
set
,
mer
method
,
development
,
discriminative
training
method
,
million
,
fea
tures
,
million
,
sentence
pair
,
ongo
ing
area
,
research
,
recent
survey
,
stochastic
gradient
ascent,n-best
list
,
objective
function
,
large
scale
discriminative
training
,
significant
improvement
,
primary
concern
,
adop
tion,method,well-established
learning
method
,
result
,
feature
,
mrf
model
,
format
,
traditional
phrase
table
,
stand
ard
phrase-based
smt
system
,
code
change
,
section
,
mr
model
,
phrase
translation
,
section
,
model
parameter
,
experimental
result
,
europarl
translation
task
,
section
,
review
,
vious
work
,
foundation
,
ection
,
traditional
translation
model
,
directional
model
,
conditional
probability,noisy-channel
model
,
bayes
rule
,
conditioning
,
translation
probability
,
source
,
sentence
,
english
,
target
,
translation
,
h
owever,practice,implementation,state-of-the-art
phrase-based
smt
system
,
weighted
log-linear
combination
,
several
model
,
logarithm
,
phrase
probability
,
lexical
weight,source-to
target,target-to-source
direction
,
argmax
,
hidden
structure
,
derives
,
viterbi
derivation
afterwards,phrase-based
smt
,
segmentation
,
source
sentence
,
phrase
,
segmentation
,
target
sentence
,
phrase
,
alignment
,
source
,
target
phrase
,
directional
translation
model
,
mrf
model,spirit,bi-directional
translation
proba
bilities,log-linear
framework
,
agreement
,
compatibility
,
phrase
pair
,
translation
quality
,
directional
translation
probability
,
imagined
generative
story
,
mrf
mr
f
,
undirected
graphical
model
,
joint
distribution
,
contextual
dependency
,
physical
phe
nomena
,
bishop
,
graph
represent
random
variable
,
independence
semantics
,
random
variable
,
markov
property,non-neighbors
,
clique
configura
tions
,
phrase
translation
pair
,
phrase
node
,
word
node
,
se
phrase
,
figure
,
clique
,
variable
,
clique
,
joint
distribution
,
random
variable,clique,non-negative
potential
function
,
clique
,
compatibility
,
var
iables
,
parameter
,
potential
function
,
partition
function
,
malization
constant
,
major
limitation
,
exponential
number
,
summa
tion
,
global
con
stant
,
phrase
translation
hypothesis
,
decoder
,
smt
system
,
hypothesis
,
unnormalized
joint
probability
,
implementa
tion
,
phrase
table
,
translation
pair
,
unnormalized
probability
,
mrf
potential
function
,
exponential
form,real-valued
feature
function
,
clique
,
weight
,
feature
function,phrase-based
smt
system,sentence-level
translation
probability
,
product
,
phrase
translation
probability
,
phrase
segmentation
,
distortion
model
component
,
viterbi
derivation
,50
th
annual
meeting
,
association
,
computational
linguistics
,
republic
,
association
,
computational
linguistics
maximum
expected
ble
u
tr
aining
,
phrase
,
lexicon
translation
model
x
,
li
deng
microsoft
research
microsoft
research
one
microsoft
way
,
xiaohe
microsoft
,
com
deng
microsoft
,
com
a
bstract
,
new
discriminative
training
method
,
phrase
,
lexicon
translation
model
,
myriad
,
parameter
,
ble
score-based
utility
function
,
kl
regularization
,
objective
,
large
parallel
dataset
,
training
,
growth
transformation
,
phrase
,
lexicon
translation
probability
,
objective
,
method
,
europarl
german-to-english
dataset,state-of-the-art
baseline
translation
system
,
iws
lt,benchmark,system,method,chinese-to-english
translation
result
,
ted
talk
,
active
area,blunsom,chiang,foster,log-linear
model
,
multiple
feature
,
translation
,
method
,
feature
weight,log-linear
model
,
phrase
,
lexicon
translation
feature
,
important
component
,
generative
model
,
heuristic
,
parameter
,
phrase
,
lexicon
translation
model
,
relative
frequency
,
joint
likelihood
,
parameter
,
objective
,
quality
,
large
number
,
parameter
,
discriminative
training
,
chiang
,
large
set,part-of-speech
feature
,
model
weight
,
feature
,
perceptron
,
reference
translation
,
empirical
local
updating
strategy
,
problem
,
pseudo
reference
,
many
non-desirable
heuristic
,
chiang
,
syntactic
smt
system
,
syntactic
feature
,
margin
,
feature
weight
,
number
,
parameter
,
common
phrase
,
lexicon
translation
model
,
effective
discriminative
learning
method
,
phrase
,
lexicon
translation
model
,
training
objective
,
expected
ble
score
,
translation
quality
,
a
k
ullback
,
divergence
regularization,over-fitting
,
effective
optimization
,
formula
,
phrase
,
lexicon
translation
probability
,
transformation
,
probability
,
strict
non-decrease
,
objective
,
gt
iteration
,
local
maximum
,
similar
gt
technique
,
speech
recognition
,
gopalakrishnan
,
large
scale
discriminative
training
,
smt
model,phrase-based
smt
system
,
experiment
,
europarl
german-to-english
dataset
show
,
method
,
strong
baseline
,
method
,
iws
lt
,
benchmark
test
set
,
ted
talk,open-domain
spoken
language
translation
task
show
,
method
,
significant
translation
performance
improvement,state-of-the-art
baseline
,
system
,
method
,
single
system
translation
result,chinese-to-english
mt
track
,
approach
,
discriminative
training
,
multiple
feature
,
generative
model,log-linear
model
,
relative
weight
,
small
tuning
set
,
practice
,
approach
,
handful
,
parameter
,
large
set,part-of-speech
feature
,
addition
,
phrase
translation
model
,
weight
,
feature
,
perceptron
,
training
set
,
67k
sentence
,
author
,
towards
,
reference
translation
,
hidden
structure
,
phrase
segmentation
,
alignment
,
system
,
reference
translation
,
parameter
update
,
bold
updating
,
author
,
local
updating
strategy
,
model
parameter,hypothesis,n-best
list
,
approach
,
baseline
,
monotonic
decoding
,
significant
gain,baseline,full-distortion
model
,
expectation
,
ble
score
,
objective
,
heuristic
,
updating
reference
,
principal
way
,
chiang
,
syntactic
feature
,
addition
,
baseline
feature
,
feature
weight
,
tuning
,
sentence
,
parameter
,
training
,
entire
training
corpus
,
optimization
algorithm
,
efficient
,
large
scale
discriminative
training
,
related
work
,
ble
score
,
objective
,
system
combination
parameter
,
computation
,
minimum
bayes
risk
approach,eisner,tromble,lattice-based
mer
,
macherey
,
phrase
,
lexicon
translation
model
,
research
,
phrase
table
refinement
,
pruning
,
wuebker
,
method
,
phrase
translation
model,expectation-maximization
algorithm,leave-one-out
strategy
,
parallel
sentence
,
phrase
level
,
phrase
table
,
feature
,
decoding
process
,
phrase
translation
probability
,
phrase
alignment
,
overfitting
,
statistic
,
phrase
pair
,
particular
sentence
,
phrase
table
,
sentence
,
problem
,
bold
updating
,
alignment
,
source
sentence
,
reference
translation,alignment,method,problem,phrase-based
translation
system
,
translation
process,phrase-based
smt
,
segment
source
sentence
,
sequence
,
phrase
,
source
phrase
,
target
phrase,re-order
target
phrase
,
target
sentence
,
decoding
,
optimal
translation
,
source
sentence
,
normalization
denominator
,
probability
,
feature
function
,
log
domain
,
notation
,
later
section,feature,phrase-based
system
,
phrase
count
,
phrase
,
lexicon
translation
model
,
phrase
,
lexicon
translation
model
,
phrase
translation
model
set
,
phrase
pair,word-aligned
parallel
corpus
,
extraction
rule
,
relative
frequency
,
phrase
,
probability
,
source
phrase
,
target
phrase
,
joint
count
,
marginal
count
,
input
sentence
,
phrase
,
translation
feature,k-th
phrase,target-to-source
,
backward
,
phrase
translation
model
,
lexicon
translation
model
,
several
variation
,
lexicon
translation
feature
,
word
translation
table
,
possible
word
alignment
,
phrase
pair,length,m-th
word,r-th
word
,
probability
,
probability
,
joint
likelihood
,
source
,
target
sentence,target-to-source
,
backward
,
lexicon
translation
model
,
objective
function
,
parameter
,
forward
phrase
,
lexicon
translation
probability
,
backward
counterpart
,
simplification
,
matrix
,
element
,
probability
,
probability
distribution
,
utility
function
,
entire
training
set
,
number
,
sentence
,
training
,
reference
translation
,
translation
hypothesis
,
sentence
,
joint
posterior
,
subscript
,
parameter
,
factor
,
sentence
ble
score
,
entire
training,algebra,phrase-based
smt
system
,
total
number
,
parameter
,
phrase
,
lexicon
translation
model
,
regularization
,
parameter
,
distance
,
probability
distribution
,
whole
parameter
,
kl
regularization
,
kl
divergence
,
constant
prior
parameter
,
training
,
utility
function
,
change
,
parameter
,
minimum
,
objective
function
,
prior
model,approach,relative-frequency-based
phrase
translation
model
,
degree
,
regularization
,
optimization
,
section
,
gt
formula,parameter,gopalakrishnan,baum-welch
algorithm
baum-eagon
inequality
,
gt
formula,positive-coefficient
polynomial
,
random
variable,sum-to-one
constant,baum-welch
algorithm
,
model
update
algorithm
,
hidden
markov
model
,
algorithm
,
polynomial
,
review
ebw
,
random
variable
,
constraint
,
positive
polynomial
function
,
previous
iteration
,
guarantee
,
increase
,
derive
gt
formula
,
smoothing
factor
,
translation
model
,
translation
model
,
drop
optimization
irrelevant
term
,
kl
regularization
,
positive
polynomial
,
gt
formula
,
probability
,
source
phrase
,
target
phrase
,
updating
formula
,
derivation
,
expected
ble
score,sentence,k-th
phrase
,
smoothing
factor
set,baum-eagon
inequality
,
practical
use
,
practice
,
general
guide,denominator,low-bound
,
numerator
,
probability
,
source
word
,
target
word
,
derivation
,
updating
formula,m-th
word,k-th
phrase
,
source
sentence
,
backward
phrase
,
lexicon
translation
model
,
similar
way
,
implementation
issue
,
formula
,
decoding
,
relative
value
,
matter
,
absolute
value
,
large
absolute
value
,
sharp
posterior
distribution
,
sharpness
,
posterior
distribution
,
sentence
ble
,
ble
u-4
score
,
updating
formula
,
sentence
level
,
raw
precision
,
prior
value
,
smoothing
factor
,
key
role,sentence-level
ble
u1
,
factor
,
total
length
,
reference
,
training
,
baseline
output2,chiang,per-sentence
bp,corpus-level
ble
computation,training,n-gram
match
,
baseline
output
,
training
procedure
,
parameter
,
training
,
feature
weight
,
small
tuning
set3
,
training
,
iteration
,
training
,
training
process
,
validation
,
stop
point
,
training
,
validation
,
test
set
,
summary
,
training
procedure
,
multiple
processor
,
f
igure
,
method
,
separate
datasets
,
experiment
,
europarl
dataset
,
experiment
,
recent
iws
lt-2011
task
,
federico
,
experimental
setup
,
europarl
task
,
method
,
separate
datasets
,
experiment
,
europarl
german-to-english
dataset
,
training
corpus
,
sentence
pair
,
sentence
,
average
,
sentence
,
development
set
,
sentence
,
tuning
,
validation
,
test
set
,
sentence
,
tuning
set
,
test
condition
,
baseline
phrase-based
smt
system
,
word
alignment
,
training
,
hidden
markov
model
,
lexicalized
distortion
,
phrase
table
,
bilingual
text
,
maximum
phrase
length
,
baseline
system
,
ordering
model
,
word
count
,
phrase
count,3-gram
lm
,
english
side
,
parallel
training
corpus
,
feature
weight
,
fast
beam-search
phrase-based
decoder
,
distortion
limit
,
detail
,
phrase
,
lexicon
translation
model
,
baseline
,
a
b
leu
score
,
test
set
,
baseline
system,100-best
list
,
training
corpus
,
maximum
,
ble
training
,
t
ranslation
model
parameter
phrase
model
,
summary
,
phrase
,
lexicon
translation
model
,
experimental
result
,
europarl
task
,
training
,
regularization
factor
,
performance
,
validation
set
,
simplicity
reason
,
tuning
,
phrase
translation
model
,
report
,
ble
score
,
baseline
,
different
value
,
result
,
importance
,
regularization
,
validation
set
,
regularization
,
optimal
value
,
experiment
,
t
est
,
regularization
,
result
,
degree
,
validation
,
optimal
regularization
factor
,
relationship
,
baseline
system
,
decode
n-best
list
,
corpus
,
baseline
system
,
training
,
iteration
,
tuning
,
validation
,
training
converges
,
certain
number,validation,sentence-level
ble,n-best
list,corpus-level
ble
score,1-best
translation
,
conjectured
close
relationship
,
training
objective
,
training
,
training
iteration
,
different
iteration
,
ble
score
correlate
,
real
ble
score
,
training
objective
,
f
igure
,
sentence
ble,1-best
corpus
ble
,
sentence
,
effect
,
phrase
translation
probability
,
lexicon
translation
probability
,
gt
formula
,
preceding
section,break-down
result
,
baseline
,
phrase
,
lexicon
model
,
test
set
,
full
training
,
phrase
,
lexicon
model
,
learning
schedule,iteration,two-stage
,
phrase
model
,
validation
set
,
lexicon
model
,
schedule
,
significant
improvement
,
baseline
,
phrase
,
lexicon
model,two-stage
training,result,baseline,detail,two-stage
training
,
ble
score
,
function
,
gt
training
iteration
,
phrase
translation
probability
,
first
stage
,
blue
color
,
iteration
,
ble
score
,
validation
set
,
peak
value
,
iteration
,
ble
score
fluctuation
,
sixth
iteration
,
ble
score
,
red
color
,
ble
score
,
iteration
,
lexicon
model,iteration,two-stage
gt
training
,
phrase
,
lexicon
model
,
b
leu
,
validation
test
baseline
,
train
phrase
model
,
train
lexicon
model
,
result
,
europarl
german-to-english
dataset
,
ble
measure
,
various
setting
,
maximum
,
ble
training
,
baseline
,
baseline
,
significance
level
,
paired
bootstrap
,
method
,
f
igure
,
validation
,
function
,
gt
training
iteration,two-stage
training
,
phrase
translation
model
,
lexicon
model
,
phrase
model
,
lexicon
model
,
bl
eu
bl
eu
b
leu
iteration
,
iws
lt2011
benchmark
,
second
evaluation
task
,
new
method
,
iws
lt
chinese-to-english
machine
translation
benchmark
,
federico
,
main
focus
,
iws
lt2011
evaluation
,
translation
,
ted
talk,english,chinese-to-english
translation
task
,
chinese
text
,
punctuation
,
english
speech,punctuation,open-domain
spoken
language
translation
task
,
training
data
consist
,
sentence
,
transcript
,
ted
talk
,
translation
,
english
,
chinese
,
sentence
,
average
,
development
set
,
dev2010
,
tst2010
,
sentence
,
sentence
,
dev2010
,
tuning
,
tst2010
,
validation
,
tst2011
,
sentence
,
system
,
primary
phrase
table
,
ted
parallel
training
data,3-gram
lm
,
english
side
,
parallel
data
,
additional
out-of-domain
data
,
potential
usage
,
secondary
5-gram
lm
,
sentence
,
supplementary
english
data
,
secondary
phrase
table
,
sentence
,
supplementary
un
corpus
,
method
,
axelrod
,
maximum
,
ble
training,100-best
list
,
regularization
factor
,
optimal
value
,
parameter
,
primary
phrase
table
,
secondary
phrase
table
,
training
process,out-of-domain
phrase
table
,
ted
translation
task
,
large
lm,n-best
generation
process
,
final
mer
,
relative
weight
,
feature
,
secondary
phrase
table
,
translation
result,baseline,phrase-based
system
,
feature
,
secondary
phrase
table
,
new
system
,
feature
,
primary
phrase
table
,
gt
optimization,result,two-stage
training
schedule
,
iteration
,
phrase
translation
model
,
iteration
,
lexicon
translation
model
,
result
,
method
,
improvement
,
baseline
,
single
system
result
,
bl
eu
,
translation
result
,
iws
lt
,
mt
_
ce
task,summary,contribution,training,large-scale
translation
model
,
phrase
,
lexicon
model
,
parameter
,
previous
method
,
objective
function
,
utility
function
,
ble
score
,
regularization
term
,
kl
divergence
,
parameter
space
,
expected
ble
score
,
translation
quality
,
regularization
,
many
parameter,importance,result,non-trivial
derivation
,
novel
objective
function
,
gt
update
,
update
,
new
objective
function
,
new
optimization
technique
,
important
machine
translation
task
,
implementation
issue,schedule,hyper-parameter
tuning
,
superior
result
,
effectiveness
,
algorithm
,
author
,
chris
quirk,mei-yuh
hwang
,
bowen
zhou
,
assistance
,
mt
system
,
valuable
discussion
,
reference
amittai
axelrod
,
domain
adaptation
,
pseudo
in-domain
data
selection
,
emn
lp
,
necip
fazil
ayan
,
bonnie
,
extensive
analysis
,
word
alignment
,
impact
,
leonard
baum
,
inequality
,
application
,
statistical
prediction
,
function
,
markov
process
,
ecology
,
bulletin
,
american
mathematical
society
,
phil
blunsom
,
trevor
cohn
,
mile
osborne
,
discriminative
latent
variable
model
,
statistical
machine
translation
,
stephen
,
della
pietra
,
robert
,
mercer
,
mathematics
,
statistical
machine
translation
,
parameter
estimation
,
computational
linguistics
,
david
chiang
,
steve
den
eefe
,
yee
seng
chan
,
decomposability
,
translation
metric
,
improved
evaluation
,
efficient
algorithm
,
emn
lp
,
david
chiang
,
kevin
knight
,
weri
wang
,
new
feature
,
statistical
machine
translation
,
naa
cl-hlt
,
stueker
,
overview
,
iws
lt
,
evaluation
campaign
,
iws
lt
,
george
foster
,
cyril
goutte
,
roland
kuhn
,
discriminative
instance
weighting
,
domain
adaptation
,
statistical
machine
translation
,
emn
lp
,
gopalakrishnan
,
dimitri
kanevsky
,
arthur
nada
,
david
nahamoo
,
inequality
,
rational
function
,
application
,
statistical
estimation
problem
,
ee
trans,inform,theory,word-dependent
transition
model
,
word
alignment
,
second
acl
workshop
,
statistical
machine
translation
,
wu
chou
,
philipp
koehn
,
europarl
,
a
m
ultilingual
corpus
,
evaluation
,
machine
translation
,
philipp
koehn
,
franz
josef
och
,
daniel
marcu
,
statistical
phrase
,
translation
,
naa
cl
,
philipp
koehn
,
statistical
significance
test
,
machine
translation
evaluation
,
emn
lp
,
percy
liang
,
alexandre
bouchard-cote
,
dan
klein,taskar,end-to-end
discriminative
approach
,
machine
translation
,
wolfgang
macherey
,
franz
josef
och
,
gnacio
thayer
,
jakob
uskoreit,lattice-based
minimum
error
rate
training
,
statistical
machine
translation
,
emn
lp
,
robert
moore
,
chris
quirk,beam-search
decoding
,
phrasal
statistical
machine
translation
,
discriminative
training
,
maximum
entropy
model
,
statistical
machine
translation
,
franz
josef
och
,
minimum
error
rate
training
,
statistical
machine
translation
,
kishore
papineni
,
salim
roukos
,
todd
ward,wei-jing
zhu
,
method
,
automatic
evaluation
,
machine
translation
,
daniel
povey
,
discriminative
training
,
large
vocabulary
speech
recognition
,
dissertation
,
cambridge
university
,
chris
quirk
,
arul
menezes
,
colin
cherry
,
dependency
treelet
translation
,
phrasal
smt,antti-veikko
rosti
,
bing
hang
,
spyros
matsoukas
,
richard
schard
schwartz
,
ble
training
,
bbn
system
description
,
wmt
system
combination
task
,
workshop
,
statistical
machine
translation
,
jason
eisner
,
minimum
risk,log-linear
model
,
joern
wuebker
,
arne
mauser
,
hermann
ney
,
phrase
translation
model,leaving-one-out
,
roy
tromble
,
shankar
kumar
,
franz
och
,
wolfgang
macherey
,
lattice
minimum
bayes-risk
,
statistical
machine
translation
,
emn
lp
,
yang
liu
,
qun
liu
,
shouxun
lin
,
fast
generation
,
translation
forest,large-scale
smt
discriminative
training
,
em
nlp
,
r
eferences
amittai
axelrod
,
domain
adaptation
,
pseudo
in-domain
data
selection
,
emn
lp
,
necip
fazil
ayan
,
bonnie
,
extensive
analysis
,
word
alignment
,
impact
,
leonard
baum
,
application
,
statistical
prediction
,
function
,
markov
process
,
ecology
,
bulletin
,
american
mathematical
society
,
phil
blunsom
,
trevor
cohn
,
mile
osborne
,
discriminative
latent
variable
model
,
statistical
machine
translation
,
stephen
,
della
pietra
,
robert
,
mercer
,
mathematics
,
computational
linguistics
,
david
chiang
,
steve
den
eefe
,
yee
seng
chan
,
decomposability
,
translation
metric
,
improved
evaluation
,
efficient
algorithm
,
emn
lp
,
david
chiang
,
kevin
knight
,
weri
wang
,
new
feature
,
statistical
machine
translation
,
naa
cl-hlt
,
overview
,
iws
lt
,
evaluation
campaign
,
iws
lt
,
roland
kuhn
,
discriminative
instance
weighting
,
domain
adaptation
,
statistical
machine
translation
,
emn
lp
,
dimitri
kanevsky
,
arthur
nada
,
david
nahamoo
,
inequality
,
rational
function
,
application
,
statistical
estimation
problem
,
ee
trans,inform,theory,word-dependent
transition
model
,
word
alignment
,
second
acl
workshop
,
statistical
machine
translation
,
wu
chou
,
iscriminative
learning
,
philipp
koehn
,
europarl
,
a
m
ultilingual
corpus
,
evaluation
,
machine
translation
,
philipp
koehn
,
franz
josef
och
,
daniel
marcu
,
statistical
phrase
,
translation
,
naa
cl
,
philipp
koehn
,
statistical
significance
test
,
machine
translation
evaluation
,
em
nlp
,
percy
liang
,
alexandre
bouchard-cote
,
dan
klein,taskar,end-to-end
discriminative
approach
,
machine
translation
,
wolfgang
macherey
,
franz
josef
och
,
gnacio
thayer
,
jakob
uskoreit,lattice-based
minimum
error
rate
training
,
statistical
machine
translation
,
emn
lp
,
robert
moore
,
chris
quirk,beam-search
decoding
,
phrasal
statistical
machine
translation
,
mt
summit
xi
,
franz
josef
och
,
discriminative
training
,
maximum
entropy
model
,
statistical
machine
translation
,
franz
josef
och
,
minimum
error
rate
training
,
statistical
machine
translation
,
kishore
papineni
,
salim
roukos
,
todd
ward,wei-jing
zhu
,
method
,
automatic
evaluation
,
machine
translation
,
daniel
povey
,
discriminative
training
,
large
vocabulary
speech
recognition
,
dissertation
,
cambridge
university
,
chris
quirk
,
arul
menezes
,
colin
cherry
,
phrasal
smt,antti-veikko
rosti
,
bing
hang
,
spyros
matsoukas
,
richard
schard
schwartz
,
bl
eu
training
,
bbn
system
description
,
workshop
,
statistical
machine
translation
,
jason
eisner
,
minimum
risk,log-linear
model
,
joern
wuebker
,
arne
mauser
,
hermann
ney
,
phrase
translation
model,leaving-one-out
,
roy
tromble
,
shankar
kumar
,
franz
och
,
wolfgang
macherey
,
lattice
minimum
bayes-risk
,
statistical
machine
translation
,
emn
lp
,
yang
liu
,
qun
liu
,
shouxun
lin
,
fast
generation
,
translation
forest,large-scale
smt
discriminative
training
,
emn
lp
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
,
baltimore
,
maryland
,
association
,
computational
linguistics
learning
continuous
phrase
representation
,
t
ranslation
modeling
j
ianfeng
gao
x
,
xiaohe
,
scottyih
,
deng
microsoft
,
com
a
bstract
,
sparsity
problem
,
phrase
translation
probability
,
continuous
phrase
representa
tions
,
distributed
nature
,
sharing
,
related
phrase
,
represen
tations
,
source
,
target
phrase,continuous-valued
vec
tor
representation,low-dimensional
latent
space
,
translation
score
,
distance
,
new
space
,
projection
,
neural
network
,
weight
,
parallel
training
data
,
experimental
evaluation
,
wmt
translation
task,result,performance,state-of-the-art
phrase-based
statistical
machine
translation
system,french-english
data
,
ble
point
,
1
i
ntroduction
,
phrase
translation
model
,
phrase
table
,
core
component
,
system
,
common
method
,
construct
,
phrase
table
,
bilingual
phrase
pair,word-aligned
training
data
,
second
phase
,
parame
ter
estimation
,
phrase
pair,phrase,word-aligned
training
data,hrase-based
smt
system,state-of-the-art
performance
,
long
phrase
,
single
word
,
translation
unit
,
useful
context
,
formation
,
translation
,
train
ing
data
,
severe
data
sparseness
prob
lem
,
parameter
estimation
,
plethora
,
research
,
literature
,
parameter
estimation
,
problem
,
phrase
translation
pair
,
translation
score
,
phrase
pair,phrase,bag-of-words
vector
,
word
vec
tor
henceforth
,
word
vector
,
source
language
,
target
lan
guage
,
respective
continuous
feature
vector
,
common
low-dimensional
space,projection,multi-layer
neural
network
,
projected
feature
vector
,
continuous
representa
tion
,
phrase
,
translation
score,source-target
phrase
pair
,
dis
tance
,
feature
vector
,
main
motivation
,
data
sparseness
problem
,
traditional
counting-based
method
,
phrase
,
similar
meaning
,
different
language
,
grouping
,
distributed
nature,continuous-space
representation
,
sharing
,
original
sym
bolic
space
,
phrase
,
related
phrase
,
source
,
target
lan
guages
,
feature
vector
,
continuous
space
,
training
objective
,
translation
score
,
smooth
function
,
feature
vector
,
change
,
feature
,
small
change
,
primary
research
task
,
cp
tm
,
continuous
representation
,
phrase
,
recent
study,continuous-space
language
model
,
mikolov
,
schwenk
,
neural
net
work
,
word
vector
,
projection
,
latent
feature
,
good
trans
lations
,
bad
one
,
training
data
,
explicit
annotation
,
quality
,
phrase
translation
,
translation
pair
,
par
allel
source-target
sentence
pair
,
traditional
translation
model
,
quality
,
phrase
translation
,
translation
quality
,
sentence
,
phrase
pair
,
chal
lenge
,
projec
tion
learning
,
new
method
,
parameter
,
neural
network
,
new
method
,
choice
,
appropriate
objective
function
,
training
,
fea
ture
vector
,
source
phrase
,
feature
vector
,
candidate
translation
,
result
,
ble
score
,
translation
,
smt
decoder,sentence-level
translation
,
new
learning
method
,
l-b
fgs
algorithm
,
objective
function,n-best
list
,
knowledge
,
first
continuous-space
phrase
translation
model
,
joint
representation
,
phrase
,
source
language
,
translation
,
target
language
,
section
,
significant
improvement
,
standard
phrase
,
smt
system
,
traditional
phrase
translation
model
,
translation
score
,
bilingual
phrase
pair
,
phrase
translation
score
,
aligned
parallel
data
,
semantic
similarity
,
source
phrase
,
paired
target
phrase
,
continuous
space
,
language
,
1
n
iehues
,
different
translation
unit,n-gram
translation
model
,
phrase
,
approach
,
review
previous
work
,
section
,
re
view,log-linear
model,phrase-based
smt
,
section
,
section
,
model
parameter
,
experimental
result
,
section
,
section
,
elated
work
representation
,
document
,
contin
uous
vector
,
long
history
,
latent
semantic
model
,
vec
tor
,
hofmann
,
recent
work
,
continuous
space
language
model
,
prob
ability
,
word
sequence
,
mikolov
,
language
modeling
,
traditional
n-gram
model
,
speech
recognition
,
mikolov
,
sunder
meyer
et
,
mono
lingual
setting
,
mod
el,translation,result,variant,cross-lingual
scenario
,
dif
ferent
language
,
la
tent
vector
space
,
dumais
,
vinokourov
,
phrase
table,cross-lingual
model
,
derivation
,
smt
training,result,section,interest,continuous-space
model
,
translation
,
continu
ous
space
n-gram
translation
model,schwenk,schwenk,feed-forward
neural
network
language
model
,
translation
probability
,
gram
translation
model
,
translation
probability,phrase,sentence,product,n-gram
probability
,
standard
n-gram
language
model
,
approach
,
phrase
translation
model1
,
version
,
factor
model
,
modern
smt
system
,
contrast
,
representation
,
phrase
,
source
language
,
trans
lation
,
target
language
,
recurrent
contin
uous
translation
model
,
kalchbren
ner
,
blunsom
,
recurrent
language
model,mikolov,n-gram
translation
model
,
markov
assumption
,
dependency
,
target
sentence
,
continuous
space
model
,
trans
lations
,
new
word
,
mikolov
,
reordering
,
research
,
phrase
table,phrase-based
smt
,
lamber
,
banchs
,
denero
,
wuebker
,
phrase
translation
probability
,
discrimi
native
training
method,n-best
reranking
framework
,
objective
function
,
continuous
repre
sentations,phrase,strength,log-linear
model
,
smt
phrase-based
smt,log-linear
model
,
mapping
,
sample
,
source
sentence
,
reference
translation,n-best
candidate
,
baseline
phrase,in-house
implementation
,
moses
system,sentence-level
ble
score
,
quality
,
respect
,
feature
,
vector
,
feature
value,real-valued
weight
,
feature
,
ur
baseline
system
,
standard
feature
,
sec
tion
,
log
linear
model
,
output
sentence
,
consists
,
segmentation
,
source
,
target
sentence
,
phrase
,
alignment
,
source
,
target
phrase
,
argmax
,
beam
search
,
translation
candidate
,
corresponding
,
viterbi
derivation
,
architecture
,
figure
,
source
,
target
phrase,source-target
sentence
pair
,
feature
vector
,
latent
,
continuous
space
,
neural
net
work
,
hidden
layer
,
translation
score
,
distance
,
feature
vec
tor,bag-of-words
representation
,
word
vector
,
vocabulary
consisting
,
source
,
target
language
,
experiment
,
projection
,
neural
network
,
hidden
layer
,
tanh
activation
function
,
projec
tion
matrix
,
input
layer
,
hidden
layer
,
projection
matrix
,
hidden
layer
,
output
layer
,
f
igure
,
neural
network
model
,
phrase
,
continuous
representation
,
source
,
target
language
,
source
phrase
,
target
phrase
,
distance
,
feature
vector
,
dot
product
,
similarity
function3
,
function
,
projection
ma
trice,log-linear
model
,
experiment
,
dot
product
,
cosine
similarity
function
,
former
work
,
nonlinear
multi-layer
neural
network
,
linear
neural
network
,
clarity
,
dot
product
,
train
ing
,
section
,
smt
need
,
oracle
ble
score
,
new
feature
,
new
feature
weight
,
new
feature,phrase-based
smt
system
,
vector
,
handful
,
param
eters,log-linear
model
,
weight
,
feature
,
projection
matrix
,
experiment
,
baseline
phrase-based
smt
sys
tem
,
source
sentence
,
training
data,n-best
list
,
translation
hy
potheses4
,
baseline
system
,
loss
function
,
training
data5
,
next
section
,
de
tail
,
cpt
training,top-1
translation
,
initial
value
,
dev
set
,
pilot
study
,
baseline
feature
weight,log-linear
model
,
unnormalized
weight
value
,
target
lan
guage
model
,
f
igure
,
architecture
,
mapping
,
phrase
,
continuous
repre
sentation
,
figure
,
ontinuous
representation
,
target
phrase
,
ource
phrase
,
ontinuous
representation
,
source
phrase
,
ranslation
score
,
dot
product
,
feature
vector
,
continuous
space
,
section
,
loss
function
,
algorithm
,
neural
network
weight
,
nega
tive,n-best
list
,
reranking
framework
,
section
,
xb
leu,sentence-level
ble
score
,
translation
probability,softmax,log-linear
model
,
feature
,
loss
function,tiable,parameter,gradient,gradient-based
numerical
optimization
al
gorithms
,
l-b
fgs
,
gradient
,
chain
rule
,
summation
,
phrase
,
training
sample
,
sto
chastic
mode
,
entire
training
data
,
error
term
,
overall
loss
change
,
translation
score
,
derivation
,
section
,
gradient
,
generality
,
following
notation
,
projection
matrix,l-th
layer
,
input
word
vector
,
sum
vector,l-th
layer
,
output
vector,l-th
layer
,
gradient
,
matrix
,
project
,
hidden
vector
,
output
vector,element-wise
multiplication
,
back
propagation
principle
,
gradient
,
projection
matrix
,
input
vector
,
hidden
vector
,
derivation
,
neural
network
,
multiple
hidden
layer
,
notation
,
loss
func
tion
,
training
sample
,
number
,
training
algorithm
,
experiment
,
parameter
,
l-b
fgs
optimizer
,
andrew
,
loss
function
,
gradient
,
section
,
neural
network
,
simplicity
,
robustness
,
local
minimum
,
bengio
,
l-b
fgs
,
desirable
fashion
,
com
plete
training
data,example,convergence,algorithm,non-convexity
,
batch
training
,
gradient
,
training
data,section,large-scale
matrix
multiplication,multi-layer
neural
network
,
computation
cost
,
former
term
,
number
,
phrase
pair
,
phrase
table
,
training
data
,
training
method
,
amount
,
training
data
,
little
difficulty,section,parameter,log-linear
model
,
computer
cluster
,
cpt
training
,
single
ma
chine
,
example
,
phrase
table
contain
,
16m
pair,1m-sentence
training
set,couple,n-best
list,cluster,e5-2670
,
non-convex
problem
,
model
initialization
,
experiment
,
bilingual
topic
model
,
parallel
data
,
detail
,
section
,
identity
matrix
,
principle
,
loss
function
,
clear
empirical
advantage
,
simpler
early
stop
approach
,
pilot
study
,
experiment
,
6
e
xperiments
,
section
,
translation
task
,
wmt
data
set
,
data
set
,
present
experiment
,
different
version
,
previous
model
,
experimental
setup
baseline,in-house
phrase-based
system
,
translation
candidate
,
common
feature
,
maximum
likelihood
estimate
,
source
,
lexical
weighting
estimate
,
phrase
penal
tie
,
linear
distortion
feature
,
lexicalized
reordering
feature,baseline,kneser-ney
language
model
,
target
side
,
parallel
corpus,log-linear
weight
,
mer
algorithm
,
evaluation
,
different
data
set
,
french
sys
tem
,
corpus
,
cludes
,
sentence
pair
,
parliamentary
pro
ceedings
,
training
,
development
,
con
tains
,
sentence
,
test
set
,
sentence
,
official
wmt
,
a
f
rench
,
eng
lish
system
,
sentence
pair
,
training
data
,
campaign
,
majority
,
training
data
set
,
parliamentary
proceeding
,
newswire
data
set
,
sen
tences
,
development
set
,
newswire
domain
test
set
,
system
combination
test
set
,
sentence
,
detailed
empirical
comparison
,
data
set
,
result
,
evaluation
,
case
insensi
tive
ble
score
,
papineni
,
significance
test
,
wilcoxon
,
rank
test,difference,p-value
,
result
,
cpt
table
,
result
,
ble
eval
,
data
set
,
baseline
system
,
system
,
different
version
,
cp
tm
,
result
,
previous
model
,
system
,
main
result
,
section
,
figure
,
number
,
input
layer
,
hidden
layer
,
output
layer
,
nodes6
,
matrix
,
matrix
,
result
,
cp
tm
,
substantial
improvement
,
baseline
system
,
significant
margin
,
variant
,
design
choice
,
linear
6
w
,
result
,
hidden
,
output
layer
,
model
projection,multi-layer
nonlinear
projection
,
phrase
similarity,word-word
similarity
,
lexical
weighting
model
,
variant
,
data
set
,
linear
neural
network
,
word
vector
,
phrase
,
projection
matrix
,
translation
score
,
source
phrase
,
target
phrase
,
similarity
,
feature
vector
,
choose
cosine
similarity
,
dot
product
,
phrase
similarity,word-word
similarity
score
,
common
smoothing
strategy
,
data
sparseness
problem
,
phrase
translation
,
lexical
weighting
model,n-gram
translation
model
,
source
,
target
phrase
,
word
phrase
similarity
,
smooth
ap
proximation
,
training
,
detailed
study
,
rea
sonable
time
,
paper
use
,
2
c
ptm
,
5
b
ltmpr
,
7
m
rfp
,
8
c
omb
,
english
,
french
task
,
translation
model
,
system
,
data
set
,
superscript
,
significant
difference
,
baseline
,
respec
,
word
phrase
similarity
,
smooth
ap
proximation
,
maximum
function
,
tuned
smoothing
parameter
,
nonlin
ear
projection
,
phrase
vec
tor
,
observation
,
cp
tm
,
variant
,
phrase
,
lation
,
word
word
translation
,
cpt
m
,
second
,
nonlinear
projection
,
effective
feature
,
result
,
version
,
related
model
,
discussion
,
re
sults,state-of-the
art
latent
semantic
model
,
clicked
query-document
pair
,
clickthrough
data
,
search
log,query-document
matching,source-tar
get
sentence
pair
,
clicked
query-document
pair
,
method
,
parallel
bi
lingual
training
data
,
specifi
,
extension
,
performer
,
different
version
,
parallel
training
data
,
em
algorithm
,
constraint
,
source
sentence
,
paralleled
target
sentence
,
prior
topic
dis
tribution
,
similar
fraction,log-linear
model
,
7
g
ao
,
result
,
mrf
model
,
different
feature
set
,
phrase
fea
,
comparison
,
phrase
representation
,
topic
distribution,topic-word
distribution
,
translation
candidate,logarithm,probability,log-linear
model
,
tional
feature
,
discriminative
projec
tion
model
,
extension
,
matrix
,
word
vector
,
sentence
,
feature
vector
,
projection
matrix
,
parallel
train,alorithm,log-lin
ear
model
,
new
fea
ture
,
phrase
pair
,
cosine
similarity
,
phrase
,
pro
ject
space
,
latent
semantic
model
,
baseline
,
mar
kov
random
field
model
,
phrase
feature,state-of-the-art
large
scale
discriminative
training
model
,
ble
training
criterion
,
superior
performance
,
mt
task
,
linear
model
,
phrase
pair
,
2
m
rfp
,
3
c
ptm
,
4
c
omb
,
b
leu
result
,
translation
model
,
system
,
data
set
,
superscript
,
baseline
,
translation
relation
ship
,
phrase
,
different
angle
,
translation
score
,
phrase
pair
,
parameter
sharing
,
phrase
share
,
neural
network
,
project
,
phrase
,
continu
ous
space
,
smoothed
estimation
,
translation
score
,
phrase
pair
,
result
,
outperforms
,
wmt
data
set
,
difference
,
interpre
tation
,
smoothed
estimation,low-frequent
phrase
pair
,
data
sparsity
,
precise
estimation,high-frequent
phrase
pair
,
capture
complementary
information
,
translation
,
mr
fp,feature,log-lin
ear
model
,
translation
task
,
accuracy
improves
,
bl
eu
,
news2008
test
,
result
,
cp
tm
,
complementary
translation
infor
mation
,
accuracy
,
baseline
,
wm
data
set
,
7
c
onclusions
,
major
contribution
,
novel
phrase
translation
model
,
joint
represen
tations
,
phrase
,
source
lan
guage
,
translation
,
target
language
,
translation
score,source-target
phrase
,
dis
tance
,
feature
vector,low-di
mensional
,
continuous
space
,
representation
,
multi
layer
neural
network
,
method
,
weight
,
multi
layer
neural
network,end-to-end
ble
,
training
method
,
detail
,
gradient
,
closed
form
,
efficient
optimiza
tion
,
objective
function,n-best
list
,
usual
objective
function
,
architec
tures
,
neural
network
,
cross
entropy
,
hin
ton
,
mean
square
error
,
detail
,
der
ivation
,
gradient
,
ex
ample
,
derivation
,
neural
network,non-standard
objective
func
tions
,
wmt
data
set,continuous-space
phrase
translation
model,log-linear
framework,accuracy,state-of
the-art
phrase-based
smt
system
,
l-b
fgs
optimization
,
ble
centric
objective
function,closed-form
gradient
,
suc
ce
,
a
natural
extension
,
algorithm
,
shallow
,
neural
network
,
deep
model
,
flexible
se
mantic
representation
,
performance
gain
,
8
a
cknowledgements
,
michael
auli
,
dataset
,
helpful
discussion
,
anonymous
reviewer
,
comment
,
scalable
training,l1-regularized
log-linear
model
,
ic
ml
,
joint
language
,
translation
modeling
,
recurrent
neural
network
,
deep
architecture
,
fundamental
trend
machine
learning
,
journal
,
natural
language
processing
,
machine
learning
research
,
index
ing
,
latent
semantic
analysis
,
journal
,
american
society
,
information
science
,
generative
phrase
model
,
form
surface
heuristic
,
workshop
,
statis
tical
machine
translation
,
scalable
stacking
,
learning
,
deep
archi
tectures
,
princi
ple
component
neural
network
,
theory
,
application
,
automatic
cross-language
retrieval
,
latent
semantic
indexing
,
aaa
i-97
spring
symposium
series,cross-language
text
,
posterior
regularization
,
structured
latent
variable
model
,
journal
,
machine
learning
research
,
translation
model
,
gradient
ascent
,
click
through-based
latent
semantic
model
,
web
search
,
sig
ir
,
maximum
,
bleu
training
,
phrase
,
lexicon
translation
model
,
discov
,
binary
code
,
document
,
deep
generative
model
,
cogni
tive
science
,
acoustic
modeling
,
probabilistic
latent
semantic
indexing
,
sig
ir
,
deep
structured
se
mantic
model
,
web
search
,
recur
rent
continuous
translation
model
,
open
source
toolkit
,
statistical
machine
trans
lation
,
auto
matic
evaluation
,
machine
translation
,
tween
european
language
,
workshop
,
statistical
machine
translation
,
statisti
cal
phrase-based
translation
,
hlt
-
naa
cl,multi-word
expression
,
statistical
machine
translation
,
mt
summit
,
phuket
,
recursive
auto
encoders,translation,end-to-end
discriminative
approach
,
machine
translation
,
joint
probability
model
,
statistical
machine
translation
,
recurrent
neural
network
,
language
model
,
int
er
-
sp
eech
,
extension
,
re
current
neural
network
language
model
,
ic
assp
,
statistical
language
model
,
neural
network
,
thesis
,
brno
university
,
sutskever
,
similarity
,
language
,
machine
translation
,
lin
guistic
regularity
,
continuous
space
word
representation
,
polylingual
topic
model
,
emn
lp
,
context
,
bilingual
lan
guage
model
,
minimum
error
rate
training
,
sta
tistical
machine
translation
,
alignment
tem
plate
approach
,
zhu
w-j
,
method
,
automatic
evaluation
,
machine
translation
,
discriminative
projection
,
ble
training
,
bbn
system
description
,
wmt
system
combination
task
,
workshop
,
smooth
bilingual
n-gram
transla
tion
,
emn
lp-conll
,
continuous
space
translation
model,phrase-based
statistical
machine
translation
,
continuous
space
lan
guage
model
,
a
g
pu
,
statistical
machine
translation
,
naa
cl-hlt
workshop
,
future
,
language
modeling
,
discriminative
training
,
translation
parameter
,
application
,
recursive
matrix-vector
space
,
natural
scene
,
natural
lan
guage
,
recursive
neural
network
,
con
tinuous
space
translation
model
,
neural
network
,
naa
cl-hlt
,
gauvain
,
feed
forward
,
recurrent
,
ral
network
language
model
,
towards
,
understanding
,
deep
con
vex
network
,
semantic
utterance
classifica
tion
,
cristia
,
semantic
representa
tion,cross-language
correlation
anal
ysis
,
learning
,
joint
word-image
embeddings
,
ing
phrase
translation
model
,
discriminative
projection
,
text
similarity
measure,cision-feedback
learning
,
heterogeneous
model
,
relational
similarity
,
bilingual
word
embeddings,phrase-based
machine
translation
,
emn
lp
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
,
short
paper
,
baltimore
,
maryland
,
association
,
computational
linguistics
semantic
parsing,single-relation
question
answering
wen-tau
yih
xiaodong
,
christopher
meek
microsoft
research
redmond
,
xiaohe
,
meek
microsoft
,
com
abstract
,
semantic
parsing
framework
,
semantic
similarity
,
main
question,single-relation
question
,
question
,
entity
men
tion
,
relation
pattern
,
convo
lutional
neural
network
model
,
similarity
,
entity
mention
,
entity
,
similarity
,
relation
pattern
,
re
lations
,
relational
triple
,
measure
,
top
scoring
relational
triple,question,open-domain
qa
task
,
method
,
precision
,
different
recall
point
,
previous
ap
proach
,
1
i
ntroduction
open-domain
question
,
im
portant,problem,single-relation
factual
question
,
common
type
,
question
,
various
community
qa
,
search
query
log
,
question
,
single
relation
query
,
relation
,
argument
entity,single-relation
question
,
question
,
multiple
relation
,
former
secretary
,
admin
istration,single-relation
question
,
restricted
domain
,
large
number
,
paraphrase
,
question
,
problem
,
question
,
particular
relation
,
entity
,
semantic
parsing
framework,single-relation
question
,
approach
,
novel
semantic
similarity
model
,
convolutional
neural
net
work
,
question
paraphrase
data
,
wikianswers
corpus
,
semantic
similarity
mod
el
,
mention
,
question
,
entity
,
relation
pat
tern
,
relation
,
answer
,
question
,
relation
,
entity
triple
,
entity
,
question
,
general
se
mantic
similarity
model
,
pattern
,
re
lations
,
mention
,
entity
,
sys
tem
,
pre
cision
,
recall
point
,
question
,
test
set
,
achiev
able
,
system
,
par
alex
,
survey
related
work
,
problem
definition,high-level
descrip
tion
,
approach
,
detail
,
semantic
model
,
experimen
tal
result
,
elated
work
semantic
parsing
,
question
,
nat
ural
language
question
,
critical
component
,
early
example
,
research
,
semantic
parser,geography-related
question
,
inductive
logic
programming,mooney,esearch,domain-specific
database
,
geoquery
,
mooney
,
researcher
,
semantic
parser
,
general
domain
knowledge
base
,
freebase
,
db
pedia
,
berant
,
kwiatkowski
,
problem
,
method
,
large
kb
,
con
trast
,
par
alex
system,single-relation
question
,
knowl
edge
base
,
rev
erb
,
simple
seed
template,community-authored
paraphrase,question,wikianswers,high-quality
lexicon
,
restricted
form
,
semantic
parsing
,
approach
,
continuous
representation
,
semantic
simi
larity
,
long
history
,
active
research
topic
,
salton
,
mcg
ill
,
latent
semantic
analysis
,
deerwester
,
topic
model,bag-of
word
approach
,
contex
tual
information
,
document
,
sentence
,
separate
line
,
research
,
deep
learning
,
technique
,
semantic
un
derstanding
,
mesnil
,
salakhutdinov
,
hin
ton
,
semantic
distance
,
question
,
relational
triple
,
core
compo
nent
,
semantic
parsing
approach
,
knowledge
base,single-relation
question
,
single
relation
question
,
question
com
,
entity
mention
,
binary
rela
tion
description
,
answer
,
ques
tion,entity,relation,entity,example,single-relation
question
,
dvd
player
,
entity
,
relation
,
answer
,
lambda
expression
,
potential
semantic
parse
,
ques
tion
,
dvd
player
,
collection
,
binary
relation
instance
,
relation
,
second
entity
argument,single-relation
question
,
question
,
knowledge
base
,
mapping
,
re
lation
,
entity
,
question
,
answer
,
sim
ple
table
lookup
,
large
number
,
para
phrase
,
question
,
difficult
problem
,
approach
,
simple
semantic
parser,single-relation
question
,
advanced
semantic
similar
ity
model
,
paraphrase
issue
,
question
,
disjoint
part
,
entity
mention
,
relation
pattern
,
entity
mention
,
subsequence
,
consecutive
word
,
question
,
relation
pattern
,
question
,
mention
,
special
symbol
,
mapping
,
pattern
,
relation
,
mapping
,
mention
,
entity
,
semantic
similarity
model,high-level
approach
,
simple
context-free
grammar,figure,probability,single-relation
ques
tion
,
exact
decomposition
,
com
binations
,
assign
equal
probability
,
performance
,
approach
,
relation
pattern
,
entity
mention
,
15k
15k
15k
15k
,
ft
convolutional
layer
,
ht
max
,
v
s
emantic
layer
,
word
sequence
,
xt
word
hashing
matrix
,
wf
convolution
matrix
,
wc
max
,
operation
semantic
projection
matrix
,
figure
,
cnn
sm,variable-length
word
sequence,low-dimensional
vector
,
latent
semantic
space
,
receptive
field
,
illustration
,
convolution
,
word
sequence
,
matrix
,
mapping
,
local
receptive
field
,
max
operation
,
se
quence
,
feature
dimen
sion
,
probability
,
mapping
,
semantic
similarity
model
,
convolutional
neural
network
,
tech
nical
focus
,
4
c
onvolutional
neural
network
,
semantic
model
following
,
collobert
,
semantic
parsing
,
cnn
sm
,
convolutional
layer
,
context
window
,
local
contextual
feature
vec
tor
,
similar
word-n-grams
,
vector
,
contextual
feature
space
,
overall
meaning
,
sentence
,
key
word
,
salient
lo
cal
feature,fixed-length
global
feature
vector
,
global
feature
vector,feed-forward
neural
network
layer,non-linear
semantic
feature
,
architecture
,
cnn
sm
,
figure
,
fol
low
,
cnn
sm
,
detail
,
annotation
,
figure
,
word
hash
,
technique
,
letter
trigram
count
vector
,
example
,
word
boundary
sym
bols
,
se
quence
,
count
vector,letter-trigrams
,
exam
ple,letter-trigram
representation
,
figure
,
matrix
de
,
transformation
,
letter
trigram
count
vector
,
learning
,
oov
issue,mistake,letter-trigram
,
word
representation
,
letter
trigram
vector,t-th
word-n-gram
,
word-n-gram
layer,letter-trigram
representation,t-th
word
,
con
textual
window
,
convolution
operation
,
window
,
feature
extrac
tion,word-n-gram
contextual
fea
tures,t-th
word-n-gram
,
convo
lution
matrix
project,letter-trigram
representa
tion
vector
,
figure
,
feature
transformation
matrix
,
convolution
matrix
,
output
,
con
volutional
layer
,
sequence
,
local
contextual
feature
vector
,
significant
influence
,
semantics
,
sen
tence
,
global
feature
vector
,
salient
,
key
word
,
purpose
,
max
operation
,
max
pooling
,
network
,
useful
local
feature
,
con
volutional
layer,max-pooling
layer,figure,i-th
element
,
max
pool,i-th
element
,
dimensionality
,
dimensionality
,
local
contextual
feature
vector,non-linear
transformation
layer
,
global
feature
vector,high-level
semantic
repre
sentation
,
figure
,
global
fea
ture
vector
,
max
pooling
,
semantic
projection
matrix
,
vector
representa
tion
,
input
query
,
document
,
latent
se
mantic
space
,
pattern
,
relation
,
relevance
score
,
cosine
similarity
,
semantic
vector
,
semantic
relevance
score
,
pattern
,
relation
,
cosine
score
,
semantic
vector
,
cnn
semantic
model
,
pattern
,
relation
,
mention
,
entity
pair
,
respec
,
pattern
,
corresponding
relation
,
positive
example
,
relation
,
negative
example
,
set
ting
,
mention
,
entity
model
,
posterior
probability
,
positive
relation
,
pattern
,
cosine
,
softmax
,
scaling
factor
,
model
train
ing
,
stochastic
gradient
descent
,
detail
,
5
e
xperiments
,
fair
comparison
,
ous
work
,
approach
,
par
alax
dataset
,
paraphrase
,
question
,
wikianswers
,
triple
,
re
verb
,
section
,
dataset
,
system
training
,
evalua
tion
process
,
experimen
tal
result
,
par
alex
training
data
consists,question,single-relation
database
query
,
dvd
player
,
eval
uation
,
author
,
question
,
cluster
,
swer
triple
,
system
,
cnn
semantic
model
,
parallel
corpus
,
par
-
al
ex
training
data
,
relation
pattern
,
original
training
corpus
,
exact
surface
form
match,dvd-player
,
player
,
exact
match
,
pattern
,
mention
,
question
,
special
symbol
,
relation
,
pattern
,
rela
tion
,
original
database
query
,
indicat
,
answer
entity
,
sec
ond
argument
,
pattern
,
rela
tions
,
pattern
,
training
question
,
new
mention
,
exact
surface
form
match
,
entity
,
cnn
sm
,
pattern
,
relation
similarity
measure
,
pattern
,
relation
,
training
set
,
validation
set
,
hyper
parameter
,
hyphen
,
blank
space
,
ex
periment
,
re
ceptive
field
,
convolutional
neural
network
,
unique
letter-trigrams
,
training
set
,
neuron
,
convolutional
layer,max-pooling
layer
,
final
semantic
layer
,
learning
rate
,
iteration
,
similar
set
ting
,
cnn
sm
,
mention
,
entity
model,mention-entity
pair
,
result
,
test
question
,
par
alex
dataset
,
system
,
f1
precision
recall
map
cnn
sm
,
cnn
sm
,
par
alex
,
performance
,
variation
,
sys
tems
,
par
alex
system
,
answer
,
rev
erb
database
,
system
,
triple
,
par
alex
system
,
new
question
,
triple
pair
,
question
,
system
,
possible
decomposition,mention,pattern,similarity,pattern,relation,top-scoring
relation
candidate
,
relation
,
system
,
triple
,
relation
,
similarity
,
mention
,
argument
entity
,
product
,
probability
,
cosine
similarity
,
softmax
,
final
score
,
triple
,
answer
,
top
answer
triple
,
precision
,
recall
,
sys
tem
,
system
performance
,
system
,
output
,
triple
,
predefined
threshold,trade-off
,
recall
,
pre
cision
,
precision
,
recall
curve
,
performance
,
recall
,
mean
average
precision
,
sys
tems
,
par
alex
,
variation
,
nsm
pm
,
full
system
,
consists
,
semantic
similarity
model
,
pattern
,
relation
,
mention
,
entity
,
similarity
,
pattern
,
relation
,
mention
,
entity
,
surface
form,trade-off
,
precision
,
threshold
,
system
,
precision
,
recall
curve
,
fig
ure
,
figure
,
precision
,
cnn
sm
pm
system
,
recall
region
,
cnn
sm
system
,
high
precision
regime
,
recall
,
pre
ci
ion
recall
c
nnsm
pm
cn
nsmp
paralex
figure
,
precision
,
recall
curve
,
variation
,
system
,
par
alex
,
system
,
mention
,
entity
,
different
surface
form
,
par
alex
,
threshold
,
validation
,
6
c
onclusions
,
semantic
parsing
framework,single-relation
question
,
key
insight
,
relation
pattern
,
entity
mention
,
semantic
similarity
function
,
lexical
rule
,
similarity
model
,
convo
lutional
neural
network,letter-trigrams
vec
tor
,
design
,
bag
of-words
representation
,
method
,
precision
,
qa
task
,
different
recall
point
,
strong
empirical
performance
,
system
,
improvement
,
stance
,
variety
,
entity
mention
,
real
world
,
parallel
corpus
,
wikianswers
data
,
robust
entity
,
component
,
dedicated
entity
,
system
,
performance
,
number
,
pattern
mention
candidate
,
question
,
future
,
method
,
structured
kb,freebase,approach,system,multi-relation
question
,
reference
jonathan
berant
,
andrew
chou
,
roy
frostig
,
percy
liang
,
semantic
parsing
,
freebase
,
proceeding
,
conference
,
empirical
method
,
natural
lan
guage
processing
,
seattle
,
wash
ington
,
october
,
association
,
computa
tional
linguistics
,
david
m
b
lei
,
andrew
y
n
,
michael
i
j
ordan
,
latent
dirichlet
alocation
,
journal
,
alexander
yates
,
scale
semantic
parsing
,
schema
matching
,
lex
icon
extension
,
proceeding
,
annual
meeting
,
association
,
computational
lin
guistics
,
volume
,
long
paper
,
bulgaria
,
august
,
association
,
computa
tional
linguistics
,
ronan
collobert
,
jason
weston
,
leon
bottou
,
michael
karlen
,
koray
kavukcuoglu
,
pavel
kuksa
,
natural
language
processing
,
scratch
,
journal
,
machine
learning
research
,
scott
deerwester
,
susan
dumais
,
thomas
landauer
,
george
furnas
,
richard
harshman
,
latent
semantic
analysis
,
journal
,
american
society
,
information
science
,
stephen
soderland
,
oren
etzioni
,
relation
,
open
information
ex
traction
,
proceeding
,
conference
,
em
pirical
method
,
edinburgh
,
luke
zettlemoyer
,
oren
etzioni,paraphrase-driven
learning
,
open
question
,
proceeding
,
annual
meet
ing
,
association
,
computational
linguis
tic
,
volume
,
long
paper
,
bulgaria
,
august
,
association
,
computa
tional
linguistics,po-sen
huang
,
li
deng
,
alex
acero
,
larry
heck
,
semantic
model
,
web
search
,
clickthrough
data
,
proceeding
,
acm
international
conference
,
conference
,
informa
tion
knowledge
management
,
tom
kwiatkowski
,
eunsol
choi
,
yoav
artzi
,
luke
zettlemoyer
,
semantic
parser,on-the-fly
ontology
,
proceeding
,
conference
,
empirical
method
,
natu
ral
language
processing
,
seattle
,
washington
,
october
,
association
,
compu
tational
linguistics
,
percy
liang
,
michael
i
j
ordan
,
dan
klein,dependency-based
compositional
seman
tic
,
computational
linguistics
,
egoire
mesnil
,
yoshua
bengio,investigation,recurrent-neural
network
architecture
,
method
,
language
,
interspeech
,
ruslan
salakhutdinov
,
geoffrey
hinton
,
se
mantic
hashing
,
international
journal
,
approxi
mate
reasoning
,
gerard
salton
,
michael
,
mcg
ill
,
intro
duction
,
modern
information
retrieval
,
raw
hill
,
yelong
shen
,
li
deng
,
mesnil
,
convolutional
latent
semantic
model
,
web
search
,
technical
report
msr
tr-2014-55
,
microsoft
research
,
yelong
shen
,
li
deng
,
mesnil
,
learning
semantic
representation
,
convolutional
neural
network
,
web
search
,
proceeding
,
companion
publication
,
international
conference
,
world
wide
web
companion
,
lappoon
tang
,
raymond
mooney
,
multiple
clause
constructor
,
semantic
parsing
,
machine
learn
,
springer
,
gokhan
tur
,
li
deng
,
dilek
hakkani-tur
,
towards
,
understanding
,
deep
convex
network
,
semantic
utterance
classi
fication
,
acoustic
,
speech
,
john
zelle
,
raymond
mooney
,
database
query
,
inductive
logic
pro
gramming
,
proceeding
,
national
confer
ence
,
artificial
intelligence
,
proceeding
,
workshop
,
statistical
machine
translation
,
association
,
computational
linguistics
review
,
hypothesis
alignment
algorithm
,
mt
system
combination
,
confusion
network
decoding
antti-veikko
,
damianos
karakosc
,
markus
freitage
,
smithc
,
arosti
apple
,
com
bmicrosoft
research
,
xiaohe
microsoft
,
com
cjohns
hopkins
university
,
baltimore
,
damianos
,
jrsmith
jhu
,
dsa
ic
,
germany
gregor
,
com
erw
th
aachen
university,d-52056
aachen
,
germany
freitag
,
fraytheon
bbn
technology
,
moulton
street
,
smatsouk
,
bzhang
bbn
,
com
abstract
confusion
network
decoding
,
successful
approach
,
machine
translation
system
combination
,
hypothesis
alignment
algorithm
,
cru
cial
part
,
confusion
network
,
many
alternative
,
literature
,
sys
tematic
comparison
,
hy
pothesis
alignment
algorithm
,
mt
sys
tem
combination
,
confusion
network
,
experiment
,
identi
cal
pre-processing
,
decoding
,
method
,
standard
system
combina
tion
evaluation
set
,
transla
tion
quality
,
case
insensitive
ble
score
,
bootstrapping
,
tablish
statistical
significance
,
score
dif
ferences
,
aligners
,
significant
ble
score
gain
,
individual
system
,
combination
,
incremental
indi
rect
hidden
markov
model
,
novel
incre
mental
inversion
transduction
grammar
,
translation
quality
,
difference
,
aligners
,
author
,
raytheon
bbn
technology
,
th
aachen
university
,
system
,
different
paradigm
,
phrase
,
complexity
,
problem
,
system
,
various
assumption
,
different
level
,
processing
,
modeling
,
assumption
,
complemen
tary
information
,
output
,
multiple
mt
system
,
system
combination
,
availability
,
multiple
system
output
,
dar
pa
gal
program
,
nis
t
op
,
workshop
,
statistical
machine
translation
evaluation
,
research
,
combin
,
strength
,
diverse
mt
system
,
significant
gain
,
translation
quality
,
system
combination
method
,
lit
erature
,
category
,
hilde
brand,re-decoding
,
frederking
,
nirenburg
,
jayaraman
,
toutanova
,
confusion
network
,
confusion
network
decoding
,
lists1
,
surface
string
,
confu
sion
network
,
small
gain
,
speech
recognition
output
,
fiscus
,
first
application
,
confusion
net
work
decoding
,
mt
system
combination
,
bangalore
,
multiple
string
alignment
,
biological
se
quence
analysis
,
mt
system
,
matusov
,
alignment
,
alignment
,
extension
,
alignment
,
inversion
transduc
tion
grammar
,
confusion
net
work
,
different
hypothesis
alignment
algorithm
,
open
evalua
tions
,
workshop
,
statistical
machine
translation,callison-burch
,
comparison
,
popular
hypothesis
alignment
,
mt
system
output
,
wise
identical
combination
pipeline
,
tempts
,
quality
,
hypothesis
alignment
algorithm
,
alignment
,
system
output
,
common
test
set
,
nis
t
op
,
mt
evaluation
,
workshop
,
statistical
machine
translation
,
identical
pre-processing
,
coding
,
algorithm
,
alignment
quality
,
case
insensitive
ble
score
,
papineni
,
translation
quality
,
onfusion
network
,
confusion
network
,
linear
graph
,
consecutive
node
,
arc
repre
,
hypothesis
,
consecutive
node
,
alternative
word
,
position
,
hypothesis
,
network
,
special
nul
,
skipped
word
,
system
combination
output
,
example
,
hypothesis
,
twelve
car
,
dozen
car
,
twelve
big
blue
car
,
nul
l
null
car
dozen
nul
blue
car
,
alignment
,
confusion
network
,
figure
,
unique
hypothesis
,
figure
,
confusion
network
,
string
,
big
blue
car
,
twelve
car
,
dozen
blue
car
,
skeleton
,
number
,
parenthesis
,
corresponding
arc
,
building
confusion
network
,
multiple
ma
,
translation
system
,
main
prob
lem
,
output
,
skele
ton
hypothesis
,
final
word
order
,
system
combination
output
,
different
word
order
,
alignment
process
,
skeleton
se
lection
,
hypothesis
,
reference
string
,
decision
,
network
,
output
,
skeleton
,
large
lattice
,
subnetworks
,
latter
approach
,
prior
probability
,
alignment
statistic
,
different
statistic
,
weight
,
weight
,
subnetworks
,
hypothesis
alignment
algorithm
,
follow
ing
section
,
confusion
network
,
text
lattice
,
figure
,
arc
index
,
start
node
index
,
end
node
,
score
vector
,
word
label
,
score
vector
,
many
element
,
input
system
,
element
correspond
,
sys
tem
,
lattice
,
text
format
,
con
fusion
network
,
figure
,
arc
index
,
vector
,
arc
score
,
word
label
,
system
,
system
specific
word
confidence,1-best
system
output
,
hypothesis
,
a
n
ull
word
token
,
corresponding
element
,
nul
word
token
,
system
specific
word
score
,
system
weight
,
decoding
,
given
system
weight
,
system
specific
word
,
sc
element
,
weighted
word
score
,
number
,
input
system
,
hy
pothesis
score,log-word
score
,
logarithm
,
sequence
,
hypothesis
,
lm
score,number,non-null
word
,
evaluation
,
development
set,n-gram
language
model
re
,
lattice
,
synonym
,
consecutive
node
,
name
refers
,
confusion
network
structure
,
resemblance
,
sausage
,
unique
n-gram
context
,
lm
score
,
long
n-gram
context
,
memory
usage
,
uni
form
initial
system
weight
,
pruning
,
desirable
path,lattice,bi-gram
context
,
pruning
,
weight
,
lattice
,
optimizer
,
equation
,
simple
log-linear
inter
polation
,
standard
minimum
error
rate
training
,
exact
line
search
,
optimizer
client,bi-gram
decod
,
weight
optimization,5-gram
re,weight,300-best
list,bi-gram
,
lattice
,
3
h
ypothesis
alignment
algorithm
,
different
method
,
confusion
network
,
pairwise
,
incre
mental
alignment
,
pairwise
alignment
,
hypothesis
,
source
sentence
,
skeleton
hypothe
si
,
alignment
,
skeleton
word
,
anchor
,
confusion
net
work
,
matusov
,
hypothesis
,
different
word,skeleton,repetition,network,two-pass
alignment
algorithm
,
pairwise
ter
alignment
,
incremental
alignment
,
confusion
network
,
simple
graph
,
skeleton
hypothesis
,
hypothesis
,
partial
confusion
network
,
previous
hypothesis
,
hypothe
s
,
alignment
qual
ity
,
sentence
specific
alignment
order
,
unaligned
hypoth
esis
closest
,
partial
confusion
network
accord
,
alignment
algorithm
,
tar
get
language
translation
,
parallel
corpus
,
system
output
,
skeleton
,
translation
,
system
,
source
sentence
,
alignment
,
alignment
,
translation
,
direction
,
symmetrized
alignment
,
interpo
,
hmm
occupation
statistic
,
matusov
,
entire
test
set
,
alignment
model
parameter
,
word
align
ment
link
,
output
sentence
,
estimation
,
alignment
,
sentence
,
alignment
,
output
,
single
source
sentence
,
align
ment
,
monotone
one-to-one
alignment
,
confusion
network
,
aligner
,
incremental
indirect
hidden
markov
model
alignment
,
pairwise
alignment
,
system
output
,
parameter
,
variety
,
source
,
semantic
word
similarity
,
surface
word
sim
ilarity,distance-based
distortion
penalty
,
alignment
,
target
language
output
,
hidden
state
,
standard
viterbi
al
gorithm
,
alignment
,
pair
wise
ihm
,
aligner
,
iih
mm
,
incremental
inversion
transduction
grammar
alignment
,
flexible
matching
karakos
,
inversion
trans
,
grammar
,
pairwise
alignment
,
system
output
,
edit
distance
,
invwer
,
leusch
,
block
movement,substring,well-formed
sentence
,
arbitrary
shift
,
itg
algo
rithm
,
search
algorithm
,
itg
alignment,best-first
chart
parsing
,
charniak
,
search
heuristic
,
quadratic
complexity
,
manning
,
significant
reduction
,
computational
complexity
,
finite
state-machine
heuristic
computes
,
alignment
cost
,
string
,
arbitrary
word
re-orderings
,
itg
hypothesis
alignment
algorithm
,
karakos
,
novel
ver
sion
,
cost
function
,
stem
synonym
similarity
,
snover
,
sentence
specific
alignment
order
,
aligner
,
iit
gp
,
incremental
translation
edit
rate
alignment
,
flexible
matching
sim
,
translation
edit
rate
scorer3
,
pairwise
alignment
,
system
,
ter
scorer
try
,
edit
distance
,
shifted
reference
,
hypothesis
,
computational
complexity
,
heuristic
,
run
time
,
snover
,
ter
hypothesis
alignment
algorithm
,
synonym
,
stem
match
,
heuristic
,
flexible
matching
,
low
shift
,
edit
dis
tance
,
exact
match
,
new
position
,
sentence
specific
alignment
,
aligner
,
incremental
translation
edit
rate
plus
alignment
snover
,
sider
synonym
,
paraphrase
match
,
heuristic
,
paraphrase
,
reference
word
,
combina
tion
,
incremental
version
,
consensus
network
,
sentence
specific
alignment
order
,
aligner
,
ite
rp
,
4
e
xperimental
evaluation
combination
experiment
,
informal
system
combi
nation
track
,
nis
t
op
,
mt
evalua
tion4
,
system
com
bination
evaluation
,
workshop
,
sta
tistical
machine
translation,callison-burch
,
top-performing
system,case-insensitive
ble
,
language
pair
,
case
insensitive
ble
,
individual
system
,
tuning
,
test
set
,
sentence
,
reference
translation,arabic-english
tune
,
test
set
,
sentence
,
single
reference
translation,spanish-english
tune
,
test
set
,
system
output
,
confusion
network
,
hypothesis
alignment
algorithm
,
unpruned
english
bi-gram
,5
-
gram
lan
guage
model
,
evaluation
,
multiple
com
ponent
language
model
,
monolingual
corpus
,
source
,
separate
set
,
interpolation
weight
,
wmt
experiment
,
perplexity
,
english
reference
translation
,
previous
evaluation
,
st
mt08
,
sys
tem
combination
weight,bi-gram
lattice,5-gram
300-best
list
re-scoring
weight
,
lattice
,
hy
pothesis
alignment
algorithm
,
final
re-scoring
,
gov
iad
mig
test
,
resultsrelease
indexisc
,
html
output
,
sensitive
ble
score
,
statistical
significance
,
pairwise
comparison
,
boot
strapping
,
ite
rp
,
iih
mm
,
iit
gp
,
case
insensitive
ble
,
nis
t
mt,arabic-english
system
combination
output
,
reference
translation
,
decode
corre
sponds
,
result
,
weight
tuning
,
oracle
,
sponds
,
ter
oracle
,
significant
difference
,
aligners
,
ble
score,arabic-english
system
combination
output
,
first
column
,
decode
,
test
set
,
decoding
output
,
second
column
,
oracle
,
oracle
hypothesis
,
reference
translation
,
confusion
network
,
graph
ter
,
different
aligners
,
test
set
decoding
score
,
oracle
translation
,
decoding
,
difference
,
compactness
,
confu
sion
network
,
compact
network
,
signif
icant
part
,
reference
translation
,
reference
translation
,
compact
network
,
incremen
tal
alignment
algorithm
,
pairwise
,
incremental
ihm
,
flexible
matching
,
algorithm
,
incremental
ter
,
absolute
ble
gain
,
individ
ual
system
,
test
set
,
case
insensitive
ble
,
individual
system
,
test
set
,
source
language
,
decode
oracle
aligner
tune
test
tune
test
,
iih
mm
,
iit
gp
,
case
insensitive
ble,german-english
system
combination
output
,
single
reference
translation
,
segment
,
decode
,
result
,
weight
tuning
,
oracle
,
ter
oracle
,
significant
difference
,
ble
score,german-english
system
combination
output
,
graph
ter
oracle
score
,
decoding
score
,
ite
rp
,
iit
gp
,
flexible
match
,
absolute
ble
gain
,
individual
system
,
test
set
,
ble
score,spanish-english
system
combination
output
,
align
er
,
iih
mm
,
iih
mm
,
align
er
,
absolute
ble
gain
,
individual
system
,
case
insensitive
ble,spanish-english
system
combination
output
,
single
reference
translation
,
segment
,
decode
,
result
,
weight
tuning
,
oracle
,
ter
oracle
,
significant
difference
,
aligners
,
iih
mm
,
test
set
,
5
e
rror
analysis
error
analysis
,
system
combination
,
different
type
,
translation
error
,
system
combination
,
attempt
,
correlation
,
word
agreement
,
result
,
different
aligners
,
translation
error
,
snover
,
influence
,
error
type
,
individual
system
,
language
pair,per-sentence
er
rors
,
system
,
different
aligners
,
insertion
deletion
substitution
shift
,
ter
scorer
,
document
level
,
document
,
collection
,
number
,
individual
system
,
system
combina
tion
,
difference
,
difference
,
confidence
,
system
combination
,
significant
impact
,
paired
wilcoxon
test
,
probabil
ity
,
error
reduction
,
null
hypothesis
,
system
combina
tion
performs,system,condition,consideration,p-value
,
observation
,
alignment
scheme
,
number
,
substitution
shift
error
,
insertion
deletion
,
clear
trend
,
system
combination
,
number
,
insertion
deletion
,
individual
system
,
relationship
,
word
agreement
,
translation
error
,
experiment
,
rela
tionship
,
translation
error
rate
,
amount
,
agreement
,
align
ment
scheme
,
amount
,
system
agreement
,
number
,
con
fusion
network
arc
,
system
,
confusion
network
bin
,
example
,
agreement
,
figure
,
agreement
,
system
,
agreement
,
agreement
,
sys
tems
,
high
level
,
agreement
,
correctness
,
indicative
,
agreement
statistic
,
agreement
statistic
,
combined
system
,
agreement
statistic
,
half
non-null
word
,
word
weak
strong
weak
strong
arabic
,
regression
coefficient
,
agreement
feature
,
linear
model
,
target
,
combined
system
,
real
word
,
different
role
,
agreement
statistic
,
regression
,
generalized
linear
model
,
coefficient
,
agree
ment
quantity
,
align
ment
scheme
,
target
,
regression
coeffi
cients
,
negative
coefficient
,
agreement
quantity,non-null
word
point
,
good
aligners
,
reduction
,
translation
error
,
agreement
,
nul
token
,
6
c
onclusions
,
systematic
comparison
,
different
hypothesis
alignment
algorithm
,
mt
system
combination
,
confusion
network,pre-processing
,
decoding
,
alignment
algo
rithm
,
translation
quality
,
case
insensitive
ble
score
,
result
,
confusion
network
decod
,
significant
gain
,
individ
ual
system
irrespective
,
alignment
algorithm
,
difference
,
combination
output
,
different
alignment
algorithm
,
incremental
alignment
,
ter
translation
quality
,
align
ment
,
experiment
,
literature
,
incremental
ihm
,
novel
incremental
itg
,
quality
combination
output
,
error
analysis
,
language
aligner
,
sub
shft,2e-16
ihm,2e-16
arabic
iit
gp,2e-16
ite,2e-16
ite
rp,2e-16
giz,2e-16
ihm,2e-16
german
iit
gp,2e-16
ite,2e-16
ite
rp,2e-16
giz,2e-16
ihm,2e-16
spanish
iit
gp,2e-16
ite,2e-16
ite
rp,p-values
,
language
,
aligner
,
formance
gain
,
system
combination
,
reduction
,
substitution
error
,
word
re-ordering
error
,
alignment
,
sys
tem
output
,
agreement
rate
,
correlate
,
reduction
,
transla
tion
error
,
reference
necip
fazil
ayan
,
jing
zheng
,
wen
wang
,
alignment
,
confusion
network
,
machine
translation
system
,
coling
,
srinivas
bangalore
,
german
bordel
,
giuseppe
ric
cardi
,
consensus
translation
,
multiple
machine
translation
system
,
stephen
,
della
pietra
,
vincent
,
della
pietra
,
robert
,
mercer
,
mathematics
,
statistical
machine
translation
,
parameter
,
computational
linguistics
,
chris
callison-burch
,
philipp
koehn
,
christof
monz
,
zaidan
,
finding
,
workshop
,
statistical
machine
translation
,
eugene
charniak
,
sharon
goldwater
,
mark
johnson,edge-based
best-first
chart
parsing
,
sixth
workshop
,
large
corpus
,
morgan
kaufmann
,
jacob
devlin,antti-veikko
,
shankar
ananthakr
ishnan
,
spyros
matsoukas
,
system
combi
nation
,
discriminative
cross-adaptation
,
jonathan,fiscus,post-processing
system
,
reduced
word
error
rate
,
recognizer
output
vot
,
robert
frederking
,
sergei
nirenburg
,
kristina
toutanova
,
joint
opti
mization
,
machine
translation
system
combination
,
jianfeng
gao
,
patrick
nguyen
,
robert
moore,indirect-hmm-based
hy
pothesis
alignment
,
output
,
ma
chine
translation
system
,
hildebrand
,
stephan
vogel
,
combi
nation
,
machine
translation
system
,
hypothesis
selection,n-best
list
,
shyamsundar
jayaraman
,
alon
lavie
,
multi
engine
machine
translation
,
explicit
word
matching
,
damianos
karakos
,
jason
eisner
,
sanjeev
khudanpur
,
markus
dreyer
,
machine
translation
sys
tem
combination
,
alignment
,
damianos
karakos
,
sanjeev
khu
danpur
,
hypothesis
ranking,two-pass
ap
proaches
,
machine
translation
system
combination
,
dan
klein
,
christopher
,
manning
,
parsing
,
fast
exact
viterbi
parse
selection
,
philipp
koehn
,
statistical
significance
test
,
machine
translation
evaluation
,
gregor
leusch
,
nicola
ueffing
,
hermann
ney
,
novel
string-to-string
distance
measure
,
appli
cation
,
machine
translation
evaluation
,
september
,
incremental
hmm
alignment
,
mt
system
com
bination
,
lidia
mangu
,
eric
brill
,
andreas
stolcke
,
consensus
,
speech
recognition
,
word
error
minimization
,
application
,
confusion
net
work
,
computer
speech
,
language
,
evgeny
matusov
,
richard
zen
,
hermann
ney
,
symmetric
word
alignment
,
statistical
ma
chine
translation
,
evgeny
matusov
,
nicola
ueffing
,
hermann
ney
,
consensus
translation
,
multiple
machine
translation
system
,
hypothe
s
alignment
,
hermann
ney
,
systematic
comparison
,
various
statistical
alignment
model
,
computational
linguistics
,
minimum
error
rate
training
,
sta
tistical
machine
translation
,
kishore
papineni
,
salim
roukos
,
todd
ward
,
wei
jing
zhu
,
method
,
automatic
eval
uation
,
machine
translation
,
william
,
teukolsky
,
william
,
vetter
ling
,
flannery
,
numerical
recipe
,
cambridge
university
press
,
edition
,
spyros
matsoukas
,
rirchard
schwartz,word-level
system
com
bination
,
machine
translation
,
bing
xiang
,
spyros
matsoukas
,
richard
schwartz
,
necip
fazil
ayan
,
bonnie
,
output
,
multiple
machine
translation
system
,
bing
zhang
,
spyros
matsoukas
,
richard
schwartz
,
incremental
hypothesis
alignment
,
confusion
network
,
appli
cation
,
machine
translation
system
combination
,
proceeding
,
third
workshop
,
statistical
ma
chine
translation
,
bing
zhang
,
spyros
matsoukas
,
richard
schwartz
,
incremental
hypothesis
alignment
,
confu
sion
network
,
system
description
,
system
combination
task,antti-veikko
,
bing
zhang
,
spyros
matsoukas
,
richard
schwartz
,
system
combination
task
,
evgeny
matusov
,
jason
smith
,
necip
fazil
ayan
,
jason
eisner
,
damianos
karakos
,
sanjeev
khudanpur
,
gregor
leusch
,
hermann
ney
,
richard
schwartz
,
bing
zhang
,
jing
zheng
,
confusion
network
,
mt
system
combination
,
joseph
olive
,
caitlin
christianson
,
john
mcc
,
editor
,
hand
book
,
natural
language
processing
,
autonomous
language
exploitation
,
springer
,
khe
chai
sim
,
william
,
hichem
sahbi
,
woodland
,
con
sensus
network
,
statistical
machine
trans
lation
system
combination
,
matthew
snover
,
bonnie
dorr
,
richard
schwartz
,
micciula
,
john
makhoul
,
translation
edit
rate
,
human
annotation
,
matthew
snover
,
nitin
madnani
,
bonnie
dorr
,
richard
schwartz
,
fluency
,
adequacy
,
different
human
judgment
,
tunable
mt
,
stephan
vogel
,
hermann
ney
,
christoph
tillman
,
statistical
trans
lation
,
stochastic
inversion
transduction
grammar
,
bilingual
parsing
,
parallel
corpus
,
computational
linguistics
,
septem
ber
,
damianos
karakos
,
description
,
jhu
system
combination
scheme
