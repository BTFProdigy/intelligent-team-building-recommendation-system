proceeding
,
human
language
technology
conference
,
conference
,
empirical
method
,
vancouver
,
october
,
association
,
computational
linguistics
composition
,
conditional
random
field
,
transfer
learning
charles
sutton
,
andrew
mcc
,
department
,
computer
science
university
,
massachusetts
amherst
,
sutton
,
abstract
many
,
subtasks
,
much
training
data
exists
,
general
purpose
subtask
,
specific
new
task
,
transfer
learning
,
old
task
,
new
task
,
account
,
new
task
,
joint
decoding,separately-trained
sequence
model
,
uncertainty
,
information
,
new
task
,
predic
tions
,
old
task
,
standard
text
data
set
,
joint
decoding
outperforms
,
ntroduction
many
task
,
natural
language
processing
,
errorful
subtasks
,
information
extrac
tion,example,part-of-speech
tagging
,
shallow
parsing
,
main
extraction
task
,
subtasks
,
standard
set
,
labeled
training
data
,
example
,
many
large
data
set
,
person
name
,
newswire
text
,
available
training
data
,
new
application
,
appointment
information,regularity,well-studied
subtask
,
person
name
,
newswire
text
,
related
task
,
speaker
,
email
seminar
announcement
,
previous
nlp
system
,
transfer
,
subtask
,
prediction
,
feature
,
new
task
,
example
,
cent
con
ll
,
stan
dard
data
set
,
common
nlp
task
,
clause
iden
tification,named-entity
recognition
,
predic
tions,part-of-phrase
tagger
,
shallow
parser
,
feature
,
likely
sub
task
prediction
,
useful
dependency
,
subtask
prediction
,
new
task
,
final
output
,
problem
,
uncertainty
,
subtask
pre
diction
,
subtask
prediction
,
distribution
,
prediction
,
accurate
,
second
,
information
,
main
task
,
subtask
,
new
domain
,
different
charac
teristics
,
old
domain
,
standard
benchmark
data
set,example,named-entity
recog
nizers
,
newswire
text,off-the-shelf
named-entity
recognizer
,
email
task,domain-specific
feature
,
pre
vious
word
speaker
,
subtask
,
old
training
set
,
informa
tive
,
subtask
,
new
domain
,
previous
work
,
transfer
learning
,
old
task
,
new
task
,
new
task
,
prediction
,
transfer
,
cascade
,
single
model
,
decoding
,
dividual
model
,
great
freedom
,
feature
engineering
,
learning
,
richer
,
teractions
,
subtasks
,
linear
chain
crf
,
subtask
,
prediction
,
previous
subtask
,
feature
,
test
time
,
learned
weight
,
original
crf
,
single
grid-shaped
factorial
crf
,
prediction
,
viterbi
,
combined
model
im
,
possible
prediction
,
subtask
,
decision
,
main
task
,
joint
decoding
,
transfer
,
standard
email
data
set
,
standard
entity
recognition
task
,
email
data
set
,
significant
gain
,
performance
,
new
state-of-the-art
result
,
particular
interest
,
transfer
learning
,
joint
decoding
,
equivalent
result
,
training
data,inear-chain
crf
,
conditional
random
field
,
undirected
graphical
model
,
section
,
linear
chain
case,linear-chain
crf,conditionally-trained
finite
state
machine,linear-chain
crf
,
distribution
,
state
se
quences,first-order
markov
assumption
,
markov
assumption
,
distribution
,
sequence
factorizes
,
pairwise
function
,
partition
function
,
distribution
,
potential
function
,
transition
,
state
st
,
transition
probability
,
partition
function
,
sum
ming
,
many
possible
state
sequence
,
markov
assumption
,
node
marginals
,
viterbi
labeling
,
variant
,
standard
dynamic
programming
algorithm
,
potential
,
feature
,
model
parameter
,
real
weight
,
feature
,
feature
function
,
example
,
feature
function
,
label
spe
ak
-
er
name
,
label
oth
er
,
word
xt
,
capital
letter
,
chief
practical
advantage
,
conditional
model
,
ar
bitrary
highly-dependent
feature
,
distribution
,
generative
model,fully-labeled
training
instance
,
final
term,zero-mean
gaussian
prior
,
parameter
,
maxi
mization
,
closed
form
,
particularly
,
method
,
approximate
second-order
infor
mation
,
conjugate
gradient,limited-memory
bfg
,
information
,
current
training
method
,
pereira
,
3
d
ynamic
crf
dynamic
conditional
random
field,sutton,linear-chain
crf
,
dynamic
bayes
net
,
time
step
,
undi
rected
model,conditionally-trained
undirected
model
,
repeat
structure
,
parameter
,
sequence
,
repe
tition
,
clique
,
time
step
,
a
d
crf
,
probability
,
label
sequence
,
clique
template
,
input
feature
,
dcr
f,forward-backward
,
cross
product
state
space,cross-product
space
,
approximate
method
,
experience
,
loopy
belief
propagation,grid-shaped
dcr
f
,
inference
,
factorized
state
representation
,
parame
ters,fully-parameterized
linear
chain
,
cross
product
state
space
,
sutton
,
factorized
state
structure
,
interdependent
language
processing
task
,
particular
part-of-speech
tagging,noun-phrase
chunk
ing
,
previous
work
,
fcr
f
,
joint
training
,
single
training
set
,
cascade
,
many
task
data
,
example
,
syntac
tic
parse
tree
,
new
web
extraction
task
,
subtasks
,
freedom
,
standard
data
set,well-studied
subtasks,named-entity
recognition
,
4
a
lternatives
,
transfer
,
section
,
several
class
,
method
,
transfer
,
amount
,
interaction
,
principal
difference
,
method
,
individual
task
,
cascade
,
single
prediction
,
confidence
information
,
subtasks
,
main
type
,
transfer
learning
method
,
testing
,
traditional
approach
,
prediction
,
old
task
,
new
task
,
training
,
test
time
,
interaction
,
subtasks
,
performance
,
joint
training
,
family
,
ap
proaches
,
single
model
,
subtasks
,
example
,
caruana
,
multitask
learning
,
caruana
,
neural
net
work
,
classifica
tion
task
,
hidden
node
,
rep
resentation
,
trained
meth
od
,
interaction
,
computation
time
,
training
,
human
effort
,
joint
training
data
,
exact
inference,jointly-trained
model,forward-backward
,
siders
,
possible
subtask
prediction
,
confi
dence
,
probability
,
pre
diction
,
computational
efficiency
,
inference
method
,
particle
filtering
,
sparse
message-passing
,
limited
number
,
prediction
,
section
,
main
task
subtask
a
s
ubtask
b
i
nput
figure
,
graphical
model,jointly-decoded
crf
,
pairwise
clique
,
observed
input
,
diagram
,
cascaded
training
,
joint
model
,
subtasks
,
formance
,
approach
,
training
time
,
training
,
computational
effi
ciency
,
ability
,
standard
train
,
subtasks
,
test
time,separately-trained
model
,
sin
gle
model
,
joint
decoding
,
formation
,
cascaded
training
,
uncertainty
,
subtask
,
prediction
,
single
subtask
prediction
,
main
task
,
subtask
,
lattice
,
likely
prediction
,
confidence
,
advantage
,
training
procedure
,
joint
testing
procedure
,
possible
subtask
prediction
,
section
,
cascaded
training
,
transfer
learning,linear-chain
crf
,
training
time
,
subtask
prediction
,
confidence
infor
mation,cascaded-training
method
,
significant
gain
,
accuracy
,
5
c
omposition,section,individually-trained
linear-chain
crf
,
composi
tion
,
series
,
indi
vidual
crf
,
prediction
,
previous
crf
,
feature
,
feature
function
,
observed
input
,
transition
,
first
name
,
last
name
,
honorific
,
dash
wt
,
dash
wt
,
input
feature
,
seminar
data
,
position
,
pos
tag
,
position
,
training
data
,
penn
treebank
part-of-speech
tag,feature,hand-designed
regular
expression
,
several
token
,
previous
transducer
,
conjunction
,
input
feature
,
previous
transducer
,
example
,
feature
,
current
state
,
spe
akername
,
previ
ous
transducer
,
previ
ous
word
,
joint
decoding
,
test
time
,
composition
,
individual
crf
,
finite
state
transducer
,
new
linear-chain
crf
,
state
space
,
cross
product
,
individual
crf
,
transition
cost
,
transition
cost
,
individual
crf
,
state
set
,
weight
,
individual
crf
,
state
set
,
combined
crf
,
weight
,
individual
crf
,
single
feature
,
combined
model
,
graphical
model
,
combined
model
,
fac
torial
crf
,
figure
,
6
e
xperiments
,
joint
decoding,collection,e-mail
message
,
seminar
,
carnegie
mellon
uni
versity
,
freitag
,
seminar
,
location
,
speaker
,
data
set
,
sub
ject
,
much
previous
work
,
wide
variety
,
method
,
training
instance
f1
,
figure
,
learning
curve
,
seminar
,
speaker
field,10-fold
cross
validation
,
joint
training
performs
,
system
,
precision
,
recall
,
speaker
name
,
practical
system
,
message
,
many
different
people
,
ferent
way
,
announcement
information
,
finding
location
,
son
name,output,named-entity
tagger
,
use
ful
feature
,
indicative
feature
,
many
kind
,
person
name
,
seminar
announcement
,
example
,
faculty
host
,
departmental
secretary
,
sponsor
,
lecture
series
,
example
,
token
host
,
person
name
,
person
,
seminar
,
speaker
,
formance
,
prediction
,
a
c
rf
named-entity
tagger
,
standard
con
ll
,
english
data
set
,
con
ll
,
data
set
,
newswire
article
,
reuters
,
people
,
location
,
organization
,
miscellaneous
entity
,
seminar
announce
ments
data
set,named-entity
data
contains
,
training
,
seminar
announcement
data
set
,
training
,
previous
work
,
seminar
data,field-per-document
evaluation
,
single
field
value
,
viterbi
path
,
extraction
,
correct
,
true
field
mention
,
document
,
pute
precision
,
recall
,
convention
,
previous
work
,
system
stime
etime
location
speaker
overall
whi
sk
,
soderland
,
freitag
,
rap
ier
,
sno
w-ie
,
transfer
,
comparison
,
f1
performance
,
seminar
data
,
performs
,
decoding
,
overall
column,peshkin,pfeffer,10-fold
cross
validation
,
training
test
split
,
spherical
gaussian
prior
,
parameter
,
cascaded
training
performs
,
cascaded
training
,
compare
,
joint
decoding
,
previous
result
,
literature
,
previ
ous
work
,
different
feature
set,no-transfer
crf
baseline
,
impact
,
transfer
,
con
ll
data
set
,
feature
,
challenging
field
,
location
,
speaker
,
transfer
,
transfer
,
joint
decoding
,
cascaded
decod
,
speaker
,
error
reduction
,
joint
decoding
,
differ
ence
,
joint
decoding
,
speaker
,
paired
t-test
,
location
,
previous
work
,
ex
ample
,
location
,
system
,
trained
model,general-purpose
,
entity
tagger
,
newswire
text
,
long
run
,
capitalized
word
,
entity
,
email
announcement
,
capitalized
word
,
com
mon
,
formatted
text
block
,
location
,
baker
hall
host
,
michael
erdmann
,
situation
,
entity
tagger
,
entity
,
word
precedinghost,cross-validated
testing
set
,
occurrence
,
relevant
paper
,
evaluation
method
differs
,
previous
work
,
punctuation
wt
,
first
name
,
last
name
,
honorific
,
feature
,
feature
,
input
feature
,
ace
named-entity
data
,
position
,
training
data,wordhost,named-entity
tagger
label
,
entity
,
joint
decoding
,
occurrence
,
entity
,
joint
model
,
weight
,
difference
,
joint
model
,
account
information
,
seminar
label,named-entity
label,example,domain-specific
information
,
main
task
,
performance
,
general
purpose
subtask
,
figure
,
difference
,
performance
,
decoding
,
function
,
training
,
full
training
set
,
email
performs
,
training
instance
,
reduction
,
training
set
,
simple
,
training
method,well-studied
data
set
,
transfer
,
entity
recognition
,
section
,
result
,
joint
decoding
,
newswire
data
set
,
lapping
label
set
,
data
set
,
standard
entity
recognition
data
,
transfer
type
none
,
joint
person
name
,
gpe
name
,
comparison
,
f1
performance
,
training
,
geopolitical
entity
,
country
,
joint
decoding
,
common
noun
,
reference
,
result
,
small
subset
,
training
set
,
newspaper
,
newswire
,
broadcast
news
,
con
ll
entity
,
nition
data
set
,
entity
,
ace
data
,
annotation
,
entity
,
united
state
,
nominal
men
tions
,
entity
,
nation
,
input
text
,
similar
distribution
,
con
ll
ner
,
ace
data
set
,
label
distribution
,
current
state-of-the-art
system
,
ace
task
,
flo
rian
et,prediction,named-entity
recognizers
,
feature
,
cascaded
trans
,
experiment
,
transfer
,
datasets
,
joint
decoding
,
a
c
rf
entity
recognizer
,
ace
dataset,output,named-entity
entity
recog
nizer
,
con
ll
,
english
data
set
,
con
ll
recognizer
,
previous
experiment
,
result
,
subset
,
ace
training
data
,
feature
,
result
,
represen
tative
entity
type
,
decoding
,
transfer
,
transfer
,
joint
decoding
,
interestingly
,
joint
decoding
,
impact
,
nominal
reference
,
marked
improvement
,
cascaded
approach
,
elated
work
researcher
,
experimental
ev
idence
,
joint
training
,
formance
,
cascaded
approach
,
original
work
,
dynamic
crf
,
sutton
,
improvement
,
joint
training,domain,part-of-speech
tagging,noun-phrase
chunking
,
carreras
,
marquez
,
carreras
,
performance
,
clause
finding
,
cascade
,
perceptrons
,
single
global
error
function
,
miller
,
miller
,
entity
recognition
,
parsing
,
relation
extraction,jointly-trained
sin
gle
statistical
parsing
model
,
formance
,
subtasks
,
contribution
,
current
work
,
joint
decoding
,
joint
training,jointly-labeled
data
,
example
,
miller
,
al
report
,
newswire
article
,
parsing
,
relation
,
entity
,
annotation
,
relation
,
parse
tree
,
training
,
standard
statistical
parser
,
cascaded
train
ing
,
main
task
,
noisy
subtask
prediction
,
speech
community
,
weighted
finite-state
transducer
,
joint
decoding
,
method
ex
,
conditional
model
,
level
transducer
,
output
,
previ
ous
transducer
,
transducer
,
lexicon
,
exam
ple
,
phoneme
,
original
speech
signal
,
approach
,
enough
information,named-entity
label
,
example
,
extraction
,
original
word
,
conditional
model,weight,higher-level
transducer
,
arbitrary
feature
,
original
input
,
addi
tional
complexity,finite-state
structure
,
sequential
learning
,
potential
method
,
result
,
subtask
transducer
,
general
meta-learning
method
,
sequential
classification
,
base
classifier
,
time
step,higher-level
classifier
,
final
prediction
,
feature
,
window
,
prediction
,
base
classifier
,
transfer
learning
,
independent
base
model
,
independent
crf,named-entity
,
sem
inars,higher-level
crf
,
feature
,
prediction
,
base
model
,
8
c
onclusion
,
improves
,
interdependent
nlp
task
,
old
task,named-entity
recognition
,
accurate
system
,
rich
feature
,
conditional
model
,
new
task
,
diction
,
old
task
,
effect
,
joint
decoding
,
researcher
,
trained
model
,
standard
task,part-of-speech
tagging,named-entity
recognition
,
implication
,
standard
tool,result,off-the-shelf
nlp
tool,single-best
prediction,distribution,prediction,higher-level
task
,
acknowledgment
,
center
,
intelligent
,
formation
retrieval
,
central
intelligence
agency
,
national
security
agency
,
national
science
foundation
,
nsf
grant,s-0326249
,
department
,
acquisition
ser
vice
division
,
contract
number
nbc
hd030010,opinion,finding,conclusion,recommendation,material,author,sponsor,quasi-newton
matrix
,
limited
memory
method,program,pattern-match
rule
,
information
extraction
,
proceed
ings
,
sixteenth
national
conference
,
con
ll-2004
,
semantic
role
labeling
,
proceed
ings
,
con
ll-2004
,
global
feedback
,
phrase
recognition
,
neural
information
,
machine
learning
,
rule
induction
,
generalisation
,
proceeding
,
ternational
joint
conference
,
sequential
learning
,
international
joint
conference
,
artificial
intelli
gence
,
persistence
,
causation
,
multilingual
entity
detection
,
track
ing
,
information
extraction
,
informal
domain
,
doctoral
dissertation
,
carnegie
mellon
university
,
machine
learning
,
information
extraction
,
probabilistic
model
,
sequence
data
,
international
conf
,
ma
chine
learning
,
statistical
parsing
,
infor
mation
,
finite
state
transducer
,
speech
recognition
,
computer
speech
,
language
,
inference
,
sparse
belief
propagation
,
intelligent
information
retrieval
,
university
,
massachusetts
,
proceeding
,
international
joint
confer
ence
,
propo
sitional
algorithm
,
information
extraction
case
study
,
ternational
joint
conference
,
conditional
random
field
,
proceeding
,
hlt
-
naa
cl
,
information
extraction
rule
,
free
text
,
machine
learning
,
namic
conditional
random
field
,
factorized
probabilistic
model
,
sequence
data
,
proceed
ings,twenty-first
international
conference
,
con
ll-2003
,
entity
recognition
,
proceeding
,
canada
,
proceeding
,
human
language
technology
conference
,
north
american
chapter
,
new
york
,
association
,
computational
linguistics
reducing
weight
undertraining
,
structured
discriminative
learning
charles
sutton
,
michael
sindelar
,
andrew
mcc
,
department
,
computer
science
university
,
massachusetts
amherst
amherst
,
usa
casutton
,
student
,
abstract
discriminative
probabilistic
model
,
latitude
,
feature
,
involves
complex
trade-off
,
weight
,
indicative
feature,contribution,feature,weight,highly-indicative
feature
,
test
data
,
weight
undertraining
,
several
new
feature
,
method
,
separate
model
,
subset
,
original
feature
,
mixture
model
,
product
,
expert
,
method
,
logarithmic
opinion
pool,linear-chain
conditional
ran
dom
field,natural-language
task,feature-bagged
crf
performs
,
single
crf
,
feature
,
1
i
ntroduction
discriminative
method
,
probabilistic
model
,
wide
popularity
,
natural
language
pro
cessing,part-of-speech
tagging
,
toutanova
,
pereira
,
entity
recognition
,
taskar
,
conditional
probability
,
output
label
,
input
variable
,
joint
probability
,
generative
model
,
naive
bayes
classifier
,
hidden
markov
model
,
popularity
,
discriminative
model
,
great
flexibility
,
feature
,
distribution
,
input
feature
,
feature
,
training
,
inference
,
example
,
useful
feature
,
word
bi
gram,trigram,prefix,suffix,membership,domain-specific
lexicon
,
information
,
semantic
database,wordnet,hundred,thousand,million,feature,feature,performance,feature,accuracy,well-known
reason
,
feature
,
capacity
,
chance
regulari
tie
,
training
data
,
subtle
effect
,
new
feature
,
training
,
discrimi
native
model
,
regularized
logistic
regression
,
volves
complex
trade-off
,
weight
,
indicative
feature
,
contribution
,
feature
,
feature
,
indicative
,
output
,
strong
feature
,
test
data
,
effect
,
dean
pomer
leau
,
neural
network
,
vehi
cles
,
pomerleau
,
example
,
system
,
dirt
road
,
network
,
problem
learning
,
direction
,
network
,
network
,
prediction
,
identifiable
ditch
,
training
set
,
vehicle
,
network
,
feature
,
feature
,
training
,
test
time
,
dirt
road
,
detect
,
network
,
dependence
,
road
edge
,
desired
steering
direction
,
natural
way
,
undertraining
,
sep
arate
model
,
feature
,
driving
example
,
ditch
feature,side-of-the-road
feature
,
single
model
,
log
arithmic
opinion
pool
,
o
borne
,
several
new
combina
tion
method,mixture,per-sequence
,
transition
basis
,
general
class
,
method
feature
bagging,analogy,well-known
bagging
algorithm
,
ensemble
learning
,
method
,
conditional
random
field
,
sutton
,
mcc
allum,discriminatively-trained
undirected
model,natural-language
task
,
feature
bagging
performs
,
single
crf
,
available
feature
,
2
c
onditional
random
field
conditional
random
field
,
sutton
,
mcc
allum
,
undirected
graphical
model
,
conditional
distribution
,
undi
rected
graphical
model
,
random
vector
,
typical
special
case
,
labeling
,
observed
se
quence
,
clique
,
a
c
rf
model
,
conditional
probability
,
assignment
,
observed
variable
,
potential
function
,
partition
function
,
normalization
,
possible
label
assignment
,
potential
,
feature
,
model
parameter
,
real
weight
,
weight
,
feature
,
many
application,linear-chain
crf,first-order
markov
assumption
,
hidden
variable
,
clique
,
condi
tional
model
,
feature
function
,
feature
function
,
alpha
acc
urac
y
s
trong
feature
presentstrong
feature
,
figure
,
effect
,
single
strong
feature
,
feature
,
logistic
regression
,
synthetic
data
,
strength
,
strong
feature
,
top
line
,
strong
feature
,
training
,
test
time
,
bottom
line
,
strong
feature
,
training
data
,
test
time
,
example
,
binary
test
,
proper
noun
,
xt
begin
,
capital
letter,linear-chain
crf
correspond
,
state
machine,globally-normalized
extension
,
label
bias
problem
,
lafferty
,
number
,
state
sequence,linear-chain
crf
,
partition
function
,
node
marginals
,
viterbi
labeling
,
vari
ant
,
dynamic
programming
algorithm
,
section
,
simple
demonstration
,
weight
,
discriminative
classifier
,
neural
network
,
logistic
regression
,
strong
feature
,
effect
,
feature
,
weak
feature
,
indicative
put
,
effect
,
illustrative
experiment
,
logistic
regres
sion
,
strong
relation
,
chain
conditional
random
field
,
generalization
,
logistic
regression
,
independent
standard
normal
variable
,
output
,
binary
variable
,
probability
,
distribution
,
correct
decision
boundaryin
,
synthetic
problem
,
hyperplane
tangent
,
weight
vector
,
output
,
variable
alone
,
distribution
,
parameter
,
problem
,
variable
x
,
synthetic
model
,
analogy
,
pomer
leau
,
observation
,
xi
correspond
,
pomerleau
,
weak
feature
,
training
,
corresponds
,
indicative
feature
,
test
time
,
classifier
,
x
feature
,
training
time
,
test
time
,
several
value
,
weight
pa
rameter
,
regularized
logistic
regression
clas
,
instance
,
weak
variable
,
figure
,
amount
,
test
time
varies,strength,figure,randomly-generated
data
set
,
prediction
,
classifier
,
performance
,
test
time
,
classifier
,
performs
,
information
,
weak
feature
,
4
f
eature
bagging
,
section
,
feature
,
method
,
feature
,
collec
tion
,
feature
bag
,
individual
crf
,
feature
,
standard
map
training
,
individual
crf
,
single
com
,
averaging
,
several
way
,
probability
,
entire
sequence
,
individual
transition
,
arithmetic
mean
,
geometric
mean
,
combination
method,per-sequence
mixture
,
distribution
,
label
sequence
,
mixture
,
individual
crf
,
nonnegative
weight
,
combined
model
,
sequence
model
,
equation
,
pairwise
marginals
,
mixture
,
pairwise
marginal
probability
,
individual
mod
el,forward-backward
algorithm
,
mixture
model
,
individual
node
marginals
,
arg
maxyt,forward-backward
,
individual
crf
,
result
,
maximum
probability
sequence,linear-chain
distribution
pap
px
,
compute
themost
probable
sequence
,
pap
px
,
viterbi
algorithm,linear-chain
distribution
,
component
,
dis
tribution,linear-chain
distribution
,
mixture
weight
,
variety
,
equal
voting
,
traditional
bag
ging,per-sequence
product
,
expert
,
log
arithmic
opinion
pool
,
distribution
,
label
sequence
,
product
,
expert
,
hinton
,
product
,
expert
,
probability
,
individual
model
,
geometric
mean
,
arithmetic
mean
,
nonnegative
weight
,
product
model
,
combined
model
,
condi
tional
random
field
,
feature
,
log
prob
ability
,
original
model
,
crf
definition
,
equation
,
single
crf
,
parameter
,
weighted
average
,
original
parameter
,
product
method
,
family
,
mod
el
,
standard
training
,
single
crf
,
available
feature
,
parameter
,
bagged
model
,
nevertheless
,
section
,
feature
,
method
performs
,
standard
crf
training
,
combination
method
,
individual
model
,
probability
,
en
tire
sequence
,
sequence
model
,
probability
,
individual
transition
,
transition
proba
bilities
,
probabilistic
inference
,
original
crf
,
combination
method,per-transition
mixture
,
transition
probability,difference,per-sequence
,
per-transition
mixture
,
understood
genus
,
label
sequence,per-sequence
model
,
mix
ture
component,component,per-transition
model
,
component
,
component
,
component
,
gener
ate
,
second
component,per-transition
product
,
expert
,
transition
distribution
,
product
model
psp
,
transition
distribution,per-sequence
case,exponential-family
distribu
tion
,
feature
,
log
transition
proba
bilities
,
individual
model,per-sequence
product,weight-averaging
trick
,
probability
,
marginal
probability
,
sequence
distribution,per-transition
product
,
label
bias
,
feature
,
future
,
account
,
marginal
probability
,
combination
method
,
method
,
per
sequence
product
,
expert
,
combination
method
,
next
section
,
combination
method
,
several
sequence
label
,
concreteness
,
sequence
model
,
arbitrary
graphical
structure
,
natural
language
task
,
entity
recognition,noun-phrase
chunk
,
standard
con
ll
,
english
data
set
,
reuters
newswire
,
training
set
,
sentence
,
development
set
,
sentence
,
testing
set,sentence,named-entity
label
,
data
set
corresponding
,
location
,
organization
,
tities
,
second
task
,
standard
con
ll
,
data
set
,
sentence
,
training
,
sentence
,
test
ing
,
wall
street
journal
article
,
penn
treebank
project
,
con
ll
,
data
set
,
chunk
type
,
np
chunk
,
precision
,
recall
,
entity
,
con
ll
,
chunk
actual
chunk
,
harmonic
mean,precision,recall,per-sequence
product-of-experts
feature
,
feature
bag
,
prior
experience
,
data
set
,
experiment
,
baseline
crf
,
feature
set
,
feature
,
lexical
identity
,
regular
expression
,
individual
crf
,
a
g
aussian
prior
,
parameter
,
entity
task
,
feature
bag
,
character
ngrams
,
lexicon
,
baseline
feature
,
word
identity
,
regular
expression
,
ngram
crf
,
cludes
binary
feature
,
character
ngrams
,
length
,
word
prefix
,
suffix
,
length
,
lexicon
crf
,
membership
feature
,
variety
,
lexicon
,
people
,
company
,
combined
model
,
feature
,
mixture
weight
,
velopment
set
,
chunking
task
,
feature
set
,
speech
,
lexicon
,
baseline
feature
,
regular
expres
sion
,
word
identity
feature
,
entity
task
,
first
bag,part-of-speech
tag
,
brill
tagger
,
conjunction
,
pereira
,
second
bag
us
,
membership
feature
,
lexicon
,
people
,
organization
,
ad
dition,part-of-speech
lexicon
,
entire
treebank
,
brill
tagger
,
feature
,
mixture
weight,2-fold
cross
valida
tion
,
chosen
model
,
lexicon
model
,
ngram
model
,
data
set
,
bagged
model
performs
,
single
crf
,
feature
,
entity
task
,
improves
performance
,
substantial
error
reduc
tion
,
result
,
data
set
,
large
amount
,
unlabeled
data
,
chunking
task
,
performance
,
error
reduction
,
data
set
,
improvement
,
chunking
task,matsumoto,pereira,currently-best
re
sults
,
large
amount
,
unlabeled
data
,
lexicon
,
previous
model
,
additional
fea
tures
,
original
crf
,
feature
,
lexicon
,
performance
,
method
,
sec
tion,pre-transition
mixture,pre-transition
product,expert,per-sequence
mixture
,
tity
data
,
statistical
tie
,
significant
difference
,
performance
,
last
section
,
model
f1
per-sequence
product,per-transition
product,per-sequence
mixture,per-transition
mixture
,
comparison
,
method
,
con
ll
,
named
entity
task
,
model
f1
single
crf
,
base
feat
,
single
crf
,
combined
crf
,
result
,
con
ll
,
named
entity
task
,
bagged
crf
performs
,
single
crf
,
available
feature,procedure,per-sequence
mixture
,
approx
imate
,
different
decoding
procedure
,
node
marginals
,
ter
performance
,
revious
work
,
machine
learning
literature
,
much
work
,
ensemble
method
,
stacking
,
boosting
,
bag
ging
,
ensemble
,
classifier
,
different
subset
,
ferent
feature
,
literature
,
feature
subset
,
ensemble
,
cision
tree
,
feature
subset
,
standard
decision
tree
learner,nearest-neighbor
classifier
,
breiman
,
ran
dom
forest
,
ensemble
,
random
decision
tree
,
random
feature
,
literature
,
accuracy
,
classifier
,
variance
,
robustness
,
classifier
,
available
feature
,
algorithm
featureboost,adaboost,meta-learning
algorithm
,
weight
,
feature
,
stance
,
feature
subset
,
feature
,
ensemble
,
prediction
,
featureboost
,
adaboost
,
uci
data
set
,
method
,
quence
model,natural-language
model
,
hundred
,
thousand
,
feature
,
model
f1
single
crf
,
base
feat
,
single
crf
,
pereira
,
matsumoto
,
combined
crf
,
result
,
con
ll
,
chunking
task
,
bagged
crf
performs
,
re
sults
,
large
amount
,
unlabeled
data
,
capital
letter
wt
,
capital
letter
,
single
capital
letter
wt
,
capital
letter
,
lowercase
wt
,
numeric
character
wt
,
numeric
character
,
number
wt
,
string
,
period
wt
end
,
period
wt
,
dash
wt
,
acronym
wt
,
initial
wt
,
single
letter
wt
,
punctuation
wt
,
quotation
mark
pt
,
feature
,
baseline
feature
,
position
,
pos
tag
,
position
,
training
data
,
chunk
tag
,
training
data,feature,hand-designed
regular
expression
,
ensemble
,
sequence
model
,
unstructured
classifier
,
example
,
hofmann
,
johnson
,
boosting
algorithm
,
sequence
model
,
instance
,
feature
,
main
advantage
,
technique
,
model
sparseness
,
feature
,
accuracy
,
robustness
,
present
work
,
log
arithmic
opinion
pool,per-sequence
mixture
,
expert
,
previous
work
focus
,
many
feature
,
several
simpler
model
,
contrast
,
feature
bag
,
feature
undertraining
,
several
model
,
complementary
feature
set
,
current
positive
result
,
reduction
,
fitting
,
train
ing
,
feature
undertraining
,
overfitting
,
fea
tures
,
training
,
test
ing
,
particular
type
,
choice
,
feature
bag
,
contribution
,
present
work
,
careful
choice
,
feature
bag,state-of-the-art
performance
,
concurrently
,
osborne
,
similar
experiment
,
con
ll-2003
data
set,per-sequence
mixture
,
expert
,
logarithmic
opinion
pool
,
lexi
con
feature
,
work
present
,
detailed
error
analysis
,
present
result
,
combination
method
,
7
c
onclusion
discriminatively-trained
probabilistic
model
,
much
success
,
application
,
flexibil
ity
,
feature
,
indicative
feature
,
performance
,
undertrain
ing,highly-indicative
feature
,
training
,
feature
,
solution
,
feature
bag
ging
,
feature
subset
,
sepa
rate
model
,
subset
,
individual
model,real-world
natural-language
processing
task
,
feature
,
perfor
mance
,
feature
subset
,
subset
,
intuition
,
feature
,
feature
,
interesting
area
,
future
work
,
acknowledgment
,
jerod
weinman
,
max
welling
,
helpful
conversation
,
center
,
intelligent
infor
mation
retrieval
,
cen
tral
intelligence
agency
,
national
security
agency
,
national
science
foundation
,
central
intelligence
agency
,
national
security
agency
,
national
science
foundation
,
opin
ion
,
finding
,
conclusion
,
recommendation
,
material
,
author
,
sponsor
,
reference
yasemin
altun
,
thomas
hofmann
,
mark
johnson
,
discriminative
,
label
sequence
,
advance
,
neural
information
process
,
rie
ando
,
tong
zhang,high-performance
semi-supervised
learning
method
,
text
chunking
,
proceeding
,
annual
meeting
,
asso
ciation
,
ann
arbor
,
michigan
,
association
,
com
putational
linguistics
,
stephen
,
neighbor
classifier
,
multiple
feature
subset
,
fifteenth
international
con
ference
,
machine
learning
,
morgan
kaufmann
publisher
inc
,
leo
breiman
,
random
forest
,
machine
learn
ing
,
october
,
eric
brill,advance,transformation-based
part
,
speech
tagging
,
proceeding
,
twelfth
national
conference
,
artificial
intelli
gence
,
american
association
,
artificial
intelligence
,
robert
bryll
,
ricardo
gutierrez-osuna
,
francis
quek
,
bagging
,
accuracy
,
classifier
ensemble
,
random
feature
sub
set
,
pattern
recognition
,
hai
leong
chieu
,
tity
recognition
,
maximum
entropy
approach
,
walter
daelemans
,
mile
osborne
,
editor
,
pro
ceedings
,
con
ll-2003
,
edmonton
,
canada
,
radu
florian
,
abe
ittycheriah
,
hongyan
jing
,
tong
zhang
,
entity
recognition
,
combination
,
proceeding
,
hinton
,
product
,
expert
,
contrastive
divergence
,
technical
report
,
random
decision
forest
,
document
analysis
,
recognition
,
montreal
,
canada
,
matsumoto
,
sup
port
vector
machine
,
proceeding
,
pereira
,
con
ditional
random
field
,
probabilistic
model
,
seg
menting
,
sequence
data
,
inter
national
conf
,
machine
learning
,
andrew
mcc
allum
,
dayne
freitag
,
fernando
pereira
,
maximum
entropy
markov
model
,
information
extraction
,
segmentation
,
international
conf
,
machine
learning
,
morgan
kaufmann
,
john
langford
,
rich
caruana
,
avrim
blum
,
featureboost
,
algorithm
,
robustness
,
interna
tional
conference
,
machine
learning
,
dean
pomerleau
,
neural
network
vision
,
robot
driving
,
editor
,
handbook
,
brain
theory
,
neural
network
,
fei
sha
,
fernando
pereira
,
shallow
par
,
conditional
random
field
,
proceeding
,
hlt
-
naa
cl
,
association
,
computational
linguistics
,
andrew
smith
,
mile
osborne
,
gazetteer
,
discriminative
information
extraction
,
con
ll-x
,
tenth
conference
,
computational
natu
ral
language
learning
,
andrew
smith
,
trevor
cohn
,
mile
osborne
,
logarithmic
opinion
pool
,
conditional
random
field
,
proceeding
,
annual
meet
ing
,
association
,
ann
arbor
,
michigan
,
association
,
computational
linguistics
,
charles
sutton
,
andrew
mcc
allum
,
troduction
,
conditional
random
field
,
relational
learning
,
lise
getoor
,
ben
taskar
,
editor
,
intro
duction
,
ben
taskar
,
dan
klein
,
michael
collins
,
daphne
koller
,
chris
manning,max-margin
parsing
,
empirical
method
,
dan
klein
,
christopher
,
manning
,
yoram
singer,feature-rich
part-of-speech
tagging
,
cyclic
dependency
network
,
hlt
-
na
acl
,
proceeding
,
conference
,
ann
arbor
,
association
,
computational
linguistics
joint
parsing
,
semantic
role
labeling
charles
sutton
,
andrew
mcc
,
department
,
computer
science
university
,
massachusetts
amherst
,
usa
casutton
,
abstract
striking
feature
,
human
syntactic
pro
cessing
,
account
seman
tic
information
,
discourse
con
text
,
world
knowledge
,
insight
,
srl
result
,
gold
par,automatically-generated
par
,
semantic
role
labeling
,
probabilistic
srl
system
,
result
,
probabilistic
parser
,
cur
rent
result
,
trained
srl
model
,
inaccurate
probability
estimate
,
1
i
ntroduction
,
much
effort
,
statistical
parsing
model
,
many
application
,
parse
tree
error
,
parser
,
ma
jor
source
,
final
output
,
promising
approach,problem,higher-level
task
,
joint
prob
abilistic
model
,
uncertainty
,
parser
output,k-best
list
,
informa
tion,higher-level
processing
,
example
,
miller
,
parsing
,
information
extraction
,
joint
model
,
performance
,
attachment
decision
,
im
portant
,
semantic
analysis,higher-level
semantic
analysis
,
recent
interest
,
semantic
role,opportunity,higher-level
se
mantic
information
,
syntactic
parsing
,
previous
work
,
srl
system
,
full
parse
information
perform
,
shallow
parse
information,machine-generated
par,human-corrected
gold
par
,
investigation
,
srl
result
,
gold
par
,
au
tomatic
par
,
semantic
role
labeling
,
single
probabilistic
model
,
parsing
,
state
of-the-art
system
,
prediction
,
principled
way,probability,k-best
parse
tree
,
probabilistic
parser
,
srl
system
,
ap
proaches
,
log
proba
bilities
,
reranker
,
parse
tree
,
srl
frame
,
manner
,
collins
,
method
performs
,
parse
tree
,
reason
,
reason
,
ranking
,
parse
tree
,
semantic
role
,
2
b
ase
srl
system
,
approach
,
parsing
,
base
srl
system
,
standard
architec
ture
,
literature
,
base
srl
system,cascade,maximum-entropy
classifier
,
semantic
argument
label
,
constituent
,
full
parse
tree
,
system
,
pruning
,
identification
,
classifica
tion
,
pruning
,
deterministic
pre
processing
procedure
,
palmer
,
many
constituent
,
argument
,
second
,
identification
,
binary
maxent
classifier
,
ing
constituent
,
base
feature
,
feature
,
base
identification
classi
fier
,
high
probability
,
classification
,
multi
class
maxent
classifier
,
argu
ment
type
,
constituent
,
clas
sifer
,
option
,
output
nul
,
semantic
argu
ments
,
local
classifier
,
global
constraint
,
account
,
overlap
,
notation
,
overlap
,
simple
recur
sive
algorithm
,
parent
node,descendent,probability,parent,locally-predicted
argument
label
,
descen
dants
,
descendant
,
op
timal
labeling,parent,non-overlapping
assignment
,
confidence
,
sentence
,
development
set
,
classifier
,
propbank
section
,
true
semantic
argument
,
bracketing
,
parse
tree
,
identification
,
classification
model
,
gold
parse
tree
,
feature
,
standard
feature
,
previous
work,maximum-entropy
implementation
,
parameter
,
parse
tree
using
srl
information
,
general
framework
,
rerank
,
method
,
next
section
,
joint
probability
model
,
semantic
frame
,
parse
tree
,
sentence
,
standard
probabilistic
parsing
model
,
base
line
srl
model
,
feature
,
baseline
labeling
classifier
,
srl
f1
gold
,
gold
parse
f1
,
gold
frame
f1
,
simple
srl
combination
,
chosen
,
trained
reranker
,
comparison
,
overall
srl
f1
,
devel
opment
,
parse
tree
,
reranking
approach,reranking,k-best
parse
tree
,
sentence
,
base
srl
model
,
result
,
reranker
,
method
,
parse
tree
,
parse
tree
,
pre
diction
,
base
model,k-best
list
,
implementation
,
michael
collins
,
parser
,
section
,
wsj
treebank
,
development
,
test
set,k-best
list
,
implementation
,
dynamic
programming
,
aggressive
beam
search
,
maximum
,
feasible
beam
width
,
mean
number
,
sentence
,
4
r
esults
,
discussion
,
section
,
present
result
,
several
rerank
,
method
,
joint
parsing
,
semantic
role
la
,
beling
,
development
set
,
method
,
baseline
system
,
present
baseline
,
gold
tree
,
previous
work
,
gold
tree
,
baseline
,
maximum
possible
performance
,
reranking
system
,
srl
performance
,
parse
tree
,
parse
tree,k-best
list
,
gold
tree
,
expected
performance
,
approach
,
srl
performance
,
parse
tree
,
gold
frame
,
signifi
cant
gap,parse-f1-reranked
tree
,
srl
f1-reranked
tree
,
promise
,
joint
reranking
,
srl
f1-reranked
tree
,
gold
parse
tree
,
parse
list
,
srl
performance
,
parse
tree
,
score
combination
equation
,
straightforward
method
,
parse
tree,k-best
list
,
log
probability
,
parser
,
base
srl
system
,
individual
probability
,
weighted
combination
,
speech
community
,
lan
guage
model
,
method
performs,choice,performs,1-best
predicted
parse
tree
,
srl
score
,
combined
system
performs
,
problem
,
bad
parse
tree
,
many
node
,
constituent
,
bad
tree
,
weight
,
srl
score
,
unlabeled
re
call
drop
,
decrease
,
unlabeled
recall
,
reranker
,
global
feature
,
potential
solution
,
problem
,
feature
,
entire
frame
,
example
,
key
argu
ments
,
feature
,
en
tire
frame
,
local
clas
sifiers
,
global
feature
,
linear
classifier
,
parse
frame
pair
,
ranked
list
,
manner
,
collins
,
semantic
role
labeling
,
toutanova
,
several
feature,difference,toutanova,k-best
srl
frame
,
single
parse
tree,1-best
srl
frame,k-best
parse
tree
,
computational
expense,k-best
parse
tree
list
,
sentence
,
reranker
,
section
,
treebank
,
subset
,
previ
ous
con
ll
competition
,
reranker
,
logloss
,
boosting
loss
,
collins
,
reranker
,
parse
tree,globally-trained
reranker
,
fea
tures
,
local
model
,
following
global
feature
,
linear
se
quence
,
argument
label
,
log
probability
,
parse
tree
,
argument
,
binary
feature
,
conjunction
,
predicate
,
feature
,
number
,
argument
type
,
result
,
system
,
development
set
,
score
combination
method,1-best
parse
tree
,
limited
training
set
,
reranking
model
,
base
srl
model
,
section
,
com
parison
,
modest
improvement
,
system
,
offi
cial
submission
,
result
,
test
set
,
parse
tree
,
section
,
different
approach
,
rerank
,
parse
tree
,
poor
parse
tree
,
se
mantic
labeling
,
high
score
,
good
parse
tree
,
good
semantic
frame
,
semantic
frame
,
precision
recall
,
development
,
test
wsj
,
test
wsj
precision
recall
,
overall
result
,
detailed
result
,
wsj
test
,
bottom
,
sum
ming
,
parse
tree
,
practical
advantage,approach,seemingly-good
parse
tree
,
constituent
,
semantic
argument
,
many
parse
tree,k-best
list
,
sin
gle
parse
,
constituent
,
parse
tree
,
constituent
,
different
tree
,
algorithm
,
appropriate
independence
assump
tions
,
srl
model
,
particular
parse
tree
,
initial
experi
ments
,
detailed
exploration
,
future
work
,
6
c
onclusion
,
related
work
,
several
method
,
parse
tree
,
information
,
se
mantic
role
labeling,improvement,1-best
parse
tree
,
gildea
,
jurafsky
,
gildea
,
jurafsky
,
result
,
srl
system
,
negative
result
,
result
,
a
m
axent-trained
srl
model,probability,result,collins-style
reranking
,
definite
conclusion
,
po
tential
improvement
,
future
work,max-sum
approach,promise,pitfall,max-max
reranking
approach
,
acknowledgement
,
center
,
intelligent
information
retrieval
,
national
science
foundation
,
nsf
grant
,
department
,
acquisition
ser
vice
division
,
contract
number
nbc
hd030010
,
opinion
,
finding
,
conclusion
,
recommendation
,
material
,
author
,
sponsor
,
reference
daniel
,
intricacy
,
collins
,
computational
linguistics
,
michael
collins
,
discriminative
reranking
,
natu
ral
language
parsing
,
international
conf
,
machine
learning
,
morgan
kaufmann
,
daniel
gildea
,
daniel
jurafsky
,
automatic
labeling
,
semantic
role
,
computational
linguistics
,
andrew
kachites
mcc
allum
,
mallet
,
machine
learn
,
language
toolkit
,
scott
miller
,
heidi
fox
,
ramshaw
,
weischedel
,
novel
use
,
statistical
parsing
,
tract
information
,
mihai
surdeanu
,
sanda
harabagiu
,
john
williams
,
paul
aarseth,predicate-argument
structure
,
formation
extraction
,
kristina
toutanova
,
aria
haghighi
,
christopher
,
improves
semantic
role
labeling
,
nianwen
xue
,
martha
palmer
,
feature
,
semantic
role
labeling
,
proceeding
,
confer
ence
,
empirical
method
,
natural
language
process
