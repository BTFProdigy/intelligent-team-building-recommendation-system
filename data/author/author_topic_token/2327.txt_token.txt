proceeding
,
joint
conference
,
empirical
method
,
natural
language
processing
,
computational
natural
language
learning
,
prague
,
association
,
computational
linguistics
recovery
,
empty
node
,
parse
structure
denis
filimonov1
,
harper1
,
mharper
casl
,
edu
abstract
,
new
algorithm,wh-trace
empty
node,approach,hand-written
pattern
,
probabilistic
model
,
pattern
,
regu
lar
expression
,
pertinent
tree
structure
,
limited
number
,
pat
tern
,
probabilistic
model
,
approach
,
pattern
,
terminal
,
production
rule
,
algorithm
,
performance
,
gold
tree
,
parser
output
,
differ
ent
metric,method,state-of-the-art
algorithm,wh-traces
,
1
i
ntroduction
,
new
algorithm,wh-trace
empty
node
,
gold
parse
tree
,
penn
treebank
,
problem
,
handful
,
researcher
,
variety
,
parse
tree
,
logical
representation
,
structured
representation
,
language
mod
,
example
,
superarv
language
model
,
harper
,
lexical
feature
,
syntactic
constraint
,
word
error
,
english
speech
recognition
task
,
superarv
lm
training,state-of
the-art
parser,material,rule-based
transformer
,
superarv
representation
,
transformer
,
treebank
par
,
parser
lack
,
im
portant
type
,
information
,
wh
trace
,
accurate
ex
traction
,
superarvs
,
approach
,
problem
,
empty
node
recovery
fall
,
category
,
dienes
,
empty
node
,
pas
string
,
parser
,
performance
,
johnson
,
impact
,
parser
performance,collins,wh-traces
,
parser
,
sertion
accuracy,research,post-processing
,
parser
output,johnson,corpus-induced
pattern
,
gold
standard
tree
,
parser
output,campbell,hand-written
rule
,
gap
insertion
,
machine
,
method
,
higgins
,
manning
,
gabbard
,
probabilistic
model
,
pattern
,
tree
matching,insertion,wh-traces
,
insert
trace,non-null
wh-phrases
,
effort
differs
,
previous
ap
proaches
,
algorithm
,
insertion
,
small
set
,
ex
pressive
pattern
,
probabilistic
grammar-based
model,tree-matching
pattern
,
parse
tree
,
pattern
,
figure
,
pattern
,
subtree
,
propagation
,
terminal
level
,
pattern
,
directed
edge
,
ince
tree-matching
pattern,top-down
fashion
,
multiple
pattern
,
subtree
,
alternative
way
,
probabilistic
model
,
alterna
tive
path
,
pattern
,
whn
trace,example,tree-matching
pattern
,
notation
,
string
,
tween
position
,
unary
chain
,
subtree
,
gap
location
gab
,
gaptype
,
ancstr
,
gaptype
,
a
w
hnp
trace
,
ances
tor
,
indicating
,
location
,
final
location
,
ancstr
,
ancstr
,
probability
,
gaptype
,
ancestor
,
notation
,
location
,
parse
tree
,
alternative
,
argmax
,
gap
location
,
subtree
,
parse
tree
,
root
node
,
ancestor
node,wh-phrase
,
wh-node
,
gaptype
,
notation
,
root
label
,
appropri
ate,tree-matching
pat
tern
,
function
,
parse
tree
,
gap
type
,
gap
gabcd
,
special
value
,
failure
,
application
,
pattern
,
gaptype
,
application
,
pattern
,
gaptype
,
gaptype
,
gaptype
,
pattern
,
spe
cific
gap
type
,
gaptype
,
notation
,
application
,
function
,
gaptype
,
pattern
,
arbitrary
subtree
,
example
,
pattern
application
,
figure
,
relative
clause
,
whn
p-phrase
,
location
,
subtree
,
sister
node
,
viewer
,
conjunction
,
alternative
definition
,
pattern
,
simplicity
,
conjunction
,
following
dis
cussion
,
little
impact
,
development
,
figure
,
pattern
application
example
,
pattern
p1
,
tree
t28
indicating
,
subtree
t38
,
process
,
pat
tern
,
pattern
p4
,
ex
act
location
,
pattern
application
example
suppose
,
addition
,
pattern
applica
tions
,
figure
,
sequence
,
plausible
location
,
figure
,
notice
,
combination
,
sequence
,
pattern
,
figure
,
pattern
,
structure
,
tree
class
,
number
,
unique
subtrees
,
wh
phrase
,
optional
adverbial
,
char
p1
p2
p3c
,
pattern
,
pattern
,
small
set
,
pattern
application
,
pattern
,
pattern
,
tree
tij
,
recursive
application
,
sequence
,
pattern
,
pattern
set
,
result
,
consequent
application
,
pattern
,
subtree
,
example
,
application
,
function
,
pattern
chain
,
particular
tree
,
pseudocode
,
function
,
function
,
pat
tern
chain
,
application
,
concrete
gap
location
,
algorithm
,
finite
depth
,
pattern
,
gap
location
,
iteration
,
function
,
tree
tij
,
indpcs
,
element
,
element
,
function
findpcs
,
allpcs
,
concrete
location
allpcs
,
allpcs
,
allpcs
,
return
allpcs
function
findpcs
,
pseudocode
,
findpcs
,
conjunction
,
function
find
-
pc
,
case
app
,
pseudocode
,
figure
,
a
g
ap
automaton
,
pattern
chain
,
function
findpcs
,
pattern
tree
,
pattern
,
example
,
pattern
tree
,
figure
,
corresponds
,
figure
,
pattern
tree
,
history
,
gap
prop
agations
,
pattern
p1
,
subtree
,
p2
yield
subtree
,
pattern
p4
match
,
exact
gap
location
,
pattern
tree
,
automaton
,
pattern
application
,
transition
,
meaning
,
representation
,
pattern
chain
,
insertion
,
example
,
representation
,
regular
grammar
,
pattern
,
terminal
,
function
crossprod
,
pcj
return
prod
function
findpcs
,
findpcs
,
pc
newpcs
,
branch
,
conjunction
,
figure
,
pseudocode
,
findpcs
,
conjunction
powerset,non-terminals
,
detail
,
start
symbol
,
production
rule
,
pattern
,
pattern
tree
,
original
tree
,
example
,
something
,
viewer
,
pattern
chain
belongs
,
different
tree
class
,
problem
,
additional
con
straints
,
grammar
,
grammar
,
tree
class
,
start
state,transition,element,terminal,left-hand
side
,
production
,
sequence
,
terminal
becomes
,
grammar
,
grammar
,
question
,
probability
,
parse
tree
,
string
,
grammar
,
question
,
probability
,
string
,
grammar
,
genus
tive
model
,
gap
insertion
,
pattern
grammar
let
,
pattern
grammar
,
pattern
,
terminal
patterns3
,
subset
,
pattern
,
powerset
,
terminal
,
special
symbol4
,
non
terminal
,
start
symbol
,
production
,
following
set
,
powerset
,
nonterminal
transi
tions,non-terminal
pat
tern
,
terminal
transition
,
termi
nal
pattern
,
rule
model
conjunction
,
branch
,
gap
model
given
,
grammar
,
previous
subsec
tion
,
probabilistic
model
,
sertion
,
argmax
,
probability
,
sentence
,
probability
,
prob
ability
,
proba
bilities
,
pattern
chain
,
generate
exact
position
,
branch
,
string
,
con
junction
,
definition
,
approximation
,
detail
,
insertion
,
pattern
tree
,
pattern
chain
abd
gm
,
bold
line
,
pattern
,
figure
,
probability
,
pattern
chain
abd
gm
,
pattern
tree
,
number
,
occurrence
,
training
corpus
,
number
case
,
pattern
chain
abd
gm
,
correct
gap
,
many
tree
class
,
small
number
,
direct
approach
,
estimation
,
spar
sity
issue
,
pattern
,
vertex
,
pattern
,
figure
,
independence
assumption
,
specifi
,
whole
pattern
tree
,
probability
,
probability
,
meaning
,
pattern
grammar
,
section
,
pattern
,
accord
,
semantics
,
figure
,
computation
,
written
,
grammar
,
production
,
context
,
estimation
,
probability
,
transition
,
attern
tree
,
many
pattern
,
several
layer
,
parse
tree
,
figure
,
context
,
production
,
good
part
,
pattern
tree
,
important
observa
tion
,
local
configuration
,
pattern
,
decision
,
reason
,
second
approximation
,
probability
,
a
p
cfg
model
,
grammar
,
pattern
chain
pci
,
string
,
terminal
,
formula
,
argmaxx
,
conjunction
,
pattern
chain
,
equation
,
small
number,pattern,number,non-terminals
,
grammar
,
practice
,
pattern
,
exclu
sive
,
nonetheless
,
production
,
train
ing
data,probability,probability,transition,following,parameter,section,hill-climbing
algorithm
,
3
e
valuation
,
algorithm
,
variety
,
condi
tions,johnson,gabbard,approach,availability6,state-of-the-art
result,insertion,wh-traces
,
metric,co-indexation
,
correct
wh
phrase
,
word
span
,
metric
,
johnson
,
researcher
,
sertion
,
correct
,
correct
type
,
string
position
,
shortcoming
,
correct
,
tachment
,
campbell
,
correct
,
correct
gap
type
,
mother
node
,
correct
nonterminal
label
,
word
span
,
campbell
,
position
,
sibling
,
ble
object
construction
,
detect
error
,
object
order
,
incorrect
attachment
,
optional
con
stituents
,
span
requirement
,
latter
issue
,
campbell
,
respect
,
correctness
,
lexical
head
,
mother
node
,
co
indexed
wh-phrase
,
metric
differs
,
manning
,
dependency
,
rep
resents
performance
,
gap
insertion
,
gap
insertion
,
gold
tree
,
sec
tion
,
parse
tree
,
charniak
,
parser
,
parser
,
section
,
section
,
development
set
,
algorithm
,
non
empty
wh
phrase,johnson,gabbard,performance,wh-traces
,
source
code
,
ryan
gab
,
output
tree
,
sys
tem
,
gap
type
,
gold
tree
,
output
,
algorithm
,
function
tag
,
modified
version
,
bikel
parser
,
gabbard
,
sep
arate
software
tool
,
blaheta
,
charniak
parser
output
,
algorithm
,
function
tag
,
auxiliary
verb
,
tensed
construction
,
tree
surgeon
,
andrew
,
johnson
,
auxified
tree
,
algorithm
,
robustness
,
algorithm
,
corpus
,
re
sult
,
johnson
,
gabbard
,
algorithm
,
bn
corpus
,
modified
version
,
annotation
guideline
,
modification
,
gap
placement
,
treebank
,
algorithm
,
tree
transformation
,
bn
corpus
,
result
table
,
present
gap
insertion
measure
,
section
,
gold
tree
,
charniak
,
bikel
parser
,
addition
,
wha
dvp
result
,
liter
ature
,
present
result
,
whp
gap
,
small
number
,
section
,
non
empty
wha
djp
,
section
,
evaluation
,
gold
tree
charniak
parser
bikel
parser
metric
j
g
pres
j
g
pres
j
g
pres
whn
p
jo
hnson
,
head
dep
,
wha
dvp
jo
hnson
,
head
dep
,
whp
p
jo
hnson
,
head
dep
,
f1
performance
,
section
,
johnson
,
gabbard
,
algorithm
,
algorithm
,
gold
tree
,
system
,
wh
trace
,
metric
,
instance
,
gabbard
,
algorithm
,
cambpell
,
charniak
parser
,
johnson
,
tree
pro
duce
,
bikel
parser
,
dependency
,
appropri
ate
,
evaluation
,
important
aspect
,
tree
structure
,
gap
insertion
,
poor
performance
,
johnson
,
algorithm
,
whp
gap
,
wha
dvp
gap
,
number
,
whp
gap
,
training
corpus
,
wider
range
,
possible
attachment
site
,
prepositional
phrase
,
display
,
algorithm
,
wsj
perform
,
large
number
,
er
rors
,
com
mon
,
speech
corpus
,
reference
,
error
analysis
,
contrast
,
result
,
gold
standard
tree
,
pro
duced
par
,
parse
error
,
major
source
,
parse
error
,
met
rics
,
pattern
,
wh
-
np
,
campbell
,
algorithm
,
factor
,
metric
,
wha
dvps
,
metric
,
similar
degradation
,
conclusion
,
metric
,
whp
p
,
position
,
correct
attachment
,
head
dependency
,
performance
,
sys
tem
,
campbell
,
interesting
property
,
parse
tree
,
upper
bound
,
re
call
,
correct
wh
phrase
,
mother
node
exist
,
parse
tree
,
present
recall
result
,
upper
bound
,
algorithm
,
upper
bound
,
whn
p
,
account
,
impact
,
parse
error
,
improvement
,
whp
p
,
metric
j
g
pres
whn
p
jo
hnson
,
head
dep
,
wha
dvp
jo
hnson
,
head
dep
,
whp
p
jo
hnson
,
head
dep
,
f1
performance
,
gold
tree
,
addition
,
profound
impact
,
performance
,
following
source
,
impact
,
result
,
inconsistency
,
training
,
system
,
evaluation
,
charniak
parser
j
g
pres
ub
whn
,
wha
dvp
,
bikel
parser
j
g
pres
ub
whn
,
wha
dvp
,
recall
,
charniak
,
bikel
parser
,
upper
bound
,
pos
labeling
error
,
wha
dvps
,
wrong
place
,
conjunction
level
,
branch
,
sistency
,
attachment
decision
,
adverbial
gap
,
coverage
,
pattern
,
small
number
,
rare
case
,
appli
cable
pattern
chain
,
correct
gap
,
probabilistic
model
chooses
,
lexicalized
model
,
4
c
onclusions
,
future
work
,
main
contribution
,
velopment
,
generative
probabilistic
model
,
gap
insertion
,
subtree
structure,state-of-the-art
performance
,
result
,
upper
bound
,
campbell
,
performance
,
wha
dvps
,
whp
p
,
improvement
,
information
,
lexical
head
,
sentence
,
similar
structure
,
potential
place
,
sibling
,
current
model
,
congress
,
second
case
,
bias
towards
,
pattern
chain
,
deliver
,
future
work
,
method
,
lexical
information
,
performance
,
wha
dvps
,
wh
-
pp
,
addition
,
method
,
pattern
,
treebank
cor
pu
,
porting
,
approach
,
language
,
treebanks
,
5
a
cknowledgements
,
ryan
gabbard
,
provid
,
output
,
algorithm
,
evaluation
,
anonymous
reviewer
,
invaluable
comment
,
material
,
opinion
,
finding
,
conclusion
,
recommendation
,
material
,
author
,
dar
pa
,
macintyre
,
guideline
,
treebank
ii
style
penn
tree
bank
project
,
parameter
space
,
erative
lexicalized
statistical
parsing
model
,
thesis
,
university
,
function
tagging
,
thesis
,
linguistic
principle
,
cover
empty
category
,
proceeding
,
annual
meeting
,
association
,
computational
linguis
tic,charniak,maximum-entropy-inspired
parser
,
proceeding
,
north
american
chapter,association,head-driven
statistical
model
,
natural
language
parsing
,
thesis
,
university
,
antecedent
recovery
,
experiment
,
trace
tagger
,
proceeding
,
conference
,
empirical
method
,
marcus
,
penn
treebank
,
proceeding
,
north
american
chapter,association,machine-learning
approach
,
identification
,
wh
gap
,
proceeding
,
nual
meeting
,
european
chapter
,
associa
tion
,
simple
pattern-matching
algorithm
,
empty
node
,
antecedent
,
proceeding
,
annual
meeting
,
association
,
tregex
,
tsurgeon
,
tree
data
struc
tures
,
proceeding
,
manning
,
deep
dependency,context-free
statistical
parser
,
surface
dependency
approximation
,
proceeding
,
annual
meeting
,
association
,
superarv
lan
guage
model
,
effectiveness
,
multiple
knowledge
source
,
language
modeling
,
proceeding
,
empirical
method
,
harper
,
stolcke
,
ro
bustness,almost-parsing
language
model
,
errorful
training
data
,
proceeding
,
iee
e
in
ternational
conference
,
acoustic
,
speech
,
sig
nal
processing
,
proceeding
,
conference
,
empirical
method
,
natural
language
processing,singapore,6-7
august
,
afn
lp
a
j
oint
language
model,fine-grain
syntactic
tag
denis
filimonov1
,
computational
linguistics
,
information
processing
institute
,
advanced
computer
study
university
,
maryland
,
mary
harper1
,
language
technology
center
,
excellence
john
hopkins
university
mharper
umiacs
,
edu
abstract
,
scalable
joint
language
model,fine-grain
syn
tactic
tag
,
challenge
,
design
,
solution
,
scale
well
,
large
tagsets
,
cor
pora
,
simple
tag
,
deep
lin
guistic
knowledge
,
language
,
structural
information
,
pos
tag
,
automati
,
parse
tree
,
combina
tion
,
property
,
easy
adop
tion
,
new
language,fine-grain
tagsets
,
pos
tag
,
superarv
tag
,
speech
recognition
task
,
discus
future
direc
tions
,
1
i
ntroduction
,
number
,
language
processing
task
,
problem
,
sequence
,
multiple
hypothesis
,
problem
,
noisy
channel
approach
,
application
,
noisy
channel
model
,
acoustic
signal
,
result
,
unknown
stochastic
process
,
problem
,
sequence
,
acoustic
input
,
separate
model
,
argmax
,
acoustic
signal
,
se
quence
,
acoustic
model
,
language
model1
,
application
,
language
mod
el
,
probability
,
sequence
,
parameter
space
,
context
,
limited
context
,
parameter
space
,
sophisticated
tech
niques
,
reliable
probability
estimation
,
goodman
,
ngram
model
,
shallow
knowledge
,
language
,
extensive
literature
,
variety
,
method
,
semantic
information
,
differ
ent
way
,
method
,
us
surface
word
,
context
,
deterministic
class
,
zitouni
,
semantic
word
clustering
,
variable
length
context
,
stochastic
variable
,
ambiguous
nature
,
surface
words2
,
probability
,
application
,
argmax
,
heldout
,
hese
variable
,
assignment
,
stochastic
variable
,
joint
model
,
joint
event
,
random
,
chelba
,
jelinek
,
pos
tag
,
combination
,
parser
instruction
,
full
parse
tree
,
superarvs
,
complex
tu
ples
,
dependency
information
,
dependency
,
woodland
,
hee
man
,
context
,
problem
,
stan
dard
hmm
application
,
ngram
model
,
niesler
,
woodland
,
joint
model
,
potential
,
express
variability
,
word
usage
,
introduction
,
additional
latent
variable
,
increased
dimensionality
,
context
,
al
ready
complex
problem
,
parameter
estima
tion
,
complexity
,
computation
,
probability
,
challenge
,
time
constraint
,
choice
,
random
,
matter
,
utmost
importance
,
el
ements
,
prior
work
,
hee
man
,
jelinek
,
others
,
paper
outline
,
message
,
thesis
,
joint
language
model
,
variety
,
tagsets
,
section
,
ex
periments
,
tagsets
,
flexibility
,
information
theoretic
framework
,
quick
evaluation
,
tagsets
,
creation
,
new
tagsets,fine-grain
tagsets
,
coarser
pos
model
,
ngram
baseline
,
section
,
challenge
,
joint
language
model,fine-grain
tag
,
joint
language
modeling
,
chelba
,
jelinek
,
hee
man,fine-grain
tag
,
bangalore
,
prior
paper
,
combination
,
joint
language,fine-grain
tag
,
reliable
parameter
estimation
,
scalabil
ity
,
computational
complexity
,
section
,
problem
,
section
,
conclusion
,
direction
,
future
work
,
2
s
tructural
information
,
selection
,
ran
dom
,
performance
,
maximum
information
,
number
,
parameter
,
reliable
param
eter
estimation
,
sparsity
,
computational
complexity
,
section
,
structural
tag
,
parse
tree
,
pos
tag
part-of-speech
tag
,
unannotated
data,off-the-shelf
pos
tagger
,
parser
,
amount
,
infor
mation
,
figure
,
personal
pro
noun
,
information
,
subject
,
object
,
penn
tree
bank
tagset
,
following
word
,
superarv
,
superarv
,
information
,
consistent
set
,
dependency
link
,
syntactic
parse
,
superarvs
,
formation
,
semantic
con
straints
,
uniform
representation
,
lexical
category
,
vector
,
lexical
feature
,
governor
,
need
label
,
function
,
sen
tence
,
relative
position
,
de
pendent
,
reader
,
literature
,
detail
,
superarvs
,
harper
,
parse
tree
,
deterministic
rule
,
individual
tag
,
structure
,
super
-
ar
v
,
language
modeling
,
rich
set
,
annotation
,
new
language
,
large
amount
,
human
effort
,
formation
,
modifee
tag
,
combination
,
pos
tag
,
governor
role
,
dependency
parse
struc
ture,example,sentence,figure,dt-nn
black
jj-nn
cat
nn-vbd
,
henceforth
,
parent
constituent
,
combination
,
immediate
parent
,
parse
tree
,
pos
tag
,
relative
position
,
sib
ling,parent,example,figure,dt-np
start
black
jj-np-mid
cat
nn-np-end
,
tagset
,
con
stituency
information
,
parent
tagsets
,
tree
bank
,
superarvs
,
treebank
,
linguist
,
english
,
information
theoretic
comparison
,
section
,
choice
,
tagset
,
performance
,
intuition
,
language
model
,
course
,
quantifiable
metric
,
information
theoretic
approach
,
conditional
entropy
,
helpful
,
tagset
,
lm
task
,
reduction
,
condi
tional
cross
entropy
,
conditional
cross
entropy
,
conditional
entropy,tendency,fine-grain
tag
,
reality
,
prob
lem
,
con
text
,
smoothed
distribution
,
training
set3
,
test
distribution
,
3
t
ag
,
superarv
parent
head
figure
,
change
,
entropy
,
different
tagsets
,
result
,
measurement
,
figure
,
little
additional
information
,
following
word
,
parent
tagset
,
super
-
ar
v
,
information
,
head
tagset
,
information
,
follow
ing
word
,
plexity
reduction
,
perfect
tag
,
approach
,
crude
estimate
,
bigram
context
,
new
lan
guage,formance,tagsets,one-count
smoothing
,
goodman
,
3
l
anguage
model
structure
,
sparsity
,
parameter
space
,
joint
model
,
dimensionality
reduction
measure
,
accu
rate
estimation
,
parameter
,
additional
source
,
information
,
morpho
logical
feature
,
prosody
,
section
,
avenue
,
ad
dress
,
problem
,
decision
tree
clustering
binary
decision
tree
clustering
,
parameter
space
,
language
modeling
,
heeman
,
language
processing
application
,
algo
rithm
,
function
,
history
,
equivalence
class
,
tree
construction
algorithm
,
select
binary
question
,
history
,
function
,
important
decision
,
question
,
function
,
remainder
,
section
,
cisions
,
factor
,
kirchhoff
,
convenient
view
,
input
data
,
sen
tence
,
factor
,
language
model
,
additional
parameter
,
factor
,
joint
model
,
whereas
,
factor
,
factor
,
factor
,
exam
ples
,
overt
factor
,
surface
word
,
mor
phological
feature
,
suffix
,
case
informa
tion
,
hidden
factor
,
superarvs
,
henceforth
,
overt
factor
,
hidden
factor
,
heeman
,
bi
nary
tree
,
algorithm
,
zitouni
,
hierarchical
clustering
,
tag
space
,
reason
,
question
,
subset
,
ual
tag
,
unlike
,
heeman
,
question
,
representa
tion
,
addition
,
key
feature
,
optimization
,
section
,
question
,
context
space
,
bi
nary
question
,
different
type
,
ques
tions
,
hidden
,
overt
factor
,
surface
word
,
exchange
algorithm
,
algorithm
,
certain
position
,
training
data
,
current
node
,
history
tree
,
complementary
subset
,
target
function
,
av
erage
entropy
,
marginalized
word
dis
tribution
,
algorithm
,
training
data
,
something
,
unseen
word
,
question
,
history
tree
struc
ture
,
overt
factor
,
vocabu
laries
,
suffix
,
equality
ques
tions
,
section
,
hidden
factor
tree
,
question
,
hidden
factor
,
bi
nary
tree
,
binary
path
,
inner
node
,
prefix
,
ques
tion
,
tag
belongs
,
subset
,
possible
subset
,
num
ber
,
clustering
algorithm
,
subset
,
figure
,
binary
prefix
,
optimization
criterion
,
stopping
rule
,
question
,
average
entropy
,
marginalized
word
distribution
,
criterion
,
entropy
,
distribution
,
joint
event
,
sparsity
,
joint
distri
bution
,
ultimate
metric
,
word
perplexity
,
distribution
representation
,
joint
distribution
,
probability
,
internal
node
,
probability
,
repre
sentation
,
decoding
process
,
section
,
probability
distribution
,
history
tree,n-th
node
,
parent
,
distribution
,
distribu
tion
unif
,
interpolation
parameter
,
em
algo
rithm
,
magerman
,
separate
development
set,4-fold
cross
valida
tion
,
geometric
mean
,
coefficients6
,
approach
,
small
development,training,low-count
node
,
em
algorithm
,
history
tree
,
isolation
,
context
,
sequence
,
question
,
answer
,
answer
,
topmost
question
,
variant
,
jelinek
mercer
,
order
model7
,
distribution
,
backoff
node
,
grandparent
,
open
question
,
vation
,
distribution
,
formula
,
fol
low
,
distancetoroot
,
distribution
,
uniform
joint
distri
bution,word-tag
pair
,
harper
,
large
number
,
product
,
minimum
,
order
model
,
algo
rithm
,
context
,
turn
back
,
unigram
,
figure
,
fragment
,
decision
tree
,
backoff
node
,
training
data
,
unseen
word
,
backoff
node
,
hmm
decoding
,
prob
ability,i-th
step
,
possible
combination,history,prediction,i-th
step
,
straightforward
computation
,
probabili
tie
,
trigram
model
,
standard
ap
proach
,
computational
requirement
,
beam
search
,
likely
path,fine-grain
tag
,
tractable
beam
size
,
small
fraction
,
whole
space
,
good
path
,
history
,
function
,
decision
tree
,
clustering
,
nate
unnecessary
computation
,
equiva
lent
history
,
history
,
projection
,
function
,
context
,
number
,
distinct
cluster
,
decision
tree
configuration
,
different
word
,
history
,
figure
,
question
,
hidden
factor
,
figure
,
decoding
lattice
rep
,
number
,
probability
,
algorithm
,
exception
,
hidden
state
,
bigram
model
,
question
,
binary
prefix
,
question
,
figure
,
op
eration
,
decoding
lattice
,
figure
,
probability
,
previous
time
index
,
fragment
,
property
,
probability
,
inner
node
,
probability
,
operation
,
tag
prediction,i-th
word
,
question
,
history
,
question
,
overt
factor
,
probability
,
probability
,
false
branch
,
projection
,
question
,
hidden
factor
,
figure
,
process
,
fragment
,
bottom
,
history
tree
,
new
state
,
cluster
,
incoming
link
,
order
model
,
context
,
5
e
xperimental
setup,impact,fine-grain
tag
,
lan
guage
modeling
,
setting
,
first
model
,
question
,
overt
factor,tree-based
word
model
,
second
model
,
pos
tag
,
effect
,
fine
grain
tag
,
parent
,
section
,
section
,
respec
,
joint
model
,
super
-
ar
tag
,
superarvs
,
parse
tree,fine-grain
tag
,
superarv
,
use
trigram
context
,
standard
trigram
,
gram
model
,
reference
,
ngram
model
,
sri
lm
toolkit,interpo,kneser-ney
,
nbest
rescoring
task,100-best
list
,
dar
pa
wsj
,
open
vocabulary
data
set
,
detail
,
acoustic
model
,
harper
,
data
set
,
evaluation
,
optimization8
,
ptb
tokenization
,
possessive
,
auxil
iary
verb
,
contraction
,
contraction
,
personal
pronoun
,
language
model
,
nyt
1994-1995
section
,
english
gigaword
cor
pu
,
new
york
time
,
wider
range
,
wall
street
journal
,
ir
relevant
story
,
trigram
coverage
,
section
,
sen
tences
,
parser
,
formance
drop
,
long
sentence
,
corpus
,
sentence
,
low
probability
,
parser
,
percent
,
rigorous
approach
,
cleaning
,
discrim
inating
model
,
extended
ver
sion
,
berkeley
parser
,
harper
,
parser
,
combination
,
wsj
treebanks
,
speech
recognition
task
,
number
,
abbreviation
,
verbalized
form
,
nyt
cor
pu
,
punctuation
,
downcased
word
,
ngram
model
,
parent
model
,
tag
vocabulary
,
superarv
model
,
dis
tinct
superarvs
,
experiment
,
overt
fac
tor
,
surface
word
,
lm
weight
,
script
,
sri
lm
,
nis
t
sctk
toolkits
,
model
wer
trigram
,
baseline
,
word
tree
,
pos
tag
,
head
tag
,
parent
tag
,
superarv
,
oracle
wer
,
perplexity
,
factor
,
wer
notice
,
overt
factor
,
machine
translation
,
language
model
,
wider
range
,
oov
phenomenon
,
abbreviation
,
foreign
word
,
number
,
summarizes
performance
,
rescoring
task
,
parent
,
trigram
baseline
model,five-gram
model
,
trigram
baseline
,
sparsity
,
short
sen
tences
,
test
set
,
improvement
,
pos
model,baseline,fine-grain
model
,
baseline
,
superarv
,
perplexity
,
section
,
wsj
ptb
,
head
model,perplexity,baseline,five-gram
model,margin,improvement,fine-grain
tagsets
,
small
size
,
test
set
,
reduction
,
plexity
,
improvement
,
statistical
significance
,
sct
implementa
tion
,
mapsswe
test
,
model
ppl
trigram
,
baseline
,
word
tree
,
pos
tag
,
head
tag
,
parent
tag
,
superarv
,
perplexity
result
,
section
,
wsj
ptb
6
c
onclusion
,
future
work
,
joint
language
mod
,
framework
,
prior
work
,
specific
tag
set
,
large
set
,
challenge
,
tag
set
,
pos
tag
,
challenge
,
solution
,
solution
,
decoding
algorithm
,
simple
fine-grain
tagsets
,
language
modeling
,
sophisticated
tag
set,fine-grain
tag
,
superarvs
,
former
use
,
linguistic
knowledge
,
language
,
treebank
,
joint
language
model
,
pre
dicts
hidden
event
,
sequence
,
pos
tag
,
similar
result
,
fine
grain
model
,
pos
model,state-of-the-art
hmm
pos
tagger
,
filimonov
,
harper
,
detail
,
experiment
,
parser
accuracy
,
data
selection
strategy
,
parser
con
fidence
score
,
performance
,
performance
,
speech
,
machine
translation
,
amount
,
mod
ern
large-scale
ngram
model
,
technique
,
language
,
tree
bank
,
arabic
,
source
code
,
several
month
,
publication
,
7
a
cknowledgments
,
material
,
nsf
iis
,
opinion
,
finding
,
recommendation
,
author
,
funding
agency
,
institution
,
reference
lalit,robert,mercer,tree-based
statistical
language
model
,
natural
language
speech
recog
nition
,
reading
,
speech
recognition
,
srinivas
bangalore
,
technique
,
language
modeling
,
proceeding
,
inter
national
conference
,
spoken
language
process
ing
,
volume
,
bilmes
,
katrin
kirchhoff
,
language
model
,
parallel
backoff
,
proceeding
,
vincent
,
della
pietra
,
des
ouza,jennifer,robert,mercer,class-based
n-gram
model
,
natural
language
,
computational
linguistics
,
ciprian
chelba
,
frederick
jelinek
,
language
modeling
,
speech
recognition
,
stanley
,
joshua
goodman
,
em
pirical
study
,
technique
,
language
modeling
,
proceeding
,
annual
meet
,
association
,
computational
linguistics
,
association
,
computational
linguistics
,
denis
filimonov
,
mary
harper
,
performance
,
joint
language
model
,
proceeding
,
interspeech
,
heeman
,
decision
tree
,
language
modeling
,
proceeding
,
joint
sig
dat
co
nference
,
empirical
method
,
natural
language
processing
,
large
cor
pora
,
zhongqiang
huang
,
mary
harper
,
self
training
pcf
grammar
,
latent
annotation
,
language
,
proceeding
,
emn
lp
,
magerman
,
natural
language
par
,
statistical
pattern
recognition
,
thesis
,
sven
martin
,
jorg
liermann
,
hermann
ney
,
algorithm
,
bigram
,
trigram
word
clustering
,
speech
communication,thomas,niesler,woodland,variable-length
category-based
n-gram
language
model
,
proceeding
,
iee
e
in
ternational
con
ference
,
acoustic
,
speech
,
signal
process
,
harper
,
second
order
hidden
markov
model,part-of-speech
tag
ging
,
proceeding
,
annual
meeting
,
wen
wang
,
harper
,
superarv
language
model
,
effectiveness
,
multiple
knowledge
source
,
conference
,
empirical
method
,
natural
language
process
ing
,
associ
ation
,
computational
linguistics
,
wen
wang
,
harper
,
andreas
stolcke,robustness,almost-parsing
language
model
,
errorful
training
data
,
proceeding
,
iee
e
in
ternational
conference
,
acoustic
,
speech
,
signal
processing
,
peng
xu
,
frederick
jelinek
,
random
forest
,
language
modeling
,
proceeding
,
conference
,
empirical
method
,
natural
lan
guage
processing
,
imed
zitouni
,
backoff
hierarchical
class
gram
language
model
,
effectiveness
,
speech
recognition
,
proceeding
,
conference
,
empirical
method
,
natural
language
processing
,
edinburgh
,
association
,
computational
linguistics
syntactic
decision
tree
lm
,
random
selection
,
intelligent
design
,
computer
science
university
,
maryland
,
college
park
mharper
umd
,
abstract
decision
tree
,
vari
ety
,
nlp
task
,
language
mod
eling
,
ability
,
variety
,
attribute
,
sparse
context
space
,
forest
,
collection
,
decision
tree
,
individual
decision
tree
,
vestigate
method
,
method
,
syntactic
language
modeling
,
tree
interpolation
technique
,
standard
method
,
literature
,
particular
task
,
tree
context
,
principled
way
pro
duce
,
forest
,
relative
reduction
,
word
error
rate,n-gram
baseline
,
essential
part
,
nlp
application
,
selection
,
fluent
word
sequence
,
multiple
hypothesis
,
prominent
application
,
problem
,
computation
,
probability
,
probability
,
fluent
hypothesis
,
context
space
,
function
,
independence
,
sumption
,
rel
evant
context,distribution,n-grams
wii
,
training
data
,
context
space
,
order
distribution
,
instance
,
probability
,
discounted
probability2
,
simple
markov
chain
,
notion
,
syntax
,
language
,
structure
,
syn
tax
,
language
model
,
perfor
mance
,
bangalore
,
heeman
,
chelba
,
jelinek
,
filimonov
,
harper
,
syntax
,
language
model
,
proba
-
1o,n-gram
model
,
vocabulary
size
,
reader
,
goodman
,
survey
,
discounting
method,n-gram
model
,
bility
,
word
sequence
,
primary
goal
,
research
,
strong
syntactic
language
model
,
effective
method
,
research
com
munity
,
context
,
joint
model
,
sparse
prob
lem
,
probability
estima
tion
,
utilize
decision
tree
,
joint
syntactic
language
model
,
ter
context
,
strength
,
reliance
,
information
theoretic
metric
,
context
,
extreme
sparsity
,
ability
,
corporate
attribute
,
different
types3,log-linear
model
,
rosenfeld
,
expensive
probability
normalization,runtime,section,detail,single-tree
model
,
inevitable
greediness
,
tree
construction
process
,
tendency
,
problem
,
order
decision
tree
,
sec
tion
,
inappropriateness
,
backoff
method,n-gram
model
,
decision
tree
lm
,
briefly
,
generalized
interpo
lation
,
generalized
interpola
tion
method
,
addition
,
number
,
question
,
diverse
decision
tree
,
combination
result
,
total
number
,
computational
practical
ity
,
section
,
variety
,
example
,
morphological
feature
,
inflectional
language
,
bilmes
,
kirch
hoff
,
method
,
different
tree
,
finding
,
asr
rescoring
task
,
section
,
finding
,
section
,
oint
syntactic
decision
tree
lm
decision
tree
,
func
tion
,
number
,
cluster
,
cluster
,
disjoint
subset
,
context
space
,
probability
,
joint
decision
tree
model
,
remainder
,
section
,
technique
,
deci
sion
tree
,
probability
distribu
tion
,
joint
model
,
decision
tree
construction
,
recursive
partitioning
,
decision
tree
,
approach
,
number
,
alternative
binary
split
,
training
data
,
stopping
rule
,
training
data
,
heldout
set
,
partition
,
child
node
,
stopping
rule
,
algorithm
proceeds
,
binary
split
,
question
,
context
,
binary
partition
,
binary
function
,
element
,
context
space
belongs
,
partition
,
univariate
question
,
question
,
context
,
question
,
question
,
integer
,
subset
,
offset
,
training
data
,
current
node
,
complemen
tary
subset
,
exchange
algorithm
,
martin
,
algorithm
,
initial
ization
,
question
,
word
po
sition
,
different
random
initialization
,
exchange
algorithm
,
training
data
,
structure
,
figure
,
probability
,
backoff
node
,
probability
,
grandparent
nodea
,
estimate
,
order
tree
,
noticeable
difference
,
method
,
small
fraction
,
probability
,
simplicity
,
probability
,
backoff
node
,
grandparent
,
create
question
,
hi
erarchical
clustering
,
binary
tree
,
beforehand
,
minimum
discriminating
information
al
gorithm
,
zitouni
,
entire
train
ing
data
set
,
dividual
tag
,
internal
node
,
subset
,
node
dom
inates
,
question
,
tag
tree
,
subset
,
rationale
,
tag
question
,
algorithm
,
standard
hmm
decoding
,
filimonov
,
harper
,
context
attribute
,
metric
simi
lar
,
information
gain
ratio
,
quinlan
,
context
,
question
,
leaf
yes
,
fragment
,
decision
tree
,
backoff
node
,
training
data
,
unseen
word
,
question
,
entropy
reduction
,
explicit
heldout
,
stopping
criterion
,
technique
simi
lar
,
validation
,
training
data
set
,
question
,
entropy
,
tree
induction
algorithm,word-tree
model,word-tree
model
,
effect
,
decision
tree
modeling
,
syntactic
information
,
language
modeling,n-gram
baseline
,
decision
tree
,
hierarchy
,
clustering
,
observed
distribution
,
parent
,
heeman
,
observed
distribution
,
parent
,
coefficient
,
em
algorithm
,
order
decision
tree,one-node
tree,n-gram
model
,
order
decision
tree
,
order
n-gram
model
,
different
interpolation
method
,
next
section
,
difference
,
generalized
interpolation
,
decision
tree
model
,
3
i
nterpolation
,
backoff
tree
model
,
section
,
simplicity
,
presentation
,
equation
,
word
model
,
equation
,
joint
model
,
trivial
transformation
,
backoff
property
let
,
interpolation
,
discounted
distribution
,
function
,
backoff
,
backoff
,
function
,
reduction
,
context
size,n-gram
model
,
word
sequence
,
se
quences
,
cision
tree
model
,
backoff
function
,
clustering
function
,
intuition
,
backoff
con
text
bon
,
probability
estimation
,
word
sequence
,
cluster
bon,n-gram
model
,
ackofk
leyaslknol
asol
,
backoff
property
,
sequence
,
superset
,
latter
,
decision
tree
,
property
,
figure
,
illustrates
case
,
property
,
context
sequence
,
example
,
suppose
,
backoff
cluster
,
modal
verb
,
latter
,
weight
,
backoff
scheme
,
compromise
value
,
suboptimal
performance
,
hence
arbitrary
clustering
,
advantage
,
deci
sion
tree
,
violation
,
property
,
degradation
,
performance
,
generalized
interpolation
recursive
linear
interpolation
,
jelinek
mercer,n-gram
model
,
jelinek
,
mercer
,
decision
tree
model
,
cluster
,
probability
dis
tribution
,
cluster
,
interpolation
method,count-based
discounting
method
,
distribu
tions
,
filimonov
,
harper
,
violation
,
property
,
deci
sion
tree
model
,
interpolation
method
,
following
generalized
form
,
recursive
interpolation
,
additional
con
straint
,
generalized
interpolation
,
interpolation
,
num
ber
,
parameter
,
degree
,
freedom
,
recursive
interpolation
,
special
case
,
backoff
tree
,
forest
note
,
individual
tree
,
plicit
higher-lower
order
relation
,
collection
,
forest
,
different
tree
,
difference
,
training
data,difference,algorithm,non-determinism
,
randomization
technique
,
large
forest
,
decision
tree
,
number
,
decision
tree,forest,m-th
tree
model4
,
interpolation
assumes
,
tree
model
,
priori
,
therefore
,
tree
model
,
special
case
,
parameter
,
individual
tree
,
weak
model,combination,n-gram
baseline
,
approach
,
online
application
,
sizable
model
,
experi
ments
,
fourgram
tree
,
mil
lion
leaf
,
tree
structure
,
prob
ability
,
disk
space
af
ter
compression
,
handful
,
distributed
computing
,
following
question
,
handful
,
approach
,
remainder
,
section
,
experimental
setup
,
discus
,
differ
ent
way
,
building
decision
tree
forest
,
lan
guage
modeling
,
combination
method
,
experimental
setup
,
35m
word,speech-like
form
,
number
,
abbrevi
ations
,
punctu
ation
,
contraction
,
possessive
,
syntactic
modeling
,
pos
tag
,
parsing
,
tag
extraction
,
verbalization
,
number
,
abbreviation
,
order
model
,
processing
,
latent
vari
able
pcf
parser,harper,reference,n-gram
model
,
interpolated
kn
discounting
,
mod
el
,
vocabulary
,
perplexity
number
,
wsj
section
,
result
,
filimonov
,
harper
,
baseline
,
experiment
,
cision
tree
,
joint
syntactic
model,word-tree
model
,
section
,
fourgram
tree
,
backoff
trigram
,
bi
gram
,
unigram
tree
,
parameter
,
lihood
,
heldout
set,4-way
cross
validation
,
whereas
,
parameter
,
l-b
fgs
,
denominator
,
variety
,
randomization
technique,word-only
model
,
question
,
exchange
algorithm
,
method
,
randomization
,
position
,
history
,
question
construction
,
a
b
ernoulli
trials6
,
random
initialization
,
exchange
algorithm
,
exchange
algorithm
,
bernoulli
trial
parameter
,
matter
,
exchange
algorithm
,
bernoulli
trial
pa
rameter
,
overall
forest
performance
,
similar
method
,
exchange
algorithm
randomly
,
bernoulli
trials7
,
key
difference
,
section
,
parser
,
method
,
position
,
history
,
probability
,
bernoulli
trial
,
joint
model
,
question
,
randomness
,
domization
method
,
priori
preference
,
initialization
,
exchange
algorithm
,
random
initialization
,
greedy
nature
,
al
gorithm
,
constructed
tree
,
combination
,
individual
tree
,
bernoulli
trial
,
choice
,
quality
,
dividual
tree
,
additional
diversity
,
combination
,
quality
,
individual
tree
,
randomness
,
tree
construction
,
apparent
degradation
,
dividual
tree
quality
,
different
fold
,
training
data
,
sec
tion
,
effect
,
differ
ent
type
,
randomization
,
individual
tree
,
combination
,
first
set
,
experiment
,
performance
,
single
undegraded
fourgram
tree9
,
forest
,
fourgram
tree
,
bernoulli
trial
,
order
tree
,
forest
,
interpola
tion
,
compare
,
interpolation
method
,
forest
,
different
size
,
baseline
,
effect
,
randomization
,
decision
tree
,
importance
,
order
tree
,
result
,
undegraded
syntactic
tree
,
word
tree
,
situation
,
joint
model
,
dimensional
ity
,
context
space
,
method
,
number
,
random
tree
,
forest
,
perplexity
,
interpolation
method
,
improvement
,
percentile
point,word-tree
model
,
ran
dom
decision
tree
,
performance
,
sin
gle
,
joint
model
,
henceforth
,
accord
,
algorithm
,
smooth
distribution
,
order
tree
,
perplexity
result
,
parenthesis
,
reduction
,
perplexity
relative
,
order
model
,
perplexity
number
,
fourgram
tree
,
bernoulli
trial
,
number
,
number
,
forest
,
baseline
,
refers
,
fourgram
model
,
order
tree
,
single
decision
tree
,
randomization
,
com
pare
,
performance
,
single
undegraded
fourgram
tree
,
fourgram
model
,
order
tree
,
joint
model
,
perplexity
,
correspond
ing
model
,
single
fourgram
tree
,
forest
,
fourgram
tree
,
randomization
,
tree
construction
algorithm
,
ran
dom
initialization
,
exchange
algorithm
,
variation
,
training
data
fold
,
forest
,
interpolation
method
,
perplexity
num
bers
,
bernoulli
trial
,
baseline
model
,
result
,
different
decision
tree
,
troduce
difference
,
tree
construction
process
word-tree
syntactic
tree
exchng
,
data
exchng
,
baseline
,
perplexity
number
,
fourgram
tree
,
random
initialization
,
ex
change
algorithm
,
exchng
,
column
,
variation
,
data
fold
,
data
column
,
refers
,
fourgram
model
,
order
tree
,
interpola
tion
method
,
domness
,
joint
model
,
addition
,
order
tree
,
important
role
,
high
quality
model
combination,context-restricted
forest
,
order
decision
tree
,
re
sults
,
order
decision
tree
,
context
space
,
attribute
,
con
text
,
bernoulli
trial
,
decision
tree
,
context
,
distant
context
,
decision
tree
,
degradation
,
joint
model
,
context
,
tribute
,
affords
,
variety
,
different
context
,
experiment
,
perplexity
number
,
standard
model
,
additional
tree,context-restricted
tree
,
model
size
,
perplexity
result
,
standard
syntactic
model
,
additional
tree,bernoulli-rnd
,
data
rnd
,
indicate
fourgram
tree
,
bernoulli
trial
,
training
data
,
second
column
,
combined
size
,
decision
tree
,
forest
,
decision
tree
,
fourgram
joint
model
,
formula
,
full
context
,
method
,
sec
tion
,
generalized
interpo
lation
method
,
section
,
undegraded
tree
,
performance
,
strong
baseline
,
random
tree
,
perplexity
,
quality
,
undegraded
tree
,
data
randomization
,
performance
,
improvement
,
order
tree
,
sr
rescoring
result
,
improvement
,
perplex
ity
,
impact
,
evaluation
,
test
set
,
utterance
,
model
ppl
wer
,
perplexity
,
wer
result
,
syntactic
model
,
interpolation
method
,
weight
,
combination
,
language
model
score
,
separate
develop
ment
,
utterance
,
vocabulary
,
open
vocab
ulary
set
,
asr
system
,
lattice
,
ibm
speech
transcription
system
,
gal
e
di
stillation
go
no-go
evaluation
,
acoustic
model
,
trained
model
,
hub4
acoustic
training
data
,
lattice
,
trigram
lm
,
unique
hypothesis,lattice,1-best
hypothesis
,
test
set
,
oracle
wer
,
wer
result
,
corresponding
perplexity
number
,
perplexity
syntactic
model
,
baseline
,
kn
n-gram
model
,
standard
decision
tree
model
,
terpolation
method
,
terpolation
method
,
performance
,
interpolation
method
,
context
,
dif
ferent
way
,
reduces
,
im
provement
,
baseline
model,improvement,n-gram
baseline
,
absolute
,
6
c
onclusion
,
various
aspect
,
multiple
decision
tree
,
single
language
model
,
generalized
interpola
,
decision
tree
model
,
filimonov
,
harper
,
forest
,
terpolation
method
,
backoff
interpola
tion
,
order
relation
,
backoff
,
question
,
decision
tree
,
combination
result
,
formance
,
assumption
,
computational
tractability
,
handful
,
decision
tree
,
various
technique
,
forest
,
method
,
random
degrada
tion
,
tree
construction
algorithm
perform
,
joint
model
,
method
,
degrada
tion
,
variability
,
param
eters
,
data
fold
difference
,
initialization
,
context
,
dif
ferent
way
,
context
reduction
,
resulting
variation
,
forest
,
forest
,
7
a
cknowledgments
,
ariya
rastrow
,
word
lattice
,
asr
rescoring
experiment
,
reference
lalit,robert,mercer,tree-based
statistical
lan
guage
model
,
natural
language
speech
recognition
,
reading
,
speech
recognition
,
srinivas
bangalore
,
technique
,
language
modeling
,
proceeding
,
inter
national
conference
,
spoken
language
processing
,
volume
,
jeff
bilmes
,
katrin
kirchhoff
,
lan
guage
model
,
parallel
backoff
,
proceeding
,
ciprian
chelba
,
frederick
jelinek
,
language
,
speech
recognition
,
stanley
,
joshua
goodman
,
empiri
cal
study
,
technique
,
language
model
,
proceeding
,
annual
meeting
,
sociation
,
computational
linguistics
,
advance
,
speech
transcription
,
speech
,
lan
guage
processing
,
denis
filimonov
,
mary
harper
,
joint
lan
guage
model,fine-grain
syntactic
tag
,
pro
ceedings
,
emn
lp
,
denis
filimonov
,
mary
harper
,
interpolation
,
proceeding
,
annual
meeting
,
association
,
com
putational
linguistics
,
peter
heeman
,
versus
class
,
lan
guage
modeling
,
sixth
workshop
,
large
corpus
,
zhongqiang
huang
,
mary
harper
,
self
training
pcf
grammar
,
latent
annotation
,
language
,
proceeding
,
emn
lp
,
frederick
jelinek
,
robert
,
mercer
,
estimation
,
markov
source
parameter
,
sparse
data
,
proceeding
,
workshop
,
pat
tern
recognition
,
practice
,
sven
martin
,
jorg
liermann
,
hermann
ney
,
algorithm
,
bigram
,
trigram
word
clustering
,
speech
communication
,
quinlan
,
induction
,
decision
tree
,
ronald
rosenfeld
,
jaime
carbonell
,
alexander
rud
,
adaptive
statistical
language
modeling
,
maximum
entropy
approach
,
technical
report
,
random
forest
,
data
sparseness
problem
,
language
modeling
,
thesis
,
maryland
,
imed
zitouni
,
backoff
hierarchical
class
gram
language
model
,
effectiveness
,
unseen
event
,
speech
recognition
,
human
language
technology
,
annual
conference
,
north
american
chapter
,
los
angeles
,
california
,
association
,
computational
linguistics
contextual
information
improves
oov
detection
,
speech
carolina
parada
,
mark
dredze
hlt
coe
jo
hn
hopkins
university
,
north
charles
street
,
baltimore
md
,
carolinap
jhu
,
denis
filimonov
hlt
coe
un
iversity
,
maryland
,
frederick
jelinek
hlt
coe
jo
hn
hopkins
university
,
north
charles
street
,
baltimore
md
,
jelinek
jhu
,
important
source
,
recognition
failure
,
pipeline
system
,
performance
,
downstream
ap
plication
,
detection
,
oov
region
,
output
,
a
l
vcsr
system
,
binary
classification
task
,
region
,
local
information
,
oov
region
,
contextual
information
,
region
,
substantial
improvement
,
tection
,
missed
oov
rate
,
false
alarm
rate
,
vocabulary
,
thou
sand
word
,
new
word
,
entity
,
foreign
word
,
invented
word
,
training
,
lvc
sr
system
,
important
source
,
lvc
sr
system
,
reason
,
lvc
sr
system
,
nition
error
,
translation
,
document
retrieval,information-rich
noun,mis-recognized
oov
,
impact
,
understand
ing
,
transcript
,
solution
,
lvc
sr
system
,
new
word
,
vocabulary
size
,
word
error
rate
,
tradeoff
,
recognition
accuracy
,
rare
word
,
effective
solution
,
presence
,
annotation
,
addition
,
system
,
oov
segment
,
phone
recognizer
,
open
vocabu
lary
lvc
sr
system
,
oov
prevent
error
propagation
,
application
pipeline
,
literature
,
basic
approach,filler,sub-word
,
generic
word
model
,
schaaf
,
bisani
,
klakow
,
confidence
estimation
model
,
differ
ent
confidence
score
,
unreliable
region
,
burget
,
wessel
,
rastrow
,
ap
proach
,
confidence
estimation
model
,
filler
model,state-of-the-art
result
,
oov
detection
,
approach
,
confi
dence
,
system
,
treat
oov
detection
,
binary
clas
sification
task
,
region
,
local
information
,
independence
assumption
,
considers
region
,
tection
,
oov
detection
,
sequence
la
,
problem
,
add
feature
,
local
lexical
context
,
region
,
global
fea
tures
,
language
model
,
entire
utter
ance
,
result
,
information
im
,
oov
detection
,
large
reduc
tions
,
result
,
approach
,
confidence
,
system
,
current
state-of-the-art
result
,
oov
detection
,
ex
perimental
setup
,
framework
,
sequence
labeling
problem
,
feature
,
local
context
,
lexical
context
,
entire
ut
terance
,
additional
improvement
,
baseline
system
,
review
,
related
work
,
2
m
aximum
entropy
oov
detection
,
baseline
system
,
maximum
entropy
model
,
feature
,
filler
,
confidence
estimation
model
,
rastrow
,
filler
model
,
approach
model
,
hybrid
system,sub-word
unit,sub-word
unit
,
fragment
,
variable
length
phone
sequence
,
statistical
method
,
siohan
,
bacchiani
,
fragment
lex
icon
,
fragment
,
language
model
text
,
low
frequency
word
,
fragment
representation
,
pro
nunciations
,
grapheme
,
approach
,
property
,
con
fidence
estimation
system
,
hybrid
lvc
sr
system
,
confusion
network
,
compact
representation
,
recog
nizer
,
likely
hypothesis
,
utterance
,
confusion
network
,
sequence
,
confused
region
,
likely
word
sub-word
hypothesis
,
poste
rior
probabilities1
,
acous
tic
,
language
model
,
acoustic
model
score
,
confusion
network
,
hybrid
system,section,utterance,test-set
,
network
,
reference
transcription,example,in-vocabulary
word
,
confused
region
,
hypothesis
,
presence
,
fragment
,
hypothesis
bin
,
confusion
network
,
rastrow
,
feature
,
region
,
binary
maximum
entropy
classifier
,
effective
feature
,
current
bin
,
confusion
network
,
fragment
,
confusion
network
,
standard
word
,
system
,
hybrid
system
,
feature
,
identical
result
,
rastrow
,
2
a
ll
real-valued
feature,uniform-occupancy
partitioning
,
maxent
model
,
a
g
aussian
prior
,
result
,
3
e
xperimental
setup
,
context
ap
proach
,
experimental
setup
,
dataset
,
corpus
,
oov
corp
,
corpus
con
,
transcribed
broadcast
news
en
glish
speech
,
unique
oov
,
corpus
,
minimum
,
acoustic
instance
,
change
,
partition
,
minimum
,
training
value
,
partition
,
figure
,
example
confusion
network
,
hybrid
system
,
oov
region
,
bio
encoding
,
hypothesis
,
posterior
probability
,
best
hypothesis
,
concatenation
,
top
word
fragment
,
posterior
probability
,
common
english
word
,
corpus
,
short
oov
,
a
l
vcsr
system
,
ibm
speech
recognition
toolkit
,
soltau
,
acoustic
model
,
fiscus
,
utterance
con
,
oov
word
,
oov
corp
,
lan
guage
model
,
var
iou
text
source
,
83k
word
vocabulary
,
standard
rt04
bn
test
set
,
utterance
,
training
,
test
data
,
oov
detector
,
test
set
,
exper
iments
,
oov
training
,
lvc
sr
training
set,addition,word-based
lvc
sr
system
,
hybrid
lvc
sr
system,sub-word
,
fragment
,
word
sub
word
system
,
oov
spoken
term
detection
performance
,
parada
,
phone
error
rate
,
oov
region,rastrow,state-of
the-art
performance
,
oov
detection
,
hybrid
system
,
lexicon
,
20k
fragment
,
rastrow
,
ibm
system
,
speaker
adaptive
training
,
maximum
likelihood
,
discriminative
training
,
system
,
experiment
,
different
dataset
,
modern
lvc
sr
system
vocabulary
,
evaluation
confusion
network
,
hybrid
lvc
sr
system
,
performance
,
oov
detector
,
reference
transcript
,
lvc
sr
transcript
,
reference
transcript
,
confused
region
level
,
confused
region
,
oov
detector
,
score
probability
,
region
,
previous
research
,
oov
detection
accu
racy
,
test
data
,
oov
word
,
training
data
,
oov
detector
,
lvc
sr
training
data
,
fea
tures
,
previous
approach
,
advantage
,
observed
versus
,
feature
,
advan
tage
,
section
,
oov
detector
,
lvc
sr
,
training
data
,
re
sults
,
true
system
performance
,
present
result
,
martin
,
curve
measure
tradeoff
,
false
alarm
,
optimal
op,system,x-axis
varies
,
false
alarm
rate,y-axis
varies
,
false
negative
,
4
f
rom
maxent
,
classification
algorithm
,
maximum
entropy
,
region
,
iv
word
,
oov
region,co-occur
,
example
,
figure
,
oov
word
,
slobodan
,
iv
word
,
slow
vote
,
suggests
,
sequence
model
,
sequence
,
appro
priate
,
context
,
classification
,
sequence
model
,
maxent
classification
model
,
target
label
,
discrete
variable
,
feature
vector
,
information
,
position
,
conditional
distribution
,
normalization
term
,
vec
tor
ofk
feature
,
section
,
parameter
,
conditional
data
likelihood
,
maxent
model
,
model
structure
,
large
number
,
feature
,
primary
advantage
,
max
ent
model
,
ability
,
optimal
labeling
,
entire
sequence
,
local
deci
sion
,
nu
merous
text
processing
task
,
speech
,
sentence
boundary
detection
,
global
feature
vector
,
input
sequence
,
label
sequence
,
malization
term
,
5
c
ontext
,
oov
detection
,
minimal
amount
,
local
context
,
oov
decision
,
predicted
la
bel
,
adjacent
,
region
,
infor
mation
,
oov
bin
,
close
proxim
ity
,
successive
oov
bin
,
oov
detector
training
data
,
oov
sequence
,
single
bin
,
sequence
,
similar
result
,
test
data
,
minimal
amount
,
context
,
adjacent
bin
,
natural
way
,
contextual
infor
mation
,
a
c
rf
,
depen
dencies
,
neighbor
,
neighboring
bin
,
chance
,
current
bin
,
sequence
model
,
technique
,
contextual
dependence
,
scheme
,
information
extraction
,
sequence
,
adjacent
token
,
beginning
,
sequence
,
dif
ferent
tag
,
sequence
,
example
,
first
token
,
person
name
,
b-p
er
,
subsequent
token
,
i-p
er
,
bio
encoding
,
technique
,
i-o
ov
,
figure
,
algorithm
,
fea
tures
,
oov
sequence
,
superior
performance
,
crf
experiment
,
context
,
crf
model
,
first
order
model
,
neighbor
,
order
model
,
depen
dencies
,
distance
,
posi
tions
,
order
model
,
length
,
label
5cr
experiment
,
crf
package
http
,
sourceforge
,
region
,
first
order
,
second
order
crf
,
order
model
,
improvement
,
comparative
baseline
,
present
result,feature,system,real-valued
feature
,
uniform
occupancy
,
uantization
,
feature
,
stan
dard,log-linear
model,advantage,non-linear
characteristic
,
fea
ture
value
,
regulariza
tion
term
,
performance
,
figure
,
depicts
det
curve
,
oov
detection
,
maxent
baseline
,
second
order
crf
,
unobserved
oov
,
test
data
,
prediction
,
different
false
alarm
rate
,
probability
threshold
,
maxent
,
predicted
label
probability
,
marginal
probability
,
first
order
crf
,
identical
performance
,
maxent
baseline
,
second
order
crf
,
clear
improvement
,
second
order
model
,
absolute
improvement
,
false
alarm
rate
,
identi
cal
feature
,
maxent
baseline
,
small
amount
,
context
,
local
label
ing
decision
,
oov
detection
,
quantization
,
feature
yield
,
tized
prediction
score,non-smooth
curve
,
maxent
,
order
crf
result
,
second
order
,
oov
score
varies
,
feature
,
context
label
,
prediction
,
current
label
,
6
l
ocal
lexical
context
popular
approach
,
sequence
tagging
,
formation
extraction
,
speech
tagging
,
feature
,
local
lexical
content
,
context
,
lexical
form
,
pro
vide
clue
,
experiment
,
partition
,
minimum
,
training
value
,
partition
,
maxent
,
second
order
,
figure
,
oov
detection
,
a
m
ax
imum
entropy
,
maxent
,
classifier
,
contextual
infor
mation
,
order
crf
,
baseline
feature
,
actual
lexical
item
,
speech
sequence
,
speech
recognizer
output
,
example
,
figure
,
mer
president
,
good
indicator
,
following
word
,
potential
oov
,
lexical
context
,
hypothesized
word
,
subsequent
region
,
hypothesized
word
,
third
bin
,
lvc
sr
decoding
,
sentence
,
crf
oov
detector
,
confusion
network
,
probability
,
hypothesis
word
,
feature
,
current
word
,
feature
,
lvc
sr
system
,
oov
word
,
detection
,
unobserved
oov
,
feature
,
lexical
context
,
iv
word
,
feature
,
lexical
context
,
bigram
,
hypoth
esis
,
window
,
current
bin
,
feature
,
hypothesis
,
second
order,current-word
context-bigrams
current-trigrams
all-words
all-words-stemmed
figure
,
second
order
crf
,
section
,
additional
feature
,
word
identity
,
neighboring
bin,bigram,trigram,window,feature,ll-words
,
feature,words-stemmed
,
feature
,
second
order
crf
,
baseline
feature
,
current
word
,
formance
,
unobserved
oov
,
current
word
,
lexical
context
,
significant
boost
,
perfor
mance
,
absolute
improvement
,
false
alarm
rate
,
previous
crf
system
,
maxent
baseline
,
context
,
current
word
,
substantial
gain
,
certain
distributional
characteristic
,
inde
pendent
,
oov
word
,
unobserved
oov
,
entity
,
foreign
word
,
rare
noun
,
importance
,
distributional
feature
,
entity
recognition
,
speech
tagging
,
pereira
,
fea
tures,sub-strings
,
baseline
feature
,
word
-
7t
,
stemmed
word
,
cpa
package,search,fragment-posterior
,
improvement
,
lobal
utterance
context
,
feature
,
informa
tion
,
entire
utterance
,
probability
,
utterance
,
language
model
,
measure
,
fluency
,
utterance
,
oov
word
,
specific
syntactic
role
,
proper
noun
,
context
,
syntactic
property
,
syntactic
language
model
,
language
model
,
standard
trigram
language
model
,
syntactic
language
model
,
filimonov
,
harper
,
syntactic
model
,
joint
probability
,
syntactic
tag
,
preceding
word
,
proba
bility
,
utterance
wn1
,
length
,
latent
syntactic
tag
assignment
,
posi
tion
,
sequence
,
length
,
position
,
improvement
,
language
model
,
hub4
csr
,
garofolo
,
modified
berkeley
parser
,
harper
,
parse
tree
,
immediate
parent
,
relative
posi
tion
,
sibling
,
separated
contraction
,
possessive
,
lvc
sr
tokenization
,
oov
detection
,
language
model
,
sr
system,tagset,filimonov,harper,all-words-lemmas
3gram-lm
syntactic-lm
syntactic-lm
tag
figure
,
feature
,
language
model
,
standard
trigram
lm
,
refer
ence
,
sri
lm
toolkit
,
modified
kn
discounting
,
language
model
feature
,
feature
,
entire
utterance
,
language
model
,
utter
ance
,
current
token
,
utterance
,
oov
word,likelihood-ratio
log
,
length
,
probability
,
ut
terance
,
path
hypothesis
word
,
lvc
sr
system
,
utt
wi
unknown
,
probability
,
entire
utterance
,
current
word
,
lvc
sr
output
,
token
unk
,
oov
word
,
iv
word
,
flu
ency
,
utterance
,
function
word,likelihood-ratio
,
utterance
,
current
word
,
misrecognized
oov
,
second
feature,norm-lm-score
,
standard
n-gram
lm,feature,n-grams
actu
,
maxent
,
observed
,
figure
,
a
c
rf
,
context
feature,state-of-the-art
maxent
baseline
,
result
,
normalized
likelihood
,
utterance
,
unlikely
utterance
,
system
,
a
c
rf
,
feature
,
lexical
context
feature
,
section
,
trigram
model
,
joint
syntactic
language
model
,
perfor
mance
,
syntactic
model
,
improvement
,
false
alarm
rate
,
absolute
improvement,respect,result,all-words-stemmed
,
maxent
baseline
,
order
language
model
,
additional
syntactic
feature
,
syntactic
feature
,
ef
fective,5-tag
window
,
pos
tag
,
hypothesis
,
additive
improvement
,
feature
,
figure
,
feature
,
small
ad
ditional
gain
,
syntactic
feature
,
added
benefit
,
likely
pos
tag
,
utterance
,
entire
utter
ance
,
change
,
latent
state
,
global
feature
,
syntactic
lm
,
section
,
filimonov
,
harper
,
vo
cabulary
word
,
nnp
-
pos
,
nnp
-
vbz
,
8
f
inal
system
figure
,
context
,
single
second
order
bio,result,state-of-the-art
maxent
,
rastrow
,
unobserved
oov
,
final
system
,
absolute
improvement
,
result
,
lvc
sr
,
oov
detector
,
training
data
,
maxent
,
similar
performance
,
unobserved
oov
,
result
,
maxent
curve
flattens
,
false
alarm
,
maxent
curve
corresponds
,
prob
ability
threshold
,
oov
re
gion,non-zero
oov
score
,
region
,
zero
entropy
,
fragment
,
crf
model
,
context
,
oov
score
,
application
,
false
alarm
,
work
approach
,
detection
,
speech
,
filler
model
,
confidence
esti
mation
model
,
filler
model
,
dimen
sion
,
filler
unit
,
variable
length
phoneme
unit
,
baseline
system
,
joint
letter
,
rive
unit
,
choueiter
,
method
,
lvc
sr
system
,
flat
model,bisani,system,presence,sub-word
unit
,
measure
,
confidence
,
significant
improvement
,
local
confidence
measure
,
system
,
joint
word
phone
lattice
alignment
,
clas
sifies
high
local
miss-alignment
region
,
combine
filler
model
,
word
confidence
score
,
malized
log-likelihood
acoustic
model
score,fraction,n-best
utterance
hy
potheses
,
hypothesized
word
,
limited
contextual
information
,
indepen
dence
assumption,phone-posterior
estimator
,
feature
,
oov
detection
,
network
,
posterior
probability
,
recognizers
,
sys
tem,frame-based
score
,
large
improvement
,
tempo
ral
context
,
nn
input
,
context
,
feature
,
a
m
axent
model,phoneme,filler-based
model
,
confidence
approach
,
several
acoustic
fea
tures
,
context
,
feature
,
next
word
,
filler
,
acoustic
confidence
feature
,
next
word
,
number
,
filler
,
approach
,
oov
detec
tion
,
sequence
labeling
problem
,
approach
pre
,
applies
,
boundary
detection
,
conclusion
,
future
work
,
effective
approach
,
oov
detection
,
output
confusion
net
work
,
a
l
vcsr
system
,
global
con
textual
information,sub-word
po
terior
probability
,
hybrid
lvc
sr
system
,
a
c
rf
,
oov
region
,
missed
oov
rate
,
relative
error
reduc
tion
,
future
work
,
additional
fea
tures
,
recognizer
,
hypothesis
,
application
,
contex
tual
sequence
prediction
,
author
,
ariya
rastrow
,
baseline
system
code
,
abhinav
sethy
,
bhuvana
ramabhadran
,
ex
periments
,
many
insightful
discussion
,
reference
issam
bazzi
,
james
glass,domain-independent
out-of-vocabulary
word
mod
,
eurospeech
,
issam
bazzi,out-of-vocabulary
word
,
robust
speech
recognition
,
thesis
,
ma
sachusetts
institute
,
open
vocabulary
speech
recognition
,
flag
hybrid
model
,
cernocky
,
combination
,
recognizers
,
reliable
detection
,
erica
cooper
,
abhinav
sethy
,
chris
white
,
bhuvana
ramabhadran
,
murat
saraclar
,
effect
,
pronounciations
,
oov
query
,
stanley
,
conditional
,
joint
model,grapheme-to-phoneme
conversion,linguistically-motivated
sub
word
,
application
,
recogni
tion
,
thesis
,
massachusetts
institute
,
technol
ogy
,
denis
filimonov
,
mary
harper
,
joint
language
model,fine-grain
syntactic
tag
,
emn
lp
,
denis
filimonov
,
mary
harper
,
performance
,
joint
language
model
,
proceeding
,
interspeech
,
jonathan
fiscus
,
john
garofolo
,
mark
przybocki
,
william
fisher
,
david
pallett
,
philadelphia
,
john
garofolo
,
jonathan
fiscus
,
william
fisher
,
david
pallett,r-iv
hub
,
linguistic
data
consortium
,
philadelphia
,
timothy
,
issam
bazzi
,
comparison
,
combination
,
method
,
oov
word
detection
,
word
confidence
,
proceeding
,
international
conference
,
acoustic
,
zhongqiang
huang
,
mary
harper
,
self
training
pcf
grammar
,
latent
annotation
,
language
,
emn
lp
,
dietrich
klakow
,
georg
rose
,
xavier
aubert
,
large
vocabulary
system,word-fragments
,
filler
,
eu
rospeech
,
john
lafferty
,
andrew
mcc
allum
,
fernando
pereira
,
conditional
random
field
,
probabilistic
model
,
sequence
data
,
interna
tional
conference
,
kirchhoff
,
joint
word
phone
lattice
alignment
,
yang
liu
,
andreas
stolcke
,
elizabeth
shriberg
,
mary
harper
,
conditional
random
field
,
sentence
boundary
detection
,
speech
,
jonathan
mamou
,
bhuvana
ramabhadran
,
olivier
siohan
,
vocabulary
independent
spoken
term
detection
,
stolcke
,
con
sensus
,
przybocky
,
det
curve
,
assessment
,
detection
task
performance
,
eurospeech
,
andrew
mcc
allum
,
machine
learn
,
language
toolkit
,
carolina
parada
,
abhinav
sethy
,
bhuvana
ramab
hadran,query-by-example
spoken
term
detec
tion
,
oov
term
,
fernando
pereira
,
naftali
tishby
,
lillian
lee
,
distributional
clustering
,
english
word
,
ariya
rastrow
,
abhinav
sethy
,
bhuvana
ramabhad
ran
,
new
method
,
oov
detection
,
ariya
rastrow
,
abhinav
sethy
,
bhuvana
ramabhadran
,
fred
jelinek
,
towards
,
fragment
unit
,
schaaf
,
detection
,
oov
word
,
word
model
,
semantic
class
language
model
,
bacchiani
,
fast
vocabulary
independent
audio
search,path-based
graph
,
conversational
telephony
system
,
rich
transcription
,
word
confidence
measure
,
oov
word
detection
,
dialog
system
,
eurospeech
,
stanley
wang
,
graphone
model
,
au
tomatic
speech
recognition
,
master
,
thesis
,
ma
sachusetts
institute
,
confidence
measure
,
speech
,
audio
processing
,
jasha
droppo
,
alex
acero
,
ju
lian
odell
,
maximum
entropy
confidence
esti
mation
,
speech
recognition
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
,
shortpapers
,
portland
,
oregon
,
association
,
computational
linguistics
generalized
interpolation
,
computer
science
university
,
maryland
,
college
park
mharper
umd
,
edu
abstract
,
sparsity
,
statistical
model
,
backoff
,
language
modeling
,
rela
tion
,
backoff
model,interpolation,n-gram
model
,
relation
,
arbitrary
clustering
,
context
,
decision
tree
model
,
relation
,
insight
,
generalization
,
linear
interpolation
,
performance
,
decision
tree
lan
guage
model
,
1
i
ntroduction
prominent
use
case
,
nlp
application
,
selection
,
fluent
word
sequence
,
multiple
hypothesis
,
statistical
lm
,
problem
,
computation
,
proba
bility
,
probability
,
fluent
hypothesis
,
following
discussion
,
func
tion
,
language
model
,
context
space
,
function
,
independence
assumption
,
relevant
context,distribution,n-grams
wii
,
training
data
,
context
space
,
order
distribution
,
instance
,
probability
,
discounted
probability1,addition,n-gram
model
,
many
way
,
probability
distribution
,
decision
tree,n-gram
model
,
uti
lize
interpolation
,
order
model
,
interpolation
,
decision
tree
,
arbi
trary
clustering
,
context
,
main
subject
,
reader
,
goodman
,
survey
,
discounting
method,n-gram
model
,
2
d
ecision
,
vast
context
space
,
language
model
man
,
context
clustering,n-gram
model,clustering,k-ary
decision
tree
,
decision
tree
,
cluster
,
similar
distribution
,
context
,
decision
tree,n-gram
model
,
decision
tree
,
func
tion
,
number
,
cluster
,
cluster
,
disjoint
subset
,
context
space
,
probability
estimation
,
dt
construction
,
probability
,
filimonov
,
harper
,
reader
,
detail
,
advantage
,
decision
tree
,
parameter
,
syntactic
tag
,
decision
tree
,
information
,
oretic
metric
,
heuristic
,
context
attribute
,
subsequent
discussion
,
equation
,
word
model
,
joint
model
,
trivial
transformation
,
property
let
,
interpolation
,
wi
bon
,
discounted
distribution
,
function
,
backoff
,
backoff
,
function
,
reduction
,
context
size,n-gram
model
,
word
sequence
,
se
quences
,
cision
tree
model
,
backoff
function
,
clustering
function
,
intuition
,
backoff
con
text
bon
,
probability
estimation
,
word
sequence
,
cluster
bon,n-gram
model
,
property
,
sequence
,
superset
,
latter
,
decision
tree
,
context
sequence
,
example
,
suppose
,
backoff
cluster
,
modal
verb
,
latter
,
weight
,
scheme
,
compromise
value
,
formance
,
effect
,
order
model,property,2-gram
model
,
property
,
backoff
,
un
igram
,
entire
context
,
clus
ter,3-gram
example
,
position
,
following
word
,
arbitrary
clustering
,
advantage
,
violation
,
property
,
degradation
,
performance
,
next
section
,
interpolation
scheme
,
section
,
solution
,
violation
,
property
,
4
l
inear
interpolation
,
linear
interpolation
,
baseline
,
jelinek
mercer,n-gram
model
,
jelinek
,
mercer
,
cluster
,
probability
dis
tribution
,
cluster
,
interpolation
method,count-based
discounting
method
,
distribu
tions
,
eneralized
interpolation
,
recursion
,
sub
stitutions
,
decision
tree
,
distribution
,
cluster
,
heeman
,
filimonov
,
harper
,
1
n
ote
,
parameterization
,
weight
,
weight
,
order
model
,
ideally
,
different
set
,
interpolation
weight
,
eligible
combina
tion
,
cluster
,
number
,
combination
,
train
ing
data
,
parameter
estimation
cumbersome
,
following
parameteriza
tion
,
interpolation
,
decision
tree
model
,
parameterization
,
num
ber
,
parameter
,
cluster
,
ev
ery
tree
,
number
,
degree
,
freedom
,
parameter
,
denominator
,
explicit
distinction
,
backoff
model
,
knowledge
,
order
model
,
property
,
reduces
,
new
parameterization
,
generalization
,
linear
inter
polation
,
parameteri
zation
,
property
,
parameterization
,
induction
,
space
limitation
,
cluster
,
model
order
,
se
quence
,
belongs
,
order
distribution
p1
,
anything
,
induction
step
,
property
,
sequence
,
order
jelinek-mercer
mod
kn
,
perplexity
result
,
parenthesis
,
reduction
,
plexity
relative
,
order
model
,
dt
model
,
distribution
,
last
transformation
,
combination
,
multi
ple
parameter
,
iteration
,
recursive
representation
,
standard
linear
interpolation
,
spe
cial
case
,
new
interpolation
scheme
,
backoff
property
,
6
r
esults
,
discussion
model
,
35m
word,speech-like
form
,
number
,
abbrevia
tions
,
punc
tuation
,
contraction
,
posse
sif
,
syntactic
modeling
,
pos
tag
,
filimonov
,
harper
,
tag
extraction
,
verbal
ization
,
number
,
abbreviation
,
processing
,
trained
latent
variable
pcf
parser,harper,reference,n-gram
model,jelinek-mercer
,
interpolated
kn
discounting
,
vocabulary
,
decision
tree
models3
,
interpolation
method
,
l-b
fgs
,
entropy
,
heldout
set
,
influence
,
factor
,
interpolation
,
decision
tree
,
perplexity
result
,
wsj
section
,
effect
,
new
interpolation,4-gram
order
,
property
,
similar
pattern
,
syntactic
model
,
syntactic
model,word-tree
counterpart
,
jelinek
,
suf
fers
,
violation
,
property
,
heuristic
method4
,
backoff
weight
,
extent
,
main
contribution
,
insight
,
standard
recursive
backoff
,
im
plied
relation
,
backoff
,
adequate
perfor
mance
,
relation
,
terpolation
method
,
generalization
,
linear
interpolation
,
standard
form
,
reader
,
filimonov
,
harper
,
detail
,
order
model
,
kn
discounting
,
order
model
,
order
dt
,
standard
n-gram
model
,
former
performing
,
reference
lalit,robert,mercer,tree-based
statistical
lan
guage
model
,
natural
language
speech
recognition
,
reading
,
speech
recognition
,
stanley
,
joshua
goodman
,
empir
ical
study
,
technique
,
language
mod
,
denis
filimonov
,
mary
harper
,
joint
lan
guage
model,fine-grain
syntactic
tag
,
pro
ceedings
,
emn
lp
,
heeman
,
decision
tree
,
language
modeling
,
proceeding
,
joint
sig
dat
co
nference
,
empirical
method
,
natural
language
processing
,
large
corpus
,
zhongqiang
huang
,
mary
harper
,
self
training
pcf
grammar
,
latent
annotation
,
language
,
proceeding
,
emn
lp
,
frederick
jelinek
,
robert
,
mercer
,
estimation
,
markov
source
parameter
,
sparse
data
,
proceeding
,
workshop
,
pat
tern
recognition
,
practice
,
peng
xu
,
frederick
jelinek
,
random
forest
,
language
modeling
,
proceeding
,
emn
lp
