proceeding
,
conference
,
empirical
method
,
natural
language
processing,seattle,washington,18-21
october
,
association
,
computational
linguistics
a
c
,
level
mir
a
tu
,
strategy
,
machine
translation
ming
tan
,
tian
xia
,
shaojun
wang
wright
state
university
,
colonel
glenn
hwy
,
dayton
,
usa
tan
,
shaojun
,
wang
wright
,
watson
research
center
,
com
abstract
,
tuning
method
,
system
,
large
number
,
fea
tures,corpus-level
ble,approach,variety,heuristic-driven
sentence
level
,
model
loss
,
new
mir
method
,
exact
corpus-level
ble
,
model
loss,method,implementation,experiment,chinese-to
english
translation
show
,
effectiveness
,
implementation
,
1
i
ntroduction
margin
,
parameter
optimization
,
large
feature
size,watanabe,chiang,chiang,chiang,eidelman,cherry,foster,corpus,sentence,approach,variety,sentence-level
ble
u
,
model
loss,watanabe,chiang,chiang,cherry,foster,sentence-level
ble,objective,pseudo-document
,
corpus-level
ble
,
mismatch
,
performance
,
sentence
ble
,
haddow
,
sentence
,
small
batch
,
author
,
a
g
ibbs
sampling
,
tech
nique
,
fear
hypothesis
,
watanabe
,
parameter
,
small
batch
,
sen
tences
,
hinge
loss
,
stochastic
gradient
descent
,
approach
,
additional
complexity
,
baseline
,
approach
,
contrast
,
efficient
batch
,
approach
,
exact
corpus-level
ble
,
model
loss
,
corpus
,
straightforward
approach
,
structured
hinge
loss,experiment,method,performs,state-of-the-art
mir,chinese-to
english
translation
task
,
moderate
margin
,
2
m
argin
,
relaxed
algorithm
,
model
parameter,n-best
list,development,source-language
sen
tence,target-language
hy
potheses
,
number
,
refer
ences
,
feature
vector,decoder,top-1
candidate
,
transla
tion
result
,
model
parameter
,
ble
score
,
papineni
,
instance
,
online
,
overlap
,
decoding
procedure
,
parameter
optimization
procedure
,
example
,
crammer
,
chiang
,
input
sentence
,
next
sentence
,
updated
parameter
,
objective
,
sentence
,
hope
candidate
,
pa
rameter
vector
,
last
sentence,sentence-level
ble
,
algorithm
need
,
deliberate
defini
tion
,
sentence
,
sentence
ble
calcula
tion
,
smoothed
version
,
fit
eij
,
pseudo
document
,
history
,
chiang
,
chiang
,
use
eij,hypothesis,oracle,watanabe,sentence-level
ble,plexes,algorithm,result,mismatch,corpus-level
ble,orpus-level
mir,strategy,corpus-level
mir
,
objective
,
hinge
loss
,
single
sentence
,
entire
corpus
,
online
mir
,
therefore
,
cherry
,
foster
,
batch
tuning
,
following
step
,
parallel
,
previous
iteration
,
corpus
hypothesis
,
hypothesis
,
source
sentence
fi,corpus-level
ble
,
crammer
,
chiang
,
c-m
ira
,
lcorpus
,
hope
hypothesis
,
hypothesis
space
,
entire
corpus
,
ble
difference
,
optimal
ble
,
c-m
ira
,
standard
mir
,
source
,
reference
,
corpus
,
quadratic
programming
,
constraint
,
cram
mer
et
al
,
single
constraint,closed-form
update
,
performs
,
execution
,
outer
loop
,
chiang
,
fear
hypothesis
,
hypothesis
,
decoder
,
entire
space
,
precise
solution
,
tempts
,
mar
gin
proportional
,
ble
differential
,
cherry
,
foster
,
construct
,
a
b
leu
,
smoothing
,
updating
step,corpus-level
ble
,
justification
c-m
ira
,
corpus
,
sentence
,
decod
ing
,
conventional
decoder
process
sentence
,
optimal
solution
,
method
,
notation
,
search
,
hypothesis
,
probabil
ity
,
feature
vector
,
candidate
,
feature
vector
,
model
score
,
sentence
,
sentence
,
c-m
ira
,
structural
svm
,
tsochantaridis
,
cherry
,
foster
,
sentence
hypothesis
,
c-m
ira
,
cutting-plane
algorithm
,
tsochantaridis
,
a
m
ira
pattern
,
simpler
way
,
struc
tural
svm
,
cherry
,
foster
,
sentence
ble,algorithm,outlook,batch-mira
algorithm
,
cherry
,
foster
,
loss
definition,sentence-level
loss,sentence-by-sentence
tuning
pattern
,
future
work
,
structural
svm
,
c-m
ira
,
decomposable
metric
,
4
e
xperiments
,
analysis
,
c-m
ira
,
iterative
batch
,
procedure
,
a
c
hinese-to-english
machine
transla
tion
system
,
feature
,
-
mi
ra,re-ranking
task
,
feature
,
experiment
,
c-m
ira
,
baseline
,
chiang
,
chiang
,
cherry
,
foster
,
batch
mode
,
section
,
difference
,
tween
mir
a1
,
mul
tiple
constraint
,
optimization
,
mir
a2
,
constraint
,
implement
mer
,
mir
a1
,
mir
a2
,
conduct
experiment,server,8-cores
,
opteron
,
maximum
number
,
obvious
increase
,
mer
t
mira
,
mir
a2
c-m
ira
c
,06
others
,08
others
,
test
set
,
dense
feature
,
feature
,
significant
symbol
,
mir
a2
,
epoch
size
,
mir
a1
,
mir
a2
,
c-m
ira
,
c-m
ira
,
parameter
,
algorithm
,
thread
,
following
experiment
,
al
gorithm
,
epoch
size
,
mir
a1
,
mir
a2
,
improvement
,
performance
,
iterative
batch
training
,
experiment
,
pro
cedure
,
section
,
fbi
data
,
sentence
pair,grammar,4-gram
language
model
,
xinhua
portion
,
gigaword
corpus
,
hierarchical
phrase-based
model
,
chiang
,
nis
t
mt
,
sentence
,
feature
,
basic
one
,
group
feature
,
feature
template
,
group
gram
mar
,
length
,
source
side
,
target
side
,
feat
type
,
feat
type
,
relative
frequency
,
relative
frequency
,
lexical
probability
,
lexical
probability
,
possible
subranges
,
maximum
mer
t
mira
,
running
time
,
length
,
hierarchical
grammar
,
extra
group
feature,n-best
list
,
sentence
,
method
,
iteration
,
iteration
,
dev
set
,
ble
score
,
feature
setting
,
basic
feature
,
feature
,
first
case
,
algorithm
,
test
set
,
feature
size
increase,dev-set
ble
,
test
set
,
algorithm
improve
,
mir
a2
,
constraint
,
c-m
ira
,
mir
a1
,
mir
a2
,
corpus
,
sentence
,
running
time
,
mir
a2
,
c-m
ira
,
baseline
system,state-of-the-art
hierarchi
cal
phrase-based
system
,
parallel
sentence
,
dar
pa
bol
t
ch
inese-english
task
,
system
,
dense
feature
,
translation
probabili
tie
,
provenance
feature
,
sparse
feature
,
language
model,six-gram
model
,
word
monolingual
corpus
,
english
side
,
parallel
corpus
,
cor
pora
,
google
news
,
sentence
,
sentence
,
corpus
,
reference
translation
,
input
sentence
,
tuning
,
datasets
,
mir
a1
mir
a2
c-m
ira
dense
dev
,
dense
dev
,
model
parameter
,
baseline
system
,
ter
-
ble,re-ranking
task
,
ini
tial
ble
u,top-1
hypothesis
,
tuning
,
testing
,
average
number
,
hypothesis
,
sentence
,
tuning
,
tuning
set
,
ble
u
,
test
set
,
effectiveness
,
-
mi
ra
,
feature
size
,
simple
search
,
building
strategy
,
algorithm
,
slow
beam
search,n-best
list
,
eign
sentence
,
stack
size
,
significant
difference
,
strategy
,
dev
set
,
second
strategy
,
constraint
,
beam
search,corpus-level
oracle
,
hypothesis
,
chiang
,
experiment
,
constraint
,
overfitting
,
improved
performance
,
execution
,
method
,
parameter
,
smo
procedure
,
c-m
ira
,
training
ble
,
parameter
update,sentence-level
ble
,
level
ble
,
standard
mir
,
parameter
,
heuristic
definition
,
sentence
ble
,
mir
a2,pseudo-document
,
decay
rate
,
comparison
,
c-m
ira
avoids
,
sentence
level
ble
,
variable
,
5
c
onclusion
,
simple
,
effective
mir
batch
tun,algorithm,heuristic-driven
calcula
tion,sentence-level
ble
,
indecom
posability,corpus-level
ble
,
optimiza
tion
objective,corpus-level
hypothesis
,
pro
ce
,
mismatch
,
sentence
level
ble,corpus-level
ble
,
strat
egy
,
optimiza
tion
paradigm
,
structural
svm
,
cherry
,
foster
,
chiang
,
sample
,
forest
,
chiang
,
lattice
,
cherry
,
foster
,
key
idea
,
experimental
work
,
collaboration
,
ibm
researcher
,
first
author
,
watson
research
center
,
re
search
,
air
force
office
,
scientific
research
,
grant
fa9550-10-1-0335
,
national
science
foundation
,
grant
iis
ri
,
research
award
,
monte
carlo
inference
,
maxi
mization,phrase-based
translation
,
proceeding
,
thirteenth
conference
,
foster
,
strategy
,
statistical
machine
translation
,
conference
,
north
american
chapter
,
association
,
com
putational
linguistics
,
chiang
,
discriminative
train
ing
,
statistical
translation
model
,
journal
,
new
feature
,
statistical
machine
translation
,
confer
ence
,
north
american
chapter
,
associa
tion
,
computational
linguistics
,
resnik
,
large
margin
training
,
structural
translation
feature
,
conference
,
empirical
meth
od
,
hierarchical
phrase-based
translation
,
computational
linguistics,singer,passive-aggressive
al
gorithms
,
journal
,
optimization
strategy
,
online
large-margin
learning
,
machine
translation
,
pro
ceedings
,
seventh
workshop
,
statistical
ma
chine
translation,samplerank,phrase-based
machine
translation
,
pro
ceedings
,
sixth
workshop
,
statistical
machine
translation
,
association
,
computational
linguis
tic
,
herbst
,
open
source
toolkit
,
statistical
machine
translation
,
proceeding
,
annual
meeting,association,taskar,end-to-end
discriminative
approach
,
chine
translation
,
proceeding
,
interna
tional
conference
,
computational
linguistics
,
annual
meeting
,
association
,
com
putational
linguistics
,
orange
,
method
,
evaluat
,
automatic
evaluation
metric
,
machine
transla
tion
,
international
conference
,
minimum
error
rate
training
,
statistical
machine
translation
,
proceeding
,
annual
meeting
,
association
,
discriminative
training
,
maximum
entropy
model
,
statistical
machine
translation
,
proceeding
,40
th
annual
meeting
,
association
,
method
,
automatic
evaluation
,
machine
translation
,
proceeding
,40
th
annual
meeting
,
association
,
computational
linguistics
,
association
,
sequetial
minimal
optimization
,
fast
al
gorithm
,
support
vector
machine
,
tech
nical
report
mst
tr-98-14
,
support
vector
machine
,
interde
pendent
,
output
space
,
international
conference
,
online
rank
,
machine
translation
,
proceeding
,
conference
,
north
american
chapter
,
association
,
com
putational
linguistics,isozaki,large-margin
training
,
statistical
ma
chine
translation
,
proceeding
,
conference
,
em
pirical
method
,
natural
language
processing
,
a
s
calable
distributed
syntactic
,
semantic
,
lexical
language
model
ming
tan
,
wright
state
university
shaojun
wang
,
wright
state
university
,
attempt
,
large
scale
,
composite
language
model,n-gram
model
,
structured
language
model
,
probabilistic
latent
semantic
analysis
,
directed
markov
random
field
paradigm
,
account
,
local
word
lexical
information,mid-range
sentence
syntactic
structure,long-span
document
semantic
content
,
composite
language
model
,
convergent
n-best
list
approximate
em
algorithm,follow-up
em
algorithm
,
word
prediction
power
,
corpus
,
supercomputer
,
large
scale
,
composite
language
model
,
drastic
perplexity
reduction
,
translation
quality
,
bleu
score,readability,translation,n-best
list,state-of-the-art
parsing-based
machine
translation
system
,
contributor
,
official
duty
,
employee
,
united
state
government
,
united
state
government
,
accordance
,
introduction
,
markov
chain
,
source
model,previous,workhorse,state-of-the-art
speech
recognizers
,
machine
translator
,
foreign
language
ambiguity
,
probability
,
likely
original
underlying
word
string
,
markov
chain
,
local
word
interaction,n-gram
model
,
si
center
,
department
,
computer
science
,
engineering
,
wright
state
university
,
dayton
oh,e-mail
,
wright
,
si
center
,
department
,
computer
science
,
engineering
,
wright
state
university
,
dayton
oh,e-mail
,
si
center
,
wright
state
university
,
dayton
oh,e-mail
,
zheng
wright
,
si
center
,
department
,
computer
science
,
engineering
,
wright
state
university
,
dayton
oh,e-mail
,
shaojun
,
wang
wright
,
submission
,
october
,
submission
,
october
,
publication
,
november
,
copyright
protection
,
semantic
structure
,
natural
lan
guages
,
range
depen
dencies
,
natural
language
,
dimensionality
,
bengio
,
performance
,
conventional
n-gram
technology,plateau,rosenfeld,n-grams
,
jelinek,jelinek,chelba,hildebrand,papineni,sorensen,immense,paradigm,6-grams
,
billion
,
trillion
,
consistent
sys
tem
improvement
,
excellent
n-gram
hit
ratio
,
unseen
test
data
,
much
improvement
,
final
report
,
approach
,
small
improvement
,
mt
quality
,
problem
,
dire
need
,
novel
approach
,
language
,
decade
,
sophisticated
model
,
outperform
n-grams
,
syntactic
language
model
,
della
pietra
,
chelba
,
chelba
,
jelinek
,
charniak
,
harper
,
jelinek
,
van
uytsel,compernolle,sentence-level
syntactic
structure
,
natural
language
,
topic
language
model,pereira,gildea,hofmann,bellegarda,wallach,document-level
semantic
content
,
language
model
,
specific
,
distinct
linguistic
phenomenon
,
pereira
,
rosenfeld
,
capture
,
exploit
different
aspect
,
natural
language
regularity
,
natural
question
,
tractable
language
model
,
language
model
component
,
component
,
specific
linguistic
phenomenon
,
syntactic
structure
,
semantic
topic
,
morphology
,
pragmatic
,
coherent
way
,
bellegarda
,
language
model
,
used
method
,
linear
interpolation
,
goodman
,
jelinek
,
mercer
,
goodman
,
individual
model
,
weighted
linear
combination
,
syntactic
structure
,
linear
interpolation,trigram,improvement,chelba,jelinek,chelba,held-out
data
,
technique
,
effective
combination
,
rosenfeld
,
linear
additive
form
,
strong
assumption
,
subtlety
,
component
model
,
explanation
,
analysis
,
section
,
appendix
,
second
method
,
maximum
entropy
philosophy
,
machine
learning
,
natural
language
processing
community
,
berger
,
della
pietra
,
della
pietra
,
della
pietra
,
lafferty
,
rosenfeld
,
complete
data
case
,
maximum
entropy
,
nothing
,
maximum
likelihood
estimation
,
undirected
markov
random
field
,
della
pietra
,
della
pietra
,
della
pietra
,
della
pietra
,
lafferty
,
weakness
,
maximum
entropy
approach
,
first
weakness
,
approach
,
distribution
,
feature
,
al
a
s
calable
distributed
syntactic
,
semantic
,
lexical
language
model
information
,
natural
language
,
syntactic
structure
,
semantic
topic
,
second
weakness
,
statistical
model
,
model
parameter
,
expensive
markov
chain
monte
carlo
,
method
,
miller
,
grenander
,
rosenfeld
,
rosenfeld
,
first
hurdle
,
preprocessing
tool
,
hidden
feature
,
mutual
information
,
method
,
word
pair
trigger
,
trigger
,
trigram
,
maximum
conditional
entropy
approach
,
discourse
topic
,
word
prediction
,
khudanpur
,
chelba
,
jelinek
,
language
model
,
semantic
feature
,
feature
,
trigram
,
maximum
conditional
entropy
approach
,
lexical
language
model
,
colleague
,
schuurmans
,
principle
,
standard
maximum
entropy
estimation
,
hidden
dependency
structure
,
lme
wouldn
,
second
hurdle
,
third
method
,
markov
random
field
,
weakness
,
maximum
entropy
approach
,
approach
,
trigram
,
outside
algorithm
,
outside
algorithm
,
modular
modification
,
account
,
effect
,
remain
,
cubic
time
complexity
,
wall
street
journal
corpus
,
moderate
perplexity
reduction
,
probabilistic
dependency
structure
,
chelba
,
jelinek
,
stochastic
property
,
composite
language
model
,
directed
mrf
framework
,
outside
algorithm
,
language
model
,
jelinek
,
ingenious
definition
,
inside
,
outside
probability
,
jelinek
,
outside
algorithm
alters
jelinek
,
outside
algorithm
,
modular
modi
fication
,
sixth
order,sentence-length
time
complexity
,
experimental
result
,
article
,
directed
mrf
framework
,
directed
mrf
paradigm
,
section
,
section
,
sixth
order
,
outside
algorithm
,
composite
model,n-best
list
approximate
em
algorithm
,
linear
time
complexity,follow-up
em
algorithm
,
word
prediction
power,convergence,n-best
list
approximate
em
algorithm
,
data
sparseness
problem
,
jelinek
,
mercer
,
recursive
mixing
scheme
,
markov
source
,
jelinek
,
mercer
,
mixture
,
markov
chain,large-scale
corpus
,
algorithm
,
distributed
computing
environment
,
language
model
,
supercomputer
,
section
,
section
,
language
modeling
,
feature
rich
density
estimation
problem,trade-off
,
approximate
error
,
computational
linguistics
volume
,
number
,
estimation
error
,
section
,
comprehensive
experiment
,
corpus
,
compare
perplexity
result
,
corpus
,
various
situation
,
drastic
perplexity
reduction
,
com
posite
language
model
,
predictive
capacity
,
linear
interpolation
,
composite
language
model,n-best
list,chiang,state-of-the-art
parsing-based
machine
translation
system
,
translation
quality
,
bleu
score
,
readability
,
translation
,
conclusion
,
propose
future
work
,
section
,
main
theme
,
approach
,
information
,
syntactic
structure
,
semantic
fabric
,
high
degree
,
cognition
,
knowledge
,
natural
language
,
key
ingredient
,
success
,
directed
mrf
framework
,
ultimate
goal
,
available
knowledge
source
,
potential
breakthrough,on-going
effort
,
latent
synergy,not-too-distant
future
,
polyva
lent
,
tractable
solution
,
language
modeling
,
surface
,
system
,
deep
understanding
,
random
variable
,
finite
set
,
markov
random
field
,
recursive
factorization,non-negative
function
,
density
,
parent
state
,
recursive
factorization
refers
,
ayesian
network
,
speaking
,
recursive
factorization
,
representation
,
fixed
set
,
example
,
directed
mrf
,
parse
tree
structure
,
random
object
,
collins
,
pereira
,
undirected
mrf
,
directed
mrf
,
many
local
normalization
constraint
,
undirected
mrf
,
global
normalization
factor
,
jelinek
,
jurafsky
,
martin
,
language
model
,
entire
document
history
,
probability
,
vocabulary
,
chelba
,
jelinek
,
chelba
,
syntac
tic
information
,
regular
n-gram
model
,
al
a
s
calable
distributed
syntactic
,
semantic
,
lexical
language
model
dependency
,
technique
,
syntactic
analysis
,
sentence
,
sentence
,
possible
binary
parse
,
terminal
,
phrase
headword,non-terminal
label
,
sentence
,
length
word
,
sentence
,
word
k-prefix
,
sentence
,
beginning
,
sentence
,
current
position,word-parse
k-prefix
,
word-parse
k-prefix
,
exposed
head,headword,root-only
tree
,
pos
tag
,
exposed
head
,
position
,
input
sentence,function,word-parse
k-prefix
,
parse
structure
,
bottom
,
manner
,
word
generation
,
exposed
headword
,
headword
,
current
partial
parse,phrase,operator,sentence,d-predictor
predicts,headword,word-parse
k-prefix
,
probability
,
next
word
,
next
word
wk
,
pos
tag,headword,word-parse
k-prefix
,
probability
,
structor
,
partial
parse
tk
,
series
,
parse
move
,
probability
,
action
,
headword
,
tree
level
,
current
exposed
headword
,
headword
,
new
exposed
headword
,
con
structor
,
headword
indexing
,
current
parse
structure
,
con
structor,control,generalization,shift-reduce
parser
,
ullman
,
adjoin
,
detailed
description
,
chelba
,
jelinek
,
example
,
jelinek
,
complete
parse
,
distinguished
pos
tag
,
allowed
head
,
constituent
,
figure
,
exposed
headword
,
subsequent
model
action
,
computational
linguistics
volume
,
number
3
f
igure
1
a
complete
parse
tree
,
structured
language
model
,
a
p
lsa
model
,
hofmann
,
generative
probabilistic
model
,
word
document
co-occurrence
,
bag-of-words
assumption,document,probability,ord-predictor
pick
,
probability
,
joint
probability
model,mixture,log-linear
model
,
expression
,
number
,
document
,
vocabulary
size
,
latent
semantic
class
variable
,
latent
semantic
class
variable
,
function
,
bottleneck
variable
,
word
occurrence
,
document
,
m-s
lm
,
composite
generative
language
model
,
directed
mrf
paradigm
,
composite
language
model
,
generative
model
,
operator
,
tag
ger
,
con
structor
,
sem
antizer
,
wor
d-predictors
,
m-s
lm
,
wor
d-predictor
,
next
word,headword,word-parse
k-prefix
,
n-gram
history
wkk
,
semantic
content
gk
,
parameter
,
wor
d-predictor
,
language
model
,
composite
language
model
,
complex
dependency
structure
,
expressive
power
,
original
slm
,
figure
,
structure
,
language
model
,
language
model
,
mrf
model
,
al
a
s
calable
distributed
syntactic
,
semantic
,
language
model
,
hidden
information
,
parse
tree
,
semantic
content,n-gram
encodes
local
word
interaction
,
m-s
lm
model
,
sentence
,
syntactic
structure
,
document
,
semantic
content
,
generation
,
natural
language
,
wor
d-predictor
,
next
word
,
probability
,
normalization
constraint
,
parameter
,
example
,
figure
,
language
model
,
action
,
m-s
lm
,
next
word,has-vp
,
composite
model
,
wor
d-predictor
,
next
word,has-vp
,
difference
,
composite
language
model
,
training
algorithm
,
language
model
,
directed
mrf
paradigm
,
likelihood
,
training
corpus
,
collection
,
document
,
joint
sequence
,
lth
sentence
wl
,
parse
struc
ture
tl
,
semantic
annotation
,
document
,
sequence
,
unique
sequence
,
model
action
,
probability
,
probability
,
semantic
content
,
semantic
annotation
,
lth
sentence
wl
,
headword
,
semantic
content
,
parse
tl
,
semantic
annotation
,
lth
sentence
wl
,
headword
,
parse
tree
tl
,
lth
sentence
wl
,
document
,
constructor
,
conditioning
,
headword
,
parse
tree
,
lth
sentence
wl
,
document
,
ancillary
term,data-generating
parameter
,
anything
,
language
model
,
likely
word
se
quence
,
machine
translation
,
speech
recognition,n-gram
language
model
,
subsequent
development
,
objective
,
maximum
likelihood
estimation
,
respect
,
model
parameter
,
sentence
,
parse
tree
,
al
a
s
calable
distributed
syntactic
,
semantic
,
lexical
language
model
semantic
content
,
number
,
parse
tree
,
sentence
length
,
outside
algorithm
,
standard
em
algorithm
,
complexity
,
algorithm
,
sixth
order
,
sentence
length
,
large
corpus,jelinek,chelba,jelinek,n-best
list
approximate
em
similar,chelba,jelinek,chelba,n-best
list
approximate
em
re-estimation
,
modular
modification,effect,component,n-best
list
likelihood
,
parse
tree
,
sentence
,
document
,
cardinality
,
collection
,
sentence
,
entire
corpus,n-best
list
approximate
em,sentence,document,n-best
parse
tree,collection,n-best
list
parse
tree
,
sentence
,
entire
corpus
,
iteration
,
several
iteration
,
em
algorithm
,
model
parameter,n-best
list
likelihood
,
auxiliary
function,m-step
,
respect
,
new
update
,
iterate
step,convergence,n-best
list
likelihood
,
zangwill
,
global
convergence
theorem
,
zangwill
,
behavior
,
convergence
,
concept
,
zangwill
,
global
convergence
theorem,subset,point-to-set
map,point-to-point
map
,
continuity
implies
closedness
,
global
convergence
theorem
,
zangwill
,
theorem
let,point-to-set
map
,
algorithm
,
iteration
,
fixed
point
,
complement
,
continuous
function
,
limit
point
,
theorem
,
convergence
,
standard
em
algorithm,dempster,theorem,n-best
list
approximate
em
,
converges
,
stationary
point,n-best
list
likelihood
,
difficulty
,
maximization
operator,iteration,n-best
list
,
estimation
,
model
parameter
,
previous
one,convergence,n-best
list
approximate
em
algorithm
,
condition
,
zangwill
,
global
convergence
theorem
,
composite
model
,
mixture
model
,
curved
exponential
family
,
complex
hierarchy
,
closed
form
solution
,
function
irrespective,n-best
list
parse
tree,n-best
list
approximate
em
algorithm,one-to-one
map,n-best
list
likelihood
,
function
,
satisfies
,
property
,
collection
,
al
a
s
calable
distributed
syntactic
,
semantic
,
lexical
language
model,n-best
list
parse
tree
,
sentence
,
entire
corpus
,
model
parameter
,
closed
form
solution
,
respect
,
inequality
,
result
,
result
,
stationary
point,n-best
list
likelihood
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
,
portland
,
oregon
,
association
,
computational
linguistics
a
l
arge
scale
distributed
syntactic
,
semantic
,
lexical
language
model
,
machine
translation
ming
tan
wenli
zhou
lei
zheng
shaojun
wang
kno
,
si
center
department
,
computer
science
,
shaojun
,
wang
wright
,
edu
abstract
,
attempt
,
large
scale
,
composite
language
model
,
local
word
lexical
information,mid-range
sentence
syntactic
structure,long-span
document
semantic
content
,
directed
markov
,
field
paradigm
,
composite
language
model
,
con
vergent
n-best
list
approximate
em
algorithm
,
linear
time
complexity
,
em
algorithm
,
word
prediction
power
,
corpus
,
supercomputer
,
large
scale
,
composite
language
model
,
drastic
perplexity
reduction
,
quality
,
ble
score,readability,n-best
list,state-of-the
art
parsing-based
machine
translation
system
,
ntroduction
,
markov
chain
,
source
model
,
previous
n-1
word,workhorse,state-of-the-art
speech
recognizers
,
machine
translator
,
foreign
language
ambiguity
,
probability
,
likely
original
underlying
word
string
,
research
group
,
immense
,
paradigm
,
billion
,
trillion
,
consistent
system
improvement
,
markov
chain
,
local
word
interaction,n-gram
model
,
semantic
structure
,
natural
language
,
final
report
,
approach
,
small
im
provements
,
mt
quality
,
problem
,
dire
need
,
novel
approach
,
language
,
jelinek
,
directed
mrf
frame
work
,
stochas
tic
property
,
composite
language
model
,
generalized
inside-outside
algorithm
,
composite
language
model
,
gen
eral
em
,
dempster
,
je
linek
,
ingenious
definition
,
inside
,
outside
probability
,
jelinek
,
sentence
length
time
complexity
,
experimental
result
,
composite
lan
guage
model,inside-outside
algorithm
,
composite
model
,
con
vergent
n-best
list
approximate
em
algorithm
,
linear
time
complexity,follow-up
em
al
gorithm
,
word
prediction
power
,
comprehensive
experiment
,
corpus
,
compare
perplexity
result
,
corpus
,
drastic
perplexity
reduction
,
language
model,n-best
list,chiang,chiang,state-of-the-art
parsing-based
mt
system
,
translation
quality
,
ble
score
,
readability
,
omposite
language,n-gram
language
model
,
word
predictor
,
entire
document
history
,
next
word
,
last
n-1
word
,
probability
,
chelba
,
jelinek
,
chelba
,
jelinek
,
syntactic
information
,
regular
n-gram
model
,
sentence
level
,
range
dependency
,
sta
tistical
parsing
technique
,
syntactic
anal
ysis
,
sentence
,
sentence
,
possible
binary
parse
,
terminal
,
pos
tag
,
phrase
headword,non-terminal
label
,
sen
tence
,
length
word
,
sentence
,
word
k-prefix
,
sentence
,
beginning
,
sentence
,
current
position,word-parse
k-prefix
,
word-parse
k-prefix
,
exposed
head,headword,non-terminal
label,root-only
tree
,
operator
,
next
word,left-most
,
headword,word-parse
k-prefix
,
prob
ability
,
tag
ger
,
pos
tag
tk
,
next
word
,
next
word
wk
,
pos
tag,left-most
,
head
word,word-parse
k-prefix
,
prob
ability
,
con
structor
,
partial
parse
tk
,
series
,
parse
move
,
proba
bility
,
con
structor
,
control
,
chelba
,
jelinek
,
hofmann
,
gener
ative
probabilistic
model,word-document
co
occurrence,bag-of-words
assumption
,
document
,
se
mantic
class,probability,rd-predictor
,
proba
bility
,
result
,
joint
probability
model,mixture,log-linear
model
,
expression
,
number
,
document
,
vocabulary
size
,
latent
semantic
class
variable
,
latent
semantic
class
variable
,
bot
tleneck
variable
,
word
occurrence
,
document
,
order
slm
,
composite
gen
erative
language
model
,
directed
mrf
paradigm
,
tag
ger
,
con
structor
,
sem
antizer
,
wor
d-predictors
,
m-s
lm
,
wor
-
pr
edictor
,
next
word,left-most
,
headword,word-parse
k-prefix
,
n-gram
history
wkk
,
semantic
con
tent
gk
,
parameter
,
wor
d-predictor
,
language
model
,
composite
language
model
,
complex
dependency
structure
,
ex
pressive
power
,
original
slm
,
figure
,
structure
,
lan
guage
model
,
directed
mrf
model
,
lo
cal
normalization
constraint
,
param
eters
,
language
model
,
hidden
information
,
parse
tree
,
semantic
content
,
wor
d-predictor
,
next
word
,
probability
,
lan
guage
model
,
likelihood
,
training
corpus
,
collection
,
document
,
joint
sequence
,
lth
sentence
,
parse
tree
structure
,
semantic
annotation
,
document
,
sequence
,
unique
sequence
,
model
action
,
prob
ability
,
probability
,
seman
tic
content
,
semantic
annotation
,
lth
sentence
,
recent
exposed
headword
,
semantic
content
,
semantic
annotation
,
lth
sentence
,
recent
exposed
headword
,
parse
tree
,
lth
sentence
,
document
,
constructor
,
conditioning
,
headword
,
parse
tree
,
lth
sentence
,
document
,
objective
,
maximum
likelihood
estimation
,
model
parameter
,
sentence
,
parse
tree
,
semantic
content
,
num
ber
,
parse
tree
,
sentence
length
,
generalized
inside-outside
algorithm
,
standard
em
algorithm
,
complexity
,
algorithm
,
sentence
length
,
large
corpus,jelinek,chelba,jelinek,n-best
list
approximate
em
similar
,
chelba
,
jelinek
,
list
approximate
em
re-estimation
,
modular
modification
,
effect
,
component
,
list
likelihood
,
1
a
1
a
,
parse
tree
,
sentence
,
document
,
cardinality
,
collection
,
sentence
,
entire
corpus,n-best
list
approximate
em
,
sentence
,
doc
ument
,
parse
tree
,
collection
,
list
parse
tree
,
sentence
,
entire
corpus
,
iteration
,
several
iteration
,
em
algorithm,parameter,best-list
likeli
hood
,
auxiliary
function,m-step
,
re
spect
,
new
update
,
iterate
step,convergence,best-list
likelihood
,
space
constraint,convergence,n-best
list
approximate
em
algorithm
,
zangwill
,
global
convergence
theorem
,
zangwill
,
list
search
strategy
,
parse
tree
,
multi
stack
search
strategy
,
chelba
,
jelinek
,
partial
par
,
likely
one
,
prefix
wk
,
probable
par
,
hypothesis
,
partial
par
,
number
,
wor
d-predictor
,
number
,
con
structor
operation
,
joint
prob
ability
,
parse
structure
tk
,
semantic
annotation
,
document
,
stack
vector
,
ordered
set
,
partial
par
,
number
,
wor
d-predictor
op
erations
,
different
number
,
con
structor
operation
,
wor
d-predictor
,
tag
ger
operation
,
hypothesis
,
maximum
number
,
hypothesis
,
con
structor
operation
,
resulting
hypothesis
,
finite
stack
size,log-probability
threshold
,
maximum
tolerable
difference,log-probability
score,top-most
hy
pothesis,bottom-most
hypothesis
,
parse
tree
,
sentence
,
document
,
document
,
em
algorithm
,
mate
model
parameter,e-step
,
expected
count
,
model
parameter
,
sentence
,
docu
ment
,
training
corpus
,
wor
-
pr
edictor
,
number
,
possible
semantic
annotation
sequence,forward-backward
recursive
formu
la
,
hidden
markov
mod
el
,
expected
count
,
forward
man
ner
,
word
k-prefix
,
sentence,k-prefix
,
backward
manner
,
subsequence
,
sen
tence
,
incremental
parse
struc
ture
,
parse
structure
,
prefix
,
generates
,
semantic
subsequence
,
gl
relevant
,
expected
count
,
wor
d-predictor
,
sentence
,
document
,
indicator
function
,
expected
count
,
sem
antizer
,
sentence
,
document
,
tag
ger
,
con
structor
,
expected
count
,
sentence
,
document
,
real
count
,
parse
tree,sentence,document,m-step
,
recursive
linear
interpolation
scheme
,
jelinek
,
mercer
,
smooth
probability
estimate
,
con
structor
,
tag
ger
,
con
structor
,
conditional
probabilis
tic
model
,
mixed
set
,
linear
markov
chain
,
re
cursive
mixing
scheme
,
standard
one
,
relative
frequency
estimate
,
different
order,chelba,jelinek,d-predictor
,
condi
tional
probabilistic
model
,
context
,
linear
markov
chain
,
combinatorial
number
,
relative
frequency
esti
mate
,
different
order
,
linear
markov
chain
,
jelinek
,
mercer
,
original
recursive
mixing
scheme
,
jelinek
,
mercer
,
lattice
,
situation
,
context
,
mixture
,
markov
chain,follow-up
em
,
chelba
,
jelinek
,
slm
component
,
large
fraction
,
partial
parse
tree
,
probability
,
next
word
,
multi
stack
search
strategy,n-best
approximate
em
algorithm
,
estima
tion
,
wor
d-predictor
,
predic
tive
power
,
weakness
,
wor
d-predictor
,
algorithm
,
language
model
probability
assignment
,
position
,
input
sentence
,
document
,
current
stage
,
synchronous
multi
stack
,
strategy
,
function
,
word
k-prefix
,
likelihood
,
training
corpus
,
language
model
probability
assignment
,
partial
parse
tree,process,multi-stack
search
strategy
,
second
stage
,
parameter
re
estimation
,
predictive
power
,
large
corpus
,
compos
ite
language
model
,
parameter
,
single
machine
,
computing
,
large
scale
,
language
model,n-grams
,
archi
tectures,client-server
paradigm
,
real
implementation
,
store
train
,
corpus
,
suffix
array,sub-corpus
,
server
serf
raw
count
,
test
sentence
,
client
,
comput
,
language
model
probability
,
sentence
,
client
,
server
,
gram
request
,
approach
,
standard
mapreduce
paradigm,ghemawat,corpus,number,client,n-gram
count,client,n-gram
count
,
number
,
server
,
result
ing,server,n-gram
,
language
model
probability
,
sentence
,
similar
approach
,
iteration
,
list
approximate
em
algorithm
,
corpus
,
num
ber
,
client
,
public
available
parser
,
sentence
,
client
,
initial
count
,
mg
etc
,
map
part
,
particular
,
different
client
,
server
,
lient
1
c
lient
2
c
lient
m
f
igure
,
architecture
,
a
m
apre
duce
paradigm
,
client
,
form
e-step
,
compute,server,parameter,m-step
,
pa
rameters
,
server
,
reduce
,
server
,
reduce
part
,
initialization
,
list
approximate
em
step
,
client
,
server
,
pa
rameters
,
synchronous
multi-stack
search
,
sentence
,
list
parse
tree
,
expected
count
,
particular
parameter
,
client
,
a
m
ap
part
,
server
,
reduce
part
,
procedure
,
convergence
,
distributed
architecture,figure,follow-up
em
algorithm
,
language
model
,
independent
test
set
,
independent
check
data
,
linear
interpolation
coefficient
,
mil
lion
,
corpus
,
cor
pora
,
data
set
,
ldc
english
gigaword
corpus,non-verbalized
punc
tuation
,
punctuation
,
detailed
information
,
data
set
,
ldc
english
gigaword
corpus
,
vocabulary
size,d-predictor
operation
,
bil
lion
tok
ens
training
cor
pus
afp
,
mil
lion
tok
ens
training
cor
pus
afp
,
mil
lion
tok
ens
training
cor
pus
afp
,
mil
lion
tok
ens
check
corpus
,
k
t
okens
test
cor
pus
cna
,
corpus
,
experiment
,
ldc
english
gigaword
corpus
,
section
,
ldc
english
gigaword
corpus
,
unk
token
,
million
token
,
ger
operation,vocabulary,non-terminal
tag
vocabulary
,
chelba
,
jelinek
,
headword
percolation
,
binarization
,
model
component
,
con
structor
,
parsed
sentence
,
opennlp
,
software
,
northedge
,
large
amount
,
sentence
,
ldc
english
gi
gaword
corpus
,
automatic
treebank
,
different
word-tokenization
,
manual
treebank
,
upenn
treebank
,
chelba
,
jelinek
,
token
corpus
,
sentence
,
model
parameter
,
token
corpus
,
sentence
,
portion
,
corpus
,
contain
,
model
parameter
,
parser
,
opennlp
,
upenn
treebank
,
mismatch
,
upenn
treebank
,
ldc
english
gigaword
corpus
,
nevertheless
,
perimental
result
,
approach
,
initial
value
,
model
parameter
,
rithms
,
a
m
apreduce
framework
,
discussion
,
access
,
large
cluster
,
machine
,
hadoop
,
token
level
corpus
,
map
function
,
re
duce
function
,
allelize
,
execute
program
,
func
tional
style
,
resource
,
access
,
supercomputer
,
supercomputer
center
,
core
processor
,
algorithm
,
supercomputer
,
map
part
,
reduce
part
,
massage
passing
,
scheduling
,
synchronization
,
client
,
server
,
fair
amount
,
implementation
,
hadoop
,
core
proces
sors
,
composite
language
model
,
core
processor
,
parameter
,
trigram
,
baseline
model
,
token
corpus
,
baseline
model
,
token
corpus
,
baseline
model
,
token
corpus
,
model
size
,
small
set
,
consideration
,
computational
time
,
source
demand
,
perplexity
result
,
computation
time,corpus,pre-defined
number
,
total
topic
,
different
number
,
likely
topic
,
document
,
bil
lion
token
corpus
,
likely
topic
,
composite
tri
gram
,
44m
token
corpus
,
computation
time
,
percent
perplexity
improvement
,
following
experiment
,
document
,
composite
language
model,n-best
list
approximate
em
algo
rithm
,
convergence
,
em
algorithm
,
second
stage
,
parameter
re-estimation
,
wor
-
pr
edictor
,
sem
antizer
,
conver
gence
,
experiment
,
general
account
,
prob
ability
,
plexity
result
,
variety
,
different
model
,
linear
combination
,
online
em
,
parameter
,
sem
antizer
,
test
document
,
m-s
lm
performs
,
large
scale
corpus
,
num
ber
,
predictor
,
composite
language
,
token
cor
pu
,
param
eters
,
wor
d-predictor
,
m-s
lm
,
supercomputer
,
approximation
,
linear
com
bination
,
num
ber
,
predictor
,
number
,
predictor
,
composite
4-s
lm
,
linear
combination
,
head
word
,
perplexity
,
result
,
corpus
,
different
number
,
likely
topic
,
document
,
m-s
lm
,
perplexity
result
,
various
language
model
,
test
corpus
,
denotes
linear
combination
,
composite
model
,
topic
node
,
supercomputer
,
signifi
cant
perplexity
reduction
,
baseline
n-grams
,
m-s
lm
,
major
ity
,
component
,
slm
component
,
relative
perplexity
reduction
,
word
corpus
,
statistical
machine
translation,1000-best
list
,
sentence
,
mt03
chinese-english
evaluation,chiang,chiang,state-of-the-art
parsing-based
translation
model
,
decoder
,
trigram
language
model
,
modified
kneser-ney
smoothing
,
kneser
,
token
corpus
,
translation
,
feature
,
language
model
,
language
model
,
ble
score
,
papineni
,
partition
,
ten
piece
,
training
data
,
ble
score
,
papineni
,
single
piece,1000-best
list
,
ble
score,cross-validation
process
,
validation
data
,
result
,
single
estimation
,
ble
score
,
ble
score,10-fold
cross-validation
,
baseline
,
much
diversity,1000-best
list
,
distinct
sentence,1000-best
list
,
chiang
,
performance
,
machine
translation
,
ble
score,n-gram
,
ble
score,n-gram
,
pas
decoder
,
much
diversity
,
composite
language
,
pas
decoder
,
chiang
,
chiang
,
5-g
ram
,10
-
fold
cross-validation
ble
score
result
,
ble
score
,
readability
,
translation
,
study
con
,
charniak
,
translation
,
good
bad
syntax
,
good
bad
meaning
,
human
judge
,
sentence
,
syntactic
lan
guage
model
,
charniak
,
charniak
,
translation
,
good
grammar
,
translation
,
meaning
,
language
model
,
charniak
,
charniak
,
language
model
,
syntax
,
translation
model
yamada,knight,tree-to-string
translation
,
language
model
,
list
re-ranking
,
charniak
,
output
,
difference
,
human
judgment
,
ble
score
,
agreement
,
syntactic
structure
,
semantic
information
,
ble
score
evaluation
,
example
,
similar
word
,
insure
,
ex
ample
,
ble
paper
,
papineni
,
formula
,
weight
,
goodness
,
syntactic
structure
,
modification
,
information
,
composite
lan
guage
model
,
stem
mod
el
p
s
g
w
bas
eline
,
5-g
ram
,
result
,
readability
,
evaluation
,
trans
lated
sentence
,
5
c
onclusion
,
first
work
,
complex
large
scale
,
language
model
,
principled
approach
,
large
corpus
,
result
,
composite
language
model
,
en
code
long
range
dependency
,
natural
language,n-gram
,
course
,
huge
amount
,
resource
,
computation
,
cloud
computing
,
reference
,
jelinek
,
mercer
,
per
plexity
,
measure
,
difficulty
,
speech
recognition
task
,
meeting
,
acoustical
society
,
amer
ica
,
supplement
,
large
language
model
,
ma
chine
translation
,
conference
,
empirical
method,immediate-head
parsing
,
language
model
,
annual
conference
,
association
,
yamada
,
syntax
,
language
model
,
jelinek
,
syntactic
structure
,
language
modeling
,
annual
conference
,
association
,
jelinek
,
lan
guage
modeling
,
computer
speech
,
language
,
hierarchical
phrase-based
model
,
statistical
machine
translation
,43
th
annual
con
ference
,
association
,
hierarchical
phrase-based
translation
,
computational
linguistics
,
ghemawat
,
mapreduce
,
simpli
,
data
processing
,
large
cluster
,
design
,
maximum
likelihood
estimation
,
incomplete
data
,
em
algorithm
,
journal
,
royal
statistical
society
,
sorensen
,
language
modeling
,
iee
e
in
ternational
conference
,
acoustic
,
speech
,
learning
,
proba
bilistic
latent
semantic
analysis
,
machine
learning
,
mercer
,
estimation
,
markov
source
parameter
,
sparse
data
,
pat
tern
recognition
,
practice
,
chelba
,
language
,
language
modeling
,
sixth
european
confer
ence
,
speech
communication
,
stochastic
analysis
,
structured
lan
guage
modeling
,
mathematical
foundation
,
speech
,
language
processing
,
martin
,
speech
,
language
processing,edition,backing-off
,
m-gram
language
modeling
,20
th
iee
e
in
,
tional
conference
,
acoustic
,
speech
,
statistical
phrase
,
translation
,
maximum
entropy
tech
niques
,
colloca
tional
dependency
,
language
modeling
,
computer
speech
,
language
,
machine
translation
working
group
final
report
,
www
nlpir,data-intensive
text
processing
,
mapreduce
,
morgan
,
software
http
,
codeproject
,
com
kb
,
englishpar
sing
,
minimum
error
rate
training
,
statisti
cal
machine
translation
,
annual
meeting
,
association
,
method
,
automatic
evaluation
,
machine
translation
,40
th
annual
meeting
,
associa
tion
,
probabilistic
top-down
parsing
,
language
modeling
,
computational
linguistics
,
lexical
regularity
,
language
modeling
,
markov
random
field
,
international
con
ference
,
stochastic
analysis
,
semantic
enhanced
structural
language
model
,
international
colloquium,knight,syntax-based
statis
tical
translation
model
,
annual
conference
,
association
,
nonlinear
programming,approach,language,n-best
list
re-ranking
,
conference
,
empirical
method
,
language
model
,
statisti
cal
machine
translation
