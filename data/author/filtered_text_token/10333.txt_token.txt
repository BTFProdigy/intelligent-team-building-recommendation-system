context
feature
,
canonical
belief
network
,
chinesepart
of
speech
tagginghongzhi
xu
,
chunping
lis
chool
,
software
,
tsinghua
universitykey
laboratory
,
information
system
security
,
ministry
,
education
chinaxuhz05
mail
,
tsinghua
,
cncli
tsinghua
,
tagging
,
essential
basis
,
algorithm
,
variety
,
pos
tag
,
thecontext
lexical
information
,
canonical
belief
network
,
determine
thepos
tag
,
a
c
hinese
corpus
,
standard
hmm
,
software
ict
clas
,
experimental
result
,
algorithm
,
tagging
,
process
,
corresponding
pos
tag
,
syntactic
categories
,
chineselanguage
,
word
segmentation
,
beforepos
tagging
,
sentences
,
distinct
boundary
,
whitespace
,
different
word
,
word
segmentation
,
pos
tagging
,
main
approach
,
pos
tagging
,
statistical
algorithm
,
merialdo
,
method
ex
tratct
rule
,
corpus
,
use
theserules
,
tatistic
based
algorithm
,
beliefnetwork
,
ex
icalized
hmm
,
maximal
entropymodel
,
ratnaparkhi
,
statistical
information
,
corpus
,
backgroundknowledge
,
theverb
,
adverb
ornothing
,
largeprobability
,
possible
pos
tag
,
unknown
word
,
process
,
noun
verb
,
adverb
verb
,
nothing
verb
,
statisticalinformation
,
information
,
nothing
,
lexical
information
,
thatis
,
probability
,
nothing
,
forinstance
,
context
information
,
lexicalized
hmm
,
main
problem
,
lexicalized
hmm
,
thatit
suffers
,
data
sparseness
,
new
algorithm
,
pos
tag
information
andlexical
information
,
canonical
beliefnetwork
,
turtle
,
tag907of
,
new
word
,
explorechinese
word
segmentation
method
,
related
information
,
insection
,
standardhmm
based
tagging
,
lexicalized
hmm
,
algorithm
,
insection
,
belief
network
,
algorithm
thatis
,
canonical
belief
network
,
isthe
experiment
,
result
,
hidden
markov
modelthe
problem
,
pos
tagging
,
observation
,
observation
,
tofind
,
bayesian
rule
,
sequence
,
chain
rule
,
formula
,
calculation
,
combination
explosion
,
different
pos
tag
,
nothing
,
independent
assumption
,
transition
probability
,
emission
probability
,
fromthe
training
,
tag
ti
,
wordwi
,
sequence
,
process
,
possible
pos
tag
,
eachword
,
possible
ti
,
process
,
finding
,
maximal
probability
,
forthis
sub
task
,
viterbi
,
efficient
algorithm
,
hidden
markov
modellexicalized
hmm
,
improvement
,
standard
hmm
,
probabilitypr
,
otherwords
,
word
wi
,
tagsof
,
context
information
,
wi
todetermine
,
data
sparseness
,
explosivelylarger
training
corpus
,
reliable
estimation
ofthese
parameter
,
technique
,
problem
,
back
off
smoothing
,
lexicalized
hmm
,
back
offmodel
,
corpus
,
estimation
,
estimation
,
n
grame
,
gram
estimation
,
back
off
probability
,
recursive
process
,
probabilistic
graphical
model
,
a
d
,
node
representrandom
variable
,
arc
represent
conditional
independence
assumption
,
figure
,
figure
,
figure
,
decompositionwould
,
large
amount
,
parameters
,
belief
network
,
conditional
independence
relationship
,
ancestor
,
parents
,
ancestor
parent
relationship
,
topological
ordering
,
thenodes
,
graph
figure1
,
figure
,
decomposition
,
detail
,
belief
network
,
turtlein
,
turtle
,
information
retrieval
task
,
canonical
form
,
different
feature
,
probability
combination
,
relationship
,
a
d
,
relationship
,
a
d
,
parents
,
wsum
relationship
,
a
d
,
parent
,
parent
,
different
weight
,
sum
relationship
,
node
dag
,
parentsand
,
parent
,
equal
weight
,
canonical
belief
network
,
parent
,
canonical
form
,
figure
,
canonical
formand
,
following
estimation
,
standard
belief
network
,
relationship
,
real
world
,
probability
,
person
,
umbrella
,
condition
,
person
,
raining
,
violent
sunlight
,
standard
belief
network
,
suchsituation
,
relationship
,
problem
,
context
information
,
tag
word
,
pos
tag
,
afeature
,
algorithm
,
actuallythe
n
gram
feature
,
lexicalized
hmm
,
canonical
form
,
figure
,
wethink
,
pos
tag
,
new
word
,
highconfidence
,
implication
,
certain
pos
tag
,
theprobabilities
,
canonicalbelief
network
,
word
wi
,
thetag
,
transition
probabilitycould
,
probability
,
emission
probability
,
return
,
pos
tagging
problem
whichneeds
,
tag
sequence
,
word
sequence
,
canonical
belief
network
,
ptransi
,
pomitipr
,
canonical
form
,
fromthe
data
sparseness
,
gram
feature
,
appear
,
training
corpus
,
canonical
belief
network
,
feature
contributes
nothing
,
probabilitythat
word
wi
,
n
grams
,
special
,
a4
gram
,
training
corpus
,
phrasewe
,
trainingcorpus
,
phrase
withreference
,
phrase
,
corpus
,
intuitional
comprehension
,
algorithm
,
motivation
,
decoding
,
problem
,
combination
explosion
,
highgrams
,
supposeone
word
,
possible
tag
,
average
,
different
feature
,
different
combination
,
combination
,
problem
,
features
,
offeature
f1t
,
feature
f2t
,
combination
,
followingfeatures
,
f1t
isv
bp
,
bookthis
,
total
combination
,
greedy
search
scheme
,
algorithm
viterbi
,
suppose
,
theviterbi
algorithm
,
probability
,
total
com
910bination
,
possible
tag
,
a
c
hinesecorpus
,
tag
set
,
pos
tags1
,
forthe
corpus
,
trainingset
,
test
set
,
corpus
information
,
unknownwords
,
test
set
,
intraining
set
,
machinewith
,1
gb
memory
,
training
,
test
setwords
,
corpus
information
,
unknown
word
,
possible
pos
tagsin
,
possibletags
,
wordin
,
test
set
,
appear
,
training
set
,
processing
,
relative
performance
,
different
pos
tagger
,
word
segmentation
,
segmentation
result
,
ict
clas
,
segmentation
result
,
prec
,
ratioof
,
test
set
,
precision
recall
f1
prec0
,
segmentation
result
,
ict
clas
,
open
test
,
algorithm
,
standard
hmm
,
cn
corpustagging
,
htm2ictclas3
,
commercial
software
,
computing
technology
,
academy
,
science
,
word
segmentation
,
pos
tagging
,
ict
clas
,
experimental
result
,
prec
seg
,
pos
tagging
precisionon
,
prec
,
test
set
,
prec
seg
,
ict
cla
s3
,
perform
,
thisis
,
tag
set
,
ict
cla
s3
,
mapping
scheme
,
ku
tag
,
precision
,
ict
clas
,
algorithm
,
algorithm
,
open
test
comparison
result
,
chinesecorpus
,
close
test
,
algorithm
,
advantage
,
moreinformation
,
training
set
,
aphrase
,
training
set
,
thiscase
,
testset
,
training
set
,
experimental
result
,
theperformance
,
algorithm
,
hmm
doesn
,
analysis
,
algorithm
,
satisfying
performance
,
technique
,
advantage
,
moreuseful
feature
,
probability
,
ti
f2t
,
addition
,
theadoption
,
technique
,
unknown
words911ictclas
hmm
cbn
precision
,
close
test
comparison
result
,
chinesecorpus
,
technique
,
algorithm
,
training
corpus
,
becausethey
,
weak
context
information
,
n
gram
model
,
n
gram
model
,
training
corpusis
,
future
workin
,
novel
algorithm
thatcombines
useful
context
feature
,
canonical
belief
network
,
newword
,
n
gram
model
,
training
corpus
,
datasparseness
problem
,
information
,
training
corpus
,
experiments
,
a
c
hinese
popular
corpus
,
ouralgorithm
,
result
,
unknown
word
,
parameter
,
algorithm
,
corpus
,
addition
,
extract
simple
context
information
,
useful
feature
,
algorithm
,
thesyntax
analysis
,
new
feature
,
a
p
o
sequence
,
maximal
probability
,
ouralgorithm
,
future
,
research
project
,
referencesadwait
ratnaparkhi
,
aximum
entropy
modelfor
part
of
speech
tagging
,
empirical
method
,
merialdo
,
text
witha
probabilistic
model
,
cutting
,
kupied
,
pedersen
,
penelopesibun
,
ractical
part
of
speech
tagger
,
inp
roceedings
,
conference
,
brill
,
simple
rule
based
part
,
speech
tagger
,30
th
conference
,
trento
,
brill
,
advance
,
transformation
based
part
,
speech
tagging
,
national
conference
,
turtle
,
croft
,
hwee
tou
ng
,
jin
kiat
low
,
part
of
speech
tagging
,
empirical
method
,
natural
language
understanding
,
cummings
publishing
company
,
graphicalmodels
,
technical
report
,
intel
research
technicalreport
,
maosong
sun
,
jiayan
zou
,
critical
appraisalof
,
research
,
word
segmentation
,
mengqiu
,
yanxin
shi
,
part
of
speech
reranking
,
word
segmentation
,5
th
workshop
,
chi
nese
language
processing
,
sang
zoo
,
ichi
tsujii
,
hae
chang
rim
,
hidden
markov
model
,
part
of
speech
tagging
,
international
conference
,
saarbrucken
,
harper
,
econd
order
hidden
markov
model
,
part
of
speech
tagging
,
conference
