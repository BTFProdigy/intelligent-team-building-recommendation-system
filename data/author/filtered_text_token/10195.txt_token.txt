proceeding
,
columbus
,
association
,
computational
linguisticsapplying
a
grammar
based
language
modelto
a
s
,
language
model
,
ona
precise
,
grammar
,
handcrafted
head
driven
phrase
structuregrammar
,
statistical
model
estimatingthe
probability
,
parse
tree
,
languagemodel
,
n
best
rescor
ing
step
,
theperformance
gain
,
baseline
system
,
thatour
approach
,
beneficial
fornon
trivial
broad
domain
speech
recognitiontasks
,
germanbroadcast
news
transcription
task
,
significant
reduction
,
word
error
rate
,
n
gramsmodel
natural
language
,
nth
order
markov
chain
,
crude
model
,
thecomplex
dependency
,
utterance
,
accurate
statistical
model
,
naturallanguage
,
ratnaparkhi
,
language
model
,
chelba
,
jelinek
,
continuous
speech
recognition
,
context
free
grammar
,
treebank
,
exception
,
chelba
andjelinek
,
probability
,
parser
operation
,
various
contextual
information
,
derivation
history
,
animportant
reason
,
success
,
probability
distributions
,
actual
wordsoccuring
,
utterance
,
partsof
speech
,
statistical
parser
,
high
robustness
,
respect
,
out
of
grammar
sentencesby
,
arbitrary
derivation
,
rule
expansions
,
reliably
decide
,
grammaticality
,
phrase
,
linguistic
constraints
inherent
,
natural
language
,
different
position
,
thefirst
place
,
language
model
,
ungrammatical
phrase
,
precise
,
motivated
grammar
,
uncommon
phrase
,
statistical
model
,
probabilityof
,
phrase
,
syntactic
dependency
,
parser
,
degree
ofrobustness
,
grammar
,
arbitrarysequences
,
phrase
,
grammar
restrictive
,
sequence
,
thestatistical
model
,
accurate
handcrafted
grammar
,
recognition
,
kiefer
,
speech
understanding
component
,
narrow
domain
task
,
appointment
,
orpublic
transport
information
,
speech
recognition
performance
onbroad
domain
recognition
task
,
beutler
,
similar
approach
,
grammar
based
language
model
didnot
,
probabilistic
component
,
simple
recognition
task
,
dictation
text
,
goodacoustic
condition
,
out
of
vocabulary
word
,
improved
language
model
,
experimental
result
,
muchmore
,
realistic
task
,
state
of
the
baseline
system
,
following
,
ourgrammar
based
language
model
,
linguistic
component
,
namelythe
grammar
,
lexicon
,
parser
,
challenge
,
thebroad
domain
speech
recognition
application
,
broadcast
news
data
,
general
approachspeech
recognizers
,
word
sequencew
,
posterior
probabilityp
,
acoustic
observation
,
thisis
,
optimizingw
,
language
model
weight
,
word
insertion
penalty
ip
lead
,
practice
,
theoretical
justification
,
ourgrammar
based
language
model
,
intothe
expression
,
probability
,
mostlikely
parse
tree
,
expensive
operationas
,
reason
,
criterion
,
hypothesis
,
thefinal
recognition
result
,
probability
,
treethe
parse
tree
,
parser
,
theprobability
,
parse
tree
,
flatdependency
tree
,
syntax
graph
representation
,
tiger
,
dependency
,
constituent
,
phrase
,
leaf
node
,
mostimportant
word
,
phrase
,
head
child
,
phrase
,
head
child
,
immediate
child
,
thefinite
verb
,
head
child
,
adverbial
,
complements
,
flat
structure
,
advantage
,
information
,
head
childis
,
locality
,
inner
node
,
statistical
independence
,
internal
structure
,
inner
node
,
probabilistic
context
free
grammar
,
equation
,
child
node
,
statistical
model
,
german
sentence
distinguishes
,
different
tag
,
noun
phrase
,
pronominal
np
,
non
pronominal
np
,
prenominal
genitives
,
prenominal
genitive
,
dedicatedtag
,
ordinary
np
,
clause
,
main
clause
,
subordinate
clause
,
arespecific
tag
,
infinitive
verb
phrase
,
adjectivephrases
,
prepositional
phrase
,
dedicated
probability
distribution
,
conditioning
tag
,
theprobability
,
internal
structure
,
sentencewas
,
trigram
probability
,
corresponding
tag
sequence
,
sequence
,
child
tag
,
probability
,
adjective
phrase
,
probability107of
,
probability
,
length
,
long
adjective
phrase
,
model
fornoun
phrase
,
joint
probability
,
proper
name
,
presence
,
determiner
,
presence
,
pre
and
postnominal
modifier
,
probability
,
various
event
,
variables
,
prepositional
phrase
,
relative
clause
,
adjective
,
presence
,
apposition
,
postnominalgenitives
,
probability
distribution
,
german
tiger
,
consists
,
newspaper
text
,
grammar
based
approachesto
language
modeling
,
out
of
grammar
utterance
,
utterance
,
grammar
,
utterance
,
grammar
,
correct
word
sequencemay
,
hypothesis
due
toout
of
vocabulary
word
,
bad
acoustic
condition
,
hypothesis
,
language
,
hypotheses
,
unlikely
thatsome
,
hypothesis
,
language
modelis
robust
,
respect
,
reasonable
parse
tree
,
accurate
,
motivated
grammar
,
constraint
,
grammar
,
parser
,
sequence
,
correct
phrase
,
root
node
,
attachment
,
probabilistic
context
free
rule
,
probability
,
qin
order
,
possible
word
sequences
,
saturated
phrase
,
arbitrary
word
,
sucha
productive
set
,
grammar
wouldlead
,
serious
efficiency
problem
,
reason
,
parser
,
correct
phrase
,
probable
sequence
ofphrases
,
distribution
,
language
model
,
parameter
,
language
model
weight
,
attachment
probabilityq
,
hypothesis
,
parameters
,
instance
,
utterance
,
well
covered
bythe
grammar
,
acoustic
condition
,
choice
,
experiments
,
influence
,
word
error
rate
,
recognizer
outputthe
linguistic
resource
,
sectionare
,
recognizer
output
,
speech
,
transcribe
number
,
single
word
,
instance
,
theword
,
einundzwanzig
,
twenty
one
,
war
plan
,
thesetranscription
variant
,
evaluation
scheme
,
grammarshould
,
parserwe
,
pollard
,
formalism
,
precise
large
coverage
grammar
,
unrestricted
grammar
,
chomskytype
,
context
free
skeletonand
,
unification
,
complex
feature
structure
,
several
variant
,
formal
tool
,108
guistic
constraint
,
particular
variant
,
phrase
,
mechanism
,
discontinuitiesas
present
,
german
main
clause
,
seekaufmann
,
pfister
,
distinguishes
,
immediate
dominance
schema
,
rough
equivalent
,
phrase
structure
rule
,
assumption
,
constituent
order
,
precedence
rule
,
constraint
,
distinction
,
letimmediate
dominance
schema
specify
constituentorder
,
formalism
,
complex
linguistic
constraint
,
predicate
orrelational
constraint
,
parse
time
,
predicate
,
program
code
,
arbitrarycomputations
,
feature
structure
,
efficient
java
parser
forour
variant
,
hps
formalism
,
parser
supports
ambiguity
packing
,
technique
,
constituent
,
different
derivational
histories
,
identical
syntactic
property
,
grammar
,
many
idea
,
construction
,
formalsyntactic
theory
,
prenominal
andpostnominal
genitive
,
expression
,
quantity
andexpressions
,
dedicated
subgrammars
,
analyzingwritten
number
,
acronym
,
separate
word
,
ambiguity
,
onlynoun
noun
,
grammar
,
noun
noun
,
grammar
,
general
linguistic
phenomenon
,
subcategorization
,
modification
,
extraction
,
german
verbal
complex
,13
construction
specific
rule
,
relative
clause
,
genitiveattributes
,
optional
determiner
,
adjectives
,
various
subgrammars
,
expressionsof
date
,
noun
noun
,
acronym
,
amount
,
grammar
,
derivation
,
intermediate
product
,
complete
phrase
,
complete
phrase
,
besentences
,
subordinate
clause
,
interrogative
clause
,
noun
phrase
,
prepositional
phrase
,
adjective
phrase
,
expression
,
n
best
,
domain
,
recognitiontask
,
possible
reading
,
main
source
ofdictionary
information
,
syntactic
information
,
basic
valencyframes
,
complement
,
difficulty
,
acquisition
,
multi
word
lexeme
,
commonnotion
,
following
definition
,
syntactic
unit
,
multi
word
lexeme
,
grammar
,
andlarge
,
phrasal
verb
,
multi
word
lexeme
,
thelexicon
,
theword
list
,
fromsupplementary
resource
,
text
corpus
,
frankfurterrundschau
,
corpus
,
article
,
thefirst
broadcast
news
show
,
inthe
next
paragraph
,
typesof
multiword
,
method
,
extractingthem
,
productive
class
,
ger
man
prefix
verb
,
prefix
,
phrasal
verb
,
prefix
,
untergehen
,
tosink
,
da
schiff
geht
unter
,
shipsinks
,
weil
da
schiff
untergeht
,
ship
sink
,
possible
valency
frame
,
prefix
verb
,
prefix
,
certain
circumstance
,
prefix
verb
,
newspaper
text
corpus
,
prefix
verb
,
candidate
prefix
verb
,
intothe
lexicon
,
recognizer
hypothesisin
,
procedure
,
test
data
,
hypothesis
,
parser
chart
,
multiword
lexeme
,
part
arepresent
,
hypothesis
,
multi
word
lexeme
,
word
clusters
,
instance
,
prepositional
phrase
,
support
verb
constructions
,
unter
beschuss
,
multi
wordlexemes
,
nach
wie
vor
,
auf
die
dauer
,
suffix
array
,
ya
mamoto
,
church
,
pointwise
mutual
information
measure
,
church
,
thoseclusters
,
recognizer
hypothesis
,
candidate
cluster
,
different
filter
heuristic
,
split
,
multi
word
lexeme
,
grammar
,
model
noun
noun
,
unionsgefu
,
lexicon
,
algorithm
,
adda
decker
,
corpus
,
candidate
list
,
many
proper
noun
,
personal
name
,
geographic
name
,
identical
tosome
noun
,
verb
form
,
lexicon
share
inflected
form
,
personal
name
,
proper
,
ambiguity
,
ofthem
,
determiner
,
homograph
,
open
classword
,
ourtask
,
relevant
,
proper
noun
,
text
corpus
,
smalldatabases
,
formsof
address
,
personal
name
,
significant
bi
grams
,
relevant
geographic
name
,
certain
local
preposition
,
final
lexicon
contains
,
separable
prefix
,
adjective
,
closed
class
word
,
multiword
lexeme
,
lexicon
entry
,
full
form
,
noun
noun
,
theyare
,
speech
recognition
system
,
fromour
grammar
based
language
model
,
baseline
speech
recognition
system
,
hypothesis
,
respective
score
,
grammar
based
language
model
,
hypothesis
,
test
set
,
word
error
rate
,
baseline
system
,
extended
system
,
thegrammar
based
language
model
,
preprocessingour
experiment
,
word
lattice
output
,
adda
decker
,
gram
backoff
language
model
,
mct
ait
,
adda
decker
,
broadcastnews
,
signal
lengthof
,
minute
,
original
broadcast
news
transcription
task
,
artificial
recognition
taskwith
manageable
complexity
,
primary
aim
wasto
design
,
theproperties
,
grammar
based
approach
,
competitivebaseline
system
,
first
simplification
,
perfect
sentence
segmentation
,
originalword
,
mergedthem
,
lattice
boundary
,
lattice
,
ec
ond
,
respect
,
clock
broadcast
,
tagesschau
,
the14th
,
high
baseline
word
error
rate
,
classesare
interview
,
word
error
rate
,
press
conference
,
lattice
,
lattice
,
hypotheses
,
recognizer
hypotheses
,
lexiconas
described
,
hypothesis
,
the44000
hypotheses2
,
early
termination
,
parser
,
imposed
memory
limit
,
however
,
inversion
,
ambiguity
packing
,
bottleneck
,
possiblereadings
,447
lattices
,
hypothesis
,
reading
,
lattices
,
grammar
based
language
model
,
efficiency
reason
,
difficulty
,
reference
transcription
,
andthe
n
best
list
,
utterance
,
utterance
,
correcttranscription
,
best
hypothesis
,
thefirst
best
hypothesis
,
utterance
,
out
of
vocabulary
rate
,
reference
transcriptionwords
,
lattice
,
first
best
word
error
rate
,
best
oracle
word
error
rate
,
grammaticality
,
reference
transcription
,
contain
general
grammatical
construction
,
grammar
,
theseconstructions
,
ellipsis
,
broadcast
news
report
,
ambiguity
,
grammar
,
grammar
,
differenthypotheses
,
testingthe
parameter
,
maximum
number
,
hypotheses
,
effect
,
different
value
,
parameter
,
leave
one
out
cross
validation
method
,
utterance
,
single
test
item
,
remaining446
utterance
,
training
,
error
landscape
,
gradient
based
optimization
method
,
equidistant
point
withinthe
interval
,
theword
error
rate
,
possible
pairof
parameter
value
,
evaluation
scheme
,
mct
aitand
adda
decker
,
single
word
,
grammar
based
languagemodel
,
word
error
rate
,
baseline
system
,
improvementis
,
mcn
emar
,
gillickand
cox
,
parameter
,
test
data
,
worderror
rate
,
relative
,
comparison
,
probabilisticmodel
,
phrase
,
root
node
,
reduced
model
,
grammaticality
ofa
phrase
,
probability
,
itsinternal
structure
,
relative
word
errorreduction
,
improvement
,
full
model
,
reducedmodel
,
forthe
map
sswe
test
,
optimal
value
,
training
run
,
language
,
reduced
model
,
respective
value
,
full
model
,
full
model
,
morereliable
information
,
word
error
ratebaseline
,
grammar
,
statistic
,
grammar
,
grammar
,
best
oracle
,
impact
,
grammar
based
languagemodel
,
word
error
rate
,
comparison
,
resultsfor
alternative
experiment
,
grammar
,
parameter
,
figure
,
effect
,
maximum
number
,
hypothesis
,
word
error
rateboth
,
leave
one
out
training
,
optimizingthe
parameter
,
test
data
,
similar
shape
,
observed
variationsare
,
problem
structure
,
new
hypothesis
,
benefit
,
grammar
based
language
model
,
hypotheses
,
respect
,
word
error
rate
,
decrease
,
horizoneffect
,
hypotheses
,
high
rank
,
parameter
estimation
,
accidental
horizon
effect
,
therefore
,
outlookwe
,
language
model
,
precise
,
motivated
grammar
,
difficult
broad
domaintask
,
well
known
fact
,
natural
language
,
correct
,
enormous
number
ofreadings
,
approach
evenmore
relevant
,
phenomenon
,
incorrect
word
,
benefit
,
pure
grammaticality
information
,
solutionis
,
additional
information
,
reading
,
test
datafigure
,
word
error
rate
,
function
,
maximum
number
,
hypothesis
,
first
step
,
direction
,
probability
,
parse
tree
,
atthe
structure
,
parse
tree
,
actual
word
,
account
,
n
grams
,
statisticalparsers
,
word
information
,
investigate
,
word
information
,
ourgrammar
based
model
,
acknowledgementsthis
,
swiss
national
science
foundation
,
luc
gau
vain
,
lim
,
german
broadcast
news
transcription
system
,
adda
decker
,
corpus
based
,
german
lexical
modeling
,
lvc
sr
,
inp
roceedings
,
pfister
,
non
probabilistic
grammar
,
large
vocabularycontinuous
speech
recognition
,
proceeding
,
theieee
asr
,
workshop
,
san
,
tiger
treebank
,
proceeding
,
theworkshop
,
treebanks
,
linguistic
theory
,
so
zopol
,
charniak
,
maximum
entropy
inspired
parser
,
proceeding
,
naa
cl
,
jelinek
,
languagemodeling
,
mutual
information
,
lexicography
,
computational
linguistics
,
head
driven
statistical
model
fornatural
language
parsing
,
computational
linguistics
,
crysmann
,
efficient
implementation
ofg
erman
verb
placement
,
proceeding
ofr
anlp
,
crysmann
,
relative
clause
extraposition
ing
erman
,
portable
implementation
,
research
,
language
,
rterbuch
der
deutschensprache
,
dudenverlag
,
dritte
auflage
,
gillick
,
statistical
issue
,
comparison
,
speech
recognition
algorithm
,
inp
roceedings
,
kaufmann
,
pfister
,
licenserrules
,
grammar
,
continuous
constituent
,
editor
,
proceeding
,
international
conference
,
head
driven
phrase
structure
grammar
,
krieger
,
robust
parsing
,
word
hypothesis
,
wahlster
,
editor
,
verbmobil
,
foundations
,
speech
to
speech
translation
,
springer
,
berlin
,
artificial
intelligence
edition
,
adda
decker
,
lim
sige
rman
broadcast
news
transcription
system
,
proceedings
,
deutsche
syntax
deklarativ
,
linguistische
arbeiten
,
niemeyerverlag
,
head
driven
phrase
structure
grammar
,
eine
einfu
,
stauffenburg
einfu
,
robust
grammatical
analysis
,
spoken
dialogue
system
,
head
driven
phrasestructure
grammar
,
chicago
press
,
chicago
,
ratnaparkhi
,
naturallanguage
,
maximum
entropy
model
,
machinelearning
,
probabilistic
top
down
parsingand
language
modeling
,
computational
linguistics
,
yamamoto
,
suffixarrays
,
term
frequency
,
document
frequency
,
substring
,
corpus
,
computationallinguistics
