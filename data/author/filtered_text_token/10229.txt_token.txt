proceeding
,
columbus
,
association
,
computational
linguisticsefficient
,
conditional
random
field
parsingjenny
finkel
,
kleeman
,
manningdepartment
,
computer
sciencestanford
universitystanford
,
akleeman
,
eduabstractdiscriminative
feature
based
method
,
natural
language
processing
,
generative
method
,
prior
feature
baseddynamic
programming
parser
,
evaluation
,
short
sentences
,
feature
discriminative
parser
,
conditional
random
field
model
,
full
wsj
parsingdata
,
efficiency
,
stochastic
optimization
technique
,
parallelization
,
chart
prefiltering
,
relative
reduction
,
previous
model
,
ordersof
magnitude
,
length40
,
f
score
,
relative
reduction
,
past
decade
,
feature
based
discriminativemodels
,
choice
,
manynatural
language
processing
task
,
theytake
,
generative
model
,
large
part
,
ability
,
constituency
parsing
,
bygenerative
method
,
computational
complexity
,
problem
,
previous
,
discriminative
reranking
,
then
best
list
,
generative
parser
,
generative
parser
score
asa
feature
,
charniak
,
johnson
,
asequence
,
discriminative
decision
,
small
beam
,
ratna
parkhi
,
third
thread
,
joint
inference
viadynamic
programming
algorithm
,
trainmodels
,
context
,
inference
time
,
exception
,
petrov
,
grammar
,
latent
variable
,
donot
restrict
,
howevertheir
model
,
discriminative
parser
,
advantage
,
discriminative
training
,
nlp
task
,
modeling
improvement
,
switch
,
generative
training
,
training
,
performance
gain
,
thegains
,
good
feature
engineering
,
forexample
,
lafferty
,
switchingfrom
,
linear
chain
,
part
of
speechtagging
,
small
set
,
orthographic
features
,
crf
error
rate
drop
,
out
of
vocabulary
error
rate
,
parsing
gain
,
switch
959ing
,
training
,
andby
petrov
,
small
gain
,
final
model
,
method
,
framework
,
feature
discriminative
parser
,
unlikeprevious
,
shortsentences
,
result
,
trainingand
,
length
,
training
,
length
,
previous
wsj
,
result
,
contextwith
respect
,
modern
parsing
literature
,
ourmodel
,
conditional
random
field
,
rule
application
,
arbitrary
featuresto
,
rule
category
,
splitpoint
index
,
constituent
length
influence
parseprobability
,
pcf
g
,
information
,
account
,
benefit
,
featurebased
model
,
smoothing
,
unseen
rule
,
rulemay
,
practicality
,
source
,
wemade
use
,
stochastic
optimization
method
,
optimal
model
parameter
,
veryfew
pass
,
difference
,
parser
performance
,
limitedparallelization
,
prefiltering
,
speedup
,
aperformance
cost
,
f
score
,
relative
reduction
,
previous
workon
,
conditional
random
field
model
,
blunsom
,
jousse
,
particular
tree
structure
,
likely
structure
,
labeling
,
parsing
,
twoexceptions
,
parse
tree
,
joint
likelihood
,
probabilities
,
graphical
model
depiction
,
manning
,
nonterminals
nk
,
designated
start
symbolroot
,
sequence
,
terminal
,
nonterminals
,
probability
,
localclique
potential
,
one
level
subtree
,
corresponding
,
split
position
,
a
p
cfgw
,
rule
score
,
access
,
theleaves
,
many
word
,
conditional
probability
distribution
,
entire
tree
,
standardcrf
distribution
,
important
subtlety
,
thepartition
function
,
probability
,
possible
par
,
tounity
,
structure
,
belings
,
structure
,
possible
parse
tree
,
allcfgs
,
unary
rule
,
unary
chain
,
infinitemass
,
literature
,
grammar
,
classof
cfg
,
binariza
tion
,
earley
,
parsing
time
,
closure
,
unary
chain
,
total
probability
mass
,
tolcke
,
issue
,
restricted
class
,
parse
tree
,
corresponding
rule
,
potential
,
unary
chain
,
repeated
state
,
allowed
unary
chain
,
single
unary
rule
,
disallowing
multiple
unary
rule
application
,
detail
,
binarizationscheme
,
grammar
,
weakly
equivalent
,
anyarbitrary
cfg
,
objective
functionour
clique
potential
,
exponential
form
,
feature
function
,
vector
,
corresponding
parameter
,
eachfeature
,
clique
potential
function
,
log
conditional
likelihood
,
training
datad
,
additional
l2
regularization
term
,
partial
derivative
,
log
likelihood
,
withrespect
,
model
weight
,
difference
,
empirical
count
,
modelexpectations
,
implementation
,
inside
outside
algorithm
,
outside
score
,
application
,
unaryrules
,
partition
function
z
,
inside
score
,
partial
derivative
,
span
split
,
outside
log
score
,
parent
,
inside
log
score
,
log
score
,
thenormalized
log
probability
,
position
,
probability
,
rule
application
,
span
split
,
expected
feature
value
,
second
term
,
equation4
,
probability
,
weight
,
partial
derivative
,
process
,
computation
,
partial
derivativesin
linear
chain
crf
,
complexity
,
algorithm
,
isthe
length
,
taskar
,
algorithm
,
theadvantage
,
computation
,
boththe
log
likelihood
,
partial
derivative
,
computation
,
computation
,
server
,
information
,
relevant
information
,
stochastic
optimization
method
,
small
portion
,
training
data
ata
time
,
clique
potentialswhich
,
nonnegative
number
,
probability
,
additional
clientsdecrease
,
computation
time
,
onthe
inside
pas
,
algorithm
,
manyrules
,
completeparses
,
standard
pcf
,
particular
chartposition
,
big
difference
,
features
,
product
,
feature
weight
,
outside
pas
,
whichis
,
impossible
rule
applications
,
data
multiple
time
,
information
justonce
,
subsequent
iterationson
,
inside
outside
pas
,
position
,
thechart
,
possible
rule
,
entire
data
structure
,
re
computation
,
first
time
,
prefiltering
,
subsequent
iterationsthe
improvement
,
training
,
expensive
objective
functionslike
,
on
line
backpropagationlearning
,
neural
network
parser
,
hen
derson
,
stochastic
gradient
,
standard
deterministic
optimization
,
lb
fgs
,
nocedal
,
littleprogress
,
initial
iteration
,
several
pass
,
sufficient
condition
,
line
search
,
objectivefunction
value
,
lb
fgs
,
sgd
versus
,
objective
value
,
wellon
test
data
,
iteration
,
figure
,
comparable
test
,
lb
fgs
,
fraction
ofthe
time
,
early
experiment
,
aseven
time
speed
,
stochastic
optimization
routine
,
implementation
,
stochastic
objectivefunction
,
true
function
,
small
subsetof
,
training
data
,
thebatch
size
,
btraining
,
replacement
,
notation
,
thestochastic
evaluation
,
function
,
stochastic
function
,
property
,
scaling
,
objective
function
,
trainingdata
,
factor
,
derivativeof
,
stochastic
function
value
,
standard
update
,
gain
schedule
,
parameter
,
initial
gain
,
application
,
experiments
,
length
,
feature
development
,
thelength
,
corpus
,
fastertrain
,
test
time
,
sentencesand
,
training
data
,
features
,
lexicon
feature
,
grammar
features
,
local
subtrees
,
corresponding
span
split
,
access
,
dis
criminatively
trained
model
,
therules
,
grammar
feature
,
feature
based
model
,
grammar
features
,
access
,
lexicon
features
,
equivalent
,
moreelaborate
,
unknown
word
model
,
many
pcf
parser
,
petrov
,
extra
piece
,
information
,
eachword
,
distributional
similarity
tag
,
distributional
similarity
model
,
national
corpus
,
gigaword
corpus
,
unknown
word
model
,
manning
,
account
capitalization
,
character
level
features
,
full
set
,
explanation
,
notation
,
usedbinary
unarymodel
state
rule
ruleswsj15
,
grammar
size
,
standard
split
,
testing
,
development
,
section22
,
previous
,
discriminative
parsing
,
result
,
length
,
parsing
literature
,
result
,
length
,
situate
,
respect
,
setsof
literature
,
length
,
ourresults
,
context
,
previous
,
simple
grammar
,
additional
annotation
,
grammar
readoff
,
training
set
,
parent
,
pos
tag
,
inrules
,
tag
annotation
,
manning
,
right
branching
,
active
state
,
previoussibling
,
first
child
,
second
order
markovprocess
,
active
state
,
first
child
,
first
order
markov
process
,
forthe
number
,
generative
model
,
discriminative
model
,
lexicon
feature
,
grammar
,
therules
,
feature
based
model
,
access
,
length
,
data
wealso
,
grammar
,
grammar
,
rulesand
,
parent
annotation
,
parentof
,
stochastic
gradient
,
lexicon
,
grammar
feature
,
particular
rule
,
span
splitinformation
,
parent
,
binaryrules
,
last
word
,
rule
span
,
particular
context
,
pos
tag
,
base
label
,
parent
annotation
,
distributional
similarity
cluster
,
cased
version
,
word
class
,
lexicon
feature
grammar
featurest
binary
specific
featuresb
,
right
child
,
verb
tag
,
bigram
,
base
parent
state
unaries
,
trigram
,
constituent
,
johnson
,
length
,
batchsize
,
twenty
pass
,
batch
sizeof
,
ten
pass
,
development
data
,
models
,
generative
number
,
entire
ptb
,
much
performance
,
thereduced
training
data
,
generative
all
,
full
result
,
wsj
15models
,
single
dual
coreamd
opterontm
,
gigabyte
,
andno
parallelization
,
trained
generative
model
,
minute
,
feature
based
model
,
minute
,
feature
based
model
,
relaxed
grammar
,
longas
,
regular
feature
based
model
,
because
,
replacement
,
thiswe
mean
,
trained
generative
wsj
,
samemachines
,
gigabyte
,
pas
throughthe
data
,
feature
based
wsj
,
thesemachines
,
gigabyte
,
forthe
client
,
pas
throughthe
data
,
boththe
switch
,
training
,
extensive
use
,
theparse
tree
,
generative
model
,
feature
based
discriminative
model
,
correct
parse
,
feature
based
modelbetter
,
right
branching
tendency
,
heavy
feature
,
whichencourages
long
constituent
,
standard
pcf
,
thisaspect
,
language
,
account
,
server
,
computation
,
p
r
f1
exact
avg
cb
c
b
p
r
f1
exact
avg
cb
c
bdevelopment
set
,
length
,
length
,
development
,
test
set
result
,
training
,
length
,
treebank
,
model
p
r
f1
exact
avg
cb
c
b
p
r
f1
exact
avg
cb
c
btest
set
,
length
,
sentencespetrov
,
test
set
result
,
length
,
treebank
,
generative
all
result
,
length6
comparison
,
related
workthe
,
similar
related
,
johnson
,
discriminative
training
,
generativepcfg
,
parameter
,
score
forrules
,
generatively
trained
model
,
ati
treebank
corpus
,
training
sentences
,
average
sentence
length
,
significant
difference
,
trained
parser
,
thereare
,
probable
reason
,
result
,
trainingset
,
known
fact
,
generative
model
,
small
datasetsand
discriminative
model
,
forlarger
datasets
,
primarybenefits
,
discriminative
learning
,
taskar
,
large
margin
approachto
discriminative
learning
,
grammar
,
grammar
,
theintent
,
particular
statethere
,
average
,
parent
,
learning
algorithm
,
option
,
grammar
,
difficult
,
training
time
,
several
month
,
according
,
melamed
,
feature
engineering
,
possible
feature
,
melamed
,
turian
et
,
thetraining
time
,
taskar
,
simple
linear
model
,
decision
tree
,
feature
conjunction
,
linesearch
,
parameter
,
anagenda
parser
,
atomic
feature
,
decision
tree
,
entire
state
,
extensive
use
,
onlysmall
gain
,
taskar
,
similar
research
,
petrov
,
discriminative
parsing
,
different
setup
,
previous
,
petrov
,
grammar
splitting
,
output
,
feature
based
discriminative
model
,
correct
parse
,
latent
variable
,
non
convex
function
,
stochastic
optimization
technique
,
coarse
to
fine
pruning
,
gradient
,
log
likelihood
,
grammar
splitting
,
taskar
,
small
gain
,
dynamic
programming
,
parser
,
simpler
,
thanprevious
,
new
state
of
the
performance
,
training
,
first
result
,
length
,
crf
performs
,
lb
fgs
,
fraction
,
discriminative
parsing
,
ofthe
main
advantage
,
discriminative
training
methods
,
namedentity
recognition
,
part
of
speech
tagging
,
gotten
,
frombetter
model
,
framework
,
acknowledgmentsmany
thanks
,
teg
grenager
,
heymannfor
,
advice
,
general
awesomeness
,
anonymous
reviewer
,
helpful
comments
,
part
bythe
defense
advanced
research
project
agencythrough
ibm
,
phase
iii
program
,
advanced
questionanswering
,
n61339
r
,
a
s
cottish
enterprise
edinburgh
link
,
r37588
,
eas
ieproject
,
referenceseugene
charniak
,
johnson
,
coarse
to
fine
n
best
parsing
,
maxent
discriminative
rerank
ing
,
syntactic
category
,
distribution
clustering
,
conferenceon
computational
natural
language
learning
,
cohn
,
blunsom
,
semanticrole
,
tree
conditional
random
field
,
natural
language
parsing
,
earley
,
algorithm
,
communication
,
discriminative
training
,
aneural
network
statistical
parser
,
johnson
,
conditional
estimation
oftagging
,
parsing
model
,
meeting
,
association
,
computational
linguistics
,
florent
jousse
,
tellier
,
marctommasi
,
conditional
random
field
,
ecm
l
workshop
,
mining
,
learning
ing
raphs
,
klein
,
manning
,
parsing
,
proceeding
,
association
,
lafferty
,
mcc
allum
,
pereira
,
conditional
random
field
,
probabilistic
models
,
sequence
data
,
ini
cml
,
kaufmann
,
nocedal
,
limitedmemory
bfg
method
,
large
scale
optimization
,
programming
,
manning
,
hinrich
schu
,
foundation
,
statistical
natural
language
processing
,
mit
press
,
cambridge
,
santorini
,
annmarcinkiewicz
,
large
annotated
corpus
,
treebank
,
computationallinguistics
,
ng
,
comparison
,
logisticregression
,
naive
bayes
,
advance
,
slav
petrov
,
thibaux
,
danklein
,
interpretable
tree
annotation
,
slav
petrov
,
klein
,
discriminative
log
linear
grammar
,
latent
variable
,
linear
observed
time
statistical
parser
,
maximum
entropy
model
,
efficient
probabilisticcontext
free
parsing
algorithm
,
prefixprobabilities
,
computational
linguistics
,
taskar
,
klein
,
koller
,
manning
,
marginparsing
,
proceeding
,
conference
,
empirical
method
,
turian
,
melamed
,
advance
indiscriminative
parsing
,
turian
,
wellington
,
melamed
,
scalable
discriminative
learning
,
natural
language
parsing
,
translation
,
advance
,
vishwanathan
,
schraudolph
,
conditional
random
field
,
stochasticgradient
method
