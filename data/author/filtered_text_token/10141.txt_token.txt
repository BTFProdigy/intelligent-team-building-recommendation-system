proceeding
,
international
conference
,
computational
linguistics
,
coling
,
lattice
reranking
,
intelligent
information
processinginstitute
,
technologychinese
academy
,
sciencesp
,
beijing
,
graduate
,
academy
,
sciencesbeijing
,
jiangwenbin
,
new
rerank
ing
strategy
,
word
lattice
reranking
,
joint
word
segmentation
,
derivation
,
rerankingfor
parsing
,
strategyreranks
,
pruned
word
lattice
,
storage
,
withthe
traditional
n
best
list
,
aperceptron
classifier
,
local
features
,
baseline
,
word
lattice
rerank
ing
performs
,
nonlocal
features
,
intothe
perceptron
baseline
,
experimental
results
show
,
strategy
,
improvement
,
segmentation
,
pos
tagging
,
perceptron
baseline
,
n
best
list
,
word
segmentation
,
pay
much
attention
,
discriminativemethods
,
ratnaparkhi
,
adwait
,
percep
tron
training
algorithm
,
generative
one
,
discriminative
model
,
advantage
,
flexibility
,
perfect
accuracy
,
typical
approach
,
discriminative
model
,
coling
,
organizing
,
publication
,
republishing
inany
form
,
medium
,
segmentation
,
classification
style
,
character
,
positional
tag
,
itsrelative
position
,
thesepositional
tag
,
pos
information
,
segmentation
,
pos
tagging
,
asingle
pas
,
unify
classification
framework
,
operation
,
experimentsof
ng
,
segmentation
,
ata
time
,
segmentation
,
pos
tagging
,
usual
local
feature
,
thecharacter
based
one
,
ngand
low
,
many
nonlocal
feature
,
decoding
procedure
,
classifier
result
,
problem
,
classifier
,
feature
space
,
apt
tooverfit
,
training
corpus
,
second
,
variance
ofnon
local
feature
,
training
procedure
,
parameter
tuning
,
current
predication
relies
,
result
,
prior
predications
,
exact
inference
,
an
best
candidate
list
,
position
,
potential
risk
,
parameter
,
procedure
,
result
,
useful
feature
,
higher
order
wordor
pos
gram
,
non
localfeatures
,
well
known
reranking
technique
,
many
nlp
task
,
instance
,
syntactic
parsing
,
machine385v0v1v2v3v4v5v6v7c1
,
word
lattice
,
directed
graph
,
character
sequence
,
clarity
,
subsequence
pos
pair
,
single
edge
,
ignore
,
translation
,
packed
,
many
par
,
word
latticereranking
,
strategy
,
pruned
wordlattice
,
baseline
classifier
,
n
best
list
,
word
lattice
,
directed
graph
,
figure
,
packed
structure
,
many
possibility
,
segmentation
andpos
,
chi
nese
treebank
,
wordlattice
gain
obvious
improvement
,
baseline
classifier
,
n
best
list
,
baseline
,
errorreduction
,
segmentation
,
word
lattice
,
theedge
set
,
word
lattice
,
sentencec1
,
position
,
ciand
ci
,
source
node
,
cnisthe
sink
node
,
vbandarrives
,
subsequence
,
possibleword
,
word
pos
pair
,
seriesof
adjoining
edge
,
source
node
,
sink
node
,
calleddiameter
,
specific
pattern
,
segmentation
,
pos
tagging
,
diameter
,
length
,
diameter
,
figure
,
diameter
,
latticegiven
,
reference
,
prunedword
lattice
,
baseline
classifier
,
oracle
diameter
,
thediameter
,
f
measure
,
function
,
algorithm
,
adaptedto
lexical
analysis
,
oracle
computation
,
describe
,
algorithm
,
detail
,
key
point
,
oracle
diameter
,
output
,
word
count
,
matched
wordcount
,
precision
,
notice
,
linear
function
,
access
,
eachpossible
,
themaximum
matched
word
count
,
possiblediameter
length
,
algorithm
,
dynamic
programming
manner
,
structure
,
back
pointer
,
bestchoice
,
process
,
shorter
span
first
order
,
reference
,
word
lattice
,
existsan
edge
,
oracle
diameter
,
huang
,
reference
,
topological
order
do3
,
first
situation
,
s
structure
,
word
pospair
,
reference
,
structuresfrom
,
possible
child
node
pair
,
enumerate
,
combinations
,
represent
,
diameter
length
,
structure
sof
,
whenthe
dynamic
programming
procedure
,
diameter
length
,
top
node
,
f
measure
formula
,
line15
,
function
tr
,
oracle
diameter
,
word
latticewe
,
pruned
word
lattice
,
thebaseline
classifier
,
slight
modification
,
theclassifier
,
eachcharacter
,
left
to
right
fashion
,
considering
position
,
classifier
,
candidate
result
,
attachingeach
current
candidate
word
pos
pair
,
tailof
,
candidate
result
,
prior
position
,
asthe
endmost
,
new
generated
candidate
,
candidate
,
endmost
,
word
pos
pair
,
highest
score
,
lattice
,
edge
implies
,
lattice
,
node
viat
eachposition
,
limitation
,
countalgorithm
lattice
generation
algorithm
,
cands13
,
output
,
edge
set
,
lattice
,
position
,
strategy
in
degree
pruning
,
generation
algorithm
,
consider
,
character
ciin
sequence
,
atposition
,
candidate
,
enumerates
,
current
candidate
word
,
pos
tag
set
,
function
eval
inline
,
word
pos
pair
,
fromthe
baseline
classifier
,
array
best
preserve
thescore
,
labelling
result
,
after
,
possible
word
pos
pair
,
select
,
pruning
strategy
,
simple
pruning
,
promisingimprovement
,
lattice
,
elaborate
pruning
strategy
,
framework
,
n
best
list
,
word
lattices
,
candidate
set
cand
,
reranker
,
argmaxy
,
n
best
list
,
result
,
baseline
classifier
,
whilefor
,
word
lattice
,
set
ofall
diameter
,
product
,
feature
vector
,
weight
vector
,
to387algorithm
p
erceptron
training
,
reranking1
,
training
,
argmaxy
,
output
,
parameter
,
on
local
template
commentw0t0current
word
pos
pairw
,
nonlocal
feature
template
,
usual
practice
,
parsing
,
baseline
classifier
,
valueis
,
real
number
,
non
localones
,
wordand
,
n
grams
extractedfrom
candidate
,
n
best
list
,
rerank
ing
,
diameter
,
word
lattice
,
rerankerwe
,
perceptron
algorithm
,
reranker
,
algorithm
,
simple
refinement
strategy
,
parameters
,
training
corpus
,
stable
performance
,
candidate
,
n
best
reranking
,
candidate
,
whereas
,
word
lattice
reranking
,
algorithm
,
algorithm
,
oracle
diameter
,
candidateresult
,
thereranker
,
notice
,
features
,
template
,
contain
,
future
,
pos
tag
,
history
wordor
pos
,
word
pos
pair
,
future
,
informationin
n
best
list
reranking
,
wererank
,
pruned
word
lattice
,
lattice
,
difficulty
lgorithm
cube
,
nonlocal
feature
,
return
dvsink
,
procedure
,
procedure
,
ithen24
,
information
,
current
considering
node
,
cube
pruningbecause
,
nonlocal
feature
,
word
and
pos
n
grams
,
reranking
procedure
,
machine
translation
,
inter
grated
language
model
,
candidate
,
lattice
,
procedure
,
candidate
,
method
,
machine
translation
,
chiang
,
chi
ang
,
efficient
k
best
parsing
algorithm
,
chiang
,
algorithm
,
pruned
word
lattice
,
maintains
,
derivation
,
new
derivation
,
acurrent
word
pos
pair
,
antecedentderivation
,
function
eval
,
thenew
derivation
,
usea
heap
heap
,
candidate
,
thenext
best
derivation
,
initialize
,
top
derivation
,
deducingsource
,
vector
pair
,
vector
,
current
word
pos
pair
,
vector
,
derivationsat
,
antecedent
node
,
iteration
,
feature
template
,
instance
,
suppose
,
derivation
,
successor
,
derivation
,
vector
,
oftwo
index
number
,
candidate
,
vector
,
deducing
sourcep
,
candidate
,
increment
vector
,
whoseith
dimension
,
others
,
nonlocal
feature
,
usedby
function
eval
,
derivation
,
derivation
,
oforder
,
buffer
buf
,
extractedderivations
,
sort
buf
,
firstn
item
,
classificationfollowing
jiang
,
segmentation
,
sequenceinto
several
subsequence
,
subsequence
,
character
,
subsequence
,
pos
tag
ofc
ei
,
character
,
positional
tag
,
relative
position
,
expected
subsequence
,
segmentation
result
,
andjiang
,
single
character
word
,
begin
,
middle
,
withthese
positional
tag
,
segmentation
,
classification
problem
,
positional
tag
,
postfix
,
pos
information
,
classification
style
framework
,
subsequence
,
word
withpos
,
positional
part
,
tag
sequence
conforms
,
pattern
,
eachelement
,
pos
part
equal
,
tag
sequence
b
n
m
n
e
n
,
athree
character
word
,
pos
tag
nn
,
feature
templatesthe
,
classifier
,
template
,
convenience
,
external
knowledge
,
punctuation
information
,
theirtemplates
,
character
,
subscript
,
position
,
character
,
upper
column
,
template
,
template
,
becausepredications
,
current
character
,
templates
,
lexical
target
,
column
,
additional
field
c0to
,
non
lexical
target
template
,
predication
,
context
,
current
character
,
notice
,
templatesin
table
,
local
feature
,
allfeatures
,
training
instances
,
training
procedure
,
p
erceptron
training
algorithm
,
training
,
output
,
parameter
,
training
,
classifiercollins
,
perceptron
training
,
discriminative
classifier
,
character
sequence
,
isthe
sequence
,
classification
result
,
character
,
segmentation
,
classification
result
,
positional
tag
,
extended
tag
,
pos
information
,
denotesthe
set
,
character
sequence
,
tag
sequence
,
functiongen
,
candidate
tag
,
forthe
character
sequence
,
representation
,
weight
vector
,
perceptron
model
,
feature
space
,
input
character
sequence
,
missionof
,
classifier
,
theresult
,
much
plausiblywe
,
character
sequence
,
tag
sequencey
,
training
algorithm
,
algorithm5
,
parameter
,
strategyto
alleviate
,
chi
nese
treebank
,
usualpractice
,
parsing
,
chapters1
,
training
,
chapters
,
developmentset
,
chapter
,
final
test
set
,
performance
ofthe
baseline
classifier
,
word
lattice
,10
f
measurenumber
,
iterationsperceptron
learning
curvessegmentationjoint
stf
igure
,
baseline
,
perceptron
learningcurves
,
segmentation
,
reranking
,
baseline
classifier
,
segmentation
,
analogous
,
situation
,
parsing
,
word
pos
,
pos
tag
,
foreach
character
,
training
set
,
templatesin
table
,
development
set
,
parameter
vector
,
figure
,
learning
curve
,
development
set
,
averaged
parameter
vector
,
iteration
,
final
test
,
parameter
vector
,
f
measure
,
segmentation
,
segmentationis
,
similar
trend
,
segmentation
,
rerankingfor
n
best
reranking
,
bestresults
,
training
instance
,
modification
,
baseline
classifier
,
candidates
,
word
latticereranking
,
algorithm
,
algorithm
,
togenerate
,
pruned
word
lattice
,
result
list
,
pruned
wordlattice
,
candidate
result
,
oracle
diameter
,
pruned
word
lattice
,
target
,
result
,
result
,
result
,
s390f
measure
,
oracle
diameter
,
pruned
word
lattice
,
algorithm
,
baseline
model
,
traininginstances
,
training
set
,
development
set
,
test
set
,
oracleset
,
f
measure
,
reference
set
,
f
measure
,
theoracle
f
measure
,
utmost
improvement
,
algorithm
,
analysisthe
flow
,
n
best
list
reranking
,
word
lattice
,
thetraining
procedure
,
baseline
classifier
,
reranking
,
parameter
vector
,
reranker
,
developmentset
,
reranking
,
optimalnumber
,
iteration
,
reranker
,
procedure
,
word
lattice
,
n
best
list
,
experimental
result
,
experimental
result
,
n
best
list
reranking
,
arefor
word
lattice
,
n
best
list
rerank
ing
,
list
size
,
list
size
,
oraclef
measure
,
f
measure
,
however
,
tiny
improvement
,
situation
,
word
lattice
reranking
,
inn
best
reranking
,
performance
difference
between
,
degree
,
degree
,
setting
,
degree
,
doesnot
,
notable
improvement
,
degree
limitation
,
asin
degree
,
oracle
f
measures
,
segmentation
,
quite
highlevel
,
pruned
word
,
contains
,
possibility
,
segmentation
andtagging
,
n
best
list
,
setting
,
oracle
f
measure
,
f
measure
climb
,
achievesan
error
reduction
,
anerror
reduction
,
segmentation
,
n
best
list
,
andword
lattice
,
n
best
list
,
n
best
list
reranking
,
degree
,
degree
limitation
,
word
lattice
reranking
,
os
seg
,
oracle
f
measure
,
segmentation
,
n
best
list
orword
lattice
,
oracle
f
measure
,
n
best
list
,
word
lattice
,
rnk
seg
,
f
measure
,
segmentation
,
reranked
result
,
f
measure
,
reranked
resultbaseline
classifier
,
error
reduction
is6
,
segmentation
,
error
reduction
is8
,
pruned
wordlattice
,
practical
method
,
segmentation
andpos
tagging
,
small
data
representation
,
obvious
advantage
,
then
best
list
reranking
,
baseline
,
tworeranking
technique
,
nonlocal
information
,
wordor
pos
gram
,
improveaccuracy
,
segmentation
,
pos
tagging
,
reranking
technique
,
information
,
smallscale
n
best
list
,
word
lattice
,
high
oracle
f
measure
,
technique
,
word
lattice
,
promising
refining
strategy
,
segmentationand
pos
tagging
,
viewpoint
,
initial
inputcharacter
sequence
,
pruned
word
lattice
,
search
space
,
high
oracle
f
measure
,
moreprecise
reranking
,
search
space
,
thebest
result
,
structure
,
search
space
,
thetopological
directed
architecture
,
pruned
wordlattice
,
much
wider
choice
,
feature
selection
,
position
,
depictedin
,
information
,
pruned
word391lattice
,
technique
,
improvement
,
precise
rerankingalgorithm
,
appropriate
feature
,
onclusionthis
paper
,
reranking
strategy
calledword
lattice
,
derivation
,
reranking
,
rerank
ing
,
pruned
word
lattice
,
n
bestlist
,
wordand
pos
gram
information
,
technique
,
error
reduction
of16
,
segmentation
,
baseline
classifier
,
n
best
list
,
word
lattice
reranking
,
nonlocal
information
,
candidate
result
,
arelative
small
representation
structure
,
aquite
high
oracle
f
measure
,
rerank
ing
implementation
,
relative
coarse
,
many
,
improvement
,
futurework
,
algorithm
,
word
lattice
generation
,
search
space
,
oracle
f
measure
,
featureselection
strategy
,
word
lattice
architecture
,
effective
use
,
nonlocal
information
,
acknowledgementthis
,
national
natural
science
foundation
,
state
key
project
,
special
thanks
,
iang
huang
,
valuable
suggestion
,
referencescollins
,
fornatural
language
parsing
,
proceeding
,
the17th
international
conference
,
machine
learning
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceedingsof
,
empirical
method
,
natural
language
processing
conference
,
yoram
singer
,
naftali
tishby
,
hierarchical
hidden
markov
model
,
analysisand
application
,
machine
learning
,
reranking
,
nonlocal
feature
,
proceedingsof
,
annual
meeting
,
association
forcomputational
linguistics
,
wenbin
,
liang
huang
,
qun
liu
,
cascaded
linear
model
,
joint
chineseword
segmentation
,
part
of
speech
tagging
,
inp
roceedings
,
annual
meeting
,
association
,
computational
linguistics
,
lafferty
,
mcc
allum
,
fernandopereira
,
conditional
random
field
,
probabilistic
model
,
sequencedata
,
proceeding
,
international
conference
,
machine
learning
,
hwee
tou
,
jin
kiat
low
,
part
of
speech
tagging
,
all
at
once
,
proceeding
,
empirical
method
,
natural
language
processing
conference
,
rabiner
,
hiddenmarkov
model
,
application
,
speechrecognition
,
proceeding
,
ratnaparkhi
,
adwait
,
maximum
entropypart
of
speech
tagger
,
proceeding
,
empirical
method
,
natural
language
processing
conference
,
nianwen
,
libin
shen
,
wordsegmentation
,
lmr
tagging
,
proceeding
ofs
ighan
workshop
,
conference
,
empirical
method
,
natural
language
processing
,
afn
lpbi
,
monolingual
,
comliang
,
comwenbin
jiang
,
qun
liukey
lab
,
intelligent
information
processinginstitute
,
technologychinese
academy
,
sciencesp
,
beijing
,
language
,
search
space
,
monolingual
,
modeling
,
crude
approximations
,
bilingually
constrained
monolingual
parsing
,
source
languageparser
learns
,
reordering
,
additional
observation
,
target
side
tree
,
shift
reducedependency
parser
,
alignment
features
,
shift
reduce
conflict
,
experiments
,
bilingual
portion
,
chi
nese
treebank
show
,
bilingual
feature
,
accuracies
,
absolute
,
task
,
natural
language
processing
,
interestingly
,
languages
,
attachment
,
eu
ropean
language
,
unambiguous
hinese
,
telescope
,
wangyuanjin
kandao
,
telescope
,
telescope
,
figure
,
chi
nese
,
figure
,
usetwo
language
,
disambiguation
,
pp
attachmentproblem
,
fossum
,
knight
,
schwartz
etal
,
fundamental
problem
,
syntactic
parsing
,
subproblem
,
andsmith
,
burkett
,
joint
parsing
,
bitext
improves
accuracy
,
leveraging
bilingual
constraint
,
syntax
based
machine
translation
,
requires
,
good
quality
,
parse
tree
,
rule
extraction
,
galley
,
search
space
,
joint
parsing
,
monolingual
,
word
order
,
attachment
,
japanese
resort
,
unambiguity
,
attachment
ambiguity
,
schwartz
,
complicated
modeling
,
crude
approximation
,
language
,
to
mapping
,
tree
node
,
practiceone
,
expressive
formalism
,
synchronous
tree
substitution
grammar
,
eis
ner
,
galley
,
thanjoint
,
resort
,
monolingual
parsing
,
bilingualreranking
,
tree
pair
,
tinyfraction
,
whole
space
,
much
simpler
,
bilingually
constrained
monolingual
parsing
,
source
language
parser
,
reordering
,
language
,
additional
observation
,
treefor
,
target
side
,
theidea
,
suppose
,
telescope
,
attachment
,
telescope
,
telescope
,
a
c
hinese
translationthe
choice
becomes
,
precedes
thephrase
,
p
attachment
ambiguity
,
chinesetranslation
,
bitext
,
alignment
information
,
chi
nese
parsing
,
thescope
,
relative
clause
,
method
,
joint
parsing
,
backbone
,
alignment
information
,
softevidence
,
hard
constraint
,
automatic
word
alignment
,
pp
,
translatedinto
a
c
hinese
relative
clause
,
phrasalmodifiers
,
immediate
right
,
straightforward
,
monolingual
parsing
algorithm
,
dependency
parsing
,
simplicityand
efficiency
,
followingcontributions
,
baseline
shift
reduce
dependency
parser
,
similar
state
of
the
performancewith
,
arc
eager
,
scholz
,
bilingual
feature
,
word
alignment
information
,
target
sidecontiguity
,
shift
reduce
conflict
,
shift
reduce
conflicts
,
source
,
correct
shift
reduce
decision
,
bilingual
contiguity
conditions
,
automatic
alignment
,
bilingual
feature
,
dependency
,
overthe
state
of
the
baseline
,
simpler
shift
reduce
dependencyparsing
,
three
actionsthe
basic
idea
,
classical
shift
reduce
parsingfrom
compiler
theory
,
ullman
,
left
to
right
scan
,
actions
,
current
word
,
combination
,
parsing
,
simple
variant
,
dependency
parsingsimilar
,
yamada
,
matsumoto
,
arc
standard
,
version
,
three
actionsbasically
,
action
,
action
,
reduceland
reducer
,
reducer
,
formal
description
,
action
,
nonempty
queue
whilereduce
,
reduction
,
parser
configuration
,
queueof
,
setof
dependency
,
action
,
nonempty
,
queueq
,
reducel
,
thestack
,
replacethem
,
reducer
,
thestack
,
right
arc
,
hese
action
,
theinitial
configuration
,
empty
stack
,
final
configuration
,
asthe
root
,
nwords
,
action
,
shiftsand
,
reduction
,
theroot
,
reduction
,
thetime
complexity
,
shift
reduce
instance
,
shift
reduce
conflictfigure
,
paradigm
,
configurations3a
,
configuration
,
lr
ll
parsing
,
reducel
,
i4
shift
,
i5a
reducer
,
ill5b
shift
,
action
shift
reduce
,
word
,
process
,
correspond
,
attachment
,
figure
,
reduction
,
reducel
,
modifier
,
stack
containsa
single
word
,
next
word
,
shift
reduce
conflict
,
configuration
,
conflict
,
thecomplete
list
,
thisbaseline
parser
,
shift
reduce
conflictsare
,
source
,
conflict
,
part
of
speech
information
,
formeris
,
preposition
,
triple
,
typical
pp
attachment
,
wrong
decision
,
modifier
,
andoften
,
local
effect
,
thetree
,
shift
reduce
mistake
,
feature
template
,
baseline
parser
,
thestack
,
next
word
,
pos
tag
,
agiven
word
,
leftmost
,
rightmost
child
,
symbol
,
featureconjunction
,
template
,
action
shift
,
reducel
,
reducer
,
incompatible
tree
shape
,
crossingbrackets
,
thisis
,
practice
,
usto
focus
,
shift
reduce
resolution
,
bilingual
constraint
,
ection
,
arc
eagerthe
,
action
system
,
yamada
,
matsumoto
,
theirmethods
,
multiple
pass
,
arc
standard
,
comparison
tothe
four
action
,
arc
eager
,
variant
,
subsequent
,
shift
reduce
,
dependency
,
dominant
style
,
arc
standard
,
action
,
thestack
,
unrelated
subtrees
,
arc
betweenany
,
action
,
arc
eager
,
right
arrow
between
item
,
semantics
,
action
,
atomicand
disjoint
,
semantics
,
actions
,
disjoint
,
left
action
,
implicit
reduce
,
left
item
,
right
action
,
implicit
shift
,
furthermore
,
action
,
nontrivial
preconditions
,
next
problem
,
arc
standard
,
withempty
queue
,
arc
eager
,
stylesometimes
,
deadends
,
action
,
preconditions
,
result
,
well
formed
tree
,
becomes
,
failuresin
practice
,
scholz
,
fragment
,
simplerarc
standard
system
performs
,
witha
state
of
the
arc
eager
system
,
standard
treebank
parsing
,
simpler
paradigmshould
,
practice
,
beam
search
extensionwe
,
deterministic
shift
reduce
parsing
,
beam
search
,
configuration
,
parallel
,
pseudocode
,
algorithm
,
agenda
,
current
active
configurations
,
action
,
new
configuration
,
buffer
,
argument
,
arc
eager
,
beam
search
shift
reduce
parsing
,
initial
config
,
empty
stack
,
initial
agenda4
,
buffer
,
new
configs6
,
config
,
agenda
do7
,
reducel
,
reducer
do8
,
buffer
,
output
,
config
,
agenda
,
next
step
,
complexityof
,
algorithm
,
thedeterminstic
mode
,
parser
,
oracle
,
gold
standard
action
sequence
,
gold
standard
dependency
tree
,
oracle
,
three
action
system
,
forthe
four
action
system
,
dependentsof
,
allright
dependent
,
left
dependent
,
heuristic
,
alwaysprefers
,
effect
thatall
,
dependent
,
inside
out
,
right
dependent
,
inside
out
,
head
driven
constituencyparsing
model
,
popular
online
,
perceptron
,
parameter
averaging
,
early
update
,
strategy
,
update
happens
,
gold
standard
action
sequence
,
withthe
rest
,
sequence
,
specialcase
,
deterministic
mode
,
first
mistake
,
intuitionbehind
,
strategy
,
future
mistake
,
previous
one
,
parser
onthe
wrong
track
,
future
action
,
irrelevantfor
learning
,
discussion
,
telescope
,
telescope
,
le
na
wangyuanjin
,
telescope
,
le
na
wangyuanjin
,
telescope
,
bilingual
contiguity
feature
,
one
,
thestack
top
,
queuehead
,
underlined
text
,
sourceand
target
span
,
wavy
underlines
,
boldalignment
link
,
contiguity
constraint
,
oft
bilingual
constraint
,
featuresas
,
shift
reduce
conflicts
,
problem
,
intuition
,
decision
,
language
,
word
alignment
information
,
preference
,
running
,
pp
attachment
,
bilingualcontiguity
feature
,
correct
decision
,
reduction
,
corresponding
word
,
target
side
,
acontiguous
span
,
figure
,
reduction
,
side
,
target
span
,
wordwithin
,
source
word
outside
,
source
span
,
figure
,
source
span
,
muchlonger
span
,
side
,
target
,
word
,
andwangyuanjin
,
telescope
,
thesource
span
,
shift
action
,
figure
,
sourcespan
,
side
,
target
,
definitionwith
wangyuanjin
,
following
reason
,
crucial
difference
,
subtree
span
,
twowell
formed
subtrees
,
shift
action
,
stand
wiwill
,
ahoand
ullman
,
targetword
,
source
word
,
target
word
,
source
word
,
explainsthe
notational
difference
,
rightcontiguity
,
final
,
figure
,
aligns
,
right
contiguity
,
formal
definition
,
target
alowedfeature
span
sp
span
tp
span
,
formal
definition
,
bilingual
feature
,
source
span
,
target
language
,
reverse
operation
,
source
language
,
source
span
sp
,
reverse
image
,
allowed
spanextends
,
right
end
,
variation
,
implementationto
,
alignment
based
feature
,
theconjunction
,
discrimination
power
,
strong
signal
,
bilingual
feature
,
template
,
practice
amount
,
instance
,
action
,
show
ins
ection
,
withthe
correct
shift
,
action
,
practice
,
naive
implemention
,
bilingual
featurecomputation
,
clever
datastructurewould
,
complexity
,
future
,
that5our
definition
implies
,
faithfulspans
,
galley
,
dependent
,
parser
,
withthe
new
bilingual
feature
,
extra
,
bilingual
feature
,
practice
,
extraction
,
thevast
amount
,
grammar
inductionbesides
,
related
,
bilingual
constraintsfor
grammar
induction
,
use
simple
heuristics
,
tree
,
discouraging
accuracy
result
,
ganchev
,
eisner
,
adaptation
techniques
,
principledprojection
,
encouraging
result
,
constrast
,
bilingualtree
pair
,
tree
projection
,
monolingual
grammar
,
shift
reduce
algorithm
,
feature
template
,
dependency
,
pos
tag
,
tagger
,
headrules
,
yamada
,
mat
sumoto
,
conversion
,
dependencytrees
,
optimal
number
,
iteration
,
per
ceptron
training
,
oursystem
performs
,
parser
accuracy
sentmcdonald
,
baseline
,
baseline
,
baseline
parser
performance
,
standardpenn
treebank
dependency
,
speed
number
,
comparablesince
,
different
machine
,
dev
testctb
article
300bilingual
paris
,
training
,
bilingualchinese
treebank
,
burkett
,
bilingual
datathe
bilingual
data
,
translated
portion
,
ofp
tb
,
translation
,
gold
standard
parse
tree
,
training
,
test
subset
,
burkett
andklein
,
word
alignments
,
hmm
alignerof
liang
,
approximately1
,
aligner
output
,
posterior
probability
,
source
targetword
pair
,
pruning
threshold
,
low
confidence
alignment
link
,
hard
alignment
,
alignment
probability
,
future
,
simplicity
reason
,
following
experiments
,
gold
standard
pos
,
parser
,
hypothesesbefore
,
bilingual
approach
,
assumption
,
parser
,
bad
link
,
fossum
,
knight
,
error
distribution
,
dev
set
,
shift
reduce
conflict
,
source
,
reduce
reduce
conflict
,
minor
issue
,
gold
standard
decision
,
contiguities
,
hypothesis
,
wecount
,
baseline
parsermakes
,
deterministic
mode
,
en
glish
dev
,
mistake
,
previous
one
,
first
mistake
,
thisis
,
argument
,
early
update
,
applying
perceptron
,
incremental
parsing
algorithm
,
first
mistake
,
perfect
output
,
vast
majority
,
shift
reduce
errors
,
reduce
becomes
shift
,
reduce
reduce
conflict
,
hesestatistics
,
intuition
,
shift
reduce
decisions
,
parsing
,
contribute
,
overwhelming
majority
,
errors
,
next
hypothesis
,
gold
standard
shift
reduce
sequence
,
en
glish
dev
,
categories
,
bilingual
contiguity
feature
,
stackis
,
the7to
,
independent
mistakes
,
previous
one
,
errorsmade
,
parser
recovers
,
previous
mistake
,
butthis
,
future
,
shift
reduce
error
,
thenon
uniqueness
,
reducel
andshift
,
currently
,
incorrect
parse
,
gold
standardshift
,
decision
,
bilingual
contiguityconditions
,
dev
,
stack
top
,
discussion
,
clear
signal
forreduce
,
thestack
,
first
line
,
reduces
,
second
line
,
neutral
signal
,
bilingual
hypothesis
,
thatthese
correlation
,
automatic
wordalignments
,
aligner
,
future
,
manual
alignments
,
correlation
,
main
parsing
result
,
automatic
alignment
,
ourapproach
,
bitext
,
bilingual
feature
,
automatic
alignment
,
baselineparser
,
theenglish
dev
,
beam
size
,
table
8shows
,
bilingual
constraint
,
withlarger
beam
,
improvement
,
withthe
,
beam
search
,
robust
thanthe
deterministic
mode
,
latter
,
effect
,
beam
size
,
efficiency
andaccuracy
,
dev
,
improvement
,
fractional
efficiency
overhead
,
baseline
,
bilingual
feature
,
parser
,
final
result
,
test
set
,
bilingual
feature
,
parser
,
mistake
,
theformer
multiple
configuration
,
pursuedin
parallel
,
parser
,
timecomplexity
,
beam
size
,
computingthe
bilingual
feature
,
thebaseline
,
practice
,
contrast
,
burkett
,
bilingual
k2
best
,
monolingual
parsing
,
final
result
,
test
set
,
englishand
,
addition
,
bilingual
featuresimproves
dependency
,
z
test
ofc
,
resultsagainst
,
parser
,
petrov
,
reference
system
,
bilingual
data
,
gold
standard
pos
tag
,
resulting
tree
,
dependency
,
thesame
headrules
,
iteration
,
split
mergegrammar
induction
,
iteration
overfits
,
training
,
result
,
ourbaseline
,
bilingualparser
,
discrepancy
,
fact
thatour
baseline
feature
template
,
future
workwe
,
novel
parsing
paradigm
,
bilingually
constrained
monolingual
parsing
,
parsing
,
yetstill
yield
mild
improvement
,
preliminary
experiment
,
simple
method
,
incorporatingalignment
feature
,
soft
evidence
,
astate
of
the
shift
reduce
dependency
parser
,
shift
reduce
conflictswith
fractional
efficiency
overhead
,
onlythree
alignment
feature
,
hand
encouraging
,
bilingualfeature
space
,
lexical
ization
,
soft
alignment
,
impact
,
alignment
quality
,
parsing
improvement
,
linguistics
point
,
syntactic
ambiguity
,
different
language
pair
,
bilingual
monolingualapproach
,
constituency
parsing
,
acknowledgmentswe
,
anonymous
reviewer
,
tous
reference
,
insight
onp
attachment
,
joakim
nivre
,
discussion
,
yang
liu
,
suggestion
,
manual
alignment
,
third
author
,
national
natural
science
foundationof
,
and863
state
key
project
,
ullman
,
thetheory
,
parsing
,
translation
,
compiling
,
parsing
,
series
,
automatic
computation
,
englewood
,
new
,
bies
,
mott
,
colinwarner
,
translation
treebankv1
,
burkett
,
klein
,
languagesare
,
emn
lp
,
roark
,
perceptron
algorithm
,
proceedings
,
philipp
koehn
,
ivona
kucerova
,
statistical
machinetranslation
,
proceeding
,
arbor
,
head
driven
statistical
models
,
natural
language
parsing
,
thesis
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceedingsof
emn
lp
,
eisner
,
non
isomorphic
treemappings
,
machine
translation
,
proceedingsof
acl
,
poster
,
fossum
,
knight
,
bilingual
word
alignment
,
pp
attachment
ambiguity
,
proceeding
ofa
mta
student
workshop
,
galley
,
hopkins
,
knight
,
anddaniel
marcu
,
translation
rule
,
proceeding
,
hlt
naa
cl
,
kuzman
ganchev
,
gillenwater
,
bentaskar
,
dependency
grammar
inductionvia
bitext
projection
constraint
,
proceeding
ofa
cl
ijcnlp
,
liang
huang
,
reranking
,
nonlocal
feature
,
hwa
,
resnik
,
weinberg
,
claracabezas
,
okan
kolak
,
bootstrappingparsers
,
syntactic
projection
,
parallel
text
,
natural
language
engineering
,
liang
,
klein
,
taskar
,
end
to
end
discriminative
approach
,
machine
translation
,
proceedings
,
mcd
onald
,
koby
crammer
,
fernandopereira
,
large
margin
training
,
dependency
parser
,
proceeding
,
haitao
mi
,
liang
huang
,
based
translation
rule
extraction
,
proceeding
,
emn
lp
,
honolulu
,
haiwaii
,
joakim
nivre
,
scholz
,
deterministicdependency
parsing
,
text
,
joakim
nivre
,
incrementality
,
deterministicdependency
parsing
,
incremental
parsing
,
bringing
engineering
,
cognition
together
,
workshopat
,
barcelona
,
joakim
nivre
,
algorithm
,
deterministic
incremental
dependency
,
computational
linguistics
,
slav
petrov
,
klein
,
inferencefor
unlexicalized
parsing
,
proceeding
,
hlt
naa
cl
,
kenji
sagae
,
alon
lavie
,
best
first
probabilistic
shift
reduce
parser
,
proceeding
,
poster
,
schwartz
,
takako
aikawa
,
quirk
,
disambiguation
,
pp
attachment
,
proceeding
,
mt
summitix
,
eisner
,
parser
adaptation
,
projection
,
quasi
synchronous
feature
,
proceeding
,
emn
lp
,
factored
estimation
,
using
toparse
korean
,
proceeding
,
emn
lp
,
stochastic
inversion
transductiongrammars
,
bilingual
parsing
,
parallel
corpus
,
computational
linguistics
,
nianwen
xue
,
fu
dong
chiou
,
large
scale
annotated
corpus
,
proceeding
,
matsumoto
,
statistical
dependency
analysis
,
support
vector
machine
,
inp
roceedings
,
tale
oftwo
parser
,
investigating
,
transition
based
dependency
,
using
beam
search
,
proceeding
,
emn
lp
,
columbus
,
association
,
computational
linguisticsa
,
linear
model
,
intelligent
information
processing
,
computing
technology
,
pennsylvaniachinese
academy
,
science
levine
,
walnut
streetp
,
beijing
,
philadelphia
,
eduabstractwe
,
cascaded
linear
model
forjoint
word
segmentation
,
part
of
speech
tagging
,
character
basedperceptron
,
real
valued
feature
,
language
model
,
utilize
knowledge
source
,
inconvenientto
incorporate
,
perceptron
,
cascaded
modelachieves
,
segmentation
,
joint
segmentation
andpart
of
speech
tagging
,
chinesetreebank
,
error
reduction
of18
,
segmentation
,
joint
segmentation
,
part
of
speech
tagging
,
tagging
,
important
task
,
computer
processing
ofc
hinese
,
asian
language
,
several
models
,
problem
,
advantage
,
flexibility
,
generative
one
,
discriminative
method
,
perceptron
algorithm
,
comparableperformance
,
training
,
sowe
base
,
perceptron
,
segment
,
character
sequence
,
strategy
,
performing
pos
tagging
,
segmentation
,
joint
segmentationand
pos
tagging
,
typical
approach
,
discriminative
model
treat
,
labelling
problem
,
charactera
boundary
tag
,
labelling
fashion
,
expanding
boundary
tag
,
pos
information
,
ngand
low
,
segmentation
,
segmentationbut
,
usual
character
based
feature
,
additionalfeatures
,
assuch
feature
,
procedure
,
limitation
arise
,
onehand
,
amount
,
parameter
increase
,
training
corpus
,
theother
hand
,
exact
inference
,
dynamic
programming
,
current
predicationrelies
,
result
,
prior
predication
,
result
,
useful
feature
,
higher
order
word
,
n
grams
,
problem
,
cascadedlinear
model
,
log
linear
model
,
ochand
ney
,
statistical
machinetranslation
,
different
kind
,
knowledge
source
,
figure
,
cascadedmodel
,
two
layer
architecture
,
character
based
perceptron
,
otherreal
valued
feature
,
language
model
,
we897corelinear
model
,
perceptron
,
structure
,
feature
space
,
core
perceptron
,
detail
,
architecture
,
knowledge
source
,
intractable
toincorporate
,
perceptron
,
outside
linear
model
,
addition
,
knowledge
source
,
separatefeatures
,
corresponding
model
,
interestingapproach
,
training
corpus
,
space
consumption
,
experimentsshow
,
cascaded
model
,
differentknowledge
source
,
accuracyimprovements
,
segmentation
,
segmentation
result
,
e1
ce1
,
emwhile
,
segmentation
,
result
canbe
,
e1
t1
ce1
,
character
,
pos
tag
,
character
sequence
,
segmentation
,
taskis
,
character
sequence
,
several
subsequences
,
segmentation
,
uniform
framework
,
segmentationtask
,
tagging
problem
,
character
,
boundary
tag
,
middle
,
single
character
wordwe
,
segmentation
result
,
splittingthe
,
result
,
subsequence
,
pattern
orbm
,
single
character
word
,
multi
character
word
,
boundarytags
,
pos
information
,
a
p
osto
,
boundary
tag
,
postfix
followingng
,
boundary
part
,
a
p
o
part
,
uniform
boundary
poslabelling
problem
,
subsequence
,
boundary
poslabelling
result
,
ifthe
boundary
tag
sequence
,
boundary
part
conforms
,
pos
tag
,
pos
part
,
tagsequence
b
n
m
n
e
n
,
three
character
word
,
perceptronthe
perceptron
algorithm
,
nlp
byc
ollins
,
effective
discriminative
training
method
,
feature
template
,
instance
,
suppose
,
training
,
per
ceptron
,
many
nlp
task
,
asp
o
tagging
,
character
based
per
ceptron
,
theperceptron
,
high
accuracy
,
segmentation
,
followingsubsections
,
andthe
perceptron
training
algorithm
,
fromthose
,
others
,
close
test
regulation
,
character
c0
,
punctuation
,
feature
template
,
instance
,
a
c
hinese
character
,
subscript
,
position
,
current
character
,
inthe
upper
column
,
non
lexical
target
,
non
lexical
target
,
column
,
upper
one
,
field
c0
,
template
,
upper
column
,
predication
,
context
,
current
character
,
predication
,
suchtemplates
,
current
character
,
namethese
template
,
templates
,
lexical
target
one
,
kindsalgorithm
p
,
algorithm
,
training
,
output
,
parameter
,
predication
,
perceptron
model
,
ability
,
exact
predicatingfails
,
algorithmwe
,
perceptron
training
algorithm
ofc
ollins
,
discriminative
model
mapping
,
training
corpus
,
labelled
result
,
following
,
function
,
generatingall
candidate
result
,
representation
,
feature
vector
,
dimension
,
vector
space
,
amount
,
inputcharacter
sequence
,
inner
product
,
parameter
vector
,
algorithm
,
theparameter
vector
,
alleviate
overfitting
,
training
,
refinement
strategy
,
algorithm
,
algorithm
,
linear
modelin
theory
,
useful
knowledge
,
perceptron
,
character
based
feature
,
additional
featuresmost
,
pos
n
grams
,
decoding
procedure
,
thatthe
feature
space
,
figure
,
tendency
,
thecharacter
based
one
,
word
unigrams
,
bigram
,
enlargement
,
thecharacter
base
one
,
higher
ordergrams
,
trigram
,
grams
,
addition
,
problem
,
currentpredication
,
result
,
prior
one
,
procedure
,
inference
,
candidate
,
predication
position
,
potentialrisk
,
training
,
drawback
,
cascaded
linear
model
,
two
layer
architecture
,
perceptron
,
linearmodel
,
outside
layer
,
perceptron
,
perceptron
,
character
based
features
,
several
sub
models
,
additionalones
,
pos
n
grams
,
theoutside
layer
linear
model
,
output
,
thesesub
models
,
perceptron
,
per
ceptron
,
second
training
step
,
thewhole
training
procedure
,
relative
small
timeand
memory
cost
,
outside
layer
linear
model
,
different
knowledge
source
,
accurate
comparisonbetween
candidate
,
knowledgesource
,
correspondingweight
,
relative
importance
,
suppose
,
corre0
,22
f
eature
spaceintroduction
,
curvefigure
,
feature
space
,
horizontalscope
,
different
templates
,
denotesthe
word
,
fromthe
training
procedure
,
msr
corpus
,
bake
off
,
weight
,
candidate
,
totalscore
,
decoding
procedure
,
candidater
,
argmaxrs
,
mission
,
training
procedure
,
thecandidate
,
thebest
result
,
high
probability
,
sub
models
,
perceptron
,
separate
feature
,
outside
layerlinear
model
,
withspecial
algorithm
,
gram
word
language
model
,
fluency
,
segmentation
result
,
gram
pos
language
model
functioning
,
product
,
state
transition
probability
,
word
posco
occurrence
model
,
much
probablya
word
sequence
coexists
,
a
p
o
sequence
,
asshown
,
figure
,
character
based
perceptron
,
inside
layer
linear
model
,
itsoutput
,
outside
layer
,
output
,
theperceptron
,
outside
layer
,
outputs900of
,
occurrencemodel
,
word
count
penalty
,
similar
tothe
translation
length
penalty
,
linguistic
probabilities
,
word
sequence
,
important
measureof
fluency
,
translation
,
formally
,
gram
word
lm
,
probability
,
following
product
,
wi
wmax
,
n
gram
pos
lm
,
a
p
o
,
ti
tmax
,
bi
gram
pos
lm
function
,
product
,
transition
probability
,
training
corpus
,
pos
tag
,
word
pos
occurrence
model
,
probability
,
word
sequence
,
belled
result
coexists
,
pos
sequence
,
word
sequence
,
corresponding
pos
sequence
,
probability
,
probability
,
occurrence
model
,
corresponding
weight
,
thetwo
component
,
probability
,
asthe
pos
,
thecorpus
,
instance
,
timesin
training
corpus
,
ntimes
,
bythe
formula
,
throughthe
approach
,
weight
,
components
,
occurrence
probability
,
thepaper
,
generating
model
,
labelling
problem
canbe
,
viterbi
style
,
procedure
,
mission
,
decoder
,
boundary
pos
,
decoding
procedure
,
left
right
fashion
,
dynamic
programmingapproach
,
eachposition
,
sequence
,
top
nbest
candidate
,
result
,
decoding
,
position
,
possible
word
pos
pair
,
eachpos
,
possible
word
,
character
subsequence
,
endingat
position
,
candidate
result
,
length
,
candidate
result
,
prior
position
,
select
,
position
,
listof
candidate
result
,
candidate
,
whenwe
,
candidate
result
,
word
pos
pairp
,
candidate
,
prior
position
,
probability
,
generating
probability
,
algorithm
,
append
,
output
,
n
best
result
,
perceptron
model
,
addition
,
word
count
penalty
asanother
feature
,
tendency
,
lm
tofavor
shorter
candidate
,
equation
,
candidate
,
algorithm
,
generate
a
n
,
character
position
,
scan
word
,
enumeratesall
pos
,
length
,
ending
,
position
,
considers
,
candidateresult
,
prior
position
,
currentword
,
function
,
candidate
result
,
word
pos
pair
,
candidate
,
prior
position
,
result
,
performance
ofthe
perceptron
,
segmentation
,
corpus
,
bakeoff
,
hong
kong
city
corpus
,
second
,
cascadedmodel
,
segmentation
,
experiments
,
averaged
parameter
,
theperceptrons
,
f
measure
,
accuracy
measure
,
precision
,
balancef
measure
,10
f
meassurenumber
,
iterationsperceptron
learning
curvenon
avglex
avgfigure
,
perceptron
,
non
lexical
target
,
lexical
target
feature
,
cityu
pku
msr
sighan
,
f
measure
,
corpus
,
ba
,
convenience
,
others
,
close
test
,
extraresource
,
designated
training
corpus
,
thelexical
target
template
,
iteration
,
training
corpus
,
development
set
,
per
ceptron
model
,
non
,
non
lexical
target
feature
,
figure
,
showstheir
learning
curve
,
f
measure
,
thedevelopment
,
training
iteration
,
non
,
margin
,
iteration
,
learning
curve
,
tableland
,
iteration
,
thenwe
,
corpus
,7
iterations
,
test
result
,
thatthis
model
,
ofs
ighan
ba
keoff
,
corpus
,
corpus
,
word
based
perceptron
model
,
zhangand
,
pku
corpus
,
score
han9
,
test
task
f
measurepossegmentation
,
segmentation
,
f
measure
,
segmentation
,
perceptron
,
perceptron
,
research
,
thisproblem
,
cascaded
model
,
theusual
practice
,
syntactic
analysis
,
chapters
,
training
,
test
set
,
chapter301
,
development
set
,
first
step
,
contrasting
experiment
,
core
perceptron
,
segmentation
regardless
,
pos
information
,
f
measure
,
segmentation
,
pos
information
,
f
measureboth
,
segmentation
,
note
thatthe
accuracy
,
word
pospair
,
boundary
,
andthe
pos
,
evaluation
result
,
segmentation
accuracy
,
f
measure
,
thef
measure
,
segmentation
,
similar
trend
appearedin
experiment
,
f
measure
,
segmentation
,
next
step
,
linear
model
performs
,
core
perceptron
,
pos
model
,
besides
,
perceptron
,
sub
models
,
additional
feature
,
outside
layerlinear
model
,
sri
language
modellingtoolkit
,
stolcke
,
gram
word
lm
,
modified
kneser
ney
smoothing
,
goodman
,
contribution
,
feture
,
word
count
penalty
,
witten
smoothing
,
word
pos
occurrence
model
,
correspondingweights
,
minimum
error
rate
training
algorithm
,
outside
layermodel
,
much
improvementeach
feature
,
cascaded
model
,
everytime
,
others
,
performanceon
,
test
set
,
show
experiment
result
,
thatthe
cascaded
model
,
a
f
measure
,
segmentation
,
perceptron
model
functions
,
kernel
,
outside
layer
linear
model
,
perceptron
,
cascaded
model
,
bothsegmentation
,
gram
pos
lm
,
important
role
,
f
measure
decrementof
,
segmentation
,
important
feature
,
labellingmodel
,
f
measure
,
decrement
,
inh
mm
,
improvement
,
test
item
,
features
,
word
lm
,
tiny
improvement
,
character
based
feature
,
perceptron
,
similar
role
,
higher
order
word
lm
,
scale
corpus
,
word
count
penalty
,
cascaded
model
,
segmentation903and
,
cascaded
model
,
theseknowledge
source
,
thefeature
space
,
percptron
,
experimental
result
,
obviousimprovement
,
perceptron
only
model
,
segmentation
,
error
reductionsof
,
cascaded
linear
model
,
many
knowledgesources
,
perceptron
,
outside
layer
linear
model
,
asubstitute
method
,
non
localfeatures
,
corpus
,
perceptron
incorporate
,
theknowledge
,
outside
layer
linear
model
,
linear
model
,
accurate
generative
model
,
word
posco
occurrence
model
,
onlarge
scale
corpus
,
corpus
,
raw
corpus
similar
approach
,
mcc
losky
,
knowledge
source
,
coreperceptron
,
outside
layer
linear
model
,
training
corpus
,
many
open
knowledge
source
,
lexicon
etc
,
knowledge
source
,
problem
,
following
,
acknowledgementthis
,
author
,
nationalnatural
science
foundation
,
contracts60736014
,
state
key
projectno
,
byn
sf
itr
,
hwee
tou
ng
,
yang
liuand
yun
huang
,
suggestion
,
referencesstanley
,
goodman
,
empirical
study
,
technique
,
language
modeling
,
technical
report
tr
,
research
,
computing
technology
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceeding
ofe
mnlp
,
mcc
allum
,
pereira
,
conditional
random
field
,
probabilistic
models
,
sequence
data
,
inp
roceedings
,
charniak
,
johnson
,
self
training
,
adaptation
,
proceeding
,
hwee
tou
ng
,
jin
kiat
low
,
part
of
speech
tagging
,
all
at
once
,
proceeding
,
emn
lp
,
och
,
ney
,
alignment
template
approach
,
statistical
machine
translation
,
computational
linguistics
,
och
,
minimum
error
rate
training
instatistical
machine
translation
,
proceeding
,
hiddenmarkov
model
,
application
,
speechrecognition
,
proceeding
,
ratnaparkhi
,
adwait
,
maximum
entropypart
of
speech
tagger
,
proceeding
,
empiricalmethods
,
natural
language
processing
conference
,
stolcke
,
extensible
language
,
toolkit
,
proceeding
,
international
conference
,
spoken
language
processing
,
nianwen
xue
,
libin
shen
,
word
segmentation
,
lmr
tagging
,
proceeding
,
hanw
orkshop
,
yue
zhang
,
segmentation
,
word
based
perceptron
algorithm
,
proceedings
,47
th
annual
meeting
,
ijc
nlp
,
afn
lp
,
suntec
,
afn
lpau
tomatic
adaptation
,
annotation
standard
,
word
segmentation
,
intelligent
information
processing
,
google
researchinstitute
,
computing
technology
,
science
mountain
view
,
beijing
,
google
,
com
jiangwenbin
,
annotated
corpus
,
valuablebut
scarce
resource
,
many
annotation
task
,
sequence
labeling
,
exist
multiple
corpora
,
incompatible
annotation
guideline
,
standard
,
seemsto
,
great
waste
,
human
effort
,
annotation
standard
,
effective
strategy
thattransfers
,
annotated
corpus
,
corpus
,
desiredannotation
,
efficacy
,
thismethod
,
context
,
wordsegmentation
,
part
of
speech
tagging
,
segmentation
,
pos
taggingstandards
,
morphology
,
experiments
,
adaptation
,
smallerbut
,
popular
treebankresults
,
significant
improvement
,
bothsegmentation
,
witherror
reduction
,
statistical
nlp
research
relies
,
somesort
,
corpus
,
theirmodels
,
resource
,
large
scale
,
linguistic
theory
,
annotation
effort
,
result
,
multiple
corpus
,
sametask
,
incompatible
annotation
philosophy
,
u6n
r
nn
vv
nru
,
vice
,
vice
,
incompatible
word
segmentation
,
standard
,
andpeople
,
treebank
,
hps
glingo
redwood
treebank
,
dependency
treebank
,
buchholz
,
related
problem
,
thatthe
raw
text
,
different
domains
,
dialog
,
problem
,
greatwaste
,
human
effort
,
nice
ifone
,
annotation
standard
,
orderto
,
datasets
,
training
,
second
problem
,
domain
adaptation
,
blitzer
,
discussions
,
important
problem
,
annotation
style
adaptation
,
effective
strategythat
,
knowledge
,
annotated
corpus
,
training
,
modelon
,
corpus
,
desired
annotation
,
basicidea
,
source
corpus
,
source
classifier
,
target
corpus
,
result
,
annotation
,
target
corpus
,
second
model
,
target
corpus
,
thefirst
classifier
,
prediction
,
additional
featuresfor
,
learning
,
method
,
adaptation
,
underlying
problem
,
adaptation
assumes
,
labeling
guideline
,
jj
regardless
,
biomedical
text
,
thedistributions
,
control
,
nounin
biomedical
text
,
tackle
,
guideline
,
forexample
,
treebank
,
intransitive
verb
,
fundamental
disparity
,
underlying
linguistic
representation
,
problem
,
method
,
assumption
onthe
distribution
,
domain
,
annotation
standard
adaptationproblems
,
practice
because
,
latter
problem
,
study
,
efficacy
,
method
,
word
segmentation
,
part
of
speechtagging
,
problem
,
incompatible
annotation
standard
,
segmentation
standard
,
clear
definition
,
chinesewords
,
complete
,
morphology
result
,
ambiguity
,
debate
,
philosophy
,
chi
nese
parts
of
speech
,
corpus
,
inthis
study
,
people
,
corpus
,
different
segmentation
standard
,
wellas
different
pos
tagsets
,
guideline
,
figure
,
combinesthe
phrase
,
visited
,
alsoctb
,
verbal
category
,
normalverbs
,
copula
,
preferable
totransfer
knowledge
,
thelatter
,
tree
structure
,
downstream
application
,
parsing
,
summarization
,
machine
translation
,
many
effortson
translation
,
parsing
,
segmentation
andtagging
standard
,
suffers
,
limited
sizeof
training
data
,
chiang
,
chiang
,
reason
,
state
of
the
accuracy
,
parsing
,
half
thesize
,
adaptation
,
pdto
ctb
result
,
significant
improvement
,
segmentation
,
pos
tagging
,
error
reductionsof
,
addition
,
segmentation
,
tagging
,
improved
parsing
accuracy
onc
tb
,
error
propagation
fromword
segmentation
,
applicable
tomany
sequence
,
reviewthe
popular
classification
based
method
,
wordsegmentation
,
tagging
,
annotation
adaptation
,
relevant
previouswork
,
training
,
combination
,
experimental
result
,
segmentation
,
tagging
asc
haracter
classificationbefore
,
adaptation
algorithm
,
brief
,
baseline
characterclassification
strategy
,
segmentation
,
asjoint
segmenation
,
tagging
,
henceforth
,
previous
,
sequence
,
ncharacters
,
character
,
word
segmentation
aimsto
,
sequence
,
e1
ce1
,
a
c
hineseword
,
character
ci
,
in
523algorithm
p
erceptron
training
algorithm
,
training
,
output
,
parameter
,
t1
ce1
,
pos
tag
,
theword
cek
,
character
classification
methodxue
,
describe
,
first
timethe
character
classification
approach
,
chineseword
segmentation
,
character
,
givena
boundary
tag
,
relative
position
,
character
classification
problem
,
boundary
tag
,
a
p
o
tagin
order
,
pos
information
,
character
,
addition
,
ng
andlow
,
pos
taggingafter
word
segmentation
,
segmentation
,
pos
tagging
,
tag
representationof
ng
,
boundary
tag
,
middle
,
single
character
wordwhile
,
a
p
o
tag
,
boundary
tag
,
wordboundary
information
,
pos
information
together
,
character
,
characters
,
boundary
tag
,
orwith
pos
postfix
,
classifier
,
corresponding
word
sequence
,
segmentation
,
character
,
subsequence
,
algorithm
,
featuresnow
,
training
algorithm
,
theclassifier
,
several
classification
model
,
averaged
perceptron
algorithm
,
simplicity
,
highaccuracy
,
online
training
algorithm
,
many
nlp
task
,
pos
tagging
,
situation
,
sequence
labeling
problem
,
training
procedure
,
adiscriminative
model
,
sentencesin
,
training
corpus
,
corresponding
,
result
,
function
,
candidate
result
,
representation
,
feature
vector
,
input
character
sequence
,
inner
product
,
pseudo
code
,
addition
,
parameters
,
technology
,
alleviate
overfitting
,
stable
performance
,
feature
template
,
corresponding
instance
,
character
,
ith
character
,
additional
twofunctions
,
property
,
acharacter
,
boolean
function
,
character
,
punctuation
symbol
,
punctuation
,
amulti
valued
function
,
character
intofour
classification
,
letterand
others
,
return
,
utomatic
annotation
,
representation
inconvenience
,
corpus
,
corpus
,
annotation
standard
,
require
,
feature
template
,
instance
,
course
,
source
,
adaptation
,
targetcorpus
,
corpus
,
desired
standard
,
annotationstandards
,
source
standardand
target
standard
,
classifier
,
annotation
standard
,
source
classifier
,
target
classifier
,
word
segmentation
,
character
classification
manner
,
unified
standard
adaptation
framework
,
source
classifier
,
classification
,
guide
information
,
target
classifier
,
sclassification
decision
,
following
depicts
,
adaptation
strategy
,
detail
,
knowledge
,
thesource
corpus
,
source
classifier
,
knowledge
,
source
classifier
,
character
,
target
corpus
,
althoughthe
classification
result
,
standard
,
desire
,
target
classifier
,
target
corpus
,
source
classifier
,
sclassification
result
,
additional
guide
information
,
training
procedure
,
target
,
regularity
,
source
classifier
,
predication
result
fromsource
standard
,
regularity
,
knowledgelearnt
,
target
corpus
,
obtain
enhanced
predication
accuracy
,
givenun
classified
character
sequence
,
training
,
character
sequence
,
source
classifier
,
source
standard
,
classificationresult
,
target
classifierwith
,
classification
result
,
additional
information
,
final
result
,
method
,
dependencyparsers
,
mcd
on
source
corpustrain
withnormal
featuressource
,
withadditional
featurestarget
classifiertarget
corpus
source
annotationclassification
resultfigure
,
pipeline
,
training
,
raw
sentence
source
classifier
source
annotationclassification
resulttarget
classifiertarget
annotationclassification
resultfigure
,
pipeline
,
pred
baselinefor
domain
adaptation
,
showthe
flow
chart
,
training
,
decoding
,
utilization
,
source
classifier
,
classification
result
,
additional
guide
information
resorts
,
new
feature
,
character
,
classification
,
intuitive
guide
feature
,
thesource
classifier
,
classification
result
,
however
,
effort
isn
,
special
feature
,
source
classifier
,
sclassification
result
,
guide
feature
,
design
,
discriminativedependency
,
mc
525donald
,
pereira
,
basic
features
,
context
,
link
direction
,
distancein
order
,
special
feature
,
guide
feature
,
basic
features
,
current
character
,
thebeginning
,
combination
method
,
series
ofspecific
feature
,
target
,
precise
classification
,
parameter
tuning
procedure
,
target
classifier
,
regularity
,
sourceclassifier
,
classification
result
,
decision
making
,
current
considering
character
share
,
basic
feature
,
target
classifier
,
addition
,
training
procedure
,
target
classifier
,
relative
weight
,
guide
features
,
basic
feature
,
knowledgefrom
,
source
corpus
,
target
corpusare
,
complicated
feature
,
guide
information
,
error
tolerance
,
guide
feature
,
n
best
results
,
compacted
lattice
,
source
classifier
,
source
classifier
,
output
,
guide
feature
,
classificationresults
,
several
successive
character
,
worksco
training
,
sarkar
,
combination
,
twotechnologies
,
improved
dependencyparsers
,
training
technology
let
,
different
parsing
model
,
unlabelled
corpus
,
modelas
additional
training
corpus
,
powerful
parser
,
combination
let
,
transition
based
dependency
parser
,
fromeach
,
parsing
result
,
enhanced
parser
,
technology
,
samecorpora
,
distribution
,
annotation
standard
,
strategy
,
knowledge
,
multiple
corpus
,
basic
feature
,
guidefeatures
,
standard
adaptation
,
word
segmentation
,
suppose
,
transformation
based
converter
,
certain
annotation
style
word
segmentation
result
,
class
type
transformation
templates
,
method
,
word
delimiters
,
however
,
converter
,
transformation
template
,
top
o
tagging
,
structure
labeling
task
,
processing
procedure
,
isolated
step
,
conversion
aftersegmentation
,
error
propagation
,
knowledge
,
corpus
,
strategy
,
addition
,
many
effort
,
devotedto
manual
treebank
adaptation
,
grammar
formalism
,
suchas
ccg
,
hockenmaier
,
steedman
,
cahill
,
mccarthy
,
heavy
human
engineering
,
experimentsour
adaptation
experiment
,
treebank
,
corpus
,
following
different
segmentation
standard
,
labeledwith
different
pos
set
,
sentences
,
classifier
,
onc
tb
,
treestructures
,
downstreamapplications
,
translation
,
constituency
anddependency
parser
,
versionof
ctb
,
segmentation
,
standard
,
precise
ctb
style
segmenter
,
pos
tagger
,
whichwould
,
error
propagation
,
parsing
,
translation
,
word
segmentation
,
joint
segmentation
,
pos
tagging
,
performance
measurement
indicatorsfor
word
segmentation
,
balanced
f
measure
,
functionof
precision
,
recall
,
word
segmentation
,
segmentation
result
,
segmentedwords
,
gold
standard
word
,
wordis
,
singleperceptron
classifier
,
originalcorpus
,
former
,
chapters
,
chapter
,
fordevelopment
,
others
,
training
,
figure
,
learning
curve
,
iteration
,
convention
,
corpus
,
development
set
,
followingexperiments
,
corpus
,
single
perceptron0
,10
f
measurenumber
,
iterationssegmentation
onlysegmentation
,
perceptron
,
curve
forsegmentation
,
experimental
result
,
baselinemodels
,
final
system
,
annotation
adaptationfrom
pd
,
segmentation
isperforms
,
pdgives
a
p
o
,
corresponding
,
word
segmentation
,
pos
tagging
,
theperformance
,
segmentation
improves
,
thepos
tag
,
additional
information
,
wordsegmentation
,
segmentation
,
model
trainedon
pd
,
baseline
,
following
annotation
adaptation
experiment
,
word
baseerr
adaerr
errdec
ad
,
error
analysis
,
developing
set
,
adaerr
,
thebaseline
model
,
adapted
model
,
errdec
,
error
reduction
,
recall
,
segmentation
,
result
,
annotation
adaptation
experiment
,
word
segmentation
,
themodel
,
annotation
adaptation
,
f
measure
increment
,
baseline
model
,
toan
error
reduction
,
f
measure
increment
,
adapted
model
,
subtable
,
error
reduction
,
complicated
model
andfeatures
,
obvious
improvement
,
annotation
adaptation
,
knowledge
,
an
input
type
parsing
f1
gold
standard
segmentation
,
segmentation
,
segmentation
,
result
,
differentword
segmentation
result
,
notation
standard
,
sucha
simple
strategy
,
informationabout
,
annotation
adaptation
,
initial
error
analysis
,
error
reduction
ofr
ecall
,
word
cluster
,
pos
tag
,
word
cluster
,
developing
set
,
cluster
,
annotation
adaptation
strategy
,
cluster
,
compositive
error
rate
ofr
ecall
,
word
cluster
,
effectivity
,
annotationadaptation
,
parsingwe
,
parser
,
training
set
,
error
propagation
,
word
segmentation
,
constituent
span
,
constituent
subtreefrom
,
start
character
,
end
character
,
ratherthan
,
start
word
,
end
word
,
gold
standard
segmented
test
,
intothe
parser
,
f
measure
,
different
word
segmentation
result
,
parser
,
sinput
,
f
measure
,
tothe
gold
standard
segmentation
,
representsthe
,
oracle
,
parsing
,
automatic
word
segmention
,
knowledge
,
enhancedword
segmenter
gain
,
f
measure
increment
of0
,
errorpropagation
,
word
segmentation
,
future
worksthis
paper
,
automatic
annotation
adaptation
strategy
,
aclassic
problem
,
word
segmentation
,
joint528s
,
knowledge
,
corpus
,
anannotation
standard
,
require
,
classifier
,
corpus
,
pre
processthe
corpus
,
annotated
standard
,
second
classifier
,
firstclassifier
,
predication
result
,
additional
guideinformation
,
annotation
adaptation
,
word
segmentationand
pos
,
strategy
,
knowledge
,
corpuswith
different
annotation
,
considerablef
measure
increment
,
wordsegmentation
,
corresponding
error
reduction
,
final
result
,
thesame
corpus
,
complicated
technologies
,
moreover
,
improvement
brings
,
f
measure
increment
,
parsing
,
error
propagation
reduction
,
future
,
research
onannotation
adaptation
,
nlp
task
,
different
annotation
style
corpus
,
effort
,
annotation
standard
adaptation
,
different
treebanks
,
forexample
,
hps
g
lingo
redwood
treebankto
ptb
,
dependency
treebankto
ptb
,
powerful
ptb
annotation
style
parser
,
acknowledgementthis
project
,
national
naturalscience
foundation
,
state
key
project
,
grateful
tof
ernando
pereira
,
anonymous
reviewersfor
,
domain
adaption
,
yang
liu
,
haitao
mi
forhelpful
discussion
,
referencesdaniel
,
chiang
,
treebank
,
proceeding
,
second
workshop
,
chineselanguage
processing
,
blitzer
,
mcd
onald
,
pereira
,
adaptation
,
structural
correspondence
learning
,
proceeding
,
emn
lp
,
brill
,
transformation
based
error
drivenlearning
,
natural
language
processing
,
casestudy
,
part
of
speech
tagging
,
computationallinguistics
,
buchholz
,
marsi
,
conll
xshared
task
,
multilingual
dependency
,
inp
roceedings
,
ll
,
aoife
cahill
,
mccarthy
,
automatic
annotation
,
treebank
,
lfg
f
structure
information
,
proceeding
,
thelrec
workshop
,
linguistic
knowledge
acquisition
,
representation
,
bootstrapping
annotatedlanguage
data
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
roark
,
perceptron
algorithm
,
proceedings
,
annual
meeting
,
associationfor
computational
linguistics
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceedingsof
,
empirical
method
,
natural
language
processing
conference
,
marcu
,
adaptation
,
statistical
classifier
,
journal
,
artificial
intelligence
research
,
frustratingly
easy
domain
adaptation
,
proceeding
,
jianfeng
gao
,
haowei
qin
,
adaptive
word
segmentation
,
proceedings
,
hockenmaier
,
steedman
,
ccg
bank
,
corpus
,
ccg
derivation
,
dependencystructures
,
treebank
,
omputational
linguistics
,
wenbin
jiang
,
liang
huang
,
qun
liu
,
cascaded
linear
model
,
joint
chineseword
segmentation
,
part
of
speech
tagging
,
inp
roceedings
,
annual
meeting
,
association
,
computational
linguistics
,
santorini
,
annmarcinkiewicz
,
large
annotatedcorpus
,
treebank
,
computational
linguistics
,
dipanjan
da
,
anderic
,
dependency
parser
,
proceeding
,
emn
lp
,
mcd
onald
,
pereira
,
approximate
dependency
,
proceeding
,
mcd
onald
,
koby
crammer
,
fernandopereira
,
large
margin
training
,
dependency
parser
,
proceeding
,
hwee
tou
ng
,
jin
kiat
low
,
part
of
speech
tagging
,
all
at
once
,
proceeding
,
empirical
method
,
natural
language
processing
conference
,
joakim
nivre
,
mcd
onald
,
transition
based
dependencyparsers
,
proceeding
,
annual
meetingof
,
association
,
computational
linguistics
,
oepen
,
toutanova
,
shieber
,
manning
flickinger
,
thorstenbrants
,
lingo
redwood
treebank
,
motivation
,
preliminary
application
,
proceedings
,
international
conference
,
anoop
sarkar
,
training
method
tostatistical
parsing
,
proceeding
,
naa
cl
,
fei
xia
,
part
of
speech
tagging
,
treebank
,
deyi
xiong
,
shouxunlin
,
treebank
withsemantic
knowledge
,
proceeding
,
ijc
nlp2
,
nianwen
xue
,
libin
shen
,
wordsegmentation
,
lmr
tagging
,
proceeding
ofs
ighan
workshop
,
nianwen
xue
,
fei
xia
,
fu
dong
chiou
,
marthapalmer
,
treebank
,
phrasestructure
annotation
,
large
corpus
,
naturallanguage
engineering
,
huimingduan
,
shiyong
kang
,
honglin
sun
,
hui
,
qiang
zhao
,
weidong
zhan
,
processingnorms
,
modern
corpus
,
technical
report
,
yue
zhang
,
segmentation
,
word
based
perceptron
algorithm
,
proceeding
,45
th
annual
meeting
,
theassociation
,
computational
linguistics
,
international
conference
,
association
,
computational
linguisticsautomatic
adaptation
,
annotation
standard
,
dependency
parsing
,
projected
treebank
,
source
corpuswenbin
jiang
,
qun
liukey
lab
,
intelligent
information
processinginstitute
,
technologychinese
academy
,
sciencesp
,
beijing
,
jiangwenbin
,
dependency
,
annotation
adaptation
strategy
,
knowledge
froma
source
corpus
,
different
annotation
standard
,
target
parser
,
supervision
,
target
corpus
,
desired
standard
,
treebank
,
bilingual
corpus
,
source
corpus
,
benefit
,
resource
scarcelanguages
,
different
hand
annotated
treebanks
,
target
parser
gain
,
baseline
parser
,
target
corpus
,
targetcorpus
,
sequence
labeling
,
atagger
,
annotation
standard
,
transferring
knowledge
,
source
corpus
,
strategy
,
parsing
,
several
treebanks
,
different
annotation
standard
,
chomskian
style
penntreebank
,
g
li
ngoredwoods
treebank
,
conducting
annotation
adaptation
,
different
treebanks
,
valuableto
,
parser
,
resource
scarcelanguages
,
resource
richones
,
several
treebanks
,
hand
annotated
treebanks
,
costlyand
scarce
,
many
language
,
large
number
,
word
alignment
,
par
,
translation
,
parsing
,
many
effort
,
research
,
treebanks
,
ganchev
,
factthat
,
treebank
,
en
glish
annotation
standard
,
handwritten
rulesare
,
divergence
betweenlanguages
,
interesting
toadapt
,
divergence
,
parser
,
treebank
,
automatic
annotation
adaptation
strategy
,
dependencyparsing
,
source
corpus
,
adaptation
,
bilingual
corpus
,
word
alignment
andenglish
tree
,
error
tolerant
tree
projecting
algorithm
,
project
,
hasthe
,
consistency
,
corresponding
en
glish
tree
,
alignment
matrix
,
single
alignment
,
target
corpus
,
projectedchinese
treebank
,
non
literal
translation
,
word
alignment
error
,
result
,
significant
improvement
,
baselinemodel
,
target
corpus
,
tree
projecting
algorithm
,
annotation
adaptation
strategy
,
related
,
theexperiments
,
error
tolerant
tree
projectingalgorithmprevious
,
corpus
,
direct
mapping
method
forstructure
projection
,
yarowsky
,
ganchev
,
where25some
filtering
,
inaccurateor
,
dependency
edge
,
herewe
,
robust
algorithm
,
dependency
tree
projection
,
alignment
matrix
,
algorithm
,
dependency
tree
,
consistency
,
corresponding
en
glish
tree
,
alignment
,
algorithm
,
alignment
matrix
,
probability
,
word
ci
,
many
morepossible
alignment
,
degree
,
chi
nese
tree
tc
,
matrix
,
algorithm
aim
,
simple
accumulation
,
function
,
searching
procedure
,
argmax
operation
inequation
,
bottom
up
dynamic
algorithm
,
cube
pruningspeed
up
,
chiang
,
algorithm
,
space
restriction
,
nnotation
adaptation
fordependency
parsingthe
automatic
annotation
adaptation
strategy
forsequence
labeling
,
tagger
,
corpus
,
annotation
standard
,
assistantcorpus
,
standard
,
purpose
,
automatic
annotation
adaptation
,
dependency
parsing
,
sequence
labeling
,
training
corpus
,
annotation
standard
,
target
corpus
,
assistant
corpus
,
different
standard
,
calledthe
source
corpus
,
training
,
intermediateparser
,
source
parser
,
source
corpus
,
target
corpus
,
second
parser
,
thetarget
parser
,
target
corpus
withguide
feature
,
source
parser
,
result
,
token
sequence
isfirst
,
source
parser
,
intermediate
parsing
result
,
source
annotationstandard
,
target
parser
withthe
guide
feature
,
result
,
final
result
,
design
,
ofthe
target
parser
,
pereira
,
source
,
target
parser
,
guidefeatures
,
dependency
edgesin
accordance
,
edge
factored
property
ofm
st
model
,
decoding
procedure
,
thetarget
parser
,
degree
,
dependency
edge
being
,
relationshipbetween
,
modifier
,
intermediate
parsing
result
,
source
parser
,
themost
intuitionistic
relationship
,
dependency
,
modifier
exists
,
thisintermediate
result
,
bi
valued
relationshipis
,
stacking
method
,
combining
dependency
parser
,
relationship
,
combination
,
lexical
feature
,
mst
model
,
detailed
knowledge
,
source
parser
,
relationship
,
four
valued
variablewhich
,
following
situation
,
sibling
,
theguide
feature
,
parameter
,
procedure
ofthe
target
parser
,
regularity
,
source
parser
,
intermediate
result
,
worksmany
,
parsing
knowledge
,
bracketing
knowledge
,
ganchev
,
dependency
grammar
,
projection
,
filtering
,
thenoise
,
hand
designed
rule
,
language
heterogeneity
,
eisner
,
gavean
idea
,
dependency
projection
,
although
,
projection
,
annotation
,
important
difference
,
thesetwo
,
error
tolerantalignment
matrix
based
tree
projecting
algorithmto
,
whole
tree
projection
,
qg
feature
,
local
configurationsof
,
source
,
target
tree
,
second
,
theiradaptation
,
tree
fromone
annotation
standard
,
ouradaptation
,
parser
,
treebank
,
annotation
adaptation
,
thatis
,
treebank
,
million
ldc
sentence
pair
,
side
,
bilingual
corpus
,
implementationof
,
sentencesare
,
implementation
,
wsj
,
treebank
,
matrix
,
algorithm
,
projected
tree
,
thousand
withword
count
,
target
corpus
,
traditional
corpus
splitting
,
chapter
,
chapters
,
development
,
training
,
target
parser
,
betterperformance
,1
st
order
mst
model
asthe
source
parser
,
fast
training
,
twoparsers
,
averaged
perceptron
algo
model
,
ctb
p
,
annotation
adaptationwith
,
target
corpus
,
baseline
parser
,2
nd
order
mst
parser
,
target
corpus
,
accuracysentence
count
,
target
corpusbaselinetarget
parserfigure
,
target
parser
,
corpus
,
different
scale
,
development
,
ofc
tb
,
model
forthe
source
parser
,
hypothesisof
,
isomorphisme
,
experimental
result
ofannotation
adaptation
,
target
corpus
,
thatthe
source
parser
,
sourcecorpora
,
performs
,
ctb
test
set
,
projected
tree
bank
,
heterogeneous
betweenthe
ctb
tree
,
automatic
annotation
adaptation
,
knowledge
,
target
parser
,
improvement
,
target
corpus
,
accuracy
increment
of1
,
baseline
parser
,
annotation
adaptation
,
adaptation
performances
,
target
corpus
,
different
scale
,
weconduct
annotation
adaptation
,
series
,
target
corpus
,
consist
,
different
amount
ofdependency
tree
,
figure
,
experimental
result
,
training
corpus
,
significant
improvement
,
target
corpus
,
nearly2
point
,
accuracy
increment
,
good
news
,
resource
scarce
,
future
worksthis
paper
describes
,
dependency
,
anautomatic
annotation
adaptation
strategy
,
whatis
,
projected
treebank
,
hand
annotated
one
,
sourcecorpus
,
adaptation
,
different
fromprevious
,
ganchev
,
previous
,
annotation
adaptation
,
thisstrategy
gain
improvement
,
baseline
parserswith
target
corpus
,
different
scale
,
new
strategy
forresource
scarce
language
,
high
precisiondependency
parser
,
future
,
strategy
,
parsing
,
complexityof
projection
,
constituent
tree
,
obscurity
,
annotation
adaptation
,
constituent
parsing
,
acknowledgementthis
project
,
national
naturalscience
foundation
,
state
key
project
,
anonymous
reviewer
,
valuable
suggestion
,
wealso
,
yang
liu
,
alignment
matrix
generation
,
liang
huang
,
helpful
discussion
,
referencesmichael
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceedingsof
,
emn
lp
,
gillenwater
,
bentaskar
,
dependency
grammar
induction
,
projection
constraint
,
proceeding
,
the47th
acl
,
liang
huang
,
chiang
,
k
bestparsing
,
proceeding
,
hwa
,
resnik
,
weinberg
,
andokan
kolak
,
translational
correspondence
,
annotation
projection
,
proceedings
,
hwa
,
resnik
,
weinberg
,
claracabezas
,
okan
kolak
,
bootstrappingparsers
,
syntactic
projection
,
parallel
text
,
natural
language
engineering
,
wenbin
jiang
,
liang
huang
,
qun
liu
,
cascaded
linear
model
,
joint
chineseword
segmentation
,
part
of
speech
tagging
,
inp
roceedings
,
wenbin
jiang
,
liang
huang
,
qun
liu
,
automatic
adaptation
,
annotation
standard
,
chineseword
segmentation
,
po
tagging
,
study
,
inp
roceedings
,47
th
acl
,
yang
liu
,
tian
xia
,
xinyan
xiao
,
qun
liu
,
alignment
matrix
,
statistical
machinetranslation
,
proceeding
,
emn
lp
,
muyun
yang
,
bilingual
language
model
,
proceedings
,
santorini
,
annmarcinkiewicz
,
large
annotatedcorpus
,
treebank
,
computational
linguistics
,
dipanjan
da
,
anderic
,
dependency
parser
,
proceeding
,
emn
lp
,
mcd
onald
,
pereira
,
approximate
dependency
,
proceeding
,
mcd
onald
,
koby
crammer
,
fernandopereira
,
large
margin
training
,
dependency
parser
,
proceeding
,
joakim
nivre
,
mcd
onald
,
transition
based
dependencyparsers
,
proceeding
,
oepen
,
toutanova
,
shieber
,
manning
flickinger
,
thorstenbrants
,
lingo
redwood
treebank
,
motivation
,
preliminary
application
,
proceedings
,
eisner
,
parser
adaptation
,
projection
,
quasi
synchronous
grammar
feature
,
proceeding
,
emn
lp
,
nianwen
xue
,
fei
xia
,
fu
dong
chiou
,
marthapalmer
,
treebank
,
phrasestructure
annotation
,
large
corpus
,
naturallanguage
engineering
,
yarowsky
,
ngai
,
multilingual
po
tagger
,
np
bracketers
,
robustprojection
,
corpus
,
proceedingsof
,
poster
volume
,
beijing
,
constituent
projection
,
languageswenbin
jiang
,
yang
liu
,
qun
liukey
laboratory
,
intelligent
information
processinginstitute
,
technologychinese
academy
,
science
jiangwenbin
,
lvyajuan
,
effective
constituent
projection
strategy
,
constituent
projection
,
dependency
projection
,
novelmeasurement
,
thecandidate
,
constituent
,
a
p
cfgstyleparsing
procedure
,
constituent
tree
,
state
of
the
artsupervised
parser
,
atree
based
machine
translation
system
,
parser
,
supervised
parser
,
thousand
,
annotated
tree
,
ntroductionin
year
,
constituent
parsing
hasbeen
,
state
of
the
artfor
many
resource
language
,
charniak
,
petrov
,
difficulty
,
treebank
construction
,
researcher
,
utilization
,
unannotated
text
,
unsupervised
parsing
,
unannotated
data
,
manning
,
manning
,
seginer
,
semi
supervised
parsing
,
sarkar
,
steedman
,
losky
et
,
complexity
,
lowerperformance
,
unsupervised
method
,
reliable
priori
,
semi
supervised
method
,
syntax
structure
,
resource
language
,
bilingualcorpus
,
research
,
projection
,
ganchev
,
smithand
eisner
,
constituent
projection
,
progress
,
constituent
syntax
,
languagestructure
,
detailed
,
degree
ofisomorphism
,
constituent
structure
appears
,
constituent
projection
,
stepwise
,
automatic
strategy
,
constituent
projection
,
basis
,
dependency
projection
,
constraint
optimization
algorithm
,
word
alignedbilingual
corpus
,
wefirst
project
,
dependency
structure
,
theseconstituent
tree
,
adynamic
programming
algorithm
,
candidate
constituent
,
targetsentence
,
design
,
novel
evaluation
functionto
,
probability
,
candidate
constituent
,
a
p
cfgstyle
parsingprocedure
,
probable
projected
constituent
tree
,
evaluated
candidateconstituent
set
,
addition
,
constraintem
optimization
procedure
,
noisein
,
constituent
treebank
,
experimental
result
,
effectivenessof
,
fbi
scorpus
,
par
,
charniak
parser
,516
tences
,
parser
,
projected
treebank
,
supervised
parser
,
ctb
tree
,
supervised
parser
,
thesmaller
ctb
,
benefit
,
significant
f
measureincrement
,
projectedparser
,
parser
,
tree
based
translation
model
,
weachieve
translation
performance
,
parser
trainedon
thousand
,
ctb
tree
,
surprising
result
,
inspiration
,
translationwould
,
projectedparsing
,
dynamic
programming
procedure
,
dependency
projection
,
pcf
g
style
algorithm
,
constituent
projection
,
projected
dependentstructures
,
constraint
emprocedure
,
constituent
optimization
,
dynamicprogramming
algorithm
,
mostprobable
projected
target
dependency
,
source
dependency
structure
andthe
word
alignment
,
effect
,
word
alignmenterrors
,
results
,
compact
,
alignment
matrix
,
source
sentencewith
word
,
targetsentence
,
theirword
alignment
matrix
,
probabilityof
,
source
word
ei
,
target
wordfj
,
probabilityof
,
target
dependency
structure
,
source
dependency
structurede
,
alignment
matrix
,
projection
algorithm
aim
,
algorithm
dependency
projection
,
topological
order
do3
,
partitions5
,
insert
der
iv
,
insert
der
iv
,
top
derivation
,
output
,
derivation
,
new
derivation12
,
evaluation
function13
,
dependency
edge
xy
,
possible
situation
,
correspondencepe
,
function
,
dependent
relation
,
search
procedure
,
argmax
operation
,
equation
,
chu
liu
edmonds
algorithm
,
mc
,
simple
dynamic
programming
algorithm
,
algorithm
,
possible
expansion
,
inpractice
,
cube
pruning
strategy
,
enumeration
,
derivation
,
probable
projected
constituent
tree
,
search
space
,
projected
dependency
structure
,
target
constituent
tree
,
shrunken
search
space
,
candidate
constituent
,
source
tree
,
candidate
span
,
candidate
constituent
,
consistent
degree
for517each
pair
,
candidate
constituent
,
probability
,
candidateconstituent
,
spansfor
,
candidate
constituent
,
sourcetree
,
original
constituent
,
strong
hypothesis
,
isomorphism
,
constituent
projection
,
language
,
sinceit
,
couple
,
constituent
,
spanmust
,
candidate
span
,
subsequences
,
search
procedure
suffer
frommore
perplexity
,
candidate
constituent
set
,
production
,
source
constituent
tree
,
parent
,
constituent
,
represent
,
left
and
right
bound
,
subsequence
,
theconstituent
cover
,
candidate
constituentset
,
production
,
head
ofthe
production
,
incompleteconstituents
,
symbol
,
candidate
constituent
,
entire
source
tree
,
unification
ofthe
set
,
production
,
candidate
span
,
lb
andrb
,
constituent
,
candidate
span
,
regular
dependent
segment
,
corresponding
projected
dependency
structure
,
aregular
dependency
segment
,
dependentsegment
,
modifier
,
acomplete
dependency
structure
,
suppose
adependency
structure
,
cl2cl1
cr1cr2
,
themis
,
complete
dependency
structure
,
regular
dependency
segment
,
modifier
,
cl1
py
cr1
,
regular
dependency
structure
,
modifier
,
regular
dependency
segment
,
entire
projected
dependency
structure
,
dependency
node
,
candidate
constituent
,
source
tree
,
candidate
span
set
,
consistent
degree
foreach
pair
,
candidate
constituent
,
candidatespan
,
consistent
degreec
,
probability
,
derivation
,
bottom
,
alignment
probability
,
constituent
,
alignment
probability
,
thespan
,
constituent
,
index
,
simplicity
,
confusion
,
alignmentprobability
,
constituent
,
manner
,
constituent
projection
,
source
constituent
tree
,
candidateconstituents
,
constituent
,
nonterminals
,
constituent
set
,
constituents
,
probability
,
tree
tf
,
probability
,
projectedconstituents
,
probability
,
source
constituent
,
statistic
,
numerator
,
theconsistent
degree
,
constituent
,
span
andconstituent
,
pseudocode
,
constituent
projection
,
a
p
cfgstyle
,
procedure
search
,
projected
constituenttree
,
constrained
space
,
asterisk
,
nonterminals
,
algorithm
constituent
projection
,
topological
order
do3
,
partitions6
,
insert
der
iv
,
top
derivation
,
output
,
derivation
,
new
derivation12
,
evaluation
function13
,
return
,
optimizationsince
,
constituent
projection
,
oneach
sentence
pair
,
tree
bank
,
byfree
translation
,
word
alignment
error
,
iteration
,
wholeprojected
treebank
,
higherconsistence
,
inside
outside
algorithm
,
quality
,
different
,
previous
,
expectation
,
maximization
operation
,
single
treeare
,
constrained
space
,
candidate
span
set
,
projected
targetdependency
structure
,
summation
operation
,
rule
probability
,
candidate
span
,
thismeans
,
projected
dependency
structuresare
,
following
constituent
projectionprocedure
,
overall
description
,
tree
bank
optimization
procedure
,
initialpcfg
grammar
g0f
,
originalprojected
treebank
,
several
iteration
,
rule
probability
re
estimation
,
i
the
iteration
,
afterwards
,
optimized
grammar
gif
,
iterative
procedure
,
likelihood
ofwhole
treebank
increase
,
theoptimized
grammar
,
constrained
pcf
parsingprocedure
,
initial
pro
519jected
tree
,
constituent
projectionthe
,
direct
contribution
,
constituent
projection
,
initial
step
,
statistical
constituent
parsing
,
resource
scarce
languages
,
meaningful
applications
,
resource
language
,
forinstances
,
projected
treebank
,
largescale
,
high
coverage
,
traditional
supervised
trained
parser
,
treebank
,
toconduct
tree
to
string
machine
translation
,
result
,
isomorphismwith
,
target
language
,
supervised
trainedparser
dose
,
traditional
parserwe
,
unified
framework
,
enhanced
parser
,
parser
,
parsing
procedure
,
baselineparser
,
enhancedparser
,
setof
candidate
,
evaluationfunctions
,
baseline
parser
,
evaluation
function
,
decoding
procedure
,
carreras
etal
,
shallow
level
,
rerank
ing
manner
,
charniak
,
simplicity
,
generability
,
reranking
strategy
,
candidate
par
,
denotedas
,
candidates
,
high
dimensional
feature
representation
,
corresponding
weight
vector
,
first
featuref1
,
baseline
parser
,
features
,
integer
valued
guide
feature
,
guider
parser
,
predicationresult
,
particular
configuration
,
parser
,
sknowledge
,
parsing
procedure
,
thetraditional
parser
,
guide
feature
,
twoparts
,
certain
constituent
,
candidate
parse
,
projected
parse
thisspan
,
constituent
,
situation
,
constituent
,
asterisk
,
tailof
,
theguide
featuresf100
,
candidate
,
corresponds
,
segment
,
projectedparse
,
quantity
,
weight
w100
indicateshow
,
v
p
ifthe
span
,
partial
pp
,
projected
parse
,
perceptron
algorithm
,
reranker
,
stable
weight
vector
,
refinement
strategy
,
parameter
,
machine
translationresearchers
,
promising
improvements
,
tree
based
machine
translation
,
liu
etal
,
parsed
tree
,
targettree
,
string
,
traditional
source
language
parserto
,
translation
decoder
,
derivation
,
sequence
,
transformation
,
sourcetree
,
target
language
stringd
,
argmaxd
,
nonterminals
,
improvementin
,
reranking
experiment
,
impact
,
parser
,
candidate
set
,
source
tree
,
transformationrules
,
tree
based
model
,
synchronous
transformational
grammar
,
isomerism
,
thesource
syntax
,
target
sentence
structure
,
parsed
tree
,
parser
,
target
language
,
promising
idea
,
parser
,
effect
,
constituent
projection
,
parser
,
projected
treebank
,
application
,
parser
,
boostingan
traditional
supervised
trained
parser
,
integration
,
tree
based
machine
translation
system
,
previous
,
f
score
,
translation
quality
,
papineni
,
reference
,
englishto
,
fbi
corpus
,
charniak
parser
,
dependencystructures
,
head
finding
rule
,
yamada
,
word
alignment
matrixesare
,
best
result
,
dependency
,
andthen
project
,
constituent
structure
,
assessment
criteriato
,
confidence
,
word
count
,
series
,
chi
thres
resrv
cons
f1
span
f10
,
parserson
,
ctb
test
,
amountof
,
threshold
,
cons
f1
isthe
traditional
f
measure
,
span
f1
,
f
measure
,
consideration
,
nonterminals
,
nese
treebanks
,
different
scale
,
different
,
filtering
threshold
,
state
of
the
parser
,
totrain
,
treebanks
,
high
performance
,
independence
,
head
word
information
,
projected
parser
,
standard
ctb
test
set
,
whichis
,
chapter
,
decrease
,
filtering
threshold
,
projected
tree
,
parser
,
increase
,
cons
f1
,
onewithout
,
nonterminals
,
span
f1
,
constituent
projection
procedureintroduces
,
complexity
,
constituent
correspondence
,
projected
treebank
,
threshold
,
berkeleyparser
,
thousand
tree
,
thisthreshold
,
constrained
optimization
,
thenoise
,
projected
treebank
,
free
translation
,
word
alignment
error
,
projection
,
single
sentence
pair
,
figure
,
log
likelihood
,
projectedtreebank
,
iteration
,
obvious
thatthe
log
likelihood
increase
,10
iterations
,
procedure
after40
iteration
,
parser
,
optimized
projected
treebank
,40
l
og
likelihoodem
iterationfigure
,
log
likelihood
,87
k
projectedtreebank
,
interation
,
parser
,
treebank
,
parser
,
train
set
baseline
bst
ini
bst
optctb
,
performance
improvement
,
parser
,
baseline
parser
,
bst
ini
bst
opt
,
parser
,
projected
treebank
,
standard
ctb
test
set
,
parser
,
treebank
,
constituent
f1
value
,
optimized
treebank
drop
,
baseline
,
span
f1
value
remains
,
emprocedure
,
consistency
,
whilethe
,
treebank
deviate
,
ctb
annotation
standard
,
traditional
parserthe
,
parser
,
rerankingof
,
k
best
par
,
state
of
the
parser
,
baseline
parserfor
convenience
,
parser
,
treebank
,
parserfigure
,
boosting
performance
,
projectedparser
,
series
,
baseline
parser
,
treebanks
,
different
scale
,
thebaseline
parser
,
baseline
parser
,
trained
onc
tb
,
corpus
,
traditional
corpus
splitting
,
chapters271
,
chapter
,
development
,
training
,
experimental
results
,
parser
,
significant
improvement
tothe
baseline
parser
,
althoughperforms
,
ctb
standard
test
set
,
improvement
,
confirms
,
previous
assumption
,
however
,
investigation
,
thefuture
,
baseline
,
boosting
performance
,
parser
,
boosting
performance
change
,
treebank
,
baselineparser
,
series
,
baseline
parser
withdifferent
amount
,
projectedparser
,
optimized
treebank
,
enhance
,
baseline
parser
,
figure
,
show
theexperimental
result
,
training
corpus
,
baselineparser
,
significant
improvement
,
good
news
,
resource
scarce
,
large
treebanks
,
parser
,
k
best
par
,
somesentences
,
small
treebanks
,
sentences
,
k
best
reranking
experiment
,
machine
translationwe
,
effect
,
tree
based
translation
model
,
to
translation
,
series
,
contrast
translation
system
,
supervised
parser
,
particular
amount
,
ctb
tree
,
fbi
s
ch
inese
bitext
,
corpus
,
nis
t
mt
evaluationtest
,
development
,
nis
tmt
aluation
test
,
test
set
,
tree
to
string
translation
rule
,
corpus
,
algorithm
,
gram
language
model
onthe
xinhua
portion
,
gig
aword
,
withkneser
ney
smoothing
,
sri
languagemodeling
toolkit
,
stolcke
,
standard
minimum
error
ratetraining
,
feature
weightsto
,
figure
,
experimental
result
,
translation
system
,
projectedparser
,
performance
comparable
withthe
,
parser
,
onc
tb
,
f
score
,
projected
parser
,
f
score
,
parser
trainedon
,
confidence
,
theassumption
,
parser
,
syntax
structure
,
counterpart
language
,
surprising
result
,
inspiration
,
translation
,
parsing
,
schema
,
onclusionthis
paper
,
effective
strategy
,
constituent
projection
,
dependency
,
constituent
projection
,
initial
projected
treebank
,
constraint
procedure
,
projected
tree
,
parser
,
tree
bank
,
existed
state
of
the
supervised
trained
parser
,
treebank
,
projectedparser
,
tree
based
translation
,
scorescale
,
treebank
,
supervised
parsersfigure
,
translation
system
,
parser
,
series
,
supervised
parser
,
ctb
tree
,
translation
performance
,
parser
,
thousand
,
human
annotated
tree
,
first
time
thatthe
experimental
result
,
constituent
projection
,
applications
,
many
future
,
energy
need
,
treebank
optimization
,
hybrid
parsing
schema
,
supervised
trained
parser
,
projectedparser
,
forbetter
translation
,
acknowledgmentsthe
author
,
national
naturalscience
foundation
,
contract
,
microsoft
research
natural
language
processing
theme
program
,
andnational
natural
science
foundation
,
chinacontract
,
anonymous
reviewer
,
thorough
reviewing
andvaluable
suggestion
,
referencesbod
,
all
subtrees
approach
,
unsupervised
parsing
,
proceeding
,
dynamic
programming
,
percep
tron
,
feature
parsing
,
proceedings
,
ll
,
johnson
,
coarse
to
fine
grained
n
best
parsing
,
discriminativereranking
,
proceeding
,
charniak
,
maximum
entropy
inspired
parser
,
proceeding
,
naa
cl
,
head
driven
statistical
models
,
natural
language
parsing
,
thesis
,
fornatural
language
parsing
,
proceeding
,
theicml
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceedingsof
,
emn
lp
,
kuzman
,
gillenwater
,
bentaskar
,
dependency
grammar
induction
,
projection
constraint
,
proceeding
,
the47th
acl
,
chiang
,
k
bestparsing
,
proceeding
,
knight
,
aravind
joshi
,
statistical
syntax
directed
translation
,
extendeddomain
,
locality
,
proceeding
,
reranking
,
nonlocal
feature
,
proceeding
ofthe
acl
,
resnik
,
weinberg
,
andokan
kolak
,
translational
correspondence
,
annotation
projection
,
proceedings
,
resnik
,
weinberg
,
claracabezas
,
okan
kolak
,
bootstrapping
parser
,
syntactic
projection
,
parallel
text
,
natural
language
engineering
,
manning
,
agenerative
constituent
context
model
,
improvedgrammar
induction
,
proceeding
,
manning
,
cor
pusbased
induction
,
syntactic
structure
,
modelsof
dependency
,
constituency
,
proceeding
ofthe
acl
,
qun
liu
,
shouxun
,
tree
to
string
alignment
template
,
statistical
machinetranslation
,
proceeding
,
tian
xia
,
xinyan
xiao
,
qun
liu
,
alignment
matrix
,
statistical
machinetranslation
,
proceeding
,
charniak
,
self
training
,
parseradaptation
,
proceeding
,
pereira
,
kiril
ribarov
,
andjan
hajic
,
non
projective
dependency
parsing
,
tree
algorithm
,
proceedingsof
hlt
emn
lp
,
ney
,
improvedstatistical
alignment
model
,
proceeding
,
theacl
,
minimum
error
rate
training
,
statistical
machine
translation
,
proceedings
,
annual
meeting
,
associationfor
computational
linguistics
,
papineni
,
kishore
,
roukos
,
method
,
automaticevaluation
,
machine
translation
,
proceedingsof
,
petrov
,
thibaux
,
danklein
,
interpretable
tree
annotation
,
proceeding
,
theacl
,
sarkar
,
training
methodsto
statistical
parsing
,
proceeding
,
naa
cl
,
seginer
,
fast
unsupervised
incrementalparsing
,
proceeding
,
eisner
,
parser
adaptation
,
projection
,
quasi
synchronous
grammar
feature
,
proceeding
,
emn
lp
,
steedman
,
mile
,
anoop
sarkar
,
hwa
,
hockenmaier
,
ruhlen
,
baker
,
crim
,
statistical
parser
,
smalldatasets
,
proceeding
,
extensible
language
,
toolkit
,
proceeding
,
international
conference
,
spoken
language
processing
,
shouxunlin
,
treebank
withsemantic
knowledge
,
proceeding
,
ijc
nlp2
,
yamada
,
y
m
atsumoto
,
statistical
dependency
analysis
,
support
vector
machine
,
proceeding
,
tale
oftwo
parser
,
investigating
,
transition
based
dependency
,
using
beam
search
,
proceeding
,
emn
lp
,
col
ing
,
international
conference
,
computational
linguistics
,
technical
paper
,
dublin
,
laboratory
,
intelligent
information
processinginstitute
,
computing
technology
,
academy
,
science
,
academy
,
science
chenhongshen
,
xiejun
,
school
,
computing
,
dublin
city
universityqliu
,
bstractprevious
model
,
syntax
based
statistical
machine
translation
,
resort
,
kindsof
synchronous
procedure
,
analysis
transfer
generationmethodology
,
statistical
implementation
,
analysis
transfer
generation
methodology
,
rule
based
translation
,
procedure
,
syntax
analysis
,
syntaxtransfer
,
language
generation
,
synchronousconstraint
,
structure
,
dependency
edge
,
atomic
manipulatingunits
,
large
scale
experiment
,
translation
show
,
model
exhibitsstate
of
the
performance
,
phrase
based
model
,
statistical
transfer
generation
method
result
,
much
smallermodels
,
ntroductionresearches
,
statistical
machine
translation
,
year
,
statistical
translationmethods
,
syntax
based
model
,
yamada
,
knight
,
graehl
,
knight
,
chiang
,
word
based
andphrase
based
method
,
syntax
based
model
,
long
distance
reordering
,
highergeneralization
capability
,
hierarchical
structure
,
natural
language
,
thestate
of
the
performance
,
syntax
based
model
,
synchronous
generationprocedures
,
structural
correspondence
,
language
,
contrast
,
analysis
transfer
generation
methodology
,
rule
based
translation
,
machine
translationproblem
,
divided
scheme
,
processing
procedure
,
analysis
,
structural
transfer
andlanguage
generation
,
analysis
transfer
generation
strategy
,
highernon
isomorphism
,
language
,
general
transformation
unit
,
engineering
,
processing
procedure
,
statistical
transfer
,
comparable
performance
,
current
state
of
the
smt
model
,
novel
statistical
analysis
transfer
generation
model
,
machine
translation
,
advantage
,
transfer
generation
scheme
,
statistical
modeling
,
theprocedures
,
transfer
,
generation
,
dependency
structure
,
dependency
,
dependency
parser
,
thesource
dependency
structure
,
target
structure
,
translation
rule
,
source
,
target
edge
,
target
,
intermediate
syntactic
structure
,
basic
unit
,
thedependency
tree
,
modifying
relationship
,
positional
relation
betweenwords
,
non
isomorphic
problem
,
flexibility
,
a
creative
common
attribution
,
proceeding
footerare
,
organizer
,
license
detail
,
creativecommons
,
org
license
,
nsubj
advmoddobjf
,
nna
statement
,
securitya
statement
,
strategyf
,
obama
today
,
statement
,
ntomodf
,
figure
,
dependency
tree
,
corresponding
englishsentence
,
transfer
rule
,
innernodes
,
variable
,
target
side
,
thedependent
,
dependency
edge
based
transfermodel
,
rule
acquisition
algorithm
,
decoding
,
targetsentence
generation
process
,
large
scale
experiment
,
to
translation
show
,
edge
based
transfer
model
gain
state
of
the
performance
,
phrase
based
model
,
ble
point
onthree
test
set
,
knowledge
,
first
transfer
generation
based
statistical
machinetranslation
model
,
dependency
treesgiven
,
dependency
tree
,
directed
acyclic
graph
,
dependency
tree
,
figure
,
dependencyrelationship
,
dependent
,
nominal
dependent
act
,
asubject
,
verbal
head
,
relative
position
,
figure
,
modifies
,
grammatical
relation
label
nsubj
,
anoun
phrase
,
subject
,
observation
,
elementary
structure
,
dependency
treeand
,
dependency
tree
,
definition
,
source
side
edge
,
relative
position
,
grammatical
relation
label
,
upper
side
,
transfer
rule
,
source
side
edge
,
dependencytree
,
edge
,
obama
today
,
right
,
statement
,
security
,
obama
today
,
statement
,
security
strategyh2
,
statement
,
security
strategy
,
nsubj
advmodf
,
issue
,
partial
generation
,
translation
,
target
hypotheses
,
different
word
order
,
hasbeen
,
corresponding
target
sentence
fragment
,
reordering
,
relative
position
,
languagepairs
,
first
rule
show
,
nominal
subject
,
position
relation
,
thesource
side
relative
position
,6
th
rule
,
inversion
relation
,
source
andthe
target
,
transfer
rule
,
fromthe
source
dependency
tree
,
target
edge
,
one
to
one
correspondence
,
variablesin
,
transfer
rule
,
figure
,
target
dependent
,
right
side
,
target
head
,
the1105label
,
target
head
,
target
dependent
,
ifthe
dependent
,
internal
node
,
contrast
,
leaf
node
,
dependency
tree
,
substitution
node
,
dependent
,4
th
transfer
rule
,
internal
node
,
itscorresponding
target
side
,
substitution
variable
,
figure
,
partial
transfer
generation
,
analysis
,
dependency
tree
,
dependency
parser
,
subtree
,
substitution
node
,
second
,
transfer
,
internal
node
,
source
side
,
dependent
,
target
side
,
thesecond
block
,
figure
,
target
side
,
generation
,
third
block
,
figure
,
target
side
,
thetarget
head
,
first
try
,
target
side
,
left
side
,
consecutive
phrase
,
toissue
,
possible
left
concatenation
,
sequence
,
hypothesis
,
hypothesis
,
candidate
translation
,
hypothesis
,
candidate
translation
,
transfer
rulestransfer
rule
,
word
aligned
corpus
,
triple
,
source
dependency
tree
,
alignment
relationbetween
,
dependency
to
string
model
,
tree
annotation
,
dependency
tree
,
alignment
information2
,
edge
identification
,
identify
acceptable
edge
,
annotated
dependency
tree3
,
rule
induction
,
un
lexicalized
transfer
rule
,
acceptableedges
,
figure
,
attribute
,
andsub
tree
span
,
definition
,
node
span
nsp
,
consecutive
index
,
target
,
security
,
definition
,
node
span
nsp
,
dependency
tree
,
definition
,
subtree
,
subtree
span
tsp
,
consecutive
target
wordindexes
,
upper
bound
,
target
phrase
,
statement
,
securitystrategy
,
definition
,
subtree
span
tsp
,
dependency
tree
,
whiletsp
,
statement
,
security
strategyj
,
figure
,
annotated
dependency
tree
,
formeris
node
span
,
latter
,
subtree
span
,
edge
,
figure1
,
figure
,
target
side
,
edge
,
annotated
dependency
tree
,
rule
induction
,
acceptable
edge
,
node
span
,
head
nsp
,
subtree
span
,
dependenttsp
,
following
property
,
dependent
,
dependent
,
thegray
edge
,
dependent
,
acceptable
edge
,
acceptable
edge
,
acceptable
source
side
edge
,
un
lexicalized
transfer
rule
,
lexicalized
transfer
rule
,
acceptable
edge
,
following
procedure
,
source
side
edge
,
internal
node
,
substitution
site
,
position
information
,
dependent
,
left
side
,
right
side
,
figure
,
first
transfer
rule
,
addition
,
theword
,
source
side
edge
,
wild
card
,
speech
,
rulein
figure
,
generalized
version
,
generalized
rule
,
nsubjf
,
generalization
,
transfer
rule
,
un
lexicalized
rule
,
word
information
,
single
node
translation
,
generalizedwords
,
unaligned
word
,
target
side
,
dependent
,
bothleft
,
right
direction
,
process
,
method
,
acceptable
edge
,
frequency
,
extracted
rule
,
observed
data
,
relative
frequency
estimator
,
translation
probability
,
decoding
,
generationwe
,
general
log
linear
model
,
eachconcatenation
,
target
,
concatenation
,
target
,
probability
,
concatenation
,
iare
feature
weight
,
experiment
ofthis
paper
,
thirteen
feature
,
lexical
translation
probabilitiesplex
,
bilingual
,
probability
pbp
,
bilingual
phrase
lexical
translation
probabilities
pbplex
,
pbplex
,
decoder
,
bottom
up
chart
based
beam
search
algorithm
,
decodingprocess
,
composition
,
target
side
edge
,
obama
today
,
statement
,
phrase
,
dependency
tree
,
external
dependency
parser
,
postorder
,
foreach
internal
node
,
root
node
,
transfer
generation
translation
,
following
procedure
,
source
side
,
generalized
edge
,
allits
dependent
,
source
side
edge
,
transfer
rule
,
source
side
,
target
side
edge
,
generalized
rule
,
icalized
rule
,
single
word
translation
,
matched
edge
,
pseudo
translation
rule
,
word
order
,
source
head
dependent
relation
,
bidirectional
extension
,
target
edge
,
target
edge
,
translation
hypothesis
,
target
edge
,
left
side
,
possible
permutation
,
target
,
right
side
,
possible
permutation
,
target
,
directingright
,
dependency
tree
,
result
inmassive
search
space
,
time
complexity
,
maximum
distortion
limit
,
thedistortion
,
start
position
,
source
side
,
ith
target
side
edge
,
end
position
,
source
sideedge
,
th
target
side
edge
,
root
node
,
candidate
translation
,
target
edge
,
transfer
rule
,
consecutive
phraseand
,
source
side
length
,
target
sentence
fromthe
target
head
,
bilingual
phrase
,
phrase
,
single
target
head
word
,
flexibility
,
syntactic
phrase
,
non
syntactic
phrase
,
fixed
dependency
structure
,
consecutivephrases
,
figure
,
phrase
,
search
space
,
several
,
beam
threshold
,
beam
size
,
maximumnumber
,
phrase
based
model
,
nis
t
ch
inese
to
translation
task
,
influence
,
the1109mt02
tune
mt03
mt04
mt050
,
distortion
limitbleu
,
mt02
tunemt03mt04mt05figure
,
effect
,
different
maximum
distortion
limit
,
developmentset
,
maximum
distortion
limit
,
open
source
phrase
based
system
,
defaultconfiguration
,
baseline
system
,
ldc
data
,
hansard
portion
,
dependency
tree
,
source
side
,
parser
,
manning
,
projective
dependency
structure
,
pos
tag
andedges
,
dependency
label
,
word
alignment
,
corpus
,
directionsand
,
grow
diag
and
,
refinement
,
phrase
,
morethan
,
fixed
structure
,
sri
lm
,
stolcke
,
gram
language
model
,
modified
kneser
ney
smoothing
,
xinhua
portion
,
gigaword
corpus
,
nis
tmte
valuation
test
set
,
development
,
nis
,
testsets
,
quality
,
translation
,
insensitive
nis
t
bleu
,
metric2
,
minimum
error
rate
training
algorithm
,
thebleu
score
,
development
set
,
statistical
significance
test
,
sign
test
,
influence
,
maximum
distortion
limitfigure
,
different
maximum
distortion
limit
,
nis
test
set
,
different
distortion
limit
,
development
set
,
test
set
,
maximum
distortion
limit
,
lowdistortion
limit
,
sequence
,
source
,
distortion
limit
equal
,
reordering
,
high
distortionlimit
,
good
translation
,
many
ambiguity
,
possiblesequences
,
target
dependent
,
maximum
distortion
limit
,
thenext
experiment
,
statmt
,
jaguar
,
glv
mt
resource
,
statistic
,
extracted
rule
,
training
data
,
edge
based
transfer
model
,
result
,
baseline
system
,
modeltabel
,
translation
result
,
baseline
,
average
,
baseline
phrase
based
model
,
statistical
significance
test
sign
test
,
statistical
number
,
training
corpus
,
ourtransfer
rule
,
total
rule
,
worktransfer
based
mt
system
,
parse
tree
,
source
language
,
parsetree
,
target
language
,
transfer
rule
,
previous
acquired
transfer
rule
,
word
aligned
corpus
,
richardson
,
carbonell
,
lavoie
,
gimpel
,
usedquasi
synchronous
dependency
grammar
,
transfer
ofdependency
syntax
,
non
synchronous
setting
,
translation
,
monolingual
lattice
,
dependency
based
system
,
transfer
unit
,
translationproblem
,
minimal
path
,
treelet
,
source
dependency
tree
,
synchronous
grammar
,
source
dependency
structure
,
target
side
,
word
alignment
,
problem
,
non
isomorphism
betweenlanguages
,
treelet
,
corresponding
target
,
problem
,
information
,
head
dependents
rule
,
source
side
,
head
dependents
relation
,
target
side
,
string
,
simpler
elementary
structure
,
consist
,
headand
,
dependent
,
transfer
generation
model
,
source
dependency
tree
,
position
information
,
target
edge
,
non
isomorphismproblem
,
incorporate
ordering
,
different
target
,
decodingmethod
,
previous
dependency
tree
based
,
target
sentence
fragment
,
internalnode
,
future
workin
,
novel
dependency
edge
based
transfer
model
,
dependency
tree
,
thesource
side
,
machine
translation
,
source
dependency
tree
,
thetarget
side
,
beam
search
,
concise
transfer
rule
,
non
syntactic
phrase
,
generationprocess
,
good
performance
,
thephrase
based
model
,
large
scale
experiment
,
first
time
,
statistical
transfer
model
,
acomparable
performance
,
state
of
the
translation
model
,
translation
procedure
,
target
language
generation
,
grammatical
translation
,
natural
language
generation
methods
,
author
,
development
,
anonymous
reviewer
,
thoroughreviewing
,
valuable
suggestion
,
referencespeter
f
brown
,
j
d
,
a
d
,
l
mercer
,
mathematics
ofstatistical
machine
translation
,
parameter
estimation
,
computational
linguistics
,
carbonell
,
probst
,
peterson
,
monson
,
alon
lavie
,
brown
,
automatic
rule
,
machine
translation
,
research
,
pi
chuan
chang
,
huihsin
tseng
,
jurafsky
,
d
m
,
discriminative
reorderingwith
grammatical
relation
feature
,
proceeding
,
third
workshop
,
syntax
,
structure
ins
tatistical
translation
,
association
,
computational
linguistics
,
chiang
,
hierarchical
phrase
based
model
,
statistical
machine
translation
,
proceedingsof
,
annual
meeting
,
association
,
computational
linguistics
,
association
forcomputational
linguistics
,
philipp
koehn
,
statistical
machine
translation
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
,
association
,
computational
linguistics
,
synchronous
dependency
insertion
grammar
,
grammar
formalism
forsyntax
,
workshop
,
advance
,
a
,
feature
translation
,
quasi
synchronous
lattice
parsing
,
proceedings
,
conference
,
empirical
method
,
natural
language
processing
,
volume
volume
,
association
,
computational
linguistics
,
gimpel
,
a
,
phrase
dependency
machine
translation
,
quasi
synchronous
tree
to
tree
feature
,
computational
linguistics
,
graehl
,
knight
,
tree
transducer
,
marcu
dumais
,
salimroukos
,
editor
,
main
proceeding
,
boston
,
association
,
computational
linguistics
,
liang
huang
,
knight
,
aravind
joshi
,
statistical
syntax
directed
translation
,
extended
domainof
locality
,
proceeding
,
philipp
koehn
,
och
,
marcu
,
statistical
phrase
based
translation
,
proceedingsof
,
conference
,
north
american
chapter
,
association
,
computational
linguistics
onh
uman
language
technology
volume
,
association
forcomputational
linguistics
,
benoit
lavoie
,
white
,
korelsky
,
domain
specific
transfer
rule
,
translation
,
proceeding
,
col
ing
workshop
,
association
,
computational
linguistics
,
dekang
,
path
based
transfer
model
,
machine
translation
,
proceeding
,
coling
,
pages625
,
qun
liu
,
shouxun
,
tree
to
string
alignment
template
,
statistical
machine
translation
,
proceeding
,
international
conference
,
computational
linguistics
,
association
,
computational
linguistics
,
association
,
computational
linguistics
,
marcu
,
wong
,
joint
probability
model
,
statistical
machine
translation
,
proceeding
,
conference
,
empirical
method
,
natural
language
processing
volume10
,
association
,
computational
linguistics
,
xie
,
linfeng
song
,
yajuan
,
qun
liu
,
translation
,
source
constituencyand
dependency
tree
,
proceeding
,
conference
,
empirical
method
,
natural
languageprocessing
,
seattle
,
association
,
computational
linguistics
,
qun
liu
,
based
translation
,
proceeding
,
pages192
,
columbus
,
association
,
computational
linguistics
,
och
,
ney
,
discriminative
training
,
maximum
entropy
model
,
statisticalmachine
translation
,
proceeding
,40
th
annual
meeting
,
association
,
association
,
computational
linguistics
,
och
,
ney
,
systematic
comparison
,
various
statistical
alignment
model
,
computational
linguistics
,
och
,
ney
,
alignment
template
approach
,
statistical
machine
translation
,
computational
linguistics
,
och
,
minimum
error
rate
training
,
statistical
machine
translation
,
proceeding
,
the41st
annual
meeting
,
association
,
computational
linguistics
volume
,
association
forcomputational
linguistics
,
quirk
,
arul
menezes
,
dependency
treelet
translation
,
informedphrasal
smt
,
proceeding
,
annual
meeting
,
association
,
arbor
,
association
,
computational
linguistics
,
richardson
,
dolan
,
arul
menezes
,
pinkham
,
commercial
qualitytranslation
,
based
method
,
proceeding
,
mt
summit
vii
,
santiago
ompostela
,
libin
shen
,
weischedel
,
new
string
to
dependency
machine
translation
,
target
dependency
language
model
,
proceeding
,
columbus
,
association
,
computational
linguistics
,
stolcke
,
srilm
an
extensible
language
,
toolkit
,
proceeding
,
ics
lp
,
xie
,
qun
liu
,
novel
dependency
to
string
model
,
statistical
machine
translation
,
proceeding
,
conference
,
empirical
method
,
association
,
computational
linguistics
,
deyi
xiong
,
qun
liu
,
shouxun
,
dependency
treelet
,
correspondence
model
,
statisticalmachine
translation
,
proceeding
,
second
workshop
,
statistical
machine
translation
,
association
,
computational
linguistics
,
kenji
yamada
,
knight
,
syntax
based
statistical
translation
model
,
proceeding
,39
thannual
meeting
,
association
,
computational
linguistics
,
association
,
computationallinguistics
,
col
ing
,
international
conference
,
computational
linguistics
,
technical
paper
,
dublin
,
a
reference
dependency
,
wenbin
jiang
,
qun
liu
,
shouxun
,
key
laboratory
,
intelligent
information
processinginstitute
,
computing
technology
,
academy
,
science
,
academy
,
science
yuhui
,
xiejun
,
jiangwenbin
,
school
,
computing
,
dublin
city
xiaofengwu
,
bstractmost
,
widely
used
automatic
evaluation
metric
,
local
fragment
,
thereferences
,
translation
,
evaluation
,
syntax
level
,
current
syntax
based
evaluation
metric
,
syntax
information
,
suffer
,
poor
parsing
result
,
noisy
machine
translation
,
problem
,
noveldependency
based
evaluation
,
dependency
information
,
reference
dependency
structure
,
headword
chain
,
thelong
distance
dependency
information
,
structure
,
local
continuous
ngram
,
experiment
result
,
correlation
,
humanjudgments
,
extralinguistic
resource
,
parameter
,
state
of
the
performancewhich
,
meteor
,
sem
pos
,
system
level
,
met
eoro
sentence
level
,
evaluation
,
important
role
,
evolution
,
mt
system
,
development
,
mt
system
rapider
,
employed
information
,
automatic
mt
evaluation
,
category
,
lexicon
based
metric
,
syntax
based
metric
,
semantic
basedmetrics
,
lexicon
based
metric
,
papineni
,
snover
,
agarwal
,
capturingthe
lexicon
,
phrase
,
reflectthe
syntax
similarity
,
current
effort
,
syntax
based
metric
,
headword
chain
,
gildea
,
lfg
dependency
tree
,
owczarzak
,
andsyntactic
semantic
role
overlap
,
parsing
,
potentiallynoisy
machine
translation
,
improvement
,
seriousparsing
error
,
semantic
based
metric
,
meant
,
problem
,
semantic
role
,
error
intranslations
,
parsing
,
noisy
translation
,
result
,
reference
,
gram
dependent
,
state
of
the
performance
,
novel
dependency
tree
,
mt
evaluation
,
reference
dependency
tree
,
translation
,
error
propagation
,
reference
dependency
,
headword
chain
,
long
distance
dependency
information
,
floatingstructure
,
local
continuous
ngram
,
matchingscore
,
headword
chain
,
translation
,
distance
based
similarity
,
experimentthis
,
a
creative
common
attribution
,
proceedingsfooter
,
organizer
,
license
detail
,
creativecommons
,
org
license
,
correlation
,
human
judgment
,
extra
resource
,
parameter
,
meteor
,
sem
pos
,
system
level
,
comparable
withmeteor
,
remainder
,
new
reference
,
mt
evaluation
,
extra
resource
,
parameter
,
experiment
result
,
conclusionsand
future
,
a
reference
dependency
,
mt
evaluation
metricthe
,
a
reference
dependency
,
automatic
evaluation
,
description
,
dependency
ngrams
,
ins
ection
,
method
,
dependency
ngram
,
methodof
,
final
score
,
dependency
ngramsto
capture
,
long
distance
dependency
information
,
local
continuous
ngrams
,
boththe
headword
chain
,
fixed
floating
structure
,
correspond
,
twokinds
,
dependency
ngram
,
headword
chain
,
fixed
floating
ngram
,
figure
,
dependency
tree
,
figure
,
different
kind
,
structure
,
dependency
tree
,
figure
,
headword
chain
,
fixed
structure
,
structure
,
sequence
,
dependency
tree
,
figure
,
word
headword
chain
,
dependency
treein
figure
,
headword
chain
,
long
distance
dependency
information
,
capturemost
,
continuous
ngrams
,
headword
chain
corresponds
,
headword
chain
ngramin
,
position
,
headword
chain
ngram
,
wnposn
,
length
,
headword
chain
ngram
,
theheadword
chain
,
figure
,
magnifier7
,
floating
structure
,
sub
root
withchildren
,
complete
constituent
,
fixed
dependency
,
figure
,
fixed
structure
,
structuresconsist
,
common
head
,
sibling
,
complete
constituent
,
figure
,
floating
structure
,
fixed
floating
structure
,
fixed
floating
ngrams
,
fixed
floating
ngrams
,
needthe
position
information
,
length
,
the2043figure
,
headword
chain
ngram
,
magnifier7
,
dis
r1and
dis
,
distance
,
corresponding
twowords
,
reference
,
dis
h1and
dis
,
distance
,
thehypothesis
,
fixed
floating
ngram
,
fixed
structure
,
figure
,
structre
,
figure2
,
dep
ngramsheadword
chain
ngrams
,
fixed
floating
ngrams
,
thescoring
method
,
dep
ngrams
,
methodsin
,
headword
chain
,
headword
chain
ngram
,
w1pos1
,
wnposn
,
stringof
,
translation
,
match
andthe
,
distance
based
similarity
,
relative
distance
,
decimal
value
,
distance
,
reference
,
distance
,
different
hypothesis
,
relative
distance
dis
,
word
,
dep
ngram
,
position
,
word
wi
,
length
,
dep
ngram
,
vector
,
vector
,
translation
side
,
translation
,
length
,
dep
ngram
equal
,
matching
scoreequals
,
translation
,
score
equal
,
calculation
,
figure
,
word
headword
chain
ngram
,
magnifier7
,
dependency
tree
,
reference
,
dep
3gram
,
underline
,
reference
dependency
tree
,
figure
,
underlined
word
,
translationwith
,
reference
,
dep
3gram
,
dep
3gram
,
translation
,
possaw
,
poswith
,
possaw
,
poswith
,
denotes
,
magnifier7
,
translation
,
method
,
matching
score
,
cosine
distance
,
theabsolute
distance
,
relative
distance
,
headword
chain
ngram
,
thanone
match
,
translation
,
matching
score
,
fixed
floating
ngramthe
word
,
fixed
floating
ngram
,
matched
string
,
translationalso
,
thesen
word
,
translation
,
reference
,
translation
,
dstands
,
fixed
floating
ngram
,
hyp
stand
,
translation
,
final
score
,
fscore
,
precision
,
reference
,
string
,
translation
,
precision
andrecall
,
precision
,
dep
ngrams
,
translation
,
dependency
tree
,
translation
,
method
,
dep
ngrams
,
approximate
linear
relationship
,
length
,
length
ofthe
translation
,
dep
ngrams
,
translation
dependency
tree
,
recall
canbe
,
dep
ngrams
,
reference
,
precision
andrecall
,
countn
,
dep
ngrams
,
length
,
length
,
translation
,
countn
,
dep
ngrams
,
length
,
reference
,
final
score
,
weighted
sum
,
dep
ngrams
,
fscore
,
weight
,
dep
ngram
,
length
,
fscorenis
,
fscore
,
length
,
wngram
,
fscoren
,
introducing
extra
resourcesmany
automatic
evaluation
metric
,
exact
match
,
reference
,
translation
,
information
,
limited
number
,
reference
,
evaluationmetrics
,
snover
,
extra
resource
,
thereference
information
,
extra
resource
,
synonym
andparaphrase
,
content
word
,
function
word
,
theeffects
,
matching
score
,
parameter
,
method
,
resource
,
asfollows
,
synonymstem
,
synonym
,
wordnet1
,
alignment
,
meteor
aligner
,
denkowski
,
onlyexact
match
,
synonym
,
withexact
match
,
match
module
,
second
,
alignment
,
dep
ngram
,
translation
,
following
condition
,
dep
ngram
,
translation
,
alignment
,
dep
ngram
,
matched
word
,
translation
,
translation
,
dep
ngram
,
fixed
floating
ngram
,
match
module
score
,
dep
ngram
,
different
matchmodules
,
different
effect
,
different
weight
,
match
module
,
synonym
,
ith
word
,
matchmodule
weight
,
ith
word
,
paraphrase
,
dependency
tree
,
reference
,
becauseparaphrases
,
headword
chain
,
fixed
floating
structure
,
thealignment
,
meteor
igner
,
paraphrase
,
second
,
matchedparaphrases
,
alignment
,
paraphrase
ngram
,
aparaphrase
,
weight
,
function
word
,
content
word
,
weight
,
function
word
,
function
word
score
,
sfun
cfun
,
wfun
ccon
,
function
word
,
numberof
content
word
,
wordnet
,
princeton
,
extra
resource
,
final
score
,
fscorepis
,
wngram
,
fscorepn
,
fscorep
precisionp
,
scoreparn
scoredepnlenh
,
scoreparn
scoredepncountn
,
countn
,
length
,
translation
,
countn
,
dep
ngrams
,
length
,
reference
,
countn
,
paraphrase
,
length
,
reference
,
match
score
,
paraphrase
ngrams
,
length
,
match
score
,
length
,
scoreparnand
scoredepnare
,
paraphrase
ngrams
,
length
,
dep
ngrams
,
length
,
several
parameter
,
different
parameter
value
,
performance
ofr
edp
,
weight
,
dep
ngram
,
length
,
theeffect
,
ngrams
,
different
length
,
weight
,
parameter
,
preliminary
optimization
method
,
parameter
,
heuristic
search
,
parameter
,
subset
,
parameter
optimization
,
grid
search
,
thetwo
subset
,
parameter
,
subset
,
parameter
,
subset
,
subset
,
iteration
,
several
iteration
,
theparameter
,
process
,
heuristic
search
,
global
optimum
,
exhaustive
search
,
optimization
goal
,
system
level
,
following
equation
,
difference
,
human
rank
,
concordant
pair
,
discordant
pairsnumber
,
concordant
pair
number
,
discordant
pairsthe
data
,
into
task
,
parameter
,
tuned
parameter
,
language
pair
,
translation
system
,
language
pair
,
foreach
language
pair
,
parameter
value
,
weight
offunction
word
,
wexact
,
weight
,
match
module
,
exact
stem
synonym
,
weight
,
paraphrase
ngram
,
w1gram
,
weight
ofdep
ngram
,
length
,
wm
t2013
,
translation
system
,
language
pair
,
reference
,
constituent
tree
,
parser2and
,
constituenttree
,
dependency
tree
,
penn2malt3
,
dependency
tree
,
reference
dependency
tree
,
widely
used
lexicon
based
metrics
,
dependency
based
metric
hwc
,
semantic
based
metricsempos
,
system
level
,
thepublished
result
,
result
,
option
,
version
,
result
,
meteor
,
version
,
task
option
,
epsilon
value
,
purpose
,
correlation
,
empos
,
result
,
system
level
,
system
level
,
correlationsare
,
spearman
,
method
performsbest
,
maximum
length
,
dep
ngram
,
result
,
maximumlength
,
exact
match
,
parameter
value
,
w1gram
w2gram
,
extra
resourcesand
,
parameter
value
,
hwc
onaverage
,
syntactic
information
,
reference
side
,
result
,
language
,
exceptcz
en
,
significant
improvement
,
effect
,
extraresources
,
parameter
,
synonym
,
paraphrase
,
reference
,
provideextra
knowledge
,
automatic
evaluation
,
several
parameter
,
differentparameter
value
,
optimizedthrough
parameter
,
correlation
,
result
,
google
,
berkeleyparser
downloads
list3http
,
nivre
research
penn2malt
,
html4ftp
,
jaguar
,
gov
mt
resource
,
pl5http
,
snover
tercom6http
,
tgz20482012
,
meteor
,
correlation
,
result
,
into
task
,
result
,
meteor
,
state
of
the
performance
,
system
level
,
data
wmt
,
cz
en
de
en
es
en
fr
en
cz
en
de
en
es
en
fr
en
ru
en
avebleu
,
system
level
correlation
,
result
ineach
column
,
average
result
,
language
,
thanbleu
,
language
pair
,
effectiveness
,
syntactic
informationand
,
reference
,
extra
resource
,
parameter
,
synonym
,
paraphrase
,
reference
,
provideextra
knowledge
,
automatic
evaluation
,
several
parameter
,
differentparameter
value
,
exploitedthrough
parameter
,
result
,
thecomparable
result
,
meteor
,
data
wmt
,
cz
en
de
en
es
en
fr
en
cz
en
de
en
es
en
fr
en
ru
en
avebleu
,
resultin
,
column
,
average
result
,
language
,
future
workin
,
reference
dependency
,
automatic
mt
evaluation
metric
,
thenew
,
dependency
tree
,
reference
,
parsing
,
potentiallynoisy
translation
,
long
distance
dependency
information
,
local
continuous
ngrams
,
experiment
result
,
achieves
,
correlation
,
system
level
,
improved
version
,
extra
resource
,
preliminary
parameter
tuning
,
state
of
the
result
,
meteor
,
sem
pos
,
system
level
,
comparableperformance
,
future
,
dependency
,
dependency
tree
,
effectof
,
process
,
thetranslation
quality
,
author
,
national
natural
science
foundation
,
contract
,
national
natural
science
foundation
,
contract
,
science
foundation
,
ce
i1142
,
dublincity
,
sincere
thanks
,
anonymous
reviewer
,
thorough
reviewing
andvaluable
suggestion
,
kuhn
,
modified
bleu
,
proceeding
ofthe
sixth
workshop
,
statistical
machine
translation
,
edinburgh
,
association
forcomputational
linguistics
,
boxing
,
kuhn
,
mt
evaluation
,
proceedingsof
,
seventh
workshop
,
computational
linguistics
,
denkowski
,
alon
lavie
,
meteor
,
reliable
optimization
,
evaluationof
machine
translation
system
,
proceeding
,
sixth
workshop
,
statistical
machine
translation
,
computational
linguistics
,
linguistic
feature
,
automatic
evaluation
,
heterogenous
mt
system
,
proceeding
,
second
workshop
,
statistical
machine
translation
,
association
forcomputational
linguistics
,
g
k
endall
,
new
measure
,
rank
correlation
,
biometrika
,
abhaya
agarwal
,
meteor
,
mt
evaluation
,
high
level
ofcorrelation
,
human
judgment
,
proceeding
,
second
workshop
,
statistical
machine
translation
,
association
,
computational
linguistics
,
gildea
,
syntactic
feature
,
evaluation
,
machine
translation
,
proceeding
,
theacl
workshop
,
intrinsic
,
extrinsic
evaluation
measure
,
machine
translation
,
summarization
,
chi
kiu
lo
,
inexpensive
semantic
,
mt
evaluation
,
proceeding
,
eighth
workshop
,
statistical
machine
translation
,
pages422
,
association
,
computational
linguistics
,
fully
automatic
semantic
mt
evaluation
,
proceedings
,
seventh
workshop
,
statistical
machine
translation
,
association
,
computational
linguistics
,
rej
bojar
,
mt
evaluation
,
tuning
,
proceeding
,
sixth
workshop
,
statistical
machine
translation
,
association
forcomputational
linguistics
,
mehay
,
brew
,
mt
evaluation
,
inp
roceedings
,
conference
,
theoretical
,
methodological
issue
,
minimum
error
rate
training
,
statistical
machine
translation
,
proceeding
,
annualmeeting
,
association
,
computational
linguistics
volume
,
association
,
computational
linguistics
,
owczarzak
,
genabith
,
dependency
based
automatic
evaluation
formachine
translation
,
proceeding
,
naa
cl
hlt
,
syntax
,
structure
,
association
,
computational
linguistics
,
method
,
automatic
evaluation
,
machinetranslation
,
proceeding
,40
th
annual
meeting
,
association
,
computational
linguistics
,
pages311
,
association
,
spearman
,
correlation
coefficient
,
encyclopedia
,
statistical
science
,
f
,
snowball
,
language
,
algorithm
,
libin
shen
,
weischedel
,
string
to
dependency
statistical
machine
translation
,
computational
linguistics
,
snover
,
dorr
,
schwartz
,
micciulla
,
makhoul
,
translation
edit
rate
,
human
annotation
,
proceeding
,
association
,
machine
translation
,
theamericas
,
snover
,
madnani
,
j
d
orr
,
schwartz
,
fluency
,
adequacy
,
different
human
judgment
,
tunable
mt
,
proceeding
,
fourth
workshop
ons
tatistical
machine
translation
,
association
,
computational
linguistics
,
conference
,
empirical
method
,
natural
language
processing
,
edinburgh
,
association
,
computational
linguisticsrelaxed
cross
lingual
projection
,
constituent
syntaxwenbin
jiang
,
qun
liu
,
intelligent
information
processinginstitute
,
technologychinese
academy
,
science
jiangwenbin
,
liuqun
,
relaxed
correspondence
assumption
,
cross
lingual
projection
,
constituent
syntax
,
supposedconstituent
,
correspond
,
unrestricted
treelet
,
sourceparse
,
relaxed
assumption
,
syntactic
non
isomorphismbetween
language
,
target
language
specific
syntactic
idiosyncrasy
,
strained
grammar
,
source
language
syntax
,
assumption
,
novel
constituency
projection
method
,
proposedin
order
,
projected
constituent
tree
bank
,
source
parsed
bilingual
corpus
,
parser
,
projected
treebank
,
unsupervisedparsers
,
ntroductionfor
language
,
treebanks
,
state
of
the
performance
,
pereira
,
constituent
parsing
,
charniakand
johnson
,
petrov
,
therestriction
,
treebank
scale
,
unsupervised
method
,
kleinand
manning
,
seginer
,
hen
,
semi
supervised
methods
,
sarkar
,
steedman
,
unannotated
text
,
year
,
researcher
,
many
investigation
,
syntax
projection
,
ganchev
,
andeisner
,
knowledge
,
language
,
different
,
bilingual
parsing
,
burkett
,
bilingual
constraints
,
bilingual
grammar
induction
,
blunsom
,
snyder
etal
,
grammar
,
parallel
text
,
syntax
projection
aim
,
syntactic
knowledge
,
language
,
thisseems
,
language
,
bilingual
corpus
parallel
,
resource
languages
,
large
treebanks
,
previous
,
dependency
projection
,
dependencyrelationship
,
parsed
source
sentences
,
wordalignment
,
direct
correspondence
assumption
,
syntactic
non
isomorphism
,
language
,
incomplete
projection
,
researcher
,
strategy
,
thisproblem
,
languagenon
isomorphism
,
quasi
synchronous
grammar
,
eis
ner
,
constituency
projection
,
lack
ofisomorphism
,
aconstituent
grammar
,
language
,
moredetailed
,
relaxedcorrespondence
assumption
,
constituency1192througha
series
,
constituency
projection
,
rca
assumption
,
projection
,
englishto
,
dash
line
,
projected
constituent
,
treelet
,
graybackground
,
directly
projected
constituent
,
counterpart
,
source
parse
,
projection
,
unrestrictedtreelet
,
source
parse
,
relaxed
assumption
,
syntactic
non
isomorphism
,
language
,
target
language
specific
syntactic
idiosyncrasy
,
strained
grammar
,
source
language
syntax
,
novel
cross
lingual
projection
method
forconstituent
syntax
,
rca
assumption
,
word
aligned
source
parsed
bilingual
corpus
,
a
p
cfg
grammar
,
targetlanguage
,
maximum
likelihood
estimation
,
theexhaustive
enumeration
,
candidate
,
productions
,
nonterminal
,
productionis
,
unrestricted
treelet
,
sourceparse
,
projected
pcf
grammar
,
guidance
ofthe
,
source
tree
,
constituent
tree
,
effectiveness
,
therca
assumption
,
constituency
projectionmethod
,
constituenttreebank
,
fbi
s
ch
inese
parallelcorpus
,
char
niak
parser
,
parser
,
projected
treebank
,
unsupervised
parser
,
promising
substitute
,
unsupervised
parsing
method
,
resource
scarce
language
,
bilingual
corpus
parallel
,
resource
languages
,
human
annotated
treebanks
,
rca
assumption
,
algorithm
,
treelet
,
source
parse
,
candidate
constituent
,
induction
,
pcf
grammar
,
projected
constituent
treebank
,
theword
aligned
source
parsed
parallel
corpus
,
aftergiving
experimental
result
,
comparison
,
projected
parser
,
several
aspects
,
correspondence
assumptionthe
dca
assumption
,
wellin
dependency
projection
,
dependency
,
compact
manner
,
thesyntactic
information
,
dependencyrelationships
,
relationship
of1193algorithm
t
reelet
extraction
algorithm
,
parse
tree
,
output
,
treelet
set
,
subtree
,
function
,
netree
,
nonempty
subtree
do22
,
nonempty
subtree
,
return
ta
word
pair
,
forthe
corresponding
word
pair
,
dependency
grammar
,
constituentgrammar
depicts
,
complex
,
branched
structure
,
syntactic
isomorphism
,
constituency
projection
,
thecomplex
constituent
structure
,
language
toanother
,
constituency
projection
,
relaxedcorresponding
assumption
,
theinfluence
,
syntactic
non
isomorphism
,
thesourceand
target
,
assumption
,
supposed
constituent
,
target
sentence
tocorrespond
,
unrestricted
treelet
,
sourceparse
,
treelet
,
connected
subgraph
,
thesource
constituent
tree
,
discontigu
ous
sequence
,
thisproperty
,
supposed
constituent
,
constituent
,
source
parse
,
fundamentally
tolerate
,
syntactic
non
isomorphism
between
language
,
figure
,
treelet
pruning
,
asterisksindicate
,
subtrees
,
asempty
child
,
parent
node
,
laxed
correspondence
,
treelet
extractionaccording
,
word
alignment
,
treelet
,
ofthe
source
parse
,
possible
constituent
span
,
treeletextraction
algorithm
,
parse
tree
tf
,
word
alignment
abetween
,
algorithm
,
corresponding
treelet
,
corresponding
treelet
,
recursive
top
down
traversal
,
current
subtree
align
,
recursion
stop
,
return
,
emptytree
,
subtree
,
fromthe
final
treelet
,
talign
,
concise
representation
,
whole
subtree
,
third
situation
,
aligns
,
recursion
,
subtrees
,
treelet
,
recursive
extraction
procedure
,
source
tree
,
expatiatory
treeletwith
,
functionprunetree
,
charge
,
treelet
pruning
,
treelet
,
successiveempty
,
asterisk
,
top
down
pruning
,
redundant
branch
,
branchwith
,
nonempty
subtrees
,
figure
,
effect
,
pruning
operation
map
,
original
treelet
,
simplified
version
,
pruned
treelet
,
branch
,
original
treelet
serve
,
context
,
thepruned
treelet
,
bracketed
representation
,
thepruned
treelet
,
treelet
graph
,
nonterminals
,
projected
targetparses
,
overall
complexity
,
algorithm
iso
,
treeletsfor
,
fact
itruns
,
realistic
corpus
,
function
ext
treelet
doesn
,
talways
,
lessisomorphism
,
language
,
grammar
,
treebankthis
,
projected
constituent
treebank
,
rca
assumption
,
according
,
last
,
targetsentence
,
treelet
,
sourceparse
,
corresponding
treelet
,
candidate
,
constituent
,
n
partition
,
candidate
constituent
,
candidate
projected
production
,
many
candidate
,
constituentsbecause
,
arbitrary
combination
,
tree
projection
procedure
,
optimum
tree
fromthe
parse
,
candidate
constituents
,
production
,
optimum
treeshould
,
principle
,
thisproduction
,
whole
corpus
,
frequentlyas
,
diversity
,
wordalignment
error
,
real
constituent
tree
,
targetsentence
,
candidate
projected
constituent
,
fault
tolerant
tree
projection
strategy
,
problem
,
distribution
,
candidateprojected
constituent
,
distribution
,
whole
corpus
forthe
rule
,
constituent
,
pcf
grammar
,
a
p
cfgp
arser
,
grammar
,
guidance
,
candidate
projectedconstituent
set
,
optimum
projected
tree
,
estimation
ofthe
,
pcf
grammar
,
treeprojection
procedure
,
pcf
g
gr
,
human
annotated
treebank
,
apc
fg
grammar
,
frequency
,
theproduction
rule
,
productions
,
target
sentence
wedon
,
production
,
thecorrect
constituent
tree
,
frequency
,
production
rule
,
candidate
projected
production
,
correct
parse
,
inthis
production
,
wholecorpus
,
candidate
projectedproduction
,
correct
parse
,
different
probability
,
candidate
,
production
,
appropriate
probability
,
probability
,
appearance
frequency
,
production
,
correct
parse
,
approximation
,
pcf
grammar
hidden
,
production
,
computational
complexity
,
result
,
bina
rized
pcf
grammar
,
previous
unsupervised
,
frequency
,
candidate
pro
1195ductions
,
correct
parse
,
frequency
,
candidate
span
,
binary
tree
,
inside
outside
algorithm
,
confusion
,
count
ofbinary
tree
,
binary
tree
,
binary
tree
fragment
,
calculation
,
inside
outside
algorithm
,
simplicity
,
condition
,
formulas
,
equation
,
condition
,
probability
,
probability
,
theparse
,
candidate
,
span
aligns
,
probability
,
frequencyof
,
candidate
,
production
,
assumption
,
uniform
distribution
,
theprojected
tree
,
insideand
,
algorithm
,
counting
for
mulae
,
assumption
,
single
iterationof
,
pcf
grammar
,
maximum
likelihood
estimation
,
word
alignment
error
,
free
translation
,
andexhaustive
enumeration
,
productions
,
a
p
cfg
grammar
,
toomuch
noisy
nonterminals
,
production
rule
,
threshold
bru
le
,
grammar
,
aproduction
rule
,
frequencyis
,
relaxed
tree
projectionthe
,
pcf
grammar
,
procedure
,
constituency
projection
,
grammar
,
global
syntactic
knowledge
,
negative
effect
,
word
alignment
error
,
free
translation
,
constituency
projection
,
single
sentence
pair
,
projectedconstituency
tree
,
knowledge
,
local
knowledge
inthe
candidate
,
production
set
,
targetsentence
,
global
knowledge
,
projectedpcfg
grammar
,
integrated
projection
strategy
,
target
,
projected
pcf
grammar
,
thecandidate
,
production
,
thepcfg
parsing
,
parsing
procedure
,
boththe
pcf
tree
probability
,
productions
,
candidate
,
nt
reserved
,
rulesfigure
,
nonterminal
set
,
frequency
summation
proportion
,
whole
rule
,
duction
set
,
optimization
objective
,
argmaxy
,
production
,
boolean
function
,
weight
coefficient
,
quality
,
constituency
,
fbi
s
ch
inese
englishparallel
corpus
,
projected
constituent
treebank
,
thousand
sentencepairs
,
englishwords
,
thecharniak
parser
,
charniak
,
johnson
,
a
p
o
,
treebank
,
perform
word
alignment
,
thealignment
result
,
constituency
projection
,
previous
,
unsupervisedconstituent
parsing
,
parseron
,
subset
,
removalof
punctuation
,
gold
standard
pos
tag
,
evaluation
,
unsupervised
parsing
differs
,
ntsfigure
,
performance
curve
,
pcf
ggrammars
,
different
size
,
nonterminal
set
,
seval
metric
,
multiplicity
ofbrackets
,
bracket
,
bracket
,
unlabeled
f1value
,
harmonic
mean
,
unlabeledprecision
,
recall
,
pcf
g
gr
,
pcf
grammar
,
source
parsed
parallelcorpus
,
initialgrammar
,
large
amount
,
nonterminals
,
production
rule
,
wheremany
,
free
translation
,
wordalignment
error
,
filtration
threshold
bru
le
,
rule
withfrequency
,
rule
count
,
million
,
thousand
,
figure
,
statistic
,
remained
production
rule
,
projected
nonterminalsaccording
,
frequency
,
nonterminal
set
,
frequency
summation
,
nonterminals
account
,
thefrequency
summation
,
whole
rule
,
developing
set
,
series
,
grammar
,
figure
,
unlabeled
f1value
,
grammar
,
developingset
,
filtered
grammar
,
nonterminals
,
grammar
,
performance
curve
,
thousand
,
weight
coefficient
,
following
tree
projection
procedure
,
treebank
,
parserthe
,
grammar
g32
,
global
syntactic
knowledge
,
constituency
projection
,
suchglobal
knowledge
,
local
knowledge
,
candidate
,
production
,
linear
weighted
manner
,
formula7
,
weight
coefficient
,
quality
,
projected
treebank
,
parser
,
fromthe
fbi
corpus
,
series
,
treebanks
,
parser
oneach
,
treebank
,
developing
set
,
figure
,
performancecurve
,
unlabeled
f1
value
,
theprojected
parser
,
developingset
,
slight
fluctuationin
,
projected
pcf
grammar
,
candidate
projectedproduction
,
different
kind
ofconstraints
,
themby
,
weight
coefficient
,
range
result
,
slight
performance
fluctuation
,
parser
,
constituency
projection
,
whole
fbi
scorpus
,
thousand
,
treebank5000
,
performance
curve
,
different
amount
,
project
tree
,
thescale
,
treebank
,
to160000
,
fbi
corpus
,
heavy
burden
,
parser
,
large
atreebank
,
free
translationand
word
alignment
error
,
many
projectedtrees
,
poor
quality
,
criterion
,
quality
,
amount
,
treebank
,
parser
,
figure
,
different
amount
,
theperformance
,
parser
,
increment
,
treebanks
,
parser
,
f1
increment
,
theone
,
thousand
tree
,
parser
moreinformation
,
projection
quality
,
parallel
corpus
,
parser
,
thousand
,
final
test
,
experimental
result
,
comparisonwith
related
,
sparse
table
,
theexperiments
,
previous
researcher
,
different
data
set
,
parser
significantly1198system
ctb
test
ctb
all
ctb
all
ctb
,
manning
,
seginer
,
parser
,
thousand
,
previousworks
,
constituency
projection
,
ctb
standardtest
set
,
chapter
,
theremoval
,
punctuation
,
b5
all
,
removal
,
punctuation
,
parser
,
dca
assumption
,
dependency
projection
,
constituency
projection
,
resort
,
word
alignment
,
complicated
tree
projection
algorithm
,
rca
assumption
ismore
,
constituency
projection
,
thedca
assumption
,
language
specific
syntactic
idiosyncrasy
,
target
language
,
parser
,
existing
unsupervised
parser
,
parser
,
seginer
,
figure
,
unlabeled
f1
,
parser
,
series
,
subset
,
different
sentence
length
upper
limit
,
thewhole
treebank
,
parser
,
promisingresult
,
unsupervised
parsing
,
constituency
projection
,
syntacticinformation
,
language
,
grammar
,
comparing
,
syntax
projection
technique
,
orsemi
supervised
technique
,
resource
poor
language
,
bilingualcorpus
parallel
,
resource
language
,
ahuman
annotated
treebank
,
constituency
projection
,
rca
assumption
,
promising
substitute
,
future
worksthis
paper
,
constituency
projection
,
under
,
assumption
,
constituent
,
parser
,
subsetsof
ctb
,
different
sentence
length
upper
limit
,
whole
treebank
,
treelet
,
direct
correspondence
assumption
,
dependency
projection
,
rca
assumption
,
constituency
projection
,
syntacticnon
isomorphism
,
source
,
languages
,
rca
assumption
,
novel
constituency
projection
method
,
pcf
grammar
,
word
aligned
source
parsed
parallel
corpus
,
treeprojection
,
apc
fg
,
procedure
,
theglobal
knowledge
,
projected
pcf
,
local
knowledge
,
candidate
projected
production
,
parser
,
treebank
,
theprojected
parser
,
dca
assumption
,
effectiveness
,
rca
assumption
,
constituency
projection
method
,
rca
assumption
,
constituency
projection
,
dca
assumption
,
parser
,
unsupervised
parser
,
suggeststhat
,
resource
poor
language
,
bilingualcorpus
parallel
,
resource
language
,
ahuman
annotated
treebank
,
constituency
projection
,
rca
assumption
,
promising
substitute
,
unsupervised
method
,
result
,
currentwork
,
many
aspect
,
word
alignment
,
fundamentalprecondition
,
grammar
induction
,
constituency
projection
,
word
alignment
strategy
,
theword
alignment
quality
,
second
,
context
free
assumption
,
complicated
grammar
,
powerful
global
syntactic
constraint
,
tree
projection
procedure
,
current
tree
projectionalgorithm
,
bilingual
constraintscould
lead
,
constituency
projection
,
unsupervised
parsing
make
use
,
different
kind
,
knowledge
,
unsupervised
method
,
constituency
projection
frameworkto
,
grammar
,
treebanks
,
andparsers
,
acknowledgmentsthe
author
,
national
naturalscience
foundation
,
contract
,
theanonymous
reviewer
,
thorough
reviewingand
valuable
suggestion
,
referencesphil
blunsom
,
cohn
,
mile
,
bayesian
synchronous
grammar
induction
,
proceedings
,
all
subtrees
approach
,
unsupervised
parsing
,
proceeding
,
klein
,
language
,
proceedingsof
,
emn
lp
,
charniak
,
johnson
,
coarse
to
fine
grained
n
best
parsing
,
discriminative
rerank
ing
,
proceeding
,
wenliang
,
ichi
kazama
,
kentaro
sawa
,
bitext
dependency
,
bilingualsubtree
constraint
,
proceeding
,
logistic
normal
distribution
,
soft
parameter
,
inunsupervised
grammar
induction
,
proceeding
,
cl
hlt
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceeding
ofthe
emn
lp
,
head
driven
statistical
modelsfor
natural
language
parsing
,
computational
linguistics
,
kuzman
ganchev
,
gillenwater
,
taskar
,
dependency
grammar
induction
,
bitext
projection
constraint
,
proceeding
,47
th
acl
,
liang
huang
,
wenbin
jiang
,
qun
liu
,
shift
reduceparsing
,
proceeding
,
emn
lp
,
hwa
,
resnik
,
weinberg
,
claracabezas
,
okan
kolak
,
bootstrappingparsers
,
syntactic
projection
,
parallel
text
,
natural
language
engineering
,
wenbin
jiang
,
yang
liu
,
qun
liu
,
effective
constituent
projection
,
language
,
inp
roceedings
,
takahashi
,
treeadjunct
grammar
,
journal
computer
system
science
,
klein
,
manning
,
cor
pusbased
induction
,
syntactic
structure
,
model
ofdependency
,
constituency
,
proceeding
,
theacl
,
efficient
third
order
dependency
parser
,
proceeding
,
carreras
,
simple
semi
supervised
dependency
,
proceedings
,
kuhn
,
parallel
text
basedgrammar
induction
,
proceeding
,
parser
,
dependency
parsing
,
approximatevariational
inference
,
proceeding
,
emn
lp
,
mcc
losky
,
charniak
,
johnson
,
self
training
,
adaptation
,
proceeding
,
mcd
onald
,
pereira
,
on
line
learning
,
approximate
dependency
,
proceeding
,
nilsson
,
gulsen
eryigit
,
svetoslav
marinov
,
pseudoprojec
tive
dependency
,
support
vector
machine
,
proceeding
,
ll
,
ney
,
statistical
alignment
model
,
proceeding
,
slav
petrov
,
thibaux
,
danklein
,
interpretable
tree
annotation
,
proceeding
,
anoop
sarkar
,
training
method
tostatistical
parsing
,
proceeding
,
naa
cl
,
yoav
seginer
,
fast
unsupervised
incremental
parsing
,
proceeding
,
eisner
,
parser
adaptationand
projection
,
quasi
synchronous
grammar
features
,
proceeding
,
emn
lp
,
factored
estimation
,
using
toparse
korean
,
proceeding
,
emn
lp
,
snyder
,
tahira
naseem
,
barzilay
,
multilingual
grammar
induction
,
proceeding
,
steedman
,
mile
,
anoop
sarkar
,
stephenclark
,
hwa
,
hockenmaier
,
ruhlen
,
baker
,
crim
,
bootstrapping
statistical
parser
,
small
datasets
,
proceedings
,
stochastic
inversion
transductiongrammars
,
bilingual
parsing
,
parallel
corpus
,
computational
linguistics
,
nianwen
xue
,
fei
xia
,
fu
dong
chiou
,
marthapalmer
,
treebank
,
phrasestructure
annotation
,
large
corpus
,
natural
language
engineering
,
hai
zhao
,
yan
song
,
chunyu
,
guodong
zhou
,
cross
language
dependency
,
abilingual
lexicon
,
proceeding
,
joint
conference
,
empirical
method
,
natural
language
processing
,
computational
naturallanguage
learning
,
jeju
island
,
association
,
computational
linguisticsiterative
annotation
transformation
,
predict
self
reestimationfor
word
segmentationwenbin
jiang
,
fandong
meng
,
qun
liu
,
intelligent
information
processinginstitute
,
technologychinese
academy
,
science
jiangwenbin
,
liuqun
,
technology
,
automatic
annotation
transformation
,
annotation
adaptationalgorithm
,
human
annotated
corpus
,
annotation
guideline
,
optimization
strategy
,
iterative
training
,
predict
self
reestimation
,
annotation
guideline
transformation
,
hinese
word
segmentation
show
,
iterative
training
strategy
,
predict
self
reestimation
,
significant
improvement
,
simple
annotation
transformation
baseline
,
classifier
,
several
timesfaster
processing
,
annotation
adaptationdoes
,
treebank
,
f
measure
,
previous
,
single
classifier
,
generalpipeline
,
knowledge
,
corpus
withdifferent
,
annotation
guideline
,
jiang
etal
,
annotation
adaptation
,
classifiersare
,
classification
results
,
classifier
,
features
,
upper
classifier
,
moreaccurate
classification
,
method
,
divergence
,
different
annotation
guideline
,
improvement
,
chi
nese
word
segmentation
,
cascaded
classification
decision
,
practicalfor
task
,
high
computational
complexity
asparsing
,
thantwo
,
corpus
,
algorithm
ofautomatic
annotation
transformation
,
onthe
annotation
adaptation
algorithm
,
automatic
transformation
,
adaptation
,
human
annotated
corpus
,
annotation
guideline
,
classifier
,
corpus
,
annotation
guideline
,
corpus
,
annotation
guideline
,
corpuswith
parallel
annotation
guideline
,
secondclassifier
,
corpus
,
statistical
regularity
,
annotationtransformation
,
previouscorpus
,
annotation
guideline
,
target
corpus
,
online
knowledge
integration
methodology
,
annotation
adaptation
,
annotation
transformation
,
offline
manner
,
usingthe
,
additional
training
,
classifier
,
method
,
enhancedclassifier
,
processing
,
cascaded
classifier
,
annotation
adaptation
,
optimization
strategy
,
iterative
training
,
predict
self
reestimation
,
annotation
transformation
,
transformation
,
corpus
,
parallel
annotation
,
iterativetraining
procedure
,
trans
412formation
accuracy
,
annotated
corpus
,
source
to
target
andtarget
to
source
annotation
transformation
,
training
iteration
,
transformed
corpus
,
annotations
,
annotated
corpus
,
nextiteration
,
corporawill
result
,
accurate
transformation
classifiers
,
new
iteration
,
predict
self
reestimationis
,
following
hypothesis
,
transformation
result
,
original
form
,
predict
self
heuristicis
,
unsupervised
dependency
,
word
segmentation
,
iterative
training
strategy
,
withpredict
self
reestimation
,
significant
improvement
,
simple
annotation
transformationbaseline
,
optimized
annotation
transformation
,
treebank
,
xue
etal
,
word
segmenterwith
ctb
annotation
guideline
,
annotation
adaptation
,
optimized
annotation
transformation
strategy
,
classifier
,
significantlyhigher
accuracy
,
several
time
,
data
set
,
f
measure
,
previous
,
single
classifier
,
local
feature
,
classification
based
chineseword
segmentation
method
,
detail
thesimple
annotation
transformation
algorithm
,
thetwo
optimization
method
,
experimentalresults
,
word
segmentation
,
asthe
problem
,
sequence
labeling
,
character
,
givena
boundary
tag
,
position
,
following
ng
,
joint
word
segmentation
,
tagging
,
lgorithm
p
erceptron
training
algorithm
,
training
,
output
,
parameter
,
character
classification
approach
,
boundary
tag
,
pos
information
,
word
segmentation
,
boundary
tag
,
whereb
,
beginning
,
middle
,
theend
,
single
characterword
,
word
segmentation
result
,
labeled
character
sequenceinto
subsequence
,
pattern
,
indicatingsingle
character
word
,
multi
character
word
,
perceptron
algorithm
,
character
classifier
,
algorithm
,
inmany
nlp
task
,
pos
tagging
,
wordsegmentation
,
al2008
,
training
procedure
,
discriminativemodel
mapping
,
training
corpus
,
labeledresults
,
function
,
candidate
result
,
function
,
charactersequence
,
decoder
,
parameter
vector
,
innerproduct
,
algorithm
,
perceptron
algorithm
,
parameter
,
parameter
,
c2b
igram
,
classification
based
chi
nese
segmentation
model
,
technology
,
classifieris
,
current
character
,
ith
character
,
punctuation
character
,
others
,
character
,
others
,
predict
self
annotationtransformationthis
,
technology
,
automatic
annotation
transformation
,
optimization
strategy
,
iterative
training
andpredict
self
reestimation
,
iterative
training
takesa
global
view
,
several
round
,
bidirectional
annotation
transformation
,
improvethe
transformation
performance
round
,
predict
self
reestimation
,
local
view
,
thetransformation
performance
,
accountthe
predication
result
,
reverse
transformation
,
strategy
,
transformation
performance
,
knowledgefrom
,
corpus
,
annotation
guideline
,
classifier
,
source
classifier
,
corpus
,
source
corpus
,
annotation
standard
,
source
annotation
,
corpus
,
targetcorpus
,
annotation
standard
,
annotation
,
second
classifier
,
transformation
classifier
,
target
corpus
with1it
,
target
classifier
,
transformation
classifier
,
annotation
transformation
,
source
annotation
,
source
classifier
,
classification
result
,
guiding
feature
,
decoding
,
source
classifier
,
intothe
transformation
classifier
,
annotations
,
source
classifier
,
improved
classification
result
,
annotation
adaptation
,
drawback
,
classifier
,
knowledge
,
corpus
,
processing
speed
,
variant
,
annotation
adaptation
,
name
annotationtransformation
,
automatic
transformation
,
adaptation
,
annotation
standards
,
human
annotated
corpus
,
annotationtransformation
,
source
classifier
,
transformation
classifier
,
annotation
adaptation
,
transformation
classifier
,
source
corpus
,
classification
label
,
guiding
feature
,
sourcecorpus
,
target
annotation
guideline
,
target
corpus
,
transformed
sourcecorpus
,
training
,
character
classifier
,
improved
classification
accuracy
,
source
classifier
,
transformation
classifier
,
perceptron
algorithm
,
sourceclassifier
,
baselinerenaming
,
name
confusion
,
optimized
annotation
transformation
,
baseline
annotation
transformation
,
return
,
function
,
thetransformation
classifier
,
inannotation
adaptation
,
overall
training
algorithmfor
annotation
transformation
,
source
corpus
,
target
corpus
,
source
classifier
,
transformation
classifier
,
corpus
,
annotation
guideline
,
ctsis
,
source
corpus
,
annotation
guideline
,
function
tra
,
tra
nstrainb
,
perceptron
algorithm
,
withdifferent
feature
set
,
function
otate
andtransannotate
call
,
decode
withdifferent
model
,
source
transformation
classifier
,
feature
function
,
training
iteration
,
functionstrain
,
tra
nstrain
,
developing
set
,
source
corpus
,
targetcorpus
,
algorithm
,
parameters
,
omittedfor
simplicity
,
online
knowledgeintegration
methodology
,
annotation
adaptation
,
annotation
transformation
,
offline
manner
,
training
procedure
,
manner
,
several
time
,
cascaded
classifier
,
annotation
adaptation
,
following
,
optimization
strategies
,
detail
,
annotationtransformationthe
training
,
annotation
transformation
,
annotated
corpus
,
source
annotation
,
function
,
repeat7
,
converges14
,
return
,
function
,
source
classifier
,
transformation
training
,
source
classifier
,
iterative
training
procedure
,
transformation
accuracy
,
corpora
,
training
iteration
,
source
to
targetand
target
to
source
annotation
transformation
,
transformed
corpus
,
annotation
,
annotated
corpus
,
next
iteration
,
newiteration
,
corpus
willresult
,
accurate
transformation
classifier
,
corpus
,
overall
procedure
,
theiterative
training
method
,
performs
,
target
to
source
annotation
transformation
,
source
annotations
,
annotated
corpus
,
cst
andcts
,
source
,
target
classifier
,
target
,
sourcecorpora
,
training
iteration
,
thetransformation
classifier
,
corpus
,
transformed
corpus
,
annotation
,
parallellyannotated
corpus
,
next
iteration
,
iterative
training
terminates
,
theclassifier
,
converges
,
discriminative
training
,
tra
nstrain
,
target
annotation
,
guidance
ofsource
annotation
,
first
iteration
,
transformed
corpus
,
transformationclassifiers
,
initialized
one
,
source
,
target
classifier
,
theassistance
,
guiding
feature
,
following
iteration
,
better
annotation
,
corporaof
,
subsequent
iteration
,
transformation
accuracy
,
optimization
,
annotated
corpus
,
convergence
,
annotationtransformationthe
predict
self
hypothesis
,
many
unsupervised
learning
approach
,
markov
random
field
,
methodology
,
unsupervised
dependency
parsing
,
basic
idea
,
predict
self
isthat
,
prediction
,
candidate
,
original
inputby
,
reverse
procedure
,
annotation
transformation
,
predict
self
indicates
,
abetter
transformation
candidate
,
targetannotation
guideline
,
original
form
,
source
annotationguideline
,
intuitionistic
strategy
,
thepredict
self
methodology
,
annotation
transformation
,
reversed
annotation
transformation
procedure
,
unreliable
prediction
,
previous
transformation
,
detail
,
source
to
target
annotation
transformation
,
thesource
,
prediction
,
target
annotation
guideline
,
second
,
target
to
source
transformation
,
prediction
result
,
previous
source
annotation
,
transformation
result
,
reversalverification
,
strategy
,
namedpredict
self
filtration
,
precious
strategy
,
predict
self
reestimation
,
reversedtransformation
procedure
,
filtration
,
timation
strategy
,
bythe
source
to
target
,
target
to
source
annotationtransformation
model
,
transformation
candidate
,
relativeweights
,
transformation
direction
,
better
transformation
performance
,
transformation
model
,
parameter
,
developing
set
,
predict
self
reestima
tion
,
iterative
transformation
training
,
reversed
transformation
model
,
function
,
thefunction
tra
nsannotate
,
worksresearches
,
automatic
adaptationbetween
different
corpus
,
adaptation
,
different
domain
,
different
statistical
distribution
,
blitzer
,
adaptation
,
different
annotation
guideline
,
jianget
,
alsosome
effort
,
manual
transformation
rule
,
treebank
conversion
,
cahill
,
mccarthy
,
hockenmaierand
steedman
,
curran
,
andword
segmentation
guideline
transformation
,
al2008
,
focuseson
,
automatic
transformation
,
annotationguidelines
,
annotation
transformation
technology
,
transformationaccuracy
,
utilization
rate
,
human
annotatedknowledge
,
iterative
training
procedure
,
thiswork
share
,
similarity
,
training
algorithm
,
parsing
,
sarkar
,
training
procedure
,
different
model
,
raw
text
,
keyidea
,
training
,
complementarity
ofdifferent
,
additional
trainingdata
,
raw
text
,
iterative
training
,
annotation
transformation
,
iterative
optimization
,
corpus
used416partition
,
transformation
model
,
predict
self
methodology
,
many
unsupervisedlearning
approach
,
unsupervised
dependencyparsing
,
scenario
,
annotation
transformation
,
transformation
accuracy
,
year
many
,
tothe
word
segmentation
task
,
global
training
,
investigation
,
word
structure
,
strategy
,
modeling
,
nakagawa
,
uchimoto
,
kruengkrai
,
al2009
,
al2010
,
unsupervised
technology
utilizingraw
text
,
johnson
,
gold
water
,
mochihashi
,
al2009
,
hewlett
andcohen
,
annotation
transformation
technology
,
system
combination
,
semi
supervised
unsupervised
technology
,
analysiswe
,
annotation
transformation
,
al2001
,
chi
nese
treebank
,
experimental
setting
,
annotationadaptation
,
convenienceof
comparison
,
corpus
,
following
different
segmentation
guideline
,
quantity
,
sizewith
,
ctb
spd
ctb
,
perceptron
classifier
forchinese
word
segmentation
,
comparison
,
baseline
annotation
transformation
,
annotation
adaptation
,
simple
corpus
merging
strategy
,
general
scenario
,
annotation
adaptation
problem
,
pd
asubset
,
pd
training
data
,
new
training
,
pd
test
data
,
thenew
test
,
w
name
,
version
,
balanced
source
corpus
andtarget
corpus
,
investigation
,
annotation
transformation
,
word
segmentationwe
,
baseline
perceptron
classifier
,
training
set
,
training
iteration
,
performance
measurement
indicator
,
word
segmentation
,
function
,
precision
,
recall
,
word
,
segmentation
result
,
segmented
word
,
gold
standard
word
,
baseline
classifier
,
classifiers
,
test
set
,
opposite
corpus
,
experimental
result
,
expectation
,
classifier
performs
,
corresponding
testset
,
performs
,
different
annotation
guideline
,
original
pdcorpus
,
periodpunctuations
,
learning
curve
,
iterative
training
,
annotation
transformation
,
annotation
transformation
,
direction
,
spd
to
ctb
,
transformed
corpus
,
regular
corpus
,
enhanced
classifier
,
comparison
,
cascaded
model
,
annotation
adaptation
,
al2009
,
feature
representation
,
onthe
adaptation
direction
,
classifiers
,
baseline
annotation
transformation
,
annotation
adaptation
,
classifier
,
corpus
,
thetime
cost
,
comparison
,
practicality
,
simple
corpus
,
strategy
,
dramatic
decrease
,
incompatible
annotation
guideline
,
baseline
annotation
transformation
method
,
withaccuracy
increment
,
annotation
adaptation
strategy
,
onethird
,
decoding
time
,
predict
selfreestimationwe
,
iterative
training
strategy
,
baseline
annotation
transformation
model
,
ctb
developing
set
,
trainingiteration
,
annotation
transformation
,
spd
toc
tb
,
iteration
,
performanceof
,
classifier
,
corpus
,
figure
,
performance
curve
,
iteration
,
predict
self
filtration
andpredict
self
reestimation
,
predict
self
reestimationiterative
trainingfigure
,
learning
curve
,
withpredict
self
reestimation
,
annotation
transformation
,
baseline
annotation
transformation
model
,
corpus
,
iteration
,
predict
self
filtration
andpredict
self
reestimation
,
predict
selfreestimation
,
series
,
weight
parameters
,
pointat
,
baselineannotation
transformation
strategy
,
upper
horizontal
line
,
predict
selffiltration
,
predict
self
filtration
bringsslight
improvement
,
baseline
,
predict
self
reestimation
,
filtration
strategywhen
,
proper
range
,
initial
analysison
,
experimental
result
,
kruengkrai
,
iterative
annotationtransformation
,
predict
self
reestimation
comparedwith
annotation
adaptation
,
filtration
,
training
word
,
predict
self
filtration
,
weight
,
predict
self
reestimation
canmake
,
training
data
,
f
measure
improvement
,
annotationtransformation
baseline
,
little
worsethan
,
iterative
training
,
figure
,
performance
curve
,
iterativeannotation
transformation
,
predict
self
reesti
mation
,
predict
self
reestimationbrings
improvement
,
iterative
training
,
eachiteration
,
maximum
performance
,
achievedat
iteration
,
corresponding
model
,
test
set
,
experimental
result
,
compared
,
adaptation
,
optimized
annotation
transformation
,
classifier
,
several
time
,
processing
,
whole
pd
,
source
corpus
,
achieves
,
f
measure
,
previous
,
single
classifier
,
local
feature
,
ofcourse
,
comparison
,
previous
,
additional
training
datais
unfair
,
aim
,
word
segmentation
,
collection
,
training
data
,
mak
3the
predict
self
reestimation
ratio
,
firsttraining
iteration
,
efficiency
,
full
use
,
certain
corpus
,
theperformance
,
adoptingthe
advanced
technology
,
previous
,
suchas
,
model
combination
,
corpus
forword
segmentation
,
thousand
,
annotation
transformation
,
baseline
,
otherhand
,
source
annotated
training
data
,
thesighan
dataset
,
increment
,
valuable
toevaluate
,
improved
word
segmenter
,
out
of
domain
datasets
,
word
segmentation
,
domain
,
data
,
itmakes
evaluation
,
future
worksin
,
annotation
transformation
algorithm
,
ahuman
annotated
corpus
,
annotation
guideline
,
optimizationstrategies
,
iterative
training
,
predict
self
reesti
mation
,
annotation
guideline
transformation
,
wordsegmentation
,
optimized
annotation
transformation
strategy
,
classifier
,
better
performance
,
several
time
,
datasets
,
adaptation
,
whole
pd
,
sourcecorpus
,
final
classifier
,
outperformsprevious
,
singleclassifier
,
local
feature
,
future
,
acceleration
,
iterative
training
,
weight
parameter
tuning
,
optimized
annotationtransformation
strategy
,
word
segmentation
,
pos
tagging
,
parsing
,
nlp
task
,
acknowledgmentsthe
author
,
national
naturalscience
foundation
,
state
key
project
,
anonymousreviewers
,
thorough
reviewing
,
valuablesuggestions
,
referencesjohn
blitzer
,
mcd
onald
,
pereira
,
adaptation
,
structural
correspondence
learning
,
proceeding
,
emn
lp
,
aoife
cahill
,
mccarthy
,
automaticannotation
,
treebank
,
lfg
f
structure
information
,
proceeding
,
lre
c
workshop
,
curran
,
comparingthe
accuracy
,
treebank
parser
,
proceedings
,
roark
,
perceptron
algorithm
,
proceedingsof
acl
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceeding
ofe
mnlp
,
frustratingly
easy
domain
adaptation
,
proceeding
,
search
based
structured
prediction
,
proceeding
,
haowei
qin
,
adaptive
word
segmentation
,
proceedingsof
acl
,
hewlett
,
cohen
,
unsupervised
word
segmentation
,
proceedings
,
hockenmaier
,
steedman
,
ccgbank
,
corpus
,
ccg
derivation
,
dependency
,
treebank
,
computationallinguistics
,
wenbin
jiang
,
liang
huang
,
qun
liu
,
cascaded
linear
model
,
joint
wordsegmentation
,
part
of
speech
tagging
,
proceedings
,
wenbin
jiang
,
liang
huang
,
qun
liu
,
automatic
adaptation
,
annotation
standard
,
chineseword
segmentation
,
po
tagging
,
study
,
inp
roceedings
,47
th
acl
,
johnson
,
goldwater
,
improvingnonparameteric
bayesian
inference
,
word
segmentation
,
adaptor
grammars
,
proceeding
,
naa
cl
,
canasai
kruengkrai
,
kiyotaka
uchimoto
,
junichikazama
,
yiou
,
kentaro
torisawa
,
hitoshiisahara
,
error
driven
word
character
hybridmodel
,
joint
word
segmentation
,
postagging
,
proceeding
,
internal
structure
ofwords
,
new
paradigm
,
chineseword
segmentation
,
proceeding
,
qun
liu
,
researchon
strategy
,
lexical
analysis
andparser
,
journal
,
information
processing
,
daichi
mochihashi
,
takeshi
yamada
,
naonori
ueda
,
bayesian
unsupervised
word
segmentation
,
pitman
yor
language
modeling
,
kiyotaka
uchimoto
,
hybrid
approach
,
word
segmentation
,
po
tagging
,
proceeding
,
hwee
tou
ng
,
jin
kiat
low
,
part
of
speech
tagging
,
all
at
once
,
proceeding
,
emn
lp
,
anoop
sarkar
,
training
method
tostatistical
parsing
,
proceeding
,
naa
cl
,
weiwei
sun
,
stacked
sub
word
model
forjoint
word
segmentation
,
part
of
speechtagging
,
proceeding
,
kun
,
chengqing
zong
,
acharacter
based
joint
model
,
word
segmentation
,
proceeding
,
libin
shen
,
word
segmentation
,
lmr
tagging
,
proceeding
,
hanw
orkshop
,
nianwen
xue
,
fei
xia
,
fu
dong
chiou
,
marthapalmer
,
treebank
,
phrasestructure
annotation
,
large
corpus
,
natural
language
engineering
,
huiming
duan
,
shiyong
kang
,
honglin
sun
,
hui
,
qiang
zhao
,
weidong
zhan
,
modern
corpus
,
technical
report
,
yue
zhang
,
segmentation
,
word
based
perceptron
algorithm
,
proceedings
,
yue
zhang
,
fast
decoder
forjoint
word
segmentation
,
pos
tagging
,
single
discriminative
model
,
proceeding
,
emn
lp
,
hai
zhao
,
chunyu
,
segmentation
,
learning
,
character
taggingfor
word
segmentation
,
entity
recognition
,
proceeding
,
workshop
,
muhua
zhu
,
jingbo
zhu
,
betterautomatic
treebank
conversion
,
feature
basedapproach
,
proceeding
,
conference
,
empirical
method
,
association
,
computational
linguisticsmodeling
term
translation
,
laboratory
,
intelligent
information
processinginstitute
,
computing
technology
,
academy
,
sciences2university
,
academy
,
science
mengfandong
,
jiangwenbin
,
computer
science
,
technology
,
soochow
universitydyxiong
suda
,
next
generation
localisation
,
dublin
city
universityabstractterm
translation
,
document
informed
smt
,
thispaper
,
termtranslation
,
context
,
document
informed
smt
,
corresponding
model
,
term
translation
disambiguation
model
,
desirable
translation
,
thesource
language
,
domain
information
,
term
translation
consistency
,
consistent
translation
forterms
,
high
strength
,
translationconsistency
,
rewardstranslation
hypothesis
,
bracketablesource
term
,
wholeunit
,
model
intohierarchical
phrase
based
smt
,
effectiveness
,
nis
t
ch
inese
translation
task
,
large
scaletraining
data
,
experiment
result
,
significant
improvement
,
baseline
,
furtherimprovement
,
threemodels
,
ntroductiona
term
,
linguistic
expression
,
asthe
designation
,
defined
concept
,
concept
,
term
translation
,
original
language
,
translation
,
domain
,
andthe
context
,
vasconcellos
etal
,
domain
specificand
context
sensitive
term
translation
,
threeissues
,
bracketing
,
term
translation
ambiguity
,
translations
,
different
domain
,
asource
language
term
,
different
translations
,
different
domain
,
second
,
translation
consistency
,
consistent
translations
,
termin
different
,
different
part
,
concern
,
multi
word
term
,
translation
,
normally
,
multi
word
term
,
asa
whole
unit
,
contiguous
target
string
,
contextof
document
informed
smt
,
document
informed
information
,
term
translations
,
consistent
translation
,
samedocument
,
different
model
,
translation
,
threeissues
,
inthis
model
,
translation
,
corresponding
per
document
topic
distribution
,
decoder
,
translation
hypothesis
,
domain
specific
termtranslations
,
erm
translation
consistency
model
,
thismodel
,
highstrength
,
translation
consistency
,
different
part
,
consistent
fashion
,
translation
consistency
strength
,
topic
distribution
,
documents
,
bracketing
model
,
translation
hypothe
546ses
,
bracketable
multi
word
term
,
whole
unit
,
hierarchicalphrase
based
smt
,
chiang
,
arge
scaleexperiment
result
,
able
toachieve
significant
improvement
,
baseline
,
improvement
,
baseline
,
ble
point
,
remainder
,
witha
brief
overview
,
related
,
bilingual
term
extraction
,
wethen
,
termtranslation
,
experiments
,
effectiveness
,
proposedmodels
,
provide
direction
,
future
,
workin
,
workand
,
difference
,
workand
previous
study
,
term
translation
disambiguation
,
consistency
,
topic
modeling
,
models
,
previous
,
machine
translation
,
eidelman
,
enableword
alignment
process
,
topical
contents
,
document
pairs
,
topic
model
,
relationship
,
out
of
domain
bilingual
corpus
,
in
domain
monolingual
corpus
,
topic
mapping
,
phrase
topicdistribution
probability
estimation
,
translationmodel
adaptation
,
atopic
similarity
model
,
rule
selection
,
use
topic
model
,
probability
,
translation
,
topic
model
,
document
levelsmt
,
document
informed
information
,
term
translation
,
tiedemann
,
propose
cache
based
language
,
translation
models
,
sentences
,
additional
cache
,
static
cache
,
bilingual
phrase
,
topic
cachewith
target
language
topic
word
,
effort
,
model
lexical
cohesion
,
hardmeier
,
coherence
,
document
level
smt
,
hasler
,
use
topic
model
,
document
level
translation
probability
,
hasler
,
use
topic
adapted
model
,
lexical
selection
,
thesignificant
difference
,
thesestudies
,
term
translation
,
document
level
smt
model
,
itagaki
,
aikawa
,
bilingualterm
bank
,
machine
aided
translation
,
binary
featureto
,
bilingual
phrase
,
aterm
pair
,
skadins
,
thatbilingual
term
,
domain
adaptation
,
machine
translation
,
term
translation
,
anddocument
informed
information
,
assist
term
translation
,
itagaki
,
statistical
methodto
calculate
translation
consistency
,
domain
information
,
term
translationconsistency
,
document
informed
information
,
proposedterm
translation
consistency
model
,
actualsmt
system
,
ir
inspiredtf
idf
score
,
consistent
translationchoice
,
guillou
,
kind
ofwords
,
termtranslation
consistency
,
syntax
driven
bracketing
model
,
phrase
based
translation
,
phrase
,
usingrich
syntactic
constraint
,
difference
,
thatwe
construct
,
createdbilingual
term
bank
,
term
fromtwo
language
,
purpose
,
bilingual
term
bank
,
turn
canbe
,
informationretrieval
,
machine
translation
,
wewant
,
bilingual
term
bankso
,
term
translation
,
improvetranslation
quality
,
interest
,
extract
multi
word
term
,
strategy
,
bilingual
term
extraction
,
parallelcorpora
,
term
candidates
,
language
,
tomonolingual
term
metric
,
c
value
nc
value
,
frantzi
,
common
cooccurrence
measure
asl
og
likelihood
ratio
,
dice
coefficient
,
point
wise
mutual
information
,
daille
,
piao
etal
,
monolingual
term
,
strategy
,
toalign
word
,
word
sequence
,
translation
equivalent
,
parallel
corpus
,
non
terms
,
merkel
,
lefever
,
bouamor
,
first
strategy
,
allsource
phrase
,
alignedtarget
phrase
,
word
alignment
,
ifthe
target
side
,
sourceand
target
term
,
term
pair
,
monolingual
term
extraction
usingthe
c
value
nc
value
,
measure
,
c
value
nc
value
metric
,
term
extraction
,
thesame
,
frantzi
,
extraction
method
,
linguistic
patterns
,
phrase
,
linguistic
structure
,
forthe
llr
,
term
extraction
,
daille
,
propensity
,
amulti
word
expression
,
algorithm
,
arbitrary
length
,
c
value
nc
value
,
extraction
method
,
strict
linguisticpatterns
,
llr
measure
,
extracts
,
flexible
term
,
method
,
method
,
monolingual
multi
word
term
,
extracted
term
,
odelsthis
,
termtranslation
,
term
translation
disambiguation
model
,
term
translation
consistencymodel
,
straightforward
,
translation
,
different
domain
,
conditional
translation
probability
ofa
term
,
domain
information
,
thetopic
distribution
,
atopic
model
,
domain
,
latent
dirichlet
allocation
,
widely
used
topic
model
,
topicdistributions
,
topic
similarity
model
,
rule
selection
,
different
,
easier
strategy
,
topic
conditioned
termtranslation
probability
,
rule
topic
distributions
,
bilingual
term
bank
,
source
to
targetterm
translation
probability
,
topic
distribution
,
sourcedocument
,
source
term
,
a
k
dimension
,
vector
,
term
pair
,
k
th
componentp
,
conditional
translation
probability
,
source
term
tfto
target
,
maximumlikelihood
estimation
,
trainingdata
,
source
part
,
bilingual
termpair
,
lda
tool
,
fraction
count
,
instance
,
chiang
,
different
document
topic
distribution
,
bilingual
term
pair
,
instance
,
probability548p
,
extracted
term
pair
,
ourbilingual
term
bank
,
topic
conditioned
translation
probability
,
topic
distribution
,
lda
tool
,
containst
term
,
term
translation
disambiguation
model
termdis
,
source
term
tfiis
,
tfiand
,
bilingual
term
bank
,
conditional
translation
probability
,
documentd
,
term
translation
disambiguation
model
,
log
linear
model
,
afeature
,
weight
,
minimum
error
,
decoder
,
translationhypotheses
,
term
translation
,
domain
,
topicdistribution
,
accord
,
domain
,
translation
issue
,
domain
specific
term
translation
,
termshould
,
domainwhere
,
term
translation
consistency
,
translation
stability
,
source
termis
,
target
term
,
itagaki
etal
,
source
term
,
thetranslation
consistency
strength
,
source
termis
,
corresponding
targetterm
,
translation
,
new
translation
,
toits
context
,
thedecoder
,
givensource
term
,
extracted
corresponding
target
term
,
according
,
strength
,
translation
consistency
,
consistent
translations
,
high
translation
consistencystrength
,
term
translation
consistency
model
,
strength
,
term
translation
consistency
,
essential
component
,
term
translation
consistency
,
translation
consistency
strength
,
sourceterm
,
topic
distribution
,
thewhole
model
,
bilingual
term
bank
,
source
termand
,
corresponding
target
term
,
target
term
,
a
k
dimension
,
vector
,
k
th
component
measure
thetranslation
consistency
strength
,
thesource
term
,
data
asfollows
,
whichthe
source
term
tfoccurs
,
number
ofunique
corresponding
term
translation
,
frequency
,
nthtranslation
,
conditional
probability
,
normalization
factor
,
translation
,
translation
consistency
,
topic
based
translation
consistency
measure
,
equation
,
translation
consistency
strength
,
thesource
term
,
thedistribution
,
document549where
,
translation
consistency
strength
,
source
term
,
documentand
,
translation
,
translationconsistency
strength
,
bilingual
term
bank
,
a
k
dimension
vector
,
thetopic
conditioned
translation
consistency
,
sentences
,
topic
distribution
,
lda
tool
,
termtranslation
consistency
model
termcons
,
ast
ermcons
,
strength
,
translation
consistency
,
hypothesis
,
source
term
,
translation
,
bilingual
term
bank
,
strength
,
translation
consistency
,
soft
constraint
,
decodershould
translate
,
extracted
corresponding
target
term
,
decoder
,
translation
,
topic
dependent
consistency
pattern
,
testdata
,
training
data
,
wecan
control
,
translation
consistency
,
term
inthe
test
data
,
term
translation
consistency
model
,
log
linear
model
,
afeature
,
thedecoder
,
high
translationconsistency
,
target
term
,
bilingual
term
bank
,
thanother
translation
,
consistent
fashion
,
term
translation
accuracy
,
domain
information
,
in
tegrality
,
term
translation
,
syntax
driven
bracketing
model
forphrase
based
translation
,
whethera
phrase
,
syntactic
constraint
,
source
phrase
,
translation
,
type
ofphrase
,
bracketable
phrase
,
unbrack
etable
phrase
,
multi
word
term
,
source
termshould
,
whole
unit
,
translation
,
term
translation
,
builda
classifier
,
probability
,
sourceterm
,
bracketable
manner
,
source
part
,
extracted
bilingualterm
bank
,
target
counterpart
,
theword
aligned
training
data
,
correspondingtarget
counterpart
,
thesource
term
,
bracketable
instance
,
otherwisean
unbracketable
instance
,
bracketableand
unbracketable
instance
,
maximumentropy
binary
classifier
,
source
term
,
binary
classifier
,
binary
feature
function
,
weight
,
following
features
,
word
sequence
,
source
term
,
first
word
,
source
term
,
last
wordof
,
source
term
,
thefirst
word
,
source
term
,
succeedingword
,
last
word
,
source
term
,
source
term
,
hypothesis
,
source
termtfi
,
bracketable
probability
,
thelog
linear
model
,
thefeature
,
decoder
,
sourceterms
,
high
bracketable
probability
,
awhole
unit
,
target
d
m
,
defense
programme
,
strategic
missile
defense
system
,
bilingual
term
,
total
number
ofdocuments
,
source
term
,
corresponding
source
term
,
different
target
term
,
source
side
,
chinesepinyin
,
different
translation
,
question
,
term
translation
disambiguation
,
consistency
,
bracketing
model
able
toimprove
translation
quality
,
combination
,
modelsprovide
,
improvement
,
extent
,
translation
,
test
set
,
document
boundaries
,
bilingual
trainingdata
contain
,
chinesewords
,
word
,
development
test
set
,
nis
tmt0
,
final
test
set
,
nis
t
mt
,
mt08are
,
word
alignment
,
corpus
inboth
direction
,
grow
diag
final
and
,
balance
strategy
,
sri
language
modeling
toolkit
,
stol
cke
,
others
,
gram
languagemodel
,
modified
kneser
ney
,
onthe
xinhua
portion
,
gigaword
corpus
,
topic
model
,
open
source1the
corpus
,
default
settingfor
training
,
inference
,
iterations
,
lb
fgs
algorithm
,
inthe
maxent
toolkit3with
,
gaussian
,
andevent
cutoff
,
term
bracketingprediction
model
,
part
of
speech
tagging
,
monolingual
term
extraction
,
c
value
nc
vaule
methodin
,
source
,
target
,
nlp
toolkit4
,
bilingual
termbank
,
following
parameter
setting
,
term
extraction
method
,
maximum
length
,
c
value
nc
value
,
extraction
method
,
context
window
size
,
widely
used
setting
,
previous
,
c
value
nc
value
score
threshold
,
training
corpus
,
insensitive
gram
ble
u6asour
evaluation
,
impact
,
instability
,
average
ble
score
,
suggestion
,
in
house
hierarchical
phrase
baseddecoder
,
althoughthe
decoder
,
document
informed
information
,
term
translation
model
,
ondocuments
,
sourceforge
,
net
project
,
homepage
,
lzhang10
maxent
toolkit
,
html4http
,
software
tagger
,
maximum
length
,
preliminary
experiment
,
othervalues
,
jaguar
,
gov
mt
resource
,
member
,
deliberation
,
proposalst
,
submit
,
approval
,
unbracketable
source
term
,
training
data
,
solid
line
,
bilingual
phrase
,
source
side
isc
hinese
pinyin
,
result
,
models
,
statistic
,
bilingualterm
bank
,
training
data
,
statistic
,
training
data
,
training
data
,
average
,
asource
term
,
different
translation
,
statistic
,
real
world
data
,
source
term
canbe
,
different
target
term
,
bilingualterms
,
training
data
,
total
number
,
documents
,
corresponding
source
termoccurs
,
source
term
,
intodifferent
target
term
,
different
translation
,
theyare
,
trainingdata
,
single
translation
,
different
translation
,
different
fromthis
,
translation
,
statistic
,
source
term
,
translation
,
statistic
,
thatsource
term
,
domain
specific
translationsand
,
source
term
,
consistent
manner
,
reason
,
term
translation
disambiguation
,
consistency
model
,
domain
information
,
topic
distribution
,
source
term
,
target
string
,
wholeunit
,
figure
,
figure
,
deliberations
,
whole
unit
,
therefore
,
however
,
therefore
,
unbracketable
term
,
reason
,
bracketingmodel
,
source
term
,
modelsin
,
effectiveness
,
theproposed
term
translation
disambiguation
model
,
consistency
model
,
addition
,
traditional
hiero
,
chi
ang
,
countfeat
,
method
,
binary
feature
,
bilingualphrase
,
term
pair
,
phrase
based
system
,
ahierarchical
phrase
based
system
,
effect
,
term
translation
disambiguation
model
,
dis
model
,
result
,
inorder
,
topic
number
,
whichour
model
,
experiments
,
development
test
set
,
dis
model
obtains
steady
improvement
,
baseline
,
countfeat
,
method
,
term
translation
disambiguation
model
,
dis
model
,
term
translation
consistency
model
,
cons
model
,
brack
model
,
combination
,
development
test
,
final
test
,
dis
model
,
combination
,
single
mode
,
topic
number
,
dis
model
,
method
,
countingfeature
,
translation
hypothesis
,
bilingual
term
pair
,
theresults
,
baseline
system
,
countfeatmethod
,
performance
drop
,
ble
uscores
,
dis
model
gainshigher
performance
,
traditional
hiero
baseline
,
countfeat
,
methodwith
,
topic
setting
,
countfeat
,
methodrewards
translation
,
bilingual
term
pair
,
anydomain
information
,
dis
model
incorporatesdomain
information
,
translation
disambiguation
,
whenthe
topic
number
,
highest
ble
score
,
thebaseline
,
ble
point
,
mt06and
mt08
,
final
gain
,
thebaseline
,
ble
point
,
second
group
,
experimentsto
study
,
term
translation
consistencymodel
,
cons
model
,
theimpact
,
different
topic
number
,
cons
model
,
result
,
similar
phenomenon
,
dis
model
,
ble
score
,
baseline
system
,
countfeat
,
method
,
topicsettings
,
topic
number
,
achieves
,
ble
point
,
ble
pointson
mt06
,
average0
,
ble
point
,
effectiveness
,
brack
model
,
prediction
forsource
term
,
result
,
show
thatour
brack
model
gain
,
ble
score
thanthose
,
baseline
system
,
countfeat
,
method
,
final
gain
,
brack
model
,
thebaseline
,
ble
point
,
point
onm
t06
,
average0
,
ble
point
,
three
modelsas
,
previous
subsection
,
termtranslation
disambiguation
model
,
consistencymodel
,
baseline
,
improvement
,
last
,
table
2shows
,
combination
,
combined
model
,
ble
scorethan
,
single
model
,
term
translation
disambiguation
model
,
consistency
model
,
best
translationswhich
,
combined
model
andthe
,
single
model
,
setting
,
thedevelopment
test
,
final
test
setmt08
,
topic
number
,
best
dis
model
,
best
cons
model
,
combined
model
,
baseline
,
mt08respectively
,
ble
point
,
extent
,
translation
,
test
set
,
best
translations
,
combined
model
,
thethree
single
model
,
setting
,
test
setsmt06
,
single
model
,
corresponding
feature
,
disambiguation
,
consistency
,
best
derivation
,
corresponding
model
,
besttranslation
,
combined
model
,
ofthe
corresponding
feature
,
best
derivation
,
combined
model
affect
the1
best
translation
,
best
translations
,
theproposed
model
,
high
proportion
,
importantrole
,
translation
,
test
set
,
amongthe
,
brack
model
,
theone
,
best
translations
,
test
set
,
is60
,
brack
model
considers
sourceterms
,
decoding
,
dis
model
andcons
model
need
,
source
,
targetterms
,
brack
model
,
the1
best
translation
,
combined
model
,
single
model
,
translation
,
single
model
,
combined
model
,
best
translation
,
single
model
,
onclusion
,
future
workwe
,
term
translation
,
different
term
translation
model
,
document
informed
smt
,
theterm
translation
disambiguation
model
enablesthe
decoder
,
suitable
domain
specific
translation
,
domain
information
forsource
term
,
term
translation
consistencymodel
,
decoder
,
sourceterms
,
high
domain
translation
consistencystrength
,
target
term
,
newstrings
,
model
rewards
hypothesis
,
bracketable
termsinto
continuous
target
string
,
whole
unit
,
hierarchicalphrase
based
smt
system7and
,
effectiveness
,
nis
t
ch
inese
translation
task
,
large
scale
training
data
,
experiment
result
,
model
achievesignificant
improvement
,
baseline
,
improvement
,
future
,
different
domain
,
acknowledgmentsthis
,
andcas
action
plan
,
development
,
workwas
,
natural
science
foundation
ofj
iangsu
province
,
sciencefoundation
,
ce
i1142
,
aspart
,
dublin
city
,
sincere
thanks
,
anonymous
reviewer
,
reviewing
,
valuable
suggestion
,
author
,
tothe
meaning
,
ofc
hinese
academy
,
science
,
soochow
,
deyi
xiong
,
hierarchical
phrase
basedsmt
,
smt
formalism
,
phraseand
syntax
based
smt
,
m
b
lei
,
y
n
,
i
j
ordan
,
latent
dirichlet
allocation
,
journal
,
houda
bouamor
,
elien
,
vilnat
,
validation
,
sub
sentential
paraphrase
,
parallel
monolingual
corpus
,
proceedings
,13
th
conference
,
association
,
computational
linguistics
,
association
,
computational
linguistics
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
h
c
,
dyer
,
alon
lavie
,
asmith
,
hypothesis
,
statisticalmachine
translation
,
optimizer
instability
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
,
human
language
technology
,
short
papers
volume2
,
eatrice
daille
,
implementation
,
technique
,
automatic
extraction
,
terminology
,
journal
,
combining
symbolic
,
statistical
approach
,
language
,
eidelman
,
graber
,
philipresnik
,
topic
model
,
dynamic
translationmodel
adaptation
,
proceeding
,50
th
annual
meeting
,
association
,
computationallinguistics
,
short
papers
volume
,
association
,
computational
linguistics
,
xiaorong
,
nobuyuki
shimizu
,
hiroshi
nak
agawa
,
automatic
extraction
,
bilingual
term
,
japanese
parallel
corpus
,
proceeding
,
international
universalcommunication
symposium
,
ananiadou
,
junichitsujii
,
c
value
nc
value
method
,
automatic
recognition
,
multi
word
term
,
research
,
advanced
technology
,
digital
libraries
,
springer
,
zhengxian
gong
,
zhang
,
guodong
zhou
,
cache
based
document
level
statistical
machine
translation
,
proceeding
,
conferenceon
empirical
method
,
natural
language
processing
,
guillou
,
lexical
consistencyin
translation
,
proceeding
,
workshop
ond
iscourse
,
machine
translation
,
hardmeier
,
joakim
nivre
,
org
tiede
mann
,
phrase
based
statistical
machine
translation
,
proceedings
,
joint
conference
,
empirical
method
,
natural
language
processing
andcomputational
natural
language
learning
,
pages1179
,
hasler
,
blunsom
,
philipp
koehn
,
barryhaddow
,
proceeding
,
conference
,
chapter
,
association
forcomputational
linguistics
,
gothenburg
,
hasler
,
haddow
,
philipp
koehn
,
dynamic
topic
adaptation
,
distributional
profile
,
proceeding
,
ninth
workshop
,
statistical
machine
translation
,
baltimore
,
associationfor
computational
linguistics
,
hjelm
,
cross
language
termequivalents
,
statistical
machine
translation
anddistributional
association
measure
,
proceedingsof
,
nordic
conference
,
computational
linguistics
nodalida
,
masaki
itagaki
,
takako
aikawa
,
post
mtterm
swapper
,
statistical
machinetranslation
system
,
user
dictionary
,
takako
aikawa
,
automatic
validation
,
terminology
translation
consistency
,
statistical
method
,
proceedings
,
philipp
koehn
,
och
,
marcu
,
statistical
phrase
based
translation
,
inp
roceedings
,
conference
,
northamerican
chapter
,
association
,
computational
linguistics
,
human
language
technology
volume
,
el
lefever
,
lieve
macken
,
hoste
,
language
independent
bilingual
terminologyextraction
,
multilingual
parallel
corpus
,
inp
roceedings
,
conference
,
association
,
computational
linguistics
,
merkel
,
foo
,
terminologyextraction
,
term
ranking
,
termbanks
,
proceeding
,
nordic
conferenceof
computational
linguistics
nodalida
,
och
,
ney
,
systematic
comparison
,
various
statistical
alignmentmodels
,
computational
linguistics
,
och
,
minimum
error
rate
,
statistical
machine
translation
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
volume
,
sl
piao
,
guangfan
sun
,
rayson
,
andqi
yuan
,
automatic
extraction
,
chi
nese
multiword
expression
,
statistical
tool
,
workshop
,
multi
word
expressions
,
a
m
ul
tilingual
context
held
,
conjunction
,
trento
,
skadins
,
mt
adaptation
,
under
resourced
domain
,
uman
language
technology
,
proceeding
,
fifth
international
conference
baltic
hlt
,
volume
,
zhixiang
ren
,
yajuan
,
jie
cao
,
qun
liu
,
yunhuang
,
statistical
machine
translation
,
domain
bilingual
multiword
expressions
,
proceeding
,
workshop
,
multiwordexpressions
,
identification
,
interpretation
,
disambiguation
,
application
,
stolcke
,
srilm
an
extensible
language
,
toolkit
,
proceeding
,
international
conference
,
spoken
language
processing
,
volume
,
yidong
,
xiaodong
shi
,
huailin
dong
,
qun
liu
,
translation
model
adaptation
,
statistical
machinetranslation
,
monolingual
topic
information
,
inp
roceedings
,50
th
annual
meeting
,
theassociation
,
computational
linguistics
,
org
tiedemann
,
context
adaptation
,
statistical
machine
translation
,
proceeding
,
domain
adaptation
,
natural
language
processing
,
w
o
ard
,
resnik
,
consistent
translation
choice
,
proceeding
,
conference
,
northamerican
chapter
,
association
,
computational
linguistics
,
human
language
technology
,
association
,
computational
linguistics
,
vasconcellos
,
avey
,
gdaniec
,
gerber
,
teruko
mita
mura
,
terminology
,
machine
translation
,
handbook
,
terminology
management
,
zhang
,
extraction
,
unithood
,
termhood
unification
,
proceeding
,
third
international
joint
conference
,
natural
language
processing
,
wong
,
chunyu
,
machine
translation
evaluation
metric
,
lexical
cohesion
,
proceeding
,
the2012
joint
conference
,
empirical
method
inn
atural
language
processing
,
computationalnatural
language
learning
,
deyi
xiong
,
zhang
,
qun
liu
,
andshouxun
,
topic
similarity
model
,
hierarchical
phrase
based
translation
,
proceedingsof
,50
th
annual
meeting
,
association
forcomputational
linguistics
,
papers
volume
,
deyi
xiong
,
zhang
,
topic
basedcoherence
model
,
statistical
machine
translation
,
proceeding
,
twenty
seventh
aaa
infer
ence
,
deyi
xiong
,
zhang
,
syntax
driven
bracketing
model
,
phrase
based
translation
,
proceeding
,
joint
conference
,47
th
annual
meeting
,
international
joint
conference
,
naturallanguage
processing
,
afn
lp
,
deyi
xiong
,
guosheng
,
zhang
,
yajuan
,
qun
liu
,
lexical
cohesion
fordocument
level
machine
translation
,
proceedingsof
,
twenty
third
international
joint
conferenceon
artificial
intelligence
,
deyi
xiong
,
yang
ding
,
zhang
,
chew
limtan
,
lexical
chain
,
cohesion
models
,
document
level
statistical
machine
translation
,
proceeding
,
conference
,
empirical
method
,
natural
language
processing
,
pages1563
,
p
x
ing
,
bilingualtopic
admixture
model
,
word
alignment
,
proceedings
,
main
conferenceposter
session
,
annual
meeting
,
association
,
computational
linguistics
,
uppsala
,
association
,
computational
linguisticsdependency
parsing
,
projection
,
word
pair
classificationwenbin
jiang
,
qun
liukey
laboratory
,
intelligent
information
processinginstitute
,
technologychinese
academy
,
sciencesp
,
beijing
,
jiangwenbin
,
intuitionisticmethod
,
dependency
parsing
,
aclassifier
,
word
form
,
dependency
edge
,
effective
strategyfor
dependency
projection
,
dependency
relationship
,
source
language
,
target
language
,
classification
instance
,
complete
tree
,
classifier
,
projectedclassification
,
dependencyparsers
,
classifier
,
dependency
parser
,
obvious
improvement
,
dependency
,
state
of
the
,
year
,
pereira
,
human
annotated
treebanks
,
utilization
,
unannotated
text
,
forexample
,
unsupervised
dependency
parsing
,
manning
,
basedon
unannotated
data
,
semisupervised
dependency
parsing
,
complexity
,
unsupervised
parsing
,
need
ofreliable
priori
knowledge
,
semisupervised
parsing
,
promising
strategy
,
dependency
structure
,
resource
languageto
,
bilingual
corpus
,
ganchev
,
eisner
,
dependency
projection
,
relationship
between
word
,
word
alignment
,
dca
assumption
,
projection
procedure
suffers
,
word
alignment
error
,
syntactic
isomerism
,
languages
,
relationship
projection
conflict
,
dependencystructures
,
problem
,
filtering
rule
,
hand
designed
rule
,
languageheterogeneity
,
eisner
,
performdependency
projection
,
annotation
,
quasi
synchronous
grammar
feature
,
jiangand
liu
,
resort
,
dynamic
programmingprocedure
,
projected
tree
,
strategy
,
category
,
dependency
projection
mustproduce
,
projected
tree
,
thefree
translation
,
syntactic
isomerism
betweenlanguages
,
word
alignment
error
,
dependencystructure
,
language
,
effective
method
,
dependency
projection
,
word
aligned
bilingual
corpus
,
source
language
sentences
,
dependency
relationship
,
theword
pair
,
source
language
,
tothe
word
pair
,
target
language
,
dependency
relationship
,
boolean
value
,
word
pair
,
dependencyedge
,
classification
instance
,
intuitionisticmodel
,
dependency
parsing
,
classifier
,
word
forma
dependency
edge
,
classifier
,
classification
instance
,
projected
dependency
,
jif
igure
,
simple
collection
method
,
experimental
result
,
classification
,
projected
dependency
parser
,
previous
,
projected
classification
instances
,
precision
,
ctb
standard
test
set
,
thisclassifier
,
pereira
,
weighted
average
manner
,
significant
improvement
,
mst
baseline
,2
nd
order
mst
parser
,
classifier
,
precision
increment
of0
,
parser
,
thesmaller
ctb
,
point
precision
increment
,
word
pair
classification
model
,
generation
methodof
,
classification
instance
,
application
,
projectedparser
,
state
of
the
2nd
orderedmst
parser
,
comparisonswith
previous
,
dependency
,
andprojection
,
experimental
result
,
i
th
word
,
dependency
tree
,
represents
,
dependency
edge
,
word
xi
,
parent
,
word
pair
classification
modelis
,
candidate
word
pair
,
classification
result
,
boolean
value
,
classifier
,
vapnik
,
real
valued
probability
,
classifier
,
berger
,
probability
,
degree
,
support
,
classification
result
,
candidate
word
pair
,
dependency
parse
tree
,
candidateedges
,
boolean
valuedclassifier
,
robust
strategy
,
ambiguity
,
languagesyntax
,
classification
error
,
incomplete
parsing
result
,
factorization
method
,
eisner
,
dependency
tree
,
dependency
edge
,
design
,
dynamic
programming
algorithmto
search
,
candidate
parse
,
maximumscore
,
strategy
,
classification
errors
,
degree
,
completedependency
,
boolean
valued
classifier
,
search
algorithm
,
argmaxys
,
probability
valued
classifier
,
accumulation
,
cumula
13type
featuresunigram
wordi
,
posi
wordi
posiwordj
,
posj
wordj
posjbigram
wordi
,
posj
posi
,
posj
wordi
,
posjwordi
,
posj
wordi
,
wordj
wordi
,
wordjposi
,
posj
wordi
,
posj
posi
,
posjposi
,
word
pair
classification
model
,
tive
product
,
argmaxys
,
well
formeddependency
tree
,
real
valued
classifier
,
calculation
,
dependencyprobability
,
parameter
vector
,
feature
vector
,
assumption
,
theword
pair
,
dependency
relationship
,
classificationresult
,
dependency
edge
,
afeature
,
assumption
,
dependency
probability
,
definedas
,
classificationthe
feature
,
classifier
,
each
feature
,
pos
tag
,
word
iand
,
optional
distance
representations
,
showsthe
feature
,
previous
graph
based
dependency
model
,
index
distance
,
word
j1w
,
mcd
onald
,
preliminary
experiment
,
features
,
improvement
,
word
pair
classificationmodel
,
word
distance
information
,
syntaxinformation
,
syntactic
distance
representation
,
distance
,
distance
,
answer
,
questions
,
comma
between
word
,
thefirst
,
thesecond
,
original
feature
,
template
,
enhanced
featureswith
distance
,
postfix
,
intraining
,
decoding
,
word
pair
classifier
,
algorithmwe
,
logarithmic
dependency
probabilitiesin
decoding
,
cumulative
product
ofprobabilities
,
formula
,
accumulation
,
logarithmic
probability
,
argmaxys
,
decoding
algorithm
,1
st
ordered
mst
model
,
chu
liu
edmonds
algorithm14algorithm
dependency
parsing
algorithm
,
topological
order
do3
,
partitions5
,
insert
der
iv
,
insert
der
iv
,
top
derivation
,
output
,
derivation
,
function
der
iv
,
evaluation
function13
,
return
,
bottom
up
dynamic
programming
algorithm
algorithm
,
possible
expansion
,
contains
,
segment
,
function
,
dependency
segment
,
practice
,
cube
pruning
strategy
,
chi
ang
,
enumeration
ofderivations
,
projected
classification
instanceafter
,
word
pair
classification
model
,
extraction
,
projected
dependency
instance
,
effect
,
word
alignment
error
,
projection
,
alignment
matrix
,
compactrepresentation
,
result
,
single
word
,
previous
dependency
projection
,
figure2
,
bilingual
sentence
pair
,
parse
tree
,
thealignment
matrix
,
elementai
,
degree
,
alignment
betweenword
ei
,
dependencyrelationship
,
targetsentence
,
projected
dependency
edge
,
figure
,
word
alignment
matrix
,
translation
,
probability
,
acrossrows
,
projected
dependency
edge
,
simplicity
,
condition
factor
,
formula
,
probability
,
real
value
between0
,
ambiguous
,
theother
hand
,
dependency
instance
,
thresholdb
,
ambiguous
instance
,
instance
,
instance
,
mst
parserthe
classifier
,
human
annotated
tree
,
unified
framework
,
enhanced
parser
,
baseline
model
,
classifier
,
evaluation
,
baseline
model
,
classifier
,
parameter
,
relativeweight
,
classifier
,
baseline
model
,
several
strategy
,
twoevaluation
function
,
integrated
deeply
,
carreras
etal
,
manner
,
charniak
,
johnson
,
dependency
tree
,
word
pair
classifier
,
candidate
dependency
edge
inthis
tree
,
classifier
canbe
,
baseline
model
deeply
,
eachdependency
edge
,
evaluation
score
,
bythe
baseline
model
,
dependency
edge
,2
nd
ordered
mst
model
,
mc
,
pereira
,
baseline
,
effect
,
distance
,
thebaseline
model
,
relativeweight
,
performanceon
,
development
set
,
algorithm
similarto
minimum
error
rate
training
,
pereira
,
carreras
,
yamada
,
mat
sumoto
,
word
pair
classificationmodel
,
graph
based
method
,
modelis
,
dependency
edge
,
decoding
procedure
,
maximum
spanning
tree
,
directed
graph
,
fromthis
point
,
thegraph
based
category
,
training
method
,
differs
,
othergraph
based
model
,
ofword
pair
dependency
,
regular
dependency
treebank
,
model
ismore
,
corpus
,
apparent
similarity
,
ourmodel
,
transition
based
category
,
certain
configuration
,
classification
results
,
classifier
,
dependency
probability
,
whilethe
classifier
,
transition
based
model
,
apossible
next
transition
operation
,
shift
orreduce
,
difference
,
factorization
strategy
,
method
,
evaluation
,
candidate
parse
,
dependency
edge
,
transition
based
model
,
transition
operation
,
thanks
,
reminding
,
pairwise
classification
schema
,
japanese
dependency
parsing
,
uchimoto
,
kudoand
matsumoto
,
advantage
,
feature
engineering
,
modeltraining
,
algorithm
,
frombilingual
corpus
,
bracketing
knowledge
,
alignment
,
andganchev
,
dependency
,
projection
,
bilingual
corpora
,
threshold
,
handwritten
rule
,
heterogeneity
,
eisner
,
dependency
projection
,
annotation
adaptation
withquasi
synchronous
grammar
feature
,
jiang
andliu
,
matrix
,
dynamic
programming
search
algorithm
,
dependency
tree
,
previous
,
dependency
projection
,
ganchev
,
andeisner
,
projected
parser
,
because
,
free
translation
,
word
alignmenterrors
,
heterogeneity
,
languages
,
dependency
tree
,
dependencyprojection
strategy
,
dependency
instance
,
demand
,
corpus
,
obvious
advantageof
,
strategy
,
threshold
,
dependency
,
good
quality
,
addition
,
word
pair
classification
,
state
of
the
artmst
dependency
model
,
train
dev
testwsj
,23
c
tb
,
others
,
corpus
partition
,
dependency
edge
,
dependency
edge
,
evaluation
,
forthis
dependency
edge
,
strategy
,
betteruse
,
parser
,
decoding
,
cascaded
approach
ofj
iang
,
word
pairclassification
model
,
human
annotated
treebanks
,
effectiveness
,
dependency
projection
,
projected
classifier
,
projected
classification
instance
,
dependencyparser
,
andthe
2nd
ordered
mst
dependency
parser
,
parsing
accuracy
,
precision
oflexical
head
,
correct
parent
,
popular
treebanks
,
portion
,
englishtreebank
,
treebanks
,
head
finding
rule
,
yamada
,
matsumoto
,
automatically
assignedpos
tag
,
implementation
,
thepos
tagger
,
gold
standard
pos
,
followingthe
tradition
,
treebank
,
threepartitions
,
training
,
development
,
testing
,
dependency
tree
,
positive
dependency
instance
,
small
proportion
,
thedependency
instance
,
importantto
balance
,
proportion
,
thenegative
instance
,
batched
trained
classifier
,
new
parameter
,
negative
instance
,
positive
one
,
performance
curve
,
word
pairclassification
model
,
development
,
ofw
sj
,
respect
,
series
,
matsumoto
,
scholz
,
word
pair
classification
model
,
withthe
current
state
of
the
model
,
negativeinstances
,
positive
one
,
maxent
toolkit
,
classifier
,
extracted
instance
,
gaussian
prior
,
iteration
,
parameter
,
default
value
,
impact
,
ratio
onthe
performance
,
classifier
,
andchinese
parser
,
instance
set
,
certain
,
maximum
performance
,
classifier
,
instance
set
,
final
evaluation
phase
,
test
set
,
previous
,
test
set
,
word
pair
classification
model
,
homepage
,
s0450736
maxent
toolkit
,
fine
grained
ratio
,
theperformance
curve
,
dramatic
fluctuation
,
withthe
alteration
,
performance
curve
,
word
pair
classification
model
,
development
setof
,
respect
,
series
,
threshold
,
local
optimization
,
training
procedure
,
given
complete
tree
,
training
data
,
itis
easy
,
previous
model
,
linguistical
information
,
powerful
parameter
,
main
advantage
,
completetrees
,
parameter
,
trainedon
instance
,
human
annotated
tree
banks
,
word
pair
classification
model
,
advantage
,
existed
state
of
the
dependency
,
method
,
dependency
projection
,
fbi
schinese
bitext
,
bilingual
corpus
fordependency
projection
,
chi
nese
,
implementation
,
pos
tagger
,
implementation
,2
nd
orderedmst
model
,
mcd
onald
,
pereira
,
dependency
tree
,
alignment
matrix
,
sentencepairs
,
threshold
,
alsobe
,
appropriate
value
,
better
performance
,
larger
,
result
,
betterbut
,
classification
instance
,
coverage
,
instance
,
performance
ofthe
classifier
,
thresholds
lead
,
instance
,
toomuch
noisy
instance
,
classifier
,
series
,
classifier
,
test
set
,
previous
,
test
set
,
performance
improvement
,
classifier
,
baseline
2nd
orderedmst
parser
,
different
threshold
,
instanceset
,
classifier
,
development
set
,
figure
,
experimental
result
,
maximum
performance
,
threshold
,
classifier
,
test
set
,
test
set
,
hwa
etal
,
classifier
,
performance
ofprevious
,
corresponding
test
set
,
previous
,
test
set
,
word
pair
classification
model
,
human
annotated
treebanks
,
performs
,
projecteddependency
parsing
,
credit
,
goodcollaboration
,
word
pair
classification
instance
extraction
,
dependency
projection
,
dependency
parserwe
,
word
pair
classification
,
state
of
the
2nd
ordered
mst
model
,
chart
based
dynamic
programming
parser
,2
nd
ordered
mst
model
,
training
procedure
,
theperceptron
algorithm
,
averaged
parameter
,
wsj
corpus
,
pereira
,
derivationstep
,2
nd
ordered
mst
parser
,
evaluation
score
,
projected
classifier
,
original
mst
,
weighted
summation
,
eval
18uation
score
,
evaluation
,
candidate
par
,
weight
parameter
,
minimum
error
rate
training
algorithm
,2
nd
ordered
mst
parser
,
onc
tb
,
baseline
,
classifier
,
accuracy
improvement
,5
points
,
baseline
,
smallerctb
,
training
set
,
chapter
ofc
tb
,
accuracy
improvement
,
baseline
,
human
annotatedtreebank
,
projecting
classifier
,
promising
strategyfor
,
resource
scarce
language
,
future
worksin
,
intuitionis
tic
method
,
dependency
parsing
,
classifier
,
wordpair
,
dependency
edge
,
proposean
effective
strategy
,
dependency
projection
,
projected
classification
instances
,
parsing
method
,
previous
model
,
theword
pair
classification
instance
extraction
strategy
,
dependency
projection
,
thestate
of
the
,
dependency
,
addition
,2
nd
orderedmst
parser
,
parser
,
significant
improvement
,
baseline
,
forthe
baseline
,
treebanks
,
new
strategy
,
resource
scarce
languages
,
high
precision
dependency
parser
,
performance
onhuman
annotated
treebanks
,
dependency
parsing
method
,
investigation
,
training
method
,
classifier
,
acknowledgementthis
project
,
national
naturalscience
foundation
,
contract
,
state
key
project
,
anonymous
reviewer
,
reviewing
,
valuable
suggestions
,
special
thanks
,
rebeccahwa
,
generous
help
,
experimental
data
,
sharingthe
code
,
alignment
matrix
generation
,
helpful
discussion
,
referencesadam
,
berger
,
maximum
entropyapproach
,
natural
language
processing
,
computational
linguistics
,
carreras
,
mihai
surdeanu
,
lluis
marquez
,
projective
dependency
,
percep
tron
,
proceeding
,
ll
,
carreras
,
dynamic
programming
,
percep
tron
,
feature
parsing
,
proceedings
,
ll
,
charniak
,
johnson
,
coarse
to
fine
grained
n
best
parsing
,
discriminativereranking
,
proceeding
,
new
statistical
parser
basedon
bigram
lexical
dependency
,
proceeding
ofa
cl
,
fornatural
language
parsing
,
proceeding
,
theicml
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceedingsof
,
emn
lp
,
eisner
,
new
probabilistic
models
,
dependency
parsing
,
exploration
,
proceedings
,
kuzman
ganchev
,
gillenwater
,
bentaskar
,
dependency
grammar
induction
,
projection
constraint
,
proceeding
,
the47th
acl
,
liang
huang
,
chiang
,
k
bestparsing
,
proceeding
,
liang
huang
,
reranking
,
nonlocal
feature
,
proceeding
ofthe
acl
,
hwa
,
resnik
,
weinberg
,
andokan
kolak
,
translational
correspondence
,
annotation
projection
,
proceedings
,
hwa
,
resnik
,
weinberg
,
claracabezas
,
okan
kolak
,
bootstrappingparsers
,
syntactic
projection
,
parallel
text
,
natural
language
engineering
,
qun
liu
,
automatic
adaptation
,
annotation
standard
,
dependency
parsingusing
,
treebank
,
source
corpus
,
proceedings
,
liang
huang
,
qun
liu
,
automatic
adaptation
,
annotation
standard
,
chineseword
segmentation
,
po
tagging
,
study
,
inp
roceedings
,47
th
acl
,
klein
,
manning
,
cor
pusbased
induction
,
syntactic
structure
,
model
ofdependency
,
constituency
,
proceeding
,
theacl
,
carreras
,
simple
semi
supervised
dependency
,
proceeding
,
taku
kudo
,
yuji
matsumoto
,
japanese
dependency
structure
analysis
,
support
vectormachines
,
proceeding
,
emn
lp
,
yang
liu
,
tian
xia
,
xinyan
xiao
,
qun
liu
,
alignment
matrix
,
statistical
machinetranslation
,
proceeding
,
emn
lp
,
muyun
yang
,
bilingual
language
model
,
proceedings
,
santorini
,
annmarcinkiewicz
,
large
annotatedcorpus
,
treebank
,
computational
linguistics
,
mcd
onald
,
pereira
,
approximate
dependency
,
proceeding
,
mcd
onald
,
koby
crammer
,
fernandopereira
,
large
margin
training
,
dependency
parser
,
proceeding
,
mcd
onald
,
pereira
,
kiril
ribarov
,
andjan
hajic
,
non
projective
dependency
parsing
,
tree
algorithm
,
proceedingsof
hlt
emn
lp
,
scholz
,
deterministic
dependency
parsing
,
text
,
proceeding
,
thecoling
,
joakim
nivre
,
nilsson
,
gulseneryigit
,
svetoslav
marinov
,
labeledpseudoprojective
dependency
,
supportvector
machine
,
proceeding
,
ll
,
pages221
,
ney
,
improvedstatistical
alignment
model
,
proceeding
,
theacl
,
och
,
minimum
error
rate
,
statistical
machine
translation
,
proceeding
ofthe
acl
,
eisner
,
parser
adaptation
,
projection
,
quasi
synchronous
grammar
feature
,
proceeding
,
emn
lp
,
kiyotaka
uchimoto
,
satoshi
sekine
,
hitoshi
hara
,
japanese
dependency
structure
,
maximum
entropy
model
,
proceedingsof
,
vapnik
,
theory
,
a
w
iley
interscience
publication
,
stochastic
inversion
transductiongrammars
,
bilingual
parsing
,
parallel
corpus
,
computational
linguistics
,
nianwen
xue
,
fei
xia
,
fu
dong
chiou
,
marthapalmer
,
treebank
,
phrasestructure
annotation
,
large
corpus
,
y
m
atsumoto
,
statistical
dependency
analysis
,
support
vector
machine
,
inp
roceedings
,
joint
word
segmentation
,
single
perceptron
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
,
association
,
computational
linguisticsdiscriminative
learning
,
natural
annotation
,
word
segmentation
,
yang
q
un
liu
,
laboratory
,
intelligent
information
processinginstitute
,
computing
technology
,
academy
,
science
jiangwenbin
,
sunmeng
,
academy
,
next
generation
localisationfaculty
,
engineering
,
computing
,
dublin
city
universityqliu
,
provides
natural
annotation
,
nlp
problems
,
word
segmentation
,
parsing
,
discriminative
learning
algorithm
,
advantage
,
linguistic
knowledge
,
largeamounts
,
natural
annotation
,
in
ternet
,
internet
,
externalcorpus
,
slight
andsparse
,
natural
annotation
,
large
scaled
andreal
time
updated
text
,
chineseword
segmentation
,
study
,
experiments
,
segmenter
,
wikipedia
,
significant
improvement
,
series
,
testingsets
,
different
domain
,
asingle
classifier
,
local
feature
,
information
retrieval
,
machinetranslation
,
accurate
text
processing
,
word
segmentation
,
parsing
,
word
segmentation
,
state
of
the
models
,
nakagawa
,
uchimoto
,
zhang
andclark
,
human
annotated
corpus
,
test
set
,
corpus
,
usually
drawn
,
newswire
orfinance
,
annotated
corpus
,
natural
annotation
,
knowledge
,
word
segmentation
,
knowledge
,
dependency
parsingfigure
,
natural
annotation
,
word
segmentation
,
dependency
parsing
,
thousand
,
performance
ofword
segmentation
,
new
domain
,
internet
,
large
amount
,
raw
text
,
andstatistics
,
improve
parsing
performance
,
hearst
,
pitler
,
bansal
,
internet
,
slight
,
sparse
,
natural
annotations
,
structural
information
including
hyperlink
,
layout
,
valuableknowledge
,
problem
,
word
segmentation
,
parsing
,
hypothesis
thatthe
subsequence
,
structural
information
,
meaningful
fragment
,
figure
,
hyperlink
,
phrase
,
subgraph
,
dependency
parsing
,
creator
,
text
give
valuableannotations
,
whole
internet
canbe
,
real
time
updated
corpus
,
different
,
accurate
annotations
,
human
annotated
corpus
,
natural
annotations
,
text
,
nlp
model
,
inthis
,
word
segmentation
,
noveldiscriminative
learning
algorithm
,
theknowledge
,
massive
natural
annotation
,
webtext
,
character
classification
model
,
word
segmentation
,
whole
predictioninto
atomic
prediction
,
character
,
text
,
implausible
predication
candidate
,
related
characters
,
knowledge
,
natural
annotation
,
manner
,
searchingspace
pruning
,
constraint
decoding
,
knowledgeof
,
baseline
model
,
natural
annotation
,
itgives
prediction
,
normal
decoding
,
difference
,
outputs
,
constraint
decoding
,
normal
decodingare
,
enhanced
classifier
,
natural
annotation
,
universal
,
utilization
ofmassive
text
,
extension
,
nlp
problem
,
choice
,
wikipedia
,
knowledge
sourcedue
,
high
quality
,
structural
information
,
including
hyperlink
,
boundary
,
meaningful
fragment
,
experimental
result
,
knowledge
,
natural
annotation
,
baseline
,
f
measure
increment
of0
,
ctb
test
set
,
average
increment
,
domain
,
inexpensive
strategy
,
word
seg
menters
,
different
domain
,
strategy
,
nlp
problem
,
entity
recognition
,
parsing
,
problem
,
word
,
character
classification
model
,
feature
template
,
instance
,
classification
based
word
segmentationmodel
,
suppose
,
representation
,
knowledge
,
natural
annotation
,
text
,
section3
,
strategy
,
natural
annotation
,
after
,
experimental
result
,
analysis
insection
,
previous
relatedwork
,
expectation
,
word
segmentation
,
whole
prediction
,
atomicpredictions
,
single
character
,
natural
annotations
,
text
,
discriminative
training
,
segmentation
model
,
implausible
candidate
,
predictions
,
related
character
,
sequence
,
characters
,
word
segmentation
,
sequence
intom
,
ameaningful
word
,
word
segmentation
,
character
classification
problem
,
xueand
shen
,
character
,
boundary
tag
,
position
,
boundary
tag
,
ngand
low
,
beginning
,
middle
,
single
character
word
,
procedure
search
,
labeled
character
sequence
,
score
func
762algorithm
p
erceptron
training
algorithm
,
output
,
parameter
,
argmaxys
,
whole
sequence
,
character
label
pair
,
featurefunction
,
labeled
sequence
,
character
label
pair
,
parameter
vector
,
sequence
,
problems
,
word
segmentation
,
aviterbi
style
decoding
procedure
,
decoding
algorithm
,
simplicityand
popularity
,
classifier
,
current
character
,
kth
character
,
left
rightof
,
punctuation
character
,
others
,
character
,
letterand
others
,
classifier
,
online
learning
algorithm
,
perceptron
,
learning
model
,
support
vector
machine
,
perceptron
algorithm
,
classifier
,
characterclassification
based
word
segmentation
model
,
discriminative
model
,
output
,
training
corpus
,
result
,
perceptron
algorithm
,
parameter
,
parameter
,
technology
,
original
,
searching
,
shrink
,
natural
annotationsweb
text
,
massive
natural
annotation
,
theform
,
structural
information
,
hyper
links
,
layout
,
sparse
,
annotation
,
knowledge
,
problem
,
wordsegmentation
,
parsing
,
figure
,
bolded
characters
,
hyperlink
,
natural
annotations
,
character
,
boundary
tag
,
head
modifier
relationshipbetween
,
plausible
predication
,
character
,
word
segmentation
,
character
,
therightmost
character
,
character
,
leftmost
character
,
plausible
predication
,
becomes
,
character
,
dependency
parsing
,
subsequence
,
connected
dependency
graph
,
set
ofplausible
head
,
plausible
head
,
wordsin
,
plausible
head
,
each763algorithm
p
erceptron
,
natural
annotations
,
text
give
valuable
structuralannotations
,
annotation
,
predication
uncertainty
,
atomic
characters
,
word
segmentation
,
shrinkof
,
character
classification
based
model
,
decrement
,
uncertaintyindicates
,
increment
,
knowledge
,
wholeinternet
,
wide
coveraged
andreal
time
updated
corpus
,
chinesewikipedia
,
external
knowledge
source
,
andstructural
information
,
hyperlink
,
fontsand
color
,
current
,
natural
annotationsdifferent
,
accurate
annotationsin
human
annotated
corpus
,
natural
annotationsare
sparse
,
slight
,
direct
trainingof
nlp
model
,
annotation
,
structural
information
,
exact
predication
,
character
,
implausible
predication
candidatesfor
related
character
,
previoussection
,
previous
,
constituency
,
machine
translation
,
resort
,
kind
ofheuristic
trick
,
punctuation
restriction
,
implausible
candidate
,
natural
annotation
,
manner
,
space
pruning
,
completeness
,
decoding
algorithm
,
existing
corpus
,
notworse
predication
,
constraint
decoding
,
constraint
decodingprocedure
,
knowledge
,
baselinealgorithm
o
nline
version
,
perceptron
learning
,
natural
annotation
,
natural
annotation
do3
,
output
,
regular
timemodel
,
natural
annotation
,
predication
differences
,
output
,
constraint
decoding
,
normal
decoding
,
theenhanced
classifier
,
restriction
,
tonatural
annotation
,
intothe
decoder
,
completeness
,
searchingalgorithm
,
constraint
decoding
,
predications
,
normaldecoding
,
predication
,
constraint
decodingdiffers
,
normal
decoding
,
annotation
precision
,
latter
,
degree
,
difference
betweenthe
,
predication
,
amount
,
newknowledge
,
baseline
,
baseline
model
,
existing
human
annotated
corpus
,
sentencesf
,
natural
annotation
,
thechinese
wikipedia
,
one
forwhich
constraint
decoding
,
normal
decodinggive
different
predication
,
prediction
,
constraint
decoding
,
usedas
additional
training
data
,
enhanced
classifier
,
overall
training
pipeline
,
pseudo
codes
,
onlinecharacteristic
,
perceptron
algorithm
,
chinesewikipedia
,
natural
annotation
,
onlineversion
,
procedure
,
algorithm3
,
choice
,
technology
,
averaged
parameter
,
ollins
,
constraint
decoding
,
normal
decoding
give
different
predication
,
explicit
evidence
,
much
difference
,
the764partition
,
predication
,
muchnew
knowledge
,
sentencebrings
,
predication
,
difference
,
degree
,
current
modelmistakes
,
indicator
,
morevaluable
training
,
strategy
,
natural
annotations
,
situation
,
phrase
,
medicine
andchemical
,
large
amountof
raw
text
,
simple
andeffective
domain
adaptation
strategy
,
alreadytrained
model
,
treebank
,
corpus
,
word
segmentation
,
convenient
,
comparison
,
word
segmentation
,
whole
corpus
,
partitions
,
chapter
,
chapter
,
others
,
external
knowledge
source
,
high
quality
,
content
,
usual
text
,
structural
informations
,
hyperlink
,
annotation
information
,
improvement
,
fuzzy
knowledge
,
wikipedia
,
aseries
,
different
domain
,
hanb
akeoff
,
theyare
drawn
,
domain
,
literature
,
finance
,
computer
science
,
medicine
,
reference
set
,
different1http
,
download
,
wikimedia
,
org
backup
index
,10
a
ccuracy
,
training
iterationsfigure
,
learning
curve
,
averaged
percep
tron
classifier
,
ctb
developing
,
word
segmentation
standard
,
thequantity
,
accuracy
improvement
,
vast
diversity
,
thetwo
segmentation
standard
,
domain
,
chemistry
,
physic
,
machinery
,
wordsegmentationwe
,
baseline
perceptron
classifier
forword
segmentation
,
training
set
,
developing
,
training
iteration
,
performance
measurement
,
word
segmentation
,
f
measure
,
function
,
precision
,
ofwords
,
segmentation
result
,
segmented
word
,
gold
standard
word
,
figure
,
averaged
perceptron
,
developing
,
second
column
,
performance
ofthe
baseline
classifier
,
wherenewswire
,
ctb
itself
,
performs
,
thedomains
,
chemistry
,
physic
,
machinery
,
importance
,
domain
adaptation
forword
segmentation
,
ma
andway
,
ba
keoff
,
difference
,
domain
,
segmentation
standard
,
baseline
classifier
andthe
classifier
,
natural
annotation
,
hinese
wikipedia
,
naturalannotationsthe
wikipedia
,
millionitems
,
description
text
,
millions
,
natural
annotation
,
ctb
training
,
existing
corpus
,
algorithm
,
segmentations
,
constraint
decoding
,
additional
training
data
,
enhanced
classifier
,
previous
description
,
difference
,
constraint
,
andnormal
decoding
,
indicatesthe
importance
,
constraint
segmentation
,
theimprovement
,
baseline
classifier
,
constraint
segmentation
,
difference
,
constraint
,
andnormal
decoding
,
fromthe
beginning
,
sorted
list
,
different
amountsof
,
additionaltraining
data
,
enhanced
character
classifier
,
figure
,
performance
curve
,
enhanced
classifier
,
moreadditional
training
data
,
continuousimprovement
,
related
,
self
training
,
segmentation
,
similar
trend
,
moderate
amount
,
raw
data
,
obviousimprovements
,
classifier
,
third
column
,
sentences10000
,
sentencesfigure
,
performance
curve
,
different
scale
,
kruengkrai
,
comparison
,
state
of
the
hinese
word
segmentation
,
f
measure
increment
,
improvements
,
domain
,
distribution
,
knowledge
,
ctb
training
data
,
inthe
domain
,
newswire
,
content
,
broad
range
,
domains
,
knowledge
complementary
tothat
,
comparison
,
otherwork
,
word
segmentation
,
modelachieves
,
thestate
of
the
model
,
single
classifier
,
localfeatures
,
viewpoint
,
resource
utilization
,
comparison
,
system
andprevious
,
additional
trainingdata
,
interesting
,
chi
nese
word
segmentation
,
utilization
,
sparse
knowledge
,
internetrather
,
full
use
,
specific
human
annotated
corpus
,
onlya
single
classifier
,
local
feature
,
inour
method
,
system
combination
,
semi
supervised
technology
,
internet
,
strategy
,
word
segmenter
,
domain
,
workli
,
character
classification
instance
,
raw
text
,
wordsegmentation
,
indication
,
punctuation
,
character
,
large
scaled
unlabeled
text
,
chi
nese
word
segmentation
,
workalso
,
large
scaled
raw
text
,
methodis
,
aspectsof
,
source
,
knowledge
,
learningstrategy
,
effort
,
semi
supervised
method
,
sequence
labeling
,
wordsegmentation
,
suzuki
,
isozaki
,
haffari
,
sarkar
,
tomanek
andhahn
,
optimal
hyperplane
,
raw
data
,
toresult
,
coverage
,
higheraccuracy
,
researcher
,
unsupervised
method
,
word
segmentation
,
zhaoand
,
johnson
,
goldwater
,
mochihashi
,
hewlett
,
latentdistribution
regularity
,
raw
text
,
induces
word
segmentation
,
method
,
large
amount
ofexternal
data
,
knowledge
,
sparse
annotation
,
semi
supervised
andunsupervised
method
,
different
kind
,
knowledge
,
natural
annotation
,
structural
information
,
text
,
year
,
much
,
tothe
improvement
,
word
segmentation
,
variety
,
typical
approach
,
global
training
,
features
,
investigation
,
word
internal
structure
,
adjustment
,
adaptation
,
word
segmentation
standard
,
integratedsolution
,
segmentation
,
related
task
aspart
of
speech
tagging
,
parsing
,
gold
berg
,
tsarfaty
,
strategy
,
modeling
,
nakagawa
,
uchi
moto
,
kruengkrai
,
parsing
,
pereira
,
schabes
,
extended
inside
outside
algorithm
thatinfers
,
parameter
,
stochastic
cfg
,
treebank
,
partial
bracketing
information
,
parsing
,
itscomputational
complexity
,
impractical
formassive
natural
annotation
,
text
,
thereare
,
word
occurrencestatistics
,
raw
text
,
internet
n
gramsto
improve
parsing
performance
,
pitler
,
bansal
,
related
,
dependency
parsing
,
spitkovsky
,
constraint
,
hypertextannotations
,
unsupervised
dependency
grammar
induction
,
theirmethod
,
strategy
,
formal
anduniversal
,
discriminative
learning
strategy
,
quantitative
measurement
,
effective
utilization
,
natural
annotation
,
internet
,
future
workthis
,
novel
discriminative
learningalgorithm
,
knowledge
,
massivenatural
annotation
,
internet
,
natural
annotations
,
structural
information
,
classifier
,
constraint
decoding
,
pruned
searching
space
,
prediction
,
normal
decoding
,
annotation
,
output
,
constraint
decoding
,
normal
decoding
,
enhanced
classifier
,
linguistic
knowledge
,
human
annotatedcorpus
,
natural
annotation
,
textare
,
chi
nese
word
segmentation
show
,
enhancedword
segmenter
,
different
domain
,
single
classifier
,
local
feature
,
content
,
text
cover
,
broadrange
,
domain
,
human
annotated
corpus
,
distribution
,
domain
,
contenton
,
internet
,
drawback
,
expensive
building
,
updating
,
corpus
,
moredomain
adaptive
,
future
,
method
,
better
illustrate
,
importance
,
boundary
information
,
error
analysis
,
errors
,
method
,
investigation
,
efficient
algorithm
,
massive
text
,
natural
annotation
,
strategy
,
nlp
problem
asnamed
entity
recognition
,
parsing
,
acknowledgmentsthe
author
,
nationalnatural
science
foundation
,
contracts
,
science
foundation
,
ce
i1142
,
partof
,
dublin
city
,
sincerethanks
,
anonymous
reviewer
,
reviewing
,
valuable
suggestion
referencesmohit
bansal
,
klein
,
scale
features
,
full
scale
parsing
,
proceeding
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
proceedingsof
emn
lp
,
ngai
,
yongsheng
yang
,
feng
,
maximum
entropy
chineseparser
,
transformation
based
learning
,
proceeding
,
tal
ip
,
jianfeng
gao
,
haowei
qin
,
adaptive
word
segmentation
,
proceedings
,
jianfeng
gao
,
chang
ninghuang
,
word
segmentation
,
entity
recognition
,
pragmatic
approach
,
computational
linguistics
,
wenjun
gao
,
xipeng
qiu
,
adaptive
word
segmentation
,
onlinepassive
aggressive
algorithm
,
proceeding
ofc
ips
sighan
workshop
,
yoav
goldberg
,
reut
tsarfaty
,
single
generative
model
,
joint
morphological
segmentationand
syntactic
parsing
,
proceeding
,
acl
hlt
,
gholamreza
haffari
,
anoop
sarkar
,
homotopy
based
semi
supervised
hidden
markovmodels
,
sequence
labeling
,
hewlett
,
cohen
,
unsupervised
word
segmentation
,
inp
roceedings
,
wenbin
jiang
,
liang
huang
,
qun
liu
,
cascaded
linear
model
,
joint
chineseword
segmentation
,
part
of
speech
tagging
,
inp
roceedings
,
wenbin
jiang
,
liang
huang
,
qun
liu
,
automatic
adaptation
,
annotation
standard
,
chineseword
segmentation
,
po
tagging
,
study
,
inp
roceedings
,47
th
acl
,
johnson
,
goldwater
,
improving
nonparameteric
bayesian
inference
,
experimentson
unsupervised
word
segmentation
,
adaptorgrammars
,
proceeding
,
naa
cl
,
canasai
kruengkrai
,
kiyotaka
uchimoto
,
ichikazama
,
yiou
,
kentaro
torisawa
,
hitoshiisahara
,
error
driven
word
character
hybrid
model
,
joint
word
segmentation
,
proceeding
,
maosong
sun
,
punctuation
asimplicit
annotation
,
word
segmentation
,
computational
linguistics
,
zhongguo
,
internal
structure
ofwords
,
new
paradigm
,
word
segmentation
,
proceeding
,
yang
liu
,
yue
zhang
,
domainadaptation
,
joint
segmentation
,
pos
tagging
,
proceeding
,
bilingually
motivated
domain
adapted
word
segmentation
,
statistical
machine
translation
,
proceeding
,
charniak
,
effective
self
training
,
inp
roceedings
,
hlt
naa
cl
,
daichi
mochihashi
,
takeshi
yamada
,
naonoriueda
,
bayesian
unsupervised
word
segmentation
,
nested
pitman
yor
language
modeling
,
proceeding
,
kiyotaka
uchimoto
,
ahybrid
approach
,
word
segmentation
,
po
tagging
,
proceeding
,
preslav
nakov
,
hearst
,
implicit
training
,
application
,
structural
ambiguity
resolution
,
proceeding
,
hlt
emn
lp
,
tou
ng
,
jin
kiat
low
,
part
of
speech
tagging
,
all
at
once
,
proceeding
ofe
mnlp
,
pereira
,
schabes
,
inside
outside
reestimation
,
corpora
,
proceeding
,
pitler
,
bergsma
,
dekang
,
neth
church
,
scale
n
grams
toimprove
base
np
parsing
performance
,
proceedings
,
spitkovsky
,
jurafsky
,
hiyan
shawi
,
hyper
textannotations
,
guided
parsing
,
proceeding
ofa
cl
,
weiwei
sun
,
chineseword
segmentation
,
unlabeled
data
,
proceedings
,
emn
lp
,
maosong
sun
,
natural
language
,
resource
,
stacked
sub
word
model
forjoint
word
segmentation
,
part
of
speechtagging
,
proceeding
,
suzuki
,
hideki
isozaki
,
semi
supervisedsequential
labeling
,
segmentation
,
giga
word
scale
unlabeled
data
,
proceeding
,
katrin
tomanek
,
udo
hahn
,
semi
supervised
active
learning
,
sequence
labeling
,
inp
roceedings
,
kun
,
chengqing
zong
,
character
based
joint
model
,
word
segmentation
,
proceeding
,
ichi
kazama
,
yoshimasa
tsuruoka
,
wenliang
,
yujie
zhang
,
kentaro
sawa
,
word
segmentationand
po
,
semi
supervised
method
using
large
auto
analyzed
data
,
proceeding
,
ijc
nlp
,
customizable
segmentation
,
computational
linguistics
,
language
processing
,
toutanova
,
her
mann
ney
,
bayesian
semi
supervised
chineseword
segmentation
,
statistical
machine
translation
,
proceeding
,
libin
shen
,
wordsegmentation
,
lmr
tagging
,
proceeding
ofs
ighan
workshop
,
nianwen
xue
,
fei
xia
,
fu
dong
chiou
,
marthapalmer
,
treebank
,
phrasestructure
annotation
,
large
corpus
,
naturallanguage
engineering
,
huimingduan
,
shiyong
kang
,
honglin
sun
,
hui
,
qiang
zhao
,
weidong
zhan
,
processingnorms
,
modern
corpus
,
technical
report
,
yue
zhang
,
segmentation
,
word
based
perceptron
algorithm
,
proceeding
,
yue
zhang
,
fast
decoderfor
joint
word
segmentation
,
pos
tagging
usinga
single
discriminative
model
,
proceeding
ofe
mnlp
,
huaping
zhang
,
qunliu
,
hhmm
based
lexical
analyzerictclas
,
proceeding
,
workshop
,
hai
zhao
,
chunyu
,
unsupervisedsegmentation
,
learning
,
character
tagging
,
word
segmentation
,
entityrecognition
,
proceeding
,
workshop
,
hongmei
zhao
,
qun
liu
,
word
segmentation
bakeoff
,
inp
roceedings
,
cip
s
sighan
workshop
,
hai
zhao
,
character
level
dependency
,
usefulness
,
learning
,
efficient
analyser
integrating
word
segmentation
,
part
ofspeech
tagging
,
partial
parsing
,
full
parsing
,
inp
roceedings
,
workshop
,
guangyou
zhou
,
zhao
,
kang
liu
,
li
cai
,
derived
selectional
preference
,
statistical
dependency
,
inp
roceedings
,
annual
meeting
,
association
,
computational
linguistics
,
association
,
computational
linguisticsbilingually
guided
monolingual
dependency
grammar
inductionkai
liu
,
laboratory
,
intelligent
information
processinginstitute
,
computing
technology
,
academy
,
sciencesp
,
beijing
,
liukai
,
lvyajuan
,
jiangwenbin
,
next
generation
localisationfaculty
,
engineering
,
computing
,
dublin
city
universityqliu
,
academy
,
sciencesabstractthis
paper
,
novel
strategy
forautomatic
induction
,
monolingual
dependency
grammar
,
guidanceof
bilingually
projected
dependency
,
dependency
information
,
parsed
counterpart
language
,
underlying
syntactic
structure
ofthe
language
,
advantage
,
bilingual
projection
,
unsupervised
induction
,
monolingual
grammar
muchbetter
,
previous
model
,
usingbilingual
projection
,
unsupervised
induction
,
dependency
grammar
,
different
language
,
theguidance
,
dependency
information
,
parsed
translation
,
bilingually
guided
method
,
significantimprovement
,
unsupervised
baseline
,
projection
baseline
,
decade
,
method
,
constituency
parsing
,
charniak
,
johnson
,
petrov
,
dependency
,
human
annotated
corporaon
,
alternative
strategies
,
method
,
raw
text
,
unsupervised
methods
,
raw
text
,
manning
,
eisner
,
etal
,
semi
supervised
method
,
etal
,
raw
text
,
annotated
corpus
,
effort
,
bilingual
projection
,
language
,
project
,
syntactic
information
,
parsed
language
,
unparsed
one
,
ganchev
,
dependency
grammar
induction
,
unsupervised
method
,
continuous
improvementsin
year
,
manning
,
smithand
eisner
,
spitkovsky
,
predefineddistributional
assumption
,
approximate
indicator
,
entropy
,
likelihood
,
unsupervised
model
,
fromtwo
drawback
,
higher
computational
cost
,
bilingual
projection
,
eis
ner
,
promising
substitute
,
language
,
alarge
amount
,
existing
parser
,
counterpart
language
,
projecting
syntactic
structure
,
eisner
,
bilingual
text
,
multilingual
text
,
snyder
,
naseem
,
dependency
grammar
,
syntacticisomorphism
,
targetand
source
language
,
induction
,
bilingual
projection
run
,
different
principle
,
former
mine
,
underlying
structure
,
themonolingual
language
,
latter
leveragesthe
syntactic
knowledge
,
parsed
counter
1063bilingual
corpus
joint
optimizationbilingually
guidedparsing
projectionfigure
,
bilingually
guided
parsing
model
,
iteration
,
part
language
,
anovel
strategy
,
monolingual
dependency
grammar
,
guidanceof
bilingually
projected
dependency
information
,
advantage
,
bilingual
projection
,
unsupervised
framework
,
arandomly
initialized
monolingual
treebankevolves
,
self
training
iterative
procedure
,
andthe
grammar
parameter
,
monolingual
likelihoodand
bilingually
projected
likelihood
,
evolving
treebank
,
monolingual
likelihood
,
optimization
objective
,
conventional
unsupervised
model
,
bilingually
projected
likelihood
,
product
,
projectedprobabilities
,
dependency
tree
,
dependency
information
,
parsed
counterpart
language
,
underlying
syntactic
structure
,
language
,
monolingual
dependency
grammarwhich
,
previous
model
,
bilingual
projection
,
unsupervised
induction
,
addition
,
likelihood
,
dependency
edge
,
ofthe
hypothesis
tree
,
computational
complexity
approach
,
unsupervised
model
,
convergence
,
finalautomatically
induced
dependency
,
model
,
language
,
experimental
result
,
method
,
previous
,
unsupervised
method
,
indirect
direct
dependency
projection
,
seean
average
improvement
,
unsupervised
baseline
,
language
,
improvements
,
indirect
direct
baselines
,
significant
gain
,
improvementsare
,
direct
projection
baseline
,
unsupervised
dependency
grammar
induction
framework
,
unsupervised
optimization
objective
,
thebilingual
projection
method
,
dependency
parsing
,
optimization
objective
,
wepresent
,
bilingually
guided
induction
strategyfor
dependency
grammar
,
objectives
,
brief
,
previous
,
experimental
result
,
workin
,
unsupervised
training
algorithmwhich
,
framework
,
bilingually
guided
method
,
previous
unsupervisedwork
,
manning
,
eis
ner
,
self
trainingapproach
,
method
,
unsupervised
model
,
framework
ofour
unsupervised
model
,
random
,
monolingual
corpus
,
initializationand
train
,
discriminative
parsing
model
,
parser
,
evolved
tree
bank
,
best
result
,
next
iterationrun
,
parser
,
treebank
,
inan
iterative
,
convergence
,
define
,
ith
word
,
word
pair
dependency
relationship
,
word
pair
deij
,
category
,
relationship
,
probability
,
wordpair
deij
,
dependency
arc
,
contrary
,
weight
,
dependency
treeis
,
dependency
tree
de
,
objectivewe
,
simple
classifier
objective
function
asthe
unsupervised
objective
function
,
accordance
,
monolingual
corpus
,
treebank
,
corpus
,
denotes
,
possible
dependency
arc
,
treebank
,
empirical
value
,
impact
,
huge
number
,
unsupervised
model1
,
repeat4
,
convergencebush
,
figure
,
hinese
dependency
treeto
side
,
solid
arrowsare
,
dependency
arc
,
dependency
arc
,
unsupervised
training
inits
entirety
,
treebank
de
,
unsupervised
parsing
model
,
random
treebank
de
,
monolingual
corpus
,
parsingmodel
,
training
proceduretrain
,
classification
instance
,
unsupervised
model
,
self
training
iterative
procedure
,
e
step
,
algorithm
,
calculates
,
expectation
,
best
tree
,
objective
,
formula
,
byparsing
process
parse
,
treebank
,
m
step
,
whole
treebank
,
unsupervised
objective
,
formula
,
training
procedure
,
bilingual
projection
,
dependencygrammarin
,
projection
,
training
algorithm
,
modelwith
arc
instance
,
heterogeneity
,
different
language
,
word
alignment
error
,
projection
method
,
takefigure
,
directprojection
algorithm
,
dependency
relationship
betweenwords
,
source1065algorithm
t
,
projection
,
repeat
,
maximizationlanguage
,
target
language
,
treebank
,
direct
projection
,
projecteddiscrete
dependency
arc
instance
,
training
set
,
projected
grammar
induction
model
,
objective
,
positive
dependency
arc
instanceset
,
direct
projection
method
,
training
procedure
,
iterativesteps
,
algorithm
,
training
stepof
projection
model
,
instance
,
algorithm
,
bilingual
corpus
,
alignment
,
function
grad
,
objective
,
generic
optimization
step
,
asan
lbf
g
iteration
,
subroutine
climb
,
bilingually
guided
grammar
induction
model
,
unsupervised
framework
,
bilingual
projection
,
joint
approach
,
observation
,
unsupervised
induction
model
mine
,
syntacticstructure
,
monolingual
language
,
good
grammar
induction
,
exponential
parsing
space
,
bilingual
projection
obtains
,
reliable
syntactic
knowledge
,
theparsed
counterpart
,
figure
,
unsupervised
model
,
projection
model
,
joint
model
,
better
use
,
unsupervised
parse
tree
,
projected
dependency
arc
,
parser
,
novel
strategy
,
monolingual
grammar
induction
model
,
guidance
,
bilingually
projected
dependency
information
,
figure
,
bilingual
guidedgrammar
induction
process
,
entirety
,
ourmethod
,
compatible
objective
,
projection
model
,
theycan
share
,
grammar
parameter
,
thenwe
incorporate
projection
model
,
iterativeunsupervised
framework
,
projection
objective
,
evolving
treebank
,
constant
projection
,
bilingually
guidedmodel
,
parameter
,
monolingual
likelihood
andbilingually
projected
likelihood
,
randomly
,
treebank
,
target
sentencesfor
initialization
,
projected
arc
instances
,
projection
,
bitext
,
bilingually
guided
grammar
induction
model
,
multi
objective
optimizationmethod
,
projection
objective
,
treebank
,
projectedarc
instance
,
parsing
model
,
new
treebankon
target
language
,
next
iteration
,
repeat
,
convergence
,
unsupervised
objective
,
theloop
,
tree
bank
,
projection
constraint
,
parse
tree
,
information
,
projection
part
,
projection
,
circulation
,
projectedinstances
,
instances
,
iterative
procedure
,
aco
training
algorithm
,
sarkar
,
projection
,
classical
weighted
sum
approach
whichjust
,
weighted
linear
sum
,
mweightmobjm
,
unsupervised
objective
,
projection
objective
,
weight
sum
objective
,
mixing
coefficient
,
relativeconfidence
,
projection
objective
,
weight
,
single
parameter
,
weightsfor
different
objective
function
,
unsupervised
objective
function
,
projection
objective
function
,
instance
,
mixedparsing
model
,
objective
,
function
,
interpolation
function
,
traininginstead
,
parsing
procedure
,
ourmethod
,
probability
,
dependencyarc
,
interpolating
method
,
probabilities
,
different
model
,
algorithmwe
,
objective
,
agradient
based
search
algorithm
,
respect
,
outline
,
joint
training
procedure
,
grammar
parameter
,
unsupervised
objectivealgorithm
t
,
joint
model1
,
convergenceand
projection
objective
,
unsupervised
framework
,
projection
model
,
unsupervised
model
,
berg
kirkpatrick
,
dependency
instances
,
source
side
,
projection
method
,
random
treebank
,
initial
model
,
projectioninstances
,
generic
optimization
step
,
thesubroutine
climb
,
dependency
tree
,
tree
intothe
treebank
,
gradient
,
treebank
,
instance
,
e
step
,
theem
algorithm
,
line
,
workthe
dmv
,
manning
,
single
state
head
automaton
model
,
alshawi
,
pos
tag
,
inside
outside
re
estimation
,
smoothing
,
spitkovsky
,
grammar
learning
,
context
,
dependency
projection
method
dpa
,
direct
correspondenceassumption
,
source
word
,
dependency
relationship
,
corresponding
alignedwords
,
having
,
figure
,
method
,
modifies
,
method
,
smithand
eisner
,
adaptation
,
quasi
synchronous
grammar
features1067type
feature
templateunigram
wordi
posi
wordi
,
posiwordj
posj
wordj
,
posjbigram
wordi
,
posj
wordj
,
posi
posi
,
posjwordi
,
wordj
wordi
,
wordj
wordi
,
posjwordi
,
posj
posi
,
posjwordi
,
posj
posi
,
dependency
parsing
,
edge
deij
,
parent
word
,
child
word
,
dependency
projection
,
annotation
,
small
set
,
dependency
,
corpus
,
target
language
,
indirect
information
,
effective
,
resnik
,
non
lexicalizedparser
,
language
,
atarget
language
,
onald
et
,
multi
source
parser
,
selective
sharingmodel
,
grammar
informationin
multi
sources
,
similar
reason
,
many
,
devotedto
pos
projection
,
yarowsky
,
shen
etal
,
naseem
,
similar
problem
,
naseem
,
projection
,
graph
based
projection
,
petrov
,
model
differs
,
emphasis
,
information
,
bothsides
,
bilingual
corpus
,
unsupervised
training
framework
,
information
,
bilingually
guided
modelon
,
language
,
experiments
,
evaluation
,
different
language
,
free
data
,
ll
shared
task
,
buchholz
,
language
,
target
parallel
data
,
fbi
s
en
glish
bitext
,
bilingual
corpus
,
dependency
projectionwhich
,
about8
,
readily
,
corpus
,
ll
x
testsets
,
implementations
,
pos
tagger
,
implementation
,2
nd
ordered
mst
model
,
mcd
onald
,
pereira
,
dependency
tree
,
penntreebank
,
evaluation
,
correct
parent
,
onsentences
,
length
,
method
,
regime
,
theprojection
method
,
projection
instance
,
projection
part
,
initialization
,
whole
model
,
availing
,
initialization
method
,
modelcan
converge
,
iteration
,
result
,
random
initialization
,
method
againstthree
kind
,
different
approach
,
unsupervisedmethod
,
manning
,
single
source
direct
projection
method
,
multi
source
indirect
projection
method
,
multi
sources
,
m
,
accuracy
nl70
,
alphasvfigure
,
series
,
naseem
,
resultswe
,
method
,
data
set
,
figure
,
different
language
,
compare
,
baseline
experimental
result
,
unsupervisedframework
,
performance
approach
,
dmv
method
,
bilingually
guided
model
,
unsupervised
method
consistency
,
language
,
result
,
average
,
comparable
language
,
promotion
,
manning
,
compare
,
projection
baseline
forall
,
model
consistently
outperforms
,
direct
projection
baseline
,
average
,
language
,
result
,
ourmodel
outperforms
,
baseline
,
yielding3
,
single
source
direct
projectionmethod
,
gain
overthe
multi
source
indirect
projection
method
,
mc
,
average
,
different
parameter
,
method
,
improvement
,
baseline
,
significant
gain
,
improvementsare
,
direct
indirect
projection
base
accuracy
model
ch
da
nl
pt
sv
avgdmv
,
directed
dependency
accuracy
withdifferent
parameter
,
baselines
,
first
,
result
,
baseline
,
unsupervisedmethod
baseline
,
manning
,
single
source
projection
method
baseline
,
improvement
,
transfer
,
naseem
,
present
theresult
,
unsupervised
framework
,
third
,
mean
value
,
figure
,
removal
,
punctuation
,
incomparable
result
,
result
,
figure
,
unsupervised
framework
,
grammarinduction
,
good
start
,
initialization
,
information
,
projection
side
,
projection
information
,
unsupervised
framework
,
projection
model
,
initialization
,
parameter
,
performance
curve
,
fluctuation
,
situation
,
effect
,
training
corpusto
,
training
,
result
,
extracted
bilingual
corpus
,
figure
,
setour
modelbaselinefigure
,
language
,
rateour
modelbaselinefigure
,
different
projectionquality
,
average
,
language
,
instances
,
baseline
,
increasingsize
,
corpus
,
training
data
,
ourmethod
,
projection
information
,
monolingual
corpus
,
projection
qualitythe
projection
quality
,
thequality
,
source
parsing
,
alignment
,
projection
method
,
quality
,
many
factors
,
effect
,
projection
quality
,
thecomplex
projection
procedure
,
theprojected
instance
,
different
noiserates
,
figure
,
wpc
baseline
,
bilingual
guidedmethod
,
different
noise
rate
,
results
,
baseline
,
whenthe
noise
rate
,
figure
,
performance
curve
,
random
initialization
,
respect
toa
series
,
result
ofw
pc
model
,
increase
,
growth
,
noise
rate
,
method
,
problems
,
projection
noise
,
random
initializationwe
,
figure
,
result
,
unsupervisedoptimization
method
,
unsupervised
structureinformation
,
negative
effect
,
unsupervised
part
,
projection
part
,
strength
,
constraint
dwindles
,
control
,
andbad
unsupervised
part
,
full
model
,
future
workthis
paper
,
bilingually
guided
strategy
,
automatic
dependency
grammar
induction
,
unsupervised
skeleton
,
bilingually
projected
dependency
information
,
optimization
,
monolingual
likelihood
andbilingually
projected
likelihood
,
procedure
,
advantage
ofbilingual
projection
,
unsupervised
induction
,
language
,
novelstrategy
,
bilingually
projected
model
,
computational
complexity
,
tothe
skeleton
unsupervised
model
,
much
fewer
iteration
,
bilingual
text
,
to1070resource
language
,
ahybrid
method
,
choice
,
automatic
grammar
induction
,
thatthe
combination
,
bilingual
constraint
,
unsupervised
methodology
,
promising
prospectfor
grammar
induction
,
future
,
strategy
,
unsupervised
induction
,
acknowledgmentsthe
author
,
nationalnatural
science
foundation
,
contracts
,
knowledge
innovation
program
,
chi
nese
academy
,
qun
liu
,
sciencefoundation
,
ce
i1142
,
aspart
,
dublin
city
,
anonymous
reviewer
,
insightful
comment
,
referencesh
,
alshawi
,
head
automaton
,
speech
translation
,
ics
lp
,
k
baker
,
trainable
grammar
,
speechrecognition
,
journal
,
acoustical
societyof
,
unsupervised
learning
,
rens
bod
,
all
subtrees
approach
,
unsupervised
parsing
,
the44th
acl
,
buchholz
,
taskon
multilingual
dependency
,
the2002
conference
,
emn
lp
,
ll
,
charniak
,
johnson
,
coarse
to
fine
n
best
parsing
,
maxent
discriminative
r
eranking
,
arbor
,
torisawa
,
bi
text
dependency
,
bilingual
subtree
constraints
,
unsupervised
structure
prediction
,
nonparallel
multilingual
guidance
,
conference
one
mnlp
,
discriminative
training
methods
,
hidden
markov
model
,
theory
,
experiments
,
perceptron
algorithm
,
the2002
conference
,
emn
lp
,
head
driven
statistical
models
,
natural
language
parsing
,
computationallinguistics
,
petrov
,
part
of
speech
tagging
,
bilingual
graph
based
projections
,
taskar
,
dependency
grammar
induction
,
bitext
projectionconstraints
,
ijc
nlp
,
afn
lp
,
volume
volume
,
translational
correspondence
,
annotation
projection
,
steedman
,
training
,
statistical
parser
,
icm
l
workshop
,
continuum
,
labeled
,
unlabeled
data
,
machine
learning
anddata
mining
,
parser
,
syntacticprojection
,
parallel
text
,
natural
languageengineering
,
dependency
parsingand
projection
,
word
pair
classification
,
inp
roc
,
manning
,
corpus
based
induction
,
syntactic
structure
,
constituency
,
efficient
third
order
dependency
parser
,
simplesemi
supervised
dependency
,
pereira
,
online
learningof
approximate
dependency
,
algorithm
,
inp
roc
,
crammer
,
pereira
,
on
line
large
margin
training
,
dependency
parser
,
inp
roc
,
non
projective
dependency
,
spanning
tree
algorithm
,
emn
lp
,
pages523
,
pereira
,
multilingual
dependency
analysis
,
two
stage
discriminative
parser
,
ll
,
multi
source
transfer
,
delexicalized
dependency
parser
,
emn
lp
,
barzilay
,
multilingual
part
of
speech
tagging
,
unsupervised
approach
,
journal
,
artificial
intelligence
research
,
tahira
naseem
,
barzilay
,
amir
globerson
,
selective
sharing
,
multilingual
dependencyparsing
,50
th
acl
,
pseudo
projective
dependencyparsing
,
support
vector
machine
,
ofc
onll
,
malt
parser
,
language
independent
system
,
data
driven
dependency
parsing
,
natural
language
engineering
,
slav
petrov
,
thibaux
,
danklein
,
interpretable
tree
annotation
,
sarkar
,
training
method
,
statistical
parsing
,
naa
cl
,
learningfor
bidirectional
sequence
classification
,
annualmeeting
,
eisner
,
contrastive
estimation
,
training
log
linear
model
,
unlabeled
data
,
eisner
,
parser
adaptation
,
projection
,
quasi
synchronous
grammar
feature
,
emn
lp
,
volume
v
olume2
,
barzilay
,
unsupervised
multilingual
grammar
induction
,
ijc
nlp
,
afn
lp
,
volume
volume
,
data
point
selection
,
cross
language
adaptation
,
dependency
parser
,
spitkovsky
,
hiyan
alshawi
,
ju
rafsky
,
baby
step
,
unsupervised
dependency
,
ckstro
,
uszkoreit
,
cross
lingual
word
cluster
,
direct
transfer
,
linguistic
structure
,
mcc
losky
,
improving
unsupervised
dependency
,
richer
context
,
smoothing
,
naa
cl
,
multilingual
text
analysis
tool
,
robustprojection
,
corpus
,
resnik
,
cross
language
parser
adaptation
,
related
languages
,
ijc
nlp
,
ll
,
ciyou
zhu
,
h
b
yrd
,
jorgenocedal
,
fortransubroutines
,
annual
meeting
,
association
,
computational
linguistics
,
association
,
computational
linguisticsiterative
transformation
,
annotation
guideline
forconstituency
parsingxiang
li
,
laboratory
,
intelligent
information
processinginstitute
,
computing
technology
,
academy
,
science
lixiang
,
jiangwenbin
,
academy
,
next
generation
localisationfaculty
,
engineering
,
computing
,
dublin
city
universityqliu
,
bstractthis
paper
,
effective
algorithm
,
annotation
adaptation
,
constituency
treebanks
,
treebankfrom
,
annotation
guideline
,
another
,
iterative
optimization
procedure
,
treebankto
,
enhanced
parser
,
increasing
model
complexity
,
experimentsshow
,
transformed
tsinghua
chi
nese
treebank
,
additional
training
data
brings
significant
improvement
,
thebaseline
,
tree
bank
,
indispensableresource
,
application
,
amount
,
otherhand
,
incompatible
annotation
guideline
,
thesame
nlp
task
,
segmentation
,
available
treebank
,
resource
forsyntactic
parsing
,
key
bottleneck
,
credible
treebanks
,
various
tree
banks
,
different
annotation
guideline
,
addition
,
mostpopular
ctb
,
real
large
scale
tree
bank
,
constituent
,
figure
,
difference
,
grammar
category
,
syntactic
structure
,
heterogeneous
treebanks
,
parsingmodel
,
divergence
,
great
waste
ofhuman
effort
,
desirable
totransform
,
treebank
,
compatible
withanother
annotation
guideline
,
heterogeneous
treebanks
,
effective
approach
toautomatic
treebank
transformation
,
annotation
guideline
,
convenienceof
reference
,
treebank
,
desired
annotation
guideline
,
target
treebank
,
treebank
,
differtn
annotation
guideline
,
source
treebank
,
approach
proceedsin
,
parser
,
sourcetreebank
,
raw
sentencesof
target
treebank
,
heterogeneous
annotation
guideline
,
annotation
transformer
,
theparallel
training
data
,
annotation
inconsistencies
,
last
step
,
parser
,
ontarget
treebank
,
k
best
parsetrees
,
target
annotation
,
optimal
parse
tree
,
annotation
transformer
,
source
tree
bank
,
desiredannotation
guideline
,
optimization
strategy
,
iterative
training
,
transformation
performance
,
eachiteration
,
annotation
transformation
,
source
to
target
,
target
to
source
,
transformed
treebank
,
betterannotation
guideline
,
next
iteration
,
result
,
parallel
training
data
,
improved
annotationtransformer
,
next
iteration
,
treebank
transformation
