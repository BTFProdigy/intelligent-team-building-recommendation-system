proceeding
,
conference
,
empirical
method
,
natural
language
processing
,
honolulu
,
association
,
computational
linguisticsmining
,
modeling
relation
betweenformal
,
informal
,
corporazhifei
li
,
yarowskydepartment
,
computer
science
,
language
,
speech
processingjohns
hopkins
,
baltimore
,
gmail
,
novel
method
,
discoveringand
,
relationship
,
informal
expression
,
colloquialisms
,
instant
messaging
slang
,
andtheir
formal
equivalent
,
bootstrapping
procedure
,
candidate
informal
phrase
,
webcorpora
,
informal
phrase
,
contextual
instance
,
search
engine
,
hypothesis
offormal
equivalent
,
rankthe
hypothesis
,
conditional
log
linearmodel
,
log
linear
model
,
feature
function
,
rule
based
intuitions
,
data
occurrence
phenomenon
,
explicit
,
indirect
definition
,
formal
informal
usage
,
infree
variation
,
test
,
relationship
discovery
,
extraction
process
usingour
method
,
average
best
precision
,
ubiquity
,
informalconversational
style
,
internet
,
workhas
clear
application
,
text
normalizationin
text
processing
system
,
machinetranslation
,
majority
,
inter
net
,
informal
text
tends
,
newswire
,
syntactic
structure
,
semantic
interpretation
,
bye
bye
,
formal
informal
relation
,
pinyin
pronunciation
,
parenthesis
,
optional
literal
gloss
,
bracket
,
structure
,
certain
relations
,
formal
text
,
informal
text
,
viable
formal
equivalent
,
examples
,
informal
expression
,
detailed
inventory
,
characterization
,
phenomena1
,
chineseon
line
chat
,
person
,
bye
bye
,
person
,
follows
,
standard
equivalent
,
bye
bye
,
pinyin
,
pinyin
,
baibai
,
homophone
,
inputconvenience
,
relation
,
similar
process
,
willbe
,
substantial
divergence
between1for
clarity
,
word
,
format
,
chi
nese
character
,
optional
pinyin
equivalent
,
parenthesis
andoptional
gloss
,
bracket
,
formal
text
,
formal
text
,
wellon
informal
genre
,
machinetranslation
system
,
bilingual
training
data
,
second
,
training
data
,
translation
,
inthe
formal
text
,
translation
system
,
text
normalization
step
,
informal
text
,
itsstandard
formal
equivalent
,
ageneral
purpose
text
processing
system
,
many
process
,
informal
expression
,
common
use
today
,
suchtransformations
,
flexible
diverse
,
newphrases
,
internet
,
day
due
tomajor
news
event
,
radio
talk
,
political
activity
,
great
interest
,
data
driven
methodthat
,
relation
,
formal
expression
,
novel
method
,
discovering
,
relationship
,
informal
expression
,
formal
equivalent
,
bootstrapping
procedure
,
candidate
informal
phrase
,
individual
informal
phrase
,
contextual
instances
,
search
engine
,
thiscase
,
generate
hypothesis
,
formal
equivalent
,
hypotheses
,
conditional
log
linear
model
,
log
linear
model
,
rule
based
intuition
,
data
occurrencephenomena
,
explicit
,
indirect
definition
,
formal
informal
usage
,
infree
variation
,
test
examples2
,
relationship
discovery
,
extraction
process
,
method
,
averageprecision
,
applica
2the
training
,
test
,
available
athttp
,
text
normalization
,
machine
translation
,
knowledge
,
machine
learning
approach
,
productively
model
,
relationship
,
formal
expression
,
informal
,
phenomenon
,
phenomenon
,
provide
,
relation
,
formal
andinformal
expression
,
formal
informal
phrase
hereafter
,
single
word
expression
,
formal
informal
relation
,
relation
,
category
,
multiple
pages
,
formal
informal
relation
,
duplicate
,
examples
,
good
coverage
,
typical
categories
,
formal
informal
relation
,
thedistribution
,
category
,
examples
,
representative
,
actual
distribution
,
formal
informal
relation
,
thereal
text
,
present
,
category
,
examples
,
category
,
last
column
,
tablealso
,
relative
frequency
,
category
,
recall
thatwe
represent
word
,
format
,
chinesecharacters
,
optional
pinyin
equivalent
,
parentheses
,
optional
gloss
,
bracket
,
homophonein
,
homophone
,
differs
,
written
form
,
homophone
,
loose
,
informal
phrase
,
homophone
,
formalphrase
,
pronunciation
,
similar
tothe
formal
phrase
,
homophone
category
,
first
,
true
homophone
,
areloose
homophone
,
third
,
amajor
subclass
,
informal
phrase
,
banzhu
,
bye
bye
,
meiguojundui
,
american
army
,
pengyou
,
girl
friend
,
hinese
food
,
xiexie
,
sanqiu
,
formal
informal
relation
,
category
,
literal
gloss
,
bracket
,
illustrative
purpose
,
thetransformation
path
,
informalphrase
,
formal
phrase
,
transformation
path
,
samepinyin
,
formal
phrase
,
abbreviation
,
acronyma
abbreviation
,
formal
phrase
,
character
,
thisformal
phrase
,
character
,
atany
position
,
formal
phrase
,
yarowsky
,
anacronym
,
special
form
,
abbreviation
,
first
character
,
formalphrase
,
informal
phrase
,
table2
present
,
category
,
first
,
abbreviation
,
transformation
path
,
second
,
thetransformation
path
,
third
,
inwhether
pinyin
,
bridge
,
writing
system
,
present
,
thiscategory
,
first
,
hinese
food
,
transliteration
,
phase
,
pronunciation
,
pinyin
,
transformation
path
,
category
,
othersdue
,
flexible
nature
ofexpressions
,
informal
genre
,
formation
,
aninformal
phrase
,
forexample
,
informal
phrase
,
transformation
rule
,
moreimportantly
,
many
relation
,
simple
set
,
present
,
suchexamples
,
third
exampleis
,
character
,
formal
form
,
statistic
,
the904
,
relationsbelonging
,
category
,
data
driven
method
,
therelations
,
formal
phrase
,
occurrencein
natural
language
,
related
word
,
gates1033tends
,
microsoft
,
occurrencemay
imply
,
existence
,
relationship
,
formal
informal
relation
discovery
underdifferent
condition
,
definitionsin
,
many
informal
phrase
,
popular
use
,
explicit
definition
,
meaning
,
unfamiliar
audience
,
people
,
definition
pages
,
relation
betweenformal
,
informal
phrase
,
firstexample
,
manydedicated
definition
pages
,
internet
,
onthe
hand
,
researchpapers
,
people
,
informal
phrasebefore
,
later
part
,
thetext
,
second
,
thisphenomena
,
definition
text
,
salient
pattern
,
second
,
reliableway
,
informal
phrasesas
,
data
occurrence
,
occurrence
,
online
chatinformal
phrase
,
online
chat
,
forinput
convenience
,
differentpeople
,
different
,
tradition
,
express
semantically
equivalent
phrase
,
nearby
data
occurrence
,
chattext
,
series
,
message
exchange
,
person
,
conversation
,
bye
bye
,
person
,
semantic
content
,
person
,
data
occurrence
,
online
chat
,
bye
bye
,
news
articlesfor
,
formal
informal
relation
,
informal
,
formal
phrase
,
people
,
relation
,
author
,
informaland
formal
phrase
,
bothering
,
relation
,
truein
news
article
,
well
known
relation
,
winter
olympics
,
thetitle
,
thetext
,
relativedistance
,
informal
phrase
,
formalphrase
varies
,
data
occurrence
,
news
article
,
meaning
,
winter
olympics
,
relation
,
informal
andformal
phrase
,
automatically
discovers
,
relation
,
formalphrase
,
informal
phrase
,
corpus
,
bootstrapping
procedureto
,
candidate
informal
phrase
,
target
informal
phrase
,
largeset
,
instance
,
context
,
generatecandidate
hypothesis
,
candidate
formal
phrase
,
hypothesis
,
aconditional
log
linear
model
,
log
linear
modelis
,
ruleand
data
1034driven
intuition
,
feature
function
,
informal
phrasesbefore
,
formal
phrase
,
toan
informal
phrase
,
informal
phrase
,
interest
,
phrase
,
new
relation
,
formal
phrase
,
internet
,
large
amount
,
newswire
,
informal
corpus
,
thosephrases
,
frequency
,
informal
corpus
,
formal
corpus
,
informal
phrase
,
alternative
approach
,
informal
phrase
,
yarowsky
,
small
set
,
relation
,
usingthese
relation
,
definition
pattern
,
formal
phrase
,
pattern
,
new
relation
,
procedure
iterates
,
large
list
,
formal
informal
relation
,
rule
driven
intuition
,
relations
,
webgiven
,
informal
phrase
,
usea
search
engine
,
hyper
links
thatpoint
,
context
relevant
tothe
informal
phrase
,
hyper
linksto
download
,
searchengine
,
text
query
,
informal
phrase
,
nothing
,
informal
phrase
,
third
,
thewell
known
search
engine
www
,
top
,
situation
,
canuse
,
search
engine
,
blogsearch
,
general
purpose
search
engine
,
domain
information
,
forexample
,
meansinternet
language
,
candidate
hypothesesgiven
,
informal
phrase
,
hypotheses
,
candidate
formal
phrase
,
informal
phrase
,
twogeneral
approach
,
generation
,
hypothesis
,
rule
driven
hypothesis
generation
,
canuse
,
hypothesis
,
onemay
generate
,
exponential
number
,
hypothesis
,
acronym
,
nletters
,
problem
,
thata
relation
,
informal
phrase
,
formalphrase
,
specific
rule
,
infact
,
last
,
relations
consist
,
corpus
instance
,
data
driven
hypothesis
generation
,
hypothesesby
,
frequent
n
grams
occurringwith
,
informal
phrase
,
certain
distance
,
data
occurrence
phenomenon
described
,
formal
phrase
,
informal
phrase
,
thedata
,
multiple
reason
,
thiscan
deal
,
relation
betweenan
informal
phrase
,
formal
phrase
,
fromthe
over
generation
problem
,
rule
driven
approach
,
data
driven
method
togenerate
hypothesis
,
hypothesis
usinga
conditional
log
linear
model
,
boththe
rule
,
data
intuition
,
feature
function
,
hypothesis
,
conditionallog
linear
modellog
linear
model
,
flexible
incorporation
,
feature
function
,
hint
intuition
,
hypothesis
,
subsection
,
aconditional
log
linear
model
,
boththe
rule
,
data
intuition
,
feature
function
,
informal
phrase
,
candidateformal
phrase
,
pair
ascore
,
thehypothesis
,
linear
combination
,
set
offeature
function
,
feature
function
,
weight
,
weight
vector
,
normalization
constant
,
wheren
,
training
,
a
g
aussian
prior
,
function
,
limited
memory
variable
method
,
tao
package
,
etal
,
effective
invarious
natural
language
processing
task
,
malouf
,
test
time
,
following
decision
rule
,
optimal
formal
phrasey
,
informal
phrase
,
arg
maxys
,
data
driven
intuition
,
log
linear
model
,
rule
driven
feature
function
,
rule
pattern
,
high
possibility
,
true
formal
informal
relation
,
intuition
,
several
feature
function
,
levenshtein
distance
onp
inyin
,
distance
betweentwo
pinyin
character
,
onthe
similarity
,
pronunciation
,
weight
,
weightw
,
difference
,
pinyin
character
,
a
p
inyinacronym
,
is
cn
abbreviation
,
a
c
hinese
abbreviation
,
described
ins
ection
,
formal
phrase
,
toco
occur
,
several
feature
function
,
intuition
,
n
gram
occurrence
relative
frequency
,
n
grams
,
window
,
occurrence
,
informalphrase
,
relative
frequencyas
feature
value
,
different
order
,
different
statistic
,
category
,
an
gram
,
characters
,
definition
pattern
,
discussed
definition
pattern
,
foreach
definition
pattern
,
featurefunction
,
occurrence
,
definition
pattern
,
featurevalue
,
relevant
pages
,
interesting
feature
function
,
candidate
relation
,
theweb
,
bythe
search
engine
,
million
ofqueries
,
formal
informal
relation
,
manually
collectedrelations
,
subset
,
examples
,
log
linear
model
,
describedin
,
test
data
,
precision
,
weights5
,
various
feature
function
,
different
feature
function
,
different
weight
,
feature
functionsmay
differ
,
intheir
importance
,
hypothesis
,
importance
,
log
linearmodel
,
optimal
weight
,
principledand
automatic
manner
,
tuningthe
weight
,
ad
hoc
,
show
,
precision
result
,
differentcategories
,
data
driven
features
,
precision
corresponding
,
following
,
true
hypothesis
,
top
nhypotheses
,
classification
,
correct
,
clearly
,
the3note
,
search
engine
,
training
,
test
,
available
athttp
,
definition
patternsand
,
relevant
,
efficiency
,
category
feature
weightrule
drivenld
pinyin
,
optimal
weight
,
log
linear
modellarger
,
precision
,
top
n
precision
,
usual
top
precision
,
meaningful
especiallywhen
,
relation
extractor
,
intermediate
step
,
machine
translation
,
final
decision
,
evidence
,
respectablyhigh
precision
,
top
,
rule
driven
feature
,
data
driven
feature
,
rule
driven
feature
,
absolute
improvement
,
best
precision
,
thecombination
,
individual
feature
,
absolute
improvement
,
best
precision
,
data
driven
feature
,
bootstrapping
procedure
,
section4
,
having130
relation
,
frequent
,
fromthe
data
,
seed
examples
,
pattern
,
new
possible
formal
informal
relation
,
afterthe
first
iteration
,
relations
,
pattern
,
recall
,
collected
test
set
,
these3000
pair
,
noisy
data
,
pinyin
,
abbreviation
,
pinyin
acronym
,
acronym
,
rule
driven
feature
,
precision
,
pinyin
,
abbreviation
,
pinyin
acronym
,
acronym
,
data
driven
feature
,
precision
,
pinyin
,
abbreviation
,
pinyin
acronym
,
acronym
,
rule
drive
feature
,
precision
,
formal
informal
relation
extraction1038size
,
candidate
,
test
set
,
a
candidate
set
extractedby
a
b
,
procedure6
related
workautomatically
,
relation
,
full
form
phrase
,
abbreviation
,
important
task
,
machine
translation
,
information
retrieval
,
yarowsky
,
relationship
,
full
form
phrase
,
abbreviation
,
abbreviation
,
observation
,
full
form
word
,
setof
manually
created
full
abbreviation
relation
,
abbreviation
,
thetask
,
full
form
,
vice
versa
,
changand
lai
,
relationsbetween
full
form
phrase
,
abbreviation
,
full
form
phrase
,
abbreviation
,
method
,
changand
lai
,
full
abbreviation
relations
,
training
data
,
yarowsky
,
unsupervised
method
,
relationsbetween
full
form
phrase
,
abbreviation
,
data
occurrence
,
inthe
newswire
text
,
statisticalmachine
translation
,
extractedrelations
,
baseline
translation
system
,
interesting
,
similartask
,
abbreviation
,
acronym
,
medical
domain
,
pakhomov
,
graehl
,
khudanpur
,
deal
,
relations
,
formal
text
,
formal
informal
relation
,
bothformal
,
informal
text
,
relations
,
corpus
,
method
,
semi
supervised
inthe
sense
,
weight
,
feature
functionsare
,
supervised
log
linear
model
,
asmall
number
,
seed
relation
,
generationand
ranking
,
hypothesis
,
taxonomy
ofthe
formal
informal
relation
,
chinesetext
,
novel
method
fordiscovering
,
relationship
betweeninformal
expression
,
colloquialisms
,
instant
messaging
slang
,
formalequivalents
,
bootstrapping
procedure
,
candidateinformal
phrase
,
corpus
,
informal
phrase
,
contextual
instance
,
search
engine
,
hypotheses
,
formal
equivalent
,
rankedthe
hypothesis
,
conditional
log
linear
model
,
log
linear
model
,
featurefunctions
,
rule
based
intuition
,
data
occurrence
phenomenon
,
explicit
,
indirect
definition
,
formal
informal
usagesoccurring
,
free
variation
,
testedour
system
,
test
,
relationshipdiscovery
,
extraction
process
,
methodachieves
,
average
best
precision
,
informal
conversational
style
,
theinternet
,
clear
application
,
text
normalization
,
text
processing
system
,
machine
translation
,
broad
coverage
,
acknowledgmentswe
,
anonymous
reviewer
,
helpful
comments
,
sarich
,
tao
user
,
argonne
national
laboratory
,
limited
memory
variable
metric
method
,
minimization
,
argonne
nationallaboratory
,
jing
shin
chang
,
yu
tso
lai
,
preliminarystudy
,
probabilistic
model
,
abbreviations
,
proceeding
,
wo
,
language
processing
,
barcelona
,
jing
shin
chang
,
wei
lun
teng
,
miningatomic
abbreviation
pair
,
a
p
robabilisticmodel
,
single
character
word
recovery
,
proceedings
,
workshop
,
chineselanguage
processing
,
knight
,
graehl
,
machinetransliteration
,
computational
linguistics
,
philipp
koehn
,
hieu
hoang
,
birch
,
chriscallison
burch
,
bertoldi
,
cowan
,
shen
,
moran
,
richardzens
,
dyer
,
ondrej
bojar
,
strantin
,
herbst
,
open
sourcetoolkit
,
statistical
machine
translation
,
proceedings
,
demonstration
session
,
automatic
expansion
,
hinese
abbreviation
,
thesis
,
ofh
,
yue
shi
,
hsin
hsi
,
homophone
disambiguation
,
proceeding
,
fifth
conference
,
applied
natural
language
processing
,
joint
sourcechannel
model
,
machine
transliteration
,
proceedings
,
zhifei
li
,
yarowsky
,
unsupervisedtranslation
induction
,
abbreviation
usingmonolingual
corpus
,
proceeding
,
malouf
,
comparison
,
algorithm
,
maximum
entropy
parameter
estimation
,
proceeding
ofc
,
serguei
pakhomov
,
semi
supervised
maximumentropy
,
acronym
,
abbreviation
normalization
,
medical
text
,
proceedingsof
acl
,
youngja
,
hybrid
text
mining
,
abbreviation
,
definition
,
inp
roceedings
,
emn
lp
,
roark
,
murat
saraclar
,
discriminative
n
gram
language
modeling
,
computerspeech
,
language
,
virga
,
sanjeev
khudanpur
,
transliteration
,
proper
name
,
cross
lingual
informationretrieval
,
proceeding
,
workshopon
multilingual
,
mixed
language
named
entityrecognition
,
jian
cheng
wu
,
tof
ind
,
transliteration
,
proceeding
,
emn
lp
conll
,
yarowsky
,
word
sense
disambiguation
rivaling
,
method
,
proceedingsof
acl
,
methodology
,
principle
,
chi
nese
abbreviation
formation
,
language
teachingand
study
,
conference
,
empirical
method
,
natural
language
processing
,
afn
lpfi
,
second
order
expectation
semiringswith
application
,
minimum
risk
training
,
translation
,
zhifei
li
,
eisnerdepartment
,
computer
science
,
language
,
speech
processingjohns
hopkins
,
baltimore
,
gmail
,
eduabstractmany
statistical
translation
model
,
weighted
logical
deduction
,
paradigm
,
weight
fromthe
expectation
semiring
,
eisner
,
tocompute
first
order
statistic
,
expected
hypothesis
length
,
feature
count
,
packed
,
translation
,
lattices
,
novel
second
order
expectation
semir
ing
,
variance
,
hypothesis
length
,
gradient
,
entropy
,
second
order
semiring
,
training
paradigm
suchas
minimum
risk
,
deterministic
annealing
,
active
learning
,
semi
supervisedlearning
,
gradient
optimization
,
gradient
,
entropy
,
semirings
,
anopen
source
machine
translation
toolkit
,
minimum
risk
trainingfor
,
benefit
,
hypergraph
,
manning
,
chi
ang
,
compact
data
structure
,
manytrees
,
polynomial
space
,
weighted
hypergraphalso
,
probability
,
weight
,
eachtree
,
hypothesisspace
,
monolingual
parser
,
tree
based
translation
system
,
string
,
galley
,
tree
totree
,
eisner
,
latenttree
structure
,
chiang
,
research
,
hr0011
,
early
guidance
,
regular
discussion
,
hypergraph
,
quantity
,
algorithm
,
viterbi
algorithm
,
mostprobable
derivation
tree
,
hypergraph
,
kmost
probable
tree
,
semiring
weighted
logic
programming
,
general
framework
,
thesealgorithms
,
pereira
,
shieber
etal
,
goodman
,
eisner
,
manyuseful
semirings
,
semirings
,
semirings
,
training
,
parameter
estimation
,
expectation
,
eisner
,
finite
statemachines
,
training
,
semiring
,
feature
expectation
,
e
step
,
algorithm
,
gradient
,
likelihood
function
,
gradient
,
expectation
semir
ing
,
eisner
,
hypergraph
,
lattice
,
novel
second
order
expectation
semiring
,
variance
,
original
first
order
expectation
,
vector
,
first
order
statistic
,
expectation
,
first
derivative
,
lattice
,
ahypergraph
,
second
order
expectation
semir
ing
,
matrix
,
second
order
statistic
,
expectation
,
product
,
secondderivatives
,
derivative
,
expectation
,
detail
,
many
interesting
quantity
,
hypergraph
,
theexpectation
,
variance
semirings
,
quantities
,
hypothesis
length
,
featureexpectation
,
entropy
,
kullback
leibler
divergence
,
bayes
risk
,
variance
,
hypothesis
length
,
gradient
,
entropy
,
bayesrisk
,
covariance
,
hessian
matrix
,
variance
semiring
,
paradigm
,
deterministic40annealing
,
minimum
risk
,
semi
supervised
learning
,
grandvalet
,
bengio
,
setting
,
gradient
ofentropy
,
semirings
,
forsecond
order
gradient
optimization
algorithm
,
expectation
,
variancesemirings
,
practical
benefit
,
minimum
risk
training
,
chiang
,
hypergraphswe
use
,
specific
tree
based
system
,
chiang
,
discussion
,
pergraph
,
hypothesis
space
,
word
aligned
corpus
,
word
,
thealignment
,
subscript
,
nonterminals
,
phrase
,
translation
,
a
c
ky
parser
togenerate
,
hypergraph
,
many
derivationtrees
,
translation
string
,
hypergraph
,
vertex
,
peredges
,
hyperedge
,
set
ofantecedent
node
,
single
consequent
node
,
parlance
,
node
corresponds
,
itemin
,
specifies
,
input
,
output
,
nonterminal
label
,
root
node
,
goal
item
,
ahyperedge
,
scf
rule
,
particular
position
,
thenonterminals
,
particular
antecedent
,
backpointersin
,
antecedentnodes
,
hyperedge
,
hyperedge
designate
asingle
consequent
defines
a
b
hypergraph
,
mat
na
,
nax
,
catgoal
item
,
figure
,
toy
hypergraph
,
thehypergraph
,
trigram
language
model
,
rectangles
represent
item
,
thenon
terminal
symbol
,
source
span
,
right
sidelanguage
model
state
,
incominghyperedges
,
hyperedge
,
pointer
toan
antecedent
item
,
nonterminal
symbol
,
hyperedges
,
hyper
edges
,
consequent
,
represent
different
,
figure
,
showsa
simple
hiero
style
hypergraph
,
hypergraphencodes
,
different
derivation
tree
,
sharesome
,
sharing
,
hypergraph
,
many
tree
,
finite
state
automaton
canalso
,
hypergraph
,
everyhyperedge
,
ordinary
edge
,
single
antecedent
,
methods
,
simpler
caseof
hypothesis
lattice
,
parsingwe
,
many
derivation
tree
,
derivation
,
otheraggregate
property
,
derivation
,
parsing
,
goodman
,
generalframework
,
algorithm
,
particular
algorithm
,
semiring
kand
,
hyper
edge
,
desired
aggregate
result
,
total
weight
,
derivation
,
hyper
graph
,
derivation
,
hyperedge
,
thesemiring
,
ordinary
integer
,
derivation
,
total
weight
,
thenumber
,
derivation
,
semiringwith
element
,
additive
operation
,
multi
41plicative
operation
,
additive
identity
,
multiplicative
identity
,
operation
,
weight
,
derivation
,
weight
,
component
hyperedges
,
operation
,
usedto
sum
,
derivation
,
hypergraphto
,
total
weight
,
total
weight
,
acyclic
hypergraphhg
,
total
weight
,
many
derivation
,
figure
,
derivation
,
linear
onthe
size
,
hypergraph
,
correctness
relieson
axiomatic
property
,
semiring
,
two
sided
identity
,
distributes
,
distributive
property
,
figure
,
property
,
algorithm
,
figure
,
novel
semirings
,
expectation
,
hypergraphswe
,
computational
problem
,
semirings
,
whichdecomposes
,
component
peredges
,
probability
distribution
,
derivation
,
hyper
2eisner
,
closed
semirings
,
undefined
otherwise
,
closure
operator
,
exact
summation
,
many
path
,
cyclic
fsm
,
non
branching
cycle
,
numerical
convergence
,
completeness
,
closure
operator
,
semirings
,
satisfyingthe
axiom
,
hypergraphs
,
assume
,
deductiveinference
,
shieber
,
practice
,
hypergraphis
,
heuristic
,
notation
,
dkeassumes
,
notation
,
ouralgorithms
,
loop
order
,
non
commutative
semiring
,
hyper
edge
,
antecedent
,
derivation
,
product
,
weight
,
hyperedges
,
inprefix
order
,
forvin
topological
order
,
antecedent
,
return
,
figure
,
inside
algorithm
,
hyperedge
weight
,
computesall
,
return
,
istotal
weight
,
forvin
reverse
topological
order
,
hyperedge6
foru
,
antecedent
,
figure
,
outside
weight
,
figure
,
probability
distribution
,
aproper
distribution
,
function
,
interest
,
component
hyperedges
,
following
quantity
,
expectation
under
,
probabilistic
interpretationis
,
discrete
sample
space
,
single
linear
combination
,
forvin
hg
,
antecedent
,
hyperedge
,
inside
outside
algorithm
,
figure
,
hypergraph
,
thexeare
vector
,
inside
,
keweights
,
outside
weight
,
side
effect
,
second
component
,
ofthe
total
weight
,
linear
combination
,
xevalues
,
wherekeis
,
weight
,
linear
coefficient
,
exclusive
weight
,
hyperedge
,
product
,
total
weight
,
derivation
,
hypergraph
,
measure
,
random
variable
,
expectations
,
random
variable
,
givesthe
expectation
,
covariance
,
length
,
translationcorresponding
,
target
side
terminal
word
,
scf
rule
,
hypothesis
length
,
referencetranslation
,
decomposableloss
function
,
minimum
risk
training
,
certainfeature
,
expected
feature
count
,
maximum
likelihoodtraining
,
toallow
,
vector
,
compute
hypothesis
length
,
second
moment
,
lengthdistribution
,
variance
,
hypothesis
,
quantitieswe
,
semiring
,
framework
tocompute
,
many
derivation
,
hyperedge
,
thenthe
algorithm
,
figure
,
reduces
,
classicalinside
algorithm
,
expectation
semiring
,
eisner
,
hen
figure
,
suppose
,
novel
second
orderexpectation
semiring
,
algorithm
,
figure
,
first
order
expectation
,
defining
,
thehyperedges
,
areidentical
,
second
order
expectation
,
variance
,
second
order
expectation
,
variance
semiring
,
algorithmsto
,
first
order
expectation
semiring
,
definitionsin
table
,
semiring
axiom
,
thereader
,
wellas
,
closure
axiom
,
avalid
semiring
,
second
equality
,
first
equality
,
definition
,
main
intuition
,
disjoint
sub
derivations
,
single
hyperedge
,
case5however
,
tricky
,
second
order
expectation
semiring
,
first
order
expectation
semiring
,
p1r2
p2r1
,
expectation
semiring
,
semir
ing
,
third
,
theoperations
,
identity
,
multiplicative
identity
,
component
,
storing
,
log
domain
,
aare
thesign
bit
,
natural
logarithm
,
operation
,
induction
,
second
order
expectation
semiring
,
underflow
overflowin
table
,
probability
,
overflow
problem
,
thelog
domain
,
takethe
log
,
negative
number
,
represent
real
number
,
ordered
pair
,
sign
bit
,
floating
point
number
,
natural
logarithm
,
avoids
log
,
floating
point
number
,
bit
eawill
,
effect
,
moredynamic
range
,
bit
exponent
,
bit
double
precision
floating
point
number
,
speedupsin
,
abovecase
,
r
valued
,
semiring
,
vector
,
algebraic
object
,
vector
,
high
dimensional
vector
,
algorithm
,
figure
,
tospeed
,
inside
outside
algorithm
,
allowing
feature
vector
,
morein
,
thefirst
order
expectation
,
second
order
,
definition
,
dothose
definition
,
semiring
axiom
,
outerproduct
rst
,
matrix
,
transpose
,
expectation
,
vector
andouter
product
,
vector
,
meansand
covariance
,
linearly
decomposable
quantity
,
feature
count
,
onthe
hypergraph
,
choice
,
sections
,
generality
,
precise
technicalconditions
,
semiring
,
vector
space
,
associativeand
commutative
addition
operation
,
anidentity
element
,
module
,
matter
,
notation
,
ofthe
addition
operation
,
respective
additive
identities
,
concatenation
,
multiplication
operation
,
p1r2
p2r1
,
p1s2
p2s1
,
p1t2
p2t1
r1s2
r2s1
,
second
order
expectation
semiring
,
variance
,
semiring
,
third
,
operation
,
identity
,
multiplicative
identity
,
component
,
distinguished
symbol
,
operation
,
identity
,
main
semiring
,
general
setting
,
multiplicativeor
additive
decomposability
,
operator
,
operation
,
usual
operation
,
first
orderexpectation
semiringsunder
,
first
order
expectation
,
inside
algorithm
,
figure
,
vector
,
feature
expectation
,
eisner
,
thatthis
,
theinside
algorithm
,
trouble
,
hypergraph
,
second
component
,
dense
vector
ofall
,
subderivations
,
atnode
,
lines3
,
vector
,
operations
,
linear
combination
,
otherdense
vector
,
second
component
,
efficient
approach
,
isthe
traditional
inside
outside
algorithm
,
expectation
semiringek
,
hypergraph
hg
whoseedges
,
weight
,
semiring
,
so7note
,
expectation
,
forward
,
expectation
,
traditional
inside
outside
algorithm
,
small
number
,
quantity
,
eisner
,
forward
backward
algorithm
,
edge
weight
,
thesame
thing
,
inside
outside
algorithm
,
single
linear
combination
,
ekexeof
,
feature
vector
,
individual
hyperedges
,
sparse
vector
,
linear
coefficientske
,
values
,
kepart
,
weight
,
expectation
,
figure
,
expectation
semiring
,
expectation
semiring
,
operationsare
,
reason
,
input
tof
igure
,
consists
,
hyperedge
weight
,
inthe
expectation
,
weight
,
eisner
,
composition
,
expectation
,
beforetheir
result
,
forward
backward
algorithm
,
second
reason
,
second
order
expectation
,
figure
,
first
order
expectation
semiring
,
constructedby
first
order
,
figure
,
inside
outside
,
whereas
,
algorithm
computes
,
din
anysemiring
,
inside
outside
algorithm
exploitsthe
special
structure
,
expectation
semir
ing
,
definition
,
first
component
,
inside
algorithm
,
thekepart
,
weight
,
second
component
,
application
,
thissubsection
,
classical
inside
outside
algorithm
,
algorithm
return
,
factthat
,
lifting
trick
,
second
order
semiringswe
,
second
order
,
first
order
expectation
,
insideanother
first
,
first
order
expectation
,
second
time
,
first
order
expectation
,
operation
,
first
order
expectationsemiring
,
construction
,
second
order
semiringas
,
first
order
semiring
,
useful
bit
,
abstractalgebra
,
propertiesof
first
order
semirings
,
second
order
one
,
second
order
,
satisfies
,
inside
outside
algorithm
,
hypergraph
,
second
orderexpectation
,
first
order
expectation
semiringek
,
totalweight
,
derivation
,
hyperedge
,
inside
outsidealgorithm
,
figure
,
inside
algorithm
,
figure
,
inside
,
first
order
,
effective
speedup
overthe
,
scalar
,
small
vector
,
sparse
high
dimensional
vector
,
weight
,
denote
,
probability
,
gradient
,
probability
,
gradient
,
probability
,
entropy
,
gradientof
probability
,
gradient
,
entropy
,
gradient
,
hypergraphsin
,
computeexpectations
,
semirings
,
compute
firstand
second
order
partial
derivative
,
result
,
respect
,
change
,
currentvalue
,
elementary
value
,
function
,
recall
,
hyperedge
,
weight
,
gradient
vector
,
willbe
,
secondtime
,
weight
,
hessian
matrix
,
second
order
mixedpartial
derivative
,
weight
,
asecond
order
expectation
,
analogy
,
trivial
isomorphism
,
semiring
,
hereand
,
vector
,
product
,
p1t2
p2t1
r1s2
r2s1
,
second
order
expectation
,
first
order
,
operation
,
operation
,
a
k
module
,
addition
,
left
multiplication
,
expectations
,
partial
derivative
,
whenthe
edge
weight
,
gradient
,
expectation
,
algorithmwill
compute
,
gradient
,
hyperedge
weight
,
mayseem
wonderful
,
intwo
distinct
,
setupof
,
specialcase
,
well
known
relationship
,
gradients
,
expectation
,
log
linear
model
,
expectation
,
perspective
,
expectations
,
certain
expectation
,
matrix
,
tocompute
second
derivative
,
covariance
,
mayexploit
,
invariant
,
tocompute
r1s2
s1r2in
multiplication
,
thesecond
,
third
component
,
matrix
,
fourth
component
,
change
nothing
,
thanks
,
symmetry
,
method
,
expectation
,
gradientrather
,
gradient
,
expectation
,
relationship
,
scalar
,
morecomplex
object
,
discussion
,
scalar
,
simplicity
,
pearlmutter
,
siskind
,
relevant
generalization
,
dual
number
,
input
weight
,
gradient
,
expectation
,
alternative
perspective
,
gradient
,
purpose
,
dual
number
,
per
ations
,
dual
number
,
compute
,
result
,
gradient
,
multiplies
dual
number
,
automaticdifferentiation
,
forward
mode
,
inside
outside
algorithm
,
reverse
mode
,
back
propagation
,
backward
,
machinery
,
expectation
,
arbitrary
reof
interest
,
automatic
differentiation
,
neural
net
,
simple
sum
of
products
functionz
,
inputweights
,
outputchanges
,
algorithm
,
log
linear
model
,
a
special
replacing
,
pewith
pereis
,
pealreadyequals
,
log
linear
model
,
feature
vector
,
key
useful
property
,
vector
,
feature
expectation
,
ractical
applicationsgiven
,
hypergraph
hg
,
hyperedges
,
recall
,
probability
distribution
,
allderivations
,
hypergraph
,
zwhere
,
expected
hypothesis
length
,
featurecounts
,
algorithm
,
figure
,
afirst
order
expectation
,
hyperedge
weight
,
algorithmcomputes
,
expectation
ofr
,
quantity
,
a
h
ypergraph
,
entropy
,
thedistribution
,
derivation
,
hypergraph14ish
,
course
,
kl
divergence
,
cross
entropy
ork
divergence
,
distribution
,
variational
decoding
,
machinetranslation
,
hypergraph
,
finite
state
automaton
,
approximation
top
,
cross
entropy
,
entropy
ofthe
distribution
,
string
,
string
,
probability
,
sumover
several
derivation
,
string
entropy
,
first
term
zqcan
,
usingthe
inside
algorithm
,
numerator
,
denominator
,
second
term
,
expectation
,
redef
log
,
kl
divergence
,
thehypotheses
,
hypergraph
,
target
yield
,
hypothesis
,
respect
,
reference
,
papineni
,
expected
loss
,
following
loss
function
,
linear
approximation
,
special
,
n
gramtypes
,
occurrence
,
indicator
,
contains
,
occurrenceof
,
weight
,
relativeimportance
,
n
gram
match
,
hypergraphis
,
language
model
state
,
loss
function
,
redef
lewhere
lei
theloss
,
hyperedge
,
expectedloss
,
hypergraph
,
expectation
andvariance
,
hypothesis
length
,
feature
expectation
vector
,
covariance
matrix
,
hessian
,
matrix
,
second
derivative
,
gradients
,
entropy
,
computations
,
discussion
,
gradient
,
entropy
,
bayes
risk
,
gradient
,
entropy
,
gradient
,
pedepends
,
particular
parameterization
,
themodel
,
gradient
,
training
,
ahiero
mt
model
,
objective
function
,
entropy
,
objectivefunction
,
first
order
expectation
semiring
,
second
order
one
,
model
pwe
,
normalized
linear
modelfor
,
simplicity
,
derivation
,
vector
,
wethen
,
unnormalized
distribution
,
scale
factor
,
thedistribution
,
highest
scoring
hypothesis
,
change
,
distribution
,
triesto
tune
,
ble
loss
,
probable
output
accordingto
,
effect
,
line
search
,
problem
,
objectivefunction
,
large
number
,
parameter
,
eisner
,
differentiable
objective
,
gradient
,
bayes
risk
,
randomized
decoder
,
hypothesis
,
proportion
,
bayes
riskis
smooth
,
local
minimum
,
smithand
eisner
,
local
minimum
,
optimization
,
deterministic
annealing
,
bayes
risk
,
best
error
,
temperature
,
optimization
proceeds
,
theentropy
,
gradientswith
respect
,
eisner
,
decoder
,
n
best
list
,
thesequantities
,
dynamic
programming
,
method
,
many
hypotheses
,
condition
,
new
second
order
semiring
method
,
additivelydecomposable
loss
,
tromble
et
,
ur
algorithm
,
localto
individual
hyperedges
,
vector
,
eindicateswhich
feature
,
hyperedge
,
algorithm
,
gradients
,
respect
,
method
,
expected
n
gram
count
,
hypergraph
usinggradient
,
objective
,
minimumrisk
objective
,
optimization
,
algorithm
,
expected
feature
n
gram
count
,
product
offeatures
,
n
gram
count
,
general
algorithm
,
firstand
second
order
semir
ings
,
regular
mer
setting
,
experiments
,
large
number
,
gradient
,
entropy
,
respect
,
weightedsum
,
gradient
,
respect
,
translation
model
,
corpus
foriwslt
,
to
translation
task
,
gram
language
modelwith
,
kneser
ney
smoothing
,
sri
lm
,
stolcke
,
a
s
mall
number
,
featureswe
,
performs
,
exact
corpus
ble
,
training
,
resultsby
,
weight
,
weobserve
,
thanmert
,
dev
set
,
becausemr
,
approximated
ble
whilemert
doesn
,
daon
,
n
best
list
,
hypergraph
,
hypergraph
,
ble
score
,
plainmr
,
local
minimum
problem
,
improvement
,
dev
set
,
test
set
,
a
large
number
,
featuresmr
,
alarge
number
,
toachieve
competitive
performance
,
reranking
approach
,
khudanpur
,
training
,
twostages
,
first
stage
,
baseline
systemas
,
optimal
feature
,
themethod
,
hypergraph
,
inthe
second
stage
,
training
data
,
baseline17pauls
et
,
dev
set
,
butperforms
,
test
set
,
dev
set
,
training
scheme
dev
testmert
,
hypergraph
,
hypergraph
,
hypergraph
,
test
set
,
scenario
,
language
model
,
translation
model
,
word
penalty
,
additional
unigram
,
bigram
feature
,
khudanpur
,
specific
bigram
,
total
score
,
baseline
system
,
alsoa
feature
,
second
stage
model
,
thesefeatures
,
hypergraphs
,
mrtraining
,
optimal
weight
,
test
time
,
similar
procedure
,
baseline
system
,
hypergraph
,
pergraph
,
second
stage
model
,
last
,
report
,
ble
score
,
clearly
,
feature
improves
,
chiang
,
conclusionswe
,
first
order
expectation
semiringsand
inside
outside
computation
,
detailthan
,
eisner
,
extension
tohigher
order
expectation
semirings
,
enablesefficient
computation
,
many
interesting
quantities
,
many
derivation
,
hypergraph
,
second
derivative
,
hes
sians
,
expectation
,
product
,
covariance
,
andexpectations
,
entropy
,
withtheir
derivative
,
knowledge
,
problem
,
otherwork
,
goodman
,
gimpel
,
new
form
,
minimum
risk
training
,
mt
,
implementation
,
theopen
source
mt
toolkit
,
training
,
specific
oracletranslation
,
specific
tree
,
trainable
grammar
,
speechrecognition
,
editor
,
speech
communication
paper
,
meeting
,
acoustical
society
,
chiang
,
knight
,
wei
,
new
feature
,
statistical
machine
translation
,
naa
cl
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
preliminary
sketch
,
bi
quaternions
,
proceeding
,
eck
,
chiori
hori
,
overview
,
theiwslt
,
evaluation
campaign
,
theinternational
workshop
,
spoken
language
translation
,
eisner
,
goldlust
,
comp
ling
,
practical
weighteddynamic
programming
,
language
,
eisner
,
parameter
estimation
,
probabilistic
finite
state
transducer
,
non
isomorphic
treemappings
,
machine
translation
,
pages205
,
galley
,
graehl
,
knight
,
danielmarcu
,
den
eefe
,
wei
,
ignaciothayer
,
scalable
inference
,
ofcontext
syntactic
translation
model
,
gallo
,
giustino
longo
,
pallottino
,
andsang
nguyen
,
hypergraphs
,
applications
,
discrete
appl
,
gimpel
,
approximate
inference
,
nonlocal
features
,
dynamic
programming
,
semirings
,
goodman
,
computational
linguistics
,
y
b
engio
,
entropy
minimization
,
pages529
,
liang
huang
,
chiang
,
k
bestparsing
,
liang
huang
,
reranking
,
nonlocal
feature
,
feng
jiao
,
shaojun
,
chi
hoon
,
russellgreiner
,
schuurmans
,
semi
supervised
conditional
random
field
,
improvedsequence
segmentation
,
labeling
,
pages209
,
klein
,
manning
,
parsing
,
hypergraphs
,
new
development
,
parsingtechnology
,
lau
,
rosenfeld
,
roukos
,
adaptive
language
,
maximum
entropy
principle
,
zhifei
li
,
sanjeev
khudanpur
,
large
scalediscriminative
n
gram
language
model
,
statistical
machine
translation
,
zhifei
li
,
sanjeev
khudanpur
,
machine
translation
,
percep
tron
algorithm
,
gal
book
chapter
,
dyer
,
juriganitkevitch
,
sanjeev
khudanpur
,
schwartz
,
weese
,
zaidan
,
open
source
toolkit
,
parsing
based
machine
translation
,
sanjeev
khudanpur
,
variational
decoding
,
statistical
machinetranslation
,
yang
liu
,
qun
liu
,
shouxun
,
tree
to
string
alignment
template
,
statistical
machinetranslation
,
lopez
,
translation
,
weighted
deduction
,
och
,
minimum
error
rate
training
instatistical
machine
translation
,
kishore
papineni
,
roukos
,
wei
jing
zhu
,
method
,
automaticevaluation
,
machine
translation
,
pages311
,
den
ero
,
klein
,
consensus
training
,
consensus
decoding
,
machinetranslation
,
emn
lp
,
proceedings
,
annual
symposium
,
principle
ofp
,
deduction
,
quirk
,
arul
menezes
,
dependency
treelet
translation
,
informed
phrasal
smt
,
clustering
,
compression
,
classification
,
regression
,
andrelated
optimization
problem
,
proceeding
ofthe
iee
,
shieber
,
schabes
,
principle
,
implementation
ofdeductive
parsing
,
journal
,
logic
programming
,
eisner
,
minimum
,
log
linear
model
,
stolcke
,
extensible
language
,
toolkit
,
proceeding
,
international
conference
,
spoken
language
processing
,
tromble
,
shankar
kumar
,
och
,
gang
macherey
,
lattice
minimum
bayes
risk
decoding
,
statistical
machine
translation
,
ine
mnlp
,
naa
cl
,
short
paper
,
association
,
computational
linguisticsefficient
extraction
,
oracle
best
translation
,
hypergraphszhifei
li
,
sanjeev
,
language
,
speech
processing
,
computer
sciencethe
hopkins
,
baltimore
,
gmail
,
eduabstracthypergraphs
,
several
syntax
inspired
method
,
machine
translation
,
many
translation
hypothesis
,
hypothesis
,
togiven
reference
translation
,
brute
force
,
popular
measure
,
closeness
,
dynamic
program
,
oracle
best
hypothesis
,
problem
,
findingthe
,
likely
hypothesis
,
n
gramlanguage
model
,
reference
translation
,
massive
redundancy
,
dynamicprogram
state
,
sparsity
,
reference
translation
,
efficient
program
,
present
runtime
statistic
,
program
,
demonstrate
successful
application
,
hypotheses
,
target
,
translation
system
component
,
ntroductiona
hypergraph
,
chi
ang
,
compact
data
structure
,
exponential
number
,
hypothesis
,
hile
thehypergraph
,
large
set
,
translations
,
reference
translation
,
hypergraph
,
inherentdeficiency
,
translation
model
,
translation
,
pergraph
,
translations
,
similarity
,
papineni
,
similar
translation
,
oracle
best
translation
,
process
,
themoracle
extraction
,
oracle
extraction
,
nontrivialtask
,
similarity
,
onehypothesis
,
information
,
manyitems
,
hypergraph
,
largenumber
,
hypothesis
,
brute
force
linearsearch
,
structure
,
hypergraph
,
efficient
oracle
extraction
algorithm
,
key
idea
,
oracle
extraction
,
bottom
up
modelscoring
process
,
hypergraph
,
algorithm
,
lattice
,
dreyeret
,
separate
dynamic
programming
,
sequence
,
sequence
,
search
,
novel
lookahead
technique
,
equivalent
oracle
state
maintenance
,
multiplestates
,
similarity
computation
,
equivalent
oracle
state
maintenance
technique
,
oracle
extraction
,
efficient
oracle
extraction
,
important
application
,
machine
translation
,
discriminative
training
,
discriminative
training
,
objective
,
model
parameter
,
weight
,
perceptron
model
,
conditionalrandom
field
,
reference
translation
,
competitor
,
referencetranslations
,
translationsystem
,
hypothesesshould
,
training
,
combination
,
component
system
,
translation
,
whichare
,
confusion
network
,
theconfusion
network
,
language
,
final
translation
,
goodness
,
ahypothesis
,
confusion
network
,
component
system
,
translation
,
confusion
network
,
component
system
,
whichcase
,
similar
reachabletranslation
serf
,
good
approximation
,
multi
source
translation
,
multi
sourcetranslation
task
,
multiple
source
language
,
situation
,
system
combination
,
component
translation
system
,
a
h
ypergraphin
,
oracle
extraction
algorithm
,
translation
,
pergraph
,
maximum
ble
score1
withrespect
,
corresponding
reference
translation
,
ble
score
,
hypothesis
,
first
component
,
brevity
penalty
,
second
component
,
tothe
geometric
mean
,
n
gram
precision
pn
,
hile
ble
,
thecorpus
level
,
purpose
,
oracle
extraction
,
key
idea
,
oracle
best
hypothesis
,
hypergraph
,
model
scoringour
first
key
idea
,
oracle
,
bottom
up
model
,
process
,
pergraph
,
reference
translation
,
method
,
metric
,
n
gram
dependency
,
compact
data
structure
,
lattice
,
hypergraph
,
hypothesis
,
maximum
,
log
bleu
value
,
log
probability
,
search
,
leftand
right
side
lmcontext
,
length
,
partial
translation
,
n
gram
precision
,
search
,
algorithm
,
ateach
item
,
vector
,
maximum
number
,
n
grammatches
,
partial
translation
,
oracle
state
,
anitem
,
uniqueness
,
lm
context
,
span
length
,
vector
,
n
gram
match
count
,
computation
,
thebrevity
penalty
,
explicit
alignment
,
source
,
exact
reference
length
,
intermediate
item
,
exact
value
,
brevity
penalty
isthus
,
true
reference
length
,
product
,
thelength
,
source
string
,
length
,
wholereference
,
effectof
clipping
,
global
feature
,
thestrict
computation
,
quality
,
oracle
best
hypothesisas
,
thebleu
score
,
hypergraph
,
process
,
first
stage
decoding
,
hypergraph
rescoring
stage
,
inthe
latter
,
hypergraph
,
thefirst
stage
decoding
,
superset
,
dp
state
,
oracle
extraction
,
first
stage
hypergraph
,
new
item
,
detailed
state
,
hypergraph
,
state
information
,
oracle
best
hypothesis
,
k
best
hypothesis
,
hyper
graph
,
thealgorithm
,
chiang
,
ble
uitem
,
computation
,
approximated
reference
length
,
oracle
best
hypothesis
,
hypergraph
,
slow
dueto
,
dedicated
item
,
combination
,
left
lm
state
,
right
lm
state
,
hypothesis
length
,
baseline
system
,
order
issmaller
,
original
hypergraph
,
many
sub
items
duringthe
search
,
extraction
,
secondkey
idea
,
equivalent
oracle
state
,
roughly
speaking
,
different
state
,
different
language
model
word
,
single
state
,
notaffect
ble
,
left
sidelm
state
,
thatthe
reference
,
withthem
,
ignore
,
last
word
,
combinationof
,
left
side
lm
state
,
n
gram
match
,
ble
computation
,
regardless
,
prefix
,
hypergraphthey
combine
,
right
side
lm
,
reference
,
n
gram
startingwith
,
first
word
,
reduction
,
figure
,
whereis
a
prefix
,
is
a
suffix
,
prefix
,
equivalent
oracle
state
maintenance
technique
,
practice
,
numberof
distinct
item
,
hypergraph
,
oracle
extraction
,
ifall
hypothesis
,
hypergraph
,
contain
munique
n
grams
,
total
number
,
equivalent
item
,
multiplicative
factorthat
,
right
side
lm
stateeq
l
state
,
is
a
suffix
,
break
stop
,
els5
else6
el
,
state7
return
elsfigure
,
equivalent
left
lm
state
computation
,
eq
r
state
,
is
a
prefix
,
break
stop
,
ers5
else6
,
state7
return
ersfigure
,
equivalent
right
lm
state
computation
,
maintenance
,
multiplicative
factor
,
equivalent
state
maintenance
,
reference
translation
,
byseveral
order
,
magnitude
,
equivalentstates
,
detailed
state
,
consequence
,
inside
parsing
eliminates
,
state
intoa
coarser
state
,
technique
,
li
andkhudanpur
,
large
lm
special
,
en
glish
task
,
similarpipeline
,
data
resource
,
chiang
,
goodness
,
oracle
best
translationstable
,
report
,
average
speed
,
oracle
extraction
,
hypergraphs
,
trigram
lm
,
oracle
extraction
,
hypergraphs
,
basic
dynamic
program
,
equivalent
oracle
state
,
report
,
goodness
,
oracle
best
hypotheses
,
standard
data
set
,
highestachievable
ble
score
,
hypergraph
,
best
unique
string
,
hypergraph
,
n
best
list
,
several
approximations
,
clippingand
,
justify
theseapproximations
,
best
unique
oracles
,
hypergraph
,
oracles
,
true
sentence
level
ble
,
lastrow
,
report
,
reranked
one
best
oraclebleu
score
,
approximation
,
oracle
ble
,
baseline
,
baseline
,
oracle
best
gram
ble
,
reference
,
nis
t
ch
inese
mt
datasets
,
critical
component
forhypergraph
based
discriminative
reranking
,
wheremillions
,
model
parameter
,
oracle
best
hypothesis
,
others
,
hypergraph
reranking
,
theforest
reranking
,
monolingual
parsing
,
oracle
best
hypothesisis
,
discriminative
model
,
trainedon
hypergraphs
,
n
best
list
,
khudanpur
,
result
,
demonstrate
,
hypergraph
reranking
witha
discriminative
lm
,
baseline
model
,
test
set
,
tm
likely
suffers
,
test
set
,
discriminative
hypergraph
reranking
,
oracle
best
hypothesis
,
onclusionswe
,
efficient
algorithm
,
oracle
best
translation
hypothesis
,
hyper
graph
,
novel
techniquefor
equivalent
oracle
state
maintenance
,
oracle
extraction
process
,
algorithm
,
clear
application
,
discriminative
training
,
multi
source
translation
,
referencesd
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
khudanpur
,
constraint
,
smt
using
efficientbleu
oracle
computation
,
reranking
,
discriminative
parsing
,
nonlocal
feature
,
chiang
,
k
best
parsing
,
inp
roc
,
chiang
,
rescoring
,
integrated
language
model
,
statisticalphrase
based
translation
,
naa
cl
,
khudanpur
,
a
scalable
decoder
forparsing
based
machine
translation
,
equivalentlanguage
model
state
maintenance
,
khudanpur
,
large
scale
discriminative
n
gram
language
model
,
statistical
machinetranslation
,
statistical
multisource
translation
,
method
,
automatic
evaluation
,
machinetranslation
,
schwartz
,
improved
word
level
system
combination
,
machinetranslation
,
columbus
,
association
,
computational
,
translation
induction
,
abbreviationsusing
monolingual
corporazhifei
li
,
yarowskydepartment
,
computer
science
,
language
,
speech
processingjohns
hopkins
,
baltimore
,
gmail
,
eduabstractchinese
abbreviation
,
used
inmodern
text
,
compared
withenglish
abbreviation
,
mostlyacronyms
,
truncation
,
formation
ofc
hinese
abbreviation
,
richness
,
abbreviation
,
available
parallel
corpus
,
current
machinetranslation
system
,
unknown
word
,
inthis
paper
,
novel
unsupervisedmethod
,
relationbetween
,
full
form
phrase
,
abbreviation
,
monolingual
corpus
,
inducestranslation
entry
,
abbreviation
,
full
form
,
bridge
,
method
doesnot
,
regular
translation
systemuses
,
method
,
state
of
the
baseline
translation
system
,
performanceof
,
baseline
system
,
various
nis
t
mt
test
set
,
ntroductionthe
modern
language
,
mixed
use
,
ancient
single
character
word
,
modern
multi
character
wordsand
word
,
typicalnews
article
,
abbreviations
,
development
,
weblog
,
newsgroup
,
en
glish
word
,
abbreviation
examplesfirst
letter
,
acronym
,
truncation
,
formation
,
abbreviation
,
figure
,
abbreviations
,
clearly
,
abbreviated
form
,
charactersfrom
,
character
,
atany
position
,
extreme
,
full
form
phrase
,
abbreviation
,
research
,
significant
progress
,
mostsmt
system
,
chiang
,
galley
,
parallel
corpus
,
extracttranslation
entry
,
richness
,
abbreviation
imposes
challenge
,
many
abbreviations
,
available
parallel
corpus
,
current
smt
system
,
asunknown
word
,
translation
quality
,
a
c
hinese
abbreviation
thatis
,
available
parallel
corpus
,
parallel
data
,
many
possible
abbreviations
,
new
abbreviation
,
abbreviation425into
,
full
form
,
current
smt
,
baselinesystem
,
translation
,
hong
kong
governor
,
abbreviation
,
hong
kong
governor
,
abbreviation
,
parallelcorpora
,
full
form
phrase
,
additional
alternative
,
abbreviation
,
full
form
containsmore
context
information
,
right
translation
,
abbreviation
,
conceptually
,
abbreviation
,
full
form
,
bridge
,
component
,
identifying
abbreviation
,
full
forms
,
translation
,
abbreviation
translation
,
thebaseline
smt
system
,
component
,
components
,
data
thattags
,
abbreviation
,
full
form
,
baseline
system
,
leastone
valid
translation
,
full
form
phrase
,
additional
componentinto
,
baseline
smt
system
,
tricky
asevident
,
research
,
smt
system
,
differentways
,
integration
lead
,
conclusionson
,
mt
performance
,
etal
,
carpuat
,
unsupervised
approach
,
abbreviation
,
data
occurrence
phenomenaand
,
parallel
,
monolingual
corpus
,
smt
system
,
abbreviation
translation
,
baseline
system
,
natural
,
minimum
error
rate
training
,
model
parameters
,
change
,
baseline
system
,
experiments
,
abbreviationtranslations
,
translation
performance
,
papineni
,
various
nis
t
mt
test
set
,
ackground
,
abbreviationsin
general
,
abbreviation
,
method
,
reduction
,
elimination
andgeneralization
,
category
,
method
,
reduction
,
abbreviation
,
character
,
thewords
,
full
form
phrase
,
characters
,
position
,
table
1presents
,
character
,
different
position
,
abbreviations
,
abbreviation
,
fromnoun
phrase
,
particular
,
entity
,
othergeneral
phrase
,
second
,
save
energy
,
verb
phrase
,
extreme
,
betweenan
abbreviation
,
full
form
phrase
,
seventh
,
monotoneabbreviation
,
popular
ordering
,
text
,
elimination
,
original
full
form
phrase
,
rest
partsremain
,
abbreviation
,
abbreviation
,
generalization
,
abbreviation
,
parallel
subparts
,
full
formphrase
,
prevention
,
abbreviation
,
phrase
,
theft
prevention
,
traffic
accident
prevention
,
subparts
,
thefull
form
,
unsupervised
methodto
induce
translation
entry
,
abbreviations
,
abbreviation
,
inthe
side
,
parallel
corpus
,
basicidea
,
relation
,
full
form
phrase
,
abbreviation
,
therelation
,
full
abbreviation
,
monolingual
corpora
,
translation
entry
,
abbreviation
,
full
form
phrase
,
bridge
,
nuclear
energy
power
plantelimination
,
tsinghua
universitygeneralization
,
abbreviation
,
category
,
examplesour
approach
,
step
,
extract
full
abbreviation
relation
fromchinese
monolingual
corpus
,
thechinese
translation
,
step
,
full
form
phrase
,
translation
entry
,
chineseabbreviations
,
full
form
phrasesas
bridge
,
augment
,
baseline
system
withtranslation
entry
,
step
,
clearly
,
main
purpose
,
step
,
entity
,
treatedas
full
form
phrase
,
step
,
namedentity
tagger
,
relies
,
existence
,
a
c
hinese
,
entity
tagger
,
high
precision
,
dedicated
tagger
,
thebaseline
system
,
entities
,
translation
output
,
entity
,
baseline
system
,
entity
,
data
resource
,
monolingual
corpus
,
parallel
corpus
,
monolingual
corpus
,
withthe
baseline
system
,
monolingual
datato
help
,
smt
system
,
onlythe
monolingual
data
,
languagemodel
,
enormous
monolingual
data
,
smallamount
,
parallel
data
,
translation
task
,
gigaword
,
billion
,
parallel
data
,
step
,
natural
,
abbreviation
translation
component
,
baselinetranslation
system
,
abbreviation
translation
,
performance
gain
,
thebaseline
system
,
remainder
,
aspecific
instantiation
,
englishmonolingual
corporathough
,
sophisticated
named
entitytagger
,
entity
,
entity
,
capitalizationinformation
,
entity
,
continuous
span
,
word
,
condition
,
function
word
,
occurrence
count
,
language
pair
,
mt
research
,
translation
,
reverse
direction
,
sincemost
,
statistical
translation
model
,
chiang
,
galley
,
translationsystem
,
a
c
hinese
language
model
fromthe
monolingual
data
,
baseline
systemmay
,
entities
,
entity
,
fromthe
monolingual
corpus
,
muchlarger
vocabulary
,
side
,
parallel
corpus
,
thechinese
translation
,
untranslatedenglish
word
,
next
step
,
n
best
listinstead
,
best
translation
,
entity
,
entity
,
full
form
phrase
,
abbreviation
,
hmm
model
,
data
occurrence
intuition
,
occurrencein
,
monolingual
corpus
,
relevant
word
,
gate
,
microsoft
,
occurrence
,
gate
,
founder
,
inspection
,
text
,
dataco
occurrence
phenomenon
,
data
occurrence
,
meaning
,
winter
olympics
,
abbreviation
relation
,
titlewhile
,
textof
,
occurrencedistance
,
abbreviation
,
full
formvaries
,
samesentence
,
data
occurrence
phenomena
,
possible
abbreviation
,
full
formphrases
,
figure
,
pseudocode
,
thefull
abbreviation
relation
extraction
algorithm
,
relation
extraction
,
corpus
,
full
list
,
corpus
,
corpus
,
sent16
,
full
list7
,
contexts8
,
sent29
,
return
countfigure
,
full
abbreviation
relation
extractiongiven
,
monolingual
corpus
,
algorithm
return
,
full
abbreviation
relation
,
occurrencecounts
,
algorithm
,
whole
corpus
,
alongthe
,
algorithm
,
contextsremember
,
algorithmidentifies
possible
abbreviation
,
implementation
,
context
,
title
,
algorithm
,
full
abbreviation
relation
,
betweenfull
,
count
table428
,
relation
,
filtering
,
throughlarge
size
monolingual
corpus
,
function
,
simple
alignment
algorithm
,
character
,
wordsin
,
alignment
,
valid
full
abbreviation
relation
,
following
condition
,
character
,
character
,
continuous
subpart
,
clearly
,
condition
,
approachmay
,
possible
abbreviation
,
abbreviation
,
generalizationmethod
,
condition
,
alignment
algorithm
,
complex
full
abbreviation
relation
,
count
table
count
,
therelative
frequency
,
chineseabbreviationsgiven
a
c
hinese
abbreviation
,
full
form
,
translation
entry
,
abbreviation
,
full
form
,
bridge
,
n
best
translation
,
full
form
phrase
,
baseline
system
,
translation
output
thatthey
,
sameset
,
model
feature
,
regular
phrase
entry
,
method
,
full
formphrase
,
en
glish
entity
,
full
form
phrase
,
entity
,
besttranslation
,
baseline
system
,
full
form
phrase
,
asymmetry
,
different
lm
,
different
translation
direction
,
baseline
phrase
table
,
translation
entry
,
full
form
,
abbreviation
,
translation
entry
,
abbreviation
,
abbreviation
,
severalcandidate
full
form
phrase
,
feature
value
,
full
abbr
,
translation
,
j
thmodel
feature
,
baseline
system
,
baseline
translationsystemsince
,
translation
entry
,
abbreviations
,
format
,
regular
translation
entry
,
baseline
phrase
table
,
baseline
phrase
,
translation
entry
,
signatured
byits
,
string
,
inthe
baseline
phrase
table
,
entryinto
,
baseline
table
,
entry
,
baseline
phrase
table
,
translation
probability
,
translation
entry
fromtwo
different
knowledge
source
,
parallel
corpus
,
chinesemonolingual
corpus
,
augmented
phrase
table
,
minimum
error
rate
training
,
augmented
phrase
table
,
themodel
parameter
,
experimental
result
,
critical
toobtain
performance
gain
,
parallel
dataset
,
various
corpus
,
nis
t
mt
evaluation
,
parallel
dataset
,
about28m
word
,
monolingual
data
,
baseline
system
,
toolkit
,
phrase
based
baseline
system
,
following429the
standard
procedure
,
running
,
direction
,
refinementrules
,
many
to
many
word
alignment
,
andthen
extracting
,
scoring
phrase
,
heuristic
,
baseline
system
,
function
,
feature
functions
,
log
linear
framework
,
weight
,
minimum
error
ratetraining
,
papineni
,
optimization
,
different
direction
,
translation
between
,
trigram
language
model
,
modified
kneser
neysmoothing
,
goodman
,
thesrilm
toolkit
,
stolcke
,
statistic
,
intermediate
stepsas
,
approach
involvesfive
step
,
report
,
statistic
,
intermediate
step
,
entities
,
best
translationsare
,
entity
,
entity
,
theenglish
entity
,
baselinesystem
,
full
abbreviation
,
monolingual
corpus
is51k
,
full
form
phrase
,
bestenglish
translation
,
translation
entry
,
thebaseline
system
,
unique
translations
,
full
form
phrase
,
thenumber
,
translation
entry
,
abbreviations
,
total
numberof
translation
entry
,
measure
valuenumber
,
entity
,
entity
,
full
abbreviation
relation
,
translation
entry
,
translation
entry
,
statistic
,
intermediate
steps2note
,
abbreviation
,
algorithm
,
true
abbreviation
,
linguistic
sense
,
insteadthey
,
continuous
span
,
phrase
,
full
abbreviation
relationstable
,
precision
,
extracted
full
abbreviation
relation
,
relation
intoseveral
class
,
occurrence
count
,
inthe
second
column
,
fraction
,
relations
,
relation
,51
k
relation
,
relation
,
tag
themas
correct
,
precision
,
occurrence
countshould
,
precision
,
fourth
column
,
incomparison
,
precision
,
relation
,
single
word
full
forms
,
single
character
abbreviation
,
canimagine
,
precision
,
general
relation
,
relation
,
multi
word
full
formsand
multi
character
abbreviation
,
result
,
precision
,
full
abbreviation
relation
extraction
precisionto
,
advantage
,
relation
extraction
algorithm
,
third
column
,
result
,
simplebaseline
,
baseline
,
thedominant
abbreviation
pattern
,
abbreviation
pattern
,
theformat
,
bit
pattern
length
,
information
,
abbreviatedform
,
original
full
form
word
,
length
,
character
inthe
full
form
word
,
character
,
corresponding
position
,
full
form
word
,
abbreviation
,
character
,
strict
comparison
,
dataset
isdifferent
,
recall
,
dominant
abbreviation
pattern
,
hang
,
baseline
,
full
formphrase
,
randomly
,
relation
,
abbreviation
,
abbreviated
form
,
eachword
,
full
form
phrase
,
dominantabbreviation
pattern
,
abbreviated
word
,
baseline
abbreviation
,
full
form
phrase
,
baseline
performs
,
relationextraction
algorithm
,
baseline
,
relation
extraction
algorithm
,
arbitrary
abbreviation
pattern
,
alignment
constraint
,
algorithm
exploitsthe
data
occurrence
phenomenon
,
tworeasons
,
large
performance
gain
,
statistic
,
abbreviation
pattern
,
relation
,
algorithm
,
report
,
statistics
,
statistic
,
relation
,
correct
,
unique
word
,
corresponding
full
form
phrase
,
result
,
relation
extraction
algorithm
,
statistic
,
collectedexamples
,
please
refer
,
result
,
translation
performance4
,
translation
,
chinesefull
form
phrasesfor
,
relation
,
correct
ins
ection
,
top
translations
,
full
form
phrase
,
top
translations
contain
,
correct
translation
,
correct
,
precision
,
high
becausethe
ble
score
,
precision
,
brevity
penalty
,
thatone
,
reason
,
statistic
,
abbreviation
patternsprecision
,
full
form
phrase
,
full
form
phrase
itself
contains
enough
context
information
,
helpsthe
system
,
right
translation
,
importance
,
full
form
phrase
,
additional
alternative
,
abbreviation
,
baseline
system
,
hastranslation
entry
,
abbreviation
,
nis
t
mt
test
setswe
use
mt02
,
development
set4
,
papineni
,
report
,
results
,
various
nis
t
mt
test
set
,
baseline
system
,
ble
u
sc
,
rerun
mer
,
augmented
phrase
tablein
order
,
performance
gain
,
abbreviationtranslation
entry
,
side
,
mer
weight
,
different
phrase
table
,
onemay
,
change
,
weight
,
word
penaltyfeature
,
thehypothesis
,
expansion
ofthe
abbreviation
,
full
forms
,
feature
baseline
aam
tlanguage
,
translation
,
translation
,
phrase
translation
,
lexical
translation
,
penalty
,
penalty
,
weight
,
mer
t5
related
workthough
,
relation
between
full
form
phrase
,
abbreviations
,
important
task
,
manynatural
language
processing
application
,
machine
translation
,
question
answering
,
informationretrieval
,
much
,
literature
,
relationship
,
full
form
phraseand
,
abbreviation
,
abbreviation
,
observation
,
full
form
word
,
manually
created
full
abbreviation
relation
,
training
data
,
result
,
givenan
abbreviation
,
full
form
,
method
,
full
abbreviation
relation
,
thework
,
relation
,
full
form
phrase
andtheir
abbreviation
,
considered
relation
,
single
word
phrase
andsingle
character
abbreviation
,
hmm
model
,
unable
toexploit
,
data
occurrence
phenomenon
,
we5however
,
hmm
model
,
character
,
abbreviation
,
full
form
,
unsupervised
,
abbreviationsare
,
present
many
,
manualrules
,
abbreviation
,
full
form
,
quantitative
result
,
chi
nese
abbreviation
issue
,
context
,
machinetranslation
task
,
primary
goal
,
thispaper
,
knowledge
,
isthe
,
abbreviation
expansion
,
machine
translation
,
obtain
translation
entry
,
unseen
word
,
abbreviation
,
paraphrase
inm
,
callison
burch
,
referencestherein
,
generalization
,
corpus
,
inspirit
similarto
,
nonparallel
corpus
,
large
amount
,
munteanuand
marcu
,
reference
,
novel
method
,
relation
,
full
formphrases
,
abbreviation
,
monolingualcorpora
,
induces
translation
entry
,
abbreviations
,
full
form
,
bridge
,
ourmethod
,
large
amountof
monolingual
data
,
baseline
translation
system
,
methodexploits
,
data
occurrence
phenomenon
,
relation
extraction
,
integrated
system
,
baseline
system
onvarious
nis
machine
translation
test
set
,
acknowledgmentswe
,
resnik
,
smaranda
muresan
,
dyerand
,
anonymous
reviewer
,
helpful
comments
,
philipp
koehn
,
mile
os
borne
,
statistical
machine
translationusing
paraphrase
,
proceeding
,
naa
cl
,
marine
carpuat
,
statistical
machine
translation
,
word
sense
disambiguation
,
proceeding
,
emn
lp
,
yee
seng
,
chiang
,
word
sense
disambiguation
,
statistical
machine
translation
,
proceeding
,
jing
shin
chang
,
yu
tso
lai
,
preliminarystudy
,
probabilistic
model
,
abbreviations
,
proceeding
,
workshop
onc
hinese
language
processing
,
jing
shin
chang
,
wei
lun
teng
,
miningatomic
abbreviation
pair
,
a
p
robabilisticmodel
,
single
character
word
recovery
,
proceedings
,
workshop
,
chineselanguage
processing
,
goodman
,
empirical
study
,
technique
,
language
modeling
,
technical
report
tr
,
research
,
computing
technology
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
galley
,
graehl
,
knight
,
danielmarcu
,
den
eefe
,
wei
,
ignaciothayer
,
scalable
inference
,
ofcontext
syntactic
translation
model
,
proceedings
,
philipp
koehn
,
hieu
hoang
,
birch
,
chriscallison
burch
,
bertoldi
,
cowan
,
shen
,
moran
,
richardzens
,
dyer
,
ondrej
bojar
,
strantin
,
herbst
,
open
sourcetoolkit
,
statistical
machine
translation
,
proceedings
,
demonstration
session
,
philipp
koehn
,
och
,
marcu
,
statistical
phrase
based
translation
,
proceedings
,
naa
cl
,
automatic
expansion
,
hinese
abbreviation
,
thesis
,
ofh
,
dragos
munteanu
,
marcu
,
extracting
parallel
sub
sentential
fragment
,
nonparallel
corpus
,
proceeding
,
pages81
,
och
,
minimum
error
rate
training
instatistical
machine
translation
,
proceeding
,
och
,
ney
,
improvedstatistical
alignment
model
,
proceeding
,
och
,
ney
,
alignmenttemplate
approach
,
statistical
machine
translation
,
computational
linguistics
,
kishore
papineni
,
roukos
,
wei
jing
zhu
,
method
,
automatic
evaluation
,
machine
translation
,
proceeding
,
stolcke
,
extensible
languagemodeling
toolkit
,
proceeding
,
internationalconference
,
spoken
language
processing
,
methodology
,
principle
,
chi
nese
abbreviation
formation
,47
th
annual
meeting
,
ijc
nlp
,
afn
lp
,
suntec
,
afn
lpva
riational
decoding
,
statistical
machine
translationzhifei
li
,
eisner
,
sanjeev
khudanpurdepartment
,
computer
science
,
language
,
speech
processingjohns
hopkins
,
baltimore
,
gmail
,
eduabstractstatistical
model
,
machine
translationexhibit
spurious
ambiguity
,
output
string
,
splitamong
many
distinct
derivation
,
segmentation
,
principle
,
thegoodness
,
string
,
thetotal
probability
,
many
derivation
,
during
decoding
,
system
usea
simple
viterbi
approximation
,
goodness
,
string
,
onlyits
,
probable
derivation
,
variational
approximation
,
derivation
,
tractable
decoding
,
particularvariational
distribution
,
parameterizedas
n
gram
model
,
n
gram
models
,
different
,
minimum
risk
decoding
,
issue
,
natural
languageprocessing
,
many
system
,
ambiguities
,
particular
syntaxtree
,
interesting
latent
variable
,
syntax
tree
,
translation
,
observed
input
,
many
ambiguities
,
additional
latent
variable
,
so
called
nuisance
variable
,
interest
,
output
,
string
,
typicalmt
system
,
chiang
,
nuisance
variable
,
trainingdata
,
supervision
,
particular
derivation
,
output
string
,
alignment
,
input
string
,
competing
derivation
,
string
,
interchangeable
forum
user
,
string
,
soa
system
,
amongthem
,
spurious
ambiguity
,
course
,
nuisance
variable
,
importantcomponents
,
translation
process
,
language
,
another
language
,
hidden
tree
transformation
process
,
recursive
fashion
,
manyfeatures
,
referenceto
hidden
structure
,
alignment
,
spuriousambiguity
,
nuisancevariables
,
cause
significant
computational
difficulties
,
goodness
,
possible
mt
output
string
,
upthe
probability
,
derivation
,
string
,
casacuberta
andhiguera
,
probable
derivation
,
corresponding
string
,
correspondsto
a
v
iterbi
approximation
,
goodness
,
output
,
probable
derivation
,
others
,
variational
methodthat
,
derivation
,
allowstractable
decoding
,
input
string
,
original
system
,
probability
distribution
,
possible
output
string
,
derivation
,
nuisance
variable
,
ur
method
,
wellas
,
string
according
,
last
step
,
reference
tonuisance
variable
,
notice
,
entire
translation
process
,
knight
,
tree
automaton
determinization
,
nuisance
variable
,
distribution
,
parsedtranslations
,
theseparse
tree
,
distribution
,
translation
string
,
distribution
,
output
string
,
particularinput
,
good
approximation
,
nuisance
variable
,
practice
,
several
different
variational
family
,
markov
,
different
order
,
approximations
,
interpolation
,
similarto
,
minimum
risk
decoding
,
ble
proposedby
tromble
,
thatour
approach
,
method
,
spurious
ambiguity
,
application
,
mixture
model
,
latent
variable
,
ourmethods
,
past
,
variational
decoding
,
goodman
,
forlatent
variable
parsing
,
matsuzaki
,
regularphrase
based
system
,
different
segmentation
,
sametranslation
string
,
differentderivation
tree
,
string
,
hiero
system
,
chiang
,
corresponds
,
distinctderivations
,
average
,
input
string
,
derivation
,
bythe
system
,
sometranslation
,
target
language
,
derivation
,
translation
,
model
ist
,
forthe
translation
string
,
output
,
decoding
,
output
,
decision
rule
isy
,
argmaxy
,
segmentation
ambiguity
,
translation
,
machine
,
machine
,
ambiguity
,
derivationtrees
,
translation
string
,
alternative
decision
rule
,
nuisance
variable
,
derivation
,
map
decision
rule
becomesy
,
argmaxy
,
log
linear
model
,
scaling
factor
,
sharpness
,
distribution
,
linear
combination
,
triple
,
normalization
constant
,
polynomial
space
,
hypergraph
,
lattice
,
owever
,
themarginalization
need
,
eachmember
,
decoding
problem
,
np
hard
,
similar
problem
,
hypergraph
,
parse
,
finite
state
lattice
,
many
hypothesis
,
marginalization
,
particular
,
training
time
,
objective
function
,
conditional
likelihood
ofa
reference
translation
,
blunsom
,
mt
system
,
chi
ang
,
simple
viterbi
approximation
,
argmaxy
,
pviterbi
,
probability
ofa
translation
string
,
probability
,
most
probable
derivation
,
viterbi
approximation
,
derivation
,
approximation
,
crunching
,
popular
approximation
,
nbest
derivation
,
derivationsis
,
crunching
,
knight
,
pcrunch
,
variational
approximate
decodingthe
viterbi
,
method
,
approximate
,
intractable
decoding
,
ignoring
,
derivation
,
novel
variational
approximation
,
derivation
,
several
popular
approach
,
approximate
inference
,
exact
inference
,
limitof
infinite
runtime
,
largeproblems
,
contrast
,
deterministic
variationalmethods
,
message
passing
,
scale
upwell
,
original
intractabledistribution
,
fast
variational
method
,
variational
method
,
exact
inference
,
complex
model
pi
,
posteriorp
,
simpler
modelq
,
surrogate
,
inference
,
baseline
mt
system
,
derivation
,
approximate
distributionq
,
kl
divergence
,
distribution
,
argminq
,
argmaxq
,
computingp
,
decoding
,
simpler
,
isthe
,
factorized
distribution
,
estimation
,
tractable
throughefficient
dynamic
program
,
subsections
,
parameterization
,
estimation
,
decoding
,
family
,
distribution
,
large
family
,
complex
distribution
,
approximate
,
family
,
baseline
system
,
pruned
hypergraph
,
effect
,
convention
,
variational
inference
,
avoid
clutter
,
respectto
,
change
argmin
,
simple
form
withmany
conditional
independency
,
distribution
,
outputstrings
,
natural
choice
,
family
ofn
gram
model
,
lastpoint
,
computation
becomesintractable
,
structure
,
m
gram
language
model
,
training
,
decoding
,
algorithm
,
thatare
linear
,
stringy
,
gramprefix
,
history
,
gram
suffix
,
rightmost
,
whole
translation
string
,
dynamic
programming
state
,
computation
cost
somehow
,
aggressive
beam
pruning
,
large
scale
system
,
method
,
nota
viable
solution
,
experimentsthat
,
reviewer
asks
,
interaction
,
backed
offlanguage
model
,
compact
finite
state
representation
,
allauzen
,
whichexploit
backoff
structure
,
compact
hypergraphs
,
khudan
pur
,
hypergraphs
,
gram
,
method
,
language
,
weighted
fsa
,
variational
family
canbe
,
version
,
weight
,
expectationsemiring
,
eisner
,
expectedtransition
count
,
expectation
,
sufficient
statistic
,
left
to
rightrefinement
,
prefix
string
,
anystates
,
n
gram
model
,
figure
,
pure
n
grammodel
,
n
grams
,
variational
family
,
topology
,
conditional
probability
distributions
,
parameter
,
test
time
,
constructedfrom
channel
,
language
model
,
finite
training
data
,
empirical
distribution
overstrings
,
training
corpus
,
justthe
maximum
likelihood
n
gram
model
,
whoseparameters
,
unsmoothed
ratio
,
gram
count
,
trainingcorpus
,
actual
,
corpus
,
hypergraphhg
,
change
,
integer
,
corpus
,
question
,
theintuition
,
brute
force
algorithmin
figure
,
algorithm
,
brute
force
sinceit
,
hypergraph
,
possible
derivation
,
hypergraph
,
algorithm
,
soft
countinto
,
expected
count
,
parameters
,
count
ratio
,
figure
,
efficient
version
,
exploitsthe
packed
structure
,
expected
count
,
inside
outside
procedure
,
inside
outsidealso
find
,
total
weight
,
derivation
,
weight
,
algorithm
,
hypergraph
,
expected10one
,
lagrange
multiplier
,
normalized
distribution
,
derivation2
forw
,
formula
,
brute
force
estimation
,
hyperedge4
ce
,
antecedent
node6
ce
,
accumulate
soft
count8
forw
,
formula
,
estimation
,
hyperedges
,
represents
,
weight
,
hyperedge
,
representsthe
set
,
antecedent
node
,
hyperedge
,
please
,
tothe
text
,
meaning
,
notation
,
hyperedge
,
theposterior
weight
ce
,
expectedcount
,
number
ofcopies
,
n
gram
,
theyields
,
antecedent
,
many
derivations
,
hypergraph
data
structure
representsthem
,
polynomial
space
,
multiplederivations
,
share
subderivations
,
algorithmof
figure
,
hyper
graph
,
hyperedges
,
runtime
,
surrogate
,
during
decoding
,
probable
string
,
n
gram
model
,
shortest
path
problem
,
certain
graphwhose
edge
,
n
grams
,
weightedwith
negative
log
probabilities
,
ver
tices
correspond
,
translation
,
short
stringsy
,
length
,
souris
,
bigram
approximation
,
themost
,
high
probability
,
search
space
,
valid
string
,
outinadequate
translation
,
sole
objective
,
good
approximation
,
singlen
gram
model
,
computational
constraint
,
reference
translation
,
theyare
,
derivation
,
order
,
mt
evaluation
,
papineni
,
partialcredit
,
lower
order
n
grams
,
reference
,
less
likely
high
order
n
grams
,
reason
,
interpolate
different
order
,
variational
model
,
argmaxy
,
whichcase
log
,
conventional
word
penalty
feature
,
geometric
interpolation
,
weight
,
relativeveto
power
,
n
gram
approximation
,
minimumrisk
procedure
,
eisner
,
viterbi
,
variational
approximation
,
different
,
exact
probability
,
haspros
,
viterbi
approximation
,
correct
probability
,
complete597derivation
,
derivation
,
hypergraph
,
comparison
,
variational
approximation
considers
,
derivation
,
pergraph
,
aggregate
statistic
,
fragments
,
derivation
,
desirable
tointerpolate
,
viterbi
approximationwhen
,
final
translation
output
,
argmaxy
,
log
pviterbi
,
first
term
corresponds
,
interpolatedvariational
decoding
,
second
termcorresponds
,
viterbi
decoding
,
second
term
,
translations
,
good
derivation
,
decoder
,
then
gram
variational
approximation
,
hypergraph
topology
,
hyperedge
weight
,
theoriginal
weight
,
derivation
,
score
oflog
,
weight
,
best
scoring
derivation
,
output
,
target
yield
,
map
decoding
,
decision
rule
,
argminy
,
bestapproximations
,
complication
,
similar
decision
rule
,
hereand
,
posterior
n
gram
probability
,
featurefunctions
,
model
estimation
,
decoding
,
overan
,
translation
,
derivation
,
hypergraph
,
hypergraph
,
thanks
,
largeor
,
translation
model
,
heuristic
,
bad
translation
,
translation
,
tiny
probability
,
problem
,
itpenalizes
translation
,
hyper
graph
,
extreme
,
translation
,
hypergraphat
,
log
pviterbi
,
decoder
,
additional
hypothesis
,
system
combination
,
trueanswer
,
expectedloss
,
statistical
decision
theory
,
true
distribution
,
whilein
practice
,
mbr
decoding
,
following
loss
function
,
linear
approximation
,
special
,
n
gramtypes
,
occurrence
,
n
gram
,
anindicator
function
,
contains
,
leastone
occurrence
,
loss
function
,
tromble
et
,
mbr
rule16y
,
argmaxy
,
probability
,
n
gram
,
n
gramtypes
,
different
,
several
subset
,
eachof
,
givenlength
,
argmaxy
,
interpolationin
,
several
important
difference
,
intersection
,
n
gram
,
thelattice
,
lattice
,
tromble15the
mbr
,
map
decision
rule
,
so
called
zero
one
loss
function
,
alattice
,
hidden
structure
,
method
,
principle
,
hypergraph
,
spurious
ambiguity
,
optimal
n
gramprobabilities
,
theinside
outside
algorithm
,
historyof
,
thedefinition
,
n
gram
model
,
proper
probabilistic
model
,
thefunction
,
approximation
,
theaverage
n
gram
precision
,
andminimum
risk
decoding
,
derivationabove
,
developedan
alternate
,
consensus
decoding
,
practice
,
open
source
mt
toolkit
,
chiang
,
experimental
setupwe
,
translation
task
,
translation
model
,28
m
word
,
eachlanguage
,
nis
t
mt
evaluation
,
method
,
n
gram
match
,
training
,
test
set
,
foreign
side
,
gram
language
model
,
modified
kneser
ney
smoothing
,
goodman
,
dataset
consisting
,
side
,
theparallel
corpus
,
suffix
array
,
stol
cke
,
risk
based
deterministic
annealing
,
eisner
,
word
alignments
,
translation
model
,
language
model
,
optimal
weight
,
standard
beam
pruning
andcube
pruning
parameter
setting
,
chi
ang
,
hypergraphs
,
nis
t
mt
,
scaling
factor17we
,
deterministic
annealing
,
result
,
viterbi
,
variational
decoding
,
overthe
viterbi
baseline
,
paired
permutation
test
,
ineach
column
,
result
,
unique
string
,
derivation
,
average
,
string
,
distinct
derivation
,
thevariational
method
,
variational
n
gram
model
,
theviterbi
baseline
,
word
penalty
feature
,
blind
test
sets
,
result
,
lowercase
ble
u
,
reference
translation
,
computing
brevity
penalty
,
present
,
viterbi
,
variational
decoding
,
bothcrunching
,
slight
significant
improvements
,
viterbi
baseline
,
substantial
improvement
,
difference
,
distribution
,
distinct
string
,
measure
,
derivation
,
different
variational
decodingtable
,
ble
result
,
differentways
,
variational
model
,
discussedin
,
viterbi
baseline
,
exceptthe
,
different
order
,
interpolation
,
wordpenalty
feature
,
ble
score
,
observation
,
tromble
et
,
restrict
,
thesame
approximation
,
decoding
,
single
variational
modeldecoding
scheme
,
interpolation
,
single
variationalmodel
,
word
penalty
feature1gram
wp
,
single
variational
model
,
theviterbi
model
,
word
penalty
feature1gram
wp
vt
,
several
n
gram
vms
,
theviterbi
model
,
word
penalty
feature1to2gram
wp
vt
,
different
variational
,
result
,
viterbi
,
paired
permutationtest
,
systemsthat
,
brevity
penaltybp
,
average
,
reference
translation
,
brevity
penalty
,
higher
order
vms
,
viterbi
feature
,
interpolation
,
improvesthe
lower
order
model
,
improvements
,
viterbi
baseline
,
interpolation
,
several
variational
model
,
further
improvement
,
previous
model
,
result
,
approximate
modelswhile
,
ble
score
,
practical
utility
,
variational
model
,
individualvariational
model
,
distribution
,
quality
,
approximation
,
cross
entropy
,
cross
entropies
,
various
approximations
,
notation
,
cross
entropies
,
total
numberof
test
word
,
perfect
approximation
,
best
list
,
entropy
,
different
model
,
report
thecross
entropies
,
various
model
,
derivational
entropyhd
,
estimate
,
thatthe
,
best
list
,
confirms
,
higher
order
variationalmodels
,
family
,
approximate
,
improvement
,
unigram
,
bi
gram
model
,
show
thatbetter
approximation
,
usinghigher
order
model
,
ble
score
,
tables
,
bigram
model
,
referencetranslation
,
good
jobof
,
bigram
,
reference
translation
,
ble
score
reward
,
future
workwe
,
general
variational
inference
framework
,
large
scale
mttask
,
intractable
problem
ofm
ap
,
presence
,
spurious
ambiguity
,
variational
model
,
viterbi
approximation
cancompensate
,
poor
approximation
,
thebayes
risk
,
empirical
results
,
expectation
,
many
derivation
,
expectationsemiring
,
eisner
,
interesting
research
direction
,
intractable
map
decoding
problem
,
different
variational
distribution
,
interpolation
,
constituent
model
,
zhangand
gildea
,
best
translation
,
n
gram
models
,
nonlocal
string
feature
,
rosenfeld
,
expectation
,
features
,
hypergraph
,
variational
inference
,
many
intractable
problem
,
word
phrase
alignment
,
system
combination
,
method
,
task
beyondmt
,
intractable
map
,
speech
recognition
,
context
free
grammarwith
,
finite
state
automaton
,
nederhof
,
referencescyril
allauzen
,
mehryar
mohri
,
roark
,
algorithm
,
statistical
language
model
,
pattern
recognition
andmachine
learning
,
springer
,
blunsom
,
cohn
,
mile
,
discriminative
latent
variable
model
,
statisticalmachine
translation
,
casacuberta
,
de
higuera
,
computational
complexity
,
problem
,
probabilistic
grammar
,
transducer
,
goodman
,
empirical
study
,
technique
,
technical
report
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
den
ero
,
chiang
,
knight
,
fast
consensus
,
translation
,
cl
ijcnlp
,
eisner
,
parameter
estimation
,
probabilistic
finite
state
transducer
,
efficient
algorithm
,
dop
model
,
emn
lp
,
liang
huang
,
chiang
,
rescor
ing
,
integrated
language
models
,
jaakkola
,
variational
methods
,
graphical
model
,
philipp
koehn
,
och
,
marcu
,
statistical
phrase
based
translation
,
inn
aacl
,
zhifei
li
,
sanjeev
khudanpur
,
scalabledecoder
,
parsing
based
machine
translation
withequivalent
language
model
state
maintenance
,
cl
sss
,
dyer
,
juriganitkevitch
,
sanjeev
khudanpur
,
schwartz
,
weese
,
zaidan
,
open
source
toolkit
,
parsing
based
machine
translation
,
lopez
,
hierarchical
phrase
based
translation
,
suffix
array
,
emn
lp
conll
,
pages976
,
takuya
matsuzaki
,
yusuke
miyao
,
ichi
tsujii
,
probabilistic
cfg
,
latent
annotation
,
cl
,
knight
,
n
bestlist
,
practical
determinization
,
weighted
finite
treeautomata
,
naa
cl
,
minka
,
divergence
measure
,
microsoft
research
technical
report
,
nederhof
,
general
technique
totrain
language
model
,
language
model
,
com
put
,
linguist
,
och
,
ney
,
improvedstatistical
alignment
model
,
och
,
minimum
error
rate
training
instatistical
machine
translation
,
kishore
papineni
,
roukos
,
wei
jing
zhu
,
method
,
automatic
evaluation
,
machine
translation
,
rosenfeld
,
xiaojin
zhu
,
whole
sentence
exponential
language
models
,
vehicle
,
linguistic
statistical
integration
,
computer
speech
,
language
,
computational
complexityof
probabilistic
disambiguation
,
tree
grammars
,
eisner
,
minimum
,
log
linear
model
,
stolcke
,
extensible
languagemodeling
toolkit
,
ics
lp
,
tromble
,
shankar
kumar
,
och
,
gang
macherey
,
lattice
minimum
bayes
risk
,
statistical
machine
translation
,
ine
mnlp
,
zen
,
ney
,
n
gram
posterior
probability
,
statistical
machine
translation
,
hao
zhang
,
gildea
,
efficient
multi
pass
decoding
,
synchronous
context
free
grammars
,
acl
ijc
nlp
,
software
demonstration
,
suntec
,
afn
lpde
monstration
,
open
source
toolkitfor
parsing
based
machine
translation
,
weese
,
language
,
speech
processing
,
hopkins
,
computational
linguistics
,
information
processing
lab
,
human
language
technology
,
natural
language
processing
lab
,
minnesotaabstractwe
describe
,
open
source
toolkit
,
statistical
machine
translation
,
implement
,
algorithm
,
translation
,
n
gram
language
model
integration
,
beamand
cube
pruning
,
extraction
,
toolkitalso
implement
suffix
array
grammar
extraction
,
minimum
error
rate
training
,
distributed
computingtechniques
,
scalability
,
demonstration
outline
,
toolkit
,
potential
user
,
newcomer
,
fieldor
power
user
,
remarkable
progress
,
last
fewyears
,
employ
made
,
software
thatis
,
open
source
,
result
,
high
barrierto
entry
,
researcher
,
experiments
,
thispaper
,
a
j
based
general
purpose
open
source
toolkit
,
parsing
based
machine
translation
,
regular
phrase
basedmachine
translation
,
research
,
national
sciencefoundation
,
theviews
,
finding
,
author
,
cite
li
et
,
yourresearch
,
toolkitwhen
,
toolkit
,
generalprinciples
,
software
engineering
,
threemajor
goal
,
extensibility
,
end
to
end
coherence
,
scalability
,
extensibility
,
codebase
,
ofa
separate
java
package
,
aspectof
functionality
,
researcher
,
single
package
,
choosing
,
extensible
component
,
byj
interface
,
unintended
interactions
,
unseen
dependency
,
common
hindrance
,
extensibility
,
large
project
,
wherethere
,
clear
point
,
departure
,
research
,
basic
implementation
,
interface
,
class
,
extension
,
end
to
end
cohesion
,
mt
pipeline
consists
,
many
diverse
component
,
designedby
separate
group
,
different
file
formatsand
interaction
requirement
,
largenumber
,
script
,
format
conversion
,
interaction
,
component
,
resulting
,
non
portable
project
,
repeatability
,
critical
componentsof
,
mt
pipeline
,
component
,
standalone
tool
,
toolkit
,
scalability
,
decoder
,
large
model
,
data
set
,
parsing
,
pruning
algorithm
,
strategiesand
efficient
data
structure
,
suffix
array
grammar
extraction
,
decoding
,
bloom
filter
language
model
,
state
of
the
quality
,
havingbeen
,
task
,
wmt
evaluation
,
top
primary
system
,
task
,
callison
burch
,
human
evaluation
result
,
short
description
,
main
features
,
detail
,
corpus
,
grammar
,
subsetof
,
training
data
,
sentences
,
particular
testset
,
themethod
,
kishore
papineni
,
personal
communication
,
detail
,
reduction
,
corpus
size
,
state
of
the
performance
,
uffix
array
grammar
extraction
,
grammars
,
corporaare
,
availablememory
,
callison
burchet
,
asource
language
suffix
array
,
onlyrules
,
translatinga
particular
test
set
,
direct
access
,
suffixarray
,
decoder
,
allowing
rule
extraction
,
formalism
,
decoder
,
chiang
,
general
scf
g
,
galley
,
related
formalism
,
synchronoustree
substitution
grammar
,
eisner
,
beamand
cube
pruning
,
chiang
,
large
scf
g
,
k
best
extraction
,
chart
parsing
algorithm
,
exponential
number
,
derivation
hypothesis
,
extraction
algorithm
,
chi
ang
,
likely
derivations
,
largeset
,
translation
,
hyper
graph
,
desired
translation
,
deficiency
,
algorithm
,
khudanpur
,
oracle
translation
,
desired
translation
,
decoding
,
wesupport
,
distributedlanguage
model
,
andmulti
processor
architecture
,
khudanpur
,
anguage
model
,
local
n
gram
language
model
,
straightforward
implementation
,
n
gram
scoringfunction
,
standard
arp
,
backoff
n
gram
model
,
native
code
bridge
,
decoder
,
sri
lm
toolkit
,
a
b
loom
filter
implementation
,
inimum
error
rate
training
,
development
set
,
automatic
evaluation
,
optimizationconsists
,
series
,
line
optimizations
,
efficient
method
,
mer
method
,
implementation
,
zaidan
,
implementation
,
thejoshua
toolkit
,
sri
lm
,
usersshould
note
,
basic
java
lm
implementation
,
sri
lm
native
bridge
code
,
module
,
standalone
application
,
probability
,
output
stringamong
,
many
derivation
,
goodness
,
string
,
bythe
total
probability
,
derivation
,
whichmeans
,
output
,
standardviterbi
approximation
,
mostprobable
derivation
,
variational
approximation
,
derivation
,
emonstration
outlinethe
purpose
,
demonstration
,
statistical
machinetranslation
,
end
to
end
operation
,
main
component
,
targetingpotential
user
,
visual
aid
,
algorithm
,
interested
inthe
technical
detail
,
thosecomponents
,
potential
powerusers
,
first
component
,
demonstration
,
interactive
user
interface
,
arbitraryuser
input
,
source
language
,
aweb
form
,
target
language
,
newcomer
,
thecurrent
state
,
multiple
system
,
multiple
languagepairs
,
remote
server
,
potential
user
,
actual
operation
,
similar
fashion
,
machine
,
toolkit
,
forthis
purpose
,
main
modules
,
toolkit
,
rule
extraction
module
,
themert
module
,
decoding
module
,
eachmodule
,
module
,
output
,
operation
,
addition
,
module
,
accompanying
visual
aid
,
technical
operational
detail
,
wewill
,
visualization
,
search
graph
,
software
,
documentation
,
ozaidan
zmert
,
best
derivation
,
thefunctionality
,
decoder
,
alternative
translation
,
phrase
,
parallel
corpus
,
grammarrule
extraction
,
mer
module
,
figure
,
demonstrationwill
,
machine
,
instant
translation
,
userinterface
,
different
components
,
algorithmic
visualizations
,
technical
discussionof
,
machine
ourselves
,
proper
software
,
thatlarge
lcd
monitor
,
different
component
,
clarity
,
laptop
display
,
internet
connectivity
,
live
demonstration
,
access
,
referenceschris
callison
burch
,
bannard
,
joshschroeder
,
phrase
based
statistical
machine
translation
,
corpus
,
longerphrases
,
proceeding
,
callison
burch
,
philipp
koehn
,
monz
,
finding
,
statistical
machine
translation
,
inp
roceedings
,
fourth
workshop
,
statisticalmachine
translation
,
association
,
computational
linguistics
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
eisner
,
non
isomorphic
treemappings
,
machine
translation
,
proceedingsof
acl
,
galley
,
graehl
,
knight
,
danielmarcu
,
den
eefe
,
wei
,
ignaciothayer
,
scalable
inference
,
ofcontext
syntactic
translation
model
,
proceedings
,
acl
coling
,
liang
huang
,
chiang
,
k
bestparsing
,
proceeding
,
international
workshop
,
workstation
,
instant
translation
demo
,
arbitrary
input
,
language
pair
,
choice
,
runtime
demonstration
,
terminal
window
,
main
component
,
visual
aid
,
derivation
tree
,
technical
discussion
,
server
hosting
trained
translation
modelsjhugrammar
extractiondecodermertfigure
,
demonstration
,
a
p
df
,
reader
mayzoom
,
detail
,
philipp
koehn
,
hieu
hoang
,
birch
,
chriscallison
burch
,
bertoldi
,
cowan
,
shen
,
moran
,
zen
,
dyer
,
ondrej
bojar
,
alexandraconstantin
,
herbst
,
opensource
toolkit
,
statistical
machine
translation
,
inp
roceedings
,
poster
sessions
,
zhifei
li
,
sanjeev
khudanpur
,
scalabledecoder
,
parsing
based
machine
translation
withequivalent
language
model
state
maintenance
,
inp
roceedings
workshop
,
syntax
,
structure
ins
tatistical
translation
,
zhifei
li
,
sanjeev
khudanpur
,
efficientextraction
,
oracle
best
translation
,
hyper
graphs
,
proceeding
,
naa
cl
,
dyer
,
juriganitkevitch
,
sanjeev
khudanpur
,
schwartz
,
weese
,
zaidan
,
open
source
toolkit
,
parsing
based
machine
translation
,
proceeding
,
thefourth
workshop
,
statistical
machine
translation
,
athens
,
association
,
computational
linguistics
,
sanjeev
khudanpur
,
variational
decoding
,
statistical
machinetranslation
,
proceeding
,
yang
liu
,
qun
liu
,
shouxun
,
tree
to
string
alignment
template
,
statistical
machinetranslation
,
proceeding
,
acl
coling
,
lopez
,
hierarchical
phrase
based
translation
,
suffix
array
,
proceeding
,
emn
lp
coling
,
och
,
minimum
error
rate
trainingfor
statistical
machine
translation
,
proceedingsof
acl
,
quirk
,
arul
menezes
,
dependency
treelet
translation
,
informed
phrasal
smt
,
proceeding
,
mile
,
statistical
machine
translation
,
proceeding
,
zaidan
,
configurableopen
source
tool
,
minimum
error
rate
training
ofmachine
translation
system
,
prague
bulletin
ofm
athematical
linguistics
,
dial
workshop
,
discourse
,
dialogue
,
columbus
,
association
,
computational
linguisticsoptimal
dialog
,
consumer
rating
system
,
a
p
omdp
frameworkzhifei
lic
enter
,
language
,
speech
processingjohns
hopkins
universitybaltimore
,
gmail
,
compatrick
nguyen
,
zweigmicrosoft
corporation1
microsoft
,
panguyen
,
gzweig
microsoft
,
comabstractvoice
rate
,
experimental
dialog
systemthrough
,
product
information
,
optimal
dialog
management
algorithm
forvoice
rate
,
algorithm
,
omdp
framework
,
captures
uncertainty
,
speech
recognition
anduser
knowledge
,
novel
methodto
,
user
knowledge
model
,
reviewdatabase
,
simulation
result
,
thepomdp
system
,
deterministic
baseline
system
,
dialog
failure
rate
,
interaction
time
,
knowledge
,
ourwork
,
a
p
omdp
canbe
,
disambiguation
,
acomplex
voice
search
domain
,
based
shopping
,
rating
systems
,
valuable
service
,
product
,
share
theirassessments
,
product
,
thesesystems
,
access
,
interface
,
laptop
,
desktop
computer
,
mobile
phonesalso
,
access
,
inconvenient
,
therefore
,
great
interest
,
spoken
dialog
interface
,
rating
,
review
,
thefly
,
voice
rate
,
typical
scenario
,
showsthe
usefulness
,
voice
rate
system
,
user
enters
,
digital
camera
,
camera
,
cell
phone
,
reallya
bargain
,
people
,
aboutthe
camera
,
wise
decision
,
voice
rate
system
,
involves
many
technique
,
information
retrieval
,
review
summarization
,
speech
recognition
,
speechsynthesis
,
dialog
management
,
dialog
management
component
,
voice
rate
,
informationof
,
specific
product
,
database
,
million
,
product
,
theexact
product
,
thesystem
,
product
name
,
product
name
,
database
,
product
,
highest
ranked
productshould
,
reality
,
various
reason
,
forexample
,
speech
recognition
,
information
retrieval
,
product
name
,
exact
product
,
product
name
,
namein
,
product
database
,
usersays
,
canon
powershot
sd750
,
product
database
,
exact
name
,
different
product
,
different
categories
,
instance
book
,
reason
,
voice
rate
system
,
multiple
product
,
theuser
,
initial
speech
query
,
dialog
procedure
,
intended
product
,
questions
,
product
,
product
database
,
attribute
,
product
,
digital
camera
,
product
name
,
category
,
resolution
,
listof
product
,
different
attribute
,
differentability
,
product
,
ifthe
product
,
many
category
,
categoryattribute
,
product
,
incontrast
,
product
,
single
category
,
question
,
category
,
addition
,
variability
,
distinguishingproducts
,
different
attribute
,
differentknowledge
,
answer
question
,
attribute
,
question
oncategory
,
questionon
,
part
number
,
product
,
partnumber
,
products
,
variability
,
difficulty
,
speech
recognition
,
speechsynthesis
,
clearly
,
product
,
question
,
dialog
,
goalis
,
important
attribute
,
stage
turn
,
baseline
system
,
asksquestions
,
product
name
,
category
,
theorder
,
question
,
first
ask
question
,
category
,
inspeech
recognition
,
user
knowledge
,
general
framework
,
theuncertainty
,
spoken
dialog
system
,
a
p
omdp
,
probabilistic
system
,
product
information
,
capturesuncertainty
,
speech
recognition
,
user
knowledge
,
novel
method
,
userknowledge
model
,
review
database
,
simulation
result
,
baseline
,
knowledge
,
firstto
show
,
fordisambiguation
,
complex
voice
search
,
main
flow
,
voice
rate
system
,
simplification
,
usercalls
voice
rate
,
information
,
specific
yes
begin
information
retrieval
dialog
manager
end
initial
speech
query
list
,
product
corrupted
user
action
human
speech
recognizer
user
action
found
product
,
product
figure
,
flow
chart
,
voice
rate
systemstep
,
remove
product
,
user
actionstep
,
category
question
,
question
,
returnno
,
product
name
,
baseline
dialog
manager
algorithmproduct
,
theproduct
name
,
user
input
,
queryand
,
product
name
,
product
database
asdocuments
,
user
input
,
tf
idf
measure
,
dialog
manager
,
generates
question
,
specific
,
product
,
product
,
rating
information
,
dialog
manager
component
,
baseline
dialog
manager
,
dialog
manager
,
step
,
allthe
product
,
user
response
,
user
answer
,
camera
,
question
,
category
,
product
,
step
,
baseline
systemasks
question
,
product
name
,
product
category
,
product
category
,
general
framework
,
spoken
dialog
system
,
nota
105tions
,
williams
,
a
p
omdp
,
environment
,
set
,
machine
action
,
operating
,
environment
,
reward
function
,
observations
,
observation
,
corrupted
version
,
user
action
,
geometricdiscount
factor
,
initial
belief
vector
,
pom
dp
,
environment
,
unobserved
state
,
distribution
,
possible
statesis
,
probability
,
particular
state
,
current
belief
vector
,
optimal
action
selection
,
machine
action
,
reward
,
andthe
environment
transit
,
new
unobserved
state
,
environment
,
observationo
,
user
action
,
system
updatethe
belief
vector
,
process
,
adjustingthe
belief
vector
,
applying
pom
dp
,
practiceas
,
williams
,
pom
dp
framework
,
aspecific
application
,
normallyneeds
,
belief
update
,
optimal
action
selectionthe
state
diagram
,
topology
,
thegraph
,
system
state
,
machine
action
,
user
action
,
transition
,
user
goal
model
,
user
action
model
,
assumption
,
state
diagram
,
themodels
,
dynamic
,
belief
,
observation
probability
,
transition
probability
,
transition
probability
,
assumption
,
theexact
belief
update
formula
,
optimal
action
selection
,
optimization
algorithm
,
refers
,
machine
action
,
optimal
action
selection
,
threesub
components
,
goodness
measure
function
,
argmax
operator
,
prediction
,
behavior
,
thefuture
,
machine
action
,
thesearch
algorithm
,
exhaustive
linear
searchor
,
approximated
greedy
search
,
thesize
,
vlassis
,
omdp
framework
,
voice
ratein
,
instantiation
ofp
omdp
,
voice
rate
system
,
main
design
choice
,
state
diagram
,
identifyingthe
,
product
,
large
list
,
product
,
williams
,
intended
product
,
user
action
,
system
state
,
update
belief
vector
,
compute
optimalaction
,
state
space
,
possible
combination
,
product
,
useractions
,
product
,
user
action
,
last
machine
action
,
eachstage
,
belief
probability
,
product
,
threshold
,
product
,
allits
,
system
state
,
intendedproduct
,
largethreshold
,
simulation
,
development
set
,
threshold
,
machine
actions
,
question
,
product
namesare
,
difficulty
,
speech
synthesis
recgonition
,
user
input
,
question
,
category
,
simple
attributes
,
toexploit
product
information
,
dialog
,
seven
kind
,
user
action
,
shownin
table
,
user
action
,
others
,
question
length
,
the106component
design
commentssystem
state
,
product
,
category
,
computer
,
machine
action
question
,
electronics
,
bookquestion
,
product
name
,
canon
sd750
digital
camera
,
canon
powershot
a40
digital
camera
,
canonsd950
digital
camera
,
othersquestion
,
memory
size
,
question
,
canon
sd750
camera
,
canon
sd750
digital
camera
,64
m
others
,
question
,
many
possible
optionsyes
,
confirmation
questionnot
,
intended
product
,
questionnot
,
knowledge
,
state
diagram
design
,
voice
ratehuman
,
option
,
option
,
single
question
,
products
,
question
,
possible
option
,
someoptions
,
others
,
third
int
,
others
,
option
,
iterative
greedy
search
algorithm
,
optimalmerge
,
belief
probability
,
option
,
others
,
option
,
somecandidate
product
,
question
,
forexample
,
question
regardingthe
attribute
,
product
,
computer
,
optionis
,
intended
product
,
attribute
,
product
,
enoughknowledge
,
question
,
attribute
,
unique
part
number
foreach
product
,
theexact
part
number
,
intended
product
,
option
,
systemexpects
,
question
,
intended
product
,
dialog
,
wealso
,
thequestion
,
speech
synthesis
,
right
information
thatthe
system
,
main
models
,
observation
,
speech
recognition
uncertainty
,
variabilityof
user
knowledge
,
questionson
different
attribute
,
observation
model
,
speech
recognition
engine
,
return
,
observation
function
,
user
action
,
user
action
,
last
machine
action
,
user
knowledge
model
,
applications
,
williams
,
where107the
pom
dp
framework
,
common
sense
,
question
,
dialog
system
,
application
,
product
information
,
differentdifficulty
,
different
question
,
question
oncategory
,
questionon
,
part
number
,
user
knowledge
model
,
uncertainty
,
question
,
intended
product
,
knowledge
,
thequestion
,
user
action
,
clearly
,
specific
product
gu
,
correct
user
action
,
itsprobability
,
user
knowledge
model
,
fourkinds
,
question
type
machine
action
,
question
,
category
,
product
name
,
machineactions
,
regardless
,
question
,
millionsof
product
,
data
sparsity
issue
,
category
,
unk
,
probabilityp
,
unk
,
attribute
attr
,
category
,
database
,
online
reviews
,
product
,
method
,
intuition
,
anattribute
,
product
,
attribute
name
,
attribute
value
,
hisreview
,
product
,
intuition
,
occurrence
frequency
,
categorycat
,
review
database
,
normalization
,
model
assumption
,
belief
update
formula
,
normalization
constant
,
observation
function
,
equation
,
user
knowledge
model
,
equation
,
setof
user
action
,
intended
product
,
state
representation
,
single
product
,
several
state
,
belief
probability
,
probability
,
therefore
,
speech
recognition
error
,
unintentional
user
mistake
,
true
product
,
getsa
nonzero
belief
probability
,
true
idealuser
action
,
probability
,
true
product
,
later
iteration
,
system
haserror
handling
capability
,
majoradvantages
,
deterministic
baseline
system
,
optimal
action
selection
,
subcomponents
,
predictionalgorithm
,
goodness
measure
,
search
algorithm
,
ideally
,
application
,
theintended
product
,
difficult
asit
need
,
infinite
future
,
reward
function
,
therefore
,
simplicity
,
one
step
forward
,
entropy
,
goodness
measure1
,
formally
,
approximation
,
modelis
,
greedy
information
theoretic
model
,
paek
andchickering
,
a
p
omdp
model
,
pom
dp
,
framework
,
optimization
function
,
entropy
,
beliefprobabilities
,
product
,
machine
actiona
,
belief
vector
using
equation
,
user
knowledgemodel
,
observation
function2
,
question
typemachine
action
,
whento
,
play
rating
action
,
dialogwill
terminate
,
play
ratingaction
,
belief
probability
,
mostprobable
product
,
moreover
,
threshold
,
number
ofsurviving
product
,
product
,
probable
producthas
,
belief
probability
,
play
rating
action
,
surviving
product
,
threshold
,
small
value
,
thesystem
,
rating
,
wrong
product
,
wewill
,
development
,
threshold
,
searchwe
,
exhaustive
linear
search
,
operator
argmin
,
equation
,
additional
filtering
,
search
,
question
,
speech
,
question
,
question
,
previous
stages3
,
sinceour
product
information
,
many
different
question
,
similar
capability
,
therefore
,
search
,
question
,
previous
stage
,
option
,
entropyhelps
,
confusion
,
machine
side
,
weirdness
,
question
tothe
human
,
productis
,
candidate
product
,
bothbooks
,
computer
,
theoptimal
action
,
entropy
reduction
,
observation
function
,
theprediction
,
real
belief
update
,
regular
decision
tree
,
answer
,
question
,
question
,
toany
additional
reduction
,
entropy
,
problem
,
due
tothe
fact
,
explicit
reward
function
,
question
,
attribute
,
question
,
nothing
,
option
,
awhile
,
dialog
quality
,
question
,
thatthe
user
,
probability
,
question
,
search
,
clearly
,
threshold
,
option
,
question
,
attribute
,
candidate
product
,
product
,
probability
,
thana
threshold
,
valid
question
,
expands
,
beginning
,
general
question
,
question
,
category
,
refined
question
,
question
,
product
brand
,
finallyvery
specific
question
,
question
,
natural
behavior
,
coarse
,
italso
,
system
adapt
,
user
knowledge
,
knowledge
,
product
,
question
,
shouldask
people
,
collectthe
performance
data
,
simulation
method
,
fast
evaluation
,
thesystem
,
development5
,
many
designchoices
,
simulation
,
general
framework
,
thesimulation
,
process
,
inf
igure
,
human
user
,
speech4while
,
baseline
dialog
manager
,
question
,
question
,
thequestion
set
,
baseline
,
simulation
,
limitations
,
result
,
reflect
real
scenario
,
question
figure
,
flow
chart
,
simulationrecognizer
,
simulated
component
,
access
,
userknowledge
model
,
theuser
action
,
corrupted
version
,
randomnumber
generator
,
equation
,
goodness
,
user
knowledge
model
,
speech
recognizer
,
deterministic
baseline
dialog
manager
,
attribute
information
helpsto
,
dialog
interaction
time
,
data
resource
,
product
database
,
review
database
,
query
clickdatabase
,
product
database
,
detailed
information
,
electronics
,
product
,
review
database
,
user
knowledge
model
,
query
click
database
,
format
,
textquery
,
product
,
canonpowershot
a700
,
canon
powershot
a700
,
development
set
,
test
set
,
result
,
information
retrievalfor
,
initial
query
,
top
ranked
product
,
intended
product
,
returned
listdepends
,
intended
product
,
theproduct
,
correlation
,
therecall
rate
,
returned
list
,
list
size
,
ir
recall
rate
,
thisis
,
query
click
data
set
,
thatis
,
clicked
product
,
nothing
,
msn
shopping
,
handspringtreo
,
list
size
recall
rate
,
information
retrieval
recall
,
tuningas
,
several
parameter
,
thesystem
,
option
,
question
as5
,
threshold
,
option
,
development
,
following
parameters
,
threshold
,
belief
probability
below
,
product
,
thresholdsabove
,
probable
product
,
parameter
,
dialog
error
,
development
set
,
error
handlingeven
,
dialog
system
,
intended
product
,
baseline
system
,
error
handlingcapability
,
speechrecognition
error
,
aquestion
,
dialog
system
,
rating
,
wrong
product
,
product
,
pom
dp
framework
,
probabilistic
nature
,
dialog
error
rate
betweenthe
baseline
,
pom
dp
system
,
pom
dp
system
performs
,
handle
error
,
pom
dp
system
,
dialog
failure
,
test
set
,
thethresholds
,
test
set6
,
reason
,
intended
product
,
rating
,
wrong
product
,
pom
dp
system
,
dialog
,
development
,
size
average
maxstages
character
word
stage
character
wordsbaseline50
,
interaction
time
result
,
dialog
failure
rate
,
interaction
timeit
,
exact
interactiontime
,
character
word
,
dialogprocess
,
character
,
true
time
,
average
,
maximum
number
,
pom
dp
system
performs
,
thanthe
baseline
system
,
differencein
,
baseline
andthe
pom
dp
system
,
thenumber
,
character
,
pom
dpsystem
,
short
question
,
baseline
system
,
product
namequestion
,
longquestion
,
product
name
,
difficulty
inspeech
synthesis
,
user
input
,
speech
recognition
,
pom
dp
framework
,
voice
rate
,
rating
,
review
,
novelmethod
,
user
knowledge
model
,
review
database
,
deterministic
baseline
system
,
pom
dp
,
speech
recognition
error
,
user
mistake
,
deterministic
baseline
system
,
moreover
,
pom
dp
system
,
product
information
,
interaction
time
,
dialog
,
simulationmodel
,
pom
dp
system
improvesthe
baseline
system
,
dialog
failure
rate
,
dialog
interaction
time
,
pom
dp
system
,
speech
demoand
plan
,
acknowledgementthis
,
first
author
,
sinternship
,
microsoft
research
,
thanks
,
hus
,
ghinwa
choueiter
,
paek
,
yeyi
,
dongyu
,
helpful
discussion
,
referencesk
,
survey
,
pom
dp
solution
techniques
,
chickering
,
markov
assumption
,
spoken
dialogue
management
,
spoken
dialogmanagement
,
vlassis
,
randomizedpoint
based
value
iteration
,
pom
dp
,
journal
ofa
rtificial
intelligence
research
,
williams
,
pom
dp
,
troubleshooting
domain
,
industrial
research
,
dialog
technology
,
williams
,
partially
observablemarkov
decision
process
,
spoken
dialog
systems
,
computer
speech
,
voice
rate
dialog
system
forconsumer
rating
,
interspeech
,
second
acl
workshop
,
syntax
,
structure
,
columbus
,
association
,
computational
linguisticsa
scalable
decoder
,
parsing
based
machine
translationwith
equivalent
language
model
state
maintenancezhifei
li
,
sanjeev
khudanpurdepartment
,
computer
science
,
language
,
speech
processingjohns
hopkins
,
baltimore
,
gmail
,
scalable
decoder
,
parsing
based
machine
translation
,
decoder
iswritten
,
implement
,
essential
algorithm
,
chiang
,
m
gram
language
model
integration
,
cube
pruning
,
uniquek
best
extraction
,
paralleland
,
technique
,
algorithm
,
equivalent
languagemodel
state
,
back
off
property
,
m
gram
language
model
,
separate
state
,
distinguished
sequence
,
equivalent
forlanguage
model
probability
calculation
,
back
off
,
decoder
,
baseline
decoder
,
decoder
,
remarkable
progress
,
thelast
year
,
sourceor
target
language
syntax
,
instance
,
hierarchical
translation
system
,
chiang
,
synchronous
grammar
,
string
,
syntactic
analysis
,
source
language
,
galley
,
target
language
syntax
,
critical
component
,
parsing
based
mt
systems
,
decoder
,
employ
made
,
decoder
,
open
source
,
result
,
high
barrierto
entry
,
researcher
,
however
,
algorithm
,
chiang
,
chiang
,
general
purpose
decoder
,
parsing
based
systems
,
important
first
step
towards
,
open
source
parsing
based
mt
decoder
,
decoder
,
implement
,
essential
algorithm
,
chiang
,
m
gram
language
model
integration
,
beamand
cube
pruning
,
unique
k
best
extraction
,
distributed
computing
technique
,
straightforward
integration
,
parsing
based
decodersubstantially
,
computational
complexity
,
efficientmethods
,
lm
integration
,
equivalent
lm
state
,
back
off
property
,
m
gram
lm
,
separate
state
,
eachdistinguished
sequence
,
lmcalculations
,
back
off
,
decoderis
,
previous
decoder
,
computingpermits
,
translation
quality
,
decoder
,
parallel
corpus
forlarge
scale
discriminative
training
experiment
,
parsing
based
mt
decoderin
,
core
algorithm
,
decoder
,
algorithm
,
chiang
,
detail
,
essential
part
,
completeness
,
notation
,
venugopal
,
probabilistic
scf
,
source
language
terminal
symbols
t
,
target
language
terminal
symbolstt
,
sequenceof
nonterminals
,
source
terminal
,
sequence
,
nonterminals
,
target
terminal
,
one
to
one
correspondence
,
nonterminal
element
,
weight
,
illustrative
rule
,
alignment
,
subscriptson
,
nonterminals
,
noun
phrasesaround
,
translation
,
rule
weight
,
bilingual
scf
derivation
,
amonolingual
cfg
derivation
,
pairof
,
start
symbol
,
alignedpair
,
nonterminals
,
corresponding
component
,
single
rule
,
derivation
,
decoder
,
scf
g
,
chiang
,
general
scf
g
,
synchronous
tree
substitutiongrammars
,
eisner
,
chiang
,
mt
decoding
,
chart
parsinggiven
,
decodermust
,
bestderivation
,
derivation
,
composite
weight
,
deductive
proofsystem
,
shieber
,
chiang
,
parser
,
weighted
item
,
asgoals
,
inference
rule
,
formi1
,
antecedent
item
ii
areprovable
,
consequent
item
,
weight
,
providedthe
side
condition
,
grammar
,
amaximum
,
nonterminals
,
figure
,
procedure
,
integration
,
actual
decoding
algorithm
,
proved
item
,
parsing
processstarts
,
proceeds
,
theinference
rule
,
item
untila
goal
item
,
parser
,
anew
item
,
appropriate
chartcell
,
backpointers
,
antecedentitems
,
k
best
extraction
,
a
s
cfg
,
decoder
,
source
language
span
,
left
side
nonterminal
label
,
givencell
,
maximum
possible
number
,
item
iso
,
decodingcomplexity
iso
,
maximum
number
,
nonterminalpairs
,
source
language
sentencelength
,
venugopal
,
general
grammar
,
nonterminals
,
venugopal
,
ww1w2p
,
inference
rule
,
chiang
,
parser
,
translation
grammar
,
substitution
,
string
,
symbol
,
string
,
lmprobability
,
complete
m
grams
,
string
,
m
grams
,
function
,
decoding
computationally
,
scf
g
,
largevocabularies
tt
,
detailed
nonterminal
set
,
inour
decoder
,
chiang
,
chiang
,
beam
pruning
,
weight
,
relative
threshold
,
weight
,
samecell
,
many
item
,
threshold
,
top
b
item
,
weight
,
combiningsmaller
item
,
aninference
rule
,
k
best
extraction
,
destination
cell
,
discardcombinations
,
weight
isworse
,
k
best
extraction
,
hyper
graphsfor
,
outputof
,
chart
parsing
algorithm
,
likely
hypothesesd
,
briefly
,
hyper
graph
,
verticesand
hyper
edges
,
hyper
edge
connectinga
set
,
antecedent
vertex
,
consequent
vertex
,
special
vertex
,
target
vertex
,
parlance
,
vertex
,
itemin
,
hyper
edge
corresponds
,
cfgr
ule
,
nonterminals
,
right
side
replacedby
back
pointers
,
antecedent
item
,
targetvertex
,
goal
item2
,
hyper
graph
,
k
best
extraction
algorithm
ofh
uang
,
chiang
,
likelytranslations
,
many
different
derivations
,
modification
,
inh
uang
et
,
translation
,
parallel
,
distributed
computingmany
application
,
parsing
based
mt
entail
theuse
,
scf
g
,
million
,
bilingual
sentence
pair
,
billions
,
target
language
text
,
requiresthe
decoder
,
distributed
computingto
,
memory
,
multiple
processor
,
technique
,
iterative
minimum
error
rate
training
,
basedmt
service
,
decoder
,
largenumber
,
unit
time
,
decoder
,
processor
,
twosuch
performance
enhancement
,
decoder
,
decoder
,
multiple
goal
item
,
different
lm
context
,
canimage
,
single
goal
item
,
thegoal
nonterminal
,
lm
context
,
decodingwe
,
decoder
,
parallel
,
exploitingthe
ability
,
multi
core
processor
,
several
thread
,
share
memory
,
specifically
,
decoder
,
severalsubsets
,
thread
,
thread
finish
,
main
thread
,
translation
,
thread
naturallyshare
memory
,
decoder
,
memory
,
significant
speedup
,
language
modelsit
,
memory
,
single
machine
,
decoder
,
iterative
decoding
,
updated
combination
weight
,
minimum
error
rate
training
,
dedicated
server
,
idea
thathas
,
emami
etal
,
implementation
,
different
server
,
decoding
,
thedecoder
,
server
,
individual
lm
probability
,
interpolates
,
interpolation
weight
,
architecture
,
largetarget
language
text
corpus
,
manyparts
,
separate
lm
,
runtime
interpolation
capability
,
document
specificlanguage
model
,
potential
network
communication
delays
,
asimple
cache
mechanism
,
decoder
,
cachesaves
,
outcome
,
lm
,
lm
probability
,
cacheis
,
threshold
,
resultant
saving
,
trie
data
structures
,
implement
m
gram
lm
,
inferencerules
,
figure
,
straightforward
integrationof
,
m
gram
lm
,
multiplicative
factor
,
computational
complexity
,
thedecoder
,
target
language
terminal
symbol
,
large
multiplier
,
structure
,
m
gram
lm
,
decoderintegrating
,
figure
,
operate
,
string
,
placeholder
,
symbol
,
elided
part
,
target
language
string
,
function
,
complete
m
grams
,
lm
history
,
p
probability
,
thelm
probability
,
exact
weight
,
bottom
up
pruning
,
approximation
,
estimate
,
lm
probability
,
estimated
probability
,
intoaccount
,
purpose
,
function
,
lm
state
,
futurecomputation
,
exact
lm
probability
,
m
gram
lmswhile
many
different
method
,
estimating
m
gram
lm
,
estimated
lmparameters
,
back
off
file
format
,
usingthe
notation
eji
,
lm
probability
calculation
,
asp
,
order
probability
pbo
,
back
off
weight
,
history
,
m
gram
,
unlisted
,
definition
,
wordsem
,
backed
off
probability
pbo
,
thefraction
,
possible
m
grams
,
corpus
diminishes
,
equivalent
lm
state
,
itemthe
maximum
possible
number
,
cell
increases
,
lm
order
,
maximum
number
,
threshold
,
lm
order
,
beam
size
,
search
error
,
thiscould
,
decoder
,
previous
subsection
,
increase
,
fraction
,
modest
value
,
decoder
considers
,
m
grams
,
andtranslation
combination
,
natural
text
,
frequent
back
off
,
subsection
,
method
,
equivalent
lm
statesso
,
decoder
,
many
moreitems
,
beam
size
,
multiple
lm
state
,
back
off
,
different
unlisted
m
grams
,
back
off
,
simplicity
,
state
merging
,
equivalent
lm
state
maintenancetechnique
,
context
,
aparsing
based
mt
decoder
,
applicable
tostandard
left
to
right
phrase
based
decoder
,
right
side
equivalent
lm
state
maintenance
,
equivalent
right
lm
staterecall
,
el1serves
,
exact
lm
probability
,
yet
to
be
determinedword
el
,
word
el
,
top
,
condition
,
matter
,
right
lm
state
,
argument
,
right
lm
state
ell
,
equivalent
right
statecomputation
procedure
,
figure
,
prefix
,
equivalent
left
lm
staterecall
,
left
lm
state
,
el1
isthe
prefix
,
exact
lm
probability
,
bottom
up
parsing
,
pruningpurposes
,
to14eq
r
state
,
is
a
prefix
,
ers5
else6
,
state7
return
ersfigure
,
back
off
weight
,
left
lm
state
,
intothe
complete
m
gram
probability
,
argument
,
lm
state
ei1
,
equivalent
,
state
procedure
,
suffix
,
listed
k
gram
,
fin
refers
,
probabilitythat
,
stateitself
,
opting
,
complete
m
gram
probability
,
cost
function
,
parsingwhen
,
reduction
,
lm
state
,
equivalent
,
probability
,
complete
m
grams
,
qualification
,
back
off
weight
,
lm
history
,
suffix
,
left
lm
state
reduction
,
final
probability
p3
,
is
a
suffix
,
fin8
el
,
state9
return
el
,
finfigure
,
equivalent
left
lm
state
computation
,
estimated
probability
,
left
lm
state
,
lm
state
function
isq
,
rs
,
prefix
look
upas
,
sri
lm
toolkit
,
stolcke
,
aback
off
m
gram
lm
,
reverse
triedata
structure
,
suffix
,
prefix
information
,
data
structure
,
incurringmuch
additional
memory
cost
,
prefix
information
,
back
off
state
,
suffix
information
,
ourdecoder
,
translation
task
,
nis
tmt
evaluation
,
parallel
data
,
adding15up
,19
m
word
,
theenglish
language
model
,
parallel
text
,
subset
,
giga
word
corpus
,
giz
toolkit
,
suffix
array
architecture
,
thesrilm
toolkit
,
stolcke
,
minimum
error
rate
training
,
word
alignments
,
translation
model
,
language
model
,
optimal
weight
,
models
,
speedwe
use
a
python
implementation
,
state
of
the
decoder
,
baseline4
,
comparisons
,
direct
comparison
,
thesame
model
,
parameter
,
gram
lm
,49
m
k
grams
,
speed
ble
u
,
decoder
comparison
,
translation
speed
andquality
,
nis
t
mt
benchmark
test
,
jav
decoder
,
withoutexplicit
parallelization
,
thepython
decoder
,
bettertranslation
quality
,
pap
ineni
,
factor
,
decoder
,
pyt
decoder
,
decoder
,
large
scale
discriminative
training
experiment
,
a
distributed
language
modelwe
,
sri
lm
toolkit
,
gram
language
model
,
resnik
,
ofm
aryland
,
pyt
decoder
asthe
baseline
,
thanks
,
chiang
,
decoder
,
lm
architecture5
,
section3
,
translation
performance
,
nonparallel
decoder
,
added
network
communication
overhead
,
lm
type
k
grams
mt
,
gram
lm
,
gram
dlm
,
language
model
,
gram
lmcannot
,
single
machine
,
computing
,
ble
u
,
equivalent
lm
statesto
,
search
error
,
beam
size
,
equivalent
lm
state
maintenance
described
,
subsection
,
tradeoff
,
search
effort
,
bydecoding
time
,
search
quality
,
average
model
cost
,
besttranslation
,
equivalent
lm
state
,
language
model
,
m
grams
,
sparse
lm
,
practice
,
usinga
large
order
,
amount
,
trainingdata
,
intuition
,
gram
lmusing
,
side
,
parallel
text
,
maintenance
ofthe
full
lm
state
,
equivalent
lm
state
,
thebeam
size
,
equivalent
lm
statesis
,
full
lm
state
inan
effort
,
search
error
,
clear
fromthe
figure
,
equivalent
lm
,
search
,
search
effort
,
effectiveness
,
equivalent
lm
statemaintenance
,
lm
architecture
,
interpolates
multiple
lm
score
,
equivalentlm
state
maintenance
,
different
lm
,
lm
state
,10
n
umber
,
second
,
sentenceavg
model
cost
,
one
bestsbaselineequivlm
beam
size
,
figure
,
search
quality
,
equivalent
gram
lm
statemaintenance
,
equivlm
,
baseline
,
afunction
,
search
effort
,
beam
size
,
gram
lm
,
corpus
,
experiments
,
equivalent
lmstates
,
decoding
time
,
fulllm
state
,
search
quality
,
thisis
,
inefficient
implementation
,
theprefixand
suffix
lookup
,
theequivalent
lm
state
,
with130m
word
,
gram
lm
,
onclusionswe
,
scalable
decoder
,
parsing
based
machine
translation
,
essential
algorithm
describedin
chiang
,
m
gram
languagemodel
integration
,
beamand
cube
pruning
,
andunique
k
best
extraction
,
technique
,
decoderis
,
baseline
decoder
,
distributed
language
,
translation
quality
,
alarge
scale
task
,
algorithm
,
back
off
property
,
m
gram
modelto
maintain
equivalent
lm
state
,
better
search
quality
,
search
,
search
space
,
thisequivalence
,
additionalsyntax
based
component
,
decoder
,
release
,
open
source
toolkit
,
acknowledgmentswe
,
resnik
,
dyer
,
smarandamuresan
,
lopez
,
helpful
discussions
,
anonymous
reviewer
,
constructive
comment
,
research
,
referencesthorsten
,
large
language
model
inm
achine
translation
,
proceeding
,
emn
lp
,
chiang
,
tos
ynchronous
grammar
,
available
athttp
,
chiang
paper
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
eisner
,
non
isomorphic
tree
mappings
,
machine
translation
,
proceeding
,
emami
,
kishore
papineni
,
sorensen
,
large
scale
distributed
language
modeling
,
inp
roceedings
,
ica
ssp
,
galley
,
graehl
,
knight
,
danielmarcu
,
den
eefe
,
wei
,
ignaciothayer
,
scalable
inference
,
ofcontext
syntactic
translation
model
,
proceedings
,
liang
huang
,
chiang
,
k
best
parsing
,
proceeding
,
liang
huang
,
chiang
,
rescoring
,
integrated
language
model
,
inp
roceedings
,
liang
huang
,
knight
,
aravind
joshi
,
statistical
syntax
directed
translation
,
extendeddomain
,
locality
,
proceeding
,
yang
liu
,
qun
liu
,
shouxun
,
tree
to
string
alignment
template
,
statistical
machine
translation
,
proceeding
,
col
ing
acl
,
lopez
,
hierarchical
phrase
based
translation
,
suffix
array
,
proceeding
,
emn
lp2007
,
och
,
minimum
error
rate
training
instatistical
machine
translation
,
proceeding
,
och
,
ney
,
improvedstatistical
alignment
model
,
proceeding
,
roukos
,
wei
jing
zhu
,
method
,
automatic
evaluation
,
machine
translation
,
proceeding
,
quirk
,
arul
menezes
,
dependency
treelet
translation
,
informedphrasal
smt
,
proceeding
,
shieber
,
schabes
,
pereira
,
principle
,
implementation
,
journal
,
logic
programming
,
stolcke
,
extensible
languagemodeling
toolkit
,
proceeding
,
internationalconference
,
spoken
language
processing
,
volume2
,
venugopal
,
zollmann
,
vo
gel
,
efficient
two
pass
approach
,
proceedings
,
naa
cl
,
almut
silja
hildebrand
,
vogel
,
language
,
n
best
list
re
ranking
,
proceeding
,
emn
lp
,
fourth
workshop
,
statistical
machine
translation
,
athens
,
association
,
computational
linguisticsjoshua
,
open
source
toolkit
,
weese
,
language
,
speech
processing
,
hopkins
,
computational
linguistics
,
information
processing
lab
,
natural
language
processing
lab
,
open
sourcetoolkit
,
statistical
machine
translation
,
algorithms
,
synchronous
contextfree
grammar
,
n
gram
language
model
integration
,
beam
and
cube
pruning
,
extraction
,
toolkit
,
suffix
arraygrammar
extraction
,
minimum
errorrate
training
,
distributed
computing
technique
,
scalability
,
toolkitachieves
state
,
translation
performance
,
remarkable
progress
,
last
fewyears
,
employ
made
,
software
thatis
,
open
source
,
result
,
high
barrier
,
researcher
,
experiments
,
inthis
paper
,
general
purposeopen
source
toolkit
,
parsing
based
machinetranslation
,
regular
phrase
based
machine
translation
,
toolkit
,
essential
algorithm
,
chiang
,
n
gram
language
model
integration
,
cube
pruning
,
k
best
extraction
,
toolkit
,
suffix
arraygrammar
extraction
,
minimumerror
rate
training
,
distributed
computing
technique
,
khudanpur
,
great
effort
,
toolkit
,
toolkit
,
roughlya
,
parallel
corpus
,
large
scale
discriminative
training
experiment
,
release
,
thetoolkit
,
progress
,
thesyntax
based
machine
translation
research
,
toolkitwhen
,
toolkit
,
generalprinciples
,
software
engineering
,
threemajor
goal
,
extensibility
,
end
to
end
coherence
,
scalability
,
extensibility
,
code
,
organizedinto
separate
package
,
aspect
offunctionality
,
researcherscan
focus
,
single
package
,
problem
,
unintended
interaction
andunseen
dependency
,
common
hinder
ance
,
extensibility
,
large
project
,
extensible
component
,
java
interface
,
clear
point
,
departure
,
research
,
basic
implementation
,
interface
,
class
,
worknecessary
,
new
extension
,
end
to
end
cohesion
,
many
components
,
machine
translation
pipeline
,
thegreat
difficulty
,
current
mt
pipeline
,
thatthese
diverse
component
,
byseparate
group
,
different
file
format
andinteraction
requirement
,
large
investment
,
script
,
format
,
different
component
,
non
portable
project
,
hinder
1the
toolkit
,
sourceforge
,
net
project
,
instructions
,
toolkit
,
ccb
,
repeatability
,
theseissues
,
toolkit
,
criticalcomponents
,
machine
translation
pipeline
,
component
,
astand
alone
tool
,
rest
ofthe
toolkit
,
scalability
,
third
design
goal
,
ensure
,
decoder
,
large
modelsand
data
set
,
parsing
,
pruning
algorithmsare
,
dynamic
programming
strategy
,
efficient
data
structure
,
overhead
,
technique
,
scalability
,
suffix
array
grammar
extraction
,
parallel
,
distributed
decoding
,
bloom
filter
language
model
,
short
description
,
themain
function
,
toolkit
,
corpus
sub
samplingrather
,
grammar
,
full
parallel
training
data
,
kishore
papineni
,
personal
communication
,
subset
,
training
data
consisting
,
grammar
,
particular
test
set
,
development
,
testsets
,
n
gram
,
initial
count
,
proceedingin
order
,
training
data
,
source
to
target
length
ratio
,
standard
deviation
,
average
,
ifany
n
gram
found
,
thecount
,
n
gram
,
occurrence
,
oursubmission
,
being
,
training
data
,
were30
,
word
,
frenchwords
,
subsampled
training
corpus
,
atranslation
grammar
,
parallel
corpus
,
grammar
rule
,
feature
value
,
real
translation
task
,
large
training
corpus
,
available
memory
,
feature
calculation
,
huge
set
,
directionsfor
relative
frequency
calculation
,
featuresas
,
translation
probability
,
reversetranslation
probability
,
extraction
step
,
anychange
,
input
training
data
,
hindrance
,
researcher
,
effect
,
tok
enization
,
word
segmentation
,
subset
,
available
rule
,
usea
source
language
suffix
array
,
thoserules
,
aparticular
set
,
result
,
technique
,
training
set
,
current
code
,
suffix
array
rule
extraction
,
preprocessing
step
,
particular
testset
,
decoder
,
access
,
suffix
array
,
decoder
,
runtime
,
rule
extractionpre
processing
step
,
algorithms2grammar
formalism
,
decoder
,
scf
g
,
thekind
,
chiang
,
synchronous
tree
substitution
grammar
,
eis
ner
,
chart
parsing
,
decode
,
decoder
,
k
besttranslations
,
a
c
ky
algorithm
,
algorithm
,
turn
maintains
,
proven
item
,
parsing
processstarts
,
proceeds
,
applyingthe
inference
rule
,
new
itemsuntil
,
goal
item
,
parserproves
,
new
item
,
appropriate
chart
cell
,
back
2more
detail
,
decoding
algorithm
,
antecedent
item
,
fork
best
extraction
,
severe
pruning
,
decoding
,
feasible
forscfgs
,
large
target
language
vocabulary
,
decoder
,
techniques
,
cube
pruning
,
chiang
,
hypergraphs
,
k
best
extraction
,
hypergraph
,
exponential
set
,
likely
derivation
hypothesis
,
k
best
extraction
algorithm
,
likely
derivations
,
hypergraph
,
parallel
,
decoding
,
parallel
decoding
,
distributedlanguage
model
,
multi
core
andmulti
processor
architecture
,
computing
technique
,
detail
,
features
,
khudanpur
,
language
modelsin
addition
,
lm
mentionedabove
,
local
n
gram
languagemodels
,
straightforward
implementation
,
function
,
java
implementation
,
standard
,
backoff
n
gram
model
,
decoder
,
native
code
bridge
,
decoder
,
thesrilm
toolkit
,
thisnative
implementation
,
thebasic
java
lm
implementation
,
implemented
a
b
loom
filter
lm
,
followingtalbot
,
parameterweights
,
development
set
,
automatic
evaluation
,
optimizationconsists
,
series
,
line
optimizations
alongthe
dimension
,
parameter
,
search
,
dimension
,
efficientmethod
,
iteration
,
ourmert
implementation
,
multiple
weight3this
feature
,
sri
lm
toolkit
,
nativebridge
code
,
basic
javalm
implementation
,
native
bridgecode
,
update
,
greedy
selection
,
thedimension
,
iterationalso
,
several
random
,
addition
,
previous
iteration
,
approximation
,
performing
multiple
random
restarts
,
detail
,
mer
method
,
implementation
,
zaidan
,
development
datawe
,
large
training
corpus
,
callison
burch
,
conductinga
crawl
,
bilingual
,
fromthe
canadian
government
,
union
,
various
international
organization
,
theamnesty
international
,
olympic
,
millionfiles
,
directory
structure
,
crawl
,
simple
heuristic
,
url
,
translation
,
eachother
,
equivalent
,
thesentences
,
paragraph
,
software
thatibm
model
,
probability
,
account
,
resulting
parallel
corpus
,
thousandsentence
pair
,
final
corpus
,
word
,
corpus
,
wmt
09participants
,
addition
,
parallel
corpus
,
word
,
word
,
translation
model
,
corpus
,
language
model
training
,
themonolingual
news
,
blog
data
,
edinburgh
,
consisted4the
module
,
standalone
application
,
mt
system
,
software
,
documentation
,
ozaidan
zmert
,
billion
word
,
gramlanguage
model
,
vocabulary
containing
the500
,
frequent
word
,
corpus
,
side
,
parallelcorpus
,
language
model
training
data
,
newstest
set
,
callison
burch
,
word
,
thousand
word
,
in
domain
data
thatwas
,
news
source
,
thewmt09
test
set
,
different
systemsare
,
giz
toolkit
,
suffix
array
architecture
,
sri
lm
toolkit
,
stol
cke
,
minimum
error
rate
training
,
word
alignments
,
translationmodel
,
language
model
,
optimal
weightsfor
,
minimum
bayes
risk
rescoring
,
n
best
output
,
baseline
system
,
minimum
bayes
risk
,
kumarand
byrne
,
translations
,
expected
loss
,
bleumetric
,
deterministic
annealing
,
instead
,
regular
mer
,
objective
,
one
best
error
,
deterministic
annealingtraining
procedure
,
eisner
,
objective
,
expected
error
,
entropy
regularization
technique
,
variational
decoding
,
statistical
model
,
translation
exhibit
spurious
ambiguity
,
probability
,
output
string
,
splitamong
many
distinct
derivation
,
tree
orsegmentations
,
principle
,
goodness
,
total
probability
,
itsmany
derivation
,
string
,
simpleviterbi
approximation
,
goodness5note
,
implementation
,
non
baseline
result
,
current
release
,
thenext
release
,
bayes
risk
rescoring
,
annealing
,
decoding
,
uncased
ble
,
wmt
09f
rench
task
,
test
set
,
reference
translation
,
string
,
probable
derivation
,
variational
approximation
,
derivation
,
detail
,
deterministic
annealing
,
training
,
variational
decoding
,
scalable
toolkit
,
parsing
based
machine
translation
,
javaand
implement
,
essential
algorithm
described
,
chiang
,
khudanpur
,
n
gram
language
modelintegration
,
cube
pruning
,
k
bestextraction
,
toolkit
,
suffix
array
grammar
extraction
,
callison
burch
,
minimum
error
rate
training
,
distributed
computing
technique
,
decoder
,
state
ofthe
translation
performance
,
acknowledgmentsthis
research
,
grantsno
,
findings
,
author
,
referenceschris
callison
burch
,
bannard
,
joshschroeder
,
phrase
based
statistical
machine
translation
,
corpus
,
longerphrases
,
proceeding
,
callison
burch
,
fordyce
,
philippkoehn
,
monz
,
evaluation
,
machine
translation
,
inp
roceedings
,
third
workshop
,
callison
burch
,
word
parallel
corpus
,
preparation
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
eisner
,
non
isomorphic
treemappings
,
machine
translation
,
proceedingsof
acl
,
galley
,
graehl
,
knight
,
danielmarcu
,
den
eefe
,
wei
,
ignaciothayer
,
scalable
inference
,
ofcontext
syntactic
translation
model
,
proceedings
,
acl
coling
,
liang
huang
,
chiang
,
k
bestparsing
,
proceeding
,
international
workshop
,
parsing
technology
,
philipp
koehn
,
och
,
marcu
,
statistical
phrase
based
translation
,
proceedings
,
philipp
koehn
,
hieu
hoang
,
birch
,
chriscallison
burch
,
bertoldi
,
cowan
,
shen
,
moran
,
zen
,
dyer
,
ondrej
bojar
,
alexandraconstantin
,
herbst
,
opensource
toolkit
,
statistical
machine
translation
,
inp
roceedings
,
poster
sessions
,
philipp
koehn
,
parallel
corpus
,
statisticalmachine
translation
,
proceeding
,
mt
summit
,
phuket
,
shankar
kumar
,
byrne
,
minimumbayes
risk
decoding
,
statistical
machine
translation
,
proceeding
,
zhifei
li
,
sanjeev
khudanpur
,
large
scalediscriminative
n
gram
language
model
,
statistical
machine
translation
,
proceeding
,
sanjeev
khudanpur
,
scalabledecoder
,
parsing
based
machine
translation
withequivalent
language
model
state
maintenance
,
inp
roceedings
workshop
,
syntax
,
structure
ins
tatistical
translation
,
sanjeev
khudanpur
,
open
source
,
parsing
based
machine
translation
,
prague
bulletin
,
mathematical
linguistics
,
sanjeev
khudanpur
,
variational
decoding
,
statistical
machinetranslation
,
preparation
,
yang
liu
,
qun
liu
,
shouxun
,
tree
to
string
alignment
template
,
statistical
machinetranslation
,
proceeding
,
acl
coling
,
lopez
,
hierarchical
phrase
based
translation
,
suffix
array
,
proceeding
,
emn
lp
coling
,
accurate
sentencealignment
,
bilingual
corpus
,
och
,
ney
,
systematic
comparison
,
various
statistical
alignmentmodels
,
computational
linguistics
,
och
,
minimum
error
rate
trainingfor
statistical
machine
translation
,
proceedingsof
acl
,
quirk
,
arul
menezes
,
dependency
treelet
translation
,
informed
phrasal
smt
,
proceeding
,
eisner
,
minimum
,
log
linear
model
,
proceedings
,
acl
coling
,
stolcke
,
extensible
language
,
toolkit
,
proceeding
,
international
conference
,
spoken
language
processing
,
denver
,
mile
,
statistical
machine
translation
,
proceeding
,
zaidan
,
configurableopen
source
tool
,
minimum
error
rate
training
ofmachine
translation
system
,
prague
bulletin
ofm
athematical
linguistics
,
poster
volume
,
beijing
,
discriminative
language
model
trainingfor
machine
translation
,
simulated
confusion
setszhifei
li
,
ziyuan
,
sanjeev
khudanpur
,
language
,
speech
processingjohns
hopkins
universityzhifei
,
gmail
,
zwang40
,
eduabstractan
unsupervised
discriminative
trainingprocedure
,
baseline
mt
system
,
capturetranslation
alternative
,
phrase
,
translationof
,
source
language
fragment
,
grammar
,
impostorsentences
,
confusion
,
correct
en
glish
translation
,
impostor
,
procedure
,
iws
ltch
inese
to
translation
task
,
improvement
,
state
of
the
mt
system
,
crucial
component
,
many
task
,
speech
recognition
,
information
retrieval
,
recognition
,
priori
probability
,
word
sequence
,
low
probability
,
implausible
word
sequence
,
dominant
lm
,
so
calledn
gram
model
,
alarge
corpus
,
target
language
,
maximumlikelihood
estimation
,
regularization
,
markovian
assumptions
,
n
gram
model
,
semantic
dependency
,
rosenfeld
,
khu
danpur
,
address
,
maximum
entropy
model
,
long
span
feature
,
whole
sentencemaximum
entropy
lm
,
rosenfeld
,
normalized
log
linear
lm
incorporating
several
sentence
wide
feature
,
whole
sentencemodel
,
descriptive
model
,
to
englishmt
,
alternative
translation
,
mt
system
,
suchalternative
translation
,
confusion
,
aconfusion
,
minuscule
subset
ofthe
set
,
possible
word
sequence
,
lm
parameter
,
candidate
,
confusion
,
competitor
,
speech
recognition
,
khu
danpur
,
thebest
candidate
,
bilingual
text
,
many
domain
,
weblog
,
newsgroup
,
language
pair
,
novel
discriminative
lm
,
thispaper
,
normalized
log
linear
lm
,
efficient
,
unsupervisedmanner
,
main
idea
,
translation
,
uncertainties
inherent
,
mt
system
,
a
h
iero
system
,
chiang
,
inh
iero
,
monolingual
scf
,
strong
tea
,
powerful
tea
,
ans
cfg
,
alternative
hypothesis
,
translation
,
lm
training
corpus
,
confusion
,
mt
system
,
target
translation
,
source
languagesentence
,
training
corpus
,
confusion
,
discriminative
lm
,
training
sentences
,
alternative
,
confusion
set
,
monolingual
cg
,
bilingualhiero
grammar
,
scf
g
,
confusionsets
,
translation
,
supervised
discriminative
training
,
confusion
,
supervised
,
key
exception
,
source
language
information
,
therefore
,
target
side
,
language
model
,
probabilities
,
confusion
set
,
discriminative
training
procedure
,
improvements
,
vectorof
arbitrary
feature
,
weight
,
vector
,
model
parameter
,
parameter
,
likelihood
,
argmax
,
called
whole
sentence
maximumentropy
,
language
model1
,
contrast
,
maximum
entropy
n
gramlm
,
rosenfeld
,
khudanpur
,
thenormalization
,
n
gram
history
,
rosenfeld
,
possibleword
,
length
,
rosenfeld
,
random
sampling
,
computational
disadvantage
,
modeling
limitation
,
task
,
primary
role
,
alternative
translation
,
alternatives
,
minuscule
subset
,
possible
target
language
word
sequence
,
thereal
confusion
,
specific
mt
system
,
todiscriminate
,
reference
translation
yiand
,
khu
danpur
,
conditional
likelihood
,
argmax
,
summing
,
candidatetranslations
,
side
feature
,
bilingual
text
,
discriminative
model
,
language
model
,
a
h
iero
style
mt
system
,
target
side
,
discriminative
trainingusing
simulated
confusion
setswhile
,
supervised
discriminative
lm
traininghas
,
wsm
elm
,
bilingual
data
,
several
domainsand
language
pair
,
novel
discriminative
language
model
,
global
log
linear
lm
,
advantage
,
computational
efficiency
,
requires
,
monolingual
text
yi
,
argmax
,
argmax
,
simulated
confusion
,
confusion
grammar
,
actual
confusion
,
anm
system
,
maximum
likelihood
training
,
expensive
computation
,
aglobal
normalization
constant
,
thereforevery
efficient
,
inputxi
,
output
yi
,
unsupervisedmanner
,
discriminative
trainingof
,
language
model
,
procedure
,
discriminative
training
,
thebaseline
mt
system
,
lmtraining
corpus
,
to
translation
model
,
asimulated
confusion
,
discriminative
language
model
,
thesimulated
confusion
set
,
reference
,
trained
model
,
actual
mtdecoding
,
detail
,
a
confusion
grammarwe
,
formalism
,
mt
systemis
bilingual
,
source
,
target
side
,
cg
rule
,
strong
tea
,
beijing
,
regular
scf
,
rule
withdifferent
,
reordering
,
nonterminals
,
last
,
theconfusions
,
mt
system
encounter
,
word
sens
,
pattern
,
a
confusion
grammar
,
bilingual
grammarthe
confusion
grammar
,
mtsystem
,
bilingual
grammar
,
bilingual
rule
,
source
side
,
cgrules
,
confusion
,
mt
system
,
itto
encounter
,
identity
rule
,
pattern
,
different
translation
option
,
different
cg
rule
,
current
,
therules
,
bilingual
grammar
,
rulesthat
,
bilingual
training
corpus
,
confusion
grammar
,
likely
,
computation
,
thebilingual
grammar
,
specifictest
set
,
mt
system
,
test
set
,
economize
,
translation
hypergraphs
,
test
set
,
pergraph
corresponds
,
specific
source
,
many
incident
peredges
,
different
bilin
2test
set
specific
cgs
,
course
,
off
line
application
,
bilingual
rule
,
incoming
hyperedges
,
givennode
translate
,
string
,
eachhypergraph
node
,
cg
rule
,
side
,
different
rule
,
bilingual
rule
,
bilingual
rulepairs
incident
,
course
,
entire
bilingual
grammar
,
testhypergraphs
,
baseline
n
gram
lm
,
pruning
,
confusions
,
system
component
,
simulated
confusion
setsfor
,
training
corpus
,
extracted
cg
,
simulated
confusion
,
regular
mt
,
a
h
iero
style
,
translation
,
grammar3
,
ane
nglish
to
translation
system
,
hypergraph
,
hierarchical
derivation
tree
,
phrase
,
many
different
derivation
tree
,
spurious
ambiguity
,
derivation
,
hypergraph
representation
,
present
,
confusion
pergraph
,
onthe
mat
,
alternative
hypothesis
,
derivation
,
gluerules
,
chiang
,
foreach
word
,
high
value
,
oov
rule
,
confusion
grammar
,
a0
cat1
on2
the3
mat4s
,
hypergraph
,
confusiongrammar
,
figure
,
confusion
grammar
,
simulatedconfusion
hypergraph
,
confusion
grammar
,
hyper
graph
,
competitor
,
result
,
translationy
,
hiero
bilingual
grammar
,
hierarchical
segmentationof
,
constraint
,
efficient
training
,
diversity4this
,
thehiero
grammar
,
identity
,
glue
rule
,
portion
,
process
,
situation
,
small
test
set
,
non
identityrules
,
discussion
,
round
view
,
same
segmentation
constraint
,
discriminative
training
,
procedures
,
chiang
,
hypergraph
based
minimum
risk
,
eis
ner
,
true
answer
,
yield
,
derivation
,
feature
vector
,
generalthey
,
training
willbe
efficient
,
actual
mt
decoding
,
objective
,
thuswe
,
gradient
based
method
,
gradient
,
hypergraph
canbe
,
second
order
expectationsemiring
,
eisner
,
full
confusion
,
confusion
grammar
,
modelthat
,
circular
dependency
problem
,
followingprocedure
,
initial
model
,
ahypergraph
,
pruning
,
hypergraphs
,
optimal
,
hypergraph
foreach
,
training
,
until
convergence
,
procedure
,
similar
tothe
k
best
mer
,
traininginvolves
,
iteration
,
iteration
,
k
best
list
,
discriminative
lmf
,
goodness
,
languagemodel
,
simulated
task
,
simulatedconfusion
set
,
englishsentences
,
canrecover
,
proof
ofconcept
,
features
,
discriminative
training
,
intended
use
,
course
,
foractual
mt
,
discriminative
model
,
mt
pipeline
,
weight
relative
,
mtsystem
,
related
,
similar
workthe
detailed
relation
,
procedure
,
language
modeling
,
method
,
context
,
globallog
linear
modelsour
method
,
eisner
,
successors
,
confusion
grammar
,
neighborhood
function
,
important
difference
,
neighborhood
function
,
basedon
human
insight
,
particular
task
,
neighborhood
function
,
bilingualgrammar
,
mt
system
,
neighborhood
function
,
maximum
likelihood
training
,
minimum660risk
training
,
training
,
task
specific
loss
function
,
betterthan
maximum
likelihood
training
,
modelsour
method
,
method
,
training
paraphrasing
model
,
ban
nard
,
callison
burch
,
callison
burch
etal
,
madnani
,
theform
,
confusion
grammar
,
paraphrase
model
,
waysof
,
grammar
model
,
paraphrase
model
,
phrase
,
good
alternatives
,
confusion
rule
,
mt
system
,
unseen
testdata
,
phrase
,
alternative
,
motivation
,
forexample
,
bannard
,
callison
burch
,
paraphrase
,
corpus
,
callison
burch
et
,
mt
quality
,
paraphrase
inthe
translation
table
,
madnani
,
minimum
error
rate
training
,
reference
set
,
contrast
,
ourmotivation
,
discriminative
languagemodel
,
confusiongrammar
,
alternative
,
modelshould
learn
,
xperimental
resultswe
,
iws
lt
2005chinese
to
text
translation
task5
,
n
gram
lm
,
solid
basedbaseline
system
,
data
partition
,
cdl
training
,
small
task
,
nis
tmt
task
,
havingbeen
,
mt
task
,
sentencesdata
usage
zh
ens
,
risk
training
,
cdl
training
,
data
set
,
translation
equivalentchinese
sentence
pair
,
translation
,
set3happens
,
side
,
additional
in
domain
text
,
in
domain
target
language
text
corpus
,
bilingual
training
,
individual
mt
system
component
,
in
domain
set
,
tuningrelative
weight
,
system
component
,
in
domain
monolingual
target
languagecorpus
,
cdl
training
,
test
set
,
improvement
,
mt
performance
,
iws
lt
data
,
subsets
,
utterance
,
thetravel
domain
,
gram
language
model
,
kneser
neysmoothing
,
goodman
,
onthe
side
,
baseline
,
baseline
mt
system
,
component
model
,
standardin
hiero
,
chiang
,
baselinetranslation
model
feature
,
arity
feature
,
many
rule
,
derivation
,
twoto
count
,
many
time
,
binaryglue
rule
,
derivation
,
relative
weight
,
viahypergraph
based
minimum
risk
training
,
bilingual
data
set2
,
mt
system
,
a
b
leu
score
of48
,
solid
baseline
,
training
,
cdl
mwe
,
test
set
specific
cg
,
hyper
graphs
,
bilingual
grammar
,
translation
,
confusion
hyper
graphs
,
cdl
m
,
different
feature
set
,
n
gram
lm
feature
,
acd
lm
,
gram
probability
,
length
,
eachcg
rule
,
bi
grams
,
target
side
,
thecg
rule
,
bigram
feature
,
countsare
,
nonterminals
,
rare
feature
,
freqent
terminal
symbol
,
en
glish
word
,
terminal
symbol
,
single
class
,
identity
,
dominant
pos
tag
,
restrictions
result
,
choice
,
feature
vector
,
training
procedure
,
theobjective
,
paraphrase
,
separate
confusion
hypergraph
,
sentencey
,
hypergraph
,
paraphrase
,
reference
translation
,
target
side
rule
based
feature
,
string
,
take
unfair
advantage
,
unusual
dataset
,
monolingual
simulationwe
,
novel
cdl
,
asa
language
model
,
perplexity
,
unseen
text
,
goodness
,
thecdlm
,
likelihood
,
howit
performs
,
mtsystem
,
test
sentencey
,
confusion
grammar
,
fullconfusion
,
likely
,
ble
score
,
andits
,
reference
,
pickingout
,
good
translation
,
results9
,
regular
n
gram
lm
,
cdl
m
,
weight
optimization
,
theblm
,
target
side
rule
,
mt
test
datawe
,
cdl
performs
duringactual
mt
decoding
,
cdl
minto
mt
decoding
,
derivation
,
additionalbat
,
unrelated
complication
,
problematic
instability
,
minimum
risk
training
procedure
,
illustration
,
problem
,
supervised
tuning
,
ble
score
,
set4
varies
,
referencetranslations
,
supervised
training
,
reference
,
baseline
,
unsupervised
cdl
trainingsuffer
,
unrelated
limitation
,
tuning
procedure
,
benefit
,
risk
ons
et3
,
paraphrase
,
main
claim
,
toscores
,
actual
translation
,
monolingual
simulation
,
fluencywith
,
consideration
,
adequacy
,
blm
wp
tsr
,
set4baseline
lm
,
monolingual
simulation
,
confusion
set
,
thecg
show
,
recovers
hypotheses
,
confusion
,
ble
ufor
,
set4joshua
,
test
set
,
baseline
mt
system
,
model
feature
,
additional
model
,
tsr
feature
,
baseline
mt
system
,
tune
relative
weight
,
bilingual
data
set2
,
mt
system
,
blm
andwp
feature
,
weight
,
retuned
ons
et2
,
dlm
intomt
decoding
,
tsr
feature
,
withthe
,
weight
,
alongsideits
,
wp
feature
,
unsupervised
discriminative
training
,
report
,
result
,
a
b
leu
,
improvement
,
claimthat
,
unsupervised
cdl
,
bettertranslations
,
alternative
,
simulated
confusion
setsthe
confusion
,
applyingthe
cg
,
real
confusion
,
bythe
mt
system
,
translation
,
weinvestigate
,
closing
,
simulatedconfusion
,
resembles
,
real
one
,
sincewe
,
actual
input
output
pair
,
confusion
set
,
goodness
,
asa
proxy
,
n
gram
typesn
gram
precision
recallunigram
,
trigram
,
n
gram
precision
,
recall
,
simulated
confusion
set
,
true
confusion
,
k
beststrings
,
precision
,
recallchange
,
n
grams
,
intersection
,
theprecision
,
recall
,
relative
,
present
precision
,
figures
,
convenience
,
n
grams
,
best
string
,
simulated
confusion
set
,
good
jobon
,
real
unigram
confusion
,
simulationneeds
,
novel
procedure
,
normalized
log
linear
language
model
,
unsupervised
manner
,
method
relies
,
construction
,
confusion
grammar
,
to
scf
,
translation
alternatives
,
mt
system
,
choosinga
translation
,
confusion
grammar
,
simulated
confusion
,
discriminative
language
,
original
sentence
oversentences
,
confusion
,
experimentsshow
,
novel
cdl
,
alternatives
,
regular
n
gram
lm
,
simulatedconfusion
set
,
nationalscience
foundation
,
dar
pa
gal
program
,
author
,
roark
,
dami
anos
karakos
,
insightful
discussion
,
callison
burch
,
bilingual
parallel
corpus
,
annual
meeting
ona
ssociation
,
computational
linguistics
,
pages597
,
association
forcomputational
linguistics
,
callison
burch
,
philipp
koehn
,
mile
os
borne
,
statistical
machine
translation
,
paraphrase
,
proceeding
,
mainconference
,
human
language
technology
conference
,
north
american
chapter
,
association
,
computational
linguistics
,
association
,
computational
linguistics
,
goodman
,
empirical
study
,
technique
,
technical
report
,
chiang
,
knight
,
wei
,
new
feature
,
statistical
machine
translation
,
naa
cl
,
chiang
,
hierarchical
phrase
basedtranslation
,
computational
linguistics
,
chiori
hori
,
overview
,
theiwslt
,
evaluation
campaign
,
theinternational
workshop
,
spoken
language
translation
,
khudanpur
,
sanjeev
,
maximum
entropy
technique
,
semanticand
collocational
dependency
,
language
modeling
,
computer
speech
,
language
,
eisner
,
firstand
second
order
expectation
semirings
,
application
tominimum
risk
training
,
translation
,
inp
roceedings
,
conference
,
empiricalmethods
,
natural
language
processing
,
association
,
sanjeev
khudanpur
,
large
scalediscriminative
n
gram
language
model
,
statistical
machine
translation
,
callison
burch
,
dyer
,
juriganitkevitch
,
sanjeev
khudanpur
,
schwartz
,
weese
,
zaidan
,
open
source
toolkitfor
parsing
based
machine
translation
,
ziyuan
,
eisner
,
sanjeevkhudanpur
,
minimum
imputed
risk
trainingfor
machine
translation
,
discriminative
training
,
variational
decoding
,
machine
translation
,
hopkins
,
madnani
,
necip
fazil
ayan
,
resnik
,
paraphrase
,
parameter
tuning
,
statistical
machine
translation
,
inp
roceedings
,
workshop
,
statistical
machinetranslation
,
prague
,
republic
,
association
,
computational
linguistics
,
minimum
error
rate
training
,
statistical
machine
translation
,
pages160
,
hoifung
,
toutanova
,
morphological
segmentationwith
log
linear
model
,
human
language
technology
,2009
annual
conference
,
north
american
chapter
,
association
,
computational
linguistics
,
association
,
computational
linguistics
,
brockett
,
dolan
,
monolingual
machine
translation
,
paraphrase
generation
,
proceeding
,
empirical
method
,
natural
language
processing
,
murat
saraclar
,
andmark
johnson
,
conditional
random
field
,
theperceptron
algorithm
,
proceeding
,
association
,
main
volume
,
barcelona
,
rosenfeld
,
xiaojin
zhu
,
whole
sentence
exponential
language
models
,
vehicle
,
linguistic
statistical
integration
,
computer
speech
,
language
,
rosenfeld
,
maximum
entropy
approachto
adaptive
statistical
language
modeling
,
computer
speech
,
language
,
eisner
,
contrastiveestimation
,
training
log
linear
model
,
unlabeleddata
,
proceeding
,
association
,
michi
gan
,
conference
,
empirical
method
,
natural
language
processing
,
edinburgh
,
association
,
computational
linguisticsminimum
imputed
risk
,
gmail
,
comziyuan
,
sanjeev
khudanpurjohns
hopkins
universitybaltimore
,
edujason
eisnerjohns
hopkins
universitybaltimore
,
eduabstractdiscriminative
training
,
machine
translation
,
past
,
limitation
,
availability
,
high
quality
in
domainbilingual
text
,
supervised
training
,
wepresent
,
unsupervised
discriminative
training
framework
,
plentiful
target
language
monolingual
data
,
translation
system
,
method
,
round
,
translation
,
source
language
andback
,
imputed
empirical
risk
,
augmenting
,
training
,
unsupervised
dataimproves
translation
performance
,
supervised
,
iws
lt
,
nis
task
,
common
problem
,
statistic
,
parameter
,
common
strategy
,
missingdata
,
emalgorithm
,
imputation
techniques
,
application
,
a
c
hinese
to
machinetranslation
system
,
zhifei
li
,
google
research
,
a
p
hd
student
,
hop
kins
,
translation
,
statistical
model
,
parameters
,
bilingual
sentence
pair
,
bilingual
data
,
training
,
technical
manual
,
corpus
,
englishsentences
,
source
languagesentences
,
estimation
,
data
scenario
,
training
,
parameter
,
monolingual
data
,
curious
idea
,
input
,
unsupervised
training
approach
,
minimum
imputed
risk
training
,
straightforward
,
observed
,
good
,
imputed
xback
,
method
,
round
,
translation
,
source
language
,
backagain
,
applicationscenario
,
enough
out
of
domainbilingual
data
,
baseline
translation
systems
,
parameter
,
forward
direction
,
reverse
direction
,
small
amount1contrast
,
traditional
semi
supervised
training
thatlooks
,
output
,
in
domain
bilingual
development
data
,
discrim
inatively
tune
,
small
number
,
parameter
,
large
amount
,
in
domain
monolingual
data
,
novelty
,
discrimina
tively
tune
,
parameter
,
translation
modelcomponents
,
theoretical
development
,
theempirical
effectiveness
,
development
,
large
mt
systems
,
log
linear
combination
,
several
component
model
score
,
unsupervised
discriminative
training
,
traditional
supervised
methods
,
mt
task
,
minimum
errorrate
training
,
macherey
,
perceptron
,
maximumconditional
likelihood
,
blunsom
,
minimum
risk
,
eisner
,
eisner
,
watanabe
,
chiang
etal
,
open
sourcemt
toolkit
,
unsupervised
data
,
traditional
supervised
training
setup
,
empirical
risklet
,
discriminative
training
,
supervised
setting
,
andsubsequent
,
parameter
,
function
,
parameter
,
scoring
function
,
pruning
,
heuristic
,
extractinga
high
scoring
translation
,
discriminative
training
,
expected
loss
,
extra
monolingual
data
,
tuningthe
model
weight
,
new
phrase
,
output
,
correct
outputis
,
mt
system
,
ble
umetric
,
papineni
,
negated
ble
score
,
low
bayes
risk
,
joint
distribution
,
input
output
pair
,
course
,
practice
,
empirical
riskby
,
supervised
training
,
search
,
numerical
method
,
regularization
,
imputed
riskwe
,
unsupervised
,
training
,
corresponding
input
,
minimum
risk
,
eisner
,
important
,
bothcases
,
minimizes
risk
,
expectationis
,
different
distribution
,
expectation
,
eisner
,
conditional
distribution
,
theexpectation
,
joint
distribution
,
terminology
,
nature
,
decision
rule
,
observation
thatare
,
unseen
state
,
nature
,
compensate
,
shortcut
,
unsmoothedempirical
distribution
,
posterior
estimate
,
regularization
term
,
objective
,
regularization
term
,
training
set
,
parameters
,
thatattempts
,
xi
data
,
variant
,
minimization
,
imputedempirical
risk
,
estimate
,
minimum
imputed
risk6
,
minimum
imputed
risk
objective
,
brute
force
,
possible
reverse
translation
,
imputed
training
,
supervised
training
,
weighted
training
data
,
second
step
,
imputed
xij
,
lossof
,
translation
,
empirical
riskwhen
,
imputed
training
,
mttask
,
round
,
translation
,
target
language
sentenceyi
,
source
language
,
trouble
,
method
,
reversemodel
,
weighted
lattice
,
hyper
graph
xi
,
investigateseveral
approximation
,
unsupervised
data
yj
,
semi
supervised
training
,
aninterpolation
,
forexample
,
speech
recognizerthat
,
speech
synthesizer
,
distribution
,
acoustic
features
,
phone
sequence
,
attempt
,
advance
,
bestjob
,
available
data
,
out
of
domain
bilingual
data
,
similar
parameterization
,
translates
,
translation
system
,
low
loss
translation
,
reverse
version
,
rathera
probabilistic
model
,
accurate
probability
distribution
,
possible
value
,
values
,
account
,
theloss
,
fortranslation
quality
,
underlying
conditional
distribution
,
lowconditional
cross
entropyh
,
practice
,
somebilingual
data
,
regularization
coefficient
,
translation
,
imputed
xij
,
simulate
,
hypothesis
,
correct
input
,
forward
translation
system
,
minimum
empirical
risk
objective
,
training
method
,
lafferty
,
crammer
,
eisner
,
translation
task
,
in
domain
monolingual
data
,
reverse
translation
system
,
imputed
xij
look
,
true
input
,
framework
,
choosing
different
function
,
thegenerality
,
minimum
imputedrisk
objective
,
investigation
,
negated
ble
score9
,
risk
objective
,
equivalentto
mer
,
imputed
training
data
,
differentiable
objective
function
,
infinitesimal
change
,
discrete
change
,
output
,
specialized
line
search
,
optimization
,
scalable
whenthe
number
,
model
parameter
,
decodinginstead
,
argmax
,
themt
system
,
result
,
objective
function
,
expectation
,
unknown
,
minimum
imputed
empirical
risk
,
loss
function
,
negated
ble
,
thisis
equivalent
,
eisner
,
eisner
,
imputed
data
,
loss
function
,
othermethods
,
deterministic
decoding
,
perceptron
,
crammer
,
loss
function
,
probabilistic
method
,
decoding
,
suchas
crf
,
lafferty
,
objective
function
,
differentiablefunction
,
gradient
based
method
,
lb
fgs
algorithm
,
syntax
based
mt
system
,
algorithm
,
second
orderexpectation
semirings
,
eisner
,
gradient
,
ofthe
imputed
reverse
translation
,
proposefour
approximation
,
different
approximation
,
equation
,
k
best
,
imputed
training
,
probable
translation
,
extractedfrom
xi
,
standard
algorithm
,
chi
ang
,
probability
,
training
,
independent
sample
,
weight
,
standard
algorithm
,
method
,
literature
,
multiple
imputation
,
lattice
,
certain
special
,
expected
loss
,
many
translation
,
representation
,
translationsshare
structure
,
representation
,
forward
translation
,
entire
set
xi
,
obtain
,
distribution
,
translation
,
distribution
,
un
11the
lattice
approximation
,
theoretical
contribution
,
itsimplementation
,
extensive
engineering
effort
,
main
scope
,
forward
translation
system
,
acertain
,
weighted
synchronous
context
freegrammar
,
loss
function
,
acertain
,
detail
,
constructionas
,
experimental
setting
,
istrue
,
aloss
function
,
tromble
et
,
thatis
,
approximation
,
setting
,
ahypergraph
,
hypergraph
representation
,
unambiguous
wfs
,
onecould
,
construction
,
wfs
a12
,
approximation
,
rule
level
composition
,
reasonwhy
,
structure
sharing
,
hypergraphxi
,
reverse
system
,
forwardhiero
system
,
recursive
phrase
,
structure
sharing
,
hypergraph
ofx
,
recursive
phrase
,
reverse
hiero
system
,
eachtranslation
phrase
,
corresponding
,
peredge
,
translation
system
,
according
,
translation
,
hypergraph
structure
,
todo
,
complete
isomorphism
,
thescfg
tree
,
reverse
,
translations
,
rulelevel
,
li
etal
,
linear
modelscore
,
feature
vector
,
ourdeterministic
test
time
translation
system
,
simply12note
,
forward
translation
,
a
w
fsa
,
lattice
based
decoder
,
highest
scoring
,
trainingtime
,
decoder
,
usesthe
boltzmann
distribution
,
scaling
factor
,
sharpness
,
degree
,
randomized
decoder
favor
,
highest
scoringy
,
objective
approachesthe
,
deterministic
test
time
system
,
addition
,
input
andoutput
,
latent
,
hidden
derivation
,
derivation
,
particular
phrase
segmentation
,
phrase
based
mt
system
,
koehn
etal
,
derivation
tree
,
typical
syntax
based
system
,
galley
,
chiang
,
detailed
derivation
,
function
,
feature
vectorcan
look
,
derivation
,
notion
,
familiarfrom
setting
,
algorithm
,
generative
approach
,
minimum
,
log
likelihood
,
marginal
probability
,
argmax
,
e
step
,
iteration
,
computing
,
expected
log
likelihood
,
complete
data
,
isthe
conditional
part
,
m
step
comprises
,
notice
,
equation
,
negated
log
likelihood
,
loss
function
,
theminimum
,
risk
approach
,
differs
,
iteration
,
specific
loss
function
,
negated
log
likelihood
,
training
,
second
reason
,
contemporary
mt
,
heavy
use
,
log
linear
probabilitymodels
,
system
designer
,
linguistic
intuition
,
prior
knowledge
,
careful
choice
,
objective
function
,
closed
form
isdifficult
,
arbitrary
log
linear
model
,
denominatorz
,
length
,
contrast
,
discriminative
framework
,
conditional
model
,
conditional
probability
,
denominators
,
packed
ofpossible
translation
,
output
,
conditional
form
,
minimum
,
risk
training
method
,
discriminative
crf
,
generative
hmm
,
wide
variety
,
log
linear
feature
,
lafferty
etal
,
conditional
model
,
sophisticated
model
feature
,
theloss
function
,
efficiency
,
to
translationtasks
,
open
sourceimplementation
,
chiang
,
baseline
systems5
,
reverse
,
baseline
systems
,
translation
model
,
corpus
,
iws
lt
,
translation
task
,
transcribed
utterance
,
traveldomain
,
gram
language
model
,
kneser
ney
smoothing
,
good
man
,
bitext
,
standard
training
pipeline
,
setting
,
nis
task
,28
m
word
,
eachlanguage
,
nis
t
mt
evaluation
,
method
,
gram
language
model
,
data
setconsisting
,
discriminativetraining
,
ten
feature
,
hi
ero
,
chiang
,
baseline
language
model
feature
,
baselinetranslation
model
,
word
penalty
feature
,
many
rule
,
derivation
,
features
,
many
time
,
binaryglue
rule
,
derivation
,
separate
parameter
,
bilingualrule
,
hiero
grammar
,
severalhundred
feature
,
bilingual
rule
,
bigram
features
,
target
side
symbol
,
nonterminals
,
terminal
,
bilingualrule
,
target
side
,
x1
issue
,
nonterminals
,
position
index
,
bigram
,
position
index
,
terminal
symbol
,
dominant
pos
tag
,
bigram
feature
,
iws
lttask
,
nis
task
,
discriminative
training5
,
baseline
generative
model
,
usedto
compute
,
bilingualdata
set
,
iws
lt
,
discriminative
training
,
reverse
modelp
,
standard
hiero
featuresas
,
reverse
model
,
supervised
data
,
forwardmodel
,
semi
supervised
manner
,
data
set
,
reference
translation
,
translation
,
semi
supervised
scenario
,
presentresults
,
purelyfor
ease
,
implementation
,
versed
step
,
purpose
,
sentenceschinese
englishdev
,
training
,
training
,
forward
model
,
emphasizes
,
side
,
thetraining
,
detail
,
different
value
,
translate
,
training
set
,
original
set
,
reference
,
nis
task
,
mt03
set
,
component
parameter
,
boththe
forward
,
reverse
baseline
system
,
side
,1788
sentences
,
semi
supervised
tuning
,
theforward
model
,
test
set
,
data
set
,
reference
translation
,
training
scenario
,
supervised
system
,
discriminative
training
,
bilingual
dataset
,
monolingual
text
,
discriminative
training
,
chinesetranslation
,
report
,
result
,
tasksunder
,
training
scenario
,
unsupervised
data
improves
,
supervised
,
iws
lt
,
analysis
purposesbelow
,
result
,
iws
ltdata
set
,
behavior
,
scenario
test
ble
usup
,
semi
supervised
training
foriwslt
task
,
supervised
system
,
subset
,
sentencesand
,
translation
,
sentencesfrom
dev
,
semi
supervised
training
,
best
translation
,
result
,
thanthe
,
baseline
,
paired
permutation
test
,
training
scenario
test
ble
umt0
,
mt06sup
,
semi
supervised
training
fornist
task
,
computational
efficiency
,
aresult
,
baseline
,
paired
permutation
test
,
method
,
different
reversemodelsa
critical
component
,
unsupervised
methodis
,
wewonder
,
unsupervisedmethod
change
,
quality
,
reverse
system
varies
,
question
,
different
reverse
translation
system
,
language
model
,
side
,
unsupervised
,
imputed
translations
,
ble
score
,
language
model
,
ble
score
,
language
modelbecause
,
reference
,
data
size
imputed
cn
ble
u
test
en
ble
uwlm
nlm
wlm
,
unsupervised
trainingwith
,
language
model
,
reversesystem
,
data
size
,
subset
,
translation
,
a
c
hinese
language
modelis
,
reverse
system
,
noc
hinese
language
model
,
addition
,
ble
score
,
imputed
cnbleu
,
ble
score
,
imputed
,
forward
translation
,
imputation
,
forward
translation
,
moremonolingual
data
,
different
,
sizesin
,
reversetranslation
system
,
single
chinesetranslation
,
best
approximation
,
unsupervised
,
increases
,
best
sentences
,
knight
,
sample
,
lattice
,
diversity
,
training
input
,
unsupervised
discriminative
training
method
,
inputs
,
key
idea
,
method
,
reverse
model
,
observed
output
,
training
,
translate
,
imputed
input
,
parameter
,
present
experiment
,
imputed
translation
,
proportion
totheir
posterior
probability
,
scenario
test
ble
uunsup
,
unsupervised
training
withdifferent
k
best
size
,
k
best
translation
,
reverse
system
,
expected
loss
,
forward
translation
,
output
,
intuition
,
round
,
translation
,
target
language
sentenceto
,
source
language
,
low
expected
loss
,
method
,
englishmachine
translation
task
,
thesupervised
,
discriminative
model
,
smallamount
,
training
data
,
future
,
method
,
settingswhere
,
large
amount
,
monolingual
training
data
,
many
discriminative
feature
,
bilingual
resource
,
domain
,
testdata
,
future
,
low
resource
test
domain
,
language
pair
,
bilingual
data
,
novel
domain
,
acknowledgementsthis
,
nsf
grantsno
iis
,
thedarpa
gal
e
program
,
author
,
markusdreyer
,
damianos
karakos
,
insightful
discussion
,
referencesphil
blunsom
,
cohn
,
mile
,
discriminative
latent
variable
model
,
statisticalmachine
translation
,
goodman
,
empirical
study
,
technique
,
language
modeling
,
technical
report
,
chiang
,
knight
,
wei
,
new
feature
,
statistical
machine
translation
,
naa
cl
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
discriminative
training
methodsfor
hidden
markov
model
,
theory
,
experimentswith
perceptron
algorithm
,
emn
lp
,
ofer
dekel
,
keshet
,
shai
shalev
shwartz
,
yoram
singer
,
dyer
,
smaranda
muresan
,
resnik
,
word
lattice
translation
,
eck
,
chiori
hori
,
overview
,
theiwslt
,
evaluation
campaign
,
iws
lt
,
galley
,
graehl
,
knight
,
danielmarcu
,
den
eefe
,
wei
,
ignaciothayer
,
scalable
inference
,
ofcontext
syntactic
translation
model
,
liang
huang
,
chiang
,
k
bestparsing
,
jui
ting
huang
,
acero
,
discriminative
training
method
,
language
model
using
conditional
entropy
criterion
,
goldwa
ter
,
bayesian
inference
,
pcf
g
,
markovchain
,
naa
cl
,
philipp
koehn
,
och
,
marcu
,
statistical
phrase
based
translation
,
naa
cl
,
lafferty
,
mcc
allum
,
pereira
,
conditional
random
field
,
probabilistic
modelsfor
segmenting
,
sequence
data
,
eisner
,
firstand
second
orderexpectation
semirings
,
application
,
minimum
risk
training
,
translation
,
emn
lp
,
dyer
,
juri
gan
itkevitch
,
sanjeev
khudanpur
,
schwartz
,
wrenthornton
,
weese
,
zaidan
,
open
source
toolkit
,
parsing
based
machine
translation
,
sanjeev
khudanpur
,
variational
decoding
,
statistical
machine
translation
,
sanjeev
khudanpur
,
jasoneisner
,
discriminative
language928model
training
,
machine
translation
,
simulatedconfusion
set
,
liang
,
klein
,
taskar
,
end
to
end
discriminative
approach
,
machine
translation
,
little
,
new
york
,
nocedal
,
thelimited
memory
bfgs
method
,
large
scale
optimization
,
mathematical
programming
,
macherey
,
och
,
thayer
,
andjakob
uszkoreit
,
lattice
based
minimum
error
rate
training
,
statistical
machine
translation
,
ine
mnlp
,
knight
,
n
bestlist
,
practical
determinization
,
weighted
finite
treeautomata
,
naa
cl
,
minka
,
empirical
risk
minimization
isan
incomplete
inductive
principle
,
mit
medium
labnote
,
och
,
minimum
error
rate
,
statistical
machine
translation
,
kishore
papineni
,
roukos
,
wei
jing
zhu
,
method
,
automatic
evaluation
,
machine
translation
,
multiple
imputation
,
new
york
,
eisner
,
minimumrisk
,
log
linear
model
,
tromble
,
shankar
kumar
,
och
,
wolfgangmacherey
,
lattice
minimum
bayes
risk
decoding
,
statistical
machine
translation
,
emn
lp
,
taro
watanabe
,
suzuki
,
hajime
tsukada
,
hidekiisozaki
,
large
margin
training
,
statistical
machine
translation
,
emn
lp
conll
,
pages764
,
workshop
,
statistical
machine
translation
,
metricsmatr
,
uppsala
,
association
,
computational
linguisticsjoshua
,
a
toolkit
,
parsing
based
machine
translationwith
syntax
,
semirings
,
discriminative
training
,
sanjeev
khudanpur
,
ziyuan
,
weese
,
language
,
speech
processing
,
hopkins
,
computational
linguistics
,
information
processing
lab
,
natural
language
processing
lab
,
progress
,
inthe
past
year
,
open
source
toolkit
,
basedmachine
translation
,
new
functionality
,
support
,
translation
grammars
,
set
,
syntactic
nonterminals
,
ability
,
external
module
,
constraint
,
input
uncertainty
,
semiring
framework
,
unified
,
various
dynamic
programming
calculation
,
variational
decoding
,
intractable
map
decoding
,
hypergraph
based
discriminative
training
,
feature
engineering
,
parallelized
mer
module
,
tail
based
mer
,
derivation
tree
,
cleanerpipeline
,
open
source
toolkit
,
parsing
basedmachine
translation
,
theinitial
release
,
are
implementation
,
hiero
system
,
chiang
,
algorithm
,
including
,
chart
parsing
,
n
gram
language
model
integration
,
cube
pruning
,
k
best
extraction
,
release
,
includedre
implementations
,
suffix
array
grammar
extraction
,
schwartz
,
callison
burch
,
minimum
error
rate
training
,
zaidan
,
techniques
,
scalability
,
khudanpur
,
addition
,
toolkitover
,
past
year
,
release
,
software
,
theauthors
,
several
group
,
daily
research
,
thefirst
release
,
important
new
function
,
toolkit
,
grammar
,
zollmann
,
venugopal
,
external
module
,
translations
,
constrain
decoding
,
ambiguous
output
fromspeech
recognizers
,
word
seg
menters
,
architecture
,
many
inference
operation
,
variational
decoding
,
approximate
methods
,
intractable
map
decoding
,
khudan
pur
,
computation
,
tail
basedoptimization
,
zaidan
,
derivation
tree
,
pergraphs
,
callison
burch
,
reproducible
machine
translation
experiments
,
schwartz
,
review
,
give
short
description
foreach
,
new
function
,
support
,
syntax
based
translationthe
initial
release
,
onlyhiero
style
scf
g
,
single
nonterminal
symbol
,
release
,
support
,
arbitrary
scf
g
,
setof
linguistic
nonterminal
symbol
,
particularwe
,
support
,
zollmann
,
venu
gopal
,
identical
toh
iero
grammar
extraction
,
side
ofthe
parallel
corpus
,
syntactic
labelsreplace
,
nonterminals
,
hiero
style
rule
,
hiero
rule
,
nonterminals
,
towhich
constituent
,
nonterminal
span
onthe
parsed
side
,
bitext
,
whattypes
,
phrase
,
decoder
,
galley
,
allowsnon
constituent
phrase
,
syntactic
label
using
ccg
style
slash
notation
,
derivation
,
motivated
grammar
,
coherent
syntactic
structure
,
result
,
reordering
,
languageswith
word
order
,
likeurdu
,
constraint
,
output
,
specialized
module
,
transliterators
,
morphological
analyzer
,
andmodality
translator
,
mt
pipeline
canimprove
translation
performance
,
forlow
resource
language
,
external
modulesto
propose
alternate
translation
rule
,
constraint
,
particular
word
span
,
decoder
,
separate
fromthe
mt
engine
,
translation
,
someset
,
source
side
word
,
phrase
,
hard
constraint
,
whichmust
,
soft
constraint
,
standard
,
translation
rule
,
wellas
,
associated
feature
weight
,
addition
,
translation
,
constraint
,
lefthand
side
,
scf
grules
,
constraint
,
particular
span
,
chart
based
decoder
,
theseconstraints
,
parsingin
,
hypergraph
,
manyderivation
tree
,
decoder
,
hypergraph
,
many
atomic
inference
operation
,
k
best
translation
,
computing
expectation
,
hypergraph
,
foreach
operation
,
dedicated
dynamic
programming
algorithm
,
however
,
general
framework
,
thesealgorithms
,
semiring
weighted
parsing
,
good
man
,
inside
algorithm
,
outside
algorithm
,
theinside
outside
speedup
,
eis
ner
,
first
order
expectation
semir
ing
,
eisner
,
second
order
version
,
liand
eisner
,
semiring
framework
,
firstand
second
order
expectation
semi
rings
,
many
interestingquantities
,
hypergraphs
,
quantity
,
translation
length
,
feature
expectation
,
entropy
,
kullback
leiblerdivergence
,
bayes
risk
,
variance
,
hypothesislength
,
gradient
,
entropy
,
bayes
risk
,
covariance
,
hessian
matrix
,
word
lattice
inputwe
,
bottom
up
parsing
,
translation
hypergraph
,
thatit
support
translation
,
word
lattice
,
implementation
,
runtime
andmemory
overhead
,
thelattice
,
lattice
,
decoder
,
besttranslation
,
output
,
statistical
preprocessing
component
,
speech
recognizers
,
word
seg
menters
,
alternative
analyses
,
confusion
network
,
lattice
,
variational
decodingstatistical
model
,
machine
translation
exhibitspurious
ambiguity
,
probability
,
anoutput
string
,
segmentation
,
thesame
yield
,
principle
,
goodness
,
stringis
,
total
probability
,
manyderivations
,
string
during
decoding
,
np
hard
,
first
version
ofj
,
viterbi
approximation
,
goodness
,
translation
,
probable
derivation
,
viterbi
approximation
,
derivation
,
hypergraph
,
variational
decoding
,
foreign
string
,
lattice
,
mt
system
,
ahypergraph
,
probability
distribution
,
possible
output
string
,
derivations
,
second
,
distribution
,
approximates
,
froma
family
,
distribution
,
inference
istractable
,
string
,
implementation
,
distribution
,
second
,
third
step
canbe
,
variational
decodingconsiders
,
derivation
,
hypergraph
,
large
number
offeatures
,
mt
performance
,
hypergraph
based
minimum
risk
training
,
eisner
,
expected
loss
,
thereference
translation
,
gradient
based
method
,
gradient
,
second
order
expectation
,
foroptimization
,
lb
fgs
,
riedmiller
,
average
percep
tron
algorithm
,
reranking
,
khu
danpur
,
reference
translationmay
,
hypergraph
,
inherent
defficiency
,
translation
grammar
,
weneed
,
translation
,
hypergraph
,
translation
,
surrogate
,
training
,
oracle
extraction
,
khudanpur
,
thispurpose
,
current
infrastructure
,
maximum
conditional
likelihood
orm
,
chiang
,
minimum
coding
,
large
number
,
feature
functionsin
,
exhaustive
feature
engineering
,
parameterweights
,
development
set
,
automatic
evaluation
,
mer
module
intwo
,
computation
,
metric
score
,
search
,
parameters
,
computation
,
metric
score
,
computational
concern
,
translationedit
rate
,
snover
,
acandidate
,
othercandidate
,
computation
,
amulti
threaded
solution1
,
optimization
,
intermediate
initial
weightvectors
,
multi
threaded
solution
,
module
,
awareness
ofdocument
information
,
capability
,
perform
optimization
,
document
based
variant
,
zaidan
,
document
based
bleu
,
a
b
leu
score
,
average
,
document
score
,
specificsubset
,
tail
subset
,
subset
,
lowest
document
bleu
score
,
detail
,
mer
method
,
implementation
,
zaidan
,
sample
code
,
heafield
,
interest
,
instance
,
evaluation
criterion
,
translation
quality
,
module
,
standalone
application
,
mt
system
,
software
,
documentation
,
ozaidan
zmert
,
visualizationwe
,
themain
data
structure
,
weese
andcallison
burch
,
displays
hypergraphs
,
decoder
,
hypergraph
,
second
visualizer
displays
derivation
tree
,
configuration
file
,
decoder
,
output
parsetrees
,
string
,
source
side
span
,
visualizer
,
multiple
n
best
list
,
format
,
derivation
tree
,
thesederivation
tree
,
grammar
,
visualization
tool
,
pipeline
,
chartvisualizer
,
researcher
,
search
error
,
duringdecoding
,
alignment
visualizer
,
parallel
corpus
,
grammar
extraction
,
pipeline
,
researcher
,
machine
translation
experiment
,
pipeline
istoo
,
short
conference
papers
,
workflow
frameworkfor
designing
,
reproducible
machinetranslation
experiment
,
schwartz
,
machine
translation
workflow
,
data
preprocessing
,
decoding
,
a
m
akescript
,
thatstep
,
auxiliary
configuration
file
,
exact
parameter
,
particular
experimental
setup
,
framework
,
completeexperiment
,
data
andsoftware
,
results
,
single
makefile
,
framework
,
researcher
,
supplement
research
publication
,
script
,
configuration
,
thejohns
hopkins
submission
,
thewmt10
,
translation
task
,
framework
,
acknowledgementsresearch
funding
,
nsf
under
iis
,
project
,
dar
pa
gal
program
,
finding
,
author
,
referenceskathy
baker
,
bethard
,
bloodgood
,
brown
,
callison
burch
,
coppersmith
,
dorr
,
filardo
,
kayser
,
tineau
,
mayfield
,
miller
,
phillips
,
philpot
,
piatko
,
schwartz
,
zajic
,
human
language
,
excellence
,
chiang
,
knight
,
wei
,
new
feature
,
statistical
machine
translation
,
naa
cl
,
chiang
,
hierarchical
phrase
based
translation
,
computational
linguistics
,
dyer
,
smaranda
muresan
,
philipresnik
,
word
lattice
translation
,
proceeding
,
columbus
,
association
,
computational
linguistics
,
eisner
,
parameter
estimation
,
probabilistic
finite
state
transducer
,
galley
,
hopkins
,
knight
,
anddaniel
marcu
,
translation
rule
,
hlt
naa
cl
,
goodman
,
computational
linguistics
,
kayser
,
callison
burch
,
specialized
module
,
machine
translation
,
transliteration
,
prague
bulletinof
mathematical
linguistics
,
zhifei
li
,
eisner
,
firstand
second
order
expectation
semirings
,
application
tominimum
risk
training
,
translation
,
ine
mnlp
,
zhifei
li
,
sanjeev
khudanpur
,
scalabledecoder
,
parsing
based
machine
translation
withequivalent
language
model
state
maintenance
,
cl
sss
,
zhifei
li
,
sanjeev
khudanpur
,
efficientextraction
,
oracle
best
translation
,
hyper
graphs
,
proceeding
,
naa
cl
,
sanjeev
khudanpur
,
machine
translation
,
percep
tron
algorithm
,
gal
book
chapter
,
dyer
,
juriganitkevitch
,
sanjeev
khudanpur
,
schwartz
,
weese
,
zaidan
,
open
source
toolkit
,
parsing
based
machine
translation
,
sanjeev
khudanpur
,
variational
decoding
,
statistical
machinetranslation
,
nocedal
,
jorgenocedal
,
limited
memory
bfgsmethod
,
large
scale
optimization
,
mathematicalprogramming
,
lopez
,
hierarchical
phrase
based
translation
,
suffix
array
,
emn
lp
conll
,
och
,
minimum
error
rate
training
instatistical
machine
translation
,
riedmiller
,
braun
,
adirect
adaptive
method
,
backpropagationlearning
,
rprop
algorithm
,
schwartz
,
callison
burch
,
hierarchical
phrase
based
grammar
extraction
,
prague
bulletin
,
mathematical
linguistics
,
schwartz
,
review
,
reproducible
result
inparsing
based
machine
translation
,
jhu
sharedtask
submission
,
snover
,
richardschwartz
,
translation
edit
ratewith
,
human
annotation
,
callison
burch
,
visualizing
data
structure
,
parsing
based
machinetranslation
,
prague
bulletin
,
mathematicallinguistics
,
zaidan
,
configurableopen
source
tool
,
minimum
error
rate
training
ofmachine
translation
system
,
prague
bulletin
ofm
athematical
linguistics
,
zaidan
,
tail
based
minimum
error
rate
training
,
machine
translation
systems
,
preparation
,
zollmann
,
venugopal
,
syntax
augmented
machine
translation
,
chart
parsing
,
proceeding
,
new
york
