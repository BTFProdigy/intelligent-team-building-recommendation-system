proceeding
,
conference
,
chapter
,
athens
,
a
pril
,
association
,
computational
linguisticsmint
,
a
method
,
effective
,
scalable
mining
,
named
entity
transliteration
,
large
comparable
corpus
raghavendra
udupa
k
saravanan
a
kumaran
j
agadeesh
jagarlamudi
m
icrosoft
research
bangalore
,
ind
ia
raghavu
,
com
,
problem
,
mining
transliteration
,
large
comparable
corpus
,
empirical
fact
,
multilingual
news
articles
,
similar
news
content
,
cross
language
document
similarity
model
,
multilingual
news
article
,
aligned
article
,
transliteration
similarity
model
,
different
comparable
corpus
,
language
,
different
language
family
,
state
of
the
competitor
,
critical
role
,
many
natural
language
processing
,
important
role
,
transliteration
,
cli
system
,
womser
hacker
,
weischedel
,
raditional
method
,
transliteration
,
machine
transliteration
system
,
abduljaleel
,
larkey
,
onaizan
,
knight
,
khudanpur
,
incorrect
transliteration
,
translation
lexcions
,
statistical
dictionary
,
good
coverage
,
nes1
occurring
,
current
news
event
,
critical
need
,
vocabulary
,
average
,
new
ne
,
afe
segment
,
ldc
gigaword
,
multilingual
named
entity
transliteration
lexicon
,
ubiquitous
availability
,
comparable
news
corpus
,
multiple
language
,
machine
transliteration
,
mining
,
corpus
,
comparable
news
corpus
,
net
e
,
klementiev
,
large
quantity
,
perpetual
availability
,
news
corpus
,
language
,
mining
,
net
e
,
viable
alternative
,
traditional
approach
,
opportunity
,
scalable
mining
method
,
named
entity
transliteration
equivalent
,
mining
,
net
e
,
several
challenge
,
mining
net
e
,
large
comparable
corpus
,
mining
sparse
net
e
,
computational
efficiency
,
corpus
size
,
language
independence
,
many
language
pair
,
linguistic
frugality
,
minimal
external
linguistic
resource
,
our
contribution
,
empirical
evidence
,
hypothesis
,
news
article
,
different
language
,
similar
content
,
source
,
net
e
,
insight
,
effective
approach
,
mining
net
e
,
large
comparable
corpus
,
similar
article
,
priori
,
demonstrate
,
effectiveness
,
language
pair
,
language
,
kannada
,
russian
,
different
language
family
,
scalability
,
corpus
,
different
size
,
article
,
method
,
klementiev
,
motivation
,
detail
,
evaluation
process
,
results
,
related
,
motivation
,
hypothesis
,
news
articles
,
different
language
,
similar
content
contain
,
news
article
,
people
,
location
,
organization
,
multilingual
news
article
,
news
event
mention
,
respective
languages
,
instance
,
news
report
,
new
york
time
,
second
oath
taking
,
ba
rack
obama
,
figure
,
article
,
barack
obama
,
white
house
,
respective
language
,
source
,
net
e
,
ur
empirical
investigation
,
comparable
corpus
,
insight
,
new
article
,
bbc
corpus
,
average
,
new
article
,
new
indian
express
,
similar
news
article
,
new
indian
express
,
single
word
ne
,
article
,
transliteration
equivalent
,
conjugate
tamil
,
method
,
backed
insight
,
net
e
,
comparable
corpus
,
several
challenge
,
mining
process
,
vast
majority
,
comparable
corpus
,
analysis
,
new
indian
express
news
corpus
,
mining
method
,
occurrences
,
corpus
,
vast
majority
,
mining
method
,
candidate
net
e
,
small
number
,
false
positive
,
linguistic
tool
,
resource
,
minimum
,
resource
,
handful
,
little
language
specific
knowledge
,
mining
method
,
vast
majority
,
language
,
issues
,
t
mi
,
method
,
first
stage
,
source
language
side
,
target
language
side
,
similar
news
content
,
cross
language
document
similarity
model
,
second
stage
,
source
language
side
,
transliteration
,
detail
,
remainder
,
finding
similar
document
pair
,
first
stage
,
method
,
figure
,
language
,
similar
article
pair
,
language
,
language
,
similar
content
,
cross
language
similarity
,
cross
language
document
similarity
model
,
degree
,
similarity
,
source
,
target
language
,
negative
kl
divergence
,
source
,
target
document
probability
distributions
,
similarity
measure
,
source
,
target
language
,
vocabulary
,
source
,
target
language
,
similarity
,
likelihood
,
numerator
,
vw
tss
wwpdwpss
,
cross
language
similarity
score
,
mining
net
e
,
document
pair
,
second
stage
,
method
,
net
e
,
language
,
language
,
transliteration
equivalent
,
transliteration
similarity
,
figure
,
outline
,
transliteration
similarity
model
mt
,
degree
,
transliteration
equivalence
,
source
language
,
rosslanguage
document
similarity
model
md
,
similar
article
,
similar
article
,
article
d
,
candidate
,
article
dt
,
end
crosslanguagesimilardocumentpairs
figure
,
t
in
put
,
language
,
entity
,
candidate
,
candidate
et
,
end
transliterationequivalents
,
employ
,
logistic
function
,
feature
vector
,
weight
vector
,
transliteration
similarity
,
weight
vector
,
training
corpus
,
transliteration
equivalent
,
model
capture
,
cross
language
association
,
unigrams
,
bigram
,
source
,
target
language
string
,
source
,
difference
,
start
position
,
source
,
length
,
string
,
enerative
transliteration
similarity
model
,
extension
,
probability
depends
,
jump
width
,
previous
source
character
,
w
h
mm
model
,
emission
probability
,
current
source
character
,
previous
target
character
,
w
h
mm
model
,
single
alignment
,
character
,
possible
alignment
,
jajajjamjnm
tstpsaapstpjj
,
character
,
hidden
alignment
,
parameter
,
algorithm
,
transliteration
similarity
score
,
experimental
setup
,
empirical
investigation
,
experiments
,
data
environment
,
answer
,
specific
set
,
question
,
oracle
aligned
article
pair
,
collection
,
similar
article
pair
,
given
comparable
corpus
,
consisting
,
article
,
knowledge
,
pairing
,
article
,
effect
,
overall
effectiveness
,
environment
,
article
,
comparable
corpora
,
similar
article
,
language
,
pairing
,
article
,
comparable
corpus
,
corpus
,
many
domain
,
interlinked
multilingual
wikipedia
article
,
ideal
environment
,
article
alignment
,
near
ideal
data
environment
,
article
,
comparable
corpus
,
conjugate
article
,
language
,
article
,
net
e
,
environment
,
ideal
,
degradation
point
,
shortcoming
,
environments
,
stage
wise
performance
,
method
,
data
environment
,
large
comparable
corpus
,
existence
,
conjugate
article
,
target
side
,
article
,
source
side
,
comparable
corpus
,
normal
large
multilingual
news
corpus
,
scenario
,
toughest
,
typical
setting
,
comparable
corpus
,
source
language
,
target
language
,
different
language
family
,
indo
aryan
family
,
slavic
,
kannada
,
language
,
common
script
,
hence
identification
,
cognates
,
variation
,
suffix
transformation
,
technique
,
related
language
,
common
script
,
different
comparable
corpus
,
empirical
investigation
,
ideal
,
near
ideal
environment
,
language
pair
,
environment
,
language
pair
,
or
pus
source
target
data
environment
article
,
thousand
,
million
,
ek
l
englishkannada
,
et
l
englishtamil
,
comparable
corpus
,
corpus
,
separate
group
,
corpus
,
article
,
human
annotator
,
corpus
,
magnitude
,
large
number
,
article
,
conjugate
,
target
side
,
addition
,
pairing
,
article
,
conjugate
,
comparable
corpus
,
publication
date
,
et
l
corpus
,
new
indian
express
news
paper
,
eh
s
corpus
,
dunia
,
s
corpus
,
bbc
lenta
news
agency
,
cross
language
similarity
model
,
cross
language
document
similarity
model
,
bilingual
dictionary
,
appropriate
language
pair
,
statistical
dictionary
,
language
pair
,
parallel
corpus
,
following
size
,11
k
sentence
pair
,
kannada
,
tamil
,
giz
statistical
alignment
tool
,
iteration
,
ibm
model
,
access
,
russian
parallel
corpus
,
dictionary
,
language
pair
,
near
ideal
experiment
,
russian
language
pair
,
coverage
,
dictionary
,
serious
issue
,
cross
language
document
similarity
model
,
ballesteros
,
length
,
news
article
,
comparable
size
,
source
,
target
language
,
many
translation
,
source
word
,
top
translations
,
document
probability
distribution
,
collection
frequency
,
transliteration
similarity
model
,
transliteration
similarity
model
,
language
pair
,
training
corpus
consisting
,
single
word
net
e
,
language
,
corpus
,
kannada
,
tamil
,
professional
,
russian
name
pair
,
wikipedia
interwiki
link
,
negative
sample
,
models
,
negative
sample
,
source
language
ne
,
random
non
matching
target
language
,
language
specific
feature
,
feature
set
,
language
pair
,
language
,
source
side
language
,
named
entity
recognizer
,
finkel
,
extract
ne
,
precision
,
recall
,
new
indian
express
corpus
,
difference
,
performance
measure
,
intention
,
effectiveness
,
oracular
,
human
annotator
,
transliteration
equivalent
,
paired
article
,
transliteration
equivalent
,
conjugate
article
,
performance
measure
,
interest
,
fraction
,
distinct
ne
,
source
language
,
transliteration
,
target
side
,
recall
,
distinct
ne
,
fraction
,
distinct
net
e
,
recall
,
distinct
net
e
,
net
e
,
infrequent
net
e
,
recall
metric
,
method
,
net
e
,
mrr
score
,
method
,
correct
one
,
candidate
,
test
bed
,
language
pair
,
test
bed
,
bed
consist
,
similar
articles
,
language
pair
,
transliteration
equivalent
,
paired
article
,
transliteration
equivalent
,
conjugate
article
,
quantitative
performance
,
algorithm
,
net
e
,
comparable
news
corpus
,
result
,
discriminative
transliteration
similarity
model
,
result
,
generative
transliteration
similarity
model
,
ideal
environment
,
first
set
,
effectiveness
,
mining
,
net
e
,
ideal
environment
,
paired
article
,
environment
,
test
bed
,
group
corpora
,
measure
,
distinct
ne
,
distinct
net
e
,
ideal
environment
,
recall
,
ideal
note
,
language
pair
,
transliteration
equivalent
,
almost
,
distinct
ne
,
russian
pair
,
noisy
training
data
,
effectiveness
,
state
of
the
net
mining
approach
,
time
series
,
ranking
algorithm
,
klementiev
,
mrr
result
,
ideal
environment
,
ranking
,
language
pair
,
time
series
similarity
,
mining
process
,
high
mrr
,
indicate
,
top
ranked
candidate
,
ranking
,
eh
st
test
bed
,
article
,
date
stamp
,
ranking
,
time
series
,
requires
date
stamp
,
article
,
bed
comparable
corpus
article
pair
distinct
ne
distinct
net
eek
st
ek
s
,
test
bed
,
t
,
ideal
,
second
set
,
effectiveness
,
comparable
corpus
,
similar
article
,
information
,
article
,
pairing
,
cross
language
document
similarity
model
,
net
e
,
previous
experiment
,
experiments
,
test
bed
,
near
ideal
environment
,
first
part
,
effectiveness
,
cross
language
document
similarity
model
,
identity
,
conjugate
article
,
article
,
test
bed
,
article
,
cross
language
document
similarity
score
,
test
bed
,
top
result
,
publication
date
,
article
,
target
article
,
algorithm
,
figure
,
result
,
date
window
,
near
ideal
subsequently
,
output
,
given
,
method
,
second
stage
,
result
,
near
ideal
data
environment
,
result
,
ideal
environment
,
time
window
,
test
bed
,
real
environment
,
third
set
,
effectiveness
,
large
comparable
corpora
,
test
bed
,
group
corpus
,
t
est
beds
,
real
environment
,
test
bed
,
environment
,
article
,
advance
,
article
,
similar
article
,
target
,
results
,
real
environment
,
real
environment
,
article
,
net
e
,
date
window
,
result
,
comparable
corpus
,
environment
,
magnitude
,
ideal
,
near
ideal
environment
,
net
e
,
algorithm
,
good
conjugate
,
source
language
article
,
generative
transliteration
similarity
model
,
extended
w
h
mm
transliteration
similarity
model
,
result
,
near
ideal
test
bed
comparable
corpus
article
distinct
ne
,
ek
lt
ek
l
,
test
bed
,
test
bed
mrr
,
real
test
bed
mrr
,
ideal
,
generative
transliteration
similarity
model
,
result
,
generative
transliteration
similarity
model
,
discriminative
transliteration
similarity
model
,
ne
,
target
language
word
,
generative
model
,
mistake
,
inflected
word
,
discriminative
model
,
mined
net
e
table
,
net
e
,
comparable
news
corpus
,
related
cli
system
,
several
,
ballesteros
,
kraiij
,
coverage
,
dictionary
,
problem
,
xu
weischedel
,
problem
,
different
kind
,
learning
transformation
rule
,
dictionary
,
cross
lingual
spelling
variant
,
pirkola
,
translation
lexicon
,
comparable
corpus
,
onaizan
,
knight
,
knight
,
finding
translation
equivalent
,
transliteration
equivalents
,
mining
,
fragment
,
contrast
,
approach
mine
,
article
pair
,
parallel
,
ete
discovery
,
comparable
corpus
,
time
series
,
transliteration
model
,
klementiev
,
net
mining
,
several
language
,
saravanan
,
kumaran
,
method
,
vast
majority
,
net
e
,
dependency
,
frequency
signature
,
large
corpus
,
target
side
,
comparable
corpus
,
phonetic
mapping
,
language
specific
knowledge
,
language
,
net
e
,
multilingual
article
,
similar
content
,
detailed
description
,
empirical
study
,
intuitive
technique
,
cross
language
document
similarity
,
transliteration
similarity
model
,
net
e
,
large
comparable
news
corpus
,
stage
empirical
investigation
,
comparable
corpus
,
similar
articles
,
pairing
,
good
pairing
,
performs
,
pairing
,
advance
,
state
of
the
baseline
,
language
neutrality
,
net
e
,
language
pair
,
kannada
,
different
linguistic
family
,
future
,
extended
w
h
mm
model
,
discriminative
transliteration
similarity
model
,
combination
,
cross
language
document
similarity
score
,
transliteration
similarity
score
,
net
e
,
mined
net
e
,
first
stage
,
acknowledgment
,
abhijit
bhole
,
quirk
,
mined
net
e
,
statistical
transliteration
,
cross
language
information
retrieval
,
proceeding
,
entity
,
bilingual
resource
,
proceedings
,40
th
annual
meeting
,
dictionary
method
,
cross
lingual
information
retrieval
,
proceeding
,
proper
name
translation
,
cross
language
information
retrieval
,
proceeding
,
annual
meeting
,
effect
,
bilingual
term
list
size
,
dictionary
based
cross
language
information
retrieval
,
proceeding
,
international
conference
,
manning
,
nonlocal
information
,
information
extraction
system
,
gibbs
sampling
,
proceeding
,
annual
meeting
,
bilingual
lexicon
entry
,
nonparallel
corpus
,
proceeding
,
workshop
,
large
corpus
,
pattern
,
method
,
proper
noun
translation
,
using
word
dependent
transition
model
,
word
alignment
,
statistical
machine
translation
,
proceeding
,
acl
workshop
,
name
translation
,
statistical
machine
translation
,
knowing
,
proceeding
,
weakly
,
entity
transliteration
,
discovery
,
multilingual
comparable
corpus
,
proceeding
,
annual
meeting
,
machine
transliteration
,
translation
lexicon
,
monolingual
corpus
,
proceeding
,
unsupervised
lexical
acquisition
,
based
statistical
translation
model
,
cross
language
information
retrieval
,
computational
linguistics
,
entity
,
effectiveness
,
proceeding
,
cross
language
evaluation
forum
campaign
,
effect
,
entity
,
effectiveness
,
parallel
sub
sentential
fragment
,
nonparallel
corpus
,
proceedings
,
systematic
comparison
,
various
statistical
alignment
model
,
computational
linguistics
,
fuzzy
translation
,
cross
lingual
spelling
variant
,
proceeding
,
ir
,
a
language
,
information
retrieval
,
proceeding
,
acm
ir
,
generative
model
,
noisy
translation
,
application
,
fragment
extraction
,
proceeding
,
mt
summit
,
automatic
identification
,
word
translations
,
unrelated
,
german
corpus
,
proceedings
,
mining
,
entity
transliteration
pair
,
comparable
corpus
,
proceeding
,
international
workshop
,
cross
lingual
information
access
,
entity
transliteration
,
phonetic
correlation
,
proceeding
,
emn
lp
,
named
entity
transliteration
equivalent
,
comparable
corpus
,
proceeding
,
transliteration
,
oov
term
,
cross
language
information
retrieval
,
proceeding
,
transliteration
,
proper
name
,
cross
lingual
information
retrieval
,
proceeding
,
acl
workshop
,
multilingual
,
empirical
study
,
impact
,
lexical
resource
,
cli
performance
,
information
processing
,
management
,
conference
,
empirical
method
,
natural
language
processing
,
edinburgh
,
association
,
computational
linguisticsimproving
bilingual
projection
,
sparse
covariance
matricesjagadeesh
jagarlamudiuniversity
,
udupamicrosoft
researchbangalore
,
indiaraghavu
microsoft
,
eduabhijit
bholemicrosoft
researchbangalore
,
indiav
abbhol
microsoft
,
interlingual
representation
,
language
barrier
,
cross
lingual
corpus
,
many
existingapproaches
,
aligned
training
data
,
covariance
matrix
,
theory
,
sucha
covariance
matrix
,
semantic
equivalence
,
presence
,
todense
covariance
matrix
,
turn
leadsto
suboptimal
document
representation
,
inthis
paper
,
technique
,
desired
sparsity
,
covariance
matrix
,
word
associationmeasures
,
bilingual
dictionary
,
word
pair
,
differentselection
strategy
,
association
,
experimental
result
,
efficacy
,
sparsecovariance
matrix
,
data
set
,
twodifferent
language
pair
,
different
language
,
parallel
phrase
extraction
,
church
,
miningtranslations
,
out
of
vocabulary
word
,
statistical
machine
translation
,
daume
iii
,
jagarla
mudi
,
document
retrieval
,
ballesteros
,
munteanu
,
thistask
,
comparable
corpus
,
somedocuments
,
language
,
language
,
thegoal
,
hidden
alignment
,
problem
,
documents
,
common
subspace
,
interlingual
representation
,
common
subspace
generalizes
thenotion
,
vector
space
model
,
cross
lingual
applications
,
turney
,
pantel
,
document
pair
,
common
subspacein
,
document
pair
,
subspace
,
either
generative
approach
,
topic
modeling
,
jagarlamudi
,
discriminative
approach
,
variant
,
canonical
correlation
analysis
,
dumais
,
vinokourov
,
haghighiet
,
document
levelterm
occurrence
,
latent
representation
,
discriminative
approach
capture
,
occurrence
,
monolingualcovariance
matrix
,
cross
covariance
matrix
,
covariance
matrix
,
projection
direction
,
strong
reliance
,
covariance
matrix
,
problem
,
withthe
noisy
data
,
noisy
wordsin
,
noisy
document
alignment
,
noisy
data
,
casewith
data
,
community
,
wikipedia
,
a930variety
,
transliteration
mining
,
kle
mentiev
,
hermjakob
,
knight
,
multilingual
search
,
problem
,
identifying
,
noisy
entry
,
covariancematrices
,
problem
,
first
stage
,
word
association
measure
,
computingthe
strength
,
word
pair
,
bilingual
dictionary
,
resource
,
parallel
data
,
thesecond
stage
,
association
strength
,
filtering
,
noisy
word
pair
,
covariancematrices
,
word
pair
selection
problem
,
multiple
strategy
,
utility
,
sparse
covariance
matrices
,
bilingual
projection
,
first
report
result
,
synthetic
multi
view
data
,
true
correspondences
,
different
view
,
effect
,
noise
level
,
ourexperimental
result
,
significant
improvementwhen
,
true
correspondence
,
experimental
result
,
documentalignment
task
,
wikipedia
data
setsand
,
language
pair
,
covariance
matrix
,
using
cleaner
resource
bilingual
dictionary
,
canonical
correlation
analysis
,
problem
,
representing
,
solution
,
covariancematrices
,
discriminativeapproaches
,
variant
,
advantage
,
sparseness
,
variant
,
training
data
,
document
pair
,
projection
direction
,
language
,
directions
,
hotelling
,
representationof
data
,
language
,
thatthe
data
,
find
projection
direction
,
projection
direction
,
eigen
system
,
monolingual
covariance
matrix
,
cross
covariance
matrix
,
regularization
parameter
,
eigenvectors
,
column
,
projection
matrix
,
projectionmatrices
,
languages
,
interlingual
representation
,
new
pair
,
similarityis
,
dimensions
space
,
cosine
,
projection
,
theeigenvectors
,
topeigenvectors
,
objective
functionin
,
discriminative
approach
,
theform
atx
y
tb
,
constraint
,
aiajcxxij
,
bibjcyyij
,
objective
function
,
theconstraints
,
careful
selection
,
vectors
,
cxyijis
,
nonzero
entry
,
cross
covariance
matrix
,
choice
,
projection
direction
,
severeproblem
,
training
data
,
high
dimensional
data
,
theinherent
ambiguity
,
natural
language
,
noisy
word
,
occurrence
,
noisy
word
,
anon
zero
contribution
,
covariance
,
turn
prevents
,
selectionof
appropriate
projection
direction
,
technique
,
sparsity
,
covariance
matrix
,
taskinto
,
sub
problem
,
associationscore
,
word
pair
,
appropriate
strategy
,
noisy
pair
,
ontheir
weight
,
multiple
,
forthe
sake
,
convenience
,
clarity
,
ourtechniques
,
context
,
cross
covariance
matrix
,
language
pair
,
butthese
technique
,
covariance
matrix
,
different
language
pair
,
word
pair
associationthe
first
step
,
noisy
word
occurrence
,
appropriate
measure
,
strength
,
word
pair
,
span
ish
word
,
problem
,
several
association
measure
,
thenlp
literature
,
dunning
,
inkpen
,
statisticsthey
use
,
cross
covariance
matrix
,
ovariancethe
first
option
,
data
matrix
,
cross
covariance
,
strength
,
whichtwo
word
,
measure
,
information
,
occurrence
,
word
pair
,
pair
doesn
,
occur
together
,
covariance
,
point
wise
mutual
information
,
frequency
,
word
pair
occurs
,
strength
,
low
frequent
word
,
log
likelihood
ratio
,
dunning
,
statistic
,
themarginal
probability
,
n01and
n00
denote
,
word
occur
,
word
,
word
,
mutual
information
,
nij
lognij
,
documentsin
,
word
occursand
,
total
number
,
occurrence
,
others
,
averagefrequency
,
corpus
,
log
likelihood
ratio
andthe
mi
differ
,
constant
,
popular
association
,
psychology
,
mutual
information
,
differs
,
frequency
,
probability
,
association
measure
,
observed
frequency
,
assumption
,
underlying
probability
distribution
,
interpretation
ofthe
variable
,
previous
,
n01n10
,
frequency
,
similarity
,
log
odds
ratio
,
association
measure
,
thesame
training
data
,
thecovariance
matrix
,
utility
,
additional
information
,
covariance
matrix
,
ourexperiments
,
document
level
occurrenceinformation
,
occurrence
,
translational
information
,
bilingual
dictionary
,
bilingual
dictionary
,
final
resource
,
word
occurrence
,
notice
,
usingbilingual
information
,
information
gleanedfrom
,
external
corpus
,
translation
table
,
data
set
,
thetranslation
table
,
translation
table
,
direction
,
conditional
probability
,
low
probability
one
,
intojoint
probability
,
association
measure
,
monolingual
data
,
bilingual
dictionarycan
,
monolingual
word
pair
,
mentionedtechniques
,
monolingual
word
pair
,
association
,
word
pair
,
thresholding
,
word
pair
selection
,
noisy
wordco
occurrences
,
thecross
covariance
matrix
,
motivation
,
therewritten
objective
function
,
individual
component
,
cross
covariance
matrix
,
covariance
matrix
,
minimal
change
,
function
,
optimal
choice
,
covariance
matrix
,
filter
outthe
,
confident
word
pair
,
strategy
,
theabove
,
bythe
frequent
word
,
frequent
word
occurswith
word
,
association
,
asa
result
,
absolute
,
frequent
word
pair
,
occurrence
,
frequent
word
,
rowsor
,
column
,
cross
covariance
matrix
,
wordlevel
,
word
,
fewspanish
word
,
high
association
,
viceversa
,
neighbour
property
,
wordpairs
,
word
pair
,
thespanish
word
,
top
ranked
list
,
englishword
,
vice
versa
,
problem
,
entire
,
column
,
bydirect
thresholding
,
frequentwords
,
high
association
measure
,
frequentenglish
word
,
many
word
,
neighbour
,
word
,
wayto
prevent
,
selectedenglish
word
,
new
spanishword
,
global
knowledge
,
theindividual
word
,
greedy
,
relative
thresholding
,
problem
,
selection
,
networkflow
problem
,
jagarlamudi
,
word
pair
,
high
associationmeasure
,
language
,
indicator
,
value
of9330
,
associatedwith
word
,
word
pairswith
high
association
score
,
objective
,
constraint
,
following
optimization
problem
,
problem
,
linear
assignment
problem
,
hungarian
algorithm
,
jonker
,
volgenant
,
constraint
iij
,
optimal
solution
,
relaxed
problem
,
linear
programming
,
ravin
dra
,
uni
modular
nature
,
theconstraints
guarantee
,
integral
solution
,
schri
jver
,
original
integer
problemdoesn
,
introduce
,
optimal
solution
,
selection
strategy
,
thecovariance
matrix
,
sectionwe
propose
,
bilingual
wordpairs
,
monolingual
word
pair
,
useany
,
strategy
,
monolingual
word
pair
,
binary
matrix
,
selectedword
,
monolingualassociation
score
,
monolingual
augmentation
strategy
,
following
,
ixxixyiyy
,
monolingual
selectionmatrices
,
matrix
,
ourmonolingual
augmentation
,
monolingual
state
transition
matrix
,
thetask
,
cross
lingual
comparable
corpus
,
training
phase
involves
finding
projection
direction
,
documentsof
,
language
,
covariancematrices
,
training
data
,
word
association
measure
,
alongwith
,
selection
criterion
,
thesparseness
,
cross
covariance
,
covariance
matrix
,
binary
matrix
,
wordpairs
,
sparsi
fication
technique
,
covariancematrices
,
element
wise
matrix
product
,
projection
directions
,
matrix
,
topeigenvectors
,
column
,
projection
matrix
,
theinterlingual
representation
,
interlingual
representation
,
many
task
,
cross
lingualtext
categorization
,
search
,
testing
,
solving
,
thenthe
,
equation
reduces
,
documents
,
cross
lingual
comparable
corpus
,
inthis
task
,
comparable
corpus
consisting
,
document
collection
,
different
language
,
corpus
,
somedocuments
,
collection
,
collection
,
hidden
alignment
,
recovered
alignment
,
ground
truth
,
covariance
matrix
,
first
evaluate
theeffectiveness
,
synthetic
data
,
asit
enables
,
effect
ofnoise
,
abovediscussed
sparsification
strategy
,
real
world
datasets
,
possible
,
word
association
measure
,
approaches
,
word
pair
selection
,
covariance
matrices
,
method
,
parameter
,
amount
,
sparseness
,
small
amount
ofdevelopment
data
,
model
selection
,
parametertuning
,
promising
model
,
state
of
the
baseline
,
language
pair
,
different
data
set
,
training
data
,
projection
direction
,
aligned
document
fromother
language
,
average
accuracy
,
thetop
,
bachand
,
synthetic
multi
viewdata
,
method
,
correspondence
,
feature
dimension
,
theviews
,
actual
correspondence
,
features
,
true
feature
correspondence
forsparsification
,
cross
covariance
matrix
,
dimensional
vector
,
thecommon
latent
space
,
projectionmatrices
,
individual
feature
spacesas
,
notice
,
projection
matrix
w1for
,
one
to
one
correspondence
,
parameter
,
amount
,4
s
parse
mrr
sparse
accuracycca
mrr
cca
ac
curacyfigure
,
noise
parameter
,
use2000
,
restfor
evaluation
,
true
feature
correspondences
,
cross
covariance
selection
matrix
ixy
,
thefull
monolingual
covariance
matrix
,
sparse
version
,
training
data
,
test
data
,
multiple
time
,
average
accuracy
,
sparse
cca
,
noise
parameter
,
sparse
version
performs
,
noise
increase
,
cca
drop
,
significant
performance
,
true
correspondence
,
butthis
information
,
realworld
data
set
,
several
choice
,
association
measure
,
selectingthe
word
pair
,
havesparsity
parameter
,
many
possiblemodels
,
model
selection
,
approximately5000
document
pair
,
wikipediabetween
,
cross
language
link
,
ground
truth
,
frequent2000
word
,
language
,
docu
,
matchyule
matchcov
matchmi
relthresholdyule
relthresholdcov
relthresholdmi
thresholdyule
thresholdcov
thresholdccafigure
,
comparison
,
word
association
,
different
selection
criterion
,
x
axis
plotsthe
number
,
nonzero
entry
,
covariance
,
y
axis
plot
,
tfi
df
vector
,
datafor
training
different
model
,
promising
,
development
,
result
,
evaluatethem
,
data
set
,
first
experiment
,
threeassociation
measure
,
covariance
,
selection
criterion
,
threshold
,
relative
threshold
,
relthreshold
,
matching
,
thesedifferent
combination
,
sparsity
,
covariance
matrix
,
data
set
,
nonzero
entry
,
covariance
matrix
,
non
zeroentries
,
data
set
,
eachlanguage
,
nonzero
entry
,
covariance
matrix
implies
,
average
,
result
,
highlysparse
covariance
matrix
,
element
inthe
covariance
matrix
,
figure
,
covariance
matrix
,
selectioncriteria
,
weightingof
,
word
pair
,
appropriate
selection
,
wordpairs
,
experiments
,
result
,
matching
asthe
selection
criterion
,
figure
,
mutual
information
,
use
covariance
,
association
measure
,
result
,
sparsityin
,
previous
experiment
,
levelof
sparsity
,
covariance
matrix
,
samenumber
,
association
,
wordin
,
covariance
matrix
,
followingexperiment
,
different
level
,
sparsity
,
individual
covariance
matrix
,
show
theperformance
,
match
,
dictionary
matchcombinations
,
different
level
,
sparsity
,
inthe
match
combination
,
association
measure
,
selection
,
dictionary
matchcombination
,
bilingual
dictionary
,
theword
,
conditional
translation
probability
,
threshold
,
monolingual
wordpairs
,
forword
pair
selection
,
sparsity
,
different
level
,
sparsity
,
monolingual
covariance
matrix
,
full
monolingual
covariance
matrix
,
monolingual
augmentation
,
sparsity
,
cross
covariancematrix
,
figure
,
dark
blue
,
performs
,
covariance
matrix
,
cross
covariance
matrix
,
the936
,
match
combination
,
x
axis
plotsthe
number
,
word
,
wordand
vice
versa
,
sparsity
,
matchingis
,
selection
criterion
,
dictionary
match
combination
,
threshold
,
bilingual
translation
probability
,
sparsity
,
matching
,
monolingual
sparsity
,
figure
,
comparison
,
match
,
dictionary
match
combination
,
different
level
,
sparsity
,
thecovariance
matrix
,
figure
,
x
axis
plot
,
sparsity
,
cross
covariance
matrix
,
eachvalue
,
different
level
,
sparsity
,
monolingual
covariance
matrix
,
individual
run
,
relevant
part
,
y
axis
plot
,
data
set
,
match
combination
,
runsseem
,
englishword
,
s
panishwords
,
vice
versa
,
different
,
monolingual
word
pair
,
augperforms
,
combination
,
match
combination
,
noclear
winner
,
dictionary
match
combination
,
performance
increase
,
translation
probability
threshold
,
decreases
,
average
,
systems
perform
,
threshold
,
final
experiment
,
bothmatch
,
orange
,
greenbars
,
perform
,
final
experiment
,
performancebars
,
ofy
ule
,
vice
versa
,
monolingual
wordpairs
,
main
idea
,
former
combination
,
thelatter
combination
,
combination
,
final
experiment
,
numberof
word
,
wordand
vice
versa
,
monolingual
word
association
,
combination
,
monolingual
augmentation
,
fordictionary
,
weighting
,
translation
probability
threshold
,
combinations
,
monolingual
augmentation
,
byd
ictionary
match
,
final
result
,
languagepairs
,
german
,
different
resource
,
andwikipedia
,
data
set
,
dictionary
match
,
dictionary
match
,
dictionary
match
,
comparison
,
germanlanguage
pair
,
statistical
significance
,
paired
t
test
,
improvement
,
second
half
,
wikipedia
data
set
,
cross
language
link
,
ground
truth
,
thesedata
set
,
aligneddocument
pair
,
stop
word
,
preprocessing
,
language
,
tfi
df
representation
,
author
,
different
system
,
comparable
document
retrievaltask
,
discriminative
approach
,
generative
counter
part
,
state
of
the
discriminative
system
,
average
result
,
fivefold
cross
validation
,
training
,
validation
,
test
set
,
validation
data
set
,
dimension
,
commonsub
space
,
theregularization
parameter
,
different
experiment
,
different
regularization
parameter
,
result
,
datasets
,
advantage
,
common
vocabularyin
,
language
,
data
set
,
language
,
sameresults
,
result
,
covariance
matrix
,
accuracies
,
data
set
,
method
,
dictionary
forcross
lingual
sparsity
selection
,
fine
granular
information
,
external
source
,
themodels
,
training
data
,
monolingual
augmentation
,
better
,
wikipedia
data
set
,
augmentation
,
datasets
,
documentsare
clean
,
statistic
,
cross
lingual
corpus
,
usemonolingual
statistic
,
bilingual
statistics
,
gain
inthe
,
wikipedia
data
set
,
gainsin
,
initial
hunchthat
,
training
data
,
covariancematrices
,
sparsi
fyng
covariance
matrix
,
bilingual
pro
938jection
direction
,
nlp
research
,
sparseness
ofthe
covariance
matrix
,
projectiondirections
,
sparsecca
,
hardoon
,
shawe
,
machine
learningliterature
,
objective
,
projection
directions
,
sparse
vector
,
common
subspace
,
different
directionis
,
sparse
covariance
matrix
selection
research
,
banerjee
,
workis
,
matrix
,
inverse
,
covariance
matrix
,
application
ing
aussian
process
,
sparsification
,
context
,
technique
,
variant
,
experimental
result
,
external
information
,
bilingual
dictionary
,
resource
,
significant
improvements
,
computingword
pair
association
measure
,
training
data
,
appropriate
selection
criteriacan
,
significant
improvement
,
certainly
encouraging
,
sophisticated
technique
,
thesparsity
,
training
data
,
anonymous
reviewer
,
helpful
comment
,
material
,
national
science
foundation
,
referencesfrancis
,
probabilistic
interpretation
,
canonical
correlation
analysis
,
technical
report
,
dept
statist
univ
ley
ca
tech
,
ballesteros
,
croft
,
dictionary
method
,
cross
lingual
information
retrieval
,
proceeding
,
international
conferenceon
database
,
springer
verlag
,
onureena
banerjee
,
lau
rent
el
ghaoui
,
sparse
covariance
selectionvia
robust
maximum
likelihood
estimation
,
nuria
,
villegas
,
cross
lingual
text
categorization
,
daume
iii
,
jagadeesh
jagarlamudi
,
domain
adaptation
,
machine
translation
,
unseen
word
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
,
human
language
technology
,
port
land
,
association
,
computational
linguistics
,
dunning
,
accurate
method
,
statistics
,
surprise
,
coincidence
,
comput
,
linguist
,
church
,
program
,
bilingual
corpus
,
inp
roceedings
,
annual
meeting
,
association
,
computational
linguistics
,
association
,
computationallinguistics
,
wei
gao
,
blitzer
,
ming
zhou
,
fai
wong
,
bilingual
information
,
search
,
proceeding
,
human
language
technologies
,
conference
,
liang
,
kirkpatrick
,
anddan
klein
,
bilingual
lexicon
frommonolingual
corpus
,
proceeding
,
columbus
,
association
,
computational
linguistics
,
hardoon
,
shawe
,
sparsecanonical
correlation
analysis
,
journal
,
machinelearning
,
ulf
hermjakob
,
knight
,
name
translation
,
statistical
machine
translation
,
proceeding
,
columbus
,
association
,
computational
linguistics
,
hung
huu
hoang
,
su
nam
,
yen
kan
,
e
examination
,
lexical
association
measures
,
proceeding
,
acl
ijc
nlp
,
workshopon
multiword
expression
,
identification
,
interpretation
,
disambiguation
,
application
,
association
,
computational
linguistics
,
hotelling
,
relation
,
variables
,
biometrica
,
zaiu
inkpen
,
hirst
,
acquiring
collocation
,
lexical
choice
,
proceeding
,
workshopon
,
lexical
acquisition
volume
,
associationfor
computational
linguistics
,
jagarlamudi
,
unaligned
comparable
corpus
,
advance
,
information
retrieval
,
conference
,
volume
,
springer
,
jagadeesh
jagarlamudi
,
daume
iii
,
raghavendraudupa
,
bilingual
dictionary
,
interlingual
document
representation
,
proceeding
,
the49th
annual
meeting
,
association
,
computational
linguistics
,
human
language
technology
,
portland
,
association
,
computational
linguistics
,
jonker
,
volgenant
,
shortest
augmenting
path
algorithm
,
sparse
linear
assignment
problem
,
computing
,
alexandre
klementiev
,
entity
transliteration
,
discoveryfrom
multilingual
comparable
corpus
,
proceedings
,
international
conference
,
computational
linguistics
,
annual
meeting
,
theassociation
,
associationfor
computational
linguistics
,
philipp
koehn
,
a
parallel
corpusfor
statistical
machine
translation
,
conferenceproceedings
,
tenth
machine
translation
summit
,
phuket
,
mimno
,
wallach
,
naradowsky
,
mcc
allum
,
polylingual
topic
model
,
proceeding
,
empirical
method
,
natural
language
processing
,
volume
v
,
associationfor
computational
linguistics
,
log
likelihood
ratiosand
,
significance
,
rare
event
,
proceeding
,
emn
lp
,
barcelona
,
associationfor
computational
linguistics
,
dragos
munteanu
,
marcu
,
improving
machine
translation
performance
,
exploiting
nonparallel
corpus
,
comput
,
linguist
,
och
,
ney
,
systematic
comparison
,
various
statistical
alignment
models
,
computational
linguistics
,
toutanova
,
wen
tau
yih
,
translingual
document
representation
fromdiscriminative
projection
,
proceeding
,
the2010
conference
,
empirical
method
,
association
,
computationallinguistics
,
piyush
rai
,
multi
label
prediction
,
sparse
infinite
cca
,
advance
,
neuralinformation
processing
system
,
vancouver
,
rapp
,
automatic
identification
,
wordtranslations
,
unrelated
,
german
corpora
,
proceeding
,37
th
annual
meetingof
,
association
,
association
,
computationallinguistics
,
sujith
,
knight
,
phonememappings
,
transliteration
,
parallel
data
,
inp
roceedings
,
human
language
technology
,
the2009
annual
conference
,
north
american
chapter
,
association
,
computational
linguistics
,
boulder
,
association
forcomputational
linguistics
,
orlinjames
,
network
flow
,
theory
,
algorithm
,
application
,
t
r
eis
,
m
j
udd
,
handbook
ofr
esearch
method
,
social
,
personality
psychology
,
cambridge
press
,
schrijver
,
combinatorial
optimization
,
springer
,
littman
,
dumais
,
lan
dauer
,
automatic
cross
linguistic
informationretrieval
,
latent
semantic
indexing
,
workingnotes
,
workshop
,
zurich
,
turney
,
pantel
,
frequency
,
meaning
,
vector
space
model
,
semantics
,
intell
,
vinokourov
,
shawe
,
nello
tianini
,
semantic
representationof
text
,
cross
language
correlation
analysis
,
dvances
,
neural
information
processing
system
,
zhang
,
feature
basedmethod
,
document
alignment
,
comparable
newscorpora
,
duo
zhang
,
qiaozhu
,
chengxiang
zhai
,
cross
lingual
latent
topic
extraction
,
proceedings
,
annual
meeting
,
associationfor
computational
linguistics
,
up
psala
,
association
,
computationallinguistics
,
joint
conference
,
empirical
method
,
natural
language
processing
,
computational
naturallanguage
learning
,
jeju
island
,
association
,
computational
linguisticsregularized
interlingual
projection
,
evaluation
,
multilingual
transliterationjagadeesh
jagarlamudiuniversity
,
umiacs
,
umiacs
,
problem
,
building
,
multilingual
transliteration
system
usingan
interlingual
representation
,
approachuses
international
phonetic
alphabet
,
interlingual
representation
,
ipa
representation
,
training
,
monolingual
resource
,
aphoneme
dictionary
,
theiripa
representation
,
phonemedictionary
,
new
language
,
transliteration
system
,
previous
language
,
expense
,
all
pairs
data
,
computation
,
wealso
,
regularization
framework
,
interlingual
representation
,
whichaccounts
,
language
specific
phonemic
variability
,
mappingsbetween
language
,
experimental
result
onthe
name
transliteration
task
,
diverselanguages
,
maximum
improvement
of29
accuracy
,
average
improvement
of17
accuracy
,
wide
usage
,
bilingualresources
,
language
,
parallel
text
,
ipa
representation
require
knowledge
,
ipa
symbol
,
language
,
monolingual
resource
,
language
,
bilingual
dictionary
,
transliteration
data
set
,
language
,
different
language
,
situation
,
nlp
community
,
resource
language
,
pivotto
build
resource
application
,
new
language
pair
,
previous
study
,
machinetranslation
,
utiyama
,
isahara
,
andsumita
,
transliteration
,
khapra
,
dictionary
mining
,
saralegi
,
bridge
language
,
resource
between
,
regularization
framework
,
bridge
language
approachesand
,
effectiveness
,
name
transliterationtask
,
key
idea
,
accountsfor
language
specific
variation
,
variation
,
technique
,
claritywe
describe
,
context
,
transliteration
,
transliteration
,
language
,
anotherlanguage
,
graehl
,
onaizan
,
knight
,
hermjakob
,
al2008
,
al2009
,
larkey
,
womser
hacker
,
large
body
,
literature
intransliteration
,
bilingual
setting
,
knight
,
phoneme
dictionary
,
andbulgarian
,
translation
,
bulgarianwords
,
museum
,
spekle
,
contextof
transliteration
mining
,
klementiev
,
sproat
,
al2006
,
source
language
name
,
targetlanguage
candidate
transliteration
,
correct
transliteration
,
language
,
problem
,
transliteration
system
betweenevery
pair
,
language
,
supervised
learning
approach
,
trainingdata
,
name
pair
,
language
,
knight
,
graehl
,
commonnames
,
language
,
apivot
language
,
obtain
name
,
pivot
language
,
suchas
,
data
set
,
bridge
language
,
common
name
,
transliteration
system
,
resource
poor
language
,
khapraet
,
bilingual
name
transliterations
,
orthographic
name
to
name
mapping
,
nthis
paper
,
name
transliterations
,
international
phonetic
alphabet
,
manner
,
bridge
language
,
transliterationwe
,
theiripa
representation
,
thewords
,
different
language
,
show
word
,
ipa
representation
,
bulgarianlanguages
,
pairsas
phoneme
dictionary
,
notice
,
thecommon
symbol
,
ipa
sequence
,
avague
phonetic
correspondence
,
character
sequence
,
bulgarian
,
bashful
,
ipa
sequence
,
apossible
mapping
,
character
sequence
,
bridge
language
,
multiple
advantage
,
training
dataand
,
name
pair
,
language
,
bilingual
resource
,
transliteration
system
,
training
data
,
toobtain
,
resource
,
phoneme
dictionaries
,
wiktionary
contain
,
least2000
word
,
language
,
transliteration
approaches
,
st
language
,
transliterationsystem
,
language
,
all
pairs
data
,
computation
,
bridge
language
,
somenew
challenge
,
language
specific
phonemic
inventory
,
doesn
,
spoken
inb
otswana
,
consonant
,
large
inventory
,
different
word
initial
clicksounds
,
haspelmath
,
documented
language
,
language
specific
phonemic
inventory
,
different
ipa
representation
,
different
language
,
ipa
sequence
,
dutchhave
common
ipa
symbol
,
ipa
sequence
,
additional
symbol
,
multiple
pronunciation
,
language
,
different
ipa
sequence
,
phonemic
diversity
,
model
language
specific
variability
,
attempt
,
language
,
phoneme
dictionary
,
ord
ipa
sequencechina
,
different
languages
,
language
code
,
parenthesis
,
high
level
,
phoneme
dictionary
,
language
,
function
,
interlingual
representation
,
language
,
aquery
name
,
language
,
list
ofcandidate
transliteration
,
language
,
mapping
function
,
language
,
correct
name
transliteration
,
mapping
function
,
language
specificvariability
,
account
,
differences
,
experimental
result
,
languagepairs
,
different
language
family
,
amaximum
improvement
,
average
improvement
,
state
of
the
baseline
approach
,
importantadvantage
,
language
,
fact
addingphoneme
dictionary
,
language
,
language
pair
,
main
contribution
,
transliteration
system
,
pairsand
hence
,
monolingual
resource
,
regularization
framework
,
applies
,
bridge
language
applications
,
lexicon
mining
,
yarowsky
,
ow
dimensional
projectionsour
approach
,
canonical
correlation
analysis
,
application
,
transliteration
mining
,
khapra
,
phoneme
dictionary
,
eachlanguage
,
feature
vector
,
feature
vector
,
n
gram
character
sequences
,
ipa
representation
,
feature
vector
,
n
gram
ipa
symbol
sequence
,
bigram
sequence
,
thefeature
vector
,
ipa
sequence
,
brevity
,
n
gram
character
,
ipa
symbolsequences
,
character
,
phonemic
space
,
character
space
,
language
,
phonemic
space
,
allthe
language
,
bridge
,
language
share
,
language
,
mapping
,
character
,
phonemic
spacesinto
,
common
k
dimensional
subspace
,
thecorrect
transliteration
,
thissubspace
,
detail
,
notation
,
givean
overview
,
process
,
transliteration
,
feature
vectors
,
mth
word
,
ipa
sequence
,
language
,
character
space
,
language
andc
,
common
phonemic
space
,
ith
languagedata
matrix
,
thecolumns
,
language
,
superscript
,
point
,
training
stage
,
language
,
findmappings
,
projection
direction
,
character
,
phonemicspaces
,
k
dimensional
subspace
,
interlingual
representation
,
k
dimensional
vector
irrespective
,
thelanguage
,
vector
ati
xi
,
ipa
sequencepi
,
testing
stage
,
name
xi
,
source
,
language
,
transliteration
,
target
,
language
,
decoding
problem
,
single
name
,
gandhi
,
input
feature
space
,
alignment
,
characterand
phonemic
space
,
double
dimensionalarrows
,
single
mapping
function
,
phonemic
space
,
common
subspace
,
the2
dimensional
green
space
,
function
u1
,
foreach
language
,
common
subspace
,
formulation
,
source
language
mapping
,
ipa
sequence
,
source
name
,
withthe
target
language
mapping
,
correct
transliteration
,
candidatetransliterations
,
high
level
,
bridge
language
approaches
,
bridge
cca
,
khapra
,
languagespecific
variation
,
implicationconsider
,
middle
portion
,
name
gandhi
,
character
space
,
three
dimensional
space
,
andits
,
sequence
,
phonemic
space
,
two
dimensional
space
,
because
,
phonemic
variation
,
distinct
point
,
bridge
cca
,
asingle
mapping
function
,
ipa
sequence
,
distinct
point
,
common
point
,
interlingual
subspace
,
new
formulation
,
hard
constraint
,
different
mappingfunctions
,
distinct
ipa
sequence
,
single
point
,
result
,
language
specific
phonemic
variation
,
projection
direction
,
forthe
phonemic
sound
,
majorityof
,
language
,
regularized
projection
,
function
u1
,
eachlanguage
,
phonemic
space
,
common
two
dimensional
space
,
bottom
,
projectionsin
,
problem
,
mapping
function
,
language
,
optimization
problem
,
followingsection
,
method
,
theoptimization
problem
,
closed
formsolution
,
prediction
problem
,
simplicity
,
projection
vector
,
full
matrix
,
generalization
istrivial
,
projection
directions
,
character
,
phonemic
space
,
eachlanguage
,
projection
,
ipa
sequence
,
barack
obama
,
languages4
,
feature
vector
,
givenby
xi
,
character
,
phone
3in
reality
,
previous
,
phonemic
variation
,
different
features
,
different
language
,
ipa
sequence
,
thefeature
value
,
different
languages
,
understanding
,
direction
,
language
,
inthe
common
phonemic
space
,
product
,
twovectors
,
projection
direction
,
phonemic
space
,
thelanguages
,
hard
constraint
,
language
specific
variability
,
discussedin
,
previous
,
languagespecificity
,
hard
constraint
,
parameter
,
phonemic
sound
,
majority
,
language
,
languages
,
parameter
,
language
specific
sound
,
language
,
thisis
,
projection
direction
,
ith
language
phonemic
space
ui
,
phonemic
spacesof
,
language
,
handle
,
multiple
language
,
residual
vector
,
language
andaccounts
,
language
specific
phonemic
variations
,
new
formulation
,
residual
parameter
,
first
term
ofthis
summation
,
subspacewhile
,
second
term
,
residual
vector
,
residualvectors
,
formulation
,
thesounds
,
majority
,
language
,
thegiven
language
,
final
optimization
problem
,
theexamples
,
language
,
constraint
,
optimization
,
trivial
solution
,
vector
tozero
,
length
constraint
,
optimizationin
,
solution
,
optimization
problem
,
previous
,
modelwe
,
standard
procedure
,
grangian
,
optimization
problem
,
lagrangian
multiplier
,
length
constraint
,
lwith
respect
,
derivativesto
zero
,
following
equation
,
i1nipip
ti
uwe
,
equation
,
matrix
form
,
solution
becomesclear
,
brevity
,
xip
ti
,
generalizedeigenvalue
problem
,
inverse
,
matrix
,
eigenvalue
problem
,
problem
,
problem
,
inverse
,
partitionedmatrix
,
identity
,
thematrix
inverse
computation
,
problem
,
sizedi
,
problem
,
size
,
time
complexity
considerablysince
,
inverse
computation
,
f
t
mi
,
simplifying
result
,
following
eigenvalue
problem
,
ti
mif
ini
,
notice
,
parameter
,
lagrangian
multipliersat
,
possible
approach
,
optimization
,
parameter
,
grangian
multiplier
,
andsolve
,
correlationand
,
maximum
value
,
practice
,
top
correlation
,
valueof
,
observation
,
ri
asfollows
,
stability
,
system
weregularizegi
andei
,
top
keigenvectors
,
corresponding
ai
,
vectors
,
column
,
mappingsu
,
mapping
,
predictingthe
transliteration
,
language
intoany
language
,
prediction
,
source
name
anda
list
,
candidate
transliteration
,
decoding
problem
,
appropriate
target
language
transliteration
,
givena
word
xi
,
ith
language
,
transliterationinto
jth
language
xj
,
optimizationproblem
,
previous
,
form
solution
,
respect
,
unknown
phonemesequence
,
target
language
transliteration
,
ipa
sequence
,
substitute
,
transliterationin
,
jth
language
,
full
rank
matrix
,
numerical
stability
,
prediction
step
,
anidentity
matrix
,
notice
,
solution
doesn
,
depend
,
workthere
,
large
body
,
literature
,
entitytransliteration
,
relevant
one
,
transliteration
,
generative
approach
,
target
language17transliteration
,
source
name
,
knight
,
al2000
,
haizhou
,
al2004
,
onaizan
,
knight
,
discriminativeapproaches
,
target
language
name
,
source
,
thecorrect
transliteration
,
klementiev
,
sproat
,
discriminative
approach
,
targetlanguage
candidate
,
sproat
,
al2006
,
report
,
sourceof
,
candidate
transliteration
,
nevertheless
,
allthese
approach
,
bilingual
name
pairsor
phoneme
sequence
,
language
,
transliteration
system
,
languages
,
language
,
approaches
,
resource
,
languages
,
bridge
language
approach
,
resource
language
,
englishas
common
language
,
khapra
,
bilingual
resource
,
bridge
cca
,
khapra
,
single
mappingfunction
,
phonemic
space
,
languagesand
,
language
specific
variability
,
original
setting
,
author
,
thepivot
,
feature
space
,
irrespective
,
target
language
,
aserious
concern
,
bridge
language
,
map
word
,
common
phonemic
space
,
language
specific
resource
,
cmu
pronunciation
dictionary
,
constructed
cost
matrix
,
addition
,
substitution
,
anddeletion
,
phoneme
,
language
,
algorithm
,
ask
odex
,
use
hand
constructedconsonant
,
code
table
,
name
transliteration
,
variant
,
soundex
mapping
,
new
language
tobuild
transliteration
system
,
n
gram
charactersand
,
ipa
symbol
,
phoneme
dictionary
,
knight
,
xperimentsour
experiment
,
aspect
,
approachto
transliteration
,
bridge
,
approaches
,
thephoneme
modification
,
language
,
phoneme
dictionary
,
languageis
,
wiktionary
,
first
aspect
,
effectiveness
,
thebridge
language
,
methodwith
bridge
language
approach
,
establishthe
importance
,
language
specific
variance
,
multilinguality
,
method
,
aphoneme
dictionary
,
new
language
,
transliteration
system
,
existing
language
,
effect
,
data
froma
,
transliterationsystem
,
complementarity
,
using
ipa
,
bridge
,
transliteration
system
,
resource
poor
language
,
transliteration
system
,
bilingualname
pairs
,
language
,
effectiveness
,
phonemedictionaries
,
ipa
representations
,
wiktionary
dump
,
ctober
,
pairsin
,
language
,
resourcepoor
language
,
principle
,
method
,
languagepairs
,
additional
information
,
thispaper
,
eval
18en
,
statistic
,
different
data
set
,
trainingdata
,
monolingual
phoneme
dictionary
,
development
test
set
,
bilingual
name
pair
,
englishand
,
respective
language
,
uation
purpose
,
thethree
aspect
,
previous
,
phoneme
dictionary
,
phoneme
dictionaries
,
bulgarian
,
russian
contain
morethan
30k
,
twolanguages
,
phoneme
dictionary
,
thedevelopment
,
test
set
,
language
pair
,
geon
ames
data
base
,
geographic
locationnames
,
different
country
,
multiplelanguages
,
phoneme
dictionary
,
language
,
feature
vector
,
unigram
andbigram
feature
,
phonemic
space
,
bigram
,
trigram
feature
,
characterspace
,
feature
generation
,
feature
vectors
,
infrequent
featuresleads
,
method
,
projection
directions
,
perfect
correlation
,
downstream
application
,
last
,
character
space
,
language
,
phonemic
space
,
language
,
has3777
feature
,
phonemic
feature
,
language
,
subset
,
givenlanguage
,
data
set
,
total3777
common
phonetic
feature
,
and1009
feature
,
bulgarian
,
geonames
,
transliteration
system
withresidual
parameter
,
bulgarian
developmentdata
set
,
russian
language
,
indicatesthe
diversity
,
phonemic
inventory
,
differentlanguages
,
bridge
cca
,
astate
of
the
bridge
language
transliteration
system
,
discriminative
approach
,
khapra
,
phoneme
dictionary
,
language
,
baselinesystem
,
projection
direction
,
transliteration
,
testname
,
exact
match
,
thetop
,
transliteration
,
correct
transliteration
,
findtransliterations
,
direction
,
language
transliteration
,
source
name
,
viceversa
,
report
average
accuracy
,
bridge
cca
,
development
set
,
resultsin
,
experimental
result
,
thethree
aspect
,
bridgefig
,
cosine
,
result
,
baseline
system
,
test
set
,
second
block
,
result
,
ourapproach
,
phoneme
dictionary
,
language
pair
,
third
block
show
result
,
language
data
,
ment
data
set
,
projection
direction
,
sand
hence
,
completelyunrelated
vector
,
residual
parameter
,
residual
vector
,
subspace
,
eachlanguage
,
commonality
,
language
,
language
specific
variability
,
performancecurves
,
development
data
,
therest
,
result
,
bridge
cca
,
ourapproach
,
language
pair
,
theresults
,
proposedin
,
simple
cosine
similarity
,
comparison
,
cosine
similarity
performsalmost
,
bridge
cca
approach
,
however
,
decoding
,
givessignificant
improvement
,
thecosine
angle
,
ati
xi
,
atj
xj
,
appropriate
measure
,
vector
,
feature
vector
,
languages
,
true
ipa
representation
,
projection
direction
,
additional
residual
matrix
ri
,
rj
makethe
cosine
measure
inappropriate
,
residual
matrix
,
smalland
,
reason
,
bridge
cca
,
otherhand
,
method
,
integrates
,
possible
phoneme
sequenceand
,
yield
significant
improvement
,
restof
,
result
,
decodingin
,
approachachieves
,
maximum
improvement
,
bridge
cca
,
onan
average
,
improvement
,
notice
,
russian
phoneme
dictionary
,
mrr
of73
,
correct
name
transliterationis
,
average
,
fifth
,
themultilingual
result
,
language
,
en
ru
test
set
,
different
system
,
en
ro
test
set
,
language
,
language
family
,
slavonic
language
whilefrench
,
romance
language
,
language
,
family
,
similarpronunciations
,
oursystem
,
multilingual
data
set
,
language
,
final
experiment
,
onlymonolingual
resource
,
transliteration
,
bilingual
name
pair
,
transliteration
system
,
comparison
,
bilingualname
pair
,
third
,
parameters
,
test
set
,
reduction
,
linear
combination
,
ourapproach
,
training
data
,
locationname
pair
,
notice
,
training
,
test
data
forthis
system
,
domain
,
hasan
additional
advantage
,
happens
,
wiktionary
,
second
,
result
,
language
pair
,
achieves
high
accuracy
,
training
data
,
domain
match
,
training
,
test
data
set
,
baseline
,
google
machine
translation
api
,
name
,
en
bg
test
set
,
translation
engine
,
theresult
,
output
,
mt
system
,
edit
distance
,
returned
transliteration
tothe
true
transliteration
,
accuracies
,
result
,
transliterationgeneration
system
,
transliteration
mining
approach
,
lack
fair
comparison
,
report
,
google
transliteration
output
,
result
,
cca
approach
,
en
glish
word
,
candidate
,
combine
theirscores
,
line
search
,
appropriateweight
combination
,
fourth
,
result
,
linear
combinationwhen
,
weight
,
development
,
improvement
,
thoughnot
,
asophisticated
,
different
systems
,
significant
improvement
,
transliteration
system
trainedon
word
,
ipa
representation
,
bilingual
name
,
leading
,
regularization
,
bridge
language
approach
,
showedits
effectiveness
,
name
transliteration
task
,
interlingual
representation
,
monolingual
resource
,
transliteration
system
,
resource
poor
language
,
language
specific
phonemic
variation
,
significant
improvement
,
experimental
result
,
transliteration
system
,
ipa
data
,
accuracyof
,
transliteration
system
,
bilingual
namepairs
,
thought
,
bridge
language
thereare
viable
option
,
shownin
khapra
,
al2010
,
thebridge
language
,
name
transliteration
problem
,
considerable
time
,
manyresources
,
otherlanguages
,
appropriateness
ofi
pa
,
bridge
language
,
important
question
,
importance
,
language
specific
phenomenon
inthe
bridge
language
approach
,
appropriateness
,
bridge
language
,
technique
,
scenario
,
acknowledgementsthis
,
nsf
,
bol
program
,
defenseadvanced
research
project
agency
,
larkey
,
statistical
transliteration
,
cross
languageinformation
retrieval
,
proceeding
,
twelfth
international
conference
,
information
,
onaizan
,
knight
,
machinetransliteration
,
text
,
proceedings
,
workshop
,
computational
approaches
,
semitic
language
,
fai
wong
,
wai
lam
,
phoneme
based
transliteration
,
foreign
name
,
oov
problem
,
proceeding
,
international
joint
conference
,
li
haizhou
,
zhang
,
su
jian
,
jointsource
channel
model
,
machine
transliteration
,
inp
roceedings
,
annual
meeting
,
association
,
dryer
,
comrie
,
editor
,
world
atlas
ofl
anguage
structure
,
oxford
press
,
ulf
hermjakob
,
knight
,
name
translation
,
statistical
machine
translation
,
proceeding
,
columbus
,
hotelling
,
relation
,
set
ofvariables
,
biometrica
,
sung
young
jung
,
sunglim
hong
,
eunok
paek
,
transliteration
model
,
markov
window
,
proceeding
,
computational
linguistics
volume
,
key
sun
choi
,
approaches
,
resolution
,
word
mismatch
problem
,
word
,
foreign
word
,
ko
rean
information
retrieval
,
proceeding
,5
thinternational
workshop
,
information
retrievalwith
asian
,
khapra
,
pushpak
bhattacharyya
,
bridge
language
,
proceedings
,
alexandre
klementiev
,
entity
transliteration
,
discoveryfrom
multilingual
comparable
corpus
,
proceedings
,
international
conference
,
computational
linguistics
,
annual
meeting
,
association
,
graehl
,
machinetransliteration
,
computational
linguistics
,
haizhou
,
kumaran
,
pervouchine
,
andmin
zhang
,
report
,
machinetransliteration
,
proceeding
,
entity
workshop
,
womser
hacker
,
theeffect
,
entity
,
effectiveness
,
cross
language
information
retrieval
evaluation
,
proceedings
,
acm
symposium
,
yarowsky
,
multipathtranslation
lexicon
induction
,
bridge
language
,
inp
roceedings
,
meeting
,
north
americanchapter
,
association
,
computational
linguistics
,
patent
number
,
eiichiro
sumita
,
translationquality
indicator
,
international
joint
conference
onn
atural
language
processing
,
chiangmai
,
knight
,
phonememappings
,
transliteration
,
parallel
data
,
inp
roceedings
,
human
language
technology
,
the2009
annual
conference
,
north
american
chapter
,
association
,
computational
linguistics
,
boulder
,
iker
manterola
,
aki
san
,
method
,
precision
ofpivot
,
bilingual
dictionary
,
proceeding
ofthe
,
conference
,
empirical
method
,
natural
language
processing
,
edinburgh
,
tao
tao
,
chengxiang
zhai
,
entity
transliteration
,
comparable
corpus
,
proceeding
,
international
conference
onc
omputational
linguistics
,
annual
meeting
,
association
,
su
youn
yoon
,
fister
,
sproat
,
chengxiang
zhai
,
named22entity
transliteration
,
phonetic
correlation
,
proceeding
,
conference
one
mpirical
method
,
mitesh
,
khapra
,
transliteration
equivalence
,
canonical
correlationanalysis
,
raghavendra
udupa
,
saravanan
,
bakalov
,
andabhijit
bhole
,
transliteration
,
oov
queryterms
,
cross
language
information
retrieval
,
proceedings
,
conference
,
ir
research
,
advance
,
berlin
,
heidelberg
,
springer
verlag
,
masao
utiyama
,
hitoshi
isahara
,
comparison
,
pivot
method
,
phrase
based
statistical
machine
translation
,
proceeding
,
humanlanguage
technology
,
conference
,
thenorth
american
chapter
,
association
,
computational
linguistics
,
proceeding
,
main
conference
,
new
york
,
su
youn
yoon
,
kyoung
young
,
sproat
,
multilingual
transliteration
,
feature
basedphonetic
method
,
proceeding
,
annualmeeting
,
association
,
computational
linguistics
,
prague
,
republic
,13
th
conference
,
chapter
,
association
,
computational
linguistics
,
avignon
,
association
,
computational
linguisticsincorporating
lexical
prior
,
topic
modelsjagadeesh
jagarlamudiuniversity
,
udupamicrosoft
researchbangalore
,
indiaraghavu
microsoft
,
comabstracttopic
model
,
helping
user
,
document
corpus
,
purely
unsupervised
nature
,
topics
,
extrinsic
task
,
topic
model
,
topicsof
specific
interest
,
seed
word
,
corpus
,
modeluses
,
topic
word
distribution
,
appropriate
seed
word
,
document
topic
distribution
,
topic
related
tothe
seed
word
,
taskreveals
,
significant
improvement
,
using
seed
information
,
models
,
powerful
tool
,
document
collection
,
anunsupervised
fashion
,
documentcollection
,
topic
model
,
documentlevel
occurrence
information
,
related
word
,
theobjective
,
probability
,
observed
data
,
tendencyto
explain
,
superficialaspects
,
corpus
,
skewed
impression
,
corpus
,
extrinsic
task
,
problem
,
category
,
reuters
,
text
corpus
,
document
distribution
,
collection
,
thelda
,
topic
reveals
,
frequent
class
,
subsequent
twofrequent
class
,
cquisition
,
frequent
class
,
coloredwords
,
correspond
,
classand
blue
word
,
situation
,
accordance
,
topical
structure
,
corpus
,
problem
,
potentiallya
problem
,
extension
thereof
,
semantic
coherence
ofthe
word
,
wallach
,
document
topic
distribution
,
mca
uliffe
,
lacoste
julien
,
aspect
,
lafferty
,
problem
,
additional
information
,
document
collection
,
level
view
,
document
collection
,
forinstance
,
runon
historical
nip
paper
,
topics
,
brain
imaging
,
cognitive
science
orh
ardware
,
call
for204mln
,
company
,
record
,
quarter
,
earnings
,
profit
,
includeslt
,
company
,
acquisition
,
shareholdersbank
,
market
,
exchange
,
government
,
todayoil
,
production
,
frequent
category
,
reuters
corpus
,
category
,
acquisition
,
order
document
frequency
,
company
,
quarter
,
earnings2
acquisition
,
procurement
,
merge3
exchange
,
currency
,
trading
,
grain
,
oilseed
,
product
,
seed
word
,
seed
topics
,
frequent
category
,
reuters
21578categorization
corpus
,
corpus
,
evidence
,
topics
,
seed
set
,
compelling
evidence
,
datato
,
seed
information
,
freedom
,
approach
incombination
,
interactive
topic
modeling
,
explorea
corpus
,
exploration
towardsthe
distinction
,
seedsour
approach
,
topicdiscovery
process
,
seed
information
,
userprovides
set
,
seed
word
,
corpus
,
seedsets
,
reuters
corpus
,
thiskind
,
supervision
,
inbootstrapping
literature
,
thelen
,
riloff
,
prototype
based
learning
,
haghighi
,
seed
set
,
external
knowledge
,
mca
uliffe
,
andrzejew
ski
,
pairwise
constraint
,
an
drzejewski
,
topic
word
anddocument
topic
probability
distribution
,
forease
,
exposition
,
combination
,
topic
word
distribution
,
upa
model
,
topic
prefers
,
generate
word
,
seedset
,
document
topicdistributions
,
existence
,
seed
word
,
detail
,
models
,
thelda
model
,
reader
,
detail
,
hyper
parameters
,
document
topic
multinomial
probability
distribution
,
regular
topic
model
,
definedby
a
multinomial
distribution
,
notion
,
amixture
,
multinomial
distribution
,
distribution
,
distribution
,
seed
topic
distribution
,
generate
word
,
corresponding
seedset
,
regular
topic
distribution
,
seed
word
,
thefive
word
,
representation
,
model1
,
regulartopic
,
nonuniform
probability
distribution
,
seed
word
,
modelwill
,
probability
distribution
,
simplicity
,
one
to
one
correspondencebetween
seed
,
seed
topics
,
mixture
,
topics
,
distribution
,
parameter
,
theprobability
,
seed
topicdistribution
,
regular
topic
distribution
,
first
model
,
corpus
,
following
generative
process
,
graphical
notation
,
choose
,
choose
,
seed
topicthe
first
step
,
multinomial
distributions
,
constrainstheir
distribution
,
adocument
,
eitherthe
seed
,
regular
topic
distribution
,
oncethis
distribution
,
eachdocument
,
mixture
,
topics
,
aspect
,
model
,
model
gather
,
seed
word
,
saythe
fourth
,
seed
word
grain
,
related
word
,
production
,
high
probabilitymass
,
agriculture
,
documents
,
documentprobability
mass
,
result
,
penalty
,
seed
topicto
,
related
word
,
consequence
,
document
topicdistributions
,
binary
variable
xi
,
first
method
,
sampling
probability
,
constant
value
,
independent
,
second
method
,
theprobability
,
previous
model
,
seed
word
,
topic
word
probability
distribution
,
herewe
,
seedwords
,
document
topic
probability
distributions
,
previous
model
,
general
,
thenumber
,
seedset
,
conciseness
,
a
multinomial
distribution
,
regulartopics
,
group
topic
distribution
,
overview
,
seed
information
,
model
1dt
,
model
2dt
,
seededldafigure
,
graphical
notation
,
topic
wordprobability
distribution
,
seed
topic
information
,
document
level
,
document
token
,
document
topic
distribution
,
seededlda
,
seededlda
,
dependency
,
hyperparameter
,
clarity
,
dependency
,
thedocument
topic
distribution
,
stepprocess
,
priorto
,
step
process
,
flexible
number
,
topicdistributions
,
itsgraphical
notation
,
choose
,
topic
distribution
,
sthgroup
,
vector
,
length
,
binary
vector
,
length
,
first
generate
topic
word
distribution
,
group
topic
distribution
,
thenfor
,
seed
setsthat
,
binary
vector
,
document
word
,
oil
company
,
seed
set
,
binary
vector
,
seed
topic
containwords
,
presence
ofseeds
,
binary
vector
,
abouttopics
,
corpus
,
seedsexist
,
adirichlet
distribution
,
adocument
group
distribution
,
dirichlet
,
group
variable
,
group
variable
brings
,
structure
,
documents
,
s
topic
distribution
,
topic
distribution
,
sampling1as
,
special
,
seed
word
,
all
ones
vector
,
proceeds
,
topic
word
distribution
,
binary
vector
,
lda
model
,
hyperparameters
,
seed
word
,
differentways
,
topic
word
,
document
topicdistributions
,
boththe
,
combinedmodel
,
seededlda
,
generative
story
isas
,
graphical
notation
,
variable
,
semantics
,
theprevious
model
,
binary
vector
,
length
,
seededlda
model
,
process
,
generating
group
variable
,
described
,
themodel
,
document
topic
probabilitydistribution
,
a
d
irichlet
draw
,
group
topic
distribution
,
chosen
group
,
tokenand
,
biased
coin
,
theseed
,
result
,
thecoin
toss
,
distribution
,
andrzejewski
,
andrzejewskiet
,
seed
information
,
feature
selection
technique
,
prevalent
,
classificationliterature
,
seed
set
,
topicality
structure
,
thelda
,
underlying
class
structure
,
seed
word
,
representative
ofthe
underlying
topicality
structure
,
multi
class
,
ramage
,
discriminating
,
foreach
class
,
discriminatingfeatures
,
initial
set
,
seed
word
,
prototype
,
unsupervised
learning
,
haghighi
,
information
gain
,
required
discriminating
feature
,
whereh
,
entropy
,
class
andh
,
conditional
entropy
,
theword
,
information
gain
,
document
vector
,
class
ornot
,
ranked
list
,
eachclass
,
ambiguous
word
,
initial
set
,
seed
word
,
workseed
based
supervision
,
theidea
,
bootstrapping
literature
,
semantic
lexicon
,
thelen
,
riloff
,
small
set
,
seed
,
much
largerset
,
key
difference
,
semantic
information
,
capture
,
semantic
lexicon
,
specific
notion
,
countrynames
,
semantics
,
topicmodels
,
seeding
,
usedin
prototype
driven
learning
,
haghighi
,
similar
efficacy
,
semi
supervised
learning
approach
,
graber
,
modelssets
,
word
sense
disambiguation208task
,
distributionover
synset
,
relies
,
wordnet
,
synset
,
related
prior
,
andrzejewski
,
dirichlet
prior
,
mustlink
,
link
constraint
,
topicmodels
,
constrainedk
means
,
wagstaff
,
basuet
,
low
probability
,
link
between
,
word
pair
,
high
probability
,
thedirichlet
approach
,
constraint
,
predefined
weight
,
treesare
,
dummy
node
,
random
,
starting
,
selectingone
,
edge
weight
,
leaf
node
,
dirichlet
method
,
supervision
,
must
link
,
linkinformation
,
andrzejewski
,
different
approach
,
supervision
,
tokenlevel
,
specific
token
,
specified
list
oftopics
,
minimal
change
,
process
,
word
type
level
seedinformation
,
token
level
information
,
preventstheir
model
,
several
model
,
usesupervision
,
document
level
,
supervisedlda
,
mca
uliffe
,
disclda
,
lacoste
julien
,
category
label
,
sentiment
classification
,
document
labeleddata
,
tos
eededlda
,
labeledlda
model
,
ramageet
,
multi
classlabeled
corpus
,
mixture
,
known
subset
,
distribution
,
process
,
document
topic
distribution
,
labeledlda
,
processof
,
group
distribution
,
model
differs
,
beledlda
,
subsequent
step
,
group
distribution
,
group
variable
,
thedocument
topic
distribution
,
documentswithin
,
model
thebinary
vector
,
form
ofdocument
label
,
document
token
,
user
intothe
loop
,
quality
,
eachiteration
,
theauthors
,
dirichlet
method
,
preference
,
seededlda
,
better
,
dirichlet
method
,
seededldawhen
,
framework
,
userto
explore
,
document
collection
,
different
aspect
,
experimental
setup
proceeds
,
theeffectiveness
,
potential
benefit
,
seedwords
,
topic
model
,
different
setting
andcompare
,
multiple
baseline
system
,
dominance
,
thetopicality
structure
,
topic
models
,
document
corpus
,
extrinsic
evaluation
,
theprimary
evaluation
method
,
document
clustering
task
,
frequent
categories
,
reuters
corpus
,
al2004
,
newsgroups
data
,
electronics
,
hardware
,
atheism
,
boththe
corpus
,
standard
preprocessingof
removing
stopwords
,
infrequent
word
,
williamson
,
gibbssampler
,
steyvers
,
inference
process
,
standard
hyperparam
eters
value
,
sampler
,
iteration
,
canuse
technique
,
thehyperparameters
,
johnson
,
goldwater
,
newsgroupsf
measure
f
measure
vil
da
,
dirichlet
,
effect
,
constraint
,
dirichlet
encoding
,
lowerscore
,
clustering
,
statistical
significance
,
t
test
,
allthe
,
improvement
,
number
oftopics
,
cluster
,
eachdocument
,
maximumprobability
,
posterior
document
topic
distribution
,
cluster
,
accuracyof
,
document
clustering
,
termsof
f
measure
,
variation
,
information
,
f
measure
,
ground
truth
,
clustering
,
clustering
,
whereh
,
entropy
,
clusteringx
,
mutual
informationbetween
,
clustering
,
clustering
,
different
random
initializationsand
,
significance
result
,
usingthe
t
test
,
extractionthe
seed
,
small
sample
,
data
thanthe
test
data
,
seed
word
,
seed
word
,
filtering
,
reuters
,
newsgroupscorpora
,
dirichlet
method
,
effectiveness
,
extracted
seed
word
,
supervision
,
andrzejewski
,
al2009
,
amust
link
,
split
constraint
betweenevery
pair
,
different
set
,
different
random
initialization
,
wehave
,
relative
performance
,
significant
improvementover
,
plain
lda
,
effectivenessof
,
automatic
extraction
,
seed
word
,
topicmodels
,
next
experiment
,
modelswith
lda
,
baseline
,
first
baseline
,
maxcluster
,
hasmost
token
,
result
,
clustering
,
documents
,
baseline
,
effectiveness
,
theseed
word
,
respect
,
underlying
clustering
,
maxcluster
baseline
,
z
labels
,
andrzejewski
,
baseline
,
z
labels
,
tokens
,
seed
word
,
comparison
,
baseline
system
,
maxcluster
,
seed
word
,
poor
,
variant
,
first
run
,
probability
,
probability
,
constant
value
,
models2the
code
,
lda
baseline
,
code
available
fromhttp
,
andrzeje
research
df
lda
,
version
,
comparable
baseline
,
moreiterations
,
different
hyperparameters
,
result
,
intuition
,
newsgroupsf
measure
f
measure
vimaxcluster
,
seededlda
,
different
model
,
z
labels
approach
,
relative
performance
gain
,
respect
,
lda
model
,
comparison
,
dirichlet
method
,
probability
,
result
,
ofthe
seed
word
,
otherhand
,
theseed
word
,
nextrow
,
oursecond
model
,
data
set
,
firstmodel
,
second
model
,
variantsof
model
,
thanthe
lda
,
z
labels
approach
,
combined
model
,
seededlda
,
corpus
,
performanceimproves
,
thanthe
baseline
system
,
individual
model
,
topic
word
anddocument
topic
distribution
,
knowledge
learnt
,
individual
model
,
result
,
individual
model
,
baseline
systems
,
last
,
relative
performance
gain
,
seededlda
,
performance
gain
,
constraint
,
dirichletforest
method
,
seededlda
,
significant
gain
,
z
labels
approach
,
standard
,
quick
inspection
ofthese
interval
,
superior
performanceof
seededlda
,
baseline
,
thestandard
deviation
,
f
measures
,
different
random
initialization
,
model
isabout
,
corpus
,
reuters
,
newsgroupscorpora
,
reduction
,
variance
,
seed
information
,
increased
robustness
,
inference
process
,
seed
word
,
theaccuracies
,
seed
edlda
model
outperforms
model
,
seed
information
,
topicmodels
,
ambiguous
seedsin
,
following
experiment
,
effectof
ambiguous
seed
,
seed
word
,
occur
,
multiple
seed
set
,
corresponding
result
,
ambiguous
seed
word
,
lda
model
,
thequality
,
discriminative
power
,
seed
word
,
thanthe
number
,
seed
word
,
thetopics
,
seededlda
,
reuterscorpus
,
seed
set
,
plain
lda
,
nip
paperswe
,
seededlda
model
,
nip
spapers
,
corpus
,
theseed
word
,
proposal
,
agreement
,
shareholder
,
acquisition
,
merger
,
saleoil
,
production
,
barrel
,
energy
,
petroleum0
,
salestonnes
,
export
,
program
,
market
,
exchange
,
seededlda
,
frequent
category
,
reuters
corpusreuters
,
newsgroupsf
f
v
ilda
,
effect
,
ambiguous
seed
word
,
seed
edlda
,
area
,
sub
area
undereach
,
topics
,
seededlda
,
areas
,
seed
word
,
theambiguous
seed
word
,
qualitative
observation
,
artificial
intelligence
,
hardware
technology
,
nip
paper
,
theother
hand
,
seededlda
,
seededlda
,
symmetric
dirich
let
distribution
,
topic
word
distributions
,
first
attempt
method
,
asymmetricdirichlet
distribution
,
topic
worddistributions
,
informed
prior
,
seedset
,
asymmetric
prior
,
component
value
,
seedwords
,
positive
constant
value
,
favorsthe
,
seed
word
,
higherprobability
,
seed
word
,
an
drzejewski
,
distribution
,
theseed
word
,
convex
combination
,
differentweights
,
different
component
,
priorvector
,
asymmetric
generalization
,
informed
prior
,
comparability
purpose
,
regular
topicsas
,
general
enoughto
handle
situation
,
unequal
number
,
topicality
structure
,
corpus
,
seedtopic
,
distribution
,
many
nlp
applications
,
partial
informationrather
,
high
level
supervision
,
empty
seed
set
,
output
,
binary
vector
corresponding
,
seed
set
,
information
gain
,
discriminatingseed
word
,
real
world
application
,
available
odp
categorizationdata
,
level
seed
word
,
corporal
,
meaningful
,
methodsto
incorporate
lexical
prior
,
topic
models
,
single
model
,
wecall
seededlda
,
experimental
analysis
,
seed
wordto
,
multiple
set
,
seed
word
,
anonymous
reviewer
,
helpful
comment
,
material
,
national
science
foundation
,
topic
in
set
knowledge
,
proceedings
,
naa
cl
hlt
,
workshop
,
semi
supervised
learning
,
natural
language
processing
,
association
,
computational
linguistics
,
topic
modelingvia
dirichlet
,
annual
international
conferenceon
machine
learning
,
algorithm
,
theory
,
application
,
chapman
,
advance
,
int
ext
mining
,
theory
,
application
,
andfrancis
,
journal
,
maching
learning
research
,
word
sense
disambiguation
,
empirical
method
,
natural
language
processing
,
tea
leaf
,
humans
interpret
topic
model
,
neural
informationprocessing
system
,
semantic
representation
,
psychologicalreview
,
proceeding
,
national
academy
ofs
ciences
,
syntax
,
advance
,
neural
information
processing
systems
,
sequence
model
,
proceeding
ofthe
main
conference
,
human
language
technology
conference
,
north
american
chapter
,
association
,
association
,
proceeding
,49
thannual
meeting
,
association
,
computational
linguistics
,
human
language
technologiesvolume
,
association
,
computational
linguistics
,
experimentson
unsupervised
word
segmentation
,
adap
tor
grammar
,
proceeding
,
human
language
technology
,
annual
conferenceof
,
north
american
chapter
,
association
forcomputational
linguistics
,
disclda
,
discriminative
learning
,
dimensionality
reduction
,
classification
,
new
benchmark
collection
,
clustering
,
information
,
raw
,
new
york
,
multi
facetedtopics
,
manning
,
supervised
topicmodel
,
credit
attribution
,
multi
labeled
corpora
,
proceeding
,
conference
one
mpirical
method
,
natural
language
processing
,
volume
v
,
association
,
computational
linguistics
,
semantic
lexicon
,
extraction
pattern
context
,
empirical
method
,
k
means
,
background
knowledge
,
proceeding
,
eighteenth
international
conference
,
kaufmann
publisher
,
bag
of
words
,
workshop
,
bayesianmethods
,
natural
language
processing
,
dirichlet
process
,
application
,
cross
lingual
information
retrieval
system
,
indian
language
jagadeesh
jagarlamudi
,
a
k
umaran
,
first
participation
,
indian
language
subtask
,
main
adhoc
monolingual
,
bilingual
track
,
cle
competition
,
corpus
,
response
,
different
indian
language
,
telugu
,
bengali
,
marathi
,
monolingual
run
,
a
h
indi
,
bilingual
run
,
optional
run
,
language
,
monolingual
run
,
a
h
indi
,
word
alignment
table
,
source
language
,
equivalent
query
,
language
,
target
document
collection
,
a
language
modeling
,
retrieval
algorithm
,
data
set
,
official
cross
lingual
performance
,
monolingual
performance
,
post
submission
,
conference
,
north
american
chapter
,
association
,
computational
linguistics
,
human
language
technology
,
association
,
computational
linguisticslow
dimensional
discriminative
rerankingjagadeesh
jagarlamudidepartment
,
computer
scienceuniversity
,
computer
scienceuniversity
,
eduabstractthe
accuracy
,
many
natural
language
processing
task
,
rerankingstep
,
candidate
output
,
bya
baseline
system
,
novel
family
,
algorithm
,
learningseparate
low
dimensional
embeddings
,
thetask
,
output
space
,
embedding
,
low
dimensional
nearest
neighborsearch
,
key
quality
,
thatfeature
engineering
,
onthe
input
,
output
space
,
relationshipbetween
input
,
output
,
part
of
speech
tagging
task
,
language
,
significantimprovements
,
baseline
decoder
,
existing
reranking
approach
,
manynatural
language
processing
application
,
appropriate
pos
tag
sequence
,
harper
,
parsing
involves
,
appropriate
tree
structure
,
kubler
,
correct
target
language
translation
,
discriminative
rerankingstep
,
charniak
,
watanabe
,
pos
tagging
,
accuracies
,
language
,
novel
approach
,
reranking
,
effectiveness
,
pos
tagging
,
arbitrary
feature
,
input
andoutput
space
,
baseline
decoder
,
computationaltractability
issue
,
effectiveness
,
rerankingdepends
,
joint
feature
,
inputand
output
space
,
community
,
substantial
effort
,
joint
feature
,
chiang
,
joint
feature
,
theinput
,
output
space
,
problem
,
exact
mapping
,
output
,
instance
,
automatic
caption
generation
,
semantic
parsing
,
contrast
,
prior
,
output
space
,
mapping
function
,
within
space
feature
,
thefeature
engineering
,
clarity
,
thecontext
,
pos
tagging
,
course
,
reranking
problem
,
test
time
,
inp
o
tagging
,
list
ofcandidate
output
pos
,
feature
extractor
,
independent699feature
extractor
,
m
many
outputsto
,
representation
,
low
k
dimensional
space
,
output
,
maximizescosine
,
lower
dimensional
space
,
maxj
,
projection
,
result
,
thisoperation
,
low
loss
output
,
reference
tag
sequence
,
allpossible
pairwise
feature
combination
,
theviews
,
matrix
,
feature
vector
,
corresponding
tag
sequence
,
possiblepairwise
combination
,
long
range
dependency
asa
word
,
position
,
tag
choice
,
position
,
language
,
effectiveness
,
comparison
,
decoder
,
approaches
,
within
space
features
,
approaches
,
informative
joint
feature
,
joint
feature
,
ourmodels
,
low
dimensional
rerankingin
,
learninglow
dimensional
representation
,
wefirst
,
notation
,
intuition
,
problem
,
discriminative
style
approachesto
,
intuition
,
softenedvariant
,
discriminative
model
,
subsequent
,
computational
issue
,
reference
tag
sequence
,
training
data
,
mi
number
,
candidate
tag
sequence
,
output
,
baseline
decoder
,
constraint
,
loss
function
,
data
matrices
,
column
,
product
,
vectorsu
,
learnprojections
,
test
time
prediction
,
highaccuracy
,
output
,
cosine
similarity
betweenthe
input
,
output
,
vectors
,
low
dimensional
space
,
cosine
similarity
,
maximum
cosine
similarity
,
correct
output
,
one
dimensional
projection
vector
,
generalization
,
generative
probabilistic
model
,
relationship
,
inputand
,
desired
output
,
alternate
possible
output
,
account
,
context
,
intuition
,
previous
,
idea
isto
,
cosinesimilarities
,
training
data
,
minimal
loss
,
output
,
information
present
,
incorrect
output
,
cosine
similarity
,
alternate
output
,
comparison
,
training
data
,
theirreference
tag
sequence
,
generative
model
,
projection
directions
,
tag
space
,
tag
sequence
pair
,
maximum
cosine
similarity
,
one
dimensional
setting
,
correlation
,
objective
,
scaling
,
vectors
,
constraint
,
length
constraints
,
objectivefunction
,
tag
sequence
,
objective
function
,
scalar
xliymi
,
weight
vector
,
vector
,
kroneckerproduct
,
feature
vector
,
generative
objective
functionbears
similarity
,
machine
learning
,
theweights
,
outer
product
,
twovectors
,
reduced
expression
,
generative
model
considers
,
possible
pairwise
combination
,
others
,
weight
,
tagpair
,
training
data
,
atthe
time
,
infrequent
,
theirown
view
,
generative
model
,
referencetag
sequence
,
incorrect
candidate
tag
sequence
,
whatfollows
,
incorrect
candidate
tag
sequence
,
negative
examplesto
,
projection
direction
,
constraint
,
high
loss
outputs
,
low
loss
output
,
inthe
context
,
maximum
margin
structure
predictiontechniques
,
taskar
,
discriminativemodel
,
margin
deviation
,
projection
direction
,
projection
,
dimensional
subspace
,
cosine
similarity
,
reference
tag
sequence
,
itsincorrect
candidate
tag
sequence
,
themargin
,
similarity
,
candidate
tag
sequence
,
reference
,
farther
,
referencein
,
projected
space
,
decomposition
,
agiven
pair
,
source
sentence
xi
,
tag
sequenceyj
,
generative
model
,
listof
candidate
tag
sequence
,
thesecandidate
sequence
,
reference
tag
sequence
,
structure
prediction
literature
,
objective
function
,
thisidea
,
margin
constraint
,
tag
sequence
pair
,
tsochantaridis
,
nonnegative
slack
variable
,
weight
parameter
,
objective
function
,
margin
betweenthe
reference
,
candidate
tag
sequence
,
theprojected
space
,
atxiyti
,
slackis
,
candidate
tag
sequence
,
discriminative
modelone
disadvantage
,
discriminative
model
described
,
previous
,
closed
form
,
model
thatlies
,
generative
model
,
discriminative
model
,
softened
model
,
attractive
computational
property
,
compute
,
building
block
,
optimization
,
full
discriminative
model
,
reference
tag
sequenceyi
,
itscandidate
tag
sequence
,
atxiyti
,
discriminative
model
,
relaxed
version
,
average
,
thiswe
,
following
term
,
objective
function
,
residual
vector
betweenthe
reference
,
candidate
sequence
,
atxirtijb
,
normalization
bymi
,
unequal
numbers
,
candidate
tag
sequence
,
because
,
difference
,
length
,
inputsentences
,
matrix
,
samesize
,
ith
column
,
followingterm
,
generative
objective
function
,
projection
direction
,
following
optimization
problem
,
argmaxa
,
bty
y
t
,
weight
parameter
,
development
,
optimization
problem
,
firstwe
,
solution
,
generative
model
,
softened
discriminative
model
,
solution
,
subroutine
,
ourfinal
discussion
,
discriminative
model
,
generative
modelthe
optimization
problem
,
generative
model
,
ofcanonical
correlation
analysis
,
hardoon
,
solution
,
eigensystem
,
inparticular
,
projection
direction
,
generalized
eigensystem
,
autocovariance
matrix
,
cross
covariance
matrix
,
regularization
parameter
,
identitymatrix
,
appropriate
size
,
eigenvectorsas
column
,
projection
matrix
,
sentences
,
tag
sequence
,
dimensional
subspace
,
eigenvectors
,
generalization
,
top
eigenvectors
,
softened
modelin
,
softened
discriminative
version
,
summation
,
difference
term
,
candidate
tagsequences
,
simplerobjective
function
,
optimum
,
procedure
,
the702generative
model
,
projection
directions
,
discriminative
modelto
,
discriminative
model
,
lagrange
,
lagrangian
multiplier
,
margin
constraint
,
thenthe
lagrangian
,
respect
,
yieldsthe
solution
,
parameter
,
grangian
multiplier
,
matrix
,
size
d2
,
ith
column
,
cross
covariance
matrix
,
dependent
onthe
lagrangian
multiplier
,
thesolution
,
previous
formulationexcept
,
residual
vector
,
thelagrangian
multiplier
,
loss
function
,
margin
formulation
,
parameter
,
lagrangian
multiplier
,
parameter
,
termsof
,
lagrangian
multiplier
,
optimization
problem
,
weresort
,
alternate
optimization
technique
,
theprimal
space
,
firststage
,
lagrangian
multiplier
,
ij
fixedand
,
parameter
,
projection
direction
,
lagrangianmultipliers
,
generalized
eigenvalue
problem
,
parameter
,
discriminative
model
,
repeat4
,
ith
column
,
eigenvectors
,
top
eigenvectorsas
column
,
version
,
length
constraint
,
then13
,
end
if16
,
end
for17
,
slack
value
,
change18
,
return
,
projection
direction
,
second
stageof
,
alternate
optimization
,
gradient
step
,
function
,
process
,
convergence
,
algorithm
converges
,
iteration
,
iteration
,
pseudocode
,
lagrangian
multipliers
,
candidate
tag
sequences
,
output
,
thesoftened
model
,
experiments
,
good
starting
point
,
top
eigenvectors
,
development
,
length
constraints
,
algorithm
,
projection
direction
,
slack
value
,
update
direction
,
lagrangian
variable
,
potential
slack
value
,
constraint
,
satisfied
andthen
,
minimum
,
ij
values
,
slack
value
,
turn
implies
,
constraint
,
current
projection
direction
,
lagrangian
multipliers
,
otherwise
,
constraint
,
corresponding
lagrangian
multiplier
,
deviation
,
margin
constraint
,
new
slack
value
,
lagrangian
multiplier
,
gradient
direction
,
principle
,
cuttingplane
algorithm
,
slack
re
scalingversion
,
structured
svm
,
tsochantaridis
,
slack
variable
,
plane
method
,
maximum
,
ij
value
,
constraint
,
results
,
constraint
,
structured
svm
,
dual
problem
,
constraints
,
contrast
,
constraint
,
constraint
,
activeset
,
considers
,
weighted
average
,
allthese
constraint
,
complexity
,
thenumber
,
training
,
constraint
,
viterbi
decoding
scoreall
,
formulation
,
viterbi
,
tag
sequence
,
andkoo
,
score
play
,
importantrole
,
simple
linear
combination
,
viterbidecoding
score
,
low
dimensional
subspace
,
projectiondirections
,
candidate
tag
sequence
pair
,
viterbi
decoding
,
dimensional
projection
,
thefinal
score
,
simple
linear
combination
,
weight
,
grid
search
onthe
development
data
set
,
increment
,
development
set
,
pos
taggingto
,
training
data
,
feature
vector
,
thethree
method
,
dimensional
projection
direction
,
ofthose
approach
,
cross
covariance
matrix
cxy
,
threeapproaches
,
problem
,
different
,
following
approach
,
itreduces
,
eigenvalue
problem
,
eigenvalue
,
pos
tagging
,
tag
vocabulary
,
equation
,
eigenvalue
problem
,
theeigenvalue
problem
,
matricesa
andb
withcolumns
,
top
eigenvectors
,
similarity
,
development
data
setwe
,
linear
combination
,
projection
,
viterbi
,
reranking
stage
,
tocompute
,
projection
score
,
candidatetag
sequence
,
thisscores
,
candidate
tagsequences
,
language
,
and704train
,31
k
28k
table
,
training
,
test
data
statistic
,
language
,
ll
,
multilingualdependency
parsing
,
buchholz
,
pos
tag
,
thedependency
link
,
datastatistics
,
language
,
second
order
hidden
markov
model
,
harper
,
tagger
,
baselinetagger
,
trigramtransition
,
emission
probability
,
good
accuracy
,
languages
,
thebaseline
tagger
,
n
best
list
,
then
best
list
,
multi
fold
cross
validation
,
charniak
,
johnson
,
top
ranked
tagsequence
,
viterbi
,
oracle
accuracy
,
best
list
,
arehigh
,
state
of
the
system
,
oracle
,
improvement
,
reranking
,
scopefor
improvement
,
point
improvement
,
parsing
,
charniakand
johnson
,
difficultyof
,
reranking
problem
,
pos
tagging
,
well
resourced
language
,
baselinesin
,
suffix
oflength
,
word
view
andunigram
,
bigram
tag
sequence
,
thetag
view
,
suffix
,
length
,
suffix
,
candidate
pos
tag
sequence
,
bag
ofunigram
,
bigram
tag
feature
,
weuse
character
sequence
,
length
,
asfeatures
,
bi
gram
pos
tag
sequence
,
tag
view
,
alignment
,
features
,
position
,
boosting
baseddiscriminative
approach
,
regularized
version
,
fair
comparison
,
suffix
andtag
pair
,
following
feature
,
phrase
,
comparison
purpose
,
result
,
runningthe
baseline
rerankers
,
n
gram
feature
,
hyper
parameter
,
ourmodels
,
parameter
,
discriminative
,
discriminative
model
,
linear
combination
,
withthe
viterbi
,
size
ofthe
,
parameter
,
development
data
set
,
optimal
hyperparameter
valuesdiffer
,
language
,
respect
tothese
parameter
value
,
valuesfor
,
discriminative
model
,
language
,
showsthe
performance
,
respect
,
parameter
,
parameter
,
optimal
value
,
notice
,
performancevaries
,
thebaseline
tagger
,
result
,
different
model
,
development
,
test
data
set
,
test
dataset
,
baseline
,
better
,
hmm
decoder
,
swedishlanguages
,
andfrench
language
,
individual
character
,
good
indicator
,
pos
tag705
,
figure
,
tagging
accuracy
,
hyperparameters
,
development
data
set
,
baseline
hmm
tagger
,
different
reranking
approach
,
comparison
purpose
,
result
,
regularized
version
,
n
gram
feature
,
improvement
,
ourdiscriminative
model
,
information
,
additional
information
,
reranking
approach
,
a
g
ermanic
languagewith
word
phenomenon
,
thebaseline
hmm
decoder
weaker
,
englishand
,
fourth
block
,
ourmodels
,
swedish
,
baseline
decoder
,
rerank
ing
approach
,
baseline
system
,
approachesindicate
,
pairwise
combinations
,
model
capturedependencies
,
amongthe
different
formulation
,
margin
,
correct
,
incorrectcandidates
,
ensuring
,
margin
,
loss
ofthe
candidate
sequence
,
improved
result
,
discriminative
version
,
theother
variant
,
baseline
decoder
,
discriminative
version
,
maximum
improvement
,
improvement
,
swedish
language
,
result
,
baselinererankers
,
n
gram
feature
,
fifth
block
oft
,
reader
,
suffix
feature
,
fair
comparison
the706en
,
viterbi
decoding
score
,
reader
,
result
,
baselinererankers
,
suffix
feature
,
baseline
ranker
,
n
gram
feature
,
thanthe
discriminative
model
,
ourmodels
,
viterbi
decoding
score
,
accordance
,
workin
,
problem
,
nlp
literature
,
discriminative
reranking
hasbeen
,
charniak
,
johnson
,
johnson
,
statistical
machine
translation
,
shen
etal
,
watanabe
,
algorithm
,
voted
perceptron
,
pos
tagging
task
,
later
huang
,
regularized
version
,
objective
usedby
,
improved
performance
,
rerankingapproaches
,
feature
function
,
output
,
whereas
,
viewand
,
algorithm
,
relationship
betweenthem
,
rerankers
,
principle
,
margin
formulation
,
margin
formulation
,
maximum
margin
regression
,
hese
approaches
,
following
optimization
problem
,
differs
,
formulation
,
twomain
,
generativemodel
,
input
output
pair
,
xti
abt
yi
,
rank
constraint
,
dimensionality
reduction
,
improvedperformance
,
rank
constraint
becomescrucial
,
difference
,
constraints
,
represent
,
output
pair
,
margin
,
constraint
include
incorrect
output
,
loss
value
,
formulation
,
suitable
forthe
,
problem
,
suitablefor
regression
,
classification
task
,
generative
model
,
supervised
semantichashing
,
novel
family
,
models
,
discriminative
reranking
problem
,
showedimprovements
,
different
language
,
utility
,
technique
,
didnot
experiment
,
different
feature
,
important
direction
,
spacefeatures
,
rerank
ing
approach
,
informative
alignment
based
feature
,
possible
toinclude
alignment
based
feature
,
problem
,
feature
selection
problem
onthe
covariance
matrix
,
jagarlamudi
,
inverse
computation
,
eigenvalue
problem
,
medium
size
data
set
,
data
set
has50k
,33
k
feature
,
alternative
approximation
technique
,
large
data
set
,
future
,
acknowledgmentswe
,
zhongqiang
huang
,
codefor
,
baseline
system
,
raghavendra
udupa
,
anonymous
reviewer
,
insightful
comments
,
grangier
,
ronancollobert
,
kunihiko
sadamasa
,
kilian
weinberger
,
learningto
rank
,
hofmann
,
bernhardscho
,
taskar
,
vishwanathan
,
structureddata
,
dellapietra
,
mercer
,
mathematics
,
statistical
machine
translation
,
parameter
estimation
,
comput
,
linguist
,
buchholz
,
marsi
,
conll
x
sharedtask
,
multilingual
dependency
,
proceedings
,
tenth
conference
,
computational
natural
language
learning
,
association
,
computational
linguistics
,
charniak
,
johnson
,
coarse
to
fine
n
best
parsing
,
maxent
discriminative
rerank
ing
,
proceeding
,
annual
meeting
ona
ssociation
,
associationfor
computational
linguistics
,
chiang
,
knight
,
wei
,
new
feature
,
statistical
machine
translation
,
proceeding
,
human
language
technologies
,
annual
conference
,
north
ameri
can
chapter
,
association
,
association
,
computational
linguistics
,
discriminative
reranking
,
natural
language
parsing
,
computational
linguistics
,
algorithm
,
named
entity
extraction
,
boosting
,
voted
perceptron
,
proceeding
,40
th
annual
meeting
,
association
,
associationfor
computational
linguistics
,
renjing
,
hinrich
schu
,
bitext
projection
feature
,
parse
rerank
ing
,
proceeding
,
conference
,
eu
ropean
chapter
,
association
,
association
,
computational
linguistics
,
halko
,
per
gunnar
,
martinsson
,
joeltropp
,
structure
,
randomness
,
stochastic
algorithm
,
approximatematrix
decomposition
,
technical
report
,
californiainstitute
,
technology
,
hardoon
,
szedmak
,
canonical
correlation
analysis
,
overview
,
application
,
method
,
neural
comput
,
hotelling
,
relation
,
set
ofvariables
,
biometrica
,
zhongqiang
huang
,
harper
,
wen
,
part
of
speech
tagging
,
discriminative
reranking
,
proceeding
,
jointconference
,
empirical
method
,
natural
language
processing
,
prague
,
republic
,
association
,
computational
linguistics
,
jagadeesh
jagarlamudi
,
raghavendra
udupa
,
abhijit
bhole
,
improvingbilingual
projection
,
sparse
covariance
matrix
,
proceeding
,
conference
,
empiricalmethods
,
natural
language
processing
,
pages930
,
edinburgh
,
associationfor
computational
linguistics
,
johnson
,
engin
ural
,
brown
parser
,
human
language
technology
,
annual
conference
,
north
american
chapter
,
association
,
computationallinguistics
,
kubler
,
mcd
onald
,
joakim
nivre
,
andgraeme
hirst
,
dependency
parsing
,
morganand
claypool
publisher
,
liang
,
klein
,
taskar
,
end
to
end
discriminativeapproach
,
machine
translation
,
proceedingsof
,
international
conference
,
computational
linguistics
,
annual
meeting
,
theassociation
,
associationfor
computational
linguistics
,
mcd
onald
,
koby
crammer
,
pereira
,
large
margin
training
,
dependencyparsers
,
proceeding
,
annual
meeting
ona
ssociation
,
association
forcomputational
linguistics
,
libin
shen
,
aravind
,
svm
basedvoting
algorithm
,
application
,
proceeding
,
seventh
conference
,
naturallanguage
,
hlt
naa
cl
,
association
,
computational
linguistics
,
anoop
sarkar
,
och
,
discriminative
reranking
,
machine
translation
,
human
language
technology
conference
,
north
american
association
,
parado
hernandez
,
linear
operator
,
maximum
margin
regression
,
multiclass
,
multiview
,
atone
class
complexity
,
technical
report
,
ofs
outhampton
,
szedmak
,
tijl
de
bie
,
hardoon
,
metamorphosis
,
canonical
correlation
analysis
,
multivariate
maximum
margin
,
inp
roceedings
,
fifteenth
symposium
ona
rtificial
neural
network
,
taskar
,
guestrin
,
koller
,
margin
markov
network
,
proceeding
ofn
ips
,
harper
,
second
order
hidden
markov
model
,
part
of
speech
tagging
,
proceeding
,
annual
meeting
,
association
,
computational
linguistics
,
association
,
computational
linguistics
,
ioannis
tsochantaridis
,
hofmann
,
thorstenjoachims
,
yasemin
altun
,
vector
machine
learning
,
interdependent
,
structuredoutput
space
,
proceeding
,
twenty
first
international
conference
,
machine
,
shawe
,
szed
mak
,
kernel
regression
,
machine
translation
,
human
language
technology
,
theconference
,
north
american
chapter
,
association
,
computational
linguistics
,
companionvolume
,
association
,
computational
linguistics
,
taro
watanabe
,
suzuki
,
hajime
tsukada
,
hidekiisozaki
,
large
margin
training
,
statistical
machine
translation
,
proceeding
,
the2007
joint
conference
,
empirical
method
,
natural
language
processing
,
prague
,
republic
,
association
forcomputational
linguistics
,
annual
meeting
,
association
,
computational
linguistics
,
shortpapers
,
portland
,
association
,
computational
linguisticsfrom
bilingual
dictionary
,
interlingual
document
representationsjagadeesh
jagarlamudiuniversity
,
udupamicrosoft
research
indiabangalore
,
indiaraghavu
microsoft
,
interlingual
representation
,
language
barrier
,
cross
lingual
corpus
,
trainingdata
,
interlingual
representation
,
domain
,
interlingual
representation
,
unsupervisedmanner
,
bilingual
dictionary
,
wefirst
,
bilingual
dictionary
,
candidate
document
alignment
,
themto
,
interlingual
representation
,
sincethe
candidate
alignment
,
robust
learning
algorithm
,
interlingual
representation
,
thatbilingual
dictionary
,
differentdomains
,
word
translation
method
,
different
domain
,
ntroductionthe
growth
,
text
corpus
,
different
languagesposes
,
inherent
problem
,
documentsacross
language
,
explicit
alignment
,
different
,
language
barrier
,
important
step
,
church
,
balles
teros
,
munteanu
,
klementievand
,
hermjakob
,
udupa
etal
,
knight
,
multilingualweb
search
,
different
language
,
problem
,
problem
,
documentsinto
,
common
subspace
,
interlingual
representation
,
common
subspace
,
notion
,
vector
space
model
,
cross
lingual
applications
,
turney
,
pantel
,
thedocument
alignment
problem
,
theavailable
resource
,
first
approach
,
literature
,
bilingual
dictionaries
,
language
,
source
,
target
,
language
,
ballesterosand
croft
,
pirkola
,
standard
measure
,
cosine
similarity
,
close
tothe
,
second
approach
,
aligned
document
pair
,
acommon
subspace
,
documentpairs
,
dumais
,
vinokourov
,
haghighi
,
strengthsand
weakness
,
dictionary
,
translation
,
relationship
,
restof
,
otherhand
,
interlingual1we
use
,
phrase
,
common
subspace
,
interlingualrepresentation
,
strong
dependency
,
data
prevents
,
different
domain
,
technique
,
advantage
,
bilingual
dictionariesto
,
initial
noisy
document
alignment
,
noisy
alignment
,
training
data
,
common
subspace
,
thealignments
,
learning
algorithmthat
,
training
data
,
technique
,
trainingdata
,
anunsupervised
approach
,
kernelized
sorting
,
quadrianto
,
supervisedvariant
,
variant
learnsto
,
alignment
,
original
algorithm
,
supervised
variant
,
candidatealignments
,
primary
advantage
,
method
,
training
data
,
generalizes
,
different
domain
,
dictionary
,
common
subspace
,
isolation
,
main
contribution
,
discriminative
technique
,
interlingual
representation
,
supervised
variantof
kernelized
sorting
algorithm
,
quadrianto
,
language
document
similarity
,
cross
lingual
corpus
,
unknown
document
alignment
,
techniqueto
,
hidden
alignment
,
interlingual
representation
,
thefirst
stage
,
bilingual
dictionary
,
initial
candidate
noisy
document
alignment
,
second
stage
,
robust
learning
algorithm
,
acommon
subspace
,
noisy
alignment
,
first
step
,
common
subspace
,
usemaximal
matching
,
hidden
alignment
,
mapping
,
thedocument
space
,
common
subspace
,
thesemappings
,
new
documentinto
,
interlingual
representation
,
detail
,
following
twosub
,
language
,
another
language
,
neighboursgives
potential
alignment
,
resulting
alignment
,
direction
,
translation
,
asymmetryof
bilingual
dictionary
,
neighbourproperty
,
asymmetry
,
language
,
bagof
translation
pair
representation
,
feature
representation
,
ja
garlamudi
,
graberand
blei
,
bilingual
dictionary
,
dictionary
entry
,
new
feature
,
bilingual
dictionary
entry
,
tfi
df
,
document
matrix
,
binary
matrix
matrix
,
sizeno
,
dictionary
entry
,
vocab
size
,
dictionary
entry
,
linear
operation
,
dictionary
entry
representation
,
bipartitegraph
,
language
,
aseparate
set
,
wij
between
,
sourceand
target
language
,
theeuclidean
distance
,
thedictionary
space
,
language
,
objective
andthe
constraint
,
bagof
dictionary
entries148problem
,
ravindra
,
argminpim
,
user
chosen
constant
,
source
,
targetlanguages
,
last
constraint
,
optimization
problem
,
anintegral
solution
,
reduces
,
maximum
matching
problem
,
jonker
,
volgenant
,
many
to
many
mapping
,
constant
,
valueless
,
wefound
,
better
performance
,
hard
,
optimal
solution
,
linear
programming
,
ravin
dra
,
kernelized
sortingkernelized
sorting
,
unsupervised
technique
toalign
object
,
quadrianto
,
ja
garalmudi
,
main
advantage
,
thismethod
,
intra
language
document
similarity
,
alignment
acrosslanguages
,
supervisedvariant
,
kernelized
sorting
,
set
ofcandidate
alignment
,
learns
,
intra
language
document
similarity
,
givenalignment
,
sorting
,
interlingual
document
similarity
,
supervised
version
,
noisyalignments
,
tfi
df
,
document
matrix
,
language
,
linear
product
,
permutation
matrixwhich
,
alignment
,
document
ofdifferent
language
,
indicates
documents
xi
,
kernelized
sorting
formulates
,
solution
,
following
optimization
problem
,
gretton
,
supervised
version
,
kernelized
sorting
,
permutation
matrix
,
kernel
matrix
kx
,
objective
function
,
permutation
,
mapping
,
language
,
common
subspace
,
alignment
,
commonsubspace
,
neighbor
,
thealigned
pair
,
mapping
,
required
subspace
,
language
,
optimization
problem
,
argmaxu
,
identity
matrix
,
appropriate
size
,
forbrevity
,
cross
covariance
matrix
,
objective
function
becomes
,
argmaxu
,
cyclic
property
,
function
,
alternative
maximization
,
unknown
,
fixingv
,
objective
function
usingthe
cyclic
property
,
function
,
following
solution
,
initial
iteration
,
v0v
t0
asidentity
matrix
,
kernel
matrix
,
theoptimization
problem
,
result
,
special
,
v0v
t0
,
u0u
t0are
identity
matrix
,
equation
,
particular
,
first
iteration
,
cross
covariance
matrix
,
mapping
,
thesubsequent
iteration
,
mapping
,
previous
iteration
,
procedure
,
alignment
,
documentsinto
bag
,
dictionary
entry
representation
,
optimization
problem
,
initial
candidate
alignment
,
thelemon3
graph
library
,
cost
flowproblem
,
piij
value
,
everycross
lingual
document
pair
,
relaxed
permutation
,
mapping
,
language
,
mapping
,
bothsource
,
common
subspace
,
bipartite
matchingproblem
,
document
pair
,
wikipedia
,
andenglish
german
language
pair
,
datasets
,
morethan
,
frequency
criterion
,
dataset
,
word
phenomenon
,
frequentwords
,
german
data
set
,
subsequentlywe
,
tfi
df
,
vectors
,
bilingual
dictionary
,
language
pair
,
data
,
different
approach
,
german
language
pair
,
thewithin
language
covariance
matrix
,
regularization
parameter
,
process
,
document
alignment
,
method
,
dictionary
basedapproach
,
word
by
word
translation
,
andsupervised
approach
,
hotelling
,
ourapproach
,
bilingual
dictionary
,
training
corpus
,
bilingual
dictionary
,
eu
roparl
data
set
,
fair
comparison
,
supervised
approach
,
document
pair
,
data
set
,
training
domain
,
foropca
,
regularization
parameter
,
bipartite
graph
,
documents
,
different
language
,
edge
weight
,
cross
lingual
similarity
,
respective
method
,
maximal
matching
,
jonkerand
volgenant
,
therecovered
alignment
,
show
accuracy
,
different
method
,
german
data
set
,
comparisonpurposes
,
documentsfrom
domain
,
and62
accuracy
,
data
set
,
trainedon
article
,
german
dataset
,
simple
word
by
word
translation
performedbetter
,
languagepairs
,
word
by
word
translation
method
,
the150supervised
approach
,
method
doesnot
,
training
data
,
parameter
,
theproblem
,
linear
assignment
problem
,
fromthe
result
,
relaxed
version
ofthe
problem
,
improvements
,
german
,
language
pair
,
firststage
,
word
by
word
translation
system
,
toword
by
word
translation
,
effectiveness
ofthe
,
kernelized
sorting
,
solution
,
supervised
kernelized
,
resembles
latent
semantic
indexing
,
deer
wester
,
document
matrix
,
efficient
algorithm
exist
,
arbitrarilylarge
matrix
,
approach
scalableto
large
data
set
,
warmuth
,
kuzmin
,
mapping
,
mapping
,
noisyalignments
,
svd
problem
,
extension
,
situationwith
different
number
,
change
,
projection
direction
,
bipartite
matching
problem
,
dummydocuments
,
language
,
documentsand
,
high
score
,
recover
document
alignment
,
bilingual
dictionary
,
thebilingual
dictionary
,
candidate
noisyalignments
,
noisy
alignment
,
kernelized
sorting
,
language
document
similarity
,
alignment
,
complimentary
information
source
,
alignment
,
thefirst
step
,
cross
lingual
cue
,
theform
,
bilingual
dictionary
,
latter
stepexploits
document
structure
,
term
ofwithin
language
document
similarity
,
experimental
result
,
approach
performs
,
word
by
word
translation
,
supervised
approach
,
croft
,
dictionary
method
,
cross
lingual
information
retrieval
,
proceeding
,
international
conferenceon
database
,
springer
verlag
,
graber
,
multilingual
topic
model
,
unaligned
text
,
uncertaintyin
artificial
intelligence
,
deerwester
,
information
,
latent
semantic
indexing
,
editor
,
proceedings
,
american
societyfor
information
science
,
church
,
program
,
bilingual
corpus
,
inp
roceedings
,
annual
meeting
,
association
,
computational
linguistics
,
association
,
computationallinguistics
,
wei
gao
,
blitzer
,
ming
zhou
,
usingenglish
information
,
non
search
,
acm
workshop
oni
,
non
searching
,
blitzer
,
ming
zhou
,
fai
wong
,
bilingual
information
,
search
,
proceeding
,
human
language
technologies
,
conference
,
gretton
,
bousquet
,
olivierbousquet
,
smola
,
schlkopf
,
bern
hard
schlkopf
,
statistical
dependence
,
schmidt
,
proceeding
ofa
,
learning
theory
,
springer
verlag
,
haghighi
,
liang
,
kirkpatrick
,
anddan
klein
,
bilingual
lexicon
frommonolingual
corpus
,
proceeding
,
columbus
,
association
,
computational
linguistics
,
ulf
hermjakob
,
knight
,
name
translation
,
statistical
machine
translation
,
proceeding
,
columbus
,
association
,
computational
linguistics
,
hotelling
,
relation
,
variables
,
biometrica
,
jagadeesh
jagaralmudi
,
juarez
,
natural
language
processing
,
proceeding
,
aaa
inference
,
artificialintelligence
,
jagadeesh
jagarlamudi
,
unaligned
comparable
corpus
,
advance
,
information
retrieval
,
conference
,
volume
,
springer
,
jonker
,
volgenant
,
shortest
augmenting
path
algorithm
,
sparse
linear
assignment
problem
,
computing
,
alexandre
klementiev
,
entity
transliteration
,
discoveryfrom
multilingual
comparable
corpus
,
proceedings
,
international
conference
,
computational
linguistics
,
annual
meeting
,
theassociation
,
associationfor
computational
linguistics
,
philipp
koehn
,
parallel
corpus
forstatistical
machine
translation
,
mt
summit
,
mimno
,
wallach
,
naradowsky
,
mcc
allum
,
polylingual
topic
model
,
proceeding
,
empirical
method
,
natural
language
processing
,
volume
v
,
associationfor
computational
linguistics
,
dragos
munteanu
,
marcu
,
improving
machine
translation
performance
,
exploiting
nonparallel
corpus
,
comput
,
linguist
,
och
,
ney
,
systematic
comparison
,
various
statistical
alignment
models
,
computational
linguistics
,
pirkola
,
turid
hedlund
,
heikki
keskustalo
,
andkalervo
jrvelin
,
dictionary
based
cross
language
information
retrieval
,
problem
,
method
,
research
finding
,
information
retrieval
,
toutanova
,
wen
tau
yih
,
translingual
document
representation
fromdiscriminative
projection
,
proceeding
,
the2010
conference
,
empirical
method
,
le
song
,
bengio
,
bottou
,
editor
,
advance
,
piyush
rai
,
multi
label
prediction
,
sparse
infinite
cca
,
advance
,
neuralinformation
processing
system
,
vancouver
,
rapp
,
automatic
identification
,
wordtranslations
,
unrelated
,
german
corpora
,
proceeding
,37
th
annual
meetingof
,
association
,
knight
,
phonememappings
,
transliteration
,
parallel
data
,
inp
roceedings
,
human
language
technology
,
the2009
annual
conference
,
north
american
chapter
,
association
,
computational
linguistics
,
boulder
,
orlinjames
,
network
,
theory
,
andapplications
,
littman
,
dumais
,
lan
dauer
,
automatic
cross
linguistic
informationretrieval
,
latent
semantic
indexing
,
workingnotes
,
workshop
,
zurich
,
turney
,
pantel
,
frequency
,
meaning
,
vector
space
model
,
semantics
,
intell
,
ja
gadeesh
jagarlamudi
,
method
,
scalable
mining
,
entity
transliterations
,
large
comparable
corpus
,
pages799
,
association
,
computer
linguistics
,
vinokourov
,
shawe
,
nello
tianini
,
semantic
representationof
text
,
cross
language
correlation
analysis
,
dvances
,
neural
information
processing
system
,
zhang
,
feature
basedmethod
,
document
alignment
,
comparable
newscorpora
,
warmuth
,
dima
kuzmin
,
randomized
pca
algorithm
,
regret
bound
,
dimension
,
neural
informationprocessing
system
,
annual
meeting
,
association
,
computational
linguistics
,
shortpapers
,
portland
,
association
,
computational
linguisticsdomain
adaptation
,
machine
translation
,
edujagadeesh
jagarlamudiuniversity
,
unseen
word
,
alarge
part
,
translation
error
,
moving
,
new
domain
,
extension
ofa
approach
,
mining
translation
fromcomparable
corpus
,
haghighi
,
translation
,
otherwiseoov
term
,
translation
,
phrase
based
translation
system
,
consistentimprovements
,
translation
quality
,
between0
,
domain
andtwo
language
pair
,
ntroductionlarge
amount
,
available
totrain
statistical
machine
translation
system
,
training
data
,
target
task
,
translation
system
,
specificaspect
,
domain
divergence
,
out
of
vocabulary
problem
,
different
target
domain
,
movie
subtitle
,
technical
documentation
,
source
language
,
degree
,
divergence
cause
,
unseen
word
,
thedegree
,
instance
,
unknown
word
arenames
,
verbatim
,
extend
,
method
,
dictionaries
,
comparable
corpus
,
domainadaptation
setting
,
translation
,
source
domain
,
develop
method
,
dictionaries
,
phrase
based
translation
system
,
target
domain
,
ofvocabulary
term
,
source
,
approximatelyhalf
,
additional
error
,
exception
,
news
domain
,
proceeding
,
frequent
word
,
intoa
translation
system
,
baseline
,
clever
integration
,
gap
betweenbaseline
,
oracle
experiment
,
improvement
,
papineni
,
banerjee
,
specific
setting
,
inwhich
,
plentiful
parallel
,
parliament
,
unlabeled
data
,
target
domain
,
good
language
model
,
access
,
small
amount
,
parallel
,
target
data
,
weight
tuning
,
knowledge
,
unseen
word
,
comparable
data
,
challengesdomain
adaptation
,
well
studied
field
,
thenlp
community
,
machine
,
andstatistics
community
,
machine
learning
,
translation
,
weight
,
learned
translation
model
,
new
domain
,
unseen
word
,
challenge
,
translation
system
,
distant
domain
,
nomachine
,
adaptation
,
problem
,
attempt
,
domain
adaptation
,
machine
translation
,
first
approach
,
test
setrelativization
,
training
sample
,
test
data
,
translation
performance
,
data
set
,
hildebrand
,
data
set
madeavailable
,
statmt
workshop
,
koehn
andschroeder
,
civera
,
bertoldi
,
fed
erico
,
snover
,
corpus
resource
,
fromparliament
domain
,
source
domain
,
parliamentproceedings
,
statmt
,
target
domain
,
thenews
commentary
corpus
,
medicinesagency
text
,
open
subtitle
data
,
php
technical
document
data
,
opu
corpus
http
,
development
,
test
set
,
corpus
,
sourcedomain
,
dev
andtest
data
,
source
,
domain
,
numberof
word
,
side
,
theparallel
data
,
languagepairs
,
german
englishhave
,
statistic
,
comparable
tune
testsents
word
sent
,
frequent
oov
wordsnews
,
behavior
,
neighbor
,
ahmedinejad
,
bernanke
,
neighbor
,
skeptic
,
skepticismemea
,
ribavirin
,
olanzapine
,
pharmacokinetics
,
riton
avir
,
hydrochlorothiazide
,
erythropoietin
,
efavirenz
,
hypoglycaemia
,
epoetin
,
blister
,
pharmacokineticsubs
,
goddamn
,
bigweldphp
,
apache
,
integer
,
socket
,
filename
,
postgresql
,
constant
,
syntax
,
domain
,
target
domain
word
,
source
domain
,
frequent
word
,
target
domain
,
source
domain
,
nthe
actual
data
,
subtitle
word
,
data
set
,
paralleltarget
domain
data
,
comparable
data
,
ofthe
text
,
thegerman
text
,
wikipedia
,
difference
betweenthese
domain
,
simple
statistic
,
vocabulary
word
,
domain
,
ofwords
,
target
domain
,
unseen
inthe
parliament
data
,
canonical
correlation
analysis
,
multi
viewdata
set
,
canonical
correlation
analysis
,
projection
direction
,
viewso
,
object
,408
rections
,
hotelling
,
new
pair
,
similarity
,
ontothe
,
dimension
space
,
cosine
similarity
,
projection
,
eigenvectors
,
top
eigenvectors
,
eralizability
,
translations
,
oov
german
word
,
haghighi
,
target
domain
corpus
,
themost
frequent
word
,
boththe
language
,
bilingual
dictionary
,
training
data
,
cca
projection
,
frequent
word
,
involves
multiple
stage
,
first
stage
,
feature
vector
,
weuse
context
,
orthographic
feature
,
second
stage
,
dictionary
probability
,
seenwords
,
feature
vectors
,
cca
projection
direction
,
final
stage
,
thesub
space
,
oov
word
,
thesesteps
,
detail
,
frequent
word
,
context
vector
,
window
,
length
,
overcome
data
sparsity
issue
,
contextword
,
character
,
thecontext
feature
,
fivewords
,
language
,
frequency
vector
,
tfi
dfvectors
,
vectors
,
feature
value
,
positive
ofnot
,
using
linear
product
kernel
,
eachword
,
orthographic
feature
,
n
gramsof
length
,
tfi
df
form
,
word
similarity
,
datainto
word
similarity
,
orthographic
feature
,
script
,
source
,
target
language
,
language
,
en
waste
blutdruckabfall
,
blutdruckabfall
,
blutdruckabfall
,
random
unseen
emea
word
,
german
andtheir
,
translation
,
language
,
thekernel
matrix
,
context
vectorsand
,
orthographic
feature
,
incomletecholesky
decomposition
,
dimensionality
,
kernel
matrix
,
pre
processng
,
training
word
,
theoov
word
,
resulting
feature
vector
,
cca
projectionssince
,
multiple
translation
,
translation
,
bipartite
graph
,
training
word
,
languageas
node
,
translationprobability
,
word
pair
,
hungar
algorithm
,
maximum
weighted
bipartite
matching
,
jonker
,
volgenant
,
bipartitematching
,
projection
direction
,
language
,
eigenvectors
,
relevant
experiment
,
setting
,
baseline
approach
,
frequent
word
,
language
,
lowerdimensional
space
,
languageas
potential
new
translation
,
dictionary
mining
,
selected
unseen
german
word
,
parliament
data
,
topthree
translation
,
cursory
evaluation
of5
,
german409by
native
speaker
,
author
,
correct
,
mt
systemthe
output
,
dicionary
mining
approach
,
foreign
word
,
en
glish
translation
,
associated
score
,
obvious
,
phrase
based
translation
system
,
parallel
corpus
,
weighting
,
translation
probability
,
dictionary
mining
,
phrase
table
,
baseline
phrase
basedtranslation
model
,
source
domaindata
,
word
pair
,
mining
,
phrase
translation
probability
,
preliminary
experiment
,
ger
man
emea
,
first
approach
,
extensive
hand
tuning
,
thesentence
weight
,
translation
performance
,
second
approach
,
translation
performance
,
average
improvement
,
development
data
,
likely
because
weight
,
single
weight
,
import
,
phrase
,
phrase
,
phrase
,
method
,
dictionary
entry
,
phrase
table
,
fournew
feature
,
plain
phrase
translation
probability
,
dictionary
entry
,
new
feature
,
dictionary
mining
translation
probability
,
original
phrase
pair
,
indicator
feature
,
ger
man
word
,
phrase
pair
,
inthe
source
data
,
true
forsource
phrase
,
dictionary
entry
,
indicator
,
germanwords
,
phrase
pair
,
negation
,
previousfeature
,
plenty
,
thetarget
data
,
featuremight
mean
something
,
conjunction
,
first
feature
wasnot
,
last
threefeatures
,
indicator
feature
,
baseline
,
performance
improve
,
result
,
result
,
combination
,
trigram
language
model
,
gigawordcorpus
,
side
ofthe
target
domain
corpus
,
language
,
weight
tuning
,
withmert
,
result
,
averaged
overthree
run
,
different
random
initialization
,
oraclesour
,
domain
,
experiments
,
translation
model
,
parliament
proceeding
,
small
amount
,
target
domain
tuning
dataand
test
,
corresponding
test
data
,
oracle
,
parallel
target
domain
data
,
traininga
system
,
parliament
data
,
target
domain
data
,
last
line
,
improvement
,
oraclesystem
,
relative
bleu
point
,
absolute
bleu
pointsfor
news
,
medical
text
,
possible
,
dictionary
mining
technique
,
phrase
,
contain
source
language
word
,
baseline
,
oracle
score
,
change
,
baseline
,
type
oforacles
,
language
,
german
frenchbleu
meteor
ble
u
me
,
dictionary
mining
system
result
,
italicizednumber
beneath
,
improvement
,
thebaseline
approach
,
parliament
proceeding
,
high
frequency
oov
term
,
dictionary
mining
system
,
as
good
translation
,
oracle
system
,
referred
toas
or
oov
,
upperbound
,
mining
unseenwords
,
halfway
,
absolute
,
baseline
,
full
oracle
,
vocabulary
differences
,
meteor
,
mining
resultsthe
result
,
dictionary
mining
experiment
,
interms
,
effect
,
translation
performance
,
modest
improvement
,
subtitle
,
markedlylarge
improvement
,
modest
improvement
,
oracle
,
baseline
result
,
data
set
,
language
,
difference
,
absolute
term
,
thebaseline
,
dictionary
miningtechniques
,
unseen
word
,
domain
adaptation
task
,
consistent
result
,
language
,
domains
,
wide
variety
,
translation
systems
,
simple
phrase
based
translation
,
course
,
unseen
word
,
causeof
translation
divergence
,
domain
,
wehave
,
estimation
,
translation
probability
,
word
sense
,
domain
,
domain
adaptation
technique
,
machine
learning
community
,
significant
additional
,
difficultto
spot
foreign
language
word
,
newsenses
,
alternative
area
,
result
,
top
most
frequent
word
,
target
domain
,
banerjee
,
alon
lavie
,
meteor
,
mt
evaluation
,
improvedcorrelation
,
human
judgment
,
proceedings
,
workshop
,
intrinsic
,
extrinsic
evaluationmeasures
,
summarization
,
bertoldi
,
domain
adaptation
,
statistical
machine
translation
withmonolingual
resource
,
fourth
workshop
,
statistical
machine
translation
,
blitzer
,
domain
adaptation
,
tutorial
,
internationalconference
,
machine
learning
,
blitzer
,
civera
,
alfons
,
adaptation
,
statistical
machine
translation
,
secondworkshop
,
statistical
machine
translation
,
aria
haghighi
,
liang
,
berg
kirkpatrick
,
klein
,
bilingual
lexiconsfrom
monolingual
corpus
,
proceeding
,
conference
,
association
,
almut
silja
hildebrand
,
eck
,
vogel
,
waibel
,
adaptation
,
translationmodel
,
statistical
machine
translation
,
information
retrieval
,
association
,
machine
translation
,
hotelling
,
relation
,
variables
,
biometrica
,
literature
survey
,
domainadaptation
,
statistical
classifier
,
available
athttp
,
jiang4
domain_adaptation
survey
,
jonker
,
volgenant
,
shortest
augmenting
path
algorithm
,
sparse
linear
assignment
problem
,
computing
,
philipp
koehn
,
adaptation
,
statistical
machine
translation
,
second
workshopon
statistical
machine
translation
,
philipp
koehn
,
hieu
hoang
,
birch
,
chriscallison
burch
,
bertoldi
,
cowan
,
shen
,
moran
,
richardzens
,
dyer
,
ondrej
bojar
,
stantin
,
herbst
,
open
sourcetoolkit
,
statistical
machine
translation
,
proceedings
,
conference
,
association
,
och
,
minimum
error
rate
training
forstatistical
machine
translation
,
proceeding
,
theconference
,
association
,
kishore
papineni
,
roukos
,
wei
jing
zhu
,
method
,
automatic
evaluation
,
machine
translation
,
proceeding
,
theconference
,
association
,
snover
,
dorr
,
schwartz
,
language
,
translation
model
adaptation
using
comparable
corpus
,
proceeding
,
conference
,
empirical
method
,
annual
meeting
,
association
,
computational
linguistics
,
association
,
computational
linguisticssensespotting
,
parallel
data
tie
,
old
domainmarine
carpuat1
,
henry3
,
irvine4
,
jagadeesh
jagarlamudi5
,
rudinger61
national
research
council
,
marine
,
chicago
,
kehenry
,
hopkins
,
watson
research
,
com6
cls
,
hopkins
,
rudinger
aya
,
eduabstractwords
,
new
sens
,
new
domains
,
corpus
,
monolingual
text
,
word
token
,
previously
unseen
sense
,
application
tomachine
translation
,
lexical
semantics
,
new
sensesin
new
domain
text
,
difficultand
expensive
annotation
,
cheaply
availableparallel
corpus
,
approach
tothe
problem
,
domain
adaptation
,
machine
translation
,
able
toachieve
f
measures
,
large
set
,
novel
feature
,
aspect
,
new
domain
,
ntroductionas
magnini
et
,
domain
ofthe
text
,
word
occurs
,
finance
,
financial
institution
,
geography
,
theclassic
wsd
task
,
setof
possible
sens
,
advance
,
thiswork
,
setting
,
different
domain
,
second
text
,
sense
thatdid
,
first
text
,
lexicalknowledge
,
new
domain
,
nounrapport
,
parliament
domain
,
meanse
,
state
report
,
regimemedical
state
,
report
dietgeo
,
state
ratio
,
regimescience
,
state
ratio
,
regimereport
dietmovies
,
state
report
,
word
,
mostfrequent
sens
,
translation
,
domain
,
report
,
moving
,
scientific
domain
,
wordgains
,
new
sense
,
parliament
domain
,
science
domain
,
report
,
medical
domain
,
report
,
new
task
,
identify
word
,
new
domain
monolingual
text
,
old
domain
text
,
unseen
sense1
,
framework
,
phrase
sense
disambiguation
,
carpuat
,
align
parallel
data
,
old
domainto
generate
,
initial
old
domain
sense
inventory
,
sense
inventory
,
phrasal
translation
,
concrete
,
ofour
key
contribution
,
development
,
richset
,
monolingual
text
,
areindicative
,
new
word
,
application
need
,
new
domain
,
many
error
,
resultof
,
source
languagewords
,
new
sense
,
new
transla
1all
feature
,
raw
result
,
com
hal3
intrinsicpsdevaluation1435tions2
,
carpuat
,
translation
,
dictionary
extraction
technique
,
fung
andyee
,
schafer
,
yarowsky
,
schafer
,
haghighi
,
mausam
,
jagarlamudi
,
active
learning
,
bloodgood
,
callison
burch
,
ow
ever
,
frequent
,
new
translation
,
motivation
,
translation
,
significant
point
,
departure
,
wordtokens
,
thequestion
,
new
sense
,
specific
question
,
occurrence
,
thisknown
word
,
new
sense
,
dictionary
mining
setting
,
theactive
learning
setting
,
considerwords
,
context
,
translation
,
definitionour
task
,
data
component
,
details
,
creation
,
old
domain
sense
dictionary
,
fromfrench
parallel
text
,
parliamentary
proceeding
,
new
domainmonolingual
text
,
medical
text
,
scientific
text
,
challenge
,
thenew
domain
text
,
new
sense
,
old
domain
dictionary
,
access
,
smallamount
,
new
domain
parallel
,
new
domain
dictionary
,
old
domain
dictionary
,
wecan
identify
,
new
sens
,
sespotting
,
supervised
binary
classification
problem
,
anexample
,
a
f
rench
word
,
context
,
newdomain
monolingual
text
,
exist
,
old
domain
dictionary
,
prediction
,
words2sense
shift
,
new
translation
,
ambiguity
,
language
,
window
,
building
,
monitor
,
window
,
experimentsuse
bilingual
data
,
eye
towards
,
mt
performance
,
new
translation
,
applied
perspective
,
assumption
,
small
amount
,
parallel
data
,
thenew
domain
,
mt
system
,
new
domain
,
system
tuning
,
evaluation
,
workwhile
word
sens
,
extensivelyin
lexical
semantics
,
research
,
wordsense
disambiguation
,
disambiguatingwords
,
context
,
edmonds
,
wordsense
induction
,
sense
inventories
,
ncontrast
,
novel
sens
,
asmuch
attention
,
addressed
withinword
sense
induction
,
distinctsensespotting
task
,
novel
sense
detectionhas
,
language
change
,
approach
modelchanges
,
occurrence
pattern
,
word
typeswhen
,
corpus
,
modernlanguage
,
stevenson
,
gulordava
,
baroni
,
type
based
model
,
new
language
,
afew
attempt
,
new
sens
,
token
level
,
sespotting
,
leverage
,
common
framework
,
senseinduction
,
disambiguation
,
topic
models
,
topic
distribution
,
disambiguation
,
topicsto
word
,
mightco
exist
,
old
sens
,
language
,
bam
man
,
use
parallel
latin
englishdata
,
latin
word
,
en
glish
sens
,
new
translation
,
asevidence
,
latin
word
,
incontrast
,
sespotting
task
,
detecting
,
parallel
data
,
novel
sense
induction
method
,
datasets
,
purpose
ofevaluation
,
expensive
process
,
therefore
evaluation
,
verysmall
scale
,
contrast
,
sespotting
taskleverages
,
word
aligned
parallel
corpora
,
source
,
annotation
,
supervision
during
training
,
evaluation
,
impact
,
domain
,
novel
sens
,
attention
,
approach
operate
,
type
level
,
change
,
themost
frequent
sense
,
change
inpredominant
sense
,
domain
sensepriors
,
sense
disambiguation
,
adaptation
,
active
learning
,
much
interest
,
translation
mining
,
comparable
corpus
,
unknown
word
,
easy
toidentify
,
translation
,
new
translation
,
active
learning
,
machine
translationhas
,
translation
,
longerunknown
segment
,
callison
burch
,
interest
,
difficulties
,
many
reason
,
nsespot
ting
focus
,
wordtokens
,
classification
setting
,
instanceconsists
,
a
f
rench
word
,
context
,
context
,
rely
onstatistics
,
entire
new
domaincorpus
,
contrast
,
word
token
,
context
,
particular
instance
,
theword
,
particular
type
withina
single
domain
,
new
sens
,
thehelp
,
word
token
feature
,
single
domain
,
several
sens
,
word
token
feature
,
basic
property
,
new
domain
,
tocapture
,
word
frequency
,
suchchanges
,
domain
shift
,
unigram
log
probability
,
viasmoothed
relative
frequency
,
word
under
consideration
,
old
domain
,
newdomain
,
logprobabilities
,
difference
,
relfreq
feature
,
n
gram
probability
feature
,
thetype
,
ngramprob
feature
,
factthat
,
unusual
context
,
new
sens
,
consideration
,
old
domain
languagemodel
,
new
domain
languagemodel
,
unusual
word
,
context
,
atthe
respective
unigram
log
probability
,
statistic
,
thenew
domain
n
gram
log
probability
,
difference
,
n
gram
probability
,
eachdomain
,
difference
,
unigram
probability
,
new
domain
,
difference
,
thesefour
value
,
following
type
basedstatistics
,
monolingual
text
,
standard
deviation
,
minimum
value
,
maximum
valueand
sum
,
trigram
model
,
topic
model
feature
,
intuition
,
thetopic
model
feature
,
distribution
,
topic
change
,
newdomain
,
new
sense
,
old
domain
,
thefrench
word
enceinte
,
new
domain
,
enceinte
,
inenceinte
,
distribution
,
topic
thatplaces
,
high
probability
,
high
probability
,
new
domain
data
,
theold
domain
,
high
probability
,
intuition
,
allwords
,
old
andnew
distribution
,
cosine
similarity
,
feature
value
,
high
probability
,
that1437is
,
high
probability
,
topic
exists
,
thescore
,
new
sense
,
online
lda
,
blei
etal
,
hoffman
,
implementedin
http
,
domain
,
context
feature
,
new
sens
,
different
argument
,
preposition
,
speech
,
additional
type
level
feature
,
new
domain
n
grams
,
inthe
old
domain
,
total
number
,
new
domainn
grams
containing
,
setof
n
grams
,
new
domain
,
n
grams
,
old
domainwhich
contain
,
then
grams
,
newbut
,
old
domain
,
n
grams
containingoovs
,
instance
,
n
gram
probability
feature
,
type
level
,
ngramprob
,
values
,
token
level
,
new
old
domain
,
entire
monolingual
corpus
,
instantaneous
value
,
tokenunder
consideration
,
unigram
,
trigram
,
log
probability
,
theold
domain
,
new
domain
,
difference
,
context
feature
,
type
level
n
gram
feature
,
particularword
token
,
n
gram
context
,
tokenwi
,
position
,
context
word
,
word
window
,
contextual
word
,
position
,
following
feature
,
ctxcnt
,
numberof
time
word
wp
,
position
relativeto
wi
,
old
domain
data
,
asingle
feature
,
contextual
word
,
old
domain
data
,
token
level
psd
feature
,
capture
,
characteristic
,
context
,
problem
,
problem
overthe
,
sense
inventory
,
source
word
context
,
classifier
,
target
translation
,
ground
truth
label
,
translation
,
source
word
,
thisclassifier
,
phrase
table
ofthe
old
domain
data
,
features
,
carpuat
,
givena
source
word
,
classifier
,
probability
distribution
,
probability
distribution
,
new
feature
,
thesensespotting
task
,
wordis
,
context
,
wehope
,
psd
classifier
,
spiky
distribution
,
unseencontext
resulting
,
psd
classifier
outputtingan
uniform
distribution
,
intuition
,
following
feature
,
maxprob
,
themaximum
probability
,
target
translation
,
entropy
,
difference
,
minimum
probability
,
probability
distribution
,
confusion
,
likely
prediction
,
thesource
token
,
mediantp
,
median
inthe
numerator
,
observation
,
topranked
translation
,
differin
morphology
,
psd
classifier
,
single
global
classifier
,
thetarget
translation
,
source
word
,
global
psd
classifier
,
lexical
feature
,
sourceword
,
real
valuedand
,
thepsd
classifier
,
additional
feature
,
theword
context
,
scontext
,
probability
distribution
output
,
pprior
,
respec
1438domain
sentence
lang
token
typeshansard
,
basic
characteristic
,
parallel
data
,
following
set
,
features
,
samemaxchecks
,
posterior
distributions
,
translation
,
mostlikely
translation
,
samemin
,
theabove
feature
,
likely
translation
,
x
o
r
mi
nmax
,
exclusive
or
,
samemax
,
kl
divergence
,
distributions
,
kl
divergence
,
pprior
,
maxnorm
,
maximum
probabilitiesin
,
posterior
distribution
,
spreadnormis
,
spread
,
posterior
distributions
,
difference
betweenmaximum
,
minimum
probability
,
distribution
,
confusionnorm
,
theratio
,
confusion
,
posterior
distributions
,
confusion
,
gold
standardthe
first
component
,
parallel
corpus
,
old
domain
data
,
thefrench
hansard
parliamentary
proceedings
,
old
domain
sense
dictionary
,
themoses
mt
framework
,
old
domain
sense
dictionary
,
newdomains
,
source
,
eme
amedical
corpus
,
tiedemann
,
corpus
ofscientific
,
corpus
,
translatedmovie
subtitle
,
tiedemann
,
parallel
corpus
,
american
spelling
,
gold
standard
truth
,
lexical
sample
apparoach
,
multiplesenses
,
single
domain
,
sensesare
,
new
domain
,
useda
semiautomatic
approach
,
phrase
table
fromparallel
repr
,
science
,
statistic
,
representative
word
,
development
set
,
columnsshow
,
total
amount
,
parallel
developmentdata
,
corpus
,
ofthese
token
,
new
sens
,
output
,
phrase
,
tf
idf
score
,
okapi
bm25
weighting
,
science
,
intersection
,
new
domain
,
wethen
,
different
translation
,
phrase
table
,
a
f
rench
speaker
,
subset
,
multiple
sens
,
practice
,
set
alost
entirelyto
source
word
,
single
multi
word
phrase
,
vue
de
enfants
,
old
domain
,
inthe
eme
domain
,
wehave
,
s
espotting
task
,
representative
word
,
representativephrases
,
source
language
word
,
simplicity
,
good
candidate
word
,
addition
,
wealso
,
translation
withthe
,
lexical
weight
,
different
domains
,
intuition
,
new
sense
,
representative
word
,
statistic
,
thesewords
,
test
domain
,
evaluation
,
distribution3in
order
,
evaluation
data
,
full
parallel
text
,
side
,
theparallel
data
,
representative
word
,
micro
averaged
precision
,
macro
averaged
precision
,
f
measure
,
single
confusion
matrix
,
test
data
,
matrix
,
separate
confusion
matrix
,
side
,
micro
f
,
afunction
,
andmacro
averaged
score
,
wellthe
system
,
type
level
basis
,
type
frequency
,
themicro
averaged
score
,
wellthe
system
,
frequency
,
result
,
standarddeviations
,
results
,
new
domain
training
data
,
result
,
fold
cross
validation
,
application
goal
,
fold
forconvenience
,
binary
fold
,
power
of
twois
easier
,
attempt
,
thesize
,
training
set
,
trickybecause
,
skewed
nature
,
entire
fold
cross
validation
procedure
,
repeated10
time
,
average
,
standard
deviation
,
replicates
,
type
levelfeatures
,
peonly
,
token
level
features
,
typeand
,
token
level
feature
,
result
,
baseline
,
not
new
sense
randomly
,
predictsnew
sense
,
recall
,
macro
level
precision
,
representative
word
,
new
sense
,
modulo
cross
validation
split
,
singleton
word
,
probability
,
classifier
,
positive
,
negative
,
wikipedia
,
result
,
oracle
,
majority
label
,
result
correspond
,
upper
bound
,
thetypeonly
experiment
,
stochastic
gradient
,
optimizelogistic
loss
,
initial
experiments
,
development
data
,
decision
tree
,
loss
function
,
hingeloss
,
aswell
,
pass
overthe
training
data
,
development
data
,
early
stopping
,
development
data
,
aregularizer
,
consecutive
bucket
,
number
ofelements
,
learner
,
small
amount
ofdevelopment
data
,
threshold
,
using
macro
f
measure
,
objective
,
result
,
sespot
tin
task
,
classifier
,
featuresthat
,
baseline
,
allmacro
level
evaluation
,
sespotting
task
,
evaluation
,
all
feature
model
,
science
,
token
level
features
,
scienceand
subtitle
data
,
reasonable
precision
,
science
,
recall
,
many
new
sensewords
,
token
levelfeatures
,
intuition
,
infrequent
context
,
new
sense
,
result
,
intuition
,
eme
athan
,
science
,
contrast
,
type
only
feature
,
peonly
,
use
http
,
vw
version
,
following
argument
,
exact
adaptive
power
,
microauc
p
r
f
p
r
f
emearandom
,
complete
,
result
,
domain
,
cross
validation
ona
single
domain
,
standard
deviation
,
cross
validation
,
domain
,
metric
,
non
oracle
result
,
new
sens
,
mea
data
,
baseline
,
f
measure
performance
,
baseline
,
experience
,
threedatasets
,
science
data
,
whichcontains
,
wide
variety
,
scientificdisciplines
,
thesubs
data
,
drug
label
,
type
level
featureswould
,
homogeneous
dataset
,
representative
word
,
scientific
text
,
variety
,
context
,
eme
data
,
thedistributions
,
old
domain
data
,
domain
,
microlevel
evaluation
,
ourmodels
,
stant
baseline
,
microlevel
evaluation
computes
precision
,
recall
,
f
measure
,
wordtokens
,
frequent
,
new
domainsare
,
new
sense
,
frequent
word
,
stant
baseline
,
contrast
,
good
predictions
,
frequent
word
,
low
frequencyin
,
new
domain
,
type
level
feature
,
instance
,
low
frequency
,
token
level
feature
,
contrast
,
old
domain
instance
,
previous
,
oneexception
,
type
level
,
token
level
features
,
finer
grained
feature
distinction
,
process
,
feature
ablation
,
setting
,
performanceleast
,
whichfeature
,
point
auc
,
scoresfrom
table
,
result
,
eme
aand
science
,
context
,
optimal
auc
score
,
macro
f
score
,
features
,
choice
of1441emea
auc
macfallfeatures
,
relfreq
,
context
,
topicsim
,
ctxcnt
,
ngramprob
,
ngramprob
,
ctxcnt
,
context
,
topicsim
,
ngramprob
,
relfreq
,
ngramprob
,
ngramprob
,
ctxcnt
,
topicsim
,
ngramprob
,
relfreq
,
context
,
feature
ablation
result
,
corpus
,
selection
criterion
,
macro
f
,
presentedfor
completeness
,
feature
selection
,
datasets
,
featurestoward
,
bottom
,
cross
domain
test
result
,
s
espotting
task
,
standard
deviation
,
macro
f
andmicro
f
,
measure
,
quiteclear
,
science
,
useful
informationis
,
type
level
feature
,
result
,
previous
,
foremea
,
token
level
features
,
significant
role
,
sixmost
useful
feature
,
domain
,
globalpsd
feature
,
ngram
probability
feature
,
relative
frequencyfeatures
,
context
feature
,
previous
method
,
sespotting
task
,
new
domain
,
suppose
,
new
domain
,
sespotting
task
,
option
isto
,
domain
,
new
domain
,
setting
,
cross
validationin
,
single
domain
,
instance
,
science
,
training
data
,
otherdomains
,
classifier
,
science
,
classifier
,
science
,
parallel
data
,
development
data
,
old
union
,
result
,
result
,
all
feature
,
cross
domain
setting
,
comparison
,
result
,
domain
shift
,
result
,
whichparallel
data
,
absolute
,
small
improvement
,
science
,
likely
becausescience
,
moredifficult
,
frequent
sense
changeswe
,
word
token
,
respect
,
old
domain
,
sense
whichis
,
old
domain
,
science
,
wordtokens
,
predominant
sense
change
,
data
typeoraclerandomallfeaturesfigure
,
learning
curve
,
domain
,
x
axis
,
macro
f
score
,
log
scale
,
fast
rate
,
growth
,
horizontal
bar
corresponding
,
randompredictions
,
typ
eoracle
result
,
comparison
,
cross
validation
result
,
mos
t
freqsensechange
task
,
standard
deviations
,
learning
framework
,
modelsfor
,
sespotting
taskhas
mt
utility
,
new
domainwords
,
new
translation
,
mos
tfre
qse
nsechange
task
,
utility
,
suggestingwhich
word
,
new
translation
probability
distribution
,
new
domain
,
result
,
mos
tfre
qse
nsechange
task
experiment
,
result
,
mos
tfreqsensechange
task
,
s
espotting
task
,
better
,
macro
level
evaluation
,
amicro
level
evaluation
,
contrast
tothe
sespotting
result
,
token
level
featuresperform
,
domain
,
token
level
feature
,
abetter
,
success
,
important
comparison
,
new
domain
,
context
,
majority
,
old
domaintokens
,
comparisonis
,
betweenthe
current
token
,
old
domain
sens
,
likethe
sespotting
result
,
microlevel
evaluation
,
stant
baseline
,
sparsity
,
curvesall
,
result
,
use
classifiers
,
instance
,
representative
token
,
fairlylarge
new
domain
parallel
corpus
,
thousand
parallelsentences
,
thousandrepresentative
token
,
somenew
domain
,
mt
setting
,
sespotting
task
,
figure
,
representative
token
,
classifier
,
about25
,
acknowledgment
,
supportof
,
jhu
summer
workshop
program
,
funders
,
dam
team
,
support
,
marine
carpuat
,
dar
pa
css
g
gr
ant
d11ap00279
,
jagadeesh
jagarlamudi
,
agirre
,
edmonds
,
word
sense
disambiguation
,
algorithm
,
application
,
speech
,
language
technology
series
,
eneko
agirre
,
aitor
soroa
,
discrimination
system
,
proceeding
,
fourthinternational
workshop
,
semantic
evaluation
,
semeval
,
crane
,
measuringhistorical
word
sense
variation
,
proceeding
ofthe
,
joint
international
conference
,
latent
dirichletallocation
,
journal
,
bloodgood
,
callison
burch
,
large
scale
cost
focused
activelearning
,
statistical
machine
translation
,
proceedings
,
annual
meeting
,
association
,
computational
linguistics
,
uppsala
,
association
,
computational
linguistics
,
marine
carpuat
,
improvingstatistical
machine
translation
,
word
sensedisambiguation
,
proceeding
,
jointconference
,
empirical
method
,
natural
language
processing
,
prague
,
marine
carpuat
,
quirk
,
fabienne
braune
,
annirvine
,
jagadeesh
jagarlamudi
,
ma
jid
razmara
,
tamchyna
,
rudinger
,
adaptation
,
machine
translation
,
final
report
,
hop
kins
summer
workshop
final
report
,
yee
seng
,
domainadaptation
,
active
learning
,
word
sense
disambiguation
,
proceeding
,
association
forcomputational
linguistics
,
stevenson
,
identifying
change
,
semantic
orientationof
word
,
proceeding
,
internationalconference
,
language
resource
,
evaluation
,
valletta
,
jagadeesh
jagarlamudi
,
domain
adaptation
,
machine
translation
,
mining
unseen
word
,
proceeding
,
conference
,
association
,
katrin
erk
,
word
sense
detection
,
detection
,
proceeding
,
main
conference
,
human
language
technology
conferenceof
,
north
american
chapter
,
association
ofc
omputational
linguistics
,
fung
,
lo
yuen
yee
,
ir
approachfor
,
new
word
,
comparable
text
,
proceeding
,
conference
,
theassociation
,
gulordava
,
baroni
,
distributional
similarity
approach
,
detection
,
semantic
change
,
google
book
ngram
corpus
,
inp
roceedings
,
workshop
,
geometrical
model
,
natural
language
semantics
,
association
forcomputational
linguistics
,
aria
haghighi
,
liang
,
berg
kirkpatrick
,
klein
,
bilingual
lexicons
,
monolingual
corpus
,
proceeding
ofthe
conference
,
association
,
hoffman
,
blei
,
bach
,
online
,
latent
dirichlet
alocation
,
advance
,
philipp
koehn
,
hieu
hoang
,
birch
,
chriscallison
burch
,
bertoldi
,
cowan
,
shen
,
moran
,
zen
,
dyer
,
ondrej
bojar
,
alexandraconstantin
,
herbst
,
opensource
toolkit
,
statistical
machine
translation
,
inp
roceedings
,
conference
,
jey
lau
,
mcc
arthy
,
new
man
,
lexical
computing
,
word
sense
induction
,
novel
sense
detection
,
proceeding
,
conference
ofthe
chapter
,
association
,
citeseer
,
magnini
,
strapparava
,
pez
zulo
,
alfio
gliozzo
,
domaininformation
,
word
sense
disambiguation
,
mausam
,
soderland
,
etzioni
,
kobi
reiter
,
skinner
,
mer
,
bilmes
,
panlingual
lexicaltranslation
,
probabilistic
inference
,
artificial
intelligence
,
mcc
arthy
,
koeling
,
weed
,
johncarroll
,
predominant
word
,
proceeding
,
annualmeeting
,
association
,
computational
linguistics
,
association
,
computational
linguistics
,
mcc
arthy
,
koeling
,
weed
,
johncarroll
,
unsupervised
acquisition
,
predominant
word
sens
,
computational
linguistics
,
hwa
,
localization
,
difficult
to
translate
phrase
,
proceedingsof
,
acl
workshop
,
statistical
machinetranslations
,
rapp
,
word
translationsin
nonparallel
text
,
proceeding
,
conference
,
association
,
eyal
sagi
,
kaufmann
,
semantic
density
analysis
,
comparing
word
meaning
,
phonetic
space
,
proceedingsof
,
workshop
,
natural
language
semantics
,
athens
,
schafer
,
yarowsky
,
inducingtranslation
lexicon
,
diverse
similarity
measuresand
bridge
language
,
proceeding
,
conference
,
schafer
,
translation
discovery
usingdiverse
similarity
measure
,
thesis
,
opus
a
collection
,
multilingual
parallel
corpus
,
tool
andinterfaces
,
mitkov
,
editor
,
wikipedia
,
operating
characteristic
,
org
wiki
receiver_operating_characteristic
area_under_the_curve
,
naa
cl
hlt
,
sixth
,
corpus
workshop
,
los
angeles
,
association
,
computational
linguisticssketching
technique
,
large
scale
nlp
amit
goyal
,
jagadeesh
jagarlamudi
,
suresh
venkatasubramanianuniversity
,
school
,
computing
amitg
,
large
amount
,
text
data
,
thecontext
,
technique
,
count
sketch
,
frequency
,
word
pair
,
corpus
without
,
themselves
,
conservativeupdate
,
count
sketch
,
average
relative
error
,
approximate
count
,
factor
,
wordsand
word
,
data
,
counter
,
counters
,
streamsize
,
big
memory
,
space
gain
,
semantic
orientation
experiment
,
thepmi
score
,
counters
,
exact
pmi
score
,
ntroductionapproaches
,
nlp
problem
,
turney
,
ravichandran
,
always
,
large
amount
,
turney
,
littman
,
wardhan
,
riloff
,
researcher
,
evidence
,
searchengines
,
problem
,
commercial
search
engine
,
automaticrequests
,
daily
basis
,
various
reason
,
computational
overhead
,
current
approach
,
data
structures
,
reside
,
main
memory
,
huge
corpus
,
seriousness
ofthe
situation
,
unique
words
word
,
total
number
,
unique
item
item
word
,
wordsfigure
,
token
type
curvea
corpus
,
inlog
log
scale
,
word
corpus
generates
,
unique
word
,
millionunique
word
pair
,
rapid
increasein
number
,
unique
word
pair
,
increase
,
compute
count
,
conventional
main
memory
,
unique
word
pairsin
,
corpus
,
disk
space
,
thisspace
,
wordpair
,
trade
off
,
small
amount
,
frequency
,
eachword
pair
,
sketch
techniques
,
count
sketch
,
frequency
,
word
pair
,
thecorpus
,
technique
,
new
word
pair
,
frequency
,
word
pair
,
frequency
,
word
pair
,
arevery
efficient
,
constant
time1
,
cm
sketch
,
tocompute
various
word
association
measure
,
log
likelihood
ratio
,
association
score
,
nlp
application
,
word
sensedisambiguation
,
speech
,
character
recognition
,
semantic
orientation
,
inour
,
semantic
orientationof
,
canonical
task
,
effectiveness
,
cm
sketch
,
association
score
,
attempt
,
count
minsketch
,
frequency
,
nlp
application
,
extrinsic
evaluation
,
intrinsicevaluation
,
low
frequent
itemsare
,
approximate
pmi
score
,
thesecounts
,
ranking
,
exact
pmi
,
counter
,
streamto
,
approximate
pmi
score
,
extrinsic
evaluation
,
semantic
orientation
,
counter
,
stream
,
exact
pmi
,
counter
,
thesame
accuracy
,
exact
pmi
score
,
counter
,
thestream
size
,
big
memory
,
large
data
,
nlp
community
,
corpus
,
usedby
agirre
,
pairwise
similarities
,
infrastructure
,
pan
tel
et
,
similarity
,
mapreduce
framework
,
quad
corenodes
,
inaccessibility
,
cluster
,
onehas
,
nlp
community
,
large
amount
,
randomized
data
structure
,
bloom
filter
,
space
efficient
languagemodels
,
algorithm
paradigm
,
toprovide
memory
,
space
efficient
platform
todeal
,
terabyte
,
language
,
asa
problem
,
frequent
item
,
streamof
data
,
effectiveness
,
proposeda
,
language
model
,
unbounded
text
stream
,
durme
andlall
,
author
,
counter
,
ranked
k
p
mi
responsewords
,
cue
word
,
issimilar
,
word
pair
,
compute
pmi
score
,
cm
sketch
,
verysimple
algorithm
,
strong
guarantee
,
goodproperties
,
summary
data
structure
,
usedto
store
,
memory
efficient
manner
,
technique
,
direction
,
backwards
,
main
advantage
,
techniquesis
,
storage
,
input
stream
length
,
typicalalgorithms
,
working
storage
,
inputsize
,
algorithm
,
artifact
,
sketch
,
method
,
small
space
sketch
vector
,
sketchvector
,
constant
time
,
operation
,
algorithm
,
popularity
,
late90s
,
researcher
,
challenge
,
massive
data
set
,
good
surveyof
,
core
challenge
,
considerable
,
different
sketchtechniques
,
charikar
,
cormode
andmuthukrishnan
,
church
,
cormode
andhadjieleftheriou
,
reviewsthe
literature
,
ount
sketchthe
count
sketch
,
cormode
,
muthukr
ishnan
,
compact
summary
data
,
frequency
,
input
stream
,
sketch
,
data
stream
,
inner
product
query
,
frequent
item
problem
,
mot
wani
,
data
stream
,
point
query
,
pointquery
,
input
stream
,
detail
,
reader
,
cormode
,
muthukrishnan
,
input
stream
,
word
pair
,
length
nand
user
chosen
parameter
,
algorithmstores
,
frequency
,
guarantee
,
frequency
,
truefrequencies
,
probabilityof
,
algorithm
iso
,
constant
time
,
updateand
query
operation
,
two
dimensional
array
,
sketch
,
sketch
,
user
chosen
parameter
,
control
theamount
,
tolerable
error
,
returned
count
,
probability
,
returnedcount
,
accepted
error
,
values
,
thetwo
dimensional
array
,
guarantee
,
previous
,
denotesthe
number
,
pairwise
independent
hash
functions
,
algorithm
,
existsan
one
to
one
correspondence
,
rowsand
,
hash
function
,
hashfunctions
,
input
stream
,
counter
,
corresponding
hashfunction
,
thatthe
word
pair
,10
th
position
inthe
second
,
sketch
array
,
hashfunctions
,
random
,
apairwise
independent
family
,
figure
,
update
procedure
,
cm
sketch
,
entire
sketch
array
,
initializedwith
zero
,
update
procedure
,
arrives
,
word
pair
,
count2
,
counter
,
corresponding
hash
function
,
process
,
arrives
,
position
,
hash
function
,
theircounts
,
usinga
hash
,
collision
canoccur
,
multiple
word
pair
,
tothe
counter
,
ofthis
,
counter
,
givenword
pair
,
query
procedure
,
frequency
,
inputstream
,
multiple
word
pair
,
mappedinto
counter
,
observation
,
thecounts
,
frequency
,
counter
,
overestimate
,
truecount
,
point
query
,
position
,
hash
functions
,
word
pair
,
minimum
,
answer
,
positive
count
,
negative
count
,
algorithm
,
wordpair
,
minimum
,
word
pair
,
setting
,
nlp
problem
,
word
pair
,
query
procedure
,
evaluating
hash
function
,
linear
scan
,
thevalues
,
procedures
,
hash
function
,
asmall
number
,
hash
function
,
sufficient
andwe
use
,
update
,
query
operations
,
constant
time
,
algorithm
,
wdcounters
,
advantage
,
space
efficient
,
constant
update
,
constant
queryingtime
,
count
sketch
,
advantages
,
attractive
choice
,
nlp
application
,
inearity
,
sketch
,
parameter
,
different
input
stream
,
sketch
ofthe
,
data
stream
,
individual
sketch
ino
,
linearity
,
individual
sketch
,
distributed
setting
,
machine
,
sketch
,
sub
set
,
technique
,
deletion
,
pointquery
,
median
,
thevalues
,
minimum
value
,
varghese
,
conservative
update
,
varghese
,
thecontext
,
networking
,
usedwith
cm
sketch
,
estimateof
,
point
query
,
word
pair
,
wwith
frequency
,
frequencyc
,
data
structure
andthe
count
,
intuition
,
point
query
returnsthe
minimum
,
indicated
bythe
,
equation
,
unnecessary
update
,
counter
valuesand
,
process
,
frequency
,
stream
,
sketch
data
structure
,
frequency
,
itemis
,
minimum
,
thisparticular
,
update
rule
,
increasethe
counter
value
,
updated
value
,
lessthan
,
result
,
thesecounters
,
update
become
,
countersis
,
position
,
first
counterwe
,
query
procedure
,
previous
,
theconservative
update
reduces
,
afactor
,
update
prevents
deletion
,
negative
update
,
effectiveness
,
count
,
context
,
intrinsic
evaluations
,
intrinsic
evaluation
,
approximate
count
,
true
count
,
total
size
,
data
structure
,
thedepth
,
data
structure
,
settingof
,
parameter
,
textual
data
set
,
quality
,
cm
sketch
,
ravichandran
,
usedto
compute
count
,
word
pair
,
forboth
,
corpus
,
tokenize
,
generatewords
,
word
pair
,
sliding
window
,
previous
,
durme3here
,
set
word
websize
,
million
,
stream
size
,
billion
,
stream
size
,
billion
,
corpus
descriptionand
lall
,
exact
frequencies
,
frequency
,
thewords
,
word
pair
,
cm
sketch4
,
stream
size
,
total
number
ofwords
,
word
pair
,
corpus
,
givesthe
characteristic
,
corpus
,
exact
frequencies
,
conventional
mainmemory
,
large
corpus
,
subset
,
giga
word
corpus
,
intrinsic
evaluation
,
word
pair
,
window
,
subset
,
sketch
,
exact
count
,
depthto
,
amount
,
overestimation
,
cmand
cu
,
true
count
,
wefirst
group
,
word
pair
,
true
frequency
,
single
bucket
,
average
relative
error
,
thesebuckets
,
low
frequent
item
,
proneto
error
,
distinction
,
frequency
let
,
region
,
thealgorithm
,
average
,
absolute
difference
,
exact
value
,
predicted
,
exactand
cm
cu
,
thenumber
,
bucket
,
memory
,
minor
point
,
counter
,
total
number
,
different
value
,
sketch
array
,
widthis
set
,
main
observations
,
low
frequency
item
,
frequent
item
,
factor
,
encouragingobservation
,
alldifferent
,
setting
,
experiments
,
setting
,
behavior
,
different
setting
,
setting
,
number
ofcounters
,
followa
pattern
,
previous
setting
,
low
frequency
item
,
frequent
one
,
conservative
update
reduces
,
factor
,
setting
,
sameand
,
restof
,
parameter
,
effect
,
counters
,
sketch
,
two
dimensionalsketch
array
,
number
ofcounters
,
length
,
thesketch
increase
,
probability
,
collision
decreases
,
true
count
,
counter
,
length
,
stream230
,
almost
,
therare
ones5
,
actual
space
requiredto
,
exact
count
,
memory
,
word
pair
,
character
,
requireseight
byte
,
figure
,
low
frequent
item
,
counter
,
stream
,
datasets
,
counterslinear
,
stream
,
true
frequency
count
,
word
word
,
pairsaverage
relative
error
,
true
frequency
count
,
word
word
,
pairsaverage
relative
error
,
countersfigure
,
comparing
,
counter
model
,
setting
,
notation
cmx
,
count
sketch
,
cm
sketch
,
conservative
update
,
true
frequency
count
,
word
word
,
pairsaverage
relative
error
20m
,
comparing
different
size
model
,
cu
pmi
rankingin
,
association
ranking
,
cuand
exact
count
,
measure
,
spearman
,
correlation
,
overlap
,
ranking
,
hurchand
,
word
w1
,
likelihood
,
w2occur
,
independent
likelihood
,
probability
,
degree
ofstatistical
dependence
,
metricsaccuracy
,
fraction
,
word
pair
thatare
,
ranking
,
top
rankedword
pair
,
cusketch
,
ep
wps
,
top
rankedword
,
exact
count
,
spearman
,
correlation
,
word
pair
,
variable
,
top
n
c
u
pmi
,
exact
pmi
value
,
measure
,
cu
pmiranking
,
difference
,
word
pair
,
ranking
,
numberof
item
,
number
ofword
,
thenspearman
,
correlation
capture
,
relative
order
,
common
item
,
therankings
,
experimental
setup
,
thesemeasures
,
andmeasure
different
aspect
,
ranking
,
acorrelation
,
cu
pmi
rankingthe
result
,
respect
,
counter
linear22counters
,
pmi
ranking
,
cms
ketch
,
stream
,
result
,
counter
,
cu
count
,
exact
count
,
word
pair
,
ranking
,
bothcu
,
exact
count
,
phenomena
,
counter
,
top
value
,
ranking
,
counter
,
number
ofcounters
,
performance
degrades
,
low
frequencycounts
,
church
,
pmi
value
,
rare
wordpairs
,
counter
,
streamto
get
,
perfect
ranking
,
counters
,
length
,
stream
,
nlp
problem
,
low
frequency
item
,
linear
,
counters
,
extrinsic
evaluation
,
length
,
thestream
,
effectiveness
,
cu
pmi
wordassociation
score
,
cu
pmi
,
exact
pmiscores
,
littman
,
positiveor
negative
sense
,
similar
framework
,
authors6
,
positive
word
,
negative
word
,
compute
,
ourmain
focus
,
cu
pmi
score
,
turney
,
littman
,
strength
,
association
,
theseven
positive
word
,
strength
,
association
,
negative
word
,
nwordslog
hit
,
pwords
,
nwords
,
negative
prototype
word
,
corpora
,
general
inquirerlexicon7
,
benchmark
toevaluate
,
littman
,
word
withmultiple
sens
,
multiple
entry
,
test
set
,
evaluationmetric
,
fraction
,
identified
word
,
different
sizedcorpora
,
gigaword
,
gi
gaword
,
exact
count
,
wordpairs
,
corpus
,
mainmemory
,
whichone
word
,
prototype
list
,
theother
word
,
test
set
,
exact
pmi
,
test
set
word
w1
,
prototype
word
,
datasets
,
compute
pmi
,
individual
word
w1
,
window
,
datasets
,
pmi
score
,
so
pmi
equation
fromsection
,
general
inquirer
lexicon
,
available
athttp
,
counter
mem
,
usage
gw
gw
wb1
gw
wb2
gw
gw
wb1
gw
wb2exact
,
evaluating
semantic
orientation
,
counter
,
cu
sketch
,
amount
,
dataon
window
size
,
result
,
correct
forum
word
,
exact
pmi
,
second
,
amount
,
window
size
,
data
,
addition
,
gigaword
aswe
,
increase
,
webdata
,
slight
increase
,
accu
racy8
,
window
,
givesbetter
accuracy
,
window
,
cu
sketch
,
counters
,
cu
pmi
,
sketch
,
word
word
pair
,
test
set
,
prototype
word
,
awindow
size
,
whole
dataset
,
result
,
withcu
pmi
score
,
addingmore
data
,
significant
increase
inaccuracy
,
data
,
gigawordover
,
window
size
,
increase
,
data
,
counter
,
cu
pmi
,
however
,
result
,
counter
,
result
,
results
,
data
setsand
,
window
size
,
increase
inaccuracy
,
expense
,
memory
usage
,
large
asmost
,
conventional
desktop
machine
,
much
,
counter
,
length
,
stream
,
datasets
,
streamsize
,
counter
,
thestream
length
,
result
,
result
,
tur
ney
,
littman
,
advantage
,
sketch
,
word
pair
,
supposewe
,
new
word
,
positive
ornegative
,
whole
corpus
,
compute
count
,
negative
prototype
word
,
procedure
,
whole
corpus
,
corpus
,
second
option
,
wordpairs
,
number
increases
,
increase
,
therefore
,
a
c
sketch
,
constant
timeby
,
memory
,
thissketch
,
nlp
applications
,
word
association
score
,
onclusionwe
,
cm
sketch
,
frequency
,
corpus
,
wordpairs
,
conservative
update
,
cm
sketch
,
average
relative
error
,
approximate
count
bya
factor
,
datain
,
counter
,
cu
sketchis
,
exact
pmi
score
,
word
association
score
,
cu
sketch
,
nlp
task
,
word
sense
disambiguation
,
speech
,
character
recognition
,
thecounts
,
cu
sketch
,
small
space
randomized
language
model
,
sketch
,
application
,
acknowledgmentswe
,
anonymous
reviewer
,
helpfulcomments
,
nsf
,
google
research
grantgrant
,
alfonseca
,
janakravalova
,
aitor
soroa
,
similarity
,
relatedness
,
wordnet
based
approach
,
human
language
technologies
,
annual
conference
,
northamerican
chapter
,
association
,
computational
linguistics
,
large
languagemodels
,
machine
translation
,
proceeding
ofthe
,
joint
conference
,
empirical
methodsin
natural
language
processing
,
charikar
,
farach
colton
,
frequent
item
,
datastreams
,
church
,
word
associationnorms
,
mutual
information
,
lexicography
,
inp
roceedings
,27
th
annual
meeting
,
association
,
computational
linguistics
,
vancouver
,
cormode
,
marios
hadjieleftheriou
,
frequent
item
,
data
stream
,
muthukrishnan
,
count
minsketch
,
application
,
algorithm
,
cristian
estan
,
varghese
,
new
directions
,
traffic
measurement
,
commun
,
amit
goyal
,
suresh
venkatasub
ramanian
,
large
scale
nlp
,
language
modeling
,
north
american
chapter
,
association
,
gigaword
,
linguistic
dataconsortium
,
levenberg
,
mile
,
stream
based
randomised
language
model
,
inp
roceedings
,
conference
,
empiricalmethods
,
natural
language
processing
,
pages756
,
association
,
computational
linguistics
,
church
,
sketch
algorithm
,
multi
associations
,
comput
,
linguist
,
motwani
,
approximatefrequency
,
data
stream
,
proceedingsof
,
international
conference
,
largedata
base
,
muthukrishnan
,
data
stream
,
algorithmsand
application
,
foundation
,
pantel
,
crestan
,
arkady
borkovsky
,
popescu
,
vishnu
vyas
,
scale
distributional
similarity
,
entity
,
expansion
,
proceeding
,
conference
one
mpirical
method
,
natural
language
processing
,
associationfor
computational
linguistics
,
patwardhan
,
riloff
,
domain
specific
information
extraction
pattern
,
theweb
,
proceeding
,
workshop
oni
nformation
extraction
beyond
,
deepak
ravichandran
,
pantel
,
eduardhovy
,
algorithm
,
usinglocality
sensitive
hash
function
,
high
speed
,
annual
meeting
,
association
,
computational
linguistics
,
florin
rusu
,
alin
dobra
,
statistical
analysisof
sketch
estimator
,
dunphy
,
ogilvie
,
general
inquirer
,
a
computer
approach
,
mile
,
smoothedbloom
filter
language
model
,
scale
lm
onthe
cheap
,
proceeding
,
joint
conference
,
empirical
method
,
natural
languageprocessing
,
turney
,
littman
,
learning
,
hundred
billion
word
corpus
,
turney
,
uniform
approach
,
analogies
,
synonym
,
antonym
,
association
,
proceedings
,
col
ing
,
durme
,
ashwin
lall
,
probabilistic
counting
,
randomized
storage
,
international
jontconference
,
artifical
intelligence
,
durme
,
ashwin
lall
,
pointwise
mutual
information
,
advances
,
workshop
,
geometrical
model
,
uppsala
,
association
,
computational
linguisticssketch
technique
,
scaling
distributional
similarity
,
webamit
goyal
,
jagadeesh
jagarlamudi
,
suresh
venkatasubramanianschool
,
computinguniversity
,
memory
,
time
efficient
framework
,
distributional
similarity
,
weexploit
sketch
technique
,
thecount
sketch
,
frequency
,
corpuswithout
,
method
,
withmassive
amount
,
item
count
,
data
,
cm
sketch
,
method
return
semantic
similaritybetween
word
pair
,
time
andcan
compute
similarity
,
wordpairs
,
sketch
,
ourexperiments
,
frameworkis
,
exact
count
,
many
nlp
problem
,
researcher
,
turney
,
largeamounts
,
agirre
,
pantel
,
ravichandran
,
large
amountsof
data
,
semantic
similarity
between
pair
,
distributional
similarity
,
large
text
collection
,
expensive
task
,
distributional
similarity
method
,
semantic
similarity
,
scale
,
difficulty
,
pairwise
similarities
,
rapid
increase
,
unique
word
context
pair
,
size
oftext
corpus
,
unique
item
word
,
context
pairswordsfigure
,
token
type
curvethe
number
,
unique
word
context
pair
,
number
word
,
tokens1
,
word
corpus2
,
thousandunique
word
,
unique
word
contextpairs
,
result
,
hard
tocompute
count
,
word
context
pair
,
giant
corpus
,
conventional
machine
,
memory
,
agirreet
,
mapreduce
infrastructure
,
pairwise
similarity
,
corpus
,
different
direction
,
technique
,
thecomputations
,
conventional
machinesby
,
sketch
,
cormode
,
muthukr
ishnan
,
frequency
ofword
,
corpus
,
column
,151
counts
,
word
word
pair
,
fixed
amount
,
memory
,
conservative
update
withcm
sketch
,
cu
sketch
,
average
relative
error
,
approximate
count
,
factor
,
approximate
count
,
cu
sketch
,
usedto
compute
approximate
pmi
,
word
pair
,
approximate
pmi
valuesare
,
exact
pmi
value
,
computing
semantic
orientation
,
turney
,
littman
,
addition
,
intrinsic
evaluations
,
showed
,
quality
,
approximate
count
,
approximate
pmi
,
countsof
item
,
context
,
word
context
pair
,
fixed
amount
,
memory
,
counter
,
approximate
count
,
cu
sketch
,
approximate
pmi
,
word
context
pair
,
topk
context
,
pmi
score
,
wordare
,
foreach
word
,
similarity
,
wordsis
,
cosine
similarity
,
theirrespective
dp
,
framework
,
cu
sketch
tocompute
semantic
similarity
,
word
hasfive
good
property
,
framework
,
semantic
similarity
,
word
pairsthat
,
cu
sketch
,
second
,
similarity
,
word
pair
,
overall
space
,
fourth
,
additive
property
,
cusketch
,
algorithm
,
large
amount
,
text
data
,
associationmeasure
,
distributional
hypothesis
,
thatwords
,
similar
context
,
context
,
thestrength
,
association
,
dependency
unit
,
occur
,
association3in
,
lexical
unit
,
context
,
conditional
probability
,
loglikelihood
ratio
,
semantic
similarity
,
similarity
measure
,
cosine
,
skewdivergence
,
jensen
divergence
,
inour
,
association
measure
,
similarity
,
pairwise
similarity
,
similarity
,
word
pair
,
mapreduceframework
,
word
corpus
,
inaccessibility
,
clusters
,
nlp
community
touse
streaming
,
algorithm
,
handle
large
amount
,
ravichandran
,
locality
sensitive
hash
function
,
word
pair
similarities
,
large
text
collection
,
approachstores
,
enormous
matrix
,
unique
word
,
context
,
main
memory
,
ithard
,
data
set
,
unique
word
context
pair
,
cu
sketch
,
apre
defined
size4
,
algorithm
paradigm
hasbeen
,
memory
,
time
efficientplatform
,
terabyte
,
forexample
,
approximate
languagemodels
,
effectiveness
,
durme
,
a
tomb
unter
,
durme
,
thetop
k
verb
,
cu
sketch
,
ofits
simplicity
,
attractive
property
,
computesemantic
similarity
,
approximate
pmi
score
,
cu
sketch
,
sketch
vector
,
datastructure
,
streaming
data
,
small
memory
footprint
,
technique
,
streaming
data
,
asmall
sketch
vector
,
technique
,
theinput
stream
,
direction
,
counter
,
bof
main
memory
,
reprocessing
previous
input
,
mainadvantage
,
technique
,
theyrequire
,
storage
,
input
stream
length
,
survey
,
rusuand
dobra
,
cormode
,
hadjieleftheriou
,
literature
,
ount
sketchthe
count
sketch
,
cormode
,
muthukr
ishnan
,
compact
summary
data
structure
,
frequency
,
input
stream
,
input
stream
,
length
nand
user
chosen
parameter
,
algorithmstores
,
frequency
,
following
guarantee
,
frequency
,
oftrue
frequency
,
probability
,
algorithm
,
constant
time
,
updateand
query
operation
,
two
dimensional
array
,
sketch
,
sketch
,
user
chosen
parameter
,
control
theamount
,
tolerable
error
,
returned
count
,
probability
,
returnedcount
,
acceptable
error
,
thesevalues
,
two
dimensional
array
,
guarantee
,
previoussection
,
pairwise
independent
hashfunctions
,
algorithm
,
one
to
one
correspondence
,
therows
,
hash
function
,
thesehash
function
,
input
stream
,
counter
,
corresponding
hash
function
,
indicates
,10
th
position
,
second
,
sketch
array
,
hash
function
,
pairwise
independent
family
,
entire
sketch
array
,
update
procedure
,
counter
,
hash
function
,
multiple
item
,
counter
,
frequency
,
counter
,
overestimate
,
truecount
,
point
query
,
position
,
hash
functions
,
minimumof
,
answer
,
mink
sketch
,
procedure
,
evaluating
hash
function
,
procedures
,
hash
function
,
section5
,
update
,
query
operation
,
advantage
,
space
efficientand
,
constant
update
,
querying
time
,
thecm
sketch
,
advantage
,
distributional
similarity
,
linearity
,
sketch
,
parameter
,
different
input
stream
,
sketch
,
data
stream
,
individual
sketch
,
linearity
,
individual
sketchesto
,
indistributed
setting
,
machine
,
sketch
,
subset
,
corpus
,
varghese
,
conservative
update
,
varghese
,
context
,
networking
,
estimate
,
point
query
,
withfrequency
,
frequency
,
setting
,
data
structure
,
thecounts
,
intuition
,
point
query
returnsthe
minimum
,
theabove
equation
,
unnecessary
updating
,
counter
value
,
distributional
similarity
,
cu
sketch
,
algorithm
,
store
approximate
count
,
contexts
,
word
context
pair
,
cu
sketchusing
fixed
amount
,
counter
,
approximate
pmi
score
,
word
context
pair
,
use
thesepmi
score
,
top
context
,
wordon
,
top
context
vectorsfor
,
sketch
,
cosine
similarity
,
similarity
,
word
pair
,
approximate
top
context
vector
,
tocompute
similarity
,
test
set
,
corresponding
human
judgement
,
wordpair
ranking
,
word
pair
,
subset
,
ws
,
similarity7
,
agirre
,
goodenough
,
word
pair
,
subset
,
rg
65dataset
,
word
pair
,
miller
andcharles
,
word
sim353
wordsim353
,
html7http
,
alfonseca
,
org
pub
ws353simrel
,
data
set
,
word
pair
,
similarity
,
ranking
,
human
ranking
,
spearman
,
rank
correlation
coefficient
,
ranking
,
copy
ofthe
,
ravichandran
,
corpus
,
sentences
,
tokenize
,
lowercase
,
removepunctuations
,
collapse
,
numbers
,
context
,
word
context
pair
,
cu
sketch
,
context
,
surrounding
word
,
window
,
contextwords
,
wordpairs
,
corpus
,
gigaword
,
gigaword
,
corpus
sub
gw
gwg
w
set
wb1
wb2size
,
million
,
stream
size
,
billion
,
baseline
,
exact1000
,
exact
count
,
exact
count
,
word
contextpairs
,
corpus
,
mainmemory
,
context
vectors
,
testset
,
former
baseline
,
test
word
,
latterbaseline
,
context
,
mi
value
,
cutoff
,
frequency
ofword
context
pair
,
cutoffs
,
intuition
,
word
contextpairs
,
frequency
,
bet
54data
gw
gw
wb1
gw
wb2model
frequency
cutoff
frequency
cutoff
frequency
,
evaluating
word
,
cu
count
,
ter
choice
,
cutoff
,
result
,
baseline
result
,
capturingthe
semantic
similarity
,
second
,
context
foreach
target
word
,
semantic
similarity
,
possible
context
,
cutoff
,
corpus
,
test
sets
,
approximate
count
,
cu
sketchwith
depth
,
counter
,
previous
observation
,
context
,
target
word
to1000
,
cutoff
,
however
,
appropriate
frequency
cutoff
,
eachcorpus
,
approximate
count
,
effectiveas
exact
count
,
gw
wb2
,
frequency
cutoff
,
reason
,
dependence
,
frequency
cutoff
,
overestimation
,
low
frequent
item
,
thesize
,
cu
sketch
,
counter
andstream
size
,
compared
,
stream
size
,
advantage
,
thesketch
,
context
,
andword
context
pair
,
fixed
memory
,
counter
,
not8our
goal
,
distributional
similaritymethod
,
framework
scale
,
exact
method
,
exact
count
,
word
context
pair
,
number
increase
,
increase
,
context
vector
,
allpossible
word
,
sketch
,
computessemantic
similarity
,
addition
,
linearity
,
sketch
allowsus
,
sketchwithout
,
sketch
,
scratch
,
parallelization
,
mapreduceframework
,
framework
toany
kind
,
association
,
framework
,
cu
sketchto
scale
distributional
similarity
,
cancompute
similarity
,
thatare
,
sketch
,
return
similarity
,
framework
,
usingthe
exact
count
,
frequency
cutoff
,
framework
robust
,
frequency
cutoffs
,
addition
,
exploringthis
framework
,
entity
,
expansion
problem
,
acknowledgmentswe
,
anonymous
reviewer
,
helpfulcomments
,
nsf
,
google
research
grantgrant
,
alfonseca
,
janakravalova
,
aitor
soroa
,
similarity
,
relatedness
,
wordnet
based
approach
,
hlt
naa
cl
,
large
languagemodels
,
machine
translation
,
proceeding
ofthe
,
joint
conference
,
empirical
methodsin
natural
language
processing
,
cormode
,
marios
hadjieleftheriou
,
frequent
item
,
data
stream
,
muthukrishnan
,
count
minsketch
,
application
,
algorithm
,
cristian
estan
,
varghese
,
new
directions
,
traffic
measurement
,
commun
,
ruppin
,
placing
search
,
context
,
concept
,
cm
transaction
,
information
system
,
synopsis
,
linguistic
theory
,
editor
,
selected
paper
,
longman
,
amit
goyal
,
suresh
venkatasub
ramanian
,
large
scale
nlp
,
language
modeling
,
north
american
chapter
,
association
,
amit
goyal
,
jagadeesh
jagarlamudi
,
suresh
venkatasubramanian
,
sketchingtechniques
,
large
scale
nlp
,
corpus
workshop
,
conjunction
,
naa
cl
hlt
,
gigaword
,
linguistic
dataconsortium
,
distributional
structure
,
editor
,
philosophy
,
linguistics
,
oxford
press
,
new
york
,
levenberg
,
mile
,
stream
based
randomised
language
model
,
inp
roceedings
,
emn
lp
,
miller
,
contextual
correlates
,
semantic
similarity
,
language
,
pantel
,
crestan
,
arkady
borkovsky
,
popescu
,
vishnu
vyas
,
scaledistributional
similarity
,
entity
,
expansion
,
inp
roceedings
,
emn
lp
,
deepak
ravichandran
,
pantel
,
eduardhovy
,
algorithm
,
usinglocality
sensitive
hash
function
,
high
speed
,
annual
meeting
,
association
,
computational
linguistics
,
rubenstein
,
goodenough
,
contextual
correlate
,
synonymy
,
florin
rusu
,
alin
dobra
,
statistical
analysisof
sketch
estimator
,
turney
,
littman
,
semantic
orientation
,
hundred
billion
word
corpus
,
turney
,
uniform
approach
,
analogies
,
synonym
,
antonym
,
association
,
proceedings
,
col
ing
,
durme
,
ashwin
lall
,
probabilistic
counting
,
randomized
storage
,
international
jontconference
,
artifical
intelligence
,
durme
,
ashwin
lall
,
pointwise
mutual
information
,
advances
,
neural
information
processing
systems22
